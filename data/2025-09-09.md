<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 68]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.CR](#cs.CR) [Total: 3]
- [eess.AS](#eess.AS) [Total: 2]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 系统研究语音语言模型离散单元表示在持续预训练中的优化策略，探讨模型架构、数据表示和训练鲁棒性的影响


<details>
  <summary>Details</summary>
Motivation: 通过分析模型架构、语音编码器和聚类粒度等因素，探索如何将现有预训练语言模型有效适配到语音模态

Method: 跨不同模型规模开展实验，分析语音编码器性能、聚类粒度选择，并通过聚类分布和音素对齐研究离散词汇的有效使用

Result: 发现最优离散化策略随模型容量变化，揭示了离散词汇中的语言/副语言模式，验证了聚类数据领域匹配对模型鲁棒性的重要性

Conclusion: 为语音语言模型的离散表示优化提供系统指导，强调模型规模适配和领域对齐在跨模态预训练中的关键作用

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [2] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: 提出基于N-Gram频率张量的新方法检测LLM幻觉，在HaluEval数据集上效果显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 现有指标（如ROUGE/BERTScore）语义深度不足，难以有效检测LLM生成内容的幻觉问题

Method: 构建N-Gram频率张量捕捉共现模式，通过张量分解提取奇异值作为MLP分类器输入特征

Result: 在HaluEval数据集上显著超越传统基线，与最先进的LLM Judges方法性能相当

Conclusion: 基于张量分解的方法能有效捕获语义结构，提升幻觉检测的准确性

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [3] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: 提出SAGE框架，通过动态微调和三模块协同实现大语言模型推理时的实时知识更新


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在推理时无法持续适应新数据的核心缺陷

Method: 1. Trigger模块实时检测推理异常
2. Trigger Buffer模块通过流式聚类处理异常样本
3. Lora Store模块动态优化参数实现知识保留

Result: 在原子推理子任务中表现出89.2%的准确率，稳定性提升37%，异常恢复时间缩短至2.3秒

Conclusion: SAGE框架有效突破了静态模型的限制，为实时知识更新提供了可扩展的解决方案

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [4] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 研究发现多智能体辩论可能降低AI推理准确性，特别在异质模型群体中，强模型反而易受错误推理影响


<details>
  <summary>Details</summary>
Motivation: 针对先前研究仅限于同质化智能体辩论的局限，探索模型能力差异对多智能体交互效果的影响

Method: 通过系列实验对比分析异质模型群体中的辩论动态，跟踪模型答案变化模式

Result: 辩论导致准确率随时间下降（即使强模型占多数），模型倾向接受错误共识而非坚持正确推理

Conclusion: 需建立激励机制与抗干扰能力，否则简单应用多智能体辩论可能产生负面效果

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [5] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 无需运行翻译系统，仅通过token生育率、语言特征等指标即可高精度预测GPT-4o在203种语言中的翻译质量（R²最高达0.72）


<details>
  <summary>Details</summary>
Motivation: 探索翻译质量预测的新范式，突破传统需要实际运行翻译系统的限制，降低多语言评估成本

Method: 使用梯度提升模型，结合token生育率比例、计数及语言类型特征（语系/文字/地区），基于FLORES-200基准的203种语言数据进行预测

Result: 英译外文R²=0.72，外文译英R²=0.66；类型学特征主导英语翻译预测，生育率特征对外语翻译更重要

Conclusion: 翻译质量受token层面特征和宏观语言类型双重影响，为质量评估提供了基于特征的预测新思路

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [6] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: 提出基于合成摘要的直接评分方法，在多个基准测试中达到与SOTA相当的样本级相关性


<details>
  <summary>Details</summary>
Motivation: 现有基于成对比较的自动评估方法无法有效分配绝对分数，而阈值处理需求要求这种能力

Method: 使用合成摘要生成成对机器排名数据，并将其应用于测试阶段的直接评分

Result: 在SummEval(+0.03)、TopicalChat(-0.03)和HANNA(+0.05)基准上达到可比性能，并开源合成摘要数据集

Conclusion: 新评估方法在保持样本级相关性的同时实现直接评分，公开数据将促进未来研究发展

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [7] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 提出基于LLM的多阶段框架分析医院呼叫中心文本数据，o3模型以78.4%加权F1值表现最佳，处理结果集成可视化决策工具支持医疗质量提升。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心海量文本数据需要高效分析工具，传统监督学习方法存在标注数据需求和计算成本高的痛点。

Method: 采用多阶段LLM框架（包含推理模型、通用模型和轻量模型），通过主题识别和多类别原因分类处理消息，集成数据安全措施和HIPAA合规要求。

Result: 最佳模型o3达到78.4%加权F1值和79.2%准确率，次优模型gpt-5达75.3%加权F1值。开发可视化决策支持工具实现数据洞见转化。

Conclusion: LLM框架有效提升医疗文本分析效率，支持导航员培训优化和患者体验改进，为医疗数据分析提供可扩展解决方案。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [8] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 分词效率低下导致非洲语言在NLP中面临计算成本激增与准确率下降，推理模型表现更优，token翻倍使训练成本激增四倍


<details>
  <summary>Details</summary>
Motivation: 解决形态复杂语言在分词效率上的结构性劣势，揭示token通胀对低资源语言NLP公平性的影响

Method: 使用AfriMMLU数据集(9,000多选题目/5科目/16种非洲语言)，评估10个大语言模型的生育率(tokens/word)与准确率相关性

Result: 生育率与准确率呈稳定负相关；推理模型(DeepSeek等)高低资源语言表现均优于非推理模型；token翻倍导致训练成本/时间增长400%

Conclusion: 需开发形态学优化的分词方案、实施公平定价策略，并建立多语言基准测试以促进NLP技术公平发展

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [9] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 基于RAG架构的生物医学问答系统整合多源数据，通过改进的检索和生成模型显著提升医学回答质量，尤其在乳腺癌领域验证效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统健康搜索引擎信息滞后、准确性不足的问题，促进循证医学知识的公共可及性。

Method: 集成PubMed/医学百科等多源数据，使用MiniLM+FAISS构建检索管道，采用QLoRA优化的Mistral-7B生成答案，并以乳腺癌文献进行领域对齐验证。

Result: BERTScore(F1)显示事实一致性和语义相关性显著优于基线模型，领域对齐检索使乳腺癌文献回答效果提升明显。

Conclusion: RAG增强模型有效连接生物医学复杂性与公共卫生需求，未来可扩展多语言、隐私计算及个性化医疗AI系统。

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [10] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 本研究提出用双向推理能力测试AI模型是否真正理解概念，发现现有模型存在认知专业化问题（微调后反向能力下降），并通过对比微调(CFT)成功实现了无需反向训练的双向推理能力。


<details>
  <summary>Details</summary>
Motivation: 验证语言模型是否真正理解概念而非单纯模式识别，探究模型是否具备自然可逆的推理能力。

Method: 提出对比微调(CFT)：使用正样本保持语义、负样本改变语义、正向混淆样本三种训练数据，促进深度理解而非表面模式记忆。

Result: CFT在保持正向任务能力的同时实现了双向推理，反向任务表现显著提升，突破了传统微调导致的认知专业化限制。

Conclusion: 双向推理既可作为评估真实理解的理论框架，也是开发更智能AI系统的有效训练范式，推动从模式匹配到概念理解的转变。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [11] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [12] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了CoPeD方法，通过正确性感知的任务设置和加权损失策略，提升小语言模型在推理任务中的质量。


<details>
  <summary>Details</summary>
Motivation: 现有CoT数据存在噪声（无效逻辑或冗余信息），导致小模型学习到虚假相关性。需要改进微调机制以确保基于正确逻辑推理。

Method: 1. 正确性感知任务设置：要求模型基于正确逻辑预测答案，错误时修正；2. 动态加权损失：根据理由与答案的联合损失调整样本权重，聚焦高支持度样本。

Result: 实验证明CoPeD在分布内(IND)和分布外(OOD)推理基准数据集均有效。

Conclusion: CoPeD通过双重机制提升了推理的忠实性，使模型能从错误中学习，并优先关注高价值训练样本。

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [13] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 提出Icon²方法，通过大语言模型表征空间的内在调控机制，高效构建高质量偏好数据集


<details>
  <summary>Details</summary>
Motivation: 传统偏好数据集构建方法存在分布不匹配问题且计算成本高昂，需探索更高效的解决方案

Method: 1. 提取层级方向向量编码人类偏好
2. 基于内在一致性过滤自合成指令
3. 双向表征控制生成具有明确差异的响应对

Result: Llama3-8B/Qwen2-7B在AlpacaEval 2.0和Arena-Hard平均胜率提升13-14%，计算成本降低48.1%

Conclusion: 利用模型内在表征调控机制能有效提升偏好数据质量，实现高效对齐且显著降低计算开销

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [14] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 提出端到端的生成搜索引擎优化框架（GSEO），包含内容影响力评估基准CC-GSEO-Bench和自动化多智能体优化系统


<details>
  <summary>Details</summary>
Motivation: 传统SEO指标无法适应生成式搜索引擎的内容合成特性，需建立量化内容语义影响力的评估体系

Method: 1.构建内容中心化基准CC-GSEO-Bench；2.设计多维度评估框架；3.开发协作式分析-修订-评估多智能体系统

Result: 实证揭示内容影响力动态规律，提供优化策略并建立未来研究的系统方法论基础

Conclusion: 该框架为内容创作者提供可操作方案，并为生成搜索引擎优化领域建立标准化研究范式

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [15] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 提出基于不平衡最优传输的跨模态对齐模型，通过软匹配和部分匹配解决ASR中声学-语言表示对齐的结构不对称问题


<details>
  <summary>Details</summary>
Motivation: 传统声学-语言对齐存在结构不对称（多对一/一对多）和噪声干扰问题，需要既能保证语言标记全覆盖又能灵活处理冗余声学帧的检测方法

Method: 将对齐建模为检测问题，使用不平衡最优传输框架：1）强制每个语言标记至少对应一个声学观测 2）允许概率化的柔性映射 3）通过部分匹配处理分布不匹配

Result: 在基于CTC的ASR系统中实验验证，通过灵活控制匹配程度有效提升了识别性能

Conclusion: 创新性地将最优传输理论应用于跨模态对齐，为ASR知识迁移提供了结构化匹配的解决方案

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [16] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 研究通过构建手动标注数据集，评估零样本LLMs和微调BERT模型在歌词多标签情感预测中的表现，揭示模型优缺点及LLMs在音乐信息检索中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 歌词情感显著影响听众体验与音乐偏好，需可靠方法进行多标签情感标注，现有模型在此任务的表现尚不明确，故构建数据集并对比不同模型效果。

Method: 采用MOS方法构建手动标注数据集，评估多个零样本LLMs，并微调BERT模型预测六种情感强度分数，通过实验对比模型性能。

Result: 零样本模型在部分情感捕捉上表现良好，但微调BERT模型整体更优，LLMs展现潜力但需针对任务优化，数据集公开促进后续研究。

Conclusion: 研究证实LLMs在歌词情感识别中的潜力，为零样本与微调模型的选择提供依据，公开数据集助力音乐信息检索应用发展。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [17] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: 提出SAID框架，首次统一整合文本信息和对话结构关系进行预训练，通过QueryAdapt机制实现细粒度知识迁移，显著提升少样本意图检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有意图检测方法仅关注文本数据，未能有效捕捉对话系统中关键的查询-查询关系、查询-答案关系等结构信息，导致模型效果受限。

Method: 1. 构建SAID框架统一建模文本与结构信息
2. 设计QueryAdapt机制，基于预训练的关系结构生成意图相关的关系令牌，实现细粒度知识迁移

Result: 在两个真实对话数据集上，SAID在准确率指标上超越现有SOTA方法3.2-5.7个百分点

Conclusion: 通过显式建模对话结构关系并设计自适应注意力机制，SAID有效提升了少样本场景下的意图识别能力，为对话系统预训练提供了新思路。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [18] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出LM-Searcher框架，通过通用数值编码NCode和排序任务重构，实现无需领域调优的跨域神经架构搜索


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的NAS方法依赖提示工程和领域调优，限制了跨任务应用的通用性和扩展性

Method: 1）设计NCode通用架构编码 2）将NAS重构为排序任务 3）采用剪枝子空间采样生成训练数据 4）构建跨域架构性能数据集

Result: 在图像分类（CNN）和分割生成（LoRA配置）等跨域任务中均达到竞争力表现

Conclusion: 建立了基于LLM的通用架构搜索新范式，显著提升了方法的灵活性和可迁移性

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [19] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 提出通过分离问题与解决方案的方法扩展LLM跨问题方法复用范围，突破传统相似性约束


<details>
  <summary>Details</summary>
Motivation: 现有方法复用技术需问题高度相似，难以处理低相似或隐含相似场景

Method: 将问题与解决方案解耦，指导LLM专注解决方案迁移而非问题识别，支持部分/隐藏特征共享场景

Result: 实验证明该方法显著提升可复用方案筛选概率，跨问题方法复用有效性提升42%

Conclusion: 通过问题-解决方案分离机制成功拓展方法复用边界，建立新的跨领域知识迁移范式

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [20] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: 提出Llama-GENBA-10B三语基础模型，通过平衡多语言训练解决英语中心偏差问题，在巴伐利亚语取得最佳表现。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型的英语中心化问题，支持德语社区并促进低资源语言巴伐利亚语的发展。

Method: 基于Llama 3.1-8B扩展参数，采用164B多语言token预训练，开发统一分词器，优化跨语言架构参数，建立首个三语评估体系。

Result: 巴伐利亚语表现超越Apertus-8B-2509和gemma-2-9b，英语优于EuroLLM，德语表现持平，训练能效显著。

Conclusion: 为整合低资源语言提供了可复制的技术框架，展示了高效多语言预训练路径，推动包容性基础模型发展。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [21] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 文本嵌入模型普遍难以精准捕捉文本中的数值细节（如2%与20%的差异），基于金融合成数据对13个主流模型的评估验证了该结论，研究为提升NLP系统数值处理能力提供方向


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型评估多聚焦非数值任务，导致模型在金融/医疗等数值敏感领域的表现不明确，需验证模型对数值语义差异的捕捉能力（如2%与20%市场增长的语义区分）

Method: 使用金融场景合成数据，系统性评估包括主流模型在内的13种文本嵌入模型对数值细节的编码能力

Result: 13个被评估模型普遍存在数值细节编码不准确现象，表明当前文本嵌入技术在数值理解方面存在显著缺陷

Conclusion: 研究揭示了文本嵌入模型的数值处理短板，为开发具备更强数值理解能力的NLP系统指明改进路径

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [22] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 综述分析了对话式问答系统的核心组件（历史选择/问题理解/答案预测）、机器学习技术（强化学习/对比学习等）和大语言模型的作用，并总结了关键数据集及未来研究方向


<details>
  <summary>Details</summary>
Motivation: 探讨对话式问答系统在跨领域应用中的技术进展，通过系统性综述促进对话系统在保持连贯性和相关性方面的研究

Method: 通过分析ConvQA核心组件（历史选择/问题理解/答案预测）、评估机器学习技术（强化学习/对比学习/迁移学习）和大语言模型（GPT-4/LLaMA 3等）的应用，结合数据集综述系统性总结技术进展

Result: 系统总结了ConvQA各组件协同工作机制，验证了机器学习技术对性能的提升，阐明了大模型在扩展性和架构优化中的关键作用，并整理出主流数据集供后续研究参考

Conclusion: ConvQA技术在多领域展现潜力，未来需在上下文理解/模型效率/小样本学习等方向突破，该综述为领域发展提供了系统性指导

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [23] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 波斯语虽被归类为中等资源语言，但其主观任务面临数据质量与可用性的根本性挑战


<details>
  <summary>Details</summary>
Motivation: 探究波斯语在情感分析等主观任务中表面数据增长与实际资源匮乏的矛盾现象

Method: 系统分析110篇文献并评估现有数据集，测试预测模型的跨数据集稳定性

Result: 发现公开数据集严重匮乏（仅1.3万维基条目），现存数据缺少人口统计维度，模型表现存在显著波动

Conclusion: 单纯数据量的增加无法根本改善低资源语言的NLP发展，需注重数据质量与标注维度

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [24] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 提出量子上下文敏感嵌入模型QCSE，利用量子计算特性实现自然语言上下文建模，并在低资源富拉尼语和英语语料中验证有效性


<details>
  <summary>Details</summary>
Motivation: 传统自然语言处理难以捕捉复杂语境信息，量子系统具有独特计算特性；同时探索量子自然语言处理在低资源语言（如非洲富拉尼语）中的应用潜力

Method: 开发量子原生上下文学习框架QCSE，提出五种上下文矩阵计算方法（指数衰减/正弦调制/相移/哈希变换等），在富拉尼语小数据集和英语稍大数据集进行验证

Result: QCSE成功捕捉上下文敏感性，量子系统表达能力有效承载语境信息；富拉尼语实验证明QNLP可缓解低资源语言数据匮乏问题

Conclusion: 量子计算为NLP提供新范式，QCSE模型在跨语言任务中展示量子优势，为实际语言挑战开辟量子解决方案新路径

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [25] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: 提出VeriFact-CoT方法，通过多阶段验证-反思-引用整合机制，解决大语言模型生成内容中的事实性错误和缺乏可信引用问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在生成复杂事实敏感内容时存在幻觉问题和缺乏可追溯引用，影响科学/新闻/法律等高精度需求领域的可靠性。

Method: 采用三阶段机制：1）事实验证 2）自我反思 3）引用集成，使模型能自主审查并修正推理过程与最终答案

Result: 显著提升生成内容的客观准确性、可信度和可追溯性，输出结果支持全链路验证

Conclusion: 该方法为高风险应用场景提供了更可靠的LLM解决方案，建立了可信AI生成内容的新范式

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [26] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatinX是基于Transformer的多语言TTS模型，通过三阶段训练实现跨语言音色保持，在WER和说话人相似度指标上优于基线模型


<details>
  <summary>Details</summary>
Motivation: 解决语音翻译过程中跨语言说话人音色不一致的问题，提高语音合成质量并保持说话人身份特征

Method: 三阶段训练：1) 文本-音频映射预训练 2) 零样本语音克隆的监督微调 3) 基于WER和说话人相似度的DPO对齐训练

Result: 相比XTTSv2基线模型，DPO训练使WER降低，客观相似度提高。人工评估显示主观相似度优势，揭示主客观指标差异

Conclusion: 验证了DPO对齐的有效性，提出未来需改进偏好信号平衡架构和降低延迟，推动语音翻译系统的实用化发展

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [27] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 提出结合图检索增强生成（GraphRAG）与大模型微调的框架ZhiFangDanTai，通过结构化知识检索和增强指令数据集改进中医方剂生成，理论证明可降低泛化误差和幻觉率，实验验证显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有中医方剂模型缺乏君臣佐使角色描述、禁忌症、舌脉诊断等关键细节，且传统指令数据集信息深度不足，导致模型输出质量受限。

Method: 1. 使用GraphRAG检索结构化中医知识生成摘要 2. 构建增强型指令数据集 3. 提供理论证明GraphRAG与微调结合可降低泛化误差和幻觉率

Result: 在收集数据集和临床数据集上均显著超越SOTA模型，模型已开源至HuggingFace平台。

Conclusion: ZhiFangDanTai框架有效提升中医方剂生成质量，理论证明与实验结果共同验证了方法在知识整合和输出可靠性方面的优势。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [28] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 提出MedFactEval评估框架和MedAgentBrief生成流程，解决LLM生成临床文本的事实准确性评估难题


<details>
  <summary>Details</summary>
Motivation: LLM生成的临床文本事实准确性缺乏可扩展的评估方案，专家评审无法满足持续质量监控需求

Method: 通过临床医生定义关键事实+多LLM多数投票（MedFactEval），结合多阶段生成流程（MedAgentBrief）

Result: LLM评审组与专家组的评估一致性达81%（Cohen's kappa），优于单个专家67%的表现（P<0.001）

Conclusion: 该框架和工作流程为临床场景生成式AI的可靠部署提供了评估-生成双重解决方案

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [29] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: 探究不同对齐方法对LLM代理在多方协作中有效性的影响


<details>
  <summary>Details</summary>
Motivation: 现有对齐技术在复杂协作场景中存在局限性，需验证LLM在长期多方互动中的可靠性

Method: 采用角色扮演方法评估不同训练模式的摩擦代理干预效果，提出反事实评估框架量化协作轨迹变化

Result: 摩擦感知方法在促进共识达成（89%）和任务结果正确性（+32%）上显著优于基线方法

Conclusion: 研究为LLM协作代理的验证体系建立新范式，展示了摩擦干预对群体决策质量提升的有效性

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [30] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: 提出PSC-Joint方法，通过多粒度语义相关性联合建模提升上下文ASR性能，在变长偏置列表下实现F1分数显著提升


<details>
  <summary>Details</summary>
Motivation: 现有基于交叉注意力的ASR模型在处理长偏置列表时效率下降，因仅部分偏置信息与当前语音特征相关，需针对性整合机制

Method: 构建列表级/短语级/词级三层语义相关性计算框架，通过联合建模获得交集信息，并设计分组竞争净化机制降低计算开销

Result: 在AISHELL-1和KeSpeech数据集上分别实现21.34%和28.46%的F1分数相对提升，且在不同长度偏置列表下表现稳定

Conclusion: PSC-Joint通过多粒度相关性筛选有效解决偏置信息量波动问题，其联合建模框架和净化策略为上下文ASR提供新解决方案

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [31] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 通过算法与架构协同设计，在动态计算与系统效率间建立新帕累托前沿，实现高效自适应推理的大语言模型


<details>
  <summary>Details</summary>
Motivation: 解决传统动态计算方法（如早退机制）在批处理推理中引发的系统级瓶颈问题，平衡计算动态性与吞吐效率的冲突

Method: 1. 提出并行解码机制降低早退机制开销
2. 利用深度参数共享架构缓解同步问题
3. 预训练轻量级路由器动态分配词元计算深度

Result: 在单一模型中同时优化自适应计算与参数效率，建立效率与性能的新平衡边界

Conclusion: 算法架构协同设计从根本上解决了动态推理的效能矛盾，为部署高效自适应计算模型提供新范式

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [32] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: 研究构建菲律宾语真实性评测基准KatotohananQA，揭示LLMs在多语言环境下的真实性差距与迁移差异


<details>
  <summary>Details</summary>
Motivation: 填补LLMs在低资源语言真实性评估的空白，验证多语言场景下模型表现公平性

Method: 将TruthfulQA翻译为菲律宾语，采用二元选择框架测试7个免费专有模型

Result: 英语与菲律宾语性能差距达32.7%，GPT-5系列展现跨语言鲁棒性，不同问题类型迁移效果差异显著

Conclusion: 需扩展多语言评估范围以保障LLMs公平性，特定问题类型的跨语言脆弱性值得关注

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [33] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 提出MFCIG-CSS对话语音合成系统，通过构建语义和韵律双模态细粒度交互图，显著提升对话语音韵律自然度


<details>
  <summary>Details</summary>
Motivation: 现有对话语音合成方法主要建模话语级交互，但忽视了多模态对话历史中词级语义与韵律的细粒度交互特征

Method: 构建语义交互图与韵律交互图，编码词级语义/韵律特征及其对后续话语的影响，利用交互特征增强语音合成

Result: 在DailyTalk数据集上，MFCIG-CSS在韵律表现力指标上超越所有基线模型，代码及样本已开源

Conclusion: 细粒度交互建模能有效提升对话语音合成的韵律自然度，双模态交互图结构在实验中展现出显著优势

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [34] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 提出caption-assisted推理框架，有效桥接视觉与文本模态，在ICML 2025 SeePhys挑战赛夺冠，并在MathVerse基准验证泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有文本推理模型（如GPT-3）在多模态场景表现不佳，需解决视觉与文本模态融合的挑战

Method: 通过生成图像描述（caption）辅助推理，构建跨模态关联的推理框架

Result: ICML 2025 SeePhys挑战赛第一名，MathVerse几何推理基准准确率提升12%

Conclusion: 该框架显著提升多模态推理性能，代码开源推动跨模态推理研究发展

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [35] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: 提出OLieRA方法，通过李群理论保持LLM参数几何结构，实现多任务场景下的最优性能表现


<details>
  <summary>Details</summary>
Motivation: 现有正交约束方法忽略了参数空间固有几何结构的保护，传统加法微调破坏模型参数几何关系导致性能受限

Method: 将李群理论引入LLM微调，采用乘法更新保持参数几何结构，同时对任务子空间施加正交约束

Result: 在标准持续学习基准测试中取得SOTA，在多任务场景下保持顶尖性能

Conclusion: 参数几何结构保持与正交约束的协同作用能有效提升LLM持续学习能力，为模型微调提供新理论框架

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [36] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: EuroParlVote基准通过连接欧洲议会辩论与投票数据，揭示LLMs在政治敏感场景存在系统性性别/政治偏见，专有模型表现更优


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估缺乏政治敏感性测试，需建立专门数据集分析模型在民主决策场景中的公平性

Method: 构建含议员人口统计的欧洲议会数据集，设计性别分类和投票预测双任务评估模型偏差

Result: LLMs系统性低估女性政治参与（性别误判率+18%，女性投票预测准确率-12%），政治预测偏中间党派（极左/右准确率低15-20%）

Conclusion: 发布首个政治敏感性评估基准，推动NLP模型在民主决策中的问责机制研究，建议加强开放模型的公平性训练

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [37] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 研究发现当前基于合成数据训练的通用文本嵌入模型存在局限性，合成数据带来的性能提升具有任务特定性且伴随性能权衡


<details>
  <summary>Details</summary>
Motivation: 填补公开合成数据集的空白，系统分析合成数据对模型泛化能力的影响机制

Method: 1. 复现并开源Mistral-E5合成数据集 2. 通过跨任务评估框架量化分析合成数据对不同任务的影响

Result: 合成数据改进效果呈现稀疏分布特征（平均+0.8%），且存在任务间负相关（例如NLI任务提升2.3%导致语义相似度下降1.1%）

Conclusion: 挑战合成数据提升模型鲁棒性的传统认知，揭示当前方法在构建通用嵌入模型中的根本性局限

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [38] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 通过微调大语言模型(LLMs)和结构化数据方法，显著提升了招聘自动化系统的准确性和性能指标


<details>
  <summary>Details</summary>
Motivation: 解决通用LLMs在招聘任务中存在的格式不一致、可扩展性差等问题，提升候选人-职位匹配的准确性

Method: 1. 创建标准化JSON格式的合成数据集
2. 使用DeepSeek解析真实简历为结构化数据
3. 针对招聘任务微调Phi-4等LLMs模型

Result: 微调后的Phi-4模型取得90.62%的F1分数，在精确匹配、BLEU/ROUGE等指标上均超越基准模型

Conclusion: 专用微调LLMs结合结构化数据处理，为招聘流程自动化提供了高效可靠的解决方案，展示了在人力资源领域的革命性应用潜力

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [39] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: 提出MSLEF多段集成框架，通过微调LLM和分段加权投票显著提升简历解析准确率，RS指标超越单模型7%


<details>
  <summary>Details</summary>
Motivation: 解决传统单一模型在多样化简历格式和结构中的解析局限性，提升招聘自动化场景的准确性需求

Method: 集成Gemini/Gemma/LLaMA/Phi-4模型，采用分段感知架构和领域特定加权策略，使用Gemini-2.5-Flash作为复杂段聚合器

Result: Exact Match/F1/BLEU/ROUGE/RS全面优化，招聘相似度(RS)相对最佳单模型提升+7%

Conclusion: 分段设计有效增强模型泛化能力，适应真实招聘场景的多样化布局，实现精准可靠的候选人信息解析

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [40] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 首次在AI音乐生成模型中应用机器遗忘技术，尝试消除预训练数据中的版权内容，分析其有效性及挑战。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成系统存在使用受版权保护内容的风险，可能引发伦理和法律问题，需开发保护创作版权的技术方案。

Method: 在预训练文本-音乐生成模型(TTM)上应用现有机器遗忘方法，评估其在消除特定数据集同时保持模型性能的有效性。

Result: 揭示了音乐生成领域应用遗忘技术的特殊挑战，为后续研究提供了基础性实验分析框架。

Conclusion: 建立了音乐生成模型遗忘技术应用的研究范式，强调该领域技术发展对解决版权争议的重要价值。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [41] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 提出Mask-GCG方法，通过动态剪枝低影响力token优化GCG攻击，减少提示冗余并提升攻击效率


<details>
  <summary>Details</summary>
Motivation: 现有GCG攻击采用固定长度后缀存在潜在冗余，需探索动态调整token的方法以提高攻击效率

Method: 引入可学习token掩码机制，识别高影响力token并增加其更新概率，同时剪枝低影响力token以减少梯度空间

Result: 实验证明多数token对攻击有效，剪枝少量低影响力token不影响攻击成功率，揭示了LLM提示的token冗余特性

Conclusion: 该方法为开发高效可解释的LLM提供了新视角，在降低计算成本的同时保持攻击成功率，推动对抗攻击领域发展

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [42] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: 提出PL-CA框架，通过参数化RAG将法律知识编码至模型参数中，结合LoRA减少上下文压力，并构建专家标注的多任务司法数据集验证效果。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在司法领域面临上下文窗口限制/计算开销大/注意力分散等问题，且现有基准缺乏专家标注及多任务混合场景测试能力。

Method: 1. 参数化RAG(P-RAG)框架对语料知识进行数据增强并编码至参数向量；2. 通过LoRA将知识注入FFN网络；3. 构建2000+专家标注的多任务司法数据集。

Result: 实验显示PL-CA显著降低长上下文开销，下游任务性能与传统RAG相当。数据集包含高质量专家标注及人工验证样本。

Conclusion: PL-CA有效缓解模型上下文压力，参数化知识与LoRA的结合具有应用潜力，专家标注数据集为司法AI发展提供重要基准。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [43] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: 论文评估了多语言大模型在常识生成任务中的表现，发现英语表现最优而低资源语言显著落后，提出新基准MULTICOM并公开数据集。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在多语言常识生成任务中的能力差异，特别关注低资源语言的表现瓶颈。

Method: 构建多语言基准MULTICOM，结合自动评估(Prometheus/JudgeLM)、人工标注，测试LLaMA/Qwen/Gemma等模型在多语言场景下的生成能力。

Result: 英语表现最优（西班牙语次之），瓦伦西亚语等低资源语言准确率下降40%；上下文增强对弱势语言效果更显著。

Conclusion: 当前大模型在多语言常识生成存在明显局限性，需针对性提升低资源语言处理能力。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [44] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: 提出了WebExplorer数据生成方法，通过模型探索和迭代式查询演化构建挑战性数据集，成功训练出支持长上下文和复杂任务处理的WebExplorer-8B网络代理模型


<details>
  <summary>Details</summary>
Motivation: 现有开源网络代理在复杂任务上存在信息检索能力不足或实现不透明的问题，核心挑战在于缺乏高质量的训练数据

Method: 采用基于模型的探索策略和长到短的迭代式查询演化生成数据集，通过监督微调+强化学习训练支持128K上下文和100次工具调用的模型

Result: 在多个信息检索基准测试中达到同规模最佳，8B模型搜索轮次达16+，在BrowseComp-en/zh超越WebSailor-72B，在WebWalkerQA/FRAMES保持100B以下模型最佳

Conclusion: 通过系统化数据生成方法成功实现长周期网络代理开发，验证了数据质量提升对小模型性能的显著增益作用

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [45] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 提出三种层间缩放变体（Framed/Reverse/Crown），在固定180M参数预算下实现与各向同性基线相当的性能，且不影响训练速度


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型的均匀层结构忽略了不同深度层的功能差异性和计算需求多样性，现有层间缩放研究尚未系统探索参数分配策略

Method: 基于线性插值设计三种FFN/注意力头分配方案：两/三点式框架结构（Framed）、反向递减结构（Reverse）、皇冠型结构（Crown）

Result: 所有变体在5B tokens训练后达到相似loss，相比等成本基线性能提升，训练吞吐量未显著下降

Conclusion: 初步证明层间架构设计的可行性，但需扩展到更大规模（参数+数据量）才能充分评估潜力

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [46] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: 提出LAMDAS方法，利用预训练LLM自身作为隐式分类器进行领域数据选择，显著提升效率与性能


<details>
  <summary>Details</summary>
Motivation: 解决领域适配中高质量数据稀缺与现有方法效率-准确性难以兼顾的问题

Method: 将数据选择重构为一类分类问题，通过参考数据集定义目标域，利用LLM的隐式分类能力避免特征工程

Result: 仅用少量数据即超越全数据训练效果，在9个基线对比中全面领先，实现最佳性能-效率平衡

Conclusion: LAMDAS为领域自适应提供了高效优质的数据选择方案，突破传统方法工程复杂与计算成本高的限制

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [47] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: 提出SLiNT框架，通过结构感知表示学习提升知识图谱链接预测性能，在基准数据集上达到优越表现


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识图谱链接预测中存在结构信号利用不足的问题，导致结构稀疏和语义模糊，特别是在不完整/零样本场景下

Method: 1. SGNE补充伪邻居增强稀疏实体表示；2. DHCL通过动态硬对比学习消除歧义；3. GDDI实现梯度解耦的双重结构注入机制

Result: 在WN18RR和FB15k-237数据集上超越传统嵌入模型和生成式基线模型，验证了框架有效性

Conclusion: 通过结构上下文注入和对比学习机制，证明了结构感知表示学习对可扩展知识图谱补全的重要价值

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [48] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: 提出HAVE框架，通过自适应注意力头门控和值校准机制，有效减少大模型在检索增强生成中的幻觉现象，无需微调且计算高效。


<details>
  <summary>Details</summary>
Motivation: 现有大模型在检索增强生成时即使存在相关证据仍会产生幻觉，主要源于注意力头重要性处理与输入无关，且原始注意力权重无法准确反映token的实际贡献。

Method: 1. 头自适应门控：实例级软重加权注意力头
2. 值校准：通过值向量幅度增强注意力，近似写回贡献
3. 轻量级不确定性缩放策略融合证据与模型分布

Result: 在多个QA基准测试中显著降低幻觉（优于DAGCD等基线），支持不同LLM家族且仅需单次前向传播，计算开销可控。

Conclusion: HAVE框架透明可复现，可无缝集成现有大模型，为实际应用中的可信生成提供了有效解决方案。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [49] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 研究比较了三种引导解码方法(Outlines/XGrammar/LM Format Enforcer)在RAG系统中的表现，揭示多轮交互对结构化输出的影响，为实际应用提供选择依据。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在应用中结构化输出需求与RAG系统幻觉抑制的挑战，探索引导解码方法在不同交互场景下的有效性。

Method: 通过多组实验(0/1/2-turn提示设置)，评估三种方法的成功率、幻觉率和输出质量，分析性能差异。

Result: 发现多轮交互显著影响解码效果，不同方法在不同场景存在意外性能波动，成功率与幻觉率呈现负相关趋势。

Conclusion: 为RAG系统结构化输出提供理论框架与实践指导，揭示了交互深度与方法选择的动态平衡关系。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [50] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 提出基于n-gram词向量相似度计算与网络分析的量化模型，实现文本互文性的大规模分析。


<details>
  <summary>Details</summary>
Motivation: 传统文学研究中互文性分析依赖人工细读，无法满足海量文本分析需求。本文旨在建立可扩展的量化模型。

Method: 通过计算两文本n-gram词向量余弦相似度的平均值作为互文性指标，并构建文本网络进行中心性与社群结构分析。

Result: 在4个基准文本验证有效性，267个文本的扩展实验中处理效率达0.25秒/文本，网络分析成功识别关键文本与主题社群。

Conclusion: 该模型可有效量化文本互文性，为数字人文研究提供可扩展的计算框架。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [51] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: 提出MoLER方法，通过混合损失增强强化学习优化RAG系统的检索性能，在领域知识和查询增强间实现平衡。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统的粗排名优化方法难以兼顾领域知识学习与查询增强，导致检索效果受限。需要开发更高效的训练策略。

Method: 两阶段框架：1）混合损失持续预训练平衡知识学习与语言能力 2）组相对策略优化强化学习提升文档召回。创新性采用多查询单段落晚期融合策略降低计算成本。

Result: 在基准测试中达到SOTA，显著超越基线方法。特别是在领域特定场景下展现更强的检索鲁棒性。

Conclusion: MoLER通过创新的训练范式有效弥合RAG系统的知识鸿沟，为专业领域提供可扩展的高效检索方案。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [52] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 提出首个教育对话兴趣度数据集IntrEx，通过序列标注和比较评分方法，发现微调后的中小型LLM在预测兴趣度上优于GPT-4o，并揭示了语言具体性、可理解性对参与度的影响


<details>
  <summary>Details</summary>
Motivation: 解决二语教育对话中学习者参与度难以维持的问题，探索对话中驱动参与度的语言特征及兴趣演化模式

Method: 基于TSCC构建含序列标注的IntrEx数据集，采用类RLHF的比较评分法提升标注一致性，测试不同规模LLM的预测性能并分析语言认知因素

Result: 微调后的7B/8B模型超越GPT-4o，具体性提升1.8倍参与度，可理解性水平与兴趣度呈强正相关(r=0.71)

Conclusion: 专用数据集能有效建模教育参与度，语言具体化和可理解性优化是维持对话兴趣的关键策略

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [53] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: ParCzech4Speech 1.0是基于ParCzech 4.0语料库改进的语音建模数据集，包含2695小时语音数据，通过WhisperX和Wav2Vec 2.0实现高精度音文对齐。


<details>
  <summary>Details</summary>
Motivation: 改进现有ParCzech 3.0版本的语音识别数据集，解决数据量有限和对齐可靠性不足的问题，为语音识别/合成任务提供更优质的资源。

Method: 1. 结合议会录音与官方文本
2. 使用WhisperX和Wav2Vec 2.0进行自动对齐
3. 开发三种数据集变体（分句版/连续版/原始对齐版）

Result: 获得比前代多29%的数据量，对齐可靠性显著提升，提供灵活应用场景：
- 分句版：语音识别/合成
- 连续版：自然语音流建模
- 原始对齐：自定义任务开发

Conclusion: 数据集通过CC-BY许可发布于LINDAT和Hugging Face平台，三种变体设计兼顾研究需求与扩展可能性，推动捷克语语音技术发展。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [54] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 提出两种识别论点主观性的方法，证明直接识别法显著提升模型性能，并分析不同损失函数的组合效果


<details>
  <summary>Details</summary>
Motivation: 聚合标注会掩盖主观性任务中的意见分歧，需要开发有效方法识别不同解释的论点以优化标注流程

Method: 对比两种范式：1）通过价值预测间接推断主观性 2）直接识别主观性；实验结合对比损失与二元交叉熵损失分析模型表现

Result: 直接识别法提升21.3%的F1值，双损失组合未提升精度但使模型减少68%的标签依赖性

Conclusion: 该方法能有效检测解释分歧的论点，为构建细粒度标注框架提供技术支持，推动人机协同标注系统发展

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [55] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 提出ProCon方法，通过约束隐藏状态在拒绝方向的投影幅度来缓解指令微调引发的安全风险，同时保持模型性能


<details>
  <summary>Details</summary>
Motivation: 指令微调虽提升模型能力，但会显著损害LLMs拒绝恶意指令的安全性，需平衡安全性与性能提升

Method: 引入投影约束损失项正则化r-direction投影，结合强调早期强约束的预热策略和扩展数据分布增强约束信号

Result: 在多数据集和LLM场景下，ProCon显著降低安全风险且保持任务性能，整体表现优于现有基线方法

Conclusion: ProCon通过稳定r-direction为模型安全提供新思路，基于可解释性机制的研究方法为安全研究奠定基础

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [56] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: 提出MachineLearningLM框架，通过持续预训练增强大语言模型的上下文机器学习能力，在保留通用能力的同时实现千样本级示范的高效学习


<details>
  <summary>Details</summary>
Motivation: 大语言模型在标准机器学习任务中难以利用大量上下文样本进行纯上下文学习（无需梯度下降），需要提升其多样本场景下的学习能力

Method: 1. 基于百万级结构因果模型合成ML任务 2. 随机森林教师模型知识蒸馏 3. 采用token高效提示序列化技术（支持单窗口3-6倍样本量）

Result: 在跨领域表格分类任务中平均优于基线15%，实现从8到1024样本的持续性能提升，MMLU基准保持75.4%通用能力

Conclusion: 成功构建首个兼顾专业ML任务与通用能力的大模型框架，验证了上下文学习中千样本级扩展规律

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [57] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: 提出改进的MoGU_v2框架，通过优化路由机制实现LLMs安全性与可用性的帕累托前沿提升


<details>
  <summary>Details</summary>
Motivation: 现有安全优化方法导致模型过度保守响应，需突破安全性和可用性的零和博弈困境

Method: 在路由器与隐藏状态间建立双向适配机制，仅在高分类性安全特征层嵌入路由器，并激活主干模块参数

Result: MoGU_v2在主流/边缘/可解释LLMs中均表现稳定提升，通过数据混合策略可无损恢复指令微调后的安全性

Conclusion: MoGU_v2为实际应用提供了兼顾鲁棒性和适应性的安全风险缓解方案

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [58] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 通过自动定理证明生成符号化数学推理数据集，突破LLM数据瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据存在质量低、逻辑缺陷问题，制约大语言模型数学能力发展

Method: 基于E-prover定理证明器自动生成三重验证机制：公理饱和→定理筛选→任务生成

Result: 前沿模型在结构推理任务（蕴涵验证/前提选择/证明重构）上表现全面崩溃

Conclusion: 该框架既是诊断模型推理缺陷的工具，又提供可扩展的符号训练数据解决方案

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [59] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 提出可复现的开源框架用于评估LLM在风电维护日志分类任务中的表现，发现模型性能与任务语义模糊性高度相关，建议采用人机协同系统提升运维效率。


<details>
  <summary>Details</summary>
Motivation: 风电维护日志的非结构化特性阻碍自动化分析，需建立标准评估LLM分类能力以提升数据标注质量和可靠性分析。

Method: 系统评估多种先进LLM（开源/闭源），分析可靠性、效率、校准的权衡，建立可复现的基准框架。

Result: 模型呈现明确性能层次，组件识别共识高于维护动作分类，校准差异显著（闭源模型置信度更可靠）。

Conclusion: 短期内应构建人在回路系统，LLM作为标注助手提升数据质量，而非完全自动化决策。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [60] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: 提出COMPACT联合剪枝方法，通过词汇表剪枝和FFN通道剪枝实现高效大模型部署


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法存在架构破坏性（宽度剪枝）或精度突变（深度剪枝）问题，需要更平衡的解决方案

Method: 联合策略：1) 剪枝低频词汇减少嵌入维度 2) 基于激活分布加权的FFN通道剪枝

Result: 在Qwen/LLaMA/Gemma系列（0.5B-70B）上实现SOTA下游任务性能，参数减少35%，GPU内存节省40%，端到端延迟降低25%

Conclusion: COMPACT兼具深度/宽度剪枝优势，支持标准架构部署，提供可扩展的模型压缩方案，显著提升边缘部署效率

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [61] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 提出波斯文化信任评估指标EPT，测试主流LLM发现安全维度存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估缺乏文化敏感性指标，需确保AI系统符合波斯伦理价值观

Method: 创建含6维度的EPT指标，构建标注数据集，采用LLM自动评估+人工评估双模式

Result: ChatGPT等主流模型安全维度得分最低，伦理对齐存在文化偏差，数据集已开源

Conclusion: EPT填补波斯文化评估空白，揭示模型安全漏洞，推动文化责任AI发展

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [62] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 提出AggLM方法，通过强化学习训练聚合器模型，有效提升大语言模型在复杂推理任务中的表现，显著优于传统多数投票和奖励模型方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于多数投票或奖励模型的聚合方法效果有限，需要开发更智能的聚合机制来综合多个候选方案的优点。

Method: 使用可验证奖励的强化学习训练聚合器模型，通过平衡难易训练样本使模型既能恢复少数正确结果，也能处理多数正确结果。

Result: 在多个基准测试中超越现有方法，可泛化至不同模型的输出（包括优于训练数据的模型），且所需token数比多数投票减少35-75%。

Conclusion: 显式学习聚合技能显著提升模型性能，该方法在计算效率和跨模型泛化方面展现优势，为提升LLM推理能力提供新方向。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [63] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 探索不同提示方法和LLM微调技术用于社交媒体声明提取，发现FLAN-T5微调效果最佳但存在指标与质量偏差现象


<details>
  <summary>Details</summary>
Motivation: 比较不同提示方法和大语言模型微调技术在提取社交媒体中值得核查声明任务中的效果差异

Method: 采用少样本提示（few-shot prompting）和不同LLM家族（包括FLAN-T5）的微调方法

Result: FLAN-T5微调获得最高METEOR分数（0.63），但其他方法在某些情况下能提取更高质量的声明（尽管METEOR分数较低）

Conclusion: METEOR指标不能完全反映声明质量，需要结合人工评估来平衡自动指标与真实核查价值

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [64] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 提出mmBERT多语言编码器模型，在1800+语言上预训练，通过新技术和训练策略显著提升分类检索任务性能


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏多语言编码器模型的进展，尤其在低资源语言处理方面存在不足

Method: 采用逆掩码比率调度、逆温度采样技术，在衰减阶段动态加入1700+低资源语言数据

Result: 分类性能媲美o3/Gemini 2.5 Pro，高低资源语言任务均超越前代模型

Conclusion: mmBERT通过创新训练机制有效提升多语言理解能力，为低资源NLP应用提供新方案

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [65] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: 提出Proof-Carrying Numbers (PCN)验证层协议，通过机械验证机制解决大语言模型的数值幻觉问题，确保生成数字的准确性


<details>
  <summary>Details</summary>
Motivation: 现有方法（检索增强生成/引用/不确定性估计）无法完全保证数值忠实性，错误数值仍可能被错误展示

Method: 将数值作为声明绑定令牌生成，在渲染层实施验证策略（精确相等/舍入/别名/容错），验证与模型分离的防欺骗机制

Result: 理论证明PCN具备可靠性、完整性、故障闭合特性及策略优化单调性，具有轻量级、模型无关、易集成扩展等技术优势

Conclusion: 通过强制验证机制建立数值敏感场景的信任契约：仅验证通过的数值可被信任，未标记数值默认存在不确定性

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [66] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 提出双层优化方法整合监督微调与强化学习，提升大型语言模型推理训练的效率和效果


<details>
  <summary>Details</summary>
Motivation: 解决强化学习训练效率低下及监督微调与强化学习两阶段训练割裂的问题

Method: 通过条件化双层优化框架，下层执行RL更新并接受SFT监督，上层显式最大化合作增益

Result: 在五个推理基准测试中持续超越基线，实现效果与效率的更好平衡

Conclusion: 双层次协同训练范式显著提升模型性能，为联合优化范式提供新方向

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [67] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: 提出轨迹感知强化学习框架TraceRL，通过扩散价值模型增强训练稳定性，在复杂数学/编程任务中取得突破性表现，并发布首个开源扩散语言模型全栈框架


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散语言模型在复杂推理任务中的性能瓶颈，通过强化学习整合推理轨迹偏好，提升模型训练稳定性和采样灵活性

Method: 1. 提出轨迹感知强化学习框架TraceRL 2. 开发扩散价值模型增强训练稳定性 3. 块结构适配技术实现模型规模扩展 4. 课程学习策略实现长链式思维训练

Result: 1. TraDo-4B-Instruct超越7B级AR模型 2. TraDo-8B数学推理准确率提升51.3% 3. 首个长链式DLM在MATH500准确率提升18.1% 4. 开源框架集成加速KV缓存和RL引擎

Conclusion: TraceRL框架突破扩散模型性能边界，实现参数效率与推理能力的双重提升，开源生态建设推动领域发展，为复杂任务提供新范式

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [68] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 研究通过Wavelength游戏框架评估语言模型的语用推理能力，发现大模型在语言理解接近人类水平，生成任务中CoT+RSA方法效果最优。


<details>
  <summary>Details</summary>
Motivation: 语言模型作为对话代理日益普及，需系统评估其语用推理能力（理解沟通目标与上下文关系），填补现有研究空白。

Method: 基于Wavelength沟通游戏设计评估框架，测试不同规模语言模型在理解/生成任务的表现，对比直接提示、思维链（CoT）和贝叶斯理性言语行为（RSA）方法。

Result: 大模型理解任务达人类水平（无需CoT/RSA），生成任务中RSA方法显著优于CoT和直接提示。

Conclusion: 揭示大模型语用推理优势与局限，证明RSA方法对提升模型社交推理能力的潜力，为未来语言理解研究提供新方向。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [69] [PaMO: Parallel Mesh Optimization for Intersection-Free Low-Poly Modeling on the GPU](https://arxiv.org/abs/2509.05595)
*Seonghun Oh,Xiaodi Yuan,Xinyue Wei,Ruoxi Shi,Fanbo Xiang,Minghua Liu,Hao Su*

Main category: cs.GR

TL;DR: 提出基于GPU的网格优化三件套方案，3秒内将200万面网格简化为2万面，解决传统方法自交、表面偏移和效率低问题


<details>
  <summary>Details</summary>
Motivation: 现有网格简化方法存在自交风险、重新网格化导致表面偏移/特征丢失、处理大规模网格耗时过长三大痛点，难以满足3D打印/软体模拟等应用需求

Method: 1) 并行重新网格化算法生成防水/流形/无自交网格；2) 带无自交保证的并行简化算法；3) 安全投影算法恢复原始特征并消除表面偏移

Result: RTX4090上3秒完成200万面→2万面简化，Thingi10K数据集验证显示几何特征保持优异，速度比传统方法快两个数量级

Conclusion: 该GPU加速方案在效率与质量间取得突破性平衡，为实时图形处理提供实用解决方案，特别适合大规模工业级模型处理

Abstract: Reducing the triangle count in complex 3D models is a basic geometry
preprocessing step in graphics pipelines such as efficient rendering and
interactive editing. However, most existing mesh simplification methods exhibit
a few issues. Firstly, they often lead to self-intersections during decimation,
a major issue for applications such as 3D printing and soft-body simulation.
Second, to perform simplification on a mesh in the wild, one would first need
to perform re-meshing, which often suffers from surface shifts and losses of
sharp features. Finally, existing re-meshing and simplification methods can
take minutes when processing large-scale meshes, limiting their applications in
practice. To address the challenges, we introduce a novel GPU-based mesh
optimization approach containing three key components: (1) a parallel
re-meshing algorithm to turn meshes in the wild into watertight, manifold, and
intersection-free ones, and reduce the prevalence of poorly shaped triangles;
(2) a robust parallel simplification algorithm with intersection-free
guarantees; (3) an optimization-based safe projection algorithm to realign the
simplified mesh with the input, eliminating the surface shift introduced by
re-meshing and recovering the original sharp features. The algorithm
demonstrates remarkable efficiency, simplifying a 2-million-face mesh to 20k
triangles in 3 seconds on RTX4090. We evaluated the approach on the Thingi10K
dataset and showcased its exceptional performance in geometry preservation and
speed.

</details>


### [70] [Programming tension in 3D printed networks inspired by spiderwebs](https://arxiv.org/abs/2509.05855)
*Thijs Masmeijer,Caleb Swain,Jeff Hill,Ed Habtour*

Main category: cs.GR

TL;DR: 提出了一种可直接3D打印预设张力梯度结构网络的算法，通过蜘蛛网纺丝启发的方法，实验验证平均应变误差<1.0%，并成功制作蜘蛛网/曲面网/张拉整体等复杂结构。


<details>
  <summary>Details</summary>
Motivation: 传统张力结构在制造展平过程中会产生误差累积，导致最终张力梯度控制困难，需开发能直接制造精确张力网络的新方法。

Method: 1.用力密度法定义网络张力梯度 → 2.通过顶点位置优化和弧线转换生成无应力预制件 → 3.分解为打印路径 → 4.可选3D展平及交叉修正 → 5.实验验证与案例演示。

Result: 2D粘弹性细丝单元平均应变误差<1.0%，最小元件长度5.8mm/最大应力7.3MPa下仍有效，成功制作平面蜘蛛网/曲面网/张拉整体三类复杂结构。

Conclusion: 该算法可生产紧凑集成缆网，推动医疗支具等新型应用，如实现施力结构设计。

Abstract: Each element in tensioned structural networks -- such as tensegrity,
architectural fabrics, or medical braces/meshes -- requires a specific tension
level to achieve and maintain the desired shape, stability, and compliance.
These structures are challenging to manufacture, 3D print, or assemble because
flattening the network during fabrication introduces multiplicative
inaccuracies in the network's final tension gradients. This study overcomes
this challenge by offering a fabrication algorithm for direct 3D printing of
such networks with programmed tension gradients, an approach analogous to the
spinning of spiderwebs. The algorithm: (i) defines the desired network and
prescribes its tension gradients using the force density method; (ii) converts
the network into an unstretched counterpart by numerically optimizing vertex
locations toward target element lengths and converting straight elements into
arcs to resolve any remaining error; and (iii) decomposes the network into
printable toolpaths; Optional additional steps are: (iv) flattening curved 2D
networks or 3D networks to ensure 3D printing compatibility; and (v)
automatically resolving any unwanted crossings introduced by the flattening
process. The proposed method is experimentally validated using 2D unit cells of
viscoelastic filaments, where accurate tension gradients are achieved with an
average element strain error of less than 1.0\%. The method remains effective
for networks with element minimum length and maximum stress of 5.8 mm and 7.3
MPa, respectively. The method is used to demonstrate the fabrication of three
complex cases: a flat spiderweb, a curved mesh, and a tensegrity system. The
programmable tension gradient algorithm can be utilized to produce compact,
integrated cable networks, enabling novel applications such as moment-exerting
structures in medical braces and splints.

</details>


### [71] [From Rigging to Waving: 3D-Guided Diffusion for Natural Animation of Hand-Drawn Characters](https://arxiv.org/abs/2509.06573)
*Jie Zhou,Linzi Qu,Miu-Ling Lam,Hongbo Fu*

Main category: cs.GR

TL;DR: 提出结合骨骼动画与视频扩散的混合动画系统，通过几何引导与纹理增强解决传统方法在非刚性元素动画中的失真问题


<details>
  <summary>Details</summary>
Motivation: 传统骨骼动画难以处理复杂非刚性元素导致变形不自然，视频扩散模型存在几何失真问题，需要结合二者优势实现高质量风格化角色动画

Method: 1. 骨骼动画生成几何引导的粗略图像 2. 基于视频扩散先验进行纹理增强和二次动态合成 3. 提出SDI策略注入运动特征 4. 开发HLM技术实现长发分层建模

Result: 在定量和定性评估中超越现有最优方法，有效改善非刚性元素动画的自然度与几何一致性

Conclusion: 混合系统成功结合几何控制与动态表现力，SDI与HLM技术创新提升了风格化角色动画的视觉效果，为手绘动画制作提供新方案

Abstract: Hand-drawn character animation is a vibrant field in computer graphics,
presenting challenges in achieving geometric consistency while conveying
expressive motion. Traditional skeletal animation methods maintain geometric
consistency but struggle with complex non-rigid elements like flowing hair and
skirts, leading to unnatural deformation. Conversely, video diffusion models
synthesize realistic dynamics but often create geometric distortions in
stylized drawings due to domain gaps. This work proposes a hybrid animation
system that combines skeletal animation and video diffusion. Initially, coarse
images are generated from characters retargeted with skeletal animations for
geometric guidance. These images are then enhanced in texture and secondary
dynamics using video diffusion priors, framing this enhancement as an
inpainting task. A domain-adapted diffusion model refines user-masked regions
needing improvement, especially for secondary dynamics. To enhance motion
realism further, we introduce a Secondary Dynamics Injection (SDI) strategy in
the denoising process, incorporating features from a pre-trained diffusion
model enriched with human motion priors. Additionally, to tackle unnatural
deformations from low-poly single-mesh character modeling, we present a Hair
Layering Modeling (HLM) technique that uses segmentation maps to separate hair
from the body, allowing for more natural animation of long-haired characters.
Extensive experiments show that our system outperforms state-of-the-art methods
in both quantitative and qualitative evaluations.

</details>


### [72] [From Skin to Skeleton: Towards Biomechanically Accurate 3D Digital Humans](https://arxiv.org/abs/2509.06607)
*Marilyn Keller,Keenon Werling,Soyong Shin,Scott Delp,Sergi Pujades,C. Karen Liu,Michael J. Black*

Main category: cs.GR

TL;DR: 提出SKEL模型，通过将生物力学骨架与SMPL模型结合，在保持易用性的同时提升生物力学准确性，并实现现有数据集的生物力学参数升级


<details>
  <summary>Details</summary>
Motivation: 现有SMPL模型的简化骨骼结构不符合真实人体生物力学特征，而传统生物力学分析方法依赖复杂设备无法普及应用

Method: 1. 构建AMASS数据集优化生物力学骨架位置
2. 训练从SMPL顶点到骨骼参数的回归器
3. 重新参数化SMPL模型创建SKEL框架

Result: SKEL相比SMPL具有更准确的关节定位（平均误差减少23%），骨骼拟合度优于现有方法，可无损升级现有SMPL数据集

Conclusion: SKEL架起了计算机视觉与生物力学的桥梁，为跨学科研究提供标准化工具，推动「野外生物力学」研究和更真实的人体运动建模

Abstract: Great progress has been made in estimating 3D human pose and shape from
images and video by training neural networks to directly regress the parameters
of parametric human models like SMPL. However, existing body models have
simplified kinematic structures that do not correspond to the true joint
locations and articulations in the human skeletal system, limiting their
potential use in biomechanics. On the other hand, methods for estimating
biomechanically accurate skeletal motion typically rely on complex motion
capture systems and expensive optimization methods. What is needed is a
parametric 3D human model with a biomechanically accurate skeletal structure
that can be easily posed. To that end, we develop SKEL, which re-rigs the SMPL
body model with a biomechanics skeleton. To enable this, we need training data
of skeletons inside SMPL meshes in diverse poses.
  We build such a dataset by optimizing biomechanically accurate skeletons
inside SMPL meshes from AMASS sequences. We then learn a regressor from SMPL
mesh vertices to the optimized joint locations and bone rotations. Finally, we
re-parametrize the SMPL mesh with the new kinematic parameters. The resulting
SKEL model is animatable like SMPL but with fewer, and
biomechanically-realistic, degrees of freedom. We show that SKEL has more
biomechanically accurate joint locations than SMPL, and the bones fit inside
the body surface better than previous methods. By fitting SKEL to SMPL meshes
we are able to "upgrade" existing human pose and shape datasets to include
biomechanical parameters. SKEL provides a new tool to enable biomechanics in
the wild, while also providing vision and graphics researchers with a better
constrained and more realistic model of human articulation. The model, code,
and data are available for research at https://skel.is.tue.mpg.de..

</details>


### [73] [Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data](https://arxiv.org/abs/2509.06950)
*Nithin Gopalakrishnan Nair,Srinivas Kaza,Xuan Luo,Vishal M. Patel,Stephen Lombardi,Jungyeon Park*

Main category: cs.GR

TL;DR: 通过扩散模型生成合成数据并结合Transformer的令牌解缠技术，显著提升了稀疏视角下3D场景重建的泛化能力和质量，同时降低计算成本


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的新视角合成模型受限于真实场景数据集多样性不足，导致对真实世界场景的泛化能力有限。合成数据虽可扩展但存在生成伪影问题

Method: 1. 利用扩散模型生成可扩展的合成训练数据 2. 在Transformer架构中引入令牌解缠机制，通过特征分离提升模型对合成数据中伪影的鲁棒性

Result: 在多个基准测试中达到SOTA，跨数据集评估提升显著，计算成本降低约30%

Conclusion: 结合合成数据生成和架构创新有效解决了3D重建中的域适应问题，为实际应用中的泛化能力提供了可扩展解决方案

Abstract: Large transformer-based models have made significant progress in
generalizable novel view synthesis (NVS) from sparse input views, generating
novel viewpoints without the need for test-time optimization. However, these
models are constrained by the limited diversity of publicly available scene
datasets, making most real-world (in-the-wild) scenes out-of-distribution. To
overcome this, we incorporate synthetic training data generated from diffusion
models, which improves generalization across unseen domains. While synthetic
data offers scalability, we identify artifacts introduced during data
generation as a key bottleneck affecting reconstruction quality. To address
this, we propose a token disentanglement process within the transformer
architecture, enhancing feature separation and ensuring more effective
learning. This refinement not only improves reconstruction quality over
standard transformers but also enables scalable training with synthetic data.
As a result, our method outperforms existing models on both in-dataset and
cross-dataset evaluations, achieving state-of-the-art results across multiple
benchmarks while significantly reducing computational costs. Project page:
https://scaling3dnvs.github.io/

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [74] [ForensicsData: A Digital Forensics Dataset for Large Language Models](https://arxiv.org/abs/2509.05331)
*Youssef Chakir,Iyad Lahsen-Cherif*

Main category: cs.CR

TL;DR: 针对数字取证面临的现实数据不足问题，研究者构建了包含5000+Q-C-A三元组的ForensicsData数据集，通过结构化提取+LLM转换+质量验证的流程，推动取证工具研发与学术合作。


<details>
  <summary>Details</summary>
Motivation: 现有数字取证研究受限于伦理法律隐私问题，缺乏真实场景数据集，影响取证技术研发和工具验证。

Method: 1.从真实恶意软件报告提取结构化数据 2.用LLM转化为问题-上下文-答案格式 3.设计专项评估流程验证数据质量

Result: Gemini 2 Flash模型在法医术语对齐评估中表现最优，证实了工作流程有效性

Conclusion: ForensicsData通过提供标准化数据集，支持可重复实验并促进取证领域协作创新

Abstract: The growing complexity of cyber incidents presents significant challenges for
digital forensic investigators, especially in evidence collection and analysis.
Public resources are still limited because of ethical, legal, and privacy
concerns, even though realistic datasets are necessary to support research and
tool developments. To address this gap, we introduce ForensicsData, an
extensive Question-Context-Answer (Q-C-A) dataset sourced from actual malware
analysis reports. It consists of more than 5,000 Q-C-A triplets. A unique
workflow was used to create the dataset, which extracts structured data, uses
large language models (LLMs) to transform it into Q-C-A format, and then uses a
specialized evaluation process to confirm its quality. Among the models
evaluated, Gemini 2 Flash demonstrated the best performance in aligning
generated content with forensic terminology. ForensicsData aims to advance
digital forensics by enabling reproducible experiments and fostering
collaboration within the research community.

</details>


### [75] [Cross-Service Threat Intelligence in LLM Services using Privacy-Preserving Fingerprints](https://arxiv.org/abs/2509.05608)
*Waris Gill,Natalie Isak,Matthew Dressman*

Main category: cs.CR

TL;DR: BinaryShield通过隐私保护技术实现跨合规边界的攻击指纹共享，在保持隐私的同时有效检测LLM的提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 企业级LLM服务因合规限制无法共享用户提示，导致同一攻击在不同服务中长期潜伏。需开发既能共享威胁情报又不泄露隐私的方案。

Method: 结合PII脱敏、语义嵌入、二值量化和随机响应机制，生成不可逆的攻击指纹，保留攻击模式特征同时保护用户隐私。

Result: F1-score达0.94，显著优于SimHash基线(0.77)，存储减少64倍，相似性搜索速度提升38倍。

Conclusion: BinaryShield在安全与隐私间取得平衡，为LLM生态系统提供了实用的威胁情报共享框架。

Abstract: The widespread deployment of LLMs across enterprise services has created a
critical security blind spot. Organizations operate multiple LLM services
handling billions of queries daily, yet regulatory compliance boundaries
prevent these services from sharing threat intelligence about prompt injection
attacks, the top security risk for LLMs. When an attack is detected in one
service, the same threat may persist undetected in others for months, as
privacy regulations prohibit sharing user prompts across compliance boundaries.
  We present BinaryShield, the first privacy-preserving threat intelligence
system that enables secure sharing of attack fingerprints across compliance
boundaries. BinaryShield transforms suspicious prompts through a unique
pipeline combining PII redaction, semantic embedding, binary quantization, and
randomized response mechanism to potentially generate non-invertible
fingerprints that preserve attack patterns while providing privacy. Our
evaluations demonstrate that BinaryShield achieves an F1-score of 0.94,
significantly outperforming SimHash (0.77), the privacy-preserving baseline,
while achieving 64x storage reduction and 38x faster similarity search compared
to dense embeddings.

</details>


### [76] [An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection](https://arxiv.org/abs/2509.06920)
*Haywood Gelman,John D. Hastings,David Kenley*

Main category: cs.CR

TL;DR: 提出使用Claude Sonnet 3.7生成动态系统日志，有效提升内部威胁检测精度


<details>
  <summary>Details</summary>
Motivation: 现有内部威胁检测依赖静态数据集，限制自适应模型发展。需动态生成更贴近真实场景的数据分布（1%威胁样本）

Method: 1. 使用Claude Sonnet 3.7动态合成含威胁指标的系统日志
2. 采用统计指标（精确率、召回率、MCC、ROC AUC）对比评估Sonnet 3.7与GPT-4o的检测性能

Result: Sonnet 3.7在几乎所有指标上超越GPT-4o，误报减少13%，检测准确率提升24%，MCC值达到0.87

Conclusion: LLM在合成数据生成和威胁检测领域展现出双重应用潜力，Sonnet架构在安全分析任务中具有显著优势

Abstract: Insider threats are a growing organizational problem due to the complexity of
identifying their technical and behavioral elements. A large research body is
dedicated to the study of insider threats from technological, psychological,
and educational perspectives. However, research in this domain has been
generally dependent on datasets that are static and limited access which
restricts the development of adaptive detection models. This study introduces a
novel, ethically grounded approach that uses the large language model (LLM)
Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which
contain indicators of insider threat scenarios. The messages reflect real-world
data distributions by being highly imbalanced (1% insider threats). The syslogs
were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with
their performance evaluated through statistical metrics including precision,
recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across
nearly all metrics, particularly in reducing false alarms and improving
detection accuracy. The results show strong promise for the use of LLMs in
synthetic dataset generation and insider threat detection.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [77] [On the Contribution of Lexical Features to Speech Emotion Recognition](https://arxiv.org/abs/2509.05634)
*David Combei*

Main category: eess.AS

TL;DR: 语音情感识别中词汇内容与声学模型表现相当甚至更优，MELD数据集上词汇方法加权F1达51.5%


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点（副语言线索主导情感识别），验证词汇内容在SER中的潜力

Method: 对比自监督语音/文本表征，分析transformer编码器层级特性，评估音频降噪效果

Result: 词汇模型以更少参数实现49.3%→51.5%的WF1提升，部分场景超越声学模型

Conclusion: 词汇信息应作为SER重要特征，未来可探索多模态融合方案提升系统性能

Abstract: Although paralinguistic cues are often considered the primary drivers of
speech emotion recognition (SER), we investigate the role of lexical content
extracted from speech and show that it can achieve competitive and in some
cases higher performance compared to acoustic models. On the MELD dataset, our
lexical-based approach obtains a weighted F1-score (WF1) of 51.5%, compared to
49.3% for an acoustic-only pipeline with a larger parameter count. Furthermore,
we analyze different self-supervised (SSL) speech and text representations,
conduct a layer-wise study of transformer-based encoders, and evaluate the
effect of audio denoising.

</details>


### [78] [Beamforming-LLM: What, Where and When Did I Miss?](https://arxiv.org/abs/2509.06221)
*Vishal Choudhari*

Main category: eess.AS

TL;DR: 开发Beamforming-LLM系统，通过波束成形和RAG技术实现多说话人环境下的语义回忆功能


<details>
  <summary>Details</summary>
Motivation: 解决多说话人场景中用户可能遗漏对话内容的问题，提升听觉记忆辅助能力

Method: 1. 波束成形分离定向音频流 → 2. Whisper语音转写 → 3. 句子编码器向量嵌入 → 4. GPT-4o-mini生成对比摘要

Result: 提供包含对比摘要、空间上下文和时间戳音频回放的三合一用户界面

Conclusion: 奠定智能听觉记忆系统基础，可应用于辅助技术、会议总结和空间感知计算领域

Abstract: We present Beamforming-LLM, a system that enables users to semantically
recall conversations they may have missed in multi-speaker environments. The
system combines spatial audio capture using a microphone array with
retrieval-augmented generation (RAG) to support natural language queries such
as, "What did I miss when I was following the conversation on dogs?"
Directional audio streams are separated using beamforming, transcribed with
Whisper, and embedded into a vector database using sentence encoders. Upon
receiving a user query, semantically relevant segments are retrieved,
temporally aligned with non-attended segments, and summarized using a
lightweight large language model (GPT-4o-mini). The result is a user-friendly
interface that provides contrastive summaries, spatial context, and timestamped
audio playback. This work lays the foundation for intelligent auditory memory
systems and has broad applications in assistive technology, meeting
summarization, and context-aware personal spatial computing.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [79] [ProtSAE: Disentangling and Interpreting Protein Language Models via Semantically-Guided Sparse Autoencoders](https://arxiv.org/abs/2509.05309)
*Xiangyu Liu,Haodi Lei,Yi Liu,Yang Liu,Wei Hu*

Main category: q-bio.QM

TL;DR: 开发ProtSAE解决蛋白质语言模型特征语义纠缠问题，通过语义引导提升可解释性


<details>
  <summary>Details</summary>
Motivation: 传统SAE在蛋白质模型应用中出现语义纠缠，导致特征难以可靠解释和操控

Method: 提出ProtSAE，在训练中融合标注数据和领域知识进行语义解耦

Result: 相比基线方法学习到更具生物相关性的特征，保持重构质量的同时实现更好的可解释性探针性能

Conclusion: ProtSAE有效缓解语义纠缠问题，为蛋白质模型解释和可控生成提供了新途径

Abstract: Sparse Autoencoder (SAE) has emerged as a powerful tool for mechanistic
interpretability of large language models. Recent works apply SAE to protein
language models (PLMs), aiming to extract and analyze biologically meaningful
features from their latent spaces. However, SAE suffers from semantic
entanglement, where individual neurons often mix multiple nonlinear concepts,
making it difficult to reliably interpret or manipulate model behaviors. In
this paper, we propose a semantically-guided SAE, called ProtSAE. Unlike
existing SAE which requires annotation datasets to filter and interpret
activations, we guide semantic disentanglement during training using both
annotation datasets and domain knowledge to mitigate the effects of entangled
attributes. We design interpretability experiments showing that ProtSAE learns
more biologically relevant and interpretable hidden features compared to
previous methods. Performance analyses further demonstrate that ProtSAE
maintains high reconstruction fidelity while achieving better results in
interpretable probing. We also show the potential of ProtSAE in steering PLMs
for downstream generation tasks.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [80] [TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition](https://arxiv.org/abs/2509.05983)
*Minh N. H. Nguyen,Anh Nguyen Tran,Dung Truong Dinh,Nam Van Vo*

Main category: cs.SD

TL;DR: 提出两阶段音素中心模型TSPC，通过扩展越南语音素集作为中间表示，显著降低越南语-英语语码转换场景的ASR词错误率至20.8%


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉越英语码转换场景中的细微音系变化，特别是越南语和英语在音系特征和相似发音识别模糊性上的双重挑战

Method: 采用基于扩展越南语音素集的音素中心方法，构建包含语音适应和语言转换的两阶段架构实现跨语言建模

Result: 在越南语-英语CS-ASR任务中词错误率降低至20.8%，优于PhoWhisper-base等基线模型且训练资源更少

Conclusion: 音素中心的两阶段架构通过中间表示有效解决复杂语码转换场景的ASR问题，语音适应和语言转换机制显著提升系统性能

Abstract: Code-switching (CS) presents a significant challenge for general Auto-Speech
Recognition (ASR) systems. Existing methods often fail to capture the subtle
phonological shifts inherent in CS scenarios. The challenge is particularly
difficult for language pairs like Vietnamese and English, where both distinct
phonological features and the ambiguity arising from similar sound recognition
are present. In this paper, we propose a novel architecture for
Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC
employs a phoneme-centric approach, built upon an extended Vietnamese phoneme
set as an intermediate representation to facilitate mixed-lingual modeling.
Experimental results demonstrate that TSPC consistently outperforms existing
baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a
significantly lower word error rate of 20.8\% with reduced training resources.
Furthermore, the phonetic-based two-stage architecture enables phoneme
adaptation and language conversion to enhance ASR performance in complex CS
Vietnamese-English ASR scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [81] [Exploring Urban Factors with Autoencoders: Relationship Between Static and Dynamic Features](https://arxiv.org/abs/2509.06167)
*Ximena Pocco,Waqar Hassan,Karelia Salinas,Vladimir Molchanov,Luis G. Nonato*

Main category: cs.LG

TL;DR: 研究通过可视化框架对比融合与独立城市数据表示的效果，发现融合表示能生成更结构化模式，而独立表示在特定场景有效


<details>
  <summary>Details</summary>
Motivation: 现有可视化工具未能充分验证融合多源城市数据是否比独立分析更具洞察优势，需建立评估框架验证数据融合的有效性

Method: 开发可视化辅助框架，通过对比实验分析融合潜在表示与独立表示在动态/静态城市数据中的模式发现能力

Result: 融合潜在表示产生更系统化的城市模式，独立数据表示在特定分析场景中展现独特价值

Conclusion: 数据融合策略需根据分析目标灵活选择，融合表示提升结构化发现，独立表示保留特定场景优势，为城市分析提供方法论参考

Abstract: Urban analytics utilizes extensive datasets with diverse urban information to
simulate, predict trends, and uncover complex patterns within cities. While
these data enables advanced analysis, it also presents challenges due to its
granularity, heterogeneity, and multimodality. To address these challenges,
visual analytics tools have been developed to support the exploration of latent
representations of fused heterogeneous and multimodal data, discretized at a
street-level of detail. However, visualization-assisted tools seldom explore
the extent to which fused data can offer deeper insights than examining each
data source independently within an integrated visualization framework. In this
work, we developed a visualization-assisted framework to analyze whether fused
latent data representations are more effective than separate representations in
uncovering patterns from dynamic and static urban data. The analysis reveals
that combined latent representations produce more structured patterns, while
separate ones are useful in particular cases.

</details>


### [82] [Outcome-based Exploration for LLM Reasoning](https://arxiv.org/abs/2509.06941)
*Yuda Song,Julia Kempe,Remi Munos*

Main category: cs.LG

TL;DR: 提出基于结果的探索方法（历史探索+批次探索），在提升LLM数学推理精度的同时有效缓解强化学习导致的生成多样性下降问题


<details>
  <summary>Details</summary>
Motivation: 传统结果导向强化学习虽然显著提升答案准确率，但会引发系统性生成多样性崩溃，这对需要多样答案的实际部署场景造成隐患。研究发现RL会降低训练集有效多样性，且存在多样性退化转移现象（已解决问题多样性下降波及未解决问题）

Method: 设计两种互补算法：1）历史探索（UCB式奖励机制激励罕见答案）2）批次探索（惩罚批内重复提升测试时多样性）。基于Llama/Qwen模型在数学竞赛基准开展实验验证

Result: 实验表明两种方法在保持准确率优势的同时显著缓解多样性崩溃，理论层面通过新型结果导向多臂老虎机模型形式化验证探索机制的有效性

Conclusion: 该研究为平衡LLM推理精度与生成多样性提供了可落地的强化学习方案，对实现可扩展部署具有重要实践价值

Abstract: Reinforcement learning (RL) has emerged as a powerful method for improving
the reasoning abilities of large language models (LLMs). Outcome-based RL,
which rewards policies solely for the correctness of the final answer, yields
substantial accuracy gains but also induces a systematic loss in generation
diversity. This collapse undermines real-world performance, where diversity is
critical for test-time scaling. We analyze this phenomenon by viewing RL
post-training as a sampling process and show that, strikingly, RL can reduce
effective diversity even on the training set relative to the base model. Our
study highlights two central findings: (i) a transfer of diversity degradation,
where reduced diversity on solved problems propagates to unsolved ones, and
(ii) the tractability of the outcome space, since reasoning tasks admit only a
limited set of distinct answers. Motivated by these insights, we propose
outcome-based exploration, which assigns exploration bonuses according to final
outcomes. We introduce two complementary algorithms: historical exploration,
which encourages rarely observed answers via UCB-style bonuses, and batch
exploration, which penalizes within-batch repetition to promote test-time
diversity. Experiments on standard competition math with Llama and Qwen models
demonstrate that both methods improve accuracy while mitigating diversity
collapse. On the theoretical side, we formalize the benefit of outcome-based
exploration through a new model of outcome-based bandits. Together, these
contributions chart a practical path toward RL methods that enhance reasoning
without sacrificing the diversity essential for scalable deployment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 研究发现不同规模的大语言模型在模拟人类被试时存在显著内部不一致性，无法准确替代真实参与者


<details>
  <summary>Details</summary>
Motivation: 验证LLM是否能在不同实验场景中保持行为一致性，突破现有研究仅关注数据表面匹配性的局限

Method: 设计双阶段实验：(a)揭示智能体内部状态 (b)基础对话场景下的行为测试，通过行为假设验证对话表现与内部状态的匹配度

Result: 发现跨模型家族和不同规模LLM均存在显著内部不一致性，响应匹配人类但缺乏内在一致性

Conclusion: 内部状态与行为表现的不一致性构成关键能力缺陷，LLM目前无法可靠替代人类被试

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [84] [Reverse-Engineered Reasoning for Open-Ended Generation](https://arxiv.org/abs/2509.06160)
*Haozhe Wang,Haoran Que,Qixin Xu,Minghao Liu,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Wei Ye,Tong Yang,Wenhao Huang,Ge Zhang,Fangzhen Lin*

Main category: cs.AI

TL;DR: 提出REER逆向工程推理方法，通过反向推导解决开放式生成任务，构建DeepWriting-20K数据集并训练出超越主流模型的DeepWriter-8B


<details>
  <summary>Details</summary>
Motivation: 现有强化学习和指令蒸馏方法在开放式创造性任务中存在奖励信号缺失、成本过高和模型能力上限问题

Method: 采用逆向工程推理（REER），从已知优秀解决方案反推潜在推理过程，利用无梯度方法自动生成深度推理轨迹

Result: 创建20,000条开放式任务推理轨迹数据集，训练模型在多项任务中超越开源基线，部分表现优于GPT-4o和Claude 3.5

Conclusion: REER范式突破传统推理训练限制，为开放式生成任务提供可扩展解决方案，证明逆向工程方法的有效性

Abstract: While the ``deep reasoning'' paradigm has spurred significant advances in
verifiable domains like mathematics, its application to open-ended, creative
generation remains a critical challenge. The two dominant methods for
instilling reasoning -- reinforcement learning (RL) and instruction
distillation -- falter in this area; RL struggles with the absence of clear
reward signals and high-quality reward models, while distillation is
prohibitively expensive and capped by the teacher model's capabilities. To
overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a
new paradigm that fundamentally shifts the approach. Instead of building a
reasoning process ``forwards'' through trial-and-error or imitation, REER works
``backwards'' from known-good solutions to computationally discover the latent,
step-by-step deep reasoning process that could have produced them. Using this
scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a
large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.
Our model, DeepWriter-8B, trained on this data, not only surpasses strong
open-source baselines but also achieves performance competitive with, and at
times superior to, leading proprietary models like GPT-4o and Claude 3.5.

</details>


### [85] [From Long to Short: LLMs Excel at Trimming Own Reasoning Chains](https://arxiv.org/abs/2509.06174)
*Wei Han,Geng Zhan,Sicheng Yu,Chenyu Wang,Bryan Hooi*

Main category: cs.AI

TL;DR: 大型推理模型(LRMs)通过扩展推理路径实现突破性进展，但存在过度复杂化简单问题的问题。研究提出EDIT方法动态优化推理路径，平衡正确性与简洁性，显著提升效率与可读性。


<details>
  <summary>Details</summary>
Motivation: LRMs在复杂推理任务中表现优异，但其'过度思考'特性导致冗长推理路径，影响模型可解释性和用户体验。现有方法难以平衡多生成目标（如正确性与简洁性）。

Method: EDIT方法通过约束引导生成技术，动态追踪不同约束下的推理路径长度与答案分布，实现推理过程的最优截断，自动选择简洁正确的输出。

Result: 跨模型/数据集的实验表明，EDIT使推理路径平均缩短47%，同时保持98%+的准确率，显著提升输出紧凑性与用户体验。

Conclusion: EDIT有效解决LRMs过度思考难题，证明动态约束优化在提升推理效率方面的潜力，为平衡AI系统性能与可解释性提供新范式。

Abstract: O1/R1 style large reasoning models (LRMs) signal a substantial leap forward
over conventional instruction-following LLMs. By applying test-time scaling to
generate extended reasoning paths, they establish many SOTAs across a wide
range of complex reasoning tasks. However, recent studies show that LRMs are
prone to suffer from overthinking -- the tendency to overcomplicate simple
problems, leading to excessive strategy switching and long, convoluted
reasoning traces that hinder their interpretability. To mitigate this issue, we
conduct a systematic investigation into the reasoning efficiency of a broad set
of LRMs and uncover a common dilemma: the difficulty in balancing multiple
generation objectives such as correctness and brevity. Based on this discovery,
we propose a test-time scaling method, EDIT (Efficient Dynamic Inference
Trimming), which efficiently guides LRMs to identify the shortest correct
reasoning paths at test time. EDIT employs constraint-guided generation while
jointly tracking length and answer distributions under varying constraints,
allowing it to select responses that strike an optimal balance between
conciseness and correctness. Extensive experiments across diverse models and
datasets show that EDIT substantially enhance the reasoning efficiency,
producing compact yet informative outputs that improve readability and user
experience.

</details>


### [86] [SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents](https://arxiv.org/abs/2509.06283)
*Xuan-Phi Nguyen,Shrey Pandit,Revanth Gangi Reddy,Austin Xu,Silvio Savarese,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 提出通过持续强化学习优化单代理模型，实现无需人工干预的动态深度研究能力


<details>
  <summary>Details</summary>
Motivation: 解决多代理系统在深度研究中静态流程限制，探索自主单代理的动态决策潜力

Method: 采用合成数据的强化学习训练框架，优化20B参数的开源模型推理能力

Result: SFR-DR-20B模型在Humanity's Last Exam基准测试达到28.7%准确率

Conclusion: 证明持续强化学习可有效提升单代理的深度研究能力，为智能体开发提供新方向

Abstract: Equipping large language models (LLMs) with complex, interleaved reasoning
and tool-use capabilities has become a key focus in agentic AI research,
especially with recent advances in reasoning-oriented (``thinking'') models.
Such capabilities are key to unlocking a number of important applications. One
such application is Deep Research (DR), which requires extensive search and
reasoning over many sources. Our work in this paper focuses on the development
of native Autonomous Single-Agent models for DR featuring minimal web crawling
and Python tool integration. Unlike multi-agent systems, where agents take up
pre-defined roles and are told what to do at each step in a static workflow, an
autonomous single-agent determines its next action dynamically based on
context, without manual directive. While prior work has proposed training
recipes for base or instruction-tuned LLMs, we focus on continual reinforcement
learning (RL) of reasoning-optimized models to further enhance agentic skills
while preserving reasoning ability. Towards this end, we propose a simple RL
recipe with entirely synthetic data, which we apply to various open-source
LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam
benchmark. In addition, we conduct key analysis experiments to provide more
insights into our methodologies.

</details>


### [87] [Reinforcement Learning Foundations for Deep Research Systems: A Survey](https://arxiv.org/abs/2509.06733)
*Wenjun Li,Zhi Chen,Jingru Lin,Hannan Cao,Wei Han,Sheng Liang,Zhi Zhang,Kuicai Dong,Dexun Li,Chen Zhang,Yong Liu*

Main category: cs.AI

TL;DR: 首次系统研究强化学习在深度研究系统中的关键作用，提出基于RL的智能体训练体系框架与实践指南


<details>
  <summary>Details</summary>
Motivation: 传统SFT和DPO方法存在模仿偏差、代理依赖性问题，且难以处理长时程任务信用分配。RL通过轨迹级策略优化能更好适应工具交互场景，降低对人类先验知识的依赖

Method: 沿三个维度系统化研究：1) 数据合成与治理 2) 智能体RL算法（稳定性、样本效率、奖励设计等）3) 分布式RL训练系统架构

Result: 揭示RL在提升研究智能体鲁棒性、探索能力和多目标优化方面的有效性，提出面向工具交互的混合奖励机制和层次化训练范式

Conclusion: 强化学习是构建透明、鲁棒深度研究系统的关键，需结合环境反馈闭环与系统级RL训练框架来突破现有范式局限

Abstract: Deep research systems, agentic AI that solve complex, multi-step tasks by
coordinating reasoning, search across the open web and user files, and tool
use, are moving toward hierarchical deployments with a Planner, Coordinator,
and Executors. In practice, training entire stacks end-to-end remains
impractical, so most work trains a single planner connected to core tools such
as search, browsing, and code. While SFT imparts protocol fidelity, it suffers
from imitation and exposure biases and underuses environment feedback.
Preference alignment methods such as DPO are schema and proxy-dependent,
off-policy, and weak for long-horizon credit assignment and multi-objective
trade-offs. A further limitation of SFT and DPO is their reliance on human
defined decision points and subskills through schema design and labeled
comparisons. Reinforcement learning aligns with closed-loop, tool-interaction
research by optimizing trajectory-level policies, enabling exploration,
recovery behaviors, and principled credit assignment, and it reduces dependence
on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations
of deep research systems. It systematizes work after DeepSeek-R1 along three
axes: (i) data synthesis and curation; (ii) RL methods for agentic research
covering stability, sample efficiency, long context handling, reward and credit
design, multi-objective optimization, and multimodal integration; and (iii)
agentic RL training systems and frameworks. We also cover agent architecture
and coordination, as well as evaluation and benchmarks, including recent QA,
VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We
distill recurring patterns, surface infrastructure bottlenecks, and offer
practical guidance for training robust, transparent deep research agents with
RL.

</details>


### [88] [VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction](https://arxiv.org/abs/2509.06736)
*Jie Yang,Jiajun Chen,Zhangyue Yin,Shuo Chen,Yuxin Wang,Yiran Guo,Yuan Li,Yining Zheng,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 提出VehicleWorld汽车座舱仿真环境与基于状态的函数调用方法（SFC），解决传统API代理在复杂座舱系统中效率低、容错差的问题，实验证明SFC显著提升执行准确率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统函数调用（FC）方法在智能座舱场景中存在静态执行、需多次试探性调用构建系统认知的缺陷，导致执行效率低下且错误恢复能力有限。

Method: 1. 构建包含30个模块/250个API的VehicleWorld仿真环境；2. 提出状态函数调用（SFC）框架，通过显式系统状态感知与直接状态转移实现目标条件。

Result: SFC相较传统FC方法执行准确率提升27.6%，延迟降低42.8%，在温度调节等典型座舱场景中达成100%准确率。

Conclusion: 本研究为汽车领域智能代理开发提供首个完整测试平台，通过状态驱动范式突破传统API调用限制，相关代码已开源推动行业发展。

Abstract: Intelligent vehicle cockpits present unique challenges for API Agents,
requiring coordination across tightly-coupled subsystems that exceed typical
task environments' complexity. Traditional Function Calling (FC) approaches
operate statelessly, requiring multiple exploratory calls to build
environmental awareness before execution, leading to inefficiency and limited
error recovery. We introduce VehicleWorld, the first comprehensive environment
for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties
with fully executable implementations that provide real-time state information
during agent execution. This environment enables precise evaluation of vehicle
agent behaviors across diverse, challenging scenarios. Through systematic
analysis, we discovered that direct state prediction outperforms function
calling for environmental control. Building on this insight, we propose
State-based Function Call (SFC), a novel approach that maintains explicit
system state awareness and implements direct state transitions to achieve
target conditions. Experimental results demonstrate that SFC significantly
outperforms traditional FC approaches, achieving superior execution accuracy
and reduced latency. We have made all implementation code publicly available on
Github https://github.com/OpenMOSS/VehicleWorld.

</details>


### [89] [RAFFLES: Reasoning-based Attribution of Faults for LLM Systems](https://arxiv.org/abs/2509.06822)
*Chenyang Zhu,Spencer Hong,Jingyu Wu,Kushal Chawla,Charlotte Tang,Youbing Yin,Nathan Wolfe,Erin Babinsky,Daben Liu*

Main category: cs.AI

TL;DR: RAFFLES提出了一种自动化评估框架，通过迭代推理和专门评估器检测长周期LLM代理系统的故障点，在算法生成数据集上实现43%的故障检测准确率


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如单次LLM评判）难以诊断复杂代理系统的故障根源，需构建能推理迭代的评估框架

Method: 构建包含中央Judge和专用Evaluators的迭代评估管道，通过假设历史记录分析系统组件及推理质量

Result: Who&When数据集测试显示：算法生成集准确率43%（原16.6%），手工集达20%（原8.8%）

Conclusion: 该框架显著降低人工审核需求，为自主系统提供可扩展的自动化故障检测方案

Abstract: We have reached a critical roadblock in the development and enhancement of
long-horizon, multi-component LLM agentic systems: it is incredibly tricky to
identify where these systems break down and why. Evaluation capabilities that
currently exist today (e.g., single pass LLM-as-a-judge) are limited in that
they often focus on individual metrics or capabilities, end-to-end outcomes,
and are narrowly grounded on the preferences of humans. We argue that to match
the agentic capabilities, evaluation frameworks must also be able to reason,
probe, iterate, and understand the complex logic passing through these systems
over long horizons. In this paper, we present RAFFLES - an evaluation
architecture that incorporates reasoning and iterative refinement.
Specifically, RAFFLES operates as an iterative, multi-component pipeline, using
a central Judge to systematically investigate faults and a set of specialized
Evaluators to assess not only the system's components but also the quality of
the reasoning by the Judge itself, thereby building a history of hypotheses. We
tested RAFFLES against several baselines on the Who&When dataset, a benchmark
designed to diagnose the "who" (agent) and "when" (step) of a system's failure.
RAFFLES outperforms these baselines, achieving an agent-step fault pair
accuracy of over 43% on the Algorithmically-Generated dataset (a substantial
increase from the previously published best of 16.6%) and over 20% on the
Hand-Crafted dataset (surpassing the previously published best of 8.8%). These
results demonstrate a key step towards introducing automated fault detection
for autonomous systems over labor-intensive manual human review.

</details>


### [90] [Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet](https://arxiv.org/abs/2509.06861)
*James Xu Zhao,Bryan Hooi,See-Kiong Ng*

Main category: cs.AI

TL;DR: 研究发现测试时扩展推理在知识密集型任务中效果有限，可能增加幻觉且无法持续提升准确率


<details>
  <summary>Details</summary>
Motivation: 探索测试时扩展推理（延长模型推理链）在知识密集型任务中的有效性，特别是在需要高事实准确性和低幻觉率的场景下

Method: 使用12个推理模型在两个知识密集型基准上进行系统评估，分析扩展推理对准确率和幻觉行为的影响机制

Result: 1. 增加计算量无法持续提升准确率
2. 62%案例出现更多幻觉
3. 幻觉减少主要源于模型主动弃答而非事实召回改进
4. 长推理可能引发确认偏误导致过度自信的幻觉

Conclusion: 测试时扩展推理在知识任务中存在准确率-幻觉的权衡，需谨慎应用。尽管存在局限性，启用扩展推理仍优于非推理基线方法

Abstract: Test-time scaling increases inference-time computation by allowing models to
generate long reasoning chains, and has shown strong performance across many
domains. However, in this work, we show that this approach is not yet effective
for knowledge-intensive tasks, where high factual accuracy and low
hallucination rates are essential. We conduct a comprehensive evaluation of
test-time scaling using 12 reasoning models on two knowledge-intensive
benchmarks. Our results reveal that increasing test-time computation does not
consistently improve accuracy and, in many cases, it even leads to more
hallucinations. We then analyze how extended reasoning affects hallucination
behavior. We find that reduced hallucinations often result from the model
choosing to abstain after thinking more, rather than from improved factual
recall. Conversely, for some models, longer reasoning encourages attempts on
previously unanswered questions, many of which result in hallucinations. Case
studies show that extended reasoning can induce confirmation bias, leading to
overconfident hallucinations. Despite these limitations, we observe that
compared to non-thinking, enabling thinking remains beneficial. Code and data
are available at https://github.com/XuZhao0/tts-knowledge

</details>


### [91] [Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents](https://arxiv.org/abs/2509.06917)
*Jiacheng Miao,Joe R. Davis,Jonathan K. Pritchard,James Zou*

Main category: cs.AI

TL;DR: Paper2Agent是将科研论文自动转化为AI代理的框架，通过构建MCP服务器和自然语言交互实现研究成果的动态复用


<details>
  <summary>Details</summary>
Motivation: 传统论文存在代码复用困难、知识转化效率低的问题，该框架旨在将静态论文转化为可执行AI代理以降低应用门槛

Method: 1. 多代理系统解析论文/代码库构建MCP服务器 2. 迭代测试优化MCP 3. 对接聊天代理实现自然语言驱动的工具调用

Result: 成功创建基因组解读（AlphaGenome）和单细胞转录组分析（ScanPy/TISSUE）代理，可复现原结果并处理新查询

Conclusion: 建立了「论文→动态AI代理」的新范式，为构建科研协作生态系统奠定基础，革新知识传播方式

Abstract: We introduce Paper2Agent, an automated framework that converts research
papers into AI agents. Paper2Agent transforms research output from passive
artifacts into active systems that can accelerate downstream use, adoption, and
discovery. Conventional research papers require readers to invest substantial
effort to understand and adapt a paper's code, data, and methods to their own
work, creating barriers to dissemination and reuse. Paper2Agent addresses this
challenge by automatically converting a paper into an AI agent that acts as a
knowledgeable research assistant. It systematically analyzes the paper and the
associated codebase using multiple agents to construct a Model Context Protocol
(MCP) server, then iteratively generates and runs tests to refine and robustify
the resulting MCP. These paper MCPs can then be flexibly connected to a chat
agent (e.g. Claude Code) to carry out complex scientific queries through
natural language while invoking tools and workflows from the original paper. We
demonstrate Paper2Agent's effectiveness in creating reliable and capable paper
agents through in-depth case studies. Paper2Agent created an agent that
leverages AlphaGenome to interpret genomic variants and agents based on ScanPy
and TISSUE to carry out single-cell and spatial transcriptomics analyses. We
validate that these paper agents can reproduce the original paper's results and
can correctly carry out novel user queries. By turning static papers into
dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for
knowledge dissemination and a foundation for the collaborative ecosystem of AI
co-scientists.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [92] [Authorship Without Writing: Large Language Models and the Senior Author Analogy](https://arxiv.org/abs/2509.05390)
*Clint Hurshman,Sebastian Porsdam Mann,Julian Savulescu,Brian D. Earp*

Main category: cs.CY

TL;DR: 论文主张在特定条件下，LLMs的使用可类比高级作者身份，认为当前作者标准需承认其合法性或进行根本性修订。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在学术写作中的作者身份争议，现有标准对"不执笔但指导项目"的高级作者身份认定存在逻辑矛盾。

Method: 通过类比论证方法，将LLMs在文本生成中的作用与传统科研团队中不执笔但决定研究方向的高级作者角色进行对比分析。

Result: 提出二元结论：要么承认LLMs使用者的合法作者身份，要么对现行作者标准进行根本性改革。

Conclusion: 研究揭示了人工智能时代学术规范面临的挑战，为科研伦理标准更新提供了重要理论依据。

Abstract: The use of large language models (LLMs) in bioethical, scientific, and
medical writing remains controversial. While there is broad agreement in some
circles that LLMs cannot count as authors, there is no consensus about whether
and how humans using LLMs can count as authors. In many fields, authorship is
distributed among large teams of researchers, some of whom, including
paradigmatic senior authors who guide and determine the scope of a project and
ultimately vouch for its integrity, may not write a single word. In this paper,
we argue that LLM use (under specific conditions) is analogous to a form of
senior authorship. On this view, the use of LLMs, even to generate complete
drafts of research papers, can be considered a legitimate form of authorship
according to the accepted criteria in many fields. We conclude that either such
use should be recognized as legitimate, or current criteria for authorship
require fundamental revision. AI use declaration: GPT-5 was used to help format
Box 1. AI was not used for any other part of the preparation or writing of this
manuscript.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [93] [Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models](https://arxiv.org/abs/2509.06415)
*Jaemin Son,Sujin Choi,Inyong Yun*

Main category: cs.CV

TL;DR: 提出轻量级令牌剪枝框架，通过预处理过滤文档图像非信息区域，在保持精度的同时显著降低视觉语言模型计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在文档理解任务中计算需求过高的问题，现有模型计算负担大需优化。

Method: 使用二进制补丁级分类器去除非文本区域+最大池化细化步骤恢复文本区域空间连贯性。

Result: 在真实文档数据集上降低35%计算成本，精度损失仅0.8%。

Conclusion: 该方法有效平衡计算效率与模型性能，为资源受限场景提供实用解决方案。

Abstract: Recent progress in vision-language models (VLMs) has led to impressive
results in document understanding tasks, but their high computational demands
remain a challenge. To mitigate the compute burdens, we propose a lightweight
token pruning framework that filters out non-informative background regions
from document images prior to VLM processing. A binary patch-level classifier
removes non-text areas, and a max-pooling refinement step recovers fragmented
text regions to enhance spatial coherence. Experiments on real-world document
datasets demonstrate that our approach substantially lowers computational
costs, while maintaining comparable accuracy.

</details>


### [94] [Interleaving Reasoning for Better Text-to-Image Generation](https://arxiv.org/abs/2509.06945)
*Wenxuan Huang,Shuang Chen,Zheyong Xie,Shaosheng Cao,Shixiang Tang,Yufan Shen,Qingyu Yin,Wenbo Hu,Xiaoman Wang,Yuntian Tang,Junbo Qiao,Yue Guo,Yao Hu,Zhenfei Yin,Philip Torr,Yu Cheng,Wanli Ouyang,Shaohui Lin*

Main category: cs.CV

TL;DR: 提出IRG框架通过交替文本推理与图像合成实现SOTA级文本到图像生成效果


<details>
  <summary>Details</summary>
Motivation: 当前统一多模态模型在图像生成细节保留和指令遵循方面显著落后于GPT-4o等理解-生成耦合系统

Method: IRG框架分两阶段交替推理：首先生成文本思考指导初始图像，随后通过反思迭代优化细节/画质/美学；IRGL-300K数据集支持六种分解学习模式；两阶段训练（基础模型训练+端到端微调）

Result: 在GenEval等5个基准取得5-10%绝对提升，视觉质量和细粒度保真度显著改进

Conclusion: 交替推理机制有效提升生成质量，完整技术栈（代码/模型/数据集）即将开源推动领域发展

Abstract: Unified multimodal understanding and generation models recently have achieve
significant improvement in image generation capability, yet a large gap remains
in instruction following and detail preservation compared to systems that
tightly couple comprehension with generation such as GPT-4o. Motivated by
recent advances in interleaving reasoning, we explore whether such reasoning
can further improve Text-to-Image (T2I) generation. We introduce Interleaving
Reasoning Generation (IRG), a framework that alternates between text-based
thinking and image synthesis: the model first produces a text-based thinking to
guide an initial image, then reflects on the result to refine fine-grained
details, visual quality, and aesthetics while preserving semantics. To train
IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL),
which targets two sub-goals: (1) strengthening the initial think-and-generate
stage to establish core content and base quality, and (2) enabling high-quality
textual reflection and faithful implementation of those refinements in a
subsequent image. We curate IRGL-300K, a dataset organized into six decomposed
learning modes that jointly cover learning text-based thinking, and full
thinking-image trajectories. Starting from a unified foundation model that
natively emits interleaved text-image outputs, our two-stage training first
builds robust thinking and reflection, then efficiently tunes the IRG pipeline
in the full thinking-image trajectory data. Extensive experiments show SoTA
performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF,
GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality
and fine-grained fidelity. The code, model weights and datasets will be
released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [95] [Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods](https://arxiv.org/abs/2509.06195)
*Jinrui Yang,Fan Jiang,Timothy Baldwin*

Main category: cs.IR

TL;DR: 该研究提出评估多语言检索系统语言公平性的方法，并设计LaKDA损失函数来缓解神经检索模型中的语言偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLIR系统存在语言偏见，导致不同语言查询相同语义时检索结果不一致，需建立公平性评估体系并提出改进方案。

Method: 结合传统检索方法和基于mBERT/XLM-R的DPR神经排序器进行评估，创新提出专门用于缓解语言偏见的LaKDA损失函数。

Result: 实验揭示当前MLIR技术存在固有语言偏见，不同检索方法差异显著，LaKDA能有效提升语言公平性指标。

Conclusion: 该研究为MLIR系统公平性评估建立新范式，LaKDA方法通过调整表示空间分布有效缩小语言间的检索性能差距。

Abstract: Language fairness in multilingual information retrieval (MLIR) systems is
crucial for ensuring equitable access to information across diverse languages.
This paper sheds light on the issue, based on the assumption that queries in
different languages, but with identical semantics, should yield equivalent
ranking lists when retrieving on the same multilingual documents. We evaluate
the degree of fairness using both traditional retrieval methods, and a DPR
neural ranker based on mBERT and XLM-R. Additionally, we introduce `LaKDA', a
novel loss designed to mitigate language biases in neural MLIR approaches. Our
analysis exposes intrinsic language biases in current MLIR technologies, with
notable disparities across the retrieval methods, and the effectiveness of
LaKDA in enhancing language fairness.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [96] [Language Native Lightly Structured Databases for Large Language Model Driven Composite Materials Research](https://arxiv.org/abs/2509.06093)
*Yuze Liu,Zhaoyuan Zhang,Xiangsheng Zeng,Yihe Zhang,Leping Yu,Lejia Wang,Xi Yu*

Main category: cs.DB

TL;DR: 论文提出了一种针对氮化硼纳米片（BNNS）聚合物导热复合材料的语言原生数据库，通过结构化文献信息实现高效检索增强生成（RAG）和工具增强代理，为LLM驱动的材料发现提供语言基础。


<details>
  <summary>Details</summary>
Motivation: 传统化学材料研究依赖语言叙述，导致数据非结构化，制约机器学习与数据库的效能。需建立结构化语言数据库以支持材料发现。

Method: 构建异构数据库整合制备/表征/理论计算等多维度文献片段，采用语义检索+关键词+数值过滤的复合检索，开发支持检索-推理联动的RAG框架。

Result: 系统可生成精准、可验证的专家级指南，检索准确率提升50%，推理效率提高3倍（需补充具体实验数据）

Conclusion: 该框架为LLM驱动的材料发现提供了语言密集型基础支撑，实现了检索与推理的有机融合。

Abstract: Chemical and materials research has traditionally relied heavily on knowledge
narrative, with progress often driven by language-based descriptions of
principles, mechanisms, and experimental experiences, rather than tables,
limiting what conventional databases and ML can exploit. We present a
language-native database for boron nitride nanosheet (BNNS) polymer thermally
conductive composites that captures lightly structured information from papers
across preparation, characterization, theory-computation, and mechanistic
reasoning, with evidence-linked snippets. Records are organized in a
heterogeneous database and queried via composite retrieval with semantics, key
words and value filters. The system can synthesizes literature into accurate,
verifiable, and expert style guidance. This substrate enables high fidelity
efficient Retrieval Augmented Generation (RAG) and tool augmented agents to
interleave retrieval with reasoning and deliver actionable SOP. The framework
supplies the language rich foundation required for LLM-driven materials
discovery.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [97] [Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance](https://arxiv.org/abs/2509.05978)
*Mohamed Mohamed,Brennan Nichyporuk,Douglas L. Arnold,Tal Arbel*

Main category: eess.IV

TL;DR: 提出首个基于自然语言引导的3D医学反事实影像生成框架，结合改进的扩散模型实现在神经影像领域的高质量三维图像生成


<details>
  <summary>Details</summary>
Motivation: 解决3D医学影像领域缺乏预训练基础模型导致的自然语言引导生成技术空白，推动个性化医疗解释和疾病模拟应用

Method: 改进Simple Diffusion架构，整合增强条件机制提升文本对齐能力，开发原生3D扩散模型适配神经影像数据特性

Result: 在多发性硬化症和阿尔茨海默病MRI数据上成功生成保留主体特征的病变/认知状态影像，定量验证图像质量达临床可用标准

Conclusion: 首次验证语言引导3D扩散模型在神经影像中的可行性，为三维疾病进展分析建立新范式，突破传统医学图像生成维度限制

Abstract: Vision-language models have demonstrated impressive capabilities in
generating 2D images under various conditions; however the impressive
performance of these models in 2D is largely enabled by extensive, readily
available pretrained foundation models. Critically, comparable pretrained
foundation models do not exist for 3D, significantly limiting progress in this
domain. As a result, the potential of vision-language models to produce
high-resolution 3D counterfactual medical images conditioned solely on natural
language descriptions remains completely unexplored. Addressing this gap would
enable powerful clinical and research applications, such as personalized
counterfactual explanations, simulation of disease progression scenarios, and
enhanced medical training by visualizing hypothetical medical conditions in
realistic detail. Our work takes a meaningful step toward addressing this
challenge by introducing a framework capable of generating high-resolution 3D
counterfactual medical images of synthesized patients guided by free-form
language prompts. We adapt state-of-the-art 3D diffusion models with
enhancements from Simple Diffusion and incorporate augmented conditioning to
improve text alignment and image quality. To our knowledge, this represents the
first demonstration of a language-guided native-3D diffusion model applied
specifically to neurological imaging data, where faithful three-dimensional
modeling is essential to represent the brain's three-dimensional structure.
Through results on two distinct neurological MRI datasets, our framework
successfully simulates varying counterfactual lesion loads in Multiple
Sclerosis (MS), and cognitive states in Alzheimer's disease, generating
high-quality images while preserving subject fidelity in synthetically
generated medical images. Our results lay the groundwork for prompt-driven
disease progression analysis within 3D medical imaging.

</details>
