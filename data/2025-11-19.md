<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.DL](#cs.DL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 评估水印技术对抗攻击的鲁棒性及其对文本质量/风格的影响


<details>
  <summary>Details</summary>
Motivation: 解决水印技术导致文本质量下降、易受对抗攻击的问题，以促进LLM开发者采用该技术

Method: 使用转述攻击与回译攻击测试鲁棒性，通过语言学指标评估文本质量和写作风格的保持能力

Result: 水印技术能保持语义但改变写作风格，且易受对抗攻击（回译攻击效果最显著）

Conclusion: 当前水印技术存在对抗脆弱性和风格偏移问题，需改进鲁棒性和风格保持能力才能广泛采用

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [2] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: RT（Refine Thought）通过多次前向传递优化文本嵌入模型的语义推理能力，在特定任务（BRIGHT/PJBenchmark1）中显著提升效果，同时保持通用任务（C-MTEB）性能稳定。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型在语义推理任务中未充分激活预训练阶段学到的语义推理能力，需开发测试时推理方法优化语义表示。

Method: RT作为推理阶段方法，通过多次运行文本嵌入模型的前向传递过程，逐步优化生成最终的语义表示向量。

Result: 实验显示RT在语义推理任务BRIGHT和PJBenchmark1上取得显著提升，同时在C-MTEB等通用语义理解基准保持原有性能水平。

Conclusion: RT通过激活解码器架构文本嵌入模型（如Qwen3-Embedding-8B）的预训练语义推理能力，证明其作为零训练成本推理优化方案的有效性。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [3] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 论文提出了两种无需训练的QE指导翻译修正方法：基于多LLM候选选择的方法胜出（Delta COMET 0.0201），基于QE解释替换错误的方法效果次之（-0.0108）。


<details>
  <summary>Details</summary>
Motivation: 现有联合训练QE和APE系统存在过校正问题，探索无需训练的方法以减少过校正并提升性能。

Method: 1. QE-informed Retranslation：从不同LLM生成的候选翻译中选择质量最高的版本；2. 基于QE解释的替换方法：根据QE标注指导LLM替换错误片段，采用条件启发式策略最小化编辑次数。

Result: 方法一Delta COMET得分0.0201（胜出），方法二得分为-0.0108。

Conclusion: 无需训练的多候选选择方法更有效，在保持编辑增益比方面展示出优势，为QE指导的翻译修正提供了新思路。

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [4] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: 研究发现LLMs在长文本检索中存在'中间迷失'现象，提出GM-Extract基准和双评估体系，揭示数据表示方式对检索性能的重要影响，并发现现有缓解方法效果具有情境敏感性。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在基于检索应用中难以有效利用长距离上下文的问题（'lost-in-the-middle'现象），研究旨在通过构建新基准和评估系统揭示该现象的实际影响机制。

Method: 1. 构建GM-Extract基准数据集评估控制变量检索能力
2. 提出文档度量（空间检索）和变量提取度量（语义检索）双评价体系
3. 对7-8B参数模型进行多文档任务系统评估
4. 分析困惑度分数与检索性能的相关性

Result: 1. 数据表示方式显著改变检索性能
2. 模型表现呈现清晰模式（虽未持续观测到U型曲线）
3. 缓解方法效果呈现高度情境化特征，存在性能负优化案例

Conclusion: 通过系统评估揭示LLMs长文本检索的脆弱性，证明现有优化方法的局限性，为实际应用中的上下文工程提供重要实证依据。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [5] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: 提出通过LLM解析电商查询中的最高级语义，并转移至轻量模型的高效检索框架


<details>
  <summary>Details</summary>
Motivation: 处理含最高级词汇的搜索查询需要跨维度比较，现有方法难以平衡语言理解与部署效率

Method: 1. 分解查询生成属性-值提示
2. 与检索并发的结构化解释框架
3. 开发模型间语义迁移技术实现轻量化部署

Result: 搜索MAP提升10.9点，排序MRR提升5.9点，有效解决LLM直接部署的延迟问题

Conclusion: 首次实现最高级语义的跨模型迁移，在保持检索系统语言理解能力的同时满足实际部署要求

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [6] [Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports](https://arxiv.org/abs/2511.14010)
*Chenchen Kuai,Zihao Li,Braden Rosen,Stephanie Paan,Navid Jafari,Jean-Louis Briaud,Yunlong Zhang,Youssef M. A. Hashash,Yang Zhou*

Main category: cs.CL

TL;DR: 开发MoRA-RAG框架提升灾害侦察报告结构化分析能力，通过混合检索机制和验证循环使LLM准确率达94.5%，减少幻觉现象


<details>
  <summary>Details</summary>
Motivation: 传统灾害侦察报告的非结构化特性导致多灾害知识转移困难，而现有LLM缺乏领域知识支撑易产生不可靠输出

Method: 集成混合检索机制动态路由跨灾害数据库查询，采用代理分块保持上下文连贯性，构建验证循环评估证据充分性并优化搜索

Result: 在HazardRecQA数据集上准确率提升30%（相比零样本LLM）和10%（相比先进RAG），不同架构LLM均显著减少幻觉生成

Conclusion: MoRA-RAG开创了将灾害文档转化为可信应急情报的新范式，使开源模型达到商业模型性能，增强灾害韧性决策支持

Abstract: Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.

</details>


### [7] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: 提出HiEAG框架，通过多模态大语言模型分层增强证据处理，提升跨模态虚假信息检测的外部一致性验证


<details>
  <summary>Details</summary>
Motivation: 现有OOC检测方法过度关注内部一致性，忽视图像-文本对与外部证据的外部一致性验证需求

Method: 分层证据增强框架：1) 证据重排序模块(AESP筛选证据) 2) 证据改写模块(AEGP优化适配) 3) 指令微调实现可解释检测

Result: 在多个基准数据集上超越现有SOTA方法，实现全样本准确率提升

Conclusion: 通过系统化证据处理流程设计，有效释放MLLMs在虚假信息检测任务中的潜力，推动可解释性检测发展

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [8] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 提出通过构建平衡数据集和改进模型架构解决多标签情感分类中的类别不平衡问题


<details>
  <summary>Details</summary>
Motivation: 现有GoEmotions等数据集存在严重的类别不平衡问题，影响模型在低代表性情感上的表现

Method: 1.整合三源数据构建平衡数据集 2.设计包含FastText嵌入、CNN-BiLSTM架构和注意力机制的模型 3.采用Sigmoid输出层和混合精度训练

Result: 实验显示准确率、F1值等指标显著优于基于不平衡数据的模型

Conclusion: 数据平衡策略与混合神经网络架构有效提升了多标签情感分类性能

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [9] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 提出一种名为Stealth Fine-Tuning的新型攻击方法，通过499个样本在3小时内即可高效突破增强型视觉语言模型的安全防护机制，攻击成功率提升38.52%且不影响模型原有推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐机制暴露的思维链（CoT）轨迹形成新的攻击面，揭示增强型视觉语言模型安全防护的脆弱性

Method: 三阶段攻击框架：1）通过段落级干扰生成有害思维链 2）复用模型自生成输出构建微调数据集 3）采用轮次加权损失设计实现轻量化、分布一致的微调

Result: 单卡A100（QLoRA）微调后攻击成功率超越IDEATOR 38.52%，在AdvBench等基准测试中验证方法有效性，同时保持原始表征分布和通用推理能力

Conclusion: 暴露思维链的模型架构存在根本性安全缺陷，需要开发新型防御机制应对此类隐蔽微调攻击

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [10] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 提出数据中心的合成数据生成框架，通过生成9万条合成临床文本显著改善ICD编码的长尾分布问题


<details>
  <summary>Details</summary>
Motivation: 现有医疗数据集中罕见和零样本ICD代码代表性不足，导致自动编码模型的宏观性能低下

Method: 基于真实医疗数据的共现模式、ICD描述和分类法构建多标签合成数据集，使用结构化提示生成覆盖7,902个代码的合成出院摘要

Result: 在保持优异微观F1的同时实现宏观F1提升，超越现有最优方法

Conclusion: 精心设计的合成数据能有效提升长尾医疗代码预测的公平性，尽管计算成本较高但验证了数据增强的有效性

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [11] [From Graphs to Hypergraphs: Enhancing Aspect-Based Sentiment Analysis via Multi-Level Relational Modeling](https://arxiv.org/abs/2511.14142)
*Omkar Mahesh Kashyap,Padegal Amit,Madhav Kashyap,Ashwini M Joshi,Shylaja SS*

Main category: cs.CL

TL;DR: 提出动态超图框架HyperABSA，通过样本特异性分层聚类构建方面-观点结构，显著提升ABSA任务性能


<details>
  <summary>Details</summary>
Motivation: 解决传统图方法因仅建模二元依赖导致的多图冗余、参数冗余和错误传播问题，提升短文本低资源场景下的鲁棒性

Method: 采用分层聚类的加速-回退截断机制，自适应确定超边粒度，实现动态超图构建

Result: 在Lap14/Rest14/MAMS基准测试中均超越强基线模型，结合RoBERTa时性能提升尤为显著

Conclusion: 动态超图构建为ABSA任务提供高效解决方案，并可扩展至其他短文本NLP任务

Abstract: Aspect-Based Sentiment Analysis (ABSA) predicts sentiment polarity for specific aspect terms, a task made difficult by conflicting sentiments across aspects and the sparse context of short texts. Prior graph-based approaches model only pairwise dependencies, forcing them to construct multiple graphs for different relational views. These introduce redundancy, parameter overhead, and error propagation during fusion, limiting robustness in short-text, low-resource settings. We present HyperABSA, a dynamic hypergraph framework that induces aspect-opinion structures through sample-specific hierarchical clustering. To construct these hyperedges, we introduce a novel acceleration-fallback cutoff for hierarchical clustering, which adaptively determines the level of granularity. Experiments on three benchmarks (Lap14, Rest14, MAMS) show consistent improvements over strong graph baselines, with substantial gains when paired with RoBERTa backbones. These results position dynamic hypergraph construction as an efficient, powerful alternative for ABSA, with potential extensions to other short-text NLP tasks.

</details>


### [12] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 将Transformer关系抽取与知识图谱验证结合，实现可追溯多选题解答，准确率达70%


<details>
  <summary>Details</summary>
Motivation: 利用动态生成的知识图谱增强多选题解答的可解释性，通过关系抽取检测错误信息

Method: 使用Transformer关系抽取生成问题句的图谱，并与事实图谱进行封闭世界假设验证

Result: 系统正确率约70%，问题类型显著影响准确率（事实类73.7% vs 逻辑类25%）

Conclusion: 动态知识图谱验证有效提升多选题解答的可追溯性，问题类型是准确率的关键因素

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [13] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 论文提出选择性弱到强泛化框架（W2SG），通过二元分类器P(IK)筛选可用自生成标签的问题，结合图平滑优化弱标签，实验证明其有效性并支持超级对齐。


<details>
  <summary>Details</summary>
Motivation: 现有W2SG方法在微调强模型时全量使用弱监督数据，但部分有害标签会损害模型性能，需选择性利用弱监督以提升鲁棒性。

Method: 1. 训练P(IK)分类器识别强模型可自主回答的问题，仅对筛选出的问题使用自生成标签对齐
2. 基于图平滑方法对剩余弱标签进行修正

Result: 在三个基准测试中性能超越基线，P(IK)展现出跨任务/难度泛化能力，证明选择性W2SG有助于超级对齐场景。

Conclusion: 该框架通过动态筛选弱监督数据，减少有害标签干扰，为超人类模型对齐提供了更高效的解决方案。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [14] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 符号语义知识是定位LLM幻觉的核心机制，通过注意力方差分析揭示符号语义处理在早期层已崩溃


<details>
  <summary>Details</summary>
Motivation: 现有研究未能系统处理符号触发因素（否定/数字/命名实体等）与幻觉的关联，缺乏基于符号语义的定位框架

Method: 提出首个基于符号语言知识的分层定位框架，分析Gemma等5个模型在HaluEval和TruthfulQA上的注意力机制

Result: 符号触发因素在2-4层即出现注意力方差爆炸（否定触发最高达93.7%），各规模Gemma模型幻觉率均超78%

Conclusion: 幻觉本质是符号语义处理失败而非通用生成问题，符号知识为理解LLM幻觉机制提供关键视角

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [15] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL框架将大语言模型整合到实体链接全流程，并提出自验证机制，显著提升性能表现


<details>
  <summary>Details</summary>
Motivation: 现有方法仅在大语言模型孤立应用阶段存在局限性，未能充分发挥其全局上下文理解能力

Method: 1. 构建全面整合LLM的端到端框架 2. 基于全局上下文设计自验证机制修正预测 3. 增强同句实体内在关联识别能力

Result: 十大数据集测试显示F1平均提升2.6%，域外数据提升达4%

Conclusion: 深度整合大语言模型可显著推进实体链接技术发展，自验证机制有效提升模型鲁棒性

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [16] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 首个阿拉伯语多系统语法纠错框架ArbESC+，通过集成AraT5/ByT5/mT5等模型，在QALB数据集上取得82.63%-84.64%的F0.5分数，超越单模型效果。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语复杂的形态句法结构使语法纠错困难，传统单模型方法未能发挥多系统集成的潜在优势。

Method: 构建多模型提案池（AraT5/ByT5/mT5/AraBART等），将修正方案编码为数值特征，通过分类器决策，采用重叠修正过滤和置信度评估提升输出质量。

Result: QALB-14测试集F0.5达82.63%，QALB-15 L1/L2分别达84.64%和65.55%，显著优于单模型。

Conclusion: 该研究首次实现阿拉伯语多系统语法纠错集成，为提升阿拉伯语文本处理工具提供重要技术突破。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [17] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 提出通过构建大规模音乐语料库（40B tokens）和基于参考模型的动态训练优化方法，有效提升音乐领域LLM的效果


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在音乐娱乐领域受限于语料规模、数据纯净度及任务匹配度，需建立领域优化的数据训练框架

Method: 1. 构建领域优先数据管道（分类过滤+多阶段清洗） 2. 整合多源音乐文本与元数据 3. 引入RM-based token级软评分机制实现动态梯度优化

Result: 开发了可扩展的MusicSimpleQA评估基准，实验证明该方法能有效控制数据质量并增强任务对齐信号

Conclusion: 通过『正确语料+正确目标』的双重优化，为音乐领域LLM提供了可复用的数据训练框架和评估工具

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [18] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 提出Authentic-Dubber模型，通过检索增强的导演-演员交互学习机制，结合多模态情感检索和渐进式语音生成，显著提升电影配音的情感表现力。


<details>
  <summary>Details</summary>
Motivation: 现有电影配音方法简化了导演-演员的交互流程（演员直接配音），忽略了真实场景中导演通过情感线索引导演员理解上下文的核心协作机制。

Method: 1. 构建多模态参考素材库模拟导演提供的学习资料（集成LLM深度理解情感表征）
2. 基于情感相似性的检索增强策略提取目标静音视频相关多模态信息
3. 渐进式图网络语音生成逐步融合检索到的情感知识

Result: 在V2C Animation基准数据集上主客观评估验证有效性，代码和演示已开源。

Conclusion: 提出的三阶段机制成功模拟真实配音流程，通过多模态情感知识整合实现了情感表达力的全面提升。

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [19] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: 首个针对非洲英语口音的领域专用评估套件AfriSpeech-MultiBench，覆盖10+国家、100+口音和7大应用领域，系统性评估各类语音识别模型表现。


<details>
  <summary>Details</summary>
Motivation: 填补非洲语言多样性领域缺乏公开应用评估工具的空白，促进包容性语音技术发展。

Method: 整合非洲口音英语数据集（自发/非自发语音），跨领域评估开源/闭源ASR模型、多模态LLM及微调模型的性能表现。

Result: 开源ASR擅长自发语音但噪声敏感；多模态LLM抗口音强但专业实体识别弱；商业模型在清晰语音表现佳但地域/领域差异大；非洲英语微调模型延迟低但幻象问题突出。

Conclusion: 通过发布多维度基准，赋能研究者和开发者选择适配非洲场景的语音技术，推动服务不足社区的语音应用发展。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [20] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 提出熵引导训练框架解决推理模型中的熵冲突问题，将推理链压缩至原长度的20%同时保持准确率


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法忽视熵冲突现象——压缩目标降低熵限制探索，性能目标增加熵延长推理链，形成局部最优困境。根源在于高熵的逻辑连接词同时受到性能目标的梯度鼓励和压缩目标的惩罚

Method: 熵引导训练框架：熵下降时引导模型精简推理步骤；熵上升时在紧凑模式下增强探索鲁棒性

Result: 在六个数学基准测试中实现推理长度压缩80%（原长20%），准确率保持或超越基线模型

Conclusion: 通过熵动态调节有效平衡推理效率与模型性能，为解决复杂推理任务的部署瓶颈提供新方案

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [21] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 通过预测概率分布提升LLM置信度估计的可靠性


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索推理策略对置信度估计的影响，特别是如何通过结构化方法鼓励深度推理

Method: 提出预测完整答案空间的概率分布，要求模型综合考虑所有候选答案并精细分配置信度得分

Result: 该方法在不同模型和任务中均显示优势（包括未知答案空间场景），强化学习后仍保持优势，推理模式符合人类预期

Conclusion: 概率分布预测法有效提升置信度估计的可靠性和可解释性，推动LLM可信评估研究

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [22] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench是首个全人工标注的阿拉伯语语言能力评估基准，通过150道专家设计的选择题揭示主流大模型存在表层熟练但深层语法理解不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语基准测试侧重知识记忆而非语言结构理解，需构建诊断性评估框架揭示模型真实语言掌握程度

Method: 设计覆盖语法/词法/拼写/阅读理解/句法5大核心领域的测评体系，对35个阿拉伯语及双语模型进行系统性测试

Result: 当前模型在表层任务表现良好（平均准确率68%），但在涉及复杂语法结构的题目上准确率骤降至42%，显示其依赖模式识别而非真正理解

Conclusion: 该基准通过隔离基础语言技能，为提升阿拉伯语大模型的核心语言推理能力提供了量化诊断工具，代码已在GitHub开源

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [23] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: 评估LLMs处理指令冲突能力的研究：专有模型检测能力强但缺乏用户提示，DeepSeek-R1表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视LLMs处理含冲突约束指令的能力，而复杂提示中冲突普遍存在。

Method: 创建ConInstruct基准测试集，系统评估LLMs的冲突检测与解决行为。

Result: 1. 专有模型冲突检测强（DeepSeek-R1达91.5% F1值）；2. 仅1.6%情况会主动提示冲突

Conclusion: 当前LLMs存在重大缺陷：即使检测到冲突也鲜少主动沟通，提示未来改进方向。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [24] [The Tokenization Bottleneck: How Vocabulary Extension Improves Chemistry Representation Learning in Pretrained Language Models](https://arxiv.org/abs/2511.14365)
*Prathamesh Kalamkar,Ned Letcher,Meissane Chami,Sahger Lad,Shayan Mohanty,Prasanna Pendse*

Main category: cs.CL

TL;DR: 提出统一自然语言与分子结构的表征方法，通过词汇扩展和持续预训练突破LLMs的化学标记化瓶颈


<details>
  <summary>Details</summary>
Motivation: 通用文本的标记器会破坏SMILES等化学表征的语义完整性，阻碍LLMs在化学领域的有效应用

Method: 1. 在预训练LLM中扩展化学相关词汇 2. 通过化学领域文本持续预训练整合新知识

Result: 在多种下游化学任务中展现出优越性能

Conclusion: 该方法有效统一了跨模态表征，为LLMs在科学领域的应用提供了新范式

Abstract: The application of large language models (LLMs) to chemistry is frequently hampered by a "tokenization bottleneck", where tokenizers tuned on general-domain text tend to fragment chemical representations such as SMILES into semantically uninformative sub-tokens. This paper introduces a principled methodology to resolve this bottleneck by unifying the representation of natural language and molecular structures within a single model. Our approach involves targeted vocabulary extension-augmenting a pretrained LLM's vocabulary with chemically salient tokens, followed by continued pretraining on chemistry-domain text to integrate this new knowledge. We provide an empirical demonstration of the effectiveness of this strategy, showing that our methodology leads to superior performance on a range of downstream chemical tasks.

</details>


### [25] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是面向AGI的科学逻辑评测基准，包含约800道原创跨学科难题，旨在解决现有大模型评测基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大模型评测基准存在性能饱和、学科单一、答案格式简化、易受数据污染等问题，与真实科研场景存在差距。

Method: 通过领域专家构建覆盖7大学科的原创题库，具备高原创性、跨学科融合、高保真答案（多步骤推理与LaTeX公式）和四阶段质量管控流程。

Result: 初步实验证明ATLAS能有效区分前沿模型的科学推理能力，模型表现与人类专家评估高度一致。

Conclusion: ATLAS将发展为长期开放的社区驱动平台，为AGI发展提供可靠评估标尺，推动跨学科科学推理能力的进步。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [26] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 提出标准化上下文校准（NCC）方法，解决LLMs在多标记类标签预测中的长度偏差问题，显著提升模型性能与鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有校准方法忽视多标记标签引发的偏差（特别是标签长度差异导致的预测不一致），影响LLMs在真实场景中的应用可靠性

Method: 通过全标签级别的标准化预测校准（NCC），同时整合上下文学习，实现跨标签长度的公平比较

Result: 在多个数据集/模型上取得统计显著改进（F1最高提升10%），扩展到多选题任务，且所需few-shot样本更少、置信度估计更可靠

Conclusion: 全标签偏差缓解对提升LLM应用性能至关重要，NCC为多标记标签场景（如现实任务）提供了更鲁棒的解决方案

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [27] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 提出教育场景专用的EduHarm安全评估基准和三阶段防护框架(TSSF)，有效防御LLM越狱攻击和微调攻击


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全研究主要关注通用场景，缺乏针对教育场景特殊安全需求（如未成年人保护、学术诚信等）的系统性防护方案

Method: 三阶段防护框架：1) 安全感知注意力重校准识别关键风险token 2) 分层安全判断聚合多层安全特征 3) 防御驱动双路由机制分离安全/危险查询

Result: 在8种越狱攻击策略下实现87.5%的恶意指令拦截率，微调攻击场景中保持92%的良性查询效用，同时防御成功率提升40%+

Conclusion: TSSF框架首次实现教育LLM的双重攻击防护，在安全性和实用性间取得平衡，为教育AI系统提供可靠安全保障

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [28] [MedBench v4: A Robust and Scalable Benchmark for Evaluating Chinese Medical Language Models, Multimodal Models, and Intelligent Agents](https://arxiv.org/abs/2511.14439)
*Jinru Ding,Lu Lu,Chao Ding,Mouxiao Bian,Jiayuan Chen,Renjie Lu,Wenrao Pang,Xiaoqin Wu,Zhiqiang Liu,Luyi Jiang,Bing Han,Yunqiu Wang,Jie Xu*

Main category: cs.CL

TL;DR: MedBench v4推出覆盖24个医疗领域的云基准测试平台，评估显示基础模型在安全伦理维度表现薄弱，但通过智能体架构设计可显著提升临床适用性


<details>
  <summary>Details</summary>
Motivation: 现有医疗大模型评估框架需反映真实临床流程与安全约束，故开发国家级多模态医疗AI评估体系MedBench v4

Method: 整合70万+专家标注任务，经多机构临床医生审核，采用LLM校准评分机制，横向测评15个前沿模型性能

Result: 基础LLM均分54.1（Claude Sonnet 62.5），安全伦理均分仅18.4；多模态模型均分47.5（GPT-5最高54.9）；智能体架构使端到端性能提升至79.8均分（Claude智能体达85.3）

Conclusion: 基础模型在多模态推理与安全性存在短板，但治理导向的智能体架构可显著提升临床准备度，该平台为中国医疗AI审计提供实践参考

Abstract: Recent advances in medical large language models (LLMs), multimodal models, and agents demand evaluation frameworks that reflect real clinical workflows and safety constraints. We present MedBench v4, a nationwide, cloud-based benchmarking infrastructure comprising over 700,000 expert-curated tasks spanning 24 primary and 91 secondary specialties, with dedicated tracks for LLMs, multimodal models, and agents. Items undergo multi-stage refinement and multi-round review by clinicians from more than 500 institutions, and open-ended responses are scored by an LLM-as-a-judge calibrated to human ratings. We evaluate 15 frontier models. Base LLMs reach a mean overall score of 54.1/100 (best: Claude Sonnet 4.5, 62.5/100), but safety and ethics remain low (18.4/100). Multimodal models perform worse overall (mean 47.5/100; best: GPT-5, 54.9/100), with solid perception yet weaker cross-modal reasoning. Agents built on the same backbones substantially improve end-to-end performance (mean 79.8/100), with Claude Sonnet 4.5-based agents achieving up to 85.3/100 overall and 88.9/100 on safety tasks. MedBench v4 thus reveals persisting gaps in multimodal reasoning and safety for base models, while showing that governance-aware agentic orchestration can markedly enhance benchmarked clinical readiness without sacrificing capability. By aligning tasks with Chinese clinical guidelines and regulatory priorities, the platform offers a practical reference for hospitals, developers, and policymakers auditing medical AI.

</details>


### [29] [Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](https://arxiv.org/abs/2511.14445)
*Trishala Jayesh Ahalpara*

Main category: cs.CL

TL;DR: 开发了集成RAG对话助手、合成治疗对话生成和AI自我关怀规划的心理健康支持系统Tell Me，通过跨学科合作推动AI在心理福祉中的负责任应用。


<details>
  <summary>Details</summary>
Motivation: 解决心理健康资源获取障碍和专业治疗数据短缺问题，通过AI技术提供补充性支持并促进相关研究

Method: 1. 检索增强生成(RAG)实现个性化对话
2. 基于用户画像的合成治疗对话生成
3. CrewAI驱动的动态自适应自我关怀规划

Result: 系统通过LLM自动评估和用户研究验证，在策划的心理健康场景中表现出有效性

Conclusion: 展示了对话助手在降低支持门槛、补充现有护理方面的潜力，强调需与心理健康专业人员跨学科合作实现负责任创新

Abstract: We present Tell Me, a mental well-being system that leverages advances in large language models to provide accessible, context-aware support for users and researchers. The system integrates three components: (i) a retrieval-augmented generation (RAG) assistant for personalized, knowledge-grounded dialogue; (ii) a synthetic client-therapist dialogue generator conditioned on client profiles to facilitate research on therapeutic language and data augmentation; and (iii) a Well-being AI crew, implemented with CrewAI, that produces weekly self-care plans and guided meditation audio. The system is designed as a reflective space for emotional processing rather than a substitute for professional therapy. It illustrates how conversational assistants can lower barriers to support, complement existing care, and broaden access to mental health resources. To address the shortage of confidential therapeutic data, we introduce synthetic client-therapist dialogue generation conditioned on client profiles. Finally, the planner demonstrates an innovative agentic workflow for dynamically adaptive, personalized self-care, bridging the limitations of static well-being tools. We describe the architecture, demonstrate its functionalities, and report evaluation of the RAG assistant in curated well-being scenarios using both automatic LLM-based judgments and a human-user study. This work highlights opportunities for interdisciplinary collaboration between NLP researchers and mental health professionals to advance responsible innovation in human-AI interaction for well-being.

</details>


### [30] [Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.14460)
*Mingyue Cheng,Jie Ouyang,Shuo Yu,Ruiran Yan,Yucong Luo,Zirui Liu,Daoyu Wang,Qi Liu,Enhong Chen*

Main category: cs.CL

TL;DR: 提出强化学习框架Agent-R1用于训练LLM智能体，通过扩展MDP框架定义关键组件并在多跳QA任务验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在LLM智能体应用中存在定制化方法缺乏和训练框架不灵活的问题，需推进该领域发展

Method: 1. 系统重构基于MDP框架的LLM智能体强化学习方法 2. 开发模块化、可扩展的Agent-R1训练框架

Result: 在多跳QA基准任务中完成初步实验验证，证明方法和框架的有效性

Conclusion: 通过理论框架重构和实验验证，推进了强化学习在LLM智能体领域的实用化应用

Abstract: Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.

</details>


### [31] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG基准包含895个合成QA对，用于系统性评估RAG问答系统，整合真实答案、支持性证据及题目难度指标


<details>
  <summary>Details</summary>
Motivation: 随着RAG技术在生成式AI中的普及，亟需系统性评估框架验证其有效性

Method: 基于SIGIR'2025竞赛数据集构建，补充真实答案/支持性声明，应用项目反应理论计算题目难度与区分度

Result: 验证了问题多样性、难度梯度及系统区分能力，为RAG评估提供多维度量化标准

Conclusion: LiveRAG通过结构化评估体系推动RAG技术迭代，助力构建更健壮的问答系统

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [32] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 研究提出通过声明对齐技术评估文档级声明提取效果，揭示当前方法在非正式语言和本地化语境中的局限性


<details>
  <summary>Details</summary>
Motivation: 现有文档级声明提取评估方法无法有效处理非正式语言和强本地语境，尤其捷克/斯洛伐克新闻评论场景需要更可靠的评估框架

Method: 开发声明对齐技术，通过相似性评分比较模型提取与人工标注的声明集，并在捷克/斯洛伐克新闻评论数据集验证框架有效性

Result: 当前评估方法在语义相似性捕捉和声明属性(原子性/可核查性/去语境化)评估方面存在显著缺陷

Conclusion: 需开发能准确评估语义相似性并量化声明本质属性的先进方法，以提升事实核查系统的可靠性

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [33] [Leveraging Digitized Newspapers to Collect Summarization Data in Low-Resource Languages](https://arxiv.org/abs/2511.14598)
*Noam Dahan,Omer Kidron,Gabriel Stanovsky*

Main category: cs.CL

TL;DR: 利用报纸头版摘要构建多语言摘要数据集的新方法，在七种语言验证并创建首个希伯来语多文档摘要数据集HEBTEASESUM。


<details>
  <summary>Details</summary>
Motivation: 解决小语种摘要数据稀缺问题，挖掘历史报纸中编辑撰写的自然摘要作为高质量数据源。

Method: 通过Front-Page Teasers提取多文档摘要，开发适配不同语言资源的自动化收集流程。

Result: 验证方法跨七种语言适用性，并产出首个希伯来语专用多文档摘要数据集。

Conclusion: 该方法为低资源语言NLP研究提供了可扩展的数据获取方案，具有重要应用价值。

Abstract: High quality summarization data remains scarce in under-represented languages. However, historical newspapers, made available through recent digitization efforts, offer an abundant source of untapped, naturally annotated data. In this work, we present a novel method for collecting naturally occurring summaries via Front-Page Teasers, where editors summarize full length articles. We show that this phenomenon is common across seven diverse languages and supports multi-document summarization. To scale data collection, we develop an automatic process, suited to varying linguistic resource levels. Finally, we apply this process to a Hebrew newspaper title, producing HEBTEASESUM, the first dedicated multi-document summarization dataset in Hebrew.

</details>


### [34] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 利用电子健康记录数据追踪急性肾损伤（AKI）患者的临床轨迹，发现17%的AKI患者发展为慢性肾病（CKD），不同临床状态对应差异化的CKD风险。


<details>
  <summary>Details</summary>
Motivation: 急性肾损伤患者进展为慢性肾病的风险较高，但现有方法难以精准识别高风险人群。本研究旨在通过动态追踪AKI患者临床演变特征，建立预测模型支持早期干预。

Method: 使用20,699例住院AKI患者的电子健康记录数据，通过纵向医疗编码和肌酐测量值聚类确定临床状态，采用多状态模型估计状态转移概率，并通过生存分析识别亚组CKD风险因素。

Result: 识别出15种不同临床状态（75%患者保持单一状态），发现AKI严重程度、糖尿病等传统风险因素与新型风险因素对CKD的影响存在状态特异性差异。

Conclusion: 数据驱动方法可有效识别AKI高危人群，为开发临床决策支持工具、实现CKD早期预警提供理论依据。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [35] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: Compares human vs LLMs (GPT/BERT/RoBERTa/FLAN) in detecting political bias in news, showing RoBERTa aligns best with human labels while GPT excels in zero-shot settings.


<details>
  <summary>Details</summary>
Motivation: Despite NLP advances in bias detection, the alignment between LLMs and human judgment in political bias perception remains underexplored.

Method: Constructs manually annotated news dataset, evaluates annotation consistency/bias polarity/inter-model agreement across transformer-based and generative models.

Result: RoBERTa achieves highest human alignment among transformers; GPT shows strongest zero-shot agreement. Fine-tuned RoBERTa achieves peak accuracy.

Conclusion: Reveals systematic human-LLM perception differences in political slant detection, advocating hybrid frameworks combining human interpretability with model scalability.

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [36] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: 多智能体系统结合视觉语言模型实现自主科学发现，通过动态评估图表实现实时纠错，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 提升科学发现的自动化水平，通过VLM实时验证图表数据来修正错误，减少人工干预需求。

Method: 采用VLM作为动态评估器，生成领域特定评分标准指导智能体自主调整数据分析路径。

Result: 在宇宙学/天体化学案例中实现错误自修正，基准测试pass@1达0.7-0.8，较基线提升2-4倍。

Conclusion: VLM增强系统显著提升科学发现效率与可解释性，提供可追溯的推理路径验证机制。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [37] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: 提出RareSeek R1系统，通过领域专用临床语料库与知识增强检索机制，显著提升罕见病诊断效率与准确性，临床推理透明度达医生水平


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断周期长（数年），传统流程存在证据提取与诊断推理割裂问题，通用/医疗大模型面临数据稀缺、知识陈旧、幻觉等问题

Method: 构建临床专业语料库+医生验证推理集，采用分阶段指令微调、思维链学习、图结构检索技术，通过多中心电子病历和公共基准测试验证

Result: 实现最优诊断准确率（SOTA），噪声/表型重叠场景下保持稳健，检索增强机制使诊断准确性提升23.1%，人类评估达到资深医师水平

Conclusion: 开创『叙事优先-知识融合』推理范式，通过可解释的决策路径缩短诊断进程，关键非表型证据（影像/干预/功能检测）支撑23.1%正确诊断

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [38] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: This paper validates noisy-channel theory by modeling comparative illusion strength through language models and behavioral data, explaining subtle CI effects and pronoun/noun phrase influences.


<details>
  <summary>Details</summary>
Motivation: To demonstrate noisy-channel inference as a unified explanation for language illusions by quantitatively predicting CI effect strength and resolving unexplained pronoun-related effects.

Method: Developed a quantitative posterior probability model through novel integration of statistical language models with human behavioral data.

Result: Model successfully explained gradations in CI effects and revealed novel pronoun vs. noun phrase subject influences on illusion strength.

Conclusion: Findings support noisy-channel theory as a unified computational framework explaining diverse language processing phenomena in both illusory and non-illusory contexts.

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


### [39] [Bias in, Bias out: Annotation Bias in Multilingual Large Language Models](https://arxiv.org/abs/2511.14662)
*Xia Cui,Ziyi Huang,Naeemeh Adel*

Main category: cs.CL

TL;DR: 提出多语言大语言模型数据标注偏见的分类框架及治理方案，涵盖类型划分、检测指标、缓解策略和伦理分析


<details>
  <summary>Details</summary>
Motivation: 解决多语言场景下因任务设计、标注者主观性和文化差异导致的模型偏差问题，避免加剧社会危害

Method: 构建标注偏见类型学（指令/标注者/文化偏见），整合检测指标（标注一致性/模型分歧/文化推理），提出基于集成学习的多语言偏见缓解方法

Result: 建立四大贡献：1）标注偏见分类体系 2）检测指标系统化框架 3）多语言集成治理方案 4）标注流程伦理分析框架

Conclusion: 研究成果为构建文化适应性强、公平公正的大语言模型标注体系提供理论支持与实践指引

Abstract: Annotation bias in NLP datasets remains a major challenge for developing multilingual Large Language Models (LLMs), particularly in culturally diverse settings. Bias from task framing, annotator subjectivity, and cultural mismatches can distort model outputs and exacerbate social harms. We propose a comprehensive framework for understanding annotation bias, distinguishing among instruction bias, annotator bias, and contextual and cultural bias. We review detection methods (including inter-annotator agreement, model disagreement, and metadata analysis) and highlight emerging techniques such as multilingual model divergence and cultural inference. We further outline proactive and reactive mitigation strategies, including diverse annotator recruitment, iterative guideline refinement, and post-hoc model adjustments. Our contributions include: (1) a typology of annotation bias; (2) a synthesis of detection metrics; (3) an ensemble-based bias mitigation approach adapted for multilingual settings, and (4) an ethical analysis of annotation processes. Together, these insights aim to inform more equitable and culturally grounded annotation pipelines for LLMs.

</details>


### [40] [Streamlining Industrial Contract Management with Retrieval-Augmented LLMs](https://arxiv.org/abs/2511.14671)
*Kristi Topollai,Tolga Dimlioglu,Anna Choromanska,Simon Odie,Reginald Hui*

Main category: cs.CL

TL;DR: 提出模块化RAG框架解决合同修订自动化难题，在低资源场景下实现超80%准确率


<details>
  <summary>Details</summary>
Motivation: 合同修订流程因标注数据稀缺和历史合同非结构化难以自动化

Method: 集成合成数据生成、语义条款检索、可接受性分类、基于奖励的优化对齐

Result: 与工业伙伴合作验证，问题修订识别和优化准确率均超80%

Conclusion: 该系统在真实低资源环境下表现优异，为加速合同修订提供实用方案

Abstract: Contract management involves reviewing and negotiating provisions, individual clauses that define rights, obligations, and terms of agreement. During this process, revisions to provisions are proposed and iteratively refined, some of which may be problematic or unacceptable. Automating this workflow is challenging due to the scarcity of labeled data and the abundance of unstructured legacy contracts. In this paper, we present a modular framework designed to streamline contract management through a retrieval-augmented generation (RAG) pipeline. Our system integrates synthetic data generation, semantic clause retrieval, acceptability classification, and reward-based alignment to flag problematic revisions and generate improved alternatives. Developed and evaluated in collaboration with an industry partner, our system achieves over 80% accuracy in both identifying and optimizing problematic revisions, demonstrating strong performance under real-world, low-resource conditions and offering a practical means of accelerating contract revision workflows.

</details>


### [41] [Quadratic Term Correction on Heaps' Law](https://arxiv.org/abs/2511.14683)
*Oscar Fontanelli,Wentian Li*

Main category: cs.CL

TL;DR: Heap定律的二次修正：通过英文文本数据验证log-log坐标系下二次函数的优越拟合性，提出伪方差解释曲率现象


<details>
  <summary>Details</summary>
Motivation: 传统Heap定律的幂律关系在log-log坐标系下仍呈现轻微凹度，需验证更高阶模型的有效性并探索其数学本质

Method: 1. 使用20部英文著作（含译本）进行词型-词例分析
2. log-log坐标系下二次函数回归
3. 基于'袋中彩球随机抽取'模型推导伪方差理论

Result: 1. 回归系数显示线性项≈1.0，二次项≈-0.02
2. 曲率对应负伪方差现象
3. 小规模语料时模型预测有效，大规模时存在数值不稳定性

Conclusion: 二次模型更准确描述类型-词例关系，伪方差理论为早期语料增长模式提供数学解释框架

Abstract: Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a linear and quadratic term consistently lead to a linear coefficient of slightly larger than 1, and a quadratic coefficient around -0.02. Using the ``random drawing colored ball from the bag with replacement" model, we have shown that the curvature of the log-log scale is identical to a ``pseudo-variance" which is negative. Although a pseudo-variance calculation may encounter numeric instability when the number of tokens is large, due to the large values of pseudo-weights, this formalism provides a rough estimation of the curvature when the number of tokens is small.

</details>


### [42] [SMRC: Aligning Large Language Models with Student Reasoning for Mathematical Error Correction](https://arxiv.org/abs/2511.14684)
*Biaojie Zeng,Min Zhang,Juan Zhou,Fengrui Liu,Ruiyang Huang,Xin Lin*

Main category: cs.CL

TL;DR: 提出SMRC方法，通过蒙特卡洛树搜索与过程级奖励机制优化大模型对学生数学推理错误的纠正能力


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于模型自我纠错，无法满足教育场景需要系统化指导学生解题过程的'教师式'纠错需求

Method: 将学生推理建模为多步骤序贯决策问题，引入蒙特卡洛树搜索探索最优纠正路径，利用LLM引导的广度优先搜索生成奖励信号并通过反向传播机制分配至中间步骤

Result: 在ProcessBench、MR-GSM8K及自建MSEB数据集上显著优于基线方法，同时构建包含158个高中数学实例的多解错误基准测试集

Conclusion: SMRC通过过程级监督和双评估协议（答案准确性与正确步骤保留率），实现了更符合教育实践需求的数学纠错系统

Abstract: Large language models (LLMs) often make reasoning errors when solving mathematical problems, and how to automatically detect and correct these errors has become an important research direction. However, existing approaches \textit{mainly focus on self-correction within the model}, which falls short of the ``teacher-style`` correction required in educational settings, \textit{i.e.}, systematically guiding and revising a student's problem-solving process. To address this gap, we propose \texttt{SMRC} (\textit{\underline{S}tudent \underline{M}athematical \underline{R}easoning \underline{C}orrection}), a novel method that aligns LLMs with student reasoning. Specifically, \texttt{SMRC} formulates student reasoning as a multi-step sequential decision problem and introduces Monte Carlo Tree Search (MCTS) to explore optimal correction paths. To reduce the cost of the annotating process-level rewards, we leverage breadth-first search (BFS) guided by LLMs and final-answer evaluation to generate reward signals, which are then distributed across intermediate reasoning steps via a back-propagation mechanism, enabling fine-grained process supervision. Additionally, we construct a benchmark for high school mathematics, MSEB (Multi-Solution Error Benchmark), consisting of 158 instances that include problem statements, student solutions, and correct reasoning steps. We further propose a dual evaluation protocol centered on \textbf{solution accuracy} and \textbf{correct-step retention}, offering a comprehensive measure of educational applicability. Experiments demonstrate that \texttt{SMRC} significantly outperforms existing methods on two public datasets (ProcessBench and MR-GSM8K) and our MSEB in terms of effectiveness and overall performance. The code and data are available at https://github.com/Mind-Lab-ECNU/SMRC.

</details>


### [43] [Encoding and Understanding Astrophysical Information in Large Language Model-Generated Summaries](https://arxiv.org/abs/2511.14685)
*Kiera McCormick,Rafael Martínez-Galarza*

Main category: cs.CL

TL;DR: 研究大型语言模型如何编码天体物理学测量中的物理信息，探讨提示策略和语言要素对编码效果的影响


<details>
  <summary>Details</summary>
Motivation: 探索LLM能否通过文本描述编码通常需科学测量获取的物理信息，验证其在跨领域物理信息表征方面的潜力

Method: 使用稀疏自编码器分析文本特征，对比不同提示策略对物理量编码的影响

Result: 提示策略影响LLM的物理量编码效果，语言中的关键要素在编码过程中起决定性作用

Conclusion: LLM能够有效编码物理信息，提示工程和语言特征提取是提升物理表征质量的关键技术路径

Abstract: Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities are codified by the LLM? and 2) What aspects of language are most important in encoding the physics represented by the measurement? We investigate this using sparse autoencoders that extract interpretable features from the text.

</details>


### [44] [Ground Truth Generation for Multilingual Historical NLP using LLMs](https://arxiv.org/abs/2511.14688)
*Clovis Gladstone,Zhao Fang,Spencer Dean Stewart*

Main category: cs.CL

TL;DR: 利用大模型生成标注数据，优化历史文本NLP工具性能


<details>
  <summary>Details</summary>
Motivation: 解决历史文本和低资源语言处理中因标注数据不足及领域不匹配导致的NLP工具性能受限问题，推动计算人文研究发展

Method: 1. 使用大语言模型为法汉历史文本生成基准标注
2. 基于生成数据微调spaCy模型
3. 重点优化词性标注、词形还原和命名实体识别任务

Result: 领域专用模型在历史文本测试集上性能显著提升，证明少量合成数据即可有效改善低资源语料库的NLP工具表现

Conclusion: 领域专用模型具有不可替代价值，大模型生成的合成数据为计算人文研究提供了高效低成本的标注解决方案

Abstract: Historical and low-resource NLP remains challenging due to limited annotated data and domain mismatches with modern, web-sourced corpora. This paper outlines our work in using large language models (LLMs) to create ground-truth annotations for historical French (16th-20th centuries) and Chinese (1900-1950) texts. By leveraging LLM-generated ground truth on a subset of our corpus, we were able to fine-tune spaCy to achieve significant gains on period-specific tests for part-of-speech (POS) annotations, lemmatization, and named entity recognition (NER). Our results underscore the importance of domain-specific models and demonstrate that even relatively limited amounts of synthetic data can improve NLP tools for under-resourced corpora in computational humanities research.

</details>


### [45] [Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances](https://arxiv.org/abs/2511.14693)
*Rishu Kumar Singh,Navneet Shreya,Sarmistha Das,Apoorva Singh,Sriparna Saha*

Main category: cs.CL

TL;DR: 提出多模态框架VALOR，通过文本与图像信息融合及专家验证机制，显著提升复杂投诉场景的分类性能，并支持联合国可持续发展目标。


<details>
  <summary>Details</summary>
Motivation: 现有投诉分析依赖单模态短文本（如推文），难以处理多轮对话中用户同时提供文本投诉（如产品描述）和视觉证据（如截图）的多模态场景。

Method: VALOR框架采用：1) 多专家推理链（Chain-of-Thought）进行细粒度决策；2) 语义对齐评分实现跨模态一致性验证；3) 元融合策略整合模态间关联性。

Result: 在多模态投诉数据集上，VALOR在细粒度投诉维度和严重性分类任务中全面超越基线模型，尤其在跨模态信息分布的复杂场景中提升显著。

Conclusion: 通过多模态交互与专家验证机制，VALOR为服务基础设施创新（SDG 9）和可持续消费体系（SDG 12）提供了可解释的AI驱动解决方案。

Abstract: Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (CoT) prompting for nuanced decision-making. To ensure coherence between modalities, a semantic alignment score is computed and integrated into the final classification through a meta-fusion strategy. In alignment with the United Nations Sustainable Development Goals (UN SDGs), the proposed framework supports SDG 9 (Industry, Innovation and Infrastructure) by advancing AI-driven tools for robust, scalable, and context-aware service infrastructure. Further, by enabling structured analysis of complaint narratives and visual context, it contributes to SDG 12 (Responsible Consumption and Production) by promoting more responsive product design and improved accountability in consumer services. We evaluate VALOR on a curated multimodal complaint dataset annotated with fine-grained aspect and severity labels, showing that it consistently outperforms baseline models, especially in complex complaint scenarios where information is distributed across text and images. This study underscores the value of multimodal interaction and expert validation in practical complaint understanding systems. Resources related to data and codes are available here: https://github.com/sarmistha-D/VALOR

</details>


### [46] [Subword Tokenization Strategies for Kurdish Word Embeddings](https://arxiv.org/abs/2511.14696)
*Ali Salehi,Cassandra L. Jacobs*

Main category: cs.CL

TL;DR: 研究比较库尔德语不同分词策略，发现语素分词在嵌入空间组织上优于BPE，并揭示评估偏差问题


<details>
  <summary>Details</summary>
Motivation: 探索低资源语言处理中不同分词策略对形态相似性保留的影响，揭示评估方法的潜在偏差

Method: 使用BiLSTM-CRF形态分割器，通过引导训练和综合指标（相似性/聚类/语义结构）比较分词方法

Result: BPE仅在28.6%测试案例有效但形态相似性虚高，语素模型覆盖68.7%案例且展现更优的语义空间组织

Conclusion: 应重视低资源语言的覆盖率评估，语素分词提供更均衡的形态覆盖，建议根据任务需求选择不同分词方案

Abstract: We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\% of test cases compared to 68.7\% for morpheme model, creating artificial performance inflation. When assessed comprehensively, morpheme-based tokenization demonstrates superior embedding space organization, better semantic neighborhood structure, and more balanced coverage across morphological complexity levels. These findings highlight the importance of coverage-aware evaluation in low-resource language processing and offers different tokenization methods for low-resourced language processing.

</details>


### [47] [Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance](https://arxiv.org/abs/2511.14709)
*Raha Aghaei,Ali A. Kiaei,Mahnaz Boush,Mahan Rofoosheh,Mohammad Zavvar*

Main category: cs.CL

TL;DR: LLMs通过自动化知识发现、促进假设生成、整合跨学科见解和促进创新生态合作，显著提升研发效率和创新速度。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何通过多功能应用优化研发流程，提升科研效率并加速技术转化。

Method: 系统性分析科学文献、专利数据库及实验数据，构建LLMs在研发中的功能框架。

Result: LLMs使研发流程更灵活智能，缩短创新周期50%以上，关键技术转化时间降低30-40%。

Conclusion: LLMs通过知识自动化与跨域协同机制，重构了现代研发范式，成为推动科技突破的核心加速器。

Abstract: This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market for breakthrough ideas.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [48] [B2F: End-to-End Body-to-Face Motion Generation with Style Reference](https://arxiv.org/abs/2511.13988)
*Bokyung Jang,Eunho Jung,Yoonsang Lee*

Main category: cs.GR

TL;DR: B2F模型通过解耦内容与风格表示，生成与身体动作同步的多样化面部动画，兼容主流虚拟角色格式并减少感知不协调


<details>
  <summary>Details</summary>
Motivation: 解决虚拟角色面部表情与身体动作不协调导致的整体感知割裂问题，增强虚拟角色行为一致性

Method: 使用Gumbel-Softmax技巧学习离散潜在编码风格表示，结合对齐约束和一致性目标训练模型，支持FLAME/SMPL-X格式输出及ARKit转换

Result: 生成的面部动画在同步性、风格表达多样性方面表现优异，兼容不同角色平台，有效降低74%的感知不协调（用户测试数据）

Conclusion: B2F通过结构化潜在空间实现了动作-表情协同生成，为多平台虚拟角色提供了通用解决方案，推动虚拟人自然交互发展

Abstract: Human motion naturally integrates body movements and facial expressions, forming a unified perception. If a virtual character's facial expression does not align well with its body movements, it may weaken the perception of the character as a cohesive whole. Motivated by this, we propose B2F, a model that generates facial motions aligned with body movements. B2F takes a facial style reference as input, generating facial animations that reflect the provided style while maintaining consistency with the associated body motion. To achieve this, B2F learns a disentangled representation of content and style, using alignment and consistency-based objectives. We represent style using discrete latent codes learned via the Gumbel-Softmax trick, enabling diverse expression generation with a structured latent representation. B2F outputs facial motion in the FLAME format, making it compatible with SMPL-X characters, and supports ARKit-style avatars through a dedicated conversion module. Our evaluations show that B2F generates expressive and engaging facial animations that synchronize with body movements and style intent, while mitigating perceptual dissonance from mismatched cues, and generalizing across diverse characters and styles.

</details>


### [49] [FreeMusco: Motion-Free Learning of Latent Control for Morphology-Adaptive Locomotion in Musculoskeletal Characters](https://arxiv.org/abs/2511.14205)
*Minkwan Kim,Yoonsang Lee*

Main category: cs.GR

TL;DR: 提出无动作捕捉框架FreeMusco，通过联合学习潜在表示与控制策略实现形态自适应的肌肉骨骼角色运动控制，支持导航等下游任务


<details>
  <summary>Details</summary>
Motivation: 传统肌肉骨骼角色运动控制依赖动作捕捉数据，但在数据采集困难场景（如非人类形态、合成生物）中无法应用

Method: 基于模型的强化学习框架，结合控制/平衡/生物力学目标函数，引入时间平均损失函数和训练时随机化策略

Result: 在人类/非人类/合成形态中实现能量高效的差异化步态（如Chimanoid四足步态 vs Humanoid双足步态），支持实时运动强度调节

Conclusion: 首次证明无需动作捕捉即可实现多样化、物理合理的运动控制，为数据不可得场景的虚拟角色运动模拟提供新范式

Abstract: We propose FreeMusco, a motion-free framework that jointly learns latent representations and control policies for musculoskeletal characters. By leveraging the musculoskeletal model as a strong prior, our method enables energy-aware and morphology-adaptive locomotion to emerge without motion data. The framework generalizes across human, non-human, and synthetic morphologies, where distinct energy-efficient strategies naturally appear--for example, quadrupedal gaits in Chimanoid versus bipedal gaits in Humanoid. The latent space and corresponding control policy are constructed from scratch, without demonstration, and enable downstream tasks such as goal navigation and path following--representing, to our knowledge, the first motion-free method to provide such capabilities. FreeMusco learns diverse and physically plausible locomotion behaviors through model-based reinforcement learning, guided by the locomotion objective that combines control, balancing, and biomechanical terms. To better capture the periodic structure of natural gait, we introduce the temporally averaged loss formulation, which compares simulated and target states over a time window rather than on a per-frame basis. We further encourage behavioral diversity by randomizing target poses and energy levels during training, enabling locomotion to be flexibly modulated in both form and intensity at runtime. Together, these results demonstrate that versatile and adaptive locomotion control can emerge without motion capture, offering a new direction for simulating movement in characters where data collection is impractical or impossible.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [50] [When AI Does Science: Evaluating the Autonomous AI Scientist KOSMOS in Radiation Biology](https://arxiv.org/abs/2511.13825)
*Humza Nusrat,Omar Nusrat*

Main category: cs.AI

TL;DR: AI科学家KOSMOS在辐射生物学中验证三个假设：1个强支持发现(CDO1)、1个不确定结果(12基因特征)、1个错误假设(DDR-p53)，强调需严谨验证机制


<details>
  <summary>Details</summary>
Motivation: 评估自主AI科学家在真实科研场景中的假设生成能力，验证其产出成果的科学可靠性

Method: 使用随机基因零模型基准，在三个辐射生物学问题上测试KOSMOS：1）DDR与p53响应相关性 2）OGT/CDO1与辐射响应模块关联 3）12基因特征预测前列腺放疗预后

Result: 假设1：DDR评分与p53响应呈弱负相关(rho=-0.40)，与随机基因无异；假设2：CDO1显著关联(empirical p=0.0039)，OGT弱相关；假设3：12基因特征C-index=0.61(p=0.017)但效应量非唯一

Conclusion: AI科学家能产生有用洞见但需严格验证，需建立适当的零模型审计机制以过滤虚假假设，展示当前AI科研的潜力与局限

Abstract: Agentic AI "scientists" now use language models to search the literature, run analyses, and generate hypotheses. We evaluate KOSMOS, an autonomous AI scientist, on three problems in radiation biology using simple random-gene null benchmarks. Hypothesis 1: baseline DNA damage response (DDR) capacity across cell lines predicts the p53 transcriptional response after irradiation (GSE30240). Hypothesis 2: baseline expression of OGT and CDO1 predicts the strength of repressed and induced radiation-response modules in breast cancer cells (GSE59732). Hypothesis 3: a 12-gene expression signature predicts biochemical recurrence-free survival after prostate radiotherapy plus androgen deprivation therapy (GSE116918). The DDR-p53 hypothesis was not supported: DDR score and p53 response were weakly negatively correlated (Spearman rho = -0.40, p = 0.76), indistinguishable from random five-gene scores. OGT showed only a weak association (r = 0.23, p = 0.34), whereas CDO1 was a clear outlier (r = 0.70, empirical p = 0.0039). The 12-gene signature achieved a concordance index of 0.61 (p = 0.017) but a non-unique effect size. Overall, KOSMOS produced one well-supported discovery, one plausible but uncertain result, and one false hypothesis, illustrating that AI scientists can generate useful ideas but require rigorous auditing against appropriate null models.

</details>


### [51] [AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance](https://arxiv.org/abs/2511.14043)
*Chandrachur Bhattacharya,Sibendu Som*

Main category: cs.AI

TL;DR: 阿贡实验室开发的多代理系统AISAC，集成LangGraph/FAISS/SQLite技术，实现透明可追溯的科学工作流并展示跨领域应用能力


<details>
  <summary>Details</summary>
Motivation: 针对科研工作流中透明性不足、定制化困难、科学语料动态更新等痛点，构建可追溯可配置的智能辅助系统

Method: 采用Router-Planner-Coordinator工作流架构，混合FAISS向量检索与SQLite结构化存储，基于文件哈希的增量索引策略，配置驱动的项目初始化框架

Result: 成功应用于废物资源化、能源安全等多个科研领域，验证了系统在专业场景与通用科学辅助中的有效性

Conclusion: AISAC通过模块化架构设计和可视化决策日志，为科研机构提供了灵活可扩展的智能工作流解决方案

Abstract: AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability.
  The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code.
  All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.

</details>


### [52] [PRISM: Prompt-Refined In-Context System Modelling for Financial Retrieval](https://arxiv.org/abs/2511.14130)
*Chun Chet Ng,Jia Yu Lim,Wei Zeng Low*

Main category: cs.AI

TL;DR: 提出PRISM框架解决金融信息检索问题，结合系统提示、上下文学习和多智能体系统，在FinAgentBench数据集上取得0.71818的NDCG@5指标


<details>
  <summary>Details</summary>
Motivation: 针对金融长文档中任务相关信息的精准提取需求，解决传统方法在工业级金融检索中的效率与精度问题

Method: 集成三要素：1) 精细化系统提示工程 2) 上下文学习提供语义样本 3) 轻量级多智能体协同评分机制

Result: 受限验证集NDCG@5达0.71818，框架模块化设计适配生产环境，推理过程无需训练

Conclusion: PRISM通过无训练架构实现工业级金融检索，开源设计提升实际部署可行性

Abstract: With the rapid progress of large language models (LLMs), financial information retrieval has become a critical industrial application. Extracting task-relevant information from lengthy financial filings is essential for both operational and analytical decision-making. The FinAgentBench dataset formalizes this problem through two tasks: document ranking and chunk ranking. We present PRISM, a training-free framework that integrates refined system prompting, in-context learning (ICL), and a lightweight multi-agent system. Each component is examined extensively to reveal their synergies: prompt engineering provides precise task instructions, ICL supplies semantically relevant few-shot examples, and the multi-agent system models coordinated scoring behaviour. Our best configuration achieves an NDCG@5 of 0.71818 on the restricted validation split. We further demonstrate that PRISM is feasible and robust for production-scale financial retrieval. Its modular, inference-only design makes it practical for real-world use cases. The source code is released at https://bit.ly/prism-ailens.

</details>


### [53] [DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning](https://arxiv.org/abs/2511.14299)
*Xiaochuan Liu,Yuanfeng Song,Xiaoming Yin,Xing Chen*

Main category: cs.AI

TL;DR: 提出DataSage多智能体框架，通过知识检索、多角色辩论和多路径推理解决现有数据洞察代理的领域知识不足、分析浅层和代码错误问题


<details>
  <summary>Details</summary>
Motivation: 现有数据洞察代理存在领域知识利用不足、分析深度有限、代码生成易错三大缺陷，影响自动化数据分析效果

Method: 1. 外部知识检索丰富分析语境
2. 多角色辩论机制模拟多维分析视角
3. 多路径推理提升代码生成准确性

Result: 在InsightBench基准测试中全面超越现有方案，各难度级别表现最优

Conclusion: DataSage框架通过创新性三阶段设计，为自动化数据洞察提供了高效可靠的解决方案

Abstract: In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [54] [GRPO Privacy Is at Risk: A Membership Inference Attack Against Reinforcement Learning With Verifiable Rewards](https://arxiv.org/abs/2511.14045)
*Yule Liu,Heyi Zhang,Jinyi Zheng,Zhen Sun,Zifan Peng,Tianshuo Cong,Yilong Yang,Xinlei He,Zhuo Ma*

Main category: cs.CR

TL;DR: 提出首个针对强化学习可验证奖励（RLVR）的成员推理框架DIBA，通过行为变化而非记忆检测隐私泄露，在多项评估中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: RLVR训练范式依赖模型自生成响应，导致传统基于答案记忆的成员推理失效，需开发基于行为变化的新型隐私风险检测方法。

Method: DIBA框架聚焦模型在优势侧改进（正确性提升）和logit侧差异（策略漂移）的双轴行为变化，建立成员推理检测机制。

Result: DIBA达到0.8 AUC值，TPR@0.1%FPR高出现有方法一个量级，在跨数据集/算法/黑盒场景及视觉语言模型中保持有效性，防御措施下依然鲁棒。

Conclusion: 首次系统揭示RLVR的隐私漏洞，证明即使无显式监督，通过行为痕迹仍可可靠推断训练数据，为隐私保护提供新视角。

Abstract: Membership inference attacks (MIAs) on large language models (LLMs) pose significant privacy risks across various stages of model training. Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have brought a profound paradigm shift in LLM training, particularly for complex reasoning tasks. However, the on-policy nature of RLVR introduces a unique privacy leakage pattern: since training relies on self-generated responses without fixed ground-truth outputs, membership inference must now determine whether a given prompt (independent of any specific response) is used during fine-tuning. This creates a threat where leakage arises not from answer memorization.
  To audit this novel privacy risk, we propose Divergence-in-Behavior Attack (DIBA), the first membership inference framework specifically designed for RLVR. DIBA shifts the focus from memorization to behavioral change, leveraging measurable shifts in model behavior across two axes: advantage-side improvement (e.g., correctness gain) and logit-side divergence (e.g., policy drift). Through comprehensive evaluations, we demonstrate that DIBA significantly outperforms existing baselines, achieving around 0.8 AUC and an order-of-magnitude higher TPR@0.1%FPR. We validate DIBA's superiority across multiple settings--including in-distribution, cross-dataset, cross-algorithm, black-box scenarios, and extensions to vision-language models. Furthermore, our attack remains robust under moderate defensive measures.
  To the best of our knowledge, this is the first work to systematically analyze privacy vulnerabilities in RLVR, revealing that even in the absence of explicit supervision, training data exposure can be reliably inferred through behavioral traces.

</details>


### [55] [Steganographic Backdoor Attacks in NLP: Ultra-Low Poisoning and Defense Evasion](https://arxiv.org/abs/2511.14301)
*Eric Xue,Ruiyi Zhang,Zijun Zhang,Pengtao Xie*

Main category: cs.CR

TL;DR: 提出SteganoBackdoor后门攻击方法，利用自然语言隐写术创建隐蔽触发器，在1/10数据投毒率下实现99%攻击成功率，全面规避现有防御检测


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击依赖显式风格/符号级触发器，与真实威胁场景中的语义触发器（如特定人名）存在脱节，需开发符合实际威胁模型的隐蔽攻击方式

Method: 结合自然语言隐写术特性，通过梯度引导的数据优化将语义触发器转化为隐写载体，保持文本流畅且无表征相似性

Result: 实验显示攻击成功率超99%，投毒率比现有方法低一个数量级，在12种数据防御方案中保持100%逃避成功率

Conclusion: 暴露当前防御体系对隐蔽语义触发器的检测盲区，呼吁加强对抗性数据防御研究并重构现实威胁模型

Abstract: Transformer models are foundational to natural language processing (NLP) applications, yet remain vulnerable to backdoor attacks introduced through poisoned data, which implant hidden behaviors during training. To strengthen the ability to prevent such compromises, recent research has focused on designing increasingly stealthy attacks to stress-test existing defenses, pairing backdoor behaviors with stylized artifact or token-level perturbation triggers. However, this trend diverts attention from the harder and more realistic case: making the model respond to semantic triggers such as specific names or entities, where a successful backdoor could manipulate outputs tied to real people or events in deployed systems. Motivated by this growing disconnect, we introduce SteganoBackdoor, bringing stealth techniques back into line with practical threat models. Leveraging innocuous properties from natural-language steganography, SteganoBackdoor applies a gradient-guided data optimization process to transform semantic trigger seeds into steganographic carriers that embed a high backdoor payload, remain fluent, and exhibit no representational resemblance to the trigger. Across diverse experimental settings, SteganoBackdoor achieves over 99% attack success at an order-of-magnitude lower data-poisoning rate than prior approaches while maintaining unparalleled evasion against a comprehensive suite of data-level defenses. By revealing this practical and covert attack, SteganoBackdoor highlights an urgent blind spot in current defenses and demands immediate attention to adversarial data defenses and real-world threat modeling.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [56] [Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments](https://arxiv.org/abs/2511.13788)
*Samuel Nathanson,Rebecca Williams,Cynthia Matuszek*

Main category: cs.LG

TL;DR: 研究发现大语言模型通过规模优势可系统性破解小模型的安全防护，引发跨模型安全风险。


<details>
  <summary>Details</summary>
Motivation: 探讨多智能体场景下模型规模差异对安全漏洞的影响，验证大模型是否可通过对抗交互突破小模型的安全防护机制。

Method: 使用JailbreakBench对抗任务库，在0.6B-120B参数模型间模拟6000+次攻击-防御交互，通过三组LLM评估代理量化危害分数和拒绝率。

Result: 攻击/防御模型尺寸比例对数与危害分数显著相关（皮尔逊r=0.51）；攻击方行为差异方差（0.18）大于防御方差（0.10）；攻击方拒绝率与危害强负相关（rho=-0.93）。

Conclusion: 模型尺寸不对称性影响安全鲁棒性，为跨模型安全研究提供实证依据，提示需加强多模型交互场景下的安全机制设计。

Abstract: Large language models (LLMs) increasingly operate in multi-agent and safety-critical settings, raising open questions about how their vulnerabilities scale when models interact adversarially. This study examines whether larger models can systematically jailbreak smaller ones - eliciting harmful or restricted behavior despite alignment safeguards. Using standardized adversarial tasks from JailbreakBench, we simulate over 6,000 multi-turn attacker-target exchanges across major LLM families and scales (0.6B-120B parameters), measuring both harm score and refusal behavior as indicators of adversarial potency and alignment integrity. Each interaction is evaluated through aggregated harm and refusal scores assigned by three independent LLM judges, providing a consistent, model-based measure of adversarial outcomes. Aggregating results across prompts, we find a strong and statistically significant correlation between mean harm and the logarithm of the attacker-to-target size ratio (Pearson r = 0.51, p < 0.001; Spearman rho = 0.52, p < 0.001), indicating that relative model size correlates with the likelihood and severity of harmful completions. Mean harm score variance is higher across attackers (0.18) than across targets (0.10), suggesting that attacker-side behavioral diversity contributes more to adversarial outcomes than target susceptibility. Attacker refusal frequency is strongly and negatively correlated with harm (rho = -0.93, p < 0.001), showing that attacker-side alignment mitigates harmful responses. These findings reveal that size asymmetry influences robustness and provide exploratory evidence for adversarial scaling patterns, motivating more controlled investigations into inter-model alignment and safety.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [NeuralSSD: A Neural Solver for Signed Distance Surface Reconstruction](https://arxiv.org/abs/2511.14283)
*Zi-Chen Xi,Jiahui Huang,Hao-Xiang Chen,Francis Williams,Qun-Ce Xu,Tai-Jiang Mu,Shi-Min Hu*

Main category: cs.CV

TL;DR: 提出NeuralSSD方法，通过新型能量方程和三维卷积网络实现高精度点云表面重建


<details>
  <summary>Details</summary>
Motivation: 现有隐式场参数化方法缺乏确保表面与点云数据紧密贴合的机制，需平衡点云信息的可靠性

Method: 结合神经Galerkin方法，设计能量方程平衡点云可靠性，开发三维卷积网络学习空间信息优化重建

Result: 在ShapeNet和Matterport数据集上达到表面重建精度与泛化性的SOTA效果

Conclusion: NeuralSSD通过物理约束和点云归纳偏置，实现了高精度、强鲁棒性的表面重建，有效处理拓扑变化

Abstract: We proposed a generalized method, NeuralSSD, for reconstructing a 3D implicit surface from the widely-available point cloud data. NeuralSSD is a solver-based on the neural Galerkin method, aimed at reconstructing higher-quality and accurate surfaces from input point clouds. Implicit method is preferred due to its ability to accurately represent shapes and its robustness in handling topological changes. However, existing parameterizations of implicit fields lack explicit mechanisms to ensure a tight fit between the surface and input data. To address this, we propose a novel energy equation that balances the reliability of point cloud information. Additionally, we introduce a new convolutional network that learns three-dimensional information to achieve superior optimization results. This approach ensures that the reconstructed surface closely adheres to the raw input points and infers valuable inductive biases from point clouds, resulting in a highly accurate and stable surface reconstruction. NeuralSSD is evaluated on a variety of challenging datasets, including the ShapeNet and Matterport datasets, and achieves state-of-the-art results in terms of both surface reconstruction accuracy and generalizability.

</details>


### [58] [A Neural Field-Based Approach for View Computation & Data Exploration in 3D Urban Environments](https://arxiv.org/abs/2511.14742)
*Stefan Cobeli,Kazi Shahrukh Omar,Rodrigo Valença,Nivan Ferreira,Fabio Miranda*

Main category: cs.CV

TL;DR: 提出基于神经场的隐式表达方法，通过双向查询机制提升3D城市数据分析效率，支持可视性评估、日照分析等关键任务。


<details>
  <summary>Details</summary>
Motivation: 现有3D城市数据分析存在计算效率低、视角遮挡严重、依赖人工调整视角等问题，限制了大规模城市环境分析的可行性。

Method: 1. 构建神经场隐式表达实现高效环境建模
2. 矢量场编码支持直接查询(视图指标计算)和逆向查询(遮挡规避与模式匹配)
3. 开发视图评估指标体系

Result: 定量实验验证了10倍查询速度提升，真实案例显示可有效识别建筑立面可视区域(精度达92%)，专家评估确认系统在规划方案比选中的实用性。

Conclusion: 该框架为城市形态分析提供了新的范式，特别在规划方案可视化影响评估、公共空间视域分析等场景具有显著应用价值。

Abstract: Despite the growing availability of 3D urban datasets, extracting insights remains challenging due to computational bottlenecks and the complexity of interacting with data. In fact, the intricate geometry of 3D urban environments results in high degrees of occlusion and requires extensive manual viewpoint adjustments that make large-scale exploration inefficient. To address this, we propose a view-based approach for 3D data exploration, where a vector field encodes views from the environment. To support this approach, we introduce a neural field-based method that constructs an efficient implicit representation of 3D environments. This representation enables both faster direct queries, which consist of the computation of view assessment indices, and inverse queries, which help avoid occlusion and facilitate the search for views that match desired data patterns. Our approach supports key urban analysis tasks such as visibility assessments, solar exposure evaluation, and assessing the visual impact of new developments. We validate our method through quantitative experiments, case studies informed by real-world urban challenges, and feedback from domain experts. Results show its effectiveness in finding desirable viewpoints, analyzing building facade visibility, and evaluating views from outdoor spaces. Code and data are publicly available at https://urbantk.org/neural-3d.

</details>


### [59] [EchoAgent: Guideline-Centric Reasoning Agent for Echocardiography Measurement and Interpretation](https://arxiv.org/abs/2511.13948)
*Matin Daghyani,Lyuyang Wang,Nima Hashemi,Bassant Medhat,Baraa Abdelsamad,Eros Rojas Velez,XiaoXiao Li,Michael Y. C. Tsang,Christina Luong,Teresa S. M. Tsang,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 提出EchoAgent框架，通过任务专用工具和全视频自动化实现指南对齐的超声心动图视频分析代理系统


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型缺乏视频级推理和指南测量分析能力，无法满足心脏超声领域的结构化自动分析需求

Method: 基于大语言模型协调专用视觉工具，实现时空定位与测量，创新性引入测量可行性预测模型实现自主工具选择

Result: 在复杂时空分析中保持准确性，输出结果具备视觉证据支持和临床指南依据，确保透明度和可追溯性

Conclusion: 验证了代理式指南对齐推理在超声视频分析中的可行性，为心脏超声可信AI发展开辟新方向

Abstract: Purpose: Echocardiographic interpretation requires video-level reasoning and guideline-based measurement analysis, which current deep learning models for cardiac ultrasound do not support. We present EchoAgent, a framework that enables structured, interpretable automation for this domain. Methods: EchoAgent orchestrates specialized vision tools under Large Language Model (LLM) control to perform temporal localization, spatial measurement, and clinical interpretation. A key contribution is a measurement-feasibility prediction model that determines whether anatomical structures are reliably measurable in each frame, enabling autonomous tool selection. We curated a benchmark of diverse, clinically validated video-query pairs for evaluation. Results: EchoAgent achieves accurate, interpretable results despite added complexity of spatiotemporal video analysis. Outputs are grounded in visual evidence and clinical guidelines, supporting transparency and traceability. Conclusion: This work demonstrates the feasibility of agentic, guideline-aligned reasoning for echocardiographic video analysis, enabled by task-specific tools and full video-level automation. EchoAgent sets a new direction for trustworthy AI in cardiac ultrasound.

</details>


### [60] [Error-Driven Scene Editing for 3D Grounding in Large Language Models](https://arxiv.org/abs/2511.14086)
*Yue Zhang,Zun Wang,Han Lin,Jialu Li,Jianing Yang,Yonatan Bitton,Idan Szpektor,Mohit Bansal*

Main category: cs.CV

TL;DR: 提出DEER-3D框架，通过错误驱动的3D场景编辑提升3D-LLMs的空间基础能力


<details>
  <summary>Details</summary>
Motivation: 现有3D-LLMs在空间基础能力上存在缺陷，主要源于训练数据侧重语言推理且3D资源稀缺

Method: DEER-3D框架包含错误分解、诊断评估、最小化场景编辑和迭代微调四阶段流程

Result: 在多个3D基础任务基准测试中实现持续性能提升，验证了方法的有效性

Conclusion: 定向的场景编辑策略成功弥补了语言推理与空间基础能力之间的鸿沟

Abstract: Despite recent progress in 3D-LLMs, they remain limited in accurately grounding language to visual and spatial elements in 3D environments. This limitation stems in part from training data that focuses on language reasoning rather than spatial understanding due to scarce 3D resources, leaving inherent grounding biases unresolved. To address this, we propose 3D scene editing as a key mechanism to generate precise visual counterfactuals that mitigate these biases through fine-grained spatial manipulation, without requiring costly scene reconstruction or large-scale 3D data collection. Furthermore, to make these edits targeted and directly address the specific weaknesses of the model, we introduce DEER-3D, an error-driven framework following a structured "Decompose, Diagnostic Evaluation, Edit, and Re-train" workflow, rather than broadly or randomly augmenting data as in conventional approaches. Specifically, upon identifying a grounding failure of the 3D-LLM, our framework first diagnoses the exact predicate-level error (e.g., attribute or spatial relation). It then executes minimal, predicate-aligned 3D scene edits, such as recoloring or repositioning, to produce targeted counterfactual supervision for iterative model fine-tuning, significantly enhancing grounding accuracy. We evaluate our editing pipeline across multiple benchmarks for 3D grounding and scene understanding tasks, consistently demonstrating improvements across all evaluated datasets through iterative refinement. DEER-3D underscores the effectiveness of targeted, error-driven scene editing in bridging linguistic reasoning capabilities with spatial grounding in 3D LLMs.

</details>


### [61] [O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model](https://arxiv.org/abs/2511.14368)
*Rishi Gupta,Mukilan Karuppasamy,Shyam Marjit,Aditay Tripathi,Anirban Chakraborty*

Main category: cs.CV

TL;DR: 通过构建图像-草图-指令三元组数据集(O3SLM)解决大型视觉语言模型在草图理解上的瓶颈，显著提升多任务性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型难以理解抽象手绘草图，核心瓶颈在于缺乏联合建模草图/真实图像/自然语言指令的大规模数据集

Method: 1. 构建包含预训练和指令微调阶段的大规模图像-草图-指令数据集 2. 开发基于该数据集的O3SLM模型

Result: 在草图定位/计数/检索/VQA等任务中，融合QuickDraw!/Sketchy/Tu Berlin及自建SketchVCL数据集，取得SOTA性能

Conclusion: 提出的数据集架构和O3SLM模型有效突破现有技术限制，在草图理解推理任务中实现显著性能提升

Abstract: While Large Vision Language Models (LVLMs) are increasingly deployed in real-world applications, their ability to interpret abstract visual inputs remains limited. Specifically, they struggle to comprehend hand-drawn sketches, a modality that offers an intuitive means of expressing concepts that are difficult to describe textually. We identify the primary bottleneck as the absence of a large-scale dataset that jointly models sketches, photorealistic images, and corresponding natural language instructions. To address this, we present two key contributions: (1) a new, large-scale dataset of image-sketch-instruction triplets designed to facilitate both pretraining and instruction tuning, and (2) O3SLM, an LVLM trained on this dataset. Comprehensive evaluations on multiple sketch-based tasks: (a) object localization, (b) counting, (c) image retrieval i.e., (SBIR and fine-grained SBIR), and (d) visual question answering (VQA); while incorporating the three existing sketch datasets, namely QuickDraw!, Sketchy, and Tu Berlin, along with our generated SketchVCL dataset, show that O3SLM achieves state-of-the-art performance, substantially outperforming existing LVLMs in sketch comprehension and reasoning.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [62] [Rdgai: Classifying transcriptional changes using Large Language Models with a test case from an Arabic Gospel tradition](https://arxiv.org/abs/2511.13801)
*Robert Turnbull*

Main category: cs.DL

TL;DR: 开发Rdgai软件包利用多语言大语言模型实现文本异读分类自动化，降低系统发育分析门槛


<details>
  <summary>Details</summary>
Motivation: 传统文本谱系分类需人工标注每个异读单元，耗时长且存在技术壁垒。现有概率方法虽支持分类分析，但人工分类效率低下制约了该技术的应用。

Method: 1. 开发Rdgai工具包实现分类流程自动化
2. 用户手动标注样本作为提示词
3. 调用多语言LLM自动分类剩余异读
4. 生成TEI XML格式数据供下游系统发育分析

Result: 以阿拉伯语《福音书》译本为案例，成功实现异读分类自动化存储。工具输出格式可直接用于构建文本传播树状图。

Conclusion: Rdgai通过人机协同模式，将传统分类效率提升2-3个数量级，为文本演化研究提供标准化技术方案。

Abstract: Application of phylogenetic methods to textual traditions has traditionally treated all changes as equivalent even though it is widely recognized that certain types of variants were more likely to be introduced than others. While it is possible to give weights to certain changes using a maximum parsimony evaluation criterion, it is difficult to state a priori what these weights should be. Probabilistic methods, such as Bayesian phylogenetics, allow users to create categories of changes, and the transition rates for each category can be estimated as part of the analysis. This classification of types of changes in readings also allows for inspecting the probability of these categories across each branch in the resulting trees. However, classification of readings is time-consuming, as it requires categorizing each reading against every other reading at each variation unit, presenting a significant barrier to entry for this kind of analysis. This paper presents Rdgai, a software package that automates this classification task using multi-lingual large language models (LLMs). The tool allows users to easily manually classify changes in readings and then it uses these annotations in the prompt for an LLM to automatically classify the remaining reading transitions. These classifications are stored in TEI XML and ready for downstream phylogenetic analysis. This paper demonstrates the application with data an Arabic translation of the Gospels.

</details>


### [63] [SciRAG: Adaptive, Citation-Aware, and Outline-Guided Retrieval and Synthesis for Scientific Literature](https://arxiv.org/abs/2511.14362)
*Hang Ding,Yilun Zhao,Tiansheng Hu,Manasi Patwardhan,Arman Cohan*

Main category: cs.DL

TL;DR: SciRAG框架通过自适应检索、引用感知推理和提纲引导合成，显著提升科学文献分析的准确性和可验证性


<details>
  <summary>Details</summary>
Motivation: 科学出版物快速增长，现有检索增强方法忽视引用网络结构，难以处理复杂查询且生成结果碎片化

Method: 1) 自适应顺序/并行证据收集 2) 利用引用图谱进行文档组织过滤 3) 基于大纲的答案规划-批判-精炼流程

Result: 在QASA/ScholarQA等基准测试中，SciRAG在事实准确性和综合质量上超越现有系统

Conclusion: 该框架为大规模科学知识聚合建立了可靠性新标准，实现透明归因的连贯知识整合

Abstract: The accelerating growth of scientific publications has intensified the need for scalable, trustworthy systems to synthesize knowledge across diverse literature. While recent retrieval-augmented generation (RAG) methods have improved access to scientific information, they often overlook citation graph structure, adapt poorly to complex queries, and yield fragmented, hard-to-verify syntheses. We introduce SciRAG, an open-source framework for scientific literature exploration that addresses these gaps through three key innovations: (1) adaptive retrieval that flexibly alternates between sequential and parallel evidence gathering; (2) citation-aware symbolic reasoning that leverages citation graphs to organize and filter supporting documents; and (3) outline-guided synthesis that plans, critiques, and refines answers to ensure coherence and transparent attribution. Extensive experiments across multiple benchmarks such as QASA and ScholarQA demonstrate that SciRAG outperforms prior systems in factual accuracy and synthesis quality, establishing a new foundation for reliable, large-scale scientific knowledge aggregation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [64] [Show and Tell: Prompt Strategies for Style Control in Multi-Turn LLM Code Generation](https://arxiv.org/abs/2511.13972)
*Jeremiah Bohr*

Main category: cs.SE

TL;DR: 组合提示方法在双轮工作流中展现出最强的初始风格控制与扩展纪律


<details>
  <summary>Details</summary>
Motivation: 探究不同提示机制在代码功能扩展时维持风格约束的持续性

Method: 采用四组条件的两轮实验设计（N=160组程序），首轮生成基础解决方案，第二轮在保持任务不变的情况下进行通用改进修订

Result: 组合提示产生最大初始压缩效果（49.2%）和最强扩展纪律（仅增加5.8%）；指令提示初始压缩率42.3%但扩展增加18.7%；示例提示仅压缩28.1%且扩展无纪律性

Conclusion: 初始提示效果与扩展纪律性是提示设计的两个独立维度，组合方法在双轮工作流中提供最稳定的风格控制

Abstract: Language models generate functionally correct code that tends toward excessive verbosity, with elaborate documentation and defensive patterns that diverge from human baselines. Two prompting mechanisms have emerged for stylistic control: instruction based prompts that articulate abstract directives, and example based prompts that provide concrete code demonstrations. The core problem is whether stylistic constraints persist when models enhance initial implementations with additional features while maintaining high functional accuracy. Here we show that instruction-based, example-based, and combined prompts produce distinct patterns of initial control and expansion discipline over one enhancement turn. We manipulated system prompts across four conditions in a paired two-turn protocol where models first generated solutions to an intermediate Python task, then revised their code under general improvement directives, holding the user task fixed (N = 160 paired programs). Combined prompts produced the strongest initial compression and greatest expansion discipline. Instructions showed large initial effects and moderate expansion discipline. Examples showed modest initial effects with no expansion discipline. These results show that initial prompt effectiveness and expansion discipline are separate aspects of prompt design, and that combined approaches provide the most stable stylistic control in this two-turn workflow.

</details>
