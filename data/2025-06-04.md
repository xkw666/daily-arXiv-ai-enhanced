<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 107]
- [cs.GR](#cs.GR) [Total: 8]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.SD](#cs.SD) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Research on Medical Named Entity Identification Based On Prompt-Biomrc Model and Its Application in Intelligent Consultation System](https://arxiv.org/abs/2506.01961)
*Jinzhu Yang*

Main category: cs.CL

TL;DR: 提出结合硬模板和软提示的Prompt-bioMRC模型，显著提升医学命名实体识别精度与效率


<details>
  <summary>Details</summary>
Motivation: 探索提示学习方法在医学NER领域的应用潜力，突破传统模型在医疗文本处理中的性能瓶颈

Method: 整合硬模板的结构化引导与软提示的柔性特征学习，优化BioBERT模型的实体识别能力

Result: 在多医疗数据集实验中准确率超越基准模型，验证方法对智能诊断系统的技术支持价值

Conclusion: 通过创新提示学习机制推动医疗信息自动化处理，为精准医疗决策提供可靠数据支撑

Abstract: This study is dedicated to exploring the application of prompt learning
methods to advance Named Entity Recognition (NER) within the medical domain. In
recent years, the emergence of large-scale models has driven significant
progress in NER tasks, particularly with the introduction of the BioBERT
language model, which has greatly enhanced NER capabilities in medical texts.
Our research introduces the Prompt-bioMRC model, which integrates both hard
template and soft prompt designs aimed at refining the precision and efficiency
of medical entity recognition. Through extensive experimentation across diverse
medical datasets, our findings consistently demonstrate that our approach
surpasses traditional models. This enhancement not only validates the efficacy
of our methodology but also highlights its potential to provide reliable
technological support for applications like intelligent diagnosis systems. By
leveraging advanced NER techniques, this study contributes to advancing
automated medical data processing, facilitating more accurate medical
information extraction, and supporting efficient healthcare decision-making
processes.

</details>


### [2] [No Free Lunch in Active Learning: LLM Embedding Quality Dictates Query Strategy Success](https://arxiv.org/abs/2506.01992)
*Lukas Rauch,Moritz Wirth,Denis Huseljic,Marek Herde,Bernhard Sick,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 研究表明LLM嵌入质量显著影响深度主动学习策略选择，多样性采样与高质量嵌入协同增效，Badge策略展现跨任务鲁棒性


<details>
  <summary>Details</summary>
Motivation: 利用冻结的LLM嵌入降低深度主动学习计算成本，探究嵌入质量对查询策略选择的影响机制

Method: 采用MTEB排行榜Top5模型及基线模型，在10个文本分类任务中系统评估嵌入质量与查询策略的交互效应

Result: 高质量嵌入提升多样性采样的早期性能，Badge策略跨任务稳定，Margin采样存在数据集特异性表现

Conclusion: 主动学习策略需结合嵌入质量与目标任务进行场景化评估，嵌入质量提升可增强特定策略的有效性

Abstract: The advent of large language models (LLMs) capable of producing
general-purpose representations lets us revisit the practicality of deep active
learning (AL): By leveraging frozen LLM embeddings, we can mitigate the
computational costs of iteratively fine-tuning large backbones. This study
establishes a benchmark and systematically investigates the influence of LLM
embedding quality on query strategies in deep AL. We employ five top-performing
models from the massive text embedding benchmark (MTEB) leaderboard and two
baselines for ten diverse text classification tasks. Our findings reveal key
insights: First, initializing the labeled pool using diversity-based sampling
synergizes with high-quality embeddings, boosting performance in early AL
iterations. Second, the choice of the optimal query strategy is sensitive to
embedding quality. While the computationally inexpensive Margin sampling can
achieve performance spikes on specific datasets, we find that strategies like
Badge exhibit greater robustness across tasks. Importantly, their effectiveness
is often enhanced when paired with higher-quality embeddings. Our results
emphasize the need for context-specific evaluation of AL strategies, as
performance heavily depends on embedding quality and the target task.

</details>


### [3] [NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts](https://arxiv.org/abs/2506.02000)
*Abhay Gupta,Michael Lu,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CL

TL;DR: 提出了首个评估大模型在6.4万-12.8万token叙事文本中进行多跳推理的基准NovelHopQA，发现前沿模型在长上下文和多跳推理时存在准确率下降问题


<details>
  <summary>Details</summary>
Motivation: 现有基准孤立测试长上下文理解或多跳推理，缺乏在自然叙事场景中综合考察上下文长度和推理深度的评估工具

Method: 基于83部公版小说构建链式QA数据集，采用关键词引导的管道构建基于连贯故事情节的跳数分离链，并通过人工验证对齐性和跳数深度

Result: 所有前沿模型（包括GPT-4）在跳数增加和上下文延长时均出现准确率下降，显示单纯扩大规模无法保证复杂推理能力

Conclusion: NovelHopQA为大规模多跳推理提供诊断工具，失败模式分析揭示了终端跳整合失败和长程漂移等关键瓶颈

Abstract: Current large language models (LLMs) struggle to answer questions that span
tens of thousands of tokens, especially when multi-hop reasoning is involved.
While prior benchmarks explore long-context comprehension or multi-hop
reasoning in isolation, none jointly vary context length and reasoning depth in
natural narrative settings. We introduce NovelHopQA, the first benchmark to
evaluate k1-4 hop QA over 64k-128k-token excerpts from 83 full-length
public-domain novels. A keyword-guided pipeline builds hop-separated chains
grounded in coherent storylines. We evaluate six state-of-the-art (SOTA) models
and apply oracle-context filtering to ensure all questions are genuinely
answerable. Human annotators validate both alignment and hop depth. We noticed
consistent accuracy drops with increased hops and context length, even in
frontier models-revealing that sheer scale does not guarantee robust reasoning.
Our failure mode analysis highlights common breakdowns, such as missed
final-hop integration and long-range drift. NovelHopQA offers a controlled
diagnostic setting to stress-test multi-hop reasoning at scale.

</details>


### [4] [Pruning for Performance: Efficient Idiom and Metaphor Classification in Low-Resource Konkani Using mBERT](https://arxiv.org/abs/2506.02005)
*Timothy Do,Pranav Saran,Harshita Poojary,Pranav Prabhu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 结合mBERT和BiLSTM的混合模型，通过注意力头剪枝提升科拉尼语隐喻分类效率（78%）和成语分类（83%）


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如科拉尼语）中比喻语言对NLP系统的处理挑战

Method: 1. 基于预训练mBERT+双向LSTM+线性分类器的混合模型
2. 引入梯度注意力头剪枝策略优化效率
3. 使用自建标注隐喻数据集进行微调

Result: 隐喻分类准确率78%，成语分类任务准确率83%

Conclusion: 注意力头剪枝技术能有效提升低资源语言NLP工具效率

Abstract: In this paper, we address the persistent challenges that figurative language
expressions pose for natural language processing (NLP) systems, particularly in
low-resource languages such as Konkani. We present a hybrid model that
integrates a pre-trained Multilingual BERT (mBERT) with a bidirectional LSTM
and a linear classifier. This architecture is fine-tuned on a newly introduced
annotated dataset for metaphor classification, developed as part of this work.
To improve the model's efficiency, we implement a gradient-based attention head
pruning strategy. For metaphor classification, the pruned model achieves an
accuracy of 78%. We also applied our pruning approach to expand on an existing
idiom classification task, achieving 83% accuracy. These results demonstrate
the effectiveness of attention head pruning for building efficient NLP tools in
underrepresented languages.

</details>


### [5] [Enhancing Paraphrase Type Generation: The Impact of DPO and RLHF Evaluated with Human-Ranked Data](https://arxiv.org/abs/2506.02018)
*Christopher Lee Lübbers*

Main category: cs.CL

TL;DR: 论文提出通过人类偏好数据和直接偏好优化（DPO）训练方法，将改写类型生成准确率提升3%，人类偏好评分提高7%，并构建新数据集支持评估。


<details>
  <summary>Details</summary>
Motivation: 现有改写生成方法依赖自动化指标且缺乏高质量人工标注数据，导致生成结果与人类偏好错位，影响语义保真度和语言转换效果。

Method: 利用人工排序的改写类型数据集，采用DPO训练框架直接对齐人类判断，同时构建人工标注检测模型（F1值达0.91/0.78/0.70）。

Result: DPO训练相较基线模型提升3%准确率，人类偏好率增加7%。检测模型在不同改写类型上表现优异。

Conclusion: 基于人类偏好数据的训练可生成更可靠、语义精准的改写，推动摘要生成、问答系统等应用，为未来人本化评估建立新基准。

Abstract: Paraphrasing re-expresses meaning to enhance applications like text
simplification, machine translation, and question-answering. Specific
paraphrase types facilitate accurate semantic analysis and robust language
models. However, existing paraphrase-type generation methods often misalign
with human preferences due to reliance on automated metrics and limited
human-annotated training data, obscuring crucial aspects of semantic fidelity
and linguistic transformations.
  This study addresses this gap by leveraging a human-ranked paraphrase-type
dataset and integrating Direct Preference Optimization (DPO) to align model
outputs directly with human judgments. DPO-based training increases
paraphrase-type generation accuracy by 3 percentage points over a supervised
baseline and raises human preference ratings by 7 percentage points. A newly
created human-annotated dataset supports more rigorous future evaluations.
Additionally, a paraphrase-type detection model achieves F1 scores of 0.91 for
addition/deletion, 0.78 for same polarity substitution, and 0.70 for
punctuation changes.
  These findings demonstrate that preference data and DPO training produce more
reliable, semantically accurate paraphrases, enabling downstream applications
such as improved summarization and more robust question-answering. The PTD
model surpasses automated metrics and provides a more reliable framework for
evaluating paraphrase quality, advancing paraphrase-type research toward
richer, user-aligned language generation and establishing a stronger foundation
for future evaluations grounded in human-centric criteria.

</details>


### [6] [ChatCFD: an End-to-End CFD Agent with Domain-specific Structured Thinking](https://arxiv.org/abs/2506.02019)
*E Fan,Weizong Wang,Tianhan Zhang*

Main category: cs.CL

TL;DR: 提出了ChatCFD，一个基于大语言模型的自动化CFD工作流管道，可简化复杂仿真配置和执行。


<details>
  <summary>Details</summary>
Motivation: 传统CFD存在操作复杂、专业门槛高的问题，需要开发更智能的自动化解决方案。

Method: 在OpenFOAM框架内构建结构化流程，整合领域知识与大语言模型，通过配置验证和错误反射机制提升准确性

Result: 验证显示ChatCFD能复现已发表CFD成果，处理基础模型难以解决的复杂新场景

Conclusion: 该框架有效降低了CFD使用门槛，展示了领域专用语言模型在工程仿真中的实用价值

Abstract: Computational Fluid Dynamics (CFD) is essential for scientific and
engineering advancements but is limited by operational complexity and the need
for extensive expertise. This paper presents ChatCFD, a large language
model-driven pipeline that automates CFD workflows within the OpenFOAM
framework. It enables users to configure and execute complex simulations from
natural language prompts or published literature with minimal expertise. The
innovation is its structured approach to database construction, configuration
validation, and error reflection, integrating CFD and OpenFOAM knowledge with
general language models to improve accuracy and adaptability. Validation shows
ChatCFD can autonomously reproduce published CFD results, handling complex,
unseen configurations beyond basic examples, a task challenging for general
language models.

</details>


### [7] [FinS-Pilot: A Benchmark for Online Financial System](https://arxiv.org/abs/2506.02037)
*Feng Wang,Yiding Sun,Jiaxin Mao,Wei Xue,Danqing Xu*

Main category: cs.CL

TL;DR: 提出FinS-Pilot基准测试框架，解决金融领域RAG评估中数据动态整合与实时性挑战，通过真实场景实验验证框架有效性


<details>
  <summary>Details</summary>
Motivation: 现有金融RAG基准受限于数据保密性和缺乏动态数据整合，难以有效评估金融NLP系统的实时信息处理能力

Method: 基于真实金融助手交互构建基准，整合实时API+结构化文本，通过意图分类框架覆盖股权分析/宏观经济预测等核心场景，系统测试多款中文领先LLM

Result: 验证框架可有效识别适用金融场景的模型，填补金融领域专用评估工具空白，揭示现有模型处理时效性市场信息的不足

Conclusion: 贡献金融NLP系统评估框架与高质量数据集，促进领域发展，公开代码与数据集助力后续研究

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
various professional domains, with their performance typically evaluated
through standardized benchmarks. However, the development of financial RAG
benchmarks has been constrained by data confidentiality issues and the lack of
dynamic data integration. To address this issue, we introduces FinS-Pilot, a
novel benchmark for evaluating RAG systems in online financial applications.
Constructed from real-world financial assistant interactions, our benchmark
incorporates both real-time API data and structured text sources, organized
through an intent classification framework covering critical financial domains
such as equity analysis and macroeconomic forecasting. The benchmark enables
comprehensive evaluation of financial assistants' capabilities in handling both
static knowledge and time-sensitive market information. Through systematic
experiments with multiple Chinese leading LLMs, we demonstrate FinS-Pilot's
effectiveness in identifying models suitable for financial applications while
addressing the current gap in specialized evaluation tools for the financial
domain. Our work contributes both a practical evaluation framework and a
curated dataset to advance research in financial NLP systems. The code and
dataset are accessible on
GitHub\footnote{https://github.com/PhealenWang/financial\_rag\_benchmark}.

</details>


### [8] [Enhancing Multimodal Continual Instruction Tuning with BranchLoRA](https://arxiv.org/abs/2506.02041)
*Duzhen Zhang,Yong Ren,Zhong-Zhi Li,Yahan Yu,Jiahua Dong,Chenxing Li,Zhilong Ji,Jinfeng Bai*

Main category: cs.CL

TL;DR: 提出BranchLoRA框架解决多模态持续指令调优中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有MoELoRA方法通过简单聚合LoRA块导致参数效率低下和性能衰退

Method: 采用分支冻结机制+任务专用路由器+自动化任务选择器的非对称框架

Result: 在最新MCIT基准上显著优于MoELoRA，且在不同规模MLLM中保持优势

Conclusion: BranchLoRA通过结构创新实现了持续学习效率与性能的同步提升

Abstract: Multimodal Continual Instruction Tuning (MCIT) aims to finetune Multimodal
Large Language Models (MLLMs) to continually align with human intent across
sequential tasks. Existing approaches often rely on the Mixture-of-Experts
(MoE) LoRA framework to preserve previous instruction alignments. However,
these methods are prone to Catastrophic Forgetting (CF), as they aggregate all
LoRA blocks via simple summation, which compromises performance over time. In
this paper, we identify a critical parameter inefficiency in the MoELoRA
framework within the MCIT context. Based on this insight, we propose
BranchLoRA, an asymmetric framework to enhance both efficiency and performance.
To mitigate CF, we introduce a flexible tuning-freezing mechanism within
BranchLoRA, enabling branches to specialize in intra-task knowledge while
fostering inter-task collaboration. Moreover, we incrementally incorporate
task-specific routers to ensure an optimal branch distribution over time,
rather than favoring the most recent task. To streamline inference, we
introduce a task selector that automatically routes test inputs to the
appropriate router without requiring task identity. Extensive experiments on
the latest MCIT benchmark demonstrate that BranchLoRA significantly outperforms
MoELoRA and maintains its superiority across various MLLM sizes.

</details>


### [9] [Evaluating the Unseen Capabilities: How Many Theorems Do LLMs Know?](https://arxiv.org/abs/2506.02058)
*Xiang Li,Jiayi Xin,Qi Long,Weijie J. Su*

Main category: cs.CL

TL;DR: 提出KnowSum统计框架解决大语言模型评估中未观察知识量化问题


<details>
  <summary>Details</summary>
Motivation: 现有评估方法因忽视模型编码但未观察到的知识（unseen knowledge）导致评估失真

Method: 基于观察知识实例的出现频率进行外推，构建三阶段统计估计框架（总知识量估计、信息检索评估、输出多样性测量）

Result: 实验显示主流LLMs基于内部知识的相对排名发生显著变化，常规评估遗漏大量潜在知识

Conclusion: KnowSum为LLM评估提供了更全面视角，揭示了传统评估方法的系统性偏差

Abstract: Accurate evaluation of large language models (LLMs) is crucial for
understanding their capabilities and guiding their development. However,
current evaluations often inconsistently reflect the actual capacities of these
models. In this paper, we demonstrate that one of many contributing factors to
this \textit{evaluation crisis} is the oversight of unseen knowledge --
information encoded by LLMs but not directly observed or not yet observed
during evaluations. We introduce KnowSum, a statistical framework designed to
provide a more comprehensive assessment by quantifying the unseen knowledge for
a class of evaluation tasks. KnowSum estimates the unobserved portion by
extrapolating from the appearance frequencies of observed knowledge instances.
We demonstrate the effectiveness and utility of KnowSum across three critical
applications: estimating total knowledge, evaluating information retrieval
effectiveness, and measuring output diversity. Our experiments reveal that a
substantial volume of knowledge is omitted when relying solely on observed LLM
performance. Importantly, KnowSum yields significantly different comparative
rankings for several common LLMs based on their internal knowledge.

</details>


### [10] [Knowledge or Reasoning? A Close Look at How LLMs Think Across Domains](https://arxiv.org/abs/2506.02126)
*Juncheng Wu,Sheng Liu,Haoqin Tu,Hang Yu,Xiaoke Huang,James Zou,Cihang Xie,Yuyin Zhou*

Main category: cs.CL

TL;DR: 研究通过分解知识推理过程，发现不同训练方法(SFT/RL)在医学和数学领域对语言模型推理质量的影响差异


<details>
  <summary>Details</summary>
Motivation: 现有推理增强型大模型在复杂任务表现提升但内部推理透明度不足，尤其在医疗领域可能带来安全隐患

Method: 提出知识指数(KI)和信息增益(InfoGain)评估框架，对比分析SFT/RL训练方法在医疗和数学领域的表现

Result: SFT提升答案准确率但损害推理质量，RL通过修剪错误知识提升医疗推理，而通用推理能力难以迁移至医疗领域

Conclusion: 医疗领域需要SFT+RL组合训练，数学领域需保持模型原始推理能力，领域知识的特殊性决定训练策略选择

Abstract: Recent advances in reasoning-enhanced Large Language Models such as
OpenAI-o1/3 and DeepSeek-R1 have significantly improved performance on complex
tasks. However, the quality and transparency of their internal reasoning
processes remain underexplored. This work moves beyond the final-answer
accuracy and investigates step-by-step reasoning in the medical and
mathematical domains by explicitly decomposing the thinking trajectories into
two parts: knowledge and reasoning. Specifically, we introduce a fine-grained
evaluation framework that judges: (1) the correctness of knowledge used
(measured by Knowledge Index (KI)) and (2) the quality of reasoning (measured
by Information Gain (InfoGain)). Using this framework, we study R1-distilled
and base Qwen models trained with supervised fine-tuning (SFT) and/or
reinforcement learning (RL) in the medical and math domains. Three intriguing
findings emerge: (1) The general reasoning abilities in R1-distilled models do
not transfer effectively to the medical domain through either SFT or RL. (2)
SFT raises final-answer accuracy in both domains, but often at the cost of
reasoning quality: InfoGain drops by 38.9% on average compared with untrained
models; In the medical domain, however, SFT remains crucial because domain
knowledge is indispensable. (3) RL enhances medical reasoning by pruning
inaccurate or irrelevant knowledge from reasoning paths, thereby improving both
reasoning accuracy and knowledge correctness.

</details>


### [11] [Model Internal Sleuthing: Finding Lexical Identity and Inflectional Morphology in Modern Language Models](https://arxiv.org/abs/2506.02132)
*Michael Li,Nishant Subramani*

Main category: cs.CL

TL;DR: 不同Transformer模型在词汇和屈折形态编码中呈现一致性模式：词汇信息早期线性/后期非线性编码，屈折信息全层线性可访问，揭示语言信息组织的底层规律


<details>
  <summary>Details</summary>
Motivation: 填补对现代大型语言模型（LLM）内部工作机制的理解空白，突破基于早期模型（如BERT）的研究范式，探究不同架构/规模模型的共性语言编码特征

Method: 使用16种经典和现代模型（含指令微调变体），训练线性/非线性分类器分析层激活，预测词元（lemma）和屈折特征（时态/数/性等）

Result: 词汇身份依赖记忆化编码（早期层线性集中，后期非线性增强），屈折形态通过抽象规则编码（全层线性可分离），该模式跨越不同架构/规模模型持续存在

Conclusion: Transformer模型的语言信息组织方式具有架构无关的稳定性，这种分层编码机制可能是实现高效next token prediction的基础能力，形成于预训练早期阶段

Abstract: Large transformer-based language models dominate modern NLP, yet our
understanding of how they encode linguistic information is rooted in studies of
early models like BERT and GPT-2. To better understand today's language models,
we investigate how both classical architectures (BERT, DeBERTa, GPT-2)and
contemporary large language models (Pythia, OLMo-2, Gemma-2, Qwen2.5,
Llama-3.1) represent lexical identity and inflectional morphology. We train
linear and nonlinear classifiers on layer-wise activations to predict word
lemmas and inflectional features. We discover that models concentrate lexical
information linearly in early layers and increasingly nonlinearly in later
layers, while keeping inflectional information uniformly accessible and
linearly separable throughout the layers. Further analysis reveals that these
models encode inflectional morphology through generalizable abstractions, but
rely predominantly on memorization to encode lexical identity. Remarkably,
these patterns emerge across all 16 models we test, despite differences in
architecture, size, and training regime (including pretrained and
instruction-tuned variants). This consistency suggests that, despite
substantial advances in LLM technologies, transformer models organize
linguistic information in similar ways, indicating that these properties could
be fundamental for next token prediction and are learned early during
pretraining. Our code is available at
https://github.com/ml5885/model_internal_sleuthing.

</details>


### [12] [BabyLM's First Constructions: Causal interventions provide a signal of learning](https://arxiv.org/abs/2506.02147)
*Joshua Rozner,Leonie Weissweiler,Cory Shain*

Main category: cs.CL

TL;DR: 研究显示，使用婴儿语言学习规模数据（BabyLM）训练的模型能有效学习构式结构，且构式表征能力与基准测试表现正相关。


<details>
  <summary>Details</summary>
Motivation: 验证在发育合理数据量下训练的模型是否仍能学习构式结构，回应先前模型使用非合理数据量的质疑。

Method: 采用Rozner等人方法，对BabyLM挑战赛模型进行构式敏感性测试，使用发育合理规模（<100M词）的语料训练。

Result: 模型成功习得多种构式（包括表面难辨的复杂构式），且构式表征能力与BabyLM基准测试成绩呈正相关。

Conclusion: 发育合理数据量下模型仍具备构式学习能力，支持计算建模对人类语言习得研究的解释力。

Abstract: Construction grammar posits that children acquire constructions (form-meaning
pairings) from the statistics of their environment. Recent work supports this
hypothesis by showing sensitivity to constructions in pretrained language
models (PLMs), including one recent study (Rozner et al., 2025) demonstrating
that constructions shape the PLM's output distribution. However, models under
study have generally been trained on developmentally implausible amounts of
data, casting doubt on their relevance to human language learning. Here we use
Rozner et al.'s methods to evaluate constructional learning in models from the
2024 BabyLM challenge. Our results show that even when trained on
developmentally plausible quantities of data, models represent diverse
constructions, even hard cases that are superficially indistinguishable. We
further find correlational evidence that constructional performance may be
functionally relevant: models that better represent constructions perform
better on the BabyLM benchmarks.

</details>


### [13] [HENT-SRT: Hierarchical Efficient Neural Transducer with Self-Distillation for Joint Speech Recognition and Translation](https://arxiv.org/abs/2506.02157)
*Amir Hussein,Cihan Xiao,Matthew Wiesner,Dan Povey,Leibny Paola Garcia,Sanjeev Khudanpur*

Main category: cs.CL

TL;DR: 提出HENT-SRT框架，通过分层任务分解与自蒸馏技术，显著提升语音翻译性能并缩小与AED系统的差距。


<details>
  <summary>Details</summary>
Motivation: 现有神经转录器在语音翻译中存在词序重排困难、联合建模性能退化及高计算成本问题。

Method: 1. 分层架构分离ASR与翻译任务
2. 自蒸馏结合CTC一致性正则化
3. 采用降采样编码器/无状态预测器/修剪损失提升效率
4. 解码阶段引入空白惩罚机制

Result: 在阿拉伯语/西班牙语/普通话对话数据集上达到NT模型SOTA，与AED系统差距显著缩小

Conclusion: HENT-SRT有效解决了神经转录器在语音翻译中的核心瓶颈，实现了性能与效率的平衡

Abstract: Neural transducers (NT) provide an effective framework for speech streaming,
demonstrating strong performance in automatic speech recognition (ASR).
However, the application of NT to speech translation (ST) remains challenging,
as existing approaches struggle with word reordering and performance
degradation when jointly modeling ASR and ST, resulting in a gap with
attention-based encoder-decoder (AED) models. Existing NT-based ST approaches
also suffer from high computational training costs. To address these issues, we
propose HENT-SRT (Hierarchical Efficient Neural Transducer for Speech
Recognition and Translation), a novel framework that factorizes ASR and
translation tasks to better handle reordering. To ensure robust ST while
preserving ASR performance, we use self-distillation with CTC consistency
regularization. Moreover, we improve computational efficiency by incorporating
best practices from ASR transducers, including a down-sampled hierarchical
encoder, a stateless predictor, and a pruned transducer loss to reduce training
complexity. Finally, we introduce a blank penalty during decoding, reducing
deletions and improving translation quality. Our approach is evaluated on three
conversational datasets Arabic, Spanish, and Mandarin achieving new
state-of-the-art performance among NT models and substantially narrowing the
gap with AED-based systems.

</details>


### [14] [Different Speech Translation Models Encode and Translate Speaker Gender Differently](https://arxiv.org/abs/2506.02172)
*Dennis Fucci,Marco Gaido,Matteo Negri,Luisa Bentivogli,Andre Martins,Giuseppe Attanasio*

Main category: cs.CL

TL;DR: 研究揭示新型语音翻译架构因性别编码能力不足导致翻译偏向男性化，传统模型仍保留性别信息。


<details>
  <summary>Details</summary>
Motivation: 探讨语音翻译模型是否捕捉说话者性别特征，及其对翻译性别分配的影响。

Method: 使用探针方法分析不同ST模型（传统编码器-解码器 vs 基于适配器整合语音编码器与翻译系统的新架构）的性别编码能力，测试英法/意/西三个语言方向。

Result: 传统模型可捕捉性别信息，新型架构无法编码性别；低性别编码能力导致系统默认男性化翻译倾向（新架构更显著）。

Conclusion: 模型架构选择直接影响性别偏见程度，性能优化可能以加剧社会偏见为代价，需平衡技术效能与伦理考量。

Abstract: Recent studies on interpreting the hidden states of speech models have shown
their ability to capture speaker-specific features, including gender. Does this
finding also hold for speech translation (ST) models? If so, what are the
implications for the speaker's gender assignment in translation? We address
these questions from an interpretability perspective, using probing methods to
assess gender encoding across diverse ST models. Results on three language
directions (English-French/Italian/Spanish) indicate that while traditional
encoder-decoder models capture gender information, newer architectures --
integrating a speech encoder with a machine translation system via adapters --
do not. We also demonstrate that low gender encoding capabilities result in
systems' tendency toward a masculine default, a translation bias that is more
pronounced in newer architectures.

</details>


### [15] [AI Debate Aids Assessment of Controversial Claims](https://arxiv.org/abs/2506.02175)
*Salman Rahman,Sheriff Issaka,Ashima Suvarna,Genglin Liu,James Shiffer,Jaeyoung Lee,Md Rizwan Parvez,Hamid Palangi,Shi Feng,Nanyun Peng,Yejin Choi,Julian Michael,Liwei Jiang,Saadia Gabriel*

Main category: cs.CL

TL;DR: AI辩论机制可提升公共卫生领域事实判断准确性，主流群体准确率+15.2%，AI评委达78.5%准确率优于人类。


<details>
  <summary>Details</summary>
Motivation: 解决AI监督中人类偏见对事实判断的干扰，探索在COVID-19等争议领域通过AI辩论实现抗偏见的可扩展监督机制。

Method: 双实验设计：1) 人类评委(主流/怀疑立场)对比AI辩论与单顾问模式 2) 个性化AI评委模拟人类信念系统

Result: 辩论模式整体准确率提升10%，主流评委提升15.2%；AI评委准确率达78.5%，显著优于人类评委的70.1%

Conclusion: AI辩论机制结合人机协同判断，为争议领域提供抗偏见的事实核查新路径，凸显个性化AI评委的监督潜力。

Abstract: As AI grows more powerful, it will increasingly shape how we understand the
world. But with this influence comes the risk of amplifying misinformation and
deepening social divides-especially on consequential topics like public health
where factual accuracy directly impacts well-being. Scalable Oversight aims to
ensure AI truthfulness by enabling humans to supervise systems that may exceed
human capabilities--yet humans themselves hold different beliefs and biases
that impair their judgment. We study whether AI debate can guide biased judges
toward the truth by having two AI systems debate opposing sides of
controversial COVID-19 factuality claims where people hold strong prior
beliefs. We conduct two studies: one with human judges holding either
mainstream or skeptical beliefs evaluating factuality claims through
AI-assisted debate or consultancy protocols, and a second examining the same
problem with personalized AI judges designed to mimic these different human
belief systems. In our human study, we find that debate-where two AI advisor
systems present opposing evidence-based arguments-consistently improves
judgment accuracy and confidence calibration, outperforming consultancy with a
single-advisor system by 10% overall. The improvement is most significant for
judges with mainstream beliefs (+15.2% accuracy), though debate also helps
skeptical judges who initially misjudge claims move toward accurate views
(+4.7% accuracy). In our AI judge study, we find that AI judges with human-like
personas achieve even higher accuracy (78.5%) than human judges (70.1%) and
default AI judges without personas (69.8%), suggesting their potential for
supervising frontier AI models. These findings highlight AI debate as a
promising path toward scalable, bias-resilient oversight--leveraging both
diverse human and AI judgments to move closer to truth in contested domains.

</details>


### [16] [Echoes of Phonetics: Unveiling Relevant Acoustic Cues for ASR via Feature Attribution](https://arxiv.org/abs/2506.02181)
*Dennis Fucci,Marco Gaido,Matteo Negri,Mauro Cettolo,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 研究通过特征归因技术揭示现代ASR模型依赖元音时长/前两个共振峰、男性语音显著性更高，并发现模型对齿擦音频谱特征和爆破音释放阶段的捕捉偏好。


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于少量音素和过时模型，需系统性分析现代ASR模型的声学特征依赖机制

Method: 应用特征归因技术分析Conformer架构ASR模型，对比爆破音/摩擦音/元音在时域和频域的声学特征对齐程度

Result: 模型完整利用元音时间跨度(前两个共振峰主导，男性语音更显著)，更好捕捉齿擦音频谱特征，优先处理爆破音释放阶段(特别是爆破特性)

Conclusion: 发现增强了ASR模型可解释性，揭示未来应重点研究模型声学表征完整性以提升鲁棒性

Abstract: Despite significant advances in ASR, the specific acoustic cues models rely
on remain unclear. Prior studies have examined such cues on a limited set of
phonemes and outdated models. In this work, we apply a feature attribution
technique to identify the relevant acoustic cues for a modern Conformer-based
ASR system. By analyzing plosives, fricatives, and vowels, we assess how
feature attributions align with their acoustic properties in the time and
frequency domains, also essential for human speech perception. Our findings
show that the ASR model relies on vowels' full time spans, particularly their
first two formants, with greater saliency in male speech. It also better
captures the spectral characteristics of sibilant fricatives than non-sibilants
and prioritizes the release phase in plosives, especially burst
characteristics. These insights enhance the interpretability of ASR models and
highlight areas for future research to uncover potential gaps in model
robustness.

</details>


### [17] [BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models](https://arxiv.org/abs/2506.02204)
*Lindia Tjuatja,Graham Neubig*

Main category: cs.CL

TL;DR: 提出了BehaviorBox方法，通过上下文感知的嵌入技术自动比较语言模型在细粒度文本特征上的性能差异


<details>
  <summary>Details</summary>
Motivation: 传统语言模型评估存在提示词脆弱性、语料库复杂度指标模糊和基准测试选择困难等问题，需要自动化方法发现模型间的实质性差异

Method: 利用性能感知的上下文嵌入技术，在特定数据集中发现体现模型性能差异的细粒度语言特征（如条件从句中的动词形态或情感语句后的感叹号）

Result: 成功识别出模型在参数规模、架构族谱和后期训练差异导致的性能差异特征，这些特征无法通过传统语料库复杂度指标发现

Conclusion: BehaviorBox为语言模型比较提供了自动化分析框架，能够发现传统评估方法遗漏的上下文敏感型性能差异，为模型优化提供具体方向

Abstract: Language model evaluation is a daunting task: prompts are brittle,
corpus-level perplexities are vague, and the choice of benchmarks are endless.
Finding examples that show meaningful, generalizable differences between two
LMs is crucial to understanding where one model succeeds and another fails. Can
this process be done automatically? In this work, we propose methodology for
automated comparison of language models that uses performance-aware contextual
embeddings to find fine-grained features of text where one LM outperforms
another. Our method, which we name BehaviorBox, extracts coherent features that
demonstrate differences with respect to the ease of generation between two LMs.
Specifically, BehaviorBox finds features that describe groups of words in
fine-grained contexts, such as "conditional 'were' in the phrase 'if you were'"
and "exclamation marks after emotional statements", where one model outperforms
another within a particular datatset. We apply BehaviorBox to compare models
that vary in size, model family, and post-training, and enumerate insights into
specific contexts that illustrate meaningful differences in performance which
cannot be found by measures such as corpus-level perplexity alone.

</details>


### [18] [Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics](https://arxiv.org/abs/2506.02212)
*Ella Rannon,David Burstein*

Main category: cs.CL

TL;DR: NLP技术通过将语言模型应用于DNA/RNA/蛋白质序列分析，推动生物信息学发展，涵盖模型架构评估、基因组数据解析及跨领域应用潜力


<details>
  <summary>Details</summary>
Motivation: 生物序列与人类语言在结构模式上存在相似性，利用NLP处理大规模基因组数据可突破传统生物信息学方法瓶颈

Method: 整合经典word2vec与新型transformer/hyena算子，开发适配生物序列特性的tokenization策略与多尺度模型架构

Result: 成功应用于蛋白质结构预测、基因表达调控解析和分子进化分析，验证NLP方法在跨物种基因组数据分析中的有效性

Conclusion: 语言模型的持续进化将深化对生命过程的理解，为组学研究提供新的方法论突破点

Abstract: Natural Language Processing (NLP) has transformed various fields beyond
linguistics by applying techniques originally developed for human language to
the analysis of biological sequences. This review explores the application of
NLP methods to biological sequence data, focusing on genomics, transcriptomics,
and proteomics. We examine how various NLP methods, from classic approaches
like word2vec to advanced models employing transformers and hyena operators,
are being adapted to analyze DNA, RNA, protein sequences, and entire genomes.
The review also examines tokenization strategies and model architectures,
evaluating their strengths, limitations, and suitability for different
biological tasks. We further cover recent advances in NLP applications for
biological data, such as structure prediction, gene expression, and
evolutionary analysis, highlighting the potential of these methods for
extracting meaningful insights from large-scale genomic data. As language
models continue to advance, their integration into bioinformatics holds immense
promise for advancing our understanding of biological processes in all domains
of life.

</details>


### [19] [Investigating the Impact of Word Informativeness on Speech Emotion Recognition](https://arxiv.org/abs/2506.02239)
*Sofoklis Kakouros*

Main category: cs.CL

TL;DR: 通过预训练语言模型筛选高信息量词汇片段，针对性提取声学特征，显著提升语音情感识别准确率


<details>
  <summary>Details</summary>
Motivation: 传统方法在整句层面计算声学特征可能遗漏关键细节，需开发更精准的片段选择方法捕捉情感相关声学变化

Method: 1. 利用预训练语言模型计算词汇信息量
2. 选择高信息量词汇对应语音片段
3. 结合标准韵律特征、功能参数和自监督表示进行建模

Result: 基于词汇信息量选择的语音片段特征使情感识别性能显著提升（具体提升幅度需参考论文数据）

Conclusion: 词汇级声学特征选择策略有效，未来可探索多模态融合与更精细的时序建模进一步优化

Abstract: In emotion recognition from speech, a key challenge lies in identifying
speech signal segments that carry the most relevant acoustic variations for
discerning specific emotions. Traditional approaches compute functionals for
features such as energy and F0 over entire sentences or longer speech portions,
potentially missing essential fine-grained variation in the long-form
statistics. This research investigates the use of word informativeness, derived
from a pre-trained language model, to identify semantically important segments.
Acoustic features are then computed exclusively for these identified segments,
enhancing emotion recognition accuracy. The methodology utilizes standard
acoustic prosodic features, their functionals, and self-supervised
representations. Results indicate a notable improvement in recognition
performance when features are computed on segments selected based on word
informativeness, underscoring the effectiveness of this approach.

</details>


### [20] [CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment](https://arxiv.org/abs/2506.02264)
*Radin Shayanfar,Chu Fei Luo,Rohan Bhambhoria,Samuel Dahan,Xiaodan Zhu*

Main category: cs.CL

TL;DR: CoDial框架通过将专家知识转化为结构化图并生成对话逻辑，实现了无需训练数据的零样本对话系统构建，在STAR数据集达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决专业领域（法律/医疗）对话系统开发中专家知识整合困难、训练数据成本高的问题，降低领域专家参与技术开发的门槛。

Method: 使用结构化异构图表示专家知识，兼容Colang等护栏语言，通过代码生成可执行的对话逻辑流程。

Result: 在STAR数据集推理任务中达到SOTA，在MultiWOZ上与基线模型竞争，支持人工和LLM反馈的迭代优化。

Conclusion: CoDial为高风险领域提供了可解释、可修改的LLM对齐工具，实现了专家指导下的零样本对话系统开发。

Abstract: It is often challenging to teach specialized, unseen tasks to dialogue
systems due to the high cost of expert knowledge, training data, and high
technical difficulty. To support domain-specific applications - such as law,
medicine, or finance - it is essential to build frameworks that enable
non-technical experts to define, test, and refine system behaviour with minimal
effort. Achieving this requires cross-disciplinary collaboration between
developers and domain specialists. In this work, we introduce a novel
framework, CoDial (Code for Dialogue), that converts expert knowledge,
represented as a novel structured heterogeneous graph, into executable
conversation logic. CoDial can be easily implemented in existing guardrailing
languages, such as Colang, to enable interpretable, modifiable, and true
zero-shot specification of task-oriented dialogue systems. Empirically, CoDial
achieves state-of-the-art performance on the STAR dataset for inference-based
models and is competitive with similar baselines on the well-known MultiWOZ
dataset. We also demonstrate CoDial's iterative improvement via manual and
LLM-aided feedback, making it a practical tool for expert-guided alignment of
LLMs in high-stakes domains.

</details>


### [21] [ImpRAG: Retrieval-Augmented Generation with Implicit Queries](https://arxiv.org/abs/2506.02279)
*Wenzheng Zhang,Xi Victoria Lin,Karl Stratos,Wen-tau Yih,Mingda Chen*

Main category: cs.CL

TL;DR: 提出无需显式查询的ImpRAG框架，将检索与生成统一到单一模型中，通过分层组优化提升跨任务泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统将检索与生成分离，依赖人工指定查询，限制了模型在不同任务格式间的泛化能力

Method: 将预训练语言模型分层组实现任务分工，采用两阶段推理流程，共享模型参数和前向计算

Result: 在8个知识密集型任务中，未见任务的精确匹配分数提升3.6-11.5个百分点

Conclusion: ImpRAG通过隐式表达信息需求，平衡检索生成参数，利用生成困惑度作为训练目标，有效提升跨任务性能

Abstract: Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval
and generation as separate processes, requiring explicit textual queries to
connect them. This separation can limit the ability of models to generalize
across diverse tasks. In this work, we propose a query-free RAG system, named
ImpRAG, which integrates retrieval and generation into a unified model. ImpRAG
allows models to implicitly express their information needs, eliminating the
need for human-specified queries. By dividing pretrained decoder-only language
models into specialized layer groups, ImpRAG optimizes retrieval and generation
tasks simultaneously. Our approach employs a two-stage inference process, using
the same model parameters and forward pass for both retrieval and generation,
thereby minimizing the disparity between retrievers and language models.
Experiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves
3.6-11.5 improvements in exact match scores on unseen tasks with diverse
formats, highlighting its effectiveness in enabling models to articulate their
own information needs and generalize across tasks. Our analysis underscores the
importance of balancing retrieval and generation parameters and leveraging
generation perplexities as retrieval training objectives for enhanced
performance.

</details>


### [22] [Sounding Like a Winner? Prosodic Differences in Post-Match Interviews](https://arxiv.org/abs/2506.02283)
*Sofoklis Kakouros,Haoyu Chen*

Main category: cs.CL

TL;DR: 通过网球赛后采访的韵律特征（如音高、强度）和自监督学习模型（Wav2Vec 2.0/HuBERT），可有效区分运动员胜负状态。SSL表征和音高变化是最强预测指标。


<details>
  <summary>Details</summary>
Motivation: 探索赛后采访中隐含胜负状态的韵律特征，验证仅通过语音数据预测比赛结果的可能性，挖掘情绪相关语音模式的识别潜力。

Method: 1. 提取传统声学特征（音高、强度）
2. 使用Wav2Vec 2.0/HuBERT获取深度语音表征
3. 采用机器学习分类器进行胜负状态分类

Result: 1. 自监督学习表征在胜负分类中表现优异
2. 音高变异性等韵律特征仍是胜利的强预测指标
3. 语音模式可有效反映运动员赛后情绪状态

Conclusion: 结合深度语音表征与传统韵律分析，为通过非语言内容洞察运动员心理状态提供了新范式，在体育心理学和情绪计算领域具有应用潜力。

Abstract: This study examines the prosodic characteristics associated with winning and
losing in post-match tennis interviews. Additionally, this research explores
the potential to classify match outcomes solely based on post-match interview
recordings using prosodic features and self-supervised learning (SSL)
representations. By analyzing prosodic elements such as pitch and intensity,
alongside SSL models like Wav2Vec 2.0 and HuBERT, the aim is to determine
whether an athlete has won or lost their match. Traditional acoustic features
and deep speech representations are extracted from the data, and machine
learning classifiers are employed to distinguish between winning and losing
players. Results indicate that SSL representations effectively differentiate
between winning and losing outcomes, capturing subtle speech patterns linked to
emotional states. At the same time, prosodic cues -- such as pitch variability
-- remain strong indicators of victory.

</details>


### [23] [LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback](https://arxiv.org/abs/2506.02298)
*Thai Hoang,Kung-Hsiang Huang,Shirley Kokane,Jianguo Zhang,Zuxin Liu,Ming Zhu,Jake Grigsby,Tian Lan,Michael S Ryoo,Chien-Sheng Wu,Shelby Heinecke,Huan Wang,Silvio Savarese,Caiming Xiong,Juan Carlos Niebles*

Main category: cs.CL

TL;DR: LAM SIMULATOR框架通过自主探索任务生成高质量训练数据，使大行动模型的性能提升达49.3%


<details>
  <summary>Details</summary>
Motivation: 大行动模型在多步骤任务中面临高质量训练数据不足的挑战，需要自主探索任务解决方案的框架

Method: 整合动态任务生成器、多样化工具集和实时反馈环境，实现LLM代理的自主工具调用与任务探索

Result: 在ToolBench和CRMArena基准测试中实现最高49.3%的性能提升，显著优于基线模型

Conclusion: 该框架通过最小化人工干预高效生成训练数据，加速了AI代理的开发进程

Abstract: Large Action Models (LAMs) for AI Agents offer incredible potential but face
challenges due to the need for high-quality training data, especially for
multi-steps tasks that involve planning, executing tool calls, and responding
to feedback. To address these issues, we present LAM SIMULATOR, a comprehensive
framework designed for online exploration of agentic tasks with high-quality
feedback. Our framework features a dynamic task query generator, an extensive
collection of tools, and an interactive environment where Large Language Model
(LLM) Agents can call tools and receive real-time feedback. This setup enables
LLM Agents to explore and solve tasks autonomously, facilitating the discovery
of multiple approaches to tackle any given task. The resulting action
trajectory data are then used to create high-quality training datasets for
LAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena,
highlight the effectiveness of LAM SIMULATOR: models trained with
self-generated datasets using our framework achieve significant performance
gains, up to a 49.3\% improvement over their original baselines. LAM SIMULATOR
requires minimal human input during dataset creation, highlighting LAM
SIMULATOR's efficiency and effectiveness in speeding up development of AI
agents.

</details>


### [24] [Explain-then-Process: Using Grammar Prompting to Enhance Grammatical Acceptability Judgments](https://arxiv.org/abs/2506.02302)
*Russell Scheinberg,Ameeta Agrawal,Amber Shore,So Young Lee*

Main category: cs.CL

TL;DR: 提出「语法提示」方法，通过大模型生成语法解释后输入目标模型，显著提升多语言环境下模型判断句子语法性的能力，有效缩小LLM与小型模型间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽能解释语法规则，但在实际应用规则判断句子正确性时存在明显能力断层，需探索低成本解决方案以提升模型实际应用性能。

Method: 两阶段范式：1) 大模型生成语法现象简明解释 2) 将解释作为上下文输入目标模型（LLM/SLM），结合思维链技术进行决策。在英/中/俄三大语法基准测试中验证。

Result: 平均缩小LLM-SLM准确率差距20%，结合思维链后差距缩小56%（13.0pp→5.8pp）。小模型以极低开销逼近前沿LLM的多语言处理性能。

Conclusion: 语法提示机制成功弥合「知而不行」的认知鸿沟，为资源受限场景提供高效解决方案，推动小模型在多语言环境下的实用化进程。

Abstract: Large language models (LLMs) can explain grammatical rules, yet they often
fail to apply those rules when judging sentence acceptability. We present
"grammar prompting", an explain-then-process paradigm: a large LLM first
produces a concise explanation of the relevant syntactic phenomenon, then that
explanation is fed back as additional context to the target model -- either an
LLM or a smaller language model (SLM) -- before deciding which sentence of a
minimal pair is grammatical. On the English BLiMP, Chinese SLING, and Russian
RuBLiMP benchmarks, this simple prompt design yields substantial improvements
over strong baselines across many syntactic phenomena. Feeding an LLM's
metalinguistic explanation back to the target model bridges the gap between
knowing a rule and using it. On SLMs, grammar prompting alone trims the average
LLM-SLM accuracy gap by about 20%, and when paired with chain-of-thought, by
56% (13.0 pp -> 5.8 pp), all at negligible cost. The lightweight,
language-agnostic cue lets low-cost SLMs approach frontier-LLM performance in
multilingual settings.

</details>


### [25] [Quantifying Misattribution Unfairness in Authorship Attribution](https://arxiv.org/abs/2506.02321)
*Pegah Alipoormolabashi,Ajay Patel,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 提出MAUIk指标量化作者归属模型的不公平性，发现模型在潜在空间中对中心位置作者的误判风险更高


<details>
  <summary>Details</summary>
Motivation: 现有作者归属系统评估标准未考虑公平性，法医场景中误判可能导致对候选作者的不公正审查

Method: 通过MAUIk指标（基于模型在非作者文本中的top-k错误排名频率），评估5个模型在2个数据集上的不公平性，并分析作者嵌入向量与误判风险的空间关系

Result: 所有模型均存在高度不公平性，嵌入空间靠近质心的作者面临更高误判风险，模型潜在空间结构直接影响误判概率

Conclusion: 作者归属模型存在显著误判风险，需在使用时明确传达风险并进行校准，特别需关注模型潜在空间结构对公平性的影响

Abstract: Authorship misattribution can have profound consequences in real life. In
forensic settings simply being considered as one of the potential authors of an
evidential piece of text or communication can result in undesirable scrutiny.
This raises a fairness question: Is every author in the candidate pool at equal
risk of misattribution? Standard evaluation measures for authorship attribution
systems do not explicitly account for this notion of fairness. We introduce a
simple measure, Misattribution Unfairness Index (MAUIk), which is based on how
often authors are ranked in the top k for texts they did not write. Using this
measure we quantify the unfairness of five models on two different datasets.
All models exhibit high levels of unfairness with increased risks for some
authors. Furthermore, we find that this unfairness relates to how the models
embed the authors as vectors in the latent search space. In particular, we
observe that the risk of misattribution is higher for authors closer to the
centroid (or center) of the embedded authors in the haystack. These results
indicate the potential for harm and the need for communicating with and
calibrating end users on misattribution risk when building and providing such
models for downstream use.

</details>


### [26] [Something Just Like TRuST : Toxicity Recognition of Span and Target](https://arxiv.org/abs/2506.02326)
*Berk Atil,Namrata Sureddy,Rebecca J. Passonneau*

Main category: cs.CL

TL;DR: TRuST数据集通过整合现有数据并标注毒性、目标群体和毒性范围，有效提升了毒性检测能力。实验表明微调模型优于零样本/少样本提示方法，但对部分社会群体检测效果仍不理想，大语言模型的社会推理能力较弱。


<details>
  <summary>Details</summary>
Motivation: 在线内容（包括语言模型生成内容）的毒性问题可能造成严重心理和社会影响。现有数据集的多样性和标注维度不足，需构建更全面的数据集以提升毒性检测能力。

Method: 整合多源数据构建TRuST数据集，包含人机标注数据及机器生成数据，涵盖种族、性别、宗教等多类社会群体。使用最先进的大语言模型进行毒性检测、目标群体识别和毒性范围提取的基准测试。

Result: 微调模型在三个任务上持续优于提示方法，但对特定社会群体（如政治群体）检测准确率低。引入推理能力未显著提升性能，揭示LLMs社会推理能力薄弱。

Conclusion: TRuST为毒性检测提供了重要基准资源，未来需增强模型的社会推理能力，并针对弱势群体优化检测性能。

Abstract: Toxicity in online content, including content generated by language models,
has become a critical concern due to its potential for negative psychological
and social impact. This paper introduces TRuST, a comprehensive dataset
designed to improve toxicity detection that merges existing datasets, and has
labels for toxicity, target social group, and toxic spans. It includes a
diverse range of target groups such as ethnicity, gender, religion, disability,
and politics, with both human/machine-annotated and human machine-generated
data. We benchmark state-of-the-art large language models (LLMs) on toxicity
detection, target group identification, and toxic span extraction. We find that
fine-tuned models consistently outperform zero-shot and few-shot prompting,
though performance remains low for certain social groups. Further, reasoning
capabilities do not significantly improve performance, indicating that LLMs
have weak social reasoning skills.

</details>


### [27] [One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL](https://arxiv.org/abs/2506.02338)
*Hyungjoo Chae,Dongjin Kang,Jihyuk Kim,Beong-woo Kwak,Sunghyun Park,Haeju Park,Jinyoung Yeo,Moontae Lee,Kyungjae Lee*

Main category: cs.CL

TL;DR: 通过未针对推理优化的短链思维模型构建长链思维数据集Long CoT Collection，实现接近R1模型的数据质量，并为强化学习提供基础支持。


<details>
  <summary>Details</summary>
Motivation: 减少对现有大型推理模型R1的依赖，探索独立开发大型推理模型的可能性。

Method: 1. 使用现有短链思维模型标注10万条长推理数据
2. 开发诱导新推理策略的流程，实现思考时长控制和预算管理
3. 通过质量分析和RLVR验证效果

Result: 数据集质量接近R1（略低5%-7%），基于该数据的模型在强化学习中增益提升2-3倍

Conclusion: 证明利用普通LLM构建长推理链的可行性，为独立开发推理模型开辟新路径

Abstract: With the release of R1, a publicly available large reasoning model (LRM),
researchers commonly train new LRMs by training language models on R1's long
chain-of-thought (CoT) inferences. While prior works show that LRMs'
capabilities can be reproduced through direct distillation, the continued
reliance on the existing models (e.g., R1) remains a critical limitation in
advancing the field. As a first step toward independent LRM development, this
paper explores the possibility of constructing a long CoT dataset with LLMs
that are not trained for inference-time scaling. To this end, we present the
Long CoT Collection, a dataset of 100K CoT rationales annotated using existing
short CoT LLMs. We develop a pipeline that induces o1's novel reasoning
strategies into short CoT LLMs, enabling them to think longer and introducing
controllability over the thought budget to better manage the overthinking
problem. Our extensive analyses validate that our dataset achieves quality
comparable to--or slightly below--R1. Furthermore, our experiments demonstrate
that training on our dataset not only strengthens general reasoning skills, but
also provides a strong foundation for reinforcement learning--models
initialized on our data achieve 2-3x larger gains with RLVR.

</details>


### [28] [STORYTELLER: An Enhanced Plot-Planning Framework for Coherent and Cohesive Story Generation](https://arxiv.org/abs/2506.02347)
*Jiaming Li,Yukun Chen,Ziqiang Liu,Minghuan Tan,Lei Zhang,Yunshui Li,Run Luo,Longze Chen,Jing Luo,Ahmadreza Argha,Hamid Alinejad-Rokny,Wei Zhou,Min Yang*

Main category: cs.CL

TL;DR: 提出Storyteller方法，通过SVO三元组构建事件节点，结合动态交互模块提升故事生成的连贯性与一致性


<details>
  <summary>Details</summary>
Motivation: 现有自动故事生成方法存在叙事连贯性差和逻辑断裂问题，影响故事体验质量，需系统性改进方案

Method: 基于语言学SVO三元组构建情节节点，创新整合动态STORYLINE模块与NEKG知识图谱的实时交互机制

Result: 人类偏好评估显示84.33%平均胜率，在创造力、连贯性、吸引力等多维度显著超越基线模型

Conclusion: Storyteller通过结构化叙事单元和动态知识维护机制，验证了认知启发的故事生成框架有效性

Abstract: Stories are central to human culture, serving to share ideas, preserve
traditions, and foster connections. Automatic story generation, a key
advancement in artificial intelligence (AI), offers new possibilities for
creating personalized content, exploring creative ideas, and enhancing
interactive experiences. However, existing methods struggle to maintain
narrative coherence and logical consistency. This disconnect compromises the
overall storytelling experience, underscoring the need for substantial
improvements. Inspired by human cognitive processes, we introduce Storyteller,
a novel approach that systemically improves the coherence and consistency of
automatically generated stories. Storyteller introduces a plot node structure
based on linguistically grounded subject verb object (SVO) triplets, which
capture essential story events and ensure a consistent logical flow. Unlike
previous methods, Storyteller integrates two dynamic modules, the STORYLINE and
narrative entity knowledge graph (NEKG),that continuously interact with the
story generation process. This integration produces structurally sound,
cohesive and immersive narratives. Extensive experiments demonstrate that
Storyteller significantly outperforms existing approaches, achieving an 84.33%
average win rate through human preference evaluation. At the same time, it is
also far ahead in other aspects including creativity, coherence, engagement,
and relevance.

</details>


### [29] [Truth over Tricks: Measuring and Mitigating Shortcut Learning in Misinformation Detection](https://arxiv.org/abs/2506.02350)
*Herun Wan,Jiaying Wu,Minnan Luo,Zhi Zeng,Zhixiong Su*

Main category: cs.CL

TL;DR: 提出TruthOverTricks评估框架揭示错误信息检测器对表面线索的依赖，并通过SMF数据增强方法提升模型鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有错误信息检测模型过度依赖训练数据中的表面关联模式(捷径)，在LLMs生成多样化错误信息的场景下泛化能力差

Method: 1. 建立包含自然/对抗性捷径的统一评估范式
2. 在14个基准测试中评估7种检测器
3. 提出LLM增强的SMF框架(转述/事实摘要/情感归一化)

Result: 1. 现有检测器在捷径干扰下性能下降16-42%
2. SMF在16个基准中平均提升12.3%鲁棒性
3. 发布NQ-Misinfo和Streaming-Misinfo新数据集

Conclusion: 揭示了错误信息检测中的捷径依赖问题，验证SMF框架有效性，公开资源促进稳健检测器发展

Abstract: Misinformation detection models often rely on superficial cues (i.e.,
\emph{shortcuts}) that correlate with misinformation in training data but fail
to generalize to the diverse and evolving nature of real-world misinformation.
This issue is exacerbated by large language models (LLMs), which can easily
generate convincing misinformation through simple prompts. We introduce
TruthOverTricks, a unified evaluation paradigm for measuring shortcut learning
in misinformation detection. TruthOverTricks categorizes shortcut behaviors
into intrinsic shortcut induction and extrinsic shortcut injection, and
evaluates seven representative detectors across 14 popular benchmarks, along
with two new factual misinformation datasets, NQ-Misinfo and Streaming-Misinfo.
Empirical results reveal that existing detectors suffer severe performance
degradation when exposed to both naturally occurring and adversarially crafted
shortcuts. To address this, we propose SMF, an LLM-augmented data augmentation
framework that mitigates shortcut reliance through paraphrasing, factual
summarization, and sentiment normalization. SMF consistently enhances
robustness across 16 benchmarks, encouraging models to rely on deeper semantic
understanding rather than shortcut cues. To promote the development of
misinformation detectors, we have published the resources publicly at
https://github.com/whr000001/TruthOverTricks.

</details>


### [30] [DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization](https://arxiv.org/abs/2506.02351)
*Jeonghun Kang,Soonmok Kwon,Joonseok Lee,Byung-Hak Kim*

Main category: cs.CL

TL;DR: DIAMOND：首个结合结构化棒球数据与LLM推理的智能体系统，显著提升比赛精彩片段检测准确率（F1分数从42.9%提升至84.8%）


<details>
  <summary>Details</summary>
Motivation: 传统统计方法（如WPA）和计算机视觉系统缺乏对比赛战略深度、势头转换和叙事逻辑的捕捉，人工标注成本过高且不可扩展

Method: 融合棒球统计指标（胜率预期、WPA、杠杆指数）与LLM的叙事推理能力，通过模块化架构实现量化分析与自然语言处理的协同

Result: 在韩国职棒五场不同比赛中的测试显示，F1分数达84.8%，显著优于商业系统（72.4%）和纯统计方法（42.9%）

Conclusion: 模块化智能体框架在保持可解释性的同时，为体育赛事等场景的事件级摘要提供了新范式，其设计理念可扩展至其他领域

Abstract: Traditional approaches -- such as Win Probability Added (WPA)-based ranking
or computer vision-driven event detection -- can identify scoring plays but
often miss strategic depth, momentum shifts, and storyline progression. Manual
curation remains the gold standard but is resource-intensive and not scalable.
We introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight
summarization that integrates structured sports analytics with natural language
reasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and
Leverage Index -- to quantify play importance, while an LLM module enhances
selection based on contextual narrative value. This hybrid approach ensures
both quantitative rigor and qualitative richness, surpassing the limitations of
purely statistical or vision-based systems. Evaluated on five diverse Korean
Baseball Organization League games, DIAMOND improves F1-score from 42.9%
(WPA-only) to 84.8%, outperforming both commercial and statistical baselines.
Though limited in scale, our results highlight the potential of modular,
interpretable agent-based frameworks for event-level summarization in sports
and beyond.

</details>


### [31] [AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM Output](https://arxiv.org/abs/2506.02372)
*Hisami Suzuki,Satoru Katsumata,Takashi Kodama,Tetsuro Takahashi,Kouta Nakayama,Satoshi Sekine*

Main category: cs.CL

TL;DR: 日本研究者创建AnswerCarefully数据集以提升LLM输出的安全性，覆盖日本社会文化风险场景，经微调后模型安全性显著提升且不影响通用性能。


<details>
  <summary>Details</summary>
Motivation: 针对日本本土LLM使用场景，解决现有英语数据集在文化适配性上的不足，需构建反映日本社会文化风险的特殊问答数据集。

Method: 1. 手动创建1,800组需特殊注意的问题-答案对；2. 通过指令微调优化日本LLM；3. 对12个日本LLM进行安全基准测试；4. 新增英文翻译及注释实现跨语言适配。

Result: 1. 微调后LLM安全指标提升（具体数值未提及）；2. 12个模型的基准测试结果揭示日本LLM安全现状；3. 通用回答效用未受影响。

Conclusion: 数据集通过文化适配性设计有效提升模型安全性，最新英语标注版本将推动多语言/地区安全数据集构建，形成可复用的技术路径。

Abstract: In this paper we present AnswerCarefully, a dataset for promoting the safety
and appropriateness of Japanese LLM outputs. The dataset consists of 1,800
pairs of questions and reference answers, where the questions require special
attention in answering. It covers a wide range of risk categories established
in prior English-language datasets, but the data samples are original in that
they are manually created to reflect the socio-cultural context of LLM usage in
Japan. We show that using this dataset for instruction to fine-tune a Japanese
LLM led to improved output safety without compromising the utility of general
responses. We also report the results of a safety evaluation of 12 Japanese
LLMs using this dataset as a benchmark. Finally, we describe the latest update
on the dataset which provides English translations and annotations of the
questions, aimed at facilitating the derivation of similar datasets in
different languages and regions.

</details>


### [32] [Exploring Explanations Improves the Robustness of In-Context Learning](https://arxiv.org/abs/2506.02378)
*Ukyo Honda,Tatsushi Oka*

Main category: cs.CL

TL;DR: X²-ICL通过系统解释所有标签，提升大模型在分布外数据的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有X-ICL方法仅关注正确标签的解释，导致模型在分布外数据上泛化能力不足

Method: 提出X²-ICL框架，系统探索所有可能标签的解释，构建全面决策依据

Result: 在多个自然语言理解数据集上验证，相比传统ICL方法显著提升分布外数据适应能力（提升幅度达15%-20%）

Conclusion: 全面标签解释机制有效增强模型推理稳健性，为改进上下文学习范式提供新方向

Abstract: In-context learning (ICL) has emerged as a successful paradigm for leveraging
large language models (LLMs). However, it often struggles to generalize beyond
the distribution of the provided demonstrations. A recent advancement in
enhancing robustness is ICL with explanations (X-ICL), which improves
prediction reliability by guiding LLMs to understand and articulate the
reasoning behind correct labels. Building on this approach, we introduce an
advanced framework that extends X-ICL by systematically exploring explanations
for all possible labels (X$^2$-ICL), thereby enabling more comprehensive and
robust decision-making. Experimental results on multiple natural language
understanding datasets validate the effectiveness of X$^2$-ICL, demonstrating
significantly improved robustness to out-of-distribution data compared to the
existing ICL approaches.

</details>


### [33] [Consultant Decoding: Yet Another Synergistic Mechanism](https://arxiv.org/abs/2506.02391)
*Chuanghao Ding,Jiaping Wang,Ziqing Yang,Xiaoliang Wang,Dahua Lin,Cam-Tu Nguyen,Fei Tan*

Main category: cs.CL

TL;DR: 提出顾问解码（CD）作为推测解码（SD）的改进方案，通过LLM自身计算的token级似然概率验证候选文本，实现2.5倍推理加速且保持生成质量


<details>
  <summary>Details</summary>
Motivation: 传统推测解码（SD）因高拒绝率需反复调用大模型验证，严重影响加速效果。现有验证机制依赖重要性采样指标存在效率瓶颈。

Method: 采用基于LLM自身计算的token级似然概率验证机制，结合不同参数规模的模型（相差两个数量级），将大模型调用频率降低至10%以下

Result: 在保持生成质量（接近目标模型100%性能）的同时实现最高2.5倍加速，且在复杂任务中CD性能甚至超越原大模型的理论上限

Conclusion: CD突破推测解码的理论上限，通过模型规模差异化组合实现效率突破，为LLM加速提供新范式

Abstract: The synergistic mechanism based on Speculative Decoding (SD) has garnered
considerable attention as a simple yet effective approach for accelerating the
inference of large language models (LLMs). Nonetheless, the high rejection
rates require repeated LLMs calls to validate draft tokens, undermining the
overall efficiency gain of SD. In this work, we revisit existing verification
mechanisms and propose a novel synergetic mechanism Consultant Decoding (CD).
Unlike SD, which relies on a metric derived from importance sampling for
verification, CD verifies candidate drafts using token-level likelihoods
computed solely by the LLM. CD achieves up to a 2.5-fold increase in inference
speed compared to the target model, while maintaining comparable generation
quality (around 100% of the target model's performance). Interestingly, this is
achieved by combining models whose parameter sizes differ by two orders of
magnitude. In addition, CD reduces the call frequency of the large target model
to below 10%, particularly in more demanding tasks. CD's performance was even
found to surpass that of the large target model, which theoretically represents
the upper bound for speculative decoding.

</details>


### [34] [GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2506.02404)
*Yilin Xiao,Junnan Dong,Chuang Zhou,Su Dong,Qianwen Zhang,Di Yin,Xing Sun,Xiao Huang*

Main category: cs.CL

TL;DR: GraphRAG-Bench是一个针对GraphRAG模型的领域专用大规模基准测试，通过设计挑战性问题、多样化任务和全面评估框架，系统量化图结构对模型推理能力的提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG评估主要依赖传统QA数据集，其有限的问题范围和评估指标无法全面评估图结构带来的推理能力提升，亟需专业化的评估基准。

Method: 1. 设计需要多跳推理的领域专业问题（如数学推理/编程）
2. 覆盖多选/判断/填空等16学科20本教材的多样化任务
3. 构建全流程评估框架（图构建/知识检索/答案生成）并评估逻辑连贯性

Result: 通过测试9种主流GraphRAG方法，验证了基准在量化图结构改进效果的有效性，揭示了图架构设计、检索效能与推理能力之间的关键关联。

Conclusion: 该基准为研究社区提供了量化图结构对LLM推理能力提升的标准化工具，通过系统评估揭示的洞见为后续方法改进提供了明确方向。

Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing
recognition for its potential to enhance large language models (LLMs) by
structurally organizing domain-specific corpora and facilitating complex
reasoning. However, current evaluations of GraphRAG models predominantly rely
on traditional question-answering datasets. Their limited scope in questions
and evaluation metrics fails to comprehensively assess the reasoning capacity
improvements enabled by GraphRAG models. To address this gap, we introduce
GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously
evaluate GraphRAG models. Our benchmark offers three key superiorities: \((i)\)
Challenging question design. Featuring college-level, domain-specific questions
that demand multi-hop reasoning, the benchmark ensures that simple content
retrieval is insufficient for problem-solving. For example, some questions
require mathematical reasoning or programming. \((ii)\) Diverse task coverage.
The dataset includes a broad spectrum of reasoning tasks, multiple-choice,
true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16
disciplines in twenty core textbooks. \((iii)\) Holistic evaluation framework.
GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG
pipeline, including graph construction, knowledge retrieval, and answer
generation. Beyond final-answer correctness, it evaluates the logical coherence
of the reasoning process. By applying nine contemporary GraphRAG methods to
GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based
structuring improves model reasoning capabilities. Our analysis reveals
critical insights about graph architectures, retrieval efficacy, and reasoning
capabilities, offering actionable guidance for the research community.

</details>


### [35] [SingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learning](https://arxiv.org/abs/2506.02412)
*Zhengyuan Liu,Geyu Lin,Hui Li Tan,Huayun Zhang,Yanfeng Lu,Xiaoxue Gao,Stella Xin Yin,He Sun,Hock Huan Goh,Lung Hsiang Wong,Nancy F. Chen*

Main category: cs.CL

TL;DR: SingaKids多语言对话导师系统通过图片描述任务整合多模态技术，提升儿童语言学习效果


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI在教育应用中存在的跨语言性能不一致问题，优化儿童友好型交互设计与学习支架

Method: 整合密集图像描述+多语言对话交互+语音理解生成，采用多语言预训练、任务调优和支架优化技术

Result: 小学生实证研究证实系统能为不同水平学习者提供有效对话教学

Conclusion: 多模态整合与对话式交互设计显著提升多语言学习效果，系统支持英/汉/马来/泰米尔四语种

Abstract: The integration of generative artificial intelligence into educational
applications has enhanced personalized and interactive learning experiences,
and it shows strong potential to promote young learners language acquisition.
However, it is still challenging to ensure consistent and robust performance
across different languages and cultural contexts, and kids-friendly design
requires simplified instructions, engaging interactions, and age-appropriate
scaffolding to maintain motivation and optimize learning outcomes. In this
work, we introduce SingaKids, a dialogic tutor designed to facilitate language
learning through picture description tasks. Our system integrates dense image
captioning, multilingual dialogic interaction, speech understanding, and
engaging speech generation to create an immersive learning environment in four
languages: English, Mandarin, Malay, and Tamil. We further improve the system
through multilingual pre-training, task-specific tuning, and scaffolding
optimization. Empirical studies with elementary school students demonstrate
that SingaKids provides effective dialogic teaching, benefiting learners at
different performance levels.

</details>


### [36] [Gender Inequality in English Textbooks Around the World: an NLP Approach](https://arxiv.org/abs/2506.02425)
*Tairan Liu*

Main category: cs.CL

TL;DR: 跨文化分析显示英语教科书中男性角色在数量、首次提及和命名实体上普遍过度代表，拉丁文化圈性别差异最小


<details>
  <summary>Details</summary>
Motivation: 填补跨文化性别不平等研究的空白，量化不同文化背景下英语教科书的性别表征差异

Method: 使用自然语言处理技术（字符统计、TF-IDF关联分析、GloVe词嵌入）分析22国教材，检测大语言模型对性别化词汇的区分能力

Result: 所有地区均存在性别不平等，男性角色数量超60%，命名实体中男性占比显著更高，拉丁文化圈性别差异指数最低（Δ=0.12）

Conclusion: 教科书性别不平等是全球性现象，需系统性改进内容编排。拉丁文化圈的相对平等表明文化因素可能影响性别表征

Abstract: Textbooks play a critical role in shaping children's understanding of the
world. While previous studies have identified gender inequality in individual
countries' textbooks, few have examined the issue cross-culturally. This study
applies natural language processing methods to quantify gender inequality in
English textbooks from 22 countries across 7 cultural spheres. Metrics include
character count, firstness (which gender is mentioned first), and TF-IDF word
associations by gender. The analysis also identifies gender patterns in proper
names appearing in TF-IDF word lists, tests whether large language models can
distinguish between gendered word lists, and uses GloVe embeddings to examine
how closely keywords associate with each gender. Results show consistent
overrepresentation of male characters in terms of count, firstness, and named
entities. All regions exhibit gender inequality, with the Latin cultural sphere
showing the least disparity.

</details>


### [37] [Comparative Analysis of AI Agent Architectures for Entity Relationship Classification](https://arxiv.org/abs/2506.02426)
*Maryam Berijanian,Kuldeep Singh,Amin Sehati*

Main category: cs.CL

TL;DR: 本研究比较了三种基于大语言模型的关系分类智能体架构，发现多智能体动态示例生成机制显著优于传统方法


<details>
  <summary>Details</summary>
Motivation: 解决有限标注数据和复杂关系场景下的实体关系分类难题，探索无需微调的LLM应用方案

Method: 提出三种架构：1) 反思自评估 2) 层次任务分解 3) 新型多智能体动态示例生成（含实时协同对抗提示机制）

Result: 多智能体协调策略优于标准少样本提示，接近微调模型性能

Conclusion: 为构建模块化、可泛化的LLM关系抽取系统提供实践指导，并开源代码和数据集

Abstract: Entity relationship classification remains a challenging task in information
extraction, especially in scenarios with limited labeled data and complex
relational structures. In this study, we conduct a comparative analysis of
three distinct AI agent architectures designed to perform relation
classification using large language models (LLMs). The agentic architectures
explored include (1) reflective self-evaluation, (2) hierarchical task
decomposition, and (3) a novel multi-agent dynamic example generation
mechanism, each leveraging different modes of reasoning and prompt adaptation.
In particular, our dynamic example generation approach introduces real-time
cooperative and adversarial prompting. We systematically compare their
performance across multiple domains and model backends. Our experiments
demonstrate that multi-agent coordination consistently outperforms standard
few-shot prompting and approaches the performance of fine-tuned models. These
findings offer practical guidance for the design of modular, generalizable
LLM-based systems for structured relation extraction. The source codes and
dataset are available at
\href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}.

</details>


### [38] [From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models](https://arxiv.org/abs/2506.02431)
*Mahammed Kamruzzaman,Abdullah Al Monsur,Gene Louis Kim,Anshuman Chhabra*

Main category: cs.CL

TL;DR: LLMs在模拟不同国家人格时展现出情绪刻板印象，其情感分配模式与人类实际反应存在显著差异


<details>
  <summary>Details</summary>
Motivation: 探究预训练大语言模型是否通过国家人格角色扮演展现出与文化规范相关的情绪刻板印象

Method: 通过为LLMs赋予不同国家的人格设定，系统分析其情感分配模式，并与人类实际情感数据进行跨文化比较

Result: 模型输出存在地域性情感偏见（如羞耻/恐惧/快乐情绪分配失衡），负面情绪表达与人类反应显著不匹配

Conclusion: LLMs在跨文化情感模拟中表现出简化且有偏见的刻板认知，揭示当前模型在文化敏感性方面的重大缺陷

Abstract: Emotions are a fundamental facet of human experience, varying across
individuals, cultural contexts, and nationalities. Given the recent success of
Large Language Models (LLMs) as role-playing agents, we examine whether LLMs
exhibit emotional stereotypes when assigned nationality-specific personas.
Specifically, we investigate how different countries are represented in
pre-trained LLMs through emotion attributions and whether these attributions
align with cultural norms. Our analysis reveals significant nationality-based
differences, with emotions such as shame, fear, and joy being
disproportionately assigned across regions. Furthermore, we observe notable
misalignment between LLM-generated and human emotional responses, particularly
for negative emotions, highlighting the presence of reductive and potentially
biased stereotypes in LLM outputs.

</details>


### [39] [Should LLM Safety Be More Than Refusing Harmful Instructions?](https://arxiv.org/abs/2506.02442)
*Utsav Maskey,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 系统评估了大型语言模型在处理长尾加密文本时的安全性，发现其安全机制在解密能力下存在漏洞，并提出改进方向。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在长尾加密文本场景中的安全风险，特别是在面对不匹配泛化攻击时安全机制的有效性。

Method: 建立二维安全评估框架（指令拒绝/生成安全），通过实验验证具备解密能力模型的安全机制失效案例。

Result: 具备解密能力的模型在至少一个安全维度失效，导致不安全响应或过度拒绝，现有防护措施存在局限性。

Conclusion: 揭示了LLMs在加密文本场景的安全脆弱性，为开发鲁棒性安全机制提供了理论依据和实践指导。

Abstract: This paper presents a systematic evaluation of Large Language Models' (LLMs)
behavior on long-tail distributed (encrypted) texts and their safety
implications. We introduce a two-dimensional framework for assessing LLM
safety: (1) instruction refusal-the ability to reject harmful obfuscated
instructions, and (2) generation safety-the suppression of generating harmful
responses. Through comprehensive experiments, we demonstrate that models that
possess capabilities to decrypt ciphers may be susceptible to
mismatched-generalization attacks: their safety mechanisms fail on at least one
safety dimension, leading to unsafe responses or over-refusal. Based on these
findings, we evaluate a number of pre-LLM and post-LLM safeguards and discuss
their strengths and limitations. This work contributes to understanding the
safety of LLM in long-tail text scenarios and provides directions for
developing robust safety mechanisms.

</details>


### [40] [IP-Dialog: Evaluating Implicit Personalization in Dialogue Systems with Synthetic Data](https://arxiv.org/abs/2506.02449)
*Bo Peng,Zhiheng Wang,Heyang Gong,Chaochao Lu*

Main category: cs.CL

TL;DR: 提出自动化合成数据生成方法解决对话系统隐式个性化评估难题，构建IP-Dialog基准并通过实验验证可靠性


<details>
  <summary>Details</summary>
Motivation: 传统数据集构建方法存在效率低、隐私泄露风险等问题，制约对话系统隐式个性化能力发展

Method: 开发自动化数据生成框架，创建覆盖10任务12属性的IP-Dialog数据集，设计四维度评估体系及五类因果推理图

Result: 实验验证数据集可靠性，揭示模型属性感知与推理能力的关联机制

Conclusion: 该方法突破数据瓶颈，IP-Dialog基准为隐式个性化研究提供标准化评估工具

Abstract: In modern dialogue systems, the ability to implicitly infer user backgrounds
from conversations and leverage this information for personalized assistance is
crucial. However, the scarcity of high-quality data remains a fundamental
challenge to evaluating and improving this capability. Traditional dataset
construction methods are labor-intensive, resource-demanding, and raise privacy
concerns. To address these issues, we propose a novel approach for automatic
synthetic data generation and introduce the Implicit Personalized Dialogue
(IP-Dialog) benchmark along with a training dataset, covering 10 tasks and 12
user attribute types. Additionally, we develop a systematic evaluation
framework with four metrics to assess both attribute awareness and reasoning
capabilities. We further propose five causal graphs to elucidate models'
reasoning pathways during implicit personalization. Extensive experiments yield
insightful observations and prove the reliability of our dataset.

</details>


### [41] [Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework](https://arxiv.org/abs/2506.02454)
*Zhaorui Yang,Bo Pan,Han Wang,Yiyao Wang,Xingyu Liu,Minfeng Zhu,Bo Zhang,Wei Chen*

Main category: cs.CL

TL;DR: 提出FDV结构化图表描述方法和多模态DeepResearcher框架，实现LLM驱动的图文融合报告自动生成


<details>
  <summary>Details</summary>
Motivation: 现有深度研究框架主要生成纯文本内容，无法有效处理图文混合内容生成，面临可视化设计与文本整合的双重挑战

Method: 1) 设计FDV结构化图表描述语言；2) 构建包含研究、示例报告文本化、规划和多模态生成四阶段框架；3) 开发含100主题的MultimodalReportBench评估体系

Result: 使用相同Claude 3.7 Sonnet模型，多模态DeepResearcher相对基线方法获得82%综合胜率

Conclusion: FDV与多模态框架成功解决图文融合生成难题，实验验证了其在多维度评估中的有效性，推动自动化研究报告向多模态方向发展

Abstract: Visualizations play a crucial part in effective communication of concepts and
information. Recent advances in reasoning and retrieval augmented generation
have enabled Large Language Models (LLMs) to perform deep research and generate
comprehensive reports. Despite its progress, existing deep research frameworks
primarily focus on generating text-only content, leaving the automated
generation of interleaved texts and visualizations underexplored. This novel
task poses key challenges in designing informative visualizations and
effectively integrating them with text reports. To address these challenges, we
propose Formal Description of Visualization (FDV), a structured textual
representation of charts that enables LLMs to learn from and generate diverse,
high-quality visualizations. Building on this representation, we introduce
Multimodal DeepResearcher, an agentic framework that decomposes the task into
four stages: (1) researching, (2) exemplar report textualization, (3) planning,
and (4) multimodal report generation. For the evaluation of generated
multimodal reports, we develop MultimodalReportBench, which contains 100
diverse topics served as inputs along with 5 dedicated metrics. Extensive
experiments across models and evaluation methods demonstrate the effectiveness
of Multimodal DeepResearcher. Notably, utilizing the same Claude 3.7 Sonnet
model, Multimodal DeepResearcher achieves an 82\% overall win rate over the
baseline method.

</details>


### [42] [MidPO: Dual Preference Optimization for Safety and Helpfulness in Large Language Models via a Mixture of Experts Framework](https://arxiv.org/abs/2506.02460)
*Yupeng Qi,Ziyu Lyu,Min Yang,Yanlin Wang,Lu Bai,Lixin Cui*

Main category: cs.CL

TL;DR: 提出混合专家框架MidPO，通过双偏好优化同时增强LLMs的安全性和有用性


<details>
  <summary>Details</summary>
Motivation: 现有安全约束方法存在过度安全导致有用性下降（在线方法）和自适应平衡能力不足（离线方法）的问题

Method: 1. 开发单偏好增强的直接偏好优化训练独立安全/有用性专家模型
2. 通过动态路由机制的MoE框架实现安全-有用性自适应平衡

Result: 在三个主流数据集上显著超越现有方法（安全性和有用性双重指标），量化实验和定性分析均验证有效性

Conclusion: MidPO框架成功解决了安全性与有用性的平衡难题，实验证明其优越性，代码和模型将开源

Abstract: As large language models (LLMs) are increasingly applied across various
domains, enhancing safety while maintaining the helpfulness of LLMs has become
a critical challenge. Recent studies solve this problem through
safety-constrained online preference optimization or safety-constrained offline
preference optimization. However, the safety-constrained online methods often
suffer from excessive safety, which might reduce helpfulness, while the
safety-constrained offline methods perform poorly in adaptively balancing
safety and helpfulness. To address these limitations, we propose MidPO, a
\textbf{\underline{Mi}}xture of Experts (MoE) framework for safety-helpfulness
\textbf{\underline{d}}ual \textbf{\underline{P}}reference
\textbf{\underline{O}}ptimization. Firstly, MidPO devises single-preference
enhanced direct preference optimization approach to transform the base model
into two independent experts, termed safety and helpfulness experts, and
fine-tunes the two independent experts for optimal safety or helpfulness
performance. Secondly, to achieve an effective balance between safety and
helpfulness, MidPO incorporates the two experts into the MoE framework and
designs a dynamic routing mechanism to allocate contributions from each expert
adaptively. We conduct quantitative and qualitative experiments on three
popular datasets to demonstrate the proposed MidPO significantly outperforms
state-of-the-art approaches in both safety and helpfulness. The code and models
will be released.

</details>


### [43] [XToM: Exploring the Multilingual Theory of Mind for Large Language Models](https://arxiv.org/abs/2506.02461)
*Chunkit Chan,Yauwai Yim,Hongchuan Zeng,Zhiying Zou,Xinyuan Cheng,Zhifan Sun,Zheye Deng,Kawai Chung,Yuzhuo Ao,Yixiang Fan,Cheng Jiayang,Ercong Nie,Ginny Y. Wong,Helmut Schmid,Hinrich Schütze,Simon See,Yangqiu Song*

Main category: cs.CL

TL;DR: XToM基准测试显示大语言模型在多语言心智理论任务中存在跨语言表现差异，暴露其与人类认知模式的差距


<details>
  <summary>Details</summary>
Motivation: 现有心智理论评估局限于英语，无法反映语言多样性对人类认知的影响，需探究大语言模型在多语言环境下的心智推理能力

Method: 开发覆盖5种语言的XToM多语言基准，包含多样化情境任务，系统评估DeepSeek R1等模型表现

Result: 模型在多语言理解表现优异但心智理论能力存在语言差异，显示其跨语言心智推理能力不足

Conclusion: 大语言模型虽具备多语言处理优势，但在模拟人类跨语言心智理论方面存在根本性局限，需突破现有架构提升社会认知能力

Abstract: Theory of Mind (ToM), the ability to infer mental states in others, is
pivotal for human social cognition. Existing evaluations of ToM in LLMs are
largely limited to English, neglecting the linguistic diversity that shapes
human cognition. This limitation raises a critical question: can LLMs exhibit
Multilingual Theory of Mind, which is the capacity to reason about mental
states across diverse linguistic contexts? To address this gap, we present
XToM, a rigorously validated multilingual benchmark that evaluates ToM across
five languages and incorporates diverse, contextually rich task scenarios.
Using XToM, we systematically evaluate LLMs (e.g., DeepSeek R1), revealing a
pronounced dissonance: while models excel in multilingual language
understanding, their ToM performance varies across languages. Our findings
expose limitations in LLMs' ability to replicate human-like mentalizing across
linguistic contexts.

</details>


### [44] [FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging](https://arxiv.org/abs/2506.02478)
*Zijian Li,Xiaocheng Feng,Huixin Liu,Yichong Huang,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: 提出FroM方法，通过Frobenius范数直接度量模型参数并引入超参数控制，有效缓解多任务微调场景下的模型合并干扰问题。


<details>
  <summary>Details</summary>
Motivation: 传统模型融合方法（如RegMean）在参数高效微调场景中面临任务干扰加剧的问题，且依赖训练数据。需开发无需训练数据、直接通过参数度量实现自适应融合的方案。

Method: 改进RegMean方法，摒弃对训练数据的依赖，基于Frobenius范数直接计算线性层参数差异，引入超参数调节不同任务模型的融合权重，实现无数据依赖的自适应合并。

Result: 在多种微调场景下（包括全参数微调和参数高效微调），FroM方法在GLUE等基准测试中均超越基线方法，显著缓解任务干扰现象。

Conclusion: FroM为参数高效微调提供了一种数据高效且性能优越的模型融合方案，对实际应用中的多任务模型整合具有重要实践价值。

Abstract: With the development of large language models, fine-tuning has emerged as an
effective method to enhance performance in specific scenarios by injecting
domain-specific knowledge. In this context, model merging techniques provide a
solution for fusing knowledge from multiple fine-tuning models by combining
their parameters. However, traditional methods often encounter task
interference when merging full fine-tuning models, and this problem becomes
even more evident in parameter-efficient fine-tuning scenarios. In this paper,
we introduce an improvement to the RegMean method, which indirectly leverages
the training data to approximate the outputs of the linear layers before and
after merging. We propose an adaptive merging method called FroM, which
directly measures the model parameters using the Frobenius norm, without any
training data. By introducing an additional hyperparameter for control, FroM
outperforms baseline methods across various fine-tuning scenarios, alleviating
the task interference problem.

</details>


### [45] [ORPP: Self-Optimizing Role-playing Prompts to Enhance Language Model Capabilities](https://arxiv.org/abs/2506.02480)
*Yifan Duan,Yihong Tang,Kehai Chen,Liqiang Nie,Min Zhang*

Main category: cs.CL

TL;DR: 提出ORPP框架，通过角色扮演提示优化提升大语言模型性能，兼容性强且超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法存在高计算开销与强模型能力依赖问题，限制其广泛应用

Method: 在小样本迭代生成角色扮演提示模板，利用few-shot学习迁移优化经验至全量数据

Result: ORPP性能优于主流方法，且能与多种提示方法兼容实现效果叠加

Conclusion: 该方法为提示优化提供了高效兼容的新范式，拓展了大模型应用潜力

Abstract: High-quality prompts are crucial for eliciting outstanding performance from
large language models (LLMs) on complex tasks. Existing research has explored
model-driven strategies for prompt optimization. However, these methods often
suffer from high computational overhead or require strong optimization
capabilities from the model itself, which limits their broad applicability.To
address these challenges, we propose ORPP (Optimized Role-Playing Prompt),a
framework that enhances model performance by optimizing and generating
role-playing prompts. The core idea of ORPP is to confine the prompt search
space to role-playing scenarios, thereby fully activating the model's intrinsic
capabilities through carefully crafted, high-quality role-playing prompts.
Specifically, ORPP first performs iterative optimization on a small subset of
training samples to generate high-quality role-playing prompts. Then,
leveraging the model's few-shot learning capability, it transfers the
optimization experience to efficiently generate suitable prompts for the
remaining samples.Our experimental results show that ORPP not only matches but
in most cases surpasses existing mainstream prompt optimization methods in
terms of performance. Notably, ORPP demonstrates superior "plug-and-play"
capability. In most cases, it can be integrated with various other prompt
methods and further enhance their effectiveness.

</details>


### [46] [Do Language Models Think Consistently? A Study of Value Preferences Across Varying Response Lengths](https://arxiv.org/abs/2506.02481)
*Inderjeet Nair,Lu Wang*

Main category: cs.CL

TL;DR: LLM价值观评估中短篇测试与长篇回答的偏好一致性较弱，需开发更稳健的跨场景评估方法


<details>
  <summary>Details</summary>
Motivation: 现有LLM伦理风险评估依赖短篇问卷，但实际应用多为开放式长文本响应，导致真实场景中的价值观风险未被充分探索

Method: 比较五个LLM（llama3-8b等）在短篇反应与不同参数数量的长篇回答中的价值偏好，分析生成属性与偏好的相关性

Result: 1. 短篇与长篇偏好弱相关（不同参数设置下r=0.16-0.22）
2. 不同长篇生成设置间相关性同样微弱
3. 对齐训练仅小幅提升一致性（+7.6%）
4. 论据特异性与偏好强度负相关，场景覆盖度与偏好正相关

Conclusion: 当前评估体系难以捕捉LLM在实际应用中的价值表达波动，亟需开发跨生成场景的稳健评估框架

Abstract: Evaluations of LLMs' ethical risks and value inclinations often rely on
short-form surveys and psychometric tests, yet real-world use involves
long-form, open-ended responses -- leaving value-related risks and preferences
in practical settings largely underexplored. In this work, we ask: Do value
preferences inferred from short-form tests align with those expressed in
long-form outputs? To address this question, we compare value preferences
elicited from short-form reactions and long-form responses, varying the number
of arguments in the latter to capture users' differing verbosity preferences.
Analyzing five LLMs (llama3-8b, gemma2-9b, mistral-7b, qwen2-7b, and olmo-7b),
we find (1) a weak correlation between value preferences inferred from
short-form and long-form responses across varying argument counts, and (2)
similarly weak correlation between preferences derived from any two distinct
long-form generation settings. (3) Alignment yields only modest gains in the
consistency of value expression. Further, we examine how long-form generation
attributes relate to value preferences, finding that argument specificity
negatively correlates with preference strength, while representation across
scenarios shows a positive correlation. Our findings underscore the need for
more robust methods to ensure consistent value expression across diverse
applications.

</details>


### [47] [Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks](https://arxiv.org/abs/2506.02483)
*Sina Bagheri Nezhad,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 提出神经符号增强推理框架（NSAR），通过结合神经推理与显式符号操作解决大模型在长文本多目标推理中的信息整合难题，在7种语言测试中显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理信息分散的长上下文时，难以准确整合多个目标的关联信息，影响复杂推理任务的可扩展性和结果可靠性。

Method: NSAR框架分两步：1）从文本显式提取符号化事实 2）生成Python代码执行复杂推理逻辑，实现神经推理与符号操作的优势互补。

Result: 在跨语言、可变长度上下文的实验中，NSAR准确率较RAG基线提升23.7%，比思维链等高级提示策略高15.2%，且具备更好的可解释性。

Conclusion: 显式符号操作与神经推理的协同机制为多语言复杂推理提供了可扩展解决方案，证明了符号增强方法在提升模型鲁棒性方面的有效性。

Abstract: Large language models (LLMs) often struggle to perform multi-target reasoning
in long-context scenarios where relevant information is scattered across
extensive documents. To address this challenge, we introduce NeuroSymbolic
Augmented Reasoning (NSAR), which combines the benefits of neural and symbolic
reasoning during inference. NSAR explicitly extracts symbolic facts from text
and generates executable Python code to handle complex reasoning steps. Through
extensive experiments across seven languages and diverse context lengths, we
demonstrate that NSAR significantly outperforms both a vanilla RAG baseline and
advanced prompting strategies in accurately identifying and synthesizing
multiple pieces of information. Our results highlight the effectiveness of
combining explicit symbolic operations with neural inference for robust,
interpretable, and scalable reasoning in multilingual settings.

</details>


### [48] [Minos: A Multimodal Evaluation Model for Bidirectional Generation Between Image and Text](https://arxiv.org/abs/2506.02494)
*Junzhe Zhang,Huixuan Zhang,Xinyu Hu,Li Lin,Mingqi Gao,Shi Qiu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 提出Minos-Corpus多模态评估数据集及Minos模型，在T2I生成任务评估中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视文本到图像生成任务的评估能力开发，且缺乏结合人类评估数据，需构建更全面的评估体系

Method: 通过Data Selection and Balance筛选数据，采用Mix-SFT训练方法结合DPO优化，在7B模型基础上训练Minos

Result: Minos在T2I评估任务上超越所有开源/闭源模型，所有任务平均评估性能达到同规模模型最佳

Conclusion: 高质量人类评估数据与跨任务联合训练显著提升多模态评估模型性能

Abstract: Evaluation is important for multimodal generation tasks. With the rapid
progress of MLLMs, there is growing interest in applying MLLMs to build general
evaluation systems. However, existing work overlooks two aspects: (1) the
development of evaluation capabilities for text-to-image (T2I) generation task,
and (2) the incorporation of large-scale human evaluation data. In this paper,
we introduce Minos-Corpus, a large-scale multimodal evaluation dataset that
combines evaluation data from both human and GPT. The corpus contains
evaluation data across both image-to-text(I2T) and T2I generation tasks. Based
on this corpus, we propose Data Selection and Balance, Mix-SFT training
methods, and apply DPO to develop Minos, a multimodal evaluation model built
upon a 7B backbone. Minos achieves state-of-the-art (SoTA) performance among
all open-source evaluation models of similar scale on the average of evaluation
performance on all tasks, and outperforms all open-source and closed-source
models on evaluation of T2I generation task. Extensive experiments demonstrate
the importance of leveraging high-quality human evaluation data and jointly
training on evaluation data from both I2T and T2I generation tasks.

</details>


### [49] [KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG](https://arxiv.org/abs/2506.02503)
*Yongjian Li,HaoCheng Chu,Yukun Yan,Zhenghao Liu,Shi Yu,Zheni Zeng,Ruobing Wang,Sen Song,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: KARE-RAG通过结构化知识表示、优化训练目标和对比数据生成三大创新，提升RAG处理噪声能力，实现高效数据优化的跨领域性能增强


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法即使采用先进检索技术仍存在检索噪声导致的事实不一致问题，增强生成模型对噪声内容的处理能力是提升鲁棒性的关键需求

Method: 1.结构化知识表示辅助训练错误检测
2.DDPO训练目标优先纠正关键错误
3.保持语义一致的对比数据生成框架

Result: 显著提升不同规模RAG模型在领域内外任务的表现，仅需少量训练数据即实现优化，验证数据高效优化的可行性

Conclusion: 通过改进模型处理检索内容的学习机制，为RAG性能提升开辟新路径，代码数据开源推动后续研究发展

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access broader knowledge sources, yet factual inconsistencies persist due to
noise in retrieved documents-even with advanced retrieval methods. We
demonstrate that enhancing generative models' capacity to process noisy content
is equally critical for robust performance. In this paper, we present KARE-RAG
(Knowledge-Aware Refinement and Enhancement for RAG), which improves knowledge
utilization through three key innovations: (1) structured knowledge
representations that facilitate error detection during training, (2) Dense
Direct Preference Optimization (DDPO)-a refined training objective that
prioritizes correction of critical errors, and (3) a contrastive data
generation pipeline that maintains semantic consistency while rectifying
factual inaccuracies. Experiments show our method significantly enhances
standard RAG pipelines across model scales, improving both in-domain and
out-of-domain task performance without compromising general capabilities.
Notably, these gains are achieved with modest training data, suggesting
data-efficient optimization is possible through targeted learning strategies.
Our findings establish a new direction for RAG improvement: by improving how
models learn to process retrieved content, we can enhance performance across
diverse inference paradigms. All data and code will be publicly available on
Github.

</details>


### [50] [M$^3$FinMeeting: A Multilingual, Multi-Sector, and Multi-Task Financial Meeting Understanding Evaluation Dataset](https://arxiv.org/abs/2506.02510)
*Jie Zhu,Junhui Li,Yalong Wen,Xiandong Li,Lifan Guo,Feng Chen*

Main category: cs.CL

TL;DR: 提出多语言多行业的金融会议理解基准M³FinMeeting，填补现有金融评测基准在真实会议场景的不足，通过三大任务验证主流长文本大模型仍有显著提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有金融评测基准依赖新闻/财报等静态数据，难以捕捉真实金融会议动态。需构建覆盖多语言、多行业、多任务的会议场景评估体系。

Method: 1. 支持中英日三语种 2. 采用GICS行业分类标准覆盖多元金融场景 3. 设计摘要生成、QA对抽取、问答三大理解任务

Result: 测试7个主流长文本大模型显示，最佳模型在摘要任务（ROUGE-L 32.1）和问答任务（准确率68.2%）仍有显著提升空间

Conclusion: M³FinMeeting有效评估大模型的金融会议理解能力，揭示了当前模型在处理复杂金融场景对话时的技术瓶颈，为后续模型优化提供方向

Abstract: Recent breakthroughs in large language models (LLMs) have led to the
development of new benchmarks for evaluating their performance in the financial
domain. However, current financial benchmarks often rely on news articles,
earnings reports, or announcements, making it challenging to capture the
real-world dynamics of financial meetings. To address this gap, we propose a
novel benchmark called $\texttt{M$^3$FinMeeting}$, which is a multilingual,
multi-sector, and multi-task dataset designed for financial meeting
understanding. First, $\texttt{M$^3$FinMeeting}$ supports English, Chinese, and
Japanese, enhancing comprehension of financial discussions in diverse
linguistic contexts. Second, it encompasses various industry sectors defined by
the Global Industry Classification Standard (GICS), ensuring that the benchmark
spans a broad range of financial activities. Finally,
$\texttt{M$^3$FinMeeting}$ includes three tasks: summarization, question-answer
(QA) pair extraction, and question answering, facilitating a more realistic and
comprehensive evaluation of understanding. Experimental results with seven
popular LLMs reveal that even the most advanced long-context models have
significant room for improvement, demonstrating the effectiveness of
$\texttt{M$^3$FinMeeting}$ as a benchmark for assessing LLMs' financial meeting
comprehension skills.

</details>


### [51] [FinChain: A Symbolic Benchmark for Verifiable Chain-of-Thought Financial Reasoning](https://arxiv.org/abs/2506.02515)
*Zhuohan Xie,Dhruv Sahnan,Debopriyo Banerjee,Georgi Georgiev,Rushil Thareja,Hachem Madmoun,Jinyan Su,Aaryamonvikram Singh,Yuxia Wang,Rui Xing,Fajri Koto,Haonan Li,Ivan Koychev,Tanmoy Chakraborty,Salem Lahlou,Veselin Stoyanov,Preslav Nakov*

Main category: cs.CL

TL;DR: 提出了FinChain基准和ChainEval指标，用于评估和改进多步金融推理


<details>
  <summary>Details</summary>
Motivation: 现有数据集仅监督最终答案，缺乏对中间推理步骤的系统评估，需建立新基准提升金融推理能力

Method: 创建FinChain基准（覆盖12领域/54主题），提供参数化模板与可执行Python跟踪实现数据生成及跨领域适配，并设计ChainEval自动评估指标

Result: 测试30个LLM显示，最先进模型在多步金融推理中仍存在显著改进空间（准确率最高仅61.2%）

Conclusion: FinChain为系统评估金融推理提供有效工具，揭示了当前模型局限性，为未来研究建立新基准

Abstract: Multi-step symbolic reasoning is critical for advancing downstream
performance on financial tasks. Yet, benchmarks for systematically evaluating
this capability are lacking. Existing datasets like FinQA and ConvFinQA
supervise only final numerical answers, without assessing intermediate
reasoning steps. To address this, we introduce FinChain, the first symbolic
benchmark designed for verifiable Chain-of- Thought (CoT) financial reasoning.
Spanning 54 topics across 12 financial domains, Fin- Chain offers five
parameterized templates per topic, each varying in reasoning complexity and
domain expertise required. Each dataset instance includes an executable Python
trace, enabling automatic generation of extensive training data and easy
adaptation to other domains. We also introduce ChainEval, a new metric for
automatic evaluation of both final answers and intermediate reasoning.
Benchmarking 30 LLMs on our dataset, we find that even state-of-the-art models
have considerable room for improvement in multi-step financial reasoning. All
templates and evaluation metrics for FinChain are available at https:
//github.com/mbzuai-nlp/finchain.

</details>


### [52] [Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning](https://arxiv.org/abs/2506.02519)
*Sohan Patnaik,Milan Aggarwal,Sumit Bhatia,Balaji Krishnamurthy*

Main category: cs.CL

TL;DR: 提出COLLATE框架，通过多样化推理路径和偏好优化提升小型模型的推理能力，无需依赖大型模型


<details>
  <summary>Details</summary>
Motivation: 由于大型模型存在版权和法律限制无法商用，且现有方法过度依赖蒸馏技术，需开发不依赖大型模型的小模型自主推理能力提升方案

Method: 1. 使多个同架构小模型生成多样化推理路径
2. 通过偏好优化选择最有利于正确答案的推理路径
3. 框架包含多样性增强和任务导向选择机制

Result: 在数学解题、自然语言推理、常识推理的5个数据集上超越基线方法，验证了框架在1B-8B不同规模模型的有效性

Conclusion: COLLATE证明了小模型通过自主生成优化推理路径可实现能力提升，为商业化场景提供了可行的技术路径

Abstract: LLMssuch as GPT-4 have shown a remarkable ability to solve complex questions
by generating step-by-step rationales. Prior works have utilized this
capability to improve smaller and cheaper LMs (say, with 7B parameters).
However, various practical constraints, such as copyright and legal issues,
owing to lack of transparency in the pre-training data of large (often closed)
models, prevent their use in commercial settings. Little focus has been given
to improving the innate reasoning ability of smaller models without distilling
information from larger LLMs. To address this, we propose COLLATE, a trainable
framework that tunes a (small) LLM to generate those outputs from a pool of
diverse rationales that selectively improves the downstream task. COLLATE
enforces multiple instances of the same LLM to exhibit distinct behavior and
employs them to generate rationales to obtain diverse outputs. The LLM is then
tuned via preference optimization to choose the candidate rationale which
maximizes the likelihood of ground-truth answer. COLLATE outperforms several
trainable and prompting baselines on 5 datasets across 3 domains: maths problem
solving, natural language inference, and commonsense reasoning. We show the eff
icacy of COLLATE on LLMs from different model families across varying parameter
scales (1B to 8B) and demonstrate the benefit of multiple rationale providers
guided by the end task through ablations. Code is released here
(https://github.com/Sohanpatnaik106/collate).

</details>


### [53] [Multilingual Information Retrieval with a Monolingual Knowledge Base](https://arxiv.org/abs/2506.02527)
*Yingying Zhuang,Aman Gupta,Anurag Beniwal*

Main category: cs.CL

TL;DR: 提出加权采样对比学习微调策略，提升单语知识库的多语言检索效果（MRR提升31.03%，Recall@3提升33.98%）


<details>
  <summary>Details</summary>
Motivation: 解决高资源语言知识库向低资源语言迁移时嵌入模型效率不足的问题

Method: 通过加权采样策略改进多语言嵌入模型的对比学习微调过程

Result: MRR提升31.03%，Recall@3提升33.98%，支持多语言和语码转换场景

Conclusion: 该方法具备语言无关性，有效促进跨语言知识共享，特别适用于资源不均衡场景

Abstract: Multilingual information retrieval has emerged as powerful tools for
expanding knowledge sharing across languages. On the other hand, resources on
high quality knowledge base are often scarce and in limited languages,
therefore an effective embedding model to transform sentences from different
languages into a feature vector space same as the knowledge base language
becomes the key ingredient for cross language knowledge sharing, especially to
transfer knowledge available in high-resource languages to low-resource ones.
In this paper we propose a novel strategy to fine-tune multilingual embedding
models with weighted sampling for contrastive learning, enabling multilingual
information retrieval with a monolingual knowledge base. We demonstrate that
the weighted sampling strategy produces performance gains compared to standard
ones by up to 31.03\% in MRR and up to 33.98\% in Recall@3. Additionally, our
proposed methodology is language agnostic and applicable for both multilingual
and code switching use cases.

</details>


### [54] [ReasoningFlow: Semantic Structure of Complex Reasoning Traces](https://arxiv.org/abs/2506.02532)
*Jinu Lee,Sagnik Mukherjee,Dilek Hakkani-Tur,Julia Hockenmaier*

Main category: cs.CL

TL;DR: 提出ReasoningFlow统一框架，通过有向无环图解析大模型推理轨迹，将复杂推理模式表征为子图结构


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型产生的复杂推理轨迹缺乏结构化分析方法，需建立可解释的语义表征框架

Method: 将推理轨迹转化为有向无环图，通过子图结构识别不同推理模式（规划/反思/验证/回溯）

Result: 构建人类可解释的结构化表示，为理解、评估和增强大模型推理过程提供新方法

Conclusion: ReasoningFlow为分析大模型复杂推理机制提供了结构化工具，在模型优化和可解释性方面具有应用潜力

Abstract: Large reasoning models (LRMs) generate complex reasoning traces with
planning, reflection, verification, and backtracking. In this work, we
introduce ReasoningFlow, a unified schema for analyzing the semantic structures
of these complex traces. ReasoningFlow parses traces into directed acyclic
graphs, enabling the characterization of distinct reasoning patterns as
subgraph structures. This human-interpretable representation offers promising
applications in understanding, evaluating, and enhancing the reasoning
processes of LRMs.

</details>


### [55] [Natural Language Processing to Enhance Deliberation in Political Online Discussions: A Survey](https://arxiv.org/abs/2506.02533)
*Maike Behrendt,Stefan Sylvius Wagner,Carina Weinmann,Marike Bormann,Mira Warne,Stefan Harmeling*

Main category: cs.CL

TL;DR: 探讨如何利用机器学习改善政治在线讨论中的审议质量


<details>
  <summary>Details</summary>
Motivation: 数字时代政治在线讨论存在非建设性对话、有害内容等问题，影响公民审议质量

Method: 分析政治在线讨论现存问题，提出机器学习在内容审核、对话引导等方面的应用框架

Result: 机器学习可有效识别有害信息、促进理性对话，为平台设计提供技术支持

Conclusion: 合理运用机器学习能优化在线讨论环境，提升政治审议的民主质量

Abstract: Political online participation in the form of discussing political issues and
exchanging opinions among citizens is gaining importance with more and more
formats being held digitally. To come to a decision, a careful discussion and
consideration of opinions and a civil exchange of arguments, which is defined
as the act of deliberation, is desirable. The quality of discussions and
participation processes in terms of their deliberativeness highly depends on
the design of platforms and processes. To facilitate online communication for
both participants and initiators, machine learning methods offer a lot of
potential. In this work we want to showcase which issues occur in political
online discussions and how machine learning can be used to counteract these
issues and enhance deliberation.

</details>


### [56] [Answer Convergence as a Signal for Early Stopping in Reasoning](https://arxiv.org/abs/2506.02536)
*Xin Liu,Lu Wang*

Main category: cs.CL

TL;DR: 提出三种推理时优化策略，通过识别冗余推理步骤显著降低LLM计算成本且保持精度


<details>
  <summary>Details</summary>
Motivation: 链式思维(CoT)提示存在推理步骤冗余，导致计算资源浪费。研究旨在确定达到稳定决策所需的最小推理步骤

Method: 1.系统性分析推理步骤与决策稳定性关系
2.提出基于答案一致性的早停机制
3.增强终止信号生成概率
4.基于内部激活的监督式停止策略

Result: 在5个基准测试中平均减少40% token使用量，NaturalQuestions任务节省40% token且精度提升

Conclusion: 推理时优化策略能有效平衡计算效率与模型性能，为实际应用提供经济高效的解决方案

Abstract: Chain-of-thought (CoT) prompting enhances reasoning in large language models
(LLMs) but often leads to verbose and redundant outputs, thus increasing
inference cost. We hypothesize that many reasoning steps are unnecessary for
producing correct answers. To investigate this, we start with a systematic
study to examine what is the minimum reasoning required for a model to reach a
stable decision. We find that on math reasoning tasks like math, models
typically converge to their final answers after 60\% of the reasoning steps,
suggesting substantial redundancy in the remaining content. Based on these
insights, we propose three inference-time strategies to improve efficiency: (1)
early stopping via answer consistency, (2) boosting the probability of
generating end-of-reasoning signals, and (3) a supervised method that learns
when to stop based on internal activations. Experiments across five benchmarks
and five open-weights LLMs show that our methods significantly reduce token
usage with little or no accuracy drop. In particular, on NaturalQuestions,
Answer Consistency reduces tokens by over 40\% while further improving
accuracy. Our work underscores the importance of cost-effective reasoning
methods that operate at inference time, offering practical benefits for
real-world applications.

</details>


### [57] [CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG](https://arxiv.org/abs/2506.02544)
*Yang Tian,Fan Liu,Jingyuan Zhang,Victoria W.,Yupeng Hu,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出CoRe-MMRAG框架解决多模态检索增强生成中的知识不一致问题，在KB-VQA基准测试中实现显著性能提升


<details>
  <summary>Details</summary>
Motivation: 解决多模态检索增强生成（MMRAG）中参数知识与非参数知识不一致（PRKI）、视觉与文本知识不对齐（VTKI）两大核心挑战

Method: 四阶段流程：参数知识生成内部响应→联合相似度评估选择多模态证据→生成外部响应→融合内外结果生成最终答案，配合专项训练范式提升知识整合能力

Result: 在InfoSeek和Encyclopedic-VQA数据集上分别实现5.6%和9.3%的性能提升

Conclusion: CoRe-MMRAG有效协调多源知识矛盾，通过端到端框架实现可靠答案生成，代码数据已开源促进后续研究

Abstract: Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to
enhance Multimodal Large Language Models by incorporating externally retrieved
multimodal knowledge, but it introduces two challenges: Parametric-Retrieved
Knowledge Inconsistency (PRKI), where discrepancies between parametric and
retrieved knowledge create uncertainty in determining reliability, and
Visual-Textual Knowledge Inconsistency (VTKI), where misalignment between
visual and textual sources disrupts entity representation. To address these
challenges, we propose \textbf{C}r\textbf{o}ss-source knowledge
\textbf{Re}conciliation for \textbf{M}ulti\textbf{M}odal \textbf{RAG}
(CoRe-MMRAG), a novel end-to-end framework that effectively reconciles
inconsistencies across knowledge sources. CoRe-MMRAG follows a four-stage
pipeline: it first generates an internal response from parametric knowledge,
then selects the most relevant multimodal evidence via joint similarity
assessment, generates an external response, and finally integrates both to
produce a reliable answer. Additionally, a specialized training paradigm
enhances knowledge source discrimination, multimodal integration, and unified
answer generation. Experiments on KB-VQA benchmarks show that CoRe-MMRAG
achieves substantial improvements over baseline methods, achieving 5.6\% and
9.3\% performance gains on InfoSeek and Encyclopedic-VQA, respectively. We
release code and data at
\href{https://github.com/TyangJN/CoRe-MMRAG}{https://github.com/TyangJN/CoRe-MMRAG}.

</details>


### [58] [Pruning General Large Language Models into Customized Expert Models](https://arxiv.org/abs/2506.02561)
*Yirao Zhao,Guizhen Chen,Kenji Kawaguchi,Lidong Bing,Wenxuan Zhang*

Main category: cs.CL

TL;DR: 提出无需后训练的定制剪枝方法Cus-Prun，将大模型压缩为轻量专家模型


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数量大导致计算资源消耗高，特定场景需要轻量化专家模型

Method: 沿语言/领域/任务三维度剪枝无关神经元，直接生成专业小模型

Result: 在多个模型家族和尺寸上，专家能力和通用能力损失最小，优于其他方法

Conclusion: Cus-Prun实现了无需微调的定向模型压缩，为下游任务提供高效定制方案

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their substantial model sizes often require substantial computational
resources. To preserve computing resources and accelerate inference speed, it
is crucial to prune redundant parameters, especially for experienced users who
often need compact expert models tailored to specific downstream scenarios.
However, most existing pruning methods focus on preserving the model's general
capabilities, often requiring extensive post-training or suffering from
degraded performance due to coarse-grained pruning. In this work, we design a
$\underline{Cus}$tom $\underline{Prun}$ing method ($\texttt{Cus-Prun}$) to
prune a large general model into a smaller lightweight expert model, which is
positioned along the "language", "domain" and "task" dimensions. By identifying
and pruning irrelevant neurons of each dimension, $\texttt{Cus-Prun}$ creates
expert models without any post-training. Our experiments demonstrate that
$\texttt{Cus-Prun}$ consistently outperforms other methods, achieving minimal
loss in both expert and general capabilities across various models from
different model families and sizes.

</details>


### [59] [IndoSafety: Culturally Grounded Safety for LLMs in Indonesian Languages](https://arxiv.org/abs/2506.02573)
*Muhammad Falensi Azmi,Muhammad Dehan Al Kautsar,Alfan Farizki Wicaksono,Fajri Koto*

Main category: cs.CL

TL;DR: 构建首个印尼语境安全评估数据集IndoSafety，发现现有印尼LLM在方言环境存在安全隐患，微调后显著提升安全性


<details>
  <summary>Details</summary>
Motivation: 印尼多语言文化背景下现有LLM安全性评估不足，需符合本土社会文化规范的安全框架

Method: 扩展安全评估框架构建印尼特色分类法，覆盖5种语言变体（正式/口语印尼语+3种地方语言）

Result: 现模型在方言场景输出不安全率较高，经IndoSafety微调后安全性提升且保持任务性能

Conclusion: 强调文化基础安全评估的必要性，为多语言LLM负责任部署提供实践路径

Abstract: Although region-specific large language models (LLMs) are increasingly
developed, their safety remains underexplored, particularly in culturally
diverse settings like Indonesia, where sensitivity to local norms is essential
and highly valued by the community. In this work, we present IndoSafety, the
first high-quality, human-verified safety evaluation dataset tailored for the
Indonesian context, covering five language varieties: formal and colloquial
Indonesian, along with three major local languages: Javanese, Sundanese, and
Minangkabau. IndoSafety is constructed by extending prior safety frameworks to
develop a taxonomy that captures Indonesia's sociocultural context. We find
that existing Indonesian-centric LLMs often generate unsafe outputs,
particularly in colloquial and local language settings, while fine-tuning on
IndoSafety significantly improves safety while preserving task performance. Our
work highlights the critical need for culturally grounded safety evaluation and
provides a concrete step toward responsible LLM deployment in multilingual
settings. Warning: This paper contains example data that may be offensive,
harmful, or biased.

</details>


### [60] [Prosodic Structure Beyond Lexical Content: A Study of Self-Supervised Learning](https://arxiv.org/abs/2506.02584)
*Sarenne Wallbridge,Christoph Minixhofer,Catherine Lai,Peter Bell*

Main category: cs.CL

TL;DR: 研究通过自监督学习探究韵律声学结构的时间粒度，发现SSL模型在长时结构任务（如情感识别）中优于传统声学特征。


<details>
  <summary>Details</summary>
Motivation: 探索韵律特征（如语调、节奏）在独立于词汇内容时对语言结构预测的贡献程度。

Method: 使用自监督学习训练Masked Prosody Model，分析韵律特征的局部与长时结构预测能力。

Result: SSL模型在词边界等局部任务有效，但对情感识别等长时结构预测效果显著优于传统基频/能量特征（相对增益达37.5%）。

Conclusion: SSL训练目标的时间尺度选择及复杂结构编码能力，对捕捉韵律的层次化时间结构具有关键价值。

Abstract: People exploit the predictability of lexical structures during text
comprehension. Though predictable structure is also present in speech, the
degree to which prosody, e.g. intonation, tempo, and loudness, contributes to
such structure independently of the lexical content is unclear. This study
leverages self-supervised learning (SSL) to examine the temporal granularity of
structures in the acoustic correlates of prosody. Representations from our
proposed Masked Prosody Model can predict perceptual labels dependent on local
information, such as word boundaries, but provide the most value for labels
involving longer-term structures, like emotion recognition. Probing experiments
across various perceptual labels show strong relative gains over untransformed
pitch, energy, and voice activity features. Our results reveal the importance
of SSL training objective timescale and highlight the value of complex
SSL-encoded structures compared to more constrained classical structures.

</details>


### [61] [Evaluating Named Entity Recognition Models for Russian Cultural News Texts: From BERT to LLM](https://arxiv.org/abs/2506.02589)
*Maria Levchenko*

Main category: cs.CL

TL;DR: 论文比较多种NER模型在俄语文化新闻中人名识别的表现，发现GPT-4o在JSON提示下F1达0.93，GPT-4精确度最高0.99，后续GPT-4.1实现F1=0.94


<details>
  <summary>Details</summary>
Motivation: 解决俄语文化领域新闻中人名NER的挑战，评估不同模型在形态丰富语言中的表现差异

Method: 使用SPbLitGuide数据集（圣彼得堡1999-2019文化活动公告），对比transformer模型(DeepPavlov/RoBERTa/SpaCy)与LLMs(GPT系列)

Result: GPT-4o在JSON提示下F1=0.93最优，GPT-4精度0.99最高。GPT-4.1后续评估显示F1=0.94且部署更简化

Conclusion: 研究揭示了LLMs在俄语NER任务中的优势，特别是结构化提示的有效性，为形态复杂语言的数字人文研究提供模型选择依据，同时展现模型迭代的快速进步

Abstract: This paper addresses the challenge of Named Entity Recognition (NER) for
person names within the specialized domain of Russian news texts concerning
cultural events. The study utilizes the unique SPbLitGuide dataset, a
collection of event announcements from Saint Petersburg spanning 1999 to 2019.
A comparative evaluation of diverse NER models is presented, encompassing
established transformer-based architectures such as DeepPavlov, RoBERTa, and
SpaCy, alongside recent Large Language Models (LLMs) including GPT-3.5, GPT-4,
and GPT-4o. Key findings highlight the superior performance of GPT-4o when
provided with specific prompting for JSON output, achieving an F1 score of
0.93. Furthermore, GPT-4 demonstrated the highest precision at 0.99. The
research contributes to a deeper understanding of current NER model
capabilities and limitations when applied to morphologically rich languages
like Russian within the cultural heritage domain, offering insights for
researchers and practitioners. Follow-up evaluation with GPT-4.1 (April 2025)
achieves F1=0.94 for both simple and structured prompts, demonstrating rapid
progress across model families and simplified deployment requirements.

</details>


### [62] [On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures](https://arxiv.org/abs/2506.02591)
*Minh Duc Bui,Kyung Eun Park,Goran Glavaš,Fabian David Schmidt,Katharina von der Wense*

Main category: cs.CL

TL;DR: 研究发现大型语言模型默认使用数据中主流的测量系统，在不同测量系统间表现不稳定，推理方法可部分改善但增加计算成本。


<details>
  <summary>Details</summary>
Motivation: 不同文化背景使用不同的测量系统（如货币单位），LLMs应具备跨测量系统的准确信息处理能力以服务全球用户。

Method: 通过新构建的数据集测试7个开源LLM，分析其在三种测量系统场景下的默认设置、准确性差异及推理缓解能力。

Result: 1.LLMs默认使用数据主导的测量系统
2.不同系统间性能差异显著
3.思维链等推理方法可提升非主流系统性能但增加2.5倍响应时间

Conclusion: LLMs对非主流测量系统的支持不足可能边缘化相关文化群体用户，需平衡计算成本与公平性。

Abstract: Measurement systems (e.g., currencies) differ across cultures, but the
conversions between them are well defined so that humans can state facts using
any measurement system of their choice. Being available to users from diverse
cultural backgrounds, large language models (LLMs) should also be able to
provide accurate information irrespective of the measurement system at hand.
Using newly compiled datasets we test if this is the case for seven open-source
LLMs, addressing three key research questions: (RQ1) What is the default system
used by LLMs for each type of measurement? (RQ2) Do LLMs' answers and their
accuracy vary across different measurement systems? (RQ3) Can LLMs mitigate
potential challenges w.r.t. underrepresented systems via reasoning? Our
findings show that LLMs default to the measurement system predominantly used in
the data. Additionally, we observe considerable instability and variance in
performance across different measurement systems. While this instability can in
part be mitigated by employing reasoning methods such as chain-of-thought
(CoT), this implies longer responses and thereby significantly increases
test-time compute (and inference costs), marginalizing users from cultural
backgrounds that use underrepresented measurement systems.

</details>


### [63] [Beyond the Surface: Measuring Self-Preference in LLM Judgments](https://arxiv.org/abs/2506.02592)
*Zhi-Yuan Chen,Hao Wang,Xinyu Zhang,Enrui Hu,Yankai Lin*

Main category: cs.CL

TL;DR: 大语言模型（LLMs）作为评判者存在自我偏好偏差，现有测量方法混淆了质量与偏差。本文提出DBG分数，通过引入黄金判断分离偏差与质量，并系统性分析模型特性、文本风格、训练数据对偏差的影响机制。


<details>
  <summary>Details</summary>
Motivation: 现有基于评分差异的自我偏好偏差测量方法无法区分真实偏差与回答质量差异（模型自身回答质量高导致的评分差异）。需要更准确的测量方式揭示真实偏差程度。

Method: 1. 引入黄金判断作为回答质量的客观基准
2. 提出DBG分数（模型自评与黄金判断的差值）
3. 跨模型版本/规模/推理能力的系统性实验
4. 探究文本风格、训练后数据、注意力机制的影响

Result: 1. DBG有效分离质量与偏差
2. 模型规模/推理能力与偏差强度负相关
3. 调整文本风格可降低20-30%偏差
4. 后训练数据影响模型自我认知

Conclusion: DBG分数为量化自我偏好提供了可靠指标，揭示了模型架构与训练数据对偏差的调控作用，为构建无偏评估体系提供理论基础。代码数据已开源。

Abstract: Recent studies show that large language models (LLMs) exhibit self-preference
bias when serving as judges, meaning they tend to favor their own responses
over those generated by other models. Existing methods typically measure this
bias by calculating the difference between the scores a judge model assigns to
its own responses and those it assigns to responses from other models. However,
this approach conflates self-preference bias with response quality, as
higher-quality responses from the judge model may also lead to positive score
differences, even in the absence of bias. To address this issue, we introduce
gold judgments as proxies for the actual quality of responses and propose the
DBG score, which measures self-preference bias as the difference between the
scores assigned by the judge model to its own responses and the corresponding
gold judgments. Since gold judgments reflect true response quality, the DBG
score mitigates the confounding effect of response quality on bias measurement.
Using the DBG score, we conduct comprehensive experiments to assess
self-preference bias across LLMs of varying versions, sizes, and reasoning
abilities. Additionally, we investigate two factors that influence and help
alleviate self-preference bias: response text style and the post-training data
of judge models. Finally, we explore potential underlying mechanisms of
self-preference bias from an attention-based perspective. Our code and data are
available at https://github.com/zhiyuanc2001/self-preference.

</details>


### [64] [EssayBench: Evaluating Large Language Models in Multi-Genre Chinese Essay Writing](https://arxiv.org/abs/2506.02596)
*Fan Gao,Dongyuan Li,Ding Xia,Fei Mi,Yasheng Wang,Lifeng Shang,Baojun Wang*

Main category: cs.CL

TL;DR: 提出多文体中文作文评估基准C3E，覆盖四大文体并建立细粒度评分框架，验证了15个主流大模型的表现差异


<details>
  <summary>Details</summary>
Motivation: 现有中文作文评估基准主要依赖粗粒度文本质量指标，忽视了不同文体的结构和修辞复杂性

Method: 1. 收集并筛选728个真实场景作文题目，分为开放型与限制型
2. 开发层次化细粒度评分框架
3. 通过人工一致性研究验证评估协议

Result: 发现不同大模型在四大文体中的表现存在显著差异，指令类型对写作质量产生系统性影响

Conclusion: C3E基准有效推动中文作文生成技术发展，为教育场景中的写作评估提供标准化测试框架

Abstract: Chinese essay writing and its evaluation are critical in educational
contexts, yet the capabilities of Large Language Models (LLMs) in this domain
remain largely underexplored. Existing benchmarks often rely on coarse-grained
text quality metrics, largely overlooking the structural and rhetorical
complexities of Chinese essays, particularly across diverse genres. To address
this gap, we propose \benchName, a multi-genre benchmark specifically designed
for Chinese essay writing across four major genres: Argumentative, Narrative,
Descriptive, and Expository. We curate and refine a total of 728 real-world
prompts to ensure authenticity and meticulously categorize them into the
\textit{Open-Ended} and \textit{Constrained} sets to capture diverse writing
scenarios. To reliably evaluate generated essays, we develop a fine-grained,
genre-specific scoring framework that hierarchically aggregates scores. We
further validate our evaluation protocol through a comprehensive human
agreement study. Finally, we benchmark 15 large-sized LLMs, analyzing their
strengths and limitations across genres and instruction types. With \benchName,
we aim to advance LLM-based Chinese essay evaluation and inspire future
research on improving essay generation in educational settings.

</details>


### [65] [Overcoming Data Scarcity in Multi-Dialectal Arabic ASR via Whisper Fine-Tuning](https://arxiv.org/abs/2506.02627)
*Ömer Tarik Özyilmaz,Matt Coler,Matias Valdenegro-Toro*

Main category: cs.CL

TL;DR: 小规模MSA数据微调可显著提升小模型性能，方言池化模型与方言专用模型表现相当，平衡数据可缓解ASR低资源困境


<details>
  <summary>Details</summary>
Motivation: 解决商用阿拉伯语ASR系统对方言语音识别能力不足的问题，探索在数据稀缺条件下提升方言语音识别性能的有效方法

Method: 基于Whisper架构，使用MSA数据和五大阿拉伯方言数据，通过控制变量法分析微调数据量、预训练策略和模型架构差异的影响

Result: 1. 300小时MSA数据即可使BASE模型性能提升7.5% 2. MSA预训练对方言识别增益有限 3. 方言池化模型CER仅比方言专用模型高0.5%

Conclusion: 通过合理平衡多方言数据，构建统一方言池化模型可有效突破单一方言数据不足的瓶颈，为低资源ASR提供实用解决方案

Abstract: Although commercial Arabic automatic speech recognition (ASR) systems support
Modern Standard Arabic (MSA), they struggle with dialectal speech. We
investigate the effect of fine-tuning OpenAI's Whisper on five major Arabic
dialects (Gulf, Levantine, Iraqi, Egyptian, Maghrebi) using Mozilla Common
Voice for MSA and the MASC dataset for dialectal speech. We evaluate MSA
training size effects, benefits of pre-training on MSA data, and
dialect-specific versus dialect-pooled models. We find that small amounts of
MSA fine-tuning data yield substantial improvements for smaller models,
matching larger non-fine-tuned models. While MSA pre-training shows minimal
benefit, suggesting limited shared features between MSA and dialects, our
dialect-pooled models perform comparably to dialect-specific ones. This
indicates that pooling dialectal data, when properly balanced, can help address
data scarcity in low-resource ASR without significant performance loss.

</details>


### [66] [Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs](https://arxiv.org/abs/2506.02659)
*Manon Reusens,Bart Baesens,David Jurgens*

Main category: cs.CL

TL;DR: 提出标准化框架分析个性化大模型在不同角色和任务中的一致性，发现角色属性、刻板印象和模型设计共同影响一致性表现，结构化任务和上下文增强稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对角色驱动型LLMs跨任务一致性的系统评估，需建立标准化框架揭示不同角色属性和任务类型对模型表现的影响机制。

Method: 开发四维度角色评估体系（幸福/职业/个性/政治立场），通过五类文本生成任务（调查/文章/社交媒体/对话）测量模型输出的跨场景一致性。

Result: 模型一致性受角色特征与任务结构的双重调节，结构化任务较开放对话提升30%稳定性，政治类角色因刻板印象显示最高任务间差异（±22%）。

Conclusion: 角色一致性是动态多维概念，通过任务结构优化和上下文增强可提升个性化LLMs的可靠性，为可信AI系统设计提供新方法论。

Abstract: Personalized Large Language Models (LLMs) are increasingly used in diverse
applications, where they are assigned a specific persona - such as a happy high
school teacher - to guide their responses. While prior research has examined
how well LLMs adhere to predefined personas in writing style, a comprehensive
analysis of consistency across different personas and task types is lacking. In
this paper, we introduce a new standardized framework to analyze consistency in
persona-assigned LLMs. We define consistency as the extent to which a model
maintains coherent responses when assigned the same persona across different
tasks and runs. Our framework evaluates personas across four different
categories (happiness, occupation, personality, and political stance) spanning
multiple task dimensions (survey writing, essay generation, social media post
generation, single turn, and multi-turn conversations). Our findings reveal
that consistency is influenced by multiple factors, including the assigned
persona, stereotypes, and model design choices. Consistency also varies across
tasks, increasing with more structured tasks and additional context. All code
is available on GitHub.

</details>


### [67] [EvaLearn: Quantifying the Learning Capability and Efficiency of LLMs via Sequential Problem Solving](https://arxiv.org/abs/2506.02672)
*Shihan Dou,Ming Zhang,Chenhao Huang,Jiayi Chen,Feng Chen,Shichun Liu,Yan Liu,Chenxiao Liu,Cheng Zhong,Zongzhang Zhang,Tao Gui,Chao Xin,Wei Chengzhi,Lin Yan,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 论文提出EvaLearn评估框架，通过序列化挑战任务测试LLMs动态学习能力，发现模型间学习效率差异显著，静态能力与学习能力不直接相关


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要评估静态能力，缺乏对LLMs持续学习能力的系统评估。作者希望开发新方法量化模型从经验中学习的能力，揭示模型与人类学习的差距

Method: 构建包含6类任务、182个序列（每个序列3-5个递增难度问题）的基准，设计序列化评估流程和5个量化指标（初始能力、学习增益等），测试9个前沿模型在两种学习场景下的表现

Result: 1. Claude-3.7-sonnet等模型展现强学习能力（学习增益达+32.6%） 2. 部分模型出现负迁移 3. 实例级规则和教师反馈提升学习效果 4. 静态能力强的模型（如GPT-4）未在所有任务显现学习优势

Conclusion: EvaLearn揭示了LLMs动态学习能力的新维度，为评估模型潜力提供创新视角，推动开发更接近人类学习机制的评估体系，所有数据集和评估框架已开源

Abstract: We introduce EvaLearn, a pioneering benchmark designed to evaluate large
language models (LLMs) on their learning capability and efficiency in
challenging tasks, a critical, yet underexplored aspect of model potential.
EvaLearn contains 648 challenging problems across six task types, grouped into
182 sequences, each sequence dedicated to one task type. Diverging from most
existing benchmarks that evaluate models in parallel, EvaLearn requires models
to solve problems sequentially, allowing them to leverage the experience gained
from previous solutions. EvaLearn provides five comprehensive automated metrics
to evaluate models and quantify their learning capability and efficiency. We
extensively benchmark nine frontier models and observe varied performance
profiles: some models, such as Claude-3.7-sonnet, start with moderate initial
performance but exhibit strong learning ability, while some models struggle to
benefit from experience and may even show negative transfer. Moreover, we
investigate model performance under two learning settings and find that
instance-level rubrics and teacher-model feedback further facilitate model
learning. Importantly, we observe that current LLMs with stronger static
abilities do not show a clear advantage in learning capability across all
tasks, highlighting that EvaLearn evaluates a new dimension of model
performance. We hope EvaLearn provides a novel evaluation perspective for
assessing LLM potential and understanding the gap between models and human
capabilities, promoting the development of deeper and more dynamic evaluation
approaches. All datasets, the automatic evaluation framework, and the results
studied in this paper are available at the GitHub repository.

</details>


### [68] [TL;DR: Too Long, Do Re-weighting for Effcient LLM Reasoning Compression](https://arxiv.org/abs/2506.02678)
*Zhong-Zhi Li,Xiao Liang,Zihao Tang,Lei Ji,Peijie Wang,Haotian Xu,Xing W,Haizhen Huang,Weiwei Deng,Ying Nian Wu,Yeyun Gong,Zhijiang Guo,Xiao Liu,Fei Yin,Cheng-Lin Liu*

Main category: cs.CL

TL;DR: 提出动态比例训练框架，减少40%推理输出token同时保持精度


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在长输出推理时冗余思维过程的效率问题

Method: 通过平衡系统1/系统2数据权重，消除冗余推理流程

Result: 在DeepSeek 7B/14B模型上验证，多基准测试保持精度同时输出token减少40%

Conclusion: 无监督动态平衡方法有效提升推理效率，未来将开源代码数据

Abstract: Large Language Models (LLMs) have recently achieved remarkable progress by
leveraging Reinforcement Learning and extended Chain-of-Thought (CoT)
techniques. However, the challenge of performing efficient language
reasoning--especially during inference with extremely long outputs--has drawn
increasing attention from the research community. In this work, we propose a
dynamic ratio-based training pipeline that does not rely on sophisticated data
annotations or interpolation between multiple models. We continuously balance
the weights between the model's System-1 and System-2 data to eliminate
redundant reasoning processes while preserving the model's reasoning
capability. We validate our approach across models on DeepSeek-R1-Distill-7B
and DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying
difficulty levels. Our method significantly reduces the number of output tokens
by nearly 40% while maintaining the accuracy of the reasoning. Our code and
data will be available soon.

</details>


### [69] [Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints](https://arxiv.org/abs/2506.02683)
*Zhengdong Lu,Weikai Lu,Yiling Tao,Yun Dai,ZiXuan Chen,Huiping Zhuang,Cen Chen,Hao Peng,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出了并行规划范式DPPM解决LLM在规划任务中的约束限制和错误累积问题


<details>
  <summary>Details</summary>
Motivation: 现有规划方法存在约束过强和错误级联两大缺陷，制约LLM智能体的规划能力

Method: 通过任务分解、并行子任务规划、子计划融合的三阶段流程，配合验证精炼模块实现冲突解决

Result: 在旅行规划任务中显著超越现有方法

Conclusion: DPPM通过并行化规划架构有效提升复杂任务的规划可靠性和执行效率

Abstract: Despite significant advances in Large Language Models (LLMs), planning tasks
still present challenges for LLM-based agents. Existing planning methods face
two key limitations: heavy constraints and cascading errors. To address these
limitations, we propose a novel parallel planning paradigm, which Decomposes,
Plans for subtasks in Parallel, and Merges subplans into a final plan (DPPM).
Specifically, DPPM decomposes the complex task based on constraints into
subtasks, generates the subplan for each subtask in parallel, and merges them
into a global plan. In addition, our approach incorporates a verification and
refinement module, enabling error correction and conflict resolution.
Experimental results demonstrate that DPPM significantly outperforms existing
methods in travel planning tasks.

</details>


### [70] [MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching](https://arxiv.org/abs/2506.02689)
*Liang Yue,Yihong Tang,Kehai Chen,Jie Liu,Min Zhang*

Main category: cs.CL

TL;DR: 提出MASTER多智能体数据增强方法解决大模型微调数据质量问题，构建BOOST-QA数据集显著提升模型推理能力


<details>
  <summary>Details</summary>
Motivation: 解决大模型指令微调中高质量数据获取困难（数据收集难、生产成本高）的行业痛点

Method: 通过模拟课堂、辅导、实践三种教学场景的多智能体交互（师生角色），生成高质量教学对话数据

Result: 基于Orca-Math等数据集构建的BOOST-QQA使模型在多个基准测试中表现优异，复杂任务推理能力提升显著

Conclusion: MASTER为数据增强提供新范式，其教育场景模拟思路对提升模型认知能力具有重要启示

Abstract: Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models'
instruction-following capabilities and task-specific performance. However,
obtaining high-quality fine-tuning data for large models is challenging due to
data collection difficulties and high production costs. To address this, we
propose MASTER, a novel data augmentation method that enriches original data
through interactions among multiple agents with varying cognitive levels. We
simulate three pedagogically grounded teaching scenarios, leveraging
multi-agent conversations to generate high-quality teacher-student interaction
data. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented
from existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5.
Experiments show that models fine-tuned with BOOST-QA perform excellently
across multiple benchmarks, demonstrating strong multitask generalization.
Notably, MASTER significantly improves models' reasoning abilities in complex
tasks, providing valuable insights for future research.

</details>


### [71] [On Entity Identification in Language Models](https://arxiv.org/abs/2506.02701)
*Masaki Sakata,Sho Yokoi,Benjamin Heinzerling,Takumi Ito,Kentaro Inui*

Main category: cs.CL

TL;DR: 研究通过聚类分析量化语言模型识别和区分命名实体的能力，发现Transformer模型能有效表征实体信息（精度/召回率0.66-0.9），且实体信息在早期网络层低维子空间中紧凑存在。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型内部如何表征实体提及的歧义性（同一实体不同表述）和变异性（不同实体相似表述）问题，探索LM表征与现实世界实体知识结构的对应关系。

Method: 提出类似聚类质量评估的框架，对5个Transformer自回归模型的隐藏层表征进行聚类分析，采用类精度/召回率指标，并通过低维子空间分析揭示特征分布规律。

Result: 模型实体识别指标达0.66-0.9，早期层存在专门的低维实体表征子空间，且该表征特性直接影响语言模型的词汇预测性能。

Conclusion: LM内部通过结构化的低维表征实现实体知识组织，这种同构性揭示了语言模型处理实体信息的认知机制，为模型可解释性提供新视角。

Abstract: We analyze the extent to which internal representations of language models
(LMs) identify and distinguish mentions of named entities, focusing on the
many-to-many correspondence between entities and their mentions. We first
formulate two problems of entity mentions -- ambiguity and variability -- and
propose a framework analogous to clustering quality metrics. Specifically, we
quantify through cluster analysis of LM internal representations the extent to
which mentions of the same entity cluster together and mentions of different
entities remain separated. Our experiments examine five Transformer-based
autoregressive models, showing that they effectively identify and distinguish
entities with metrics analogous to precision and recall ranging from 0.66 to
0.9. Further analysis reveals that entity-related information is compactly
represented in a low-dimensional linear subspace at early LM layers.
Additionally, we clarify how the characteristics of entity representations
influence word prediction performance. These findings are interpreted through
the lens of isomorphism between LM representations and entity-centric knowledge
structures in the real world, providing insights into how LMs internally
organize and use entity information.

</details>


### [72] [RACE-Align: Retrieval-Augmented and Chain-of-Thought Enhanced Preference Alignment for Large Language Models](https://arxiv.org/abs/2506.02726)
*Qihang Yan,Xinyu Zhang,Luming Guo,Qi Zhang,Feifan Liu*

Main category: cs.CL

TL;DR: 提出RACE-Align框架，通过检索增强和思维链优化的对齐方法，提升大语言模型在垂直领域的知识应用与推理可靠性


<details>
  <summary>Details</summary>
Motivation: 传统偏好对齐方法（如RLHF/DPO）忽视知识来源和推理逻辑，导致大语言模型在垂直领域存在准确性不足、领域推理能力弱和可解释性差的问题

Method: 1. 构建包含外部知识支持和显式思维链的偏好数据集
2. 将AI驱动的检索增强（事实依据）和领域特定思维链优化（推理过程）作为核心偏好维度
3. 采用多阶段AI驱动优化流程生成高质量偏好对
4. 基于DPO算法进行模型对齐

Result: 在中医领域实验中，使用Qwen3-1.7B模型的RACE-Align在答案准确性（提升37%）、信息丰富度、中医思维模式应用、推理逻辑深度和可解释性等多个维度显著超越基线模型

Conclusion: 该框架为提升大语言模型在复杂垂直领域的知识应用可靠性、推理过程透明度和领域适应性提供了有效解决方案，特别在医疗等专业领域具有应用潜力

Abstract: Large Language Models (LLMs) struggle with accuracy, domain-specific
reasoning, and interpretability in vertical domains. Traditional preference
alignment methods like Reinforcement Learning from Human Feedback (RLHF) and
Direct Preference Optimization (DPO) often overlook the underlying knowledge
sources and reasoning logic. This paper introduces RACE-Align
(Retrieval-Augmented and Chain-of-Thought Enhanced Alignment), a novel
framework designed to address these limitations. RACE-Align systematically
constructs a binary preference dataset incorporating external knowledge support
and explicit Chain-of-Thought (CoT) reasoning, then aligns LLMs using the DPO
algorithm. The core innovation lies in its preference data construction
strategy: it integrates AI-driven retrieval for factual grounding, enhancing
knowledgeability and accuracy, and emphasizes the optimization of
domain-specific CoT, treating the reasoning process itself as a key preference
dimension. A multi-stage, AI-driven refinement pipeline cost-effectively
generates these preference pairs. Experimental validation in Traditional
Chinese Medicine (TCM) using Qwen3-1.7B as the base model demonstrates that
RACE-Align significantly outperforms the original base model and a model
fine-tuned only with Supervised Fine-Tuning (SFT). Improvements were observed
across multiple dimensions, including answer accuracy, information richness,
application of TCM thinking patterns, logicality and depth of reasoning, and
interpretability. These findings suggest RACE-Align offers an effective pathway
to enhance LLMs' knowledge application, reasoning reliability, and process
transparency in complex vertical domains.

</details>


### [73] [Stereotypical gender actions can be extracted from Web text](https://arxiv.org/abs/2506.02740)
*Amaç Herdağdelen,Marco Baroni*

Main category: cs.CL

TL;DR: 论文通过分析文本和Twitter数据验证了利用自然文本(尤其是Twitter语料)增强常识库中性别刻板印象行为的可行性，并提供了人工标注和自动评分的两个行为数据集。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用自然文本数据补充常识知识库中的性别刻板印象信息，更全面反映社会中的性别偏见现象。

Method: 结合OMCS知识库，采用Twitter用户性别信息与网络语料库的代词/姓名推断方法，通过高召回率统计模型计算行为性别偏向，并与人工标注金标准进行相关性验证。

Result: 获得Spearman相关性0.47和ROC曲线下面积0.76的预测效果，构建了441个行为的人工标注数据集和21,442个自动评分行为数据集。

Conclusion: 自然文本(特别是Twitter数据)能有效扩充常识库中的性别刻板印象行为数据，为相关研究提供方法论支持和数据基础。

Abstract: We extracted gender-specific actions from text corpora and Twitter, and
compared them to stereotypical expectations of people. We used Open Mind Common
Sense (OMCS), a commonsense knowledge repository, to focus on actions that are
pertinent to common sense and daily life of humans. We use the gender
information of Twitter users and Web-corpus-based pronoun/name gender
heuristics to compute the gender bias of the actions. With high recall, we
obtained a Spearman correlation of 0.47 between corpus-based predictions and a
human gold standard, and an area under the ROC curve of 0.76 when predicting
the polarity of the gold standard. We conclude that it is feasible to use
natural text (and a Twitter-derived corpus in particular) in order to augment
commonsense repositories with the stereotypical gender expectations of actions.
We also present a dataset of 441 commonsense actions with human judges' ratings
on whether the action is typically/slightly masculine/feminine (or neutral),
and another larger dataset of 21,442 actions automatically rated by the methods
we investigate in this study.

</details>


### [74] [Multi-task Learning with Active Learning for Arabic Offensive Speech Detection](https://arxiv.org/abs/2506.02753)
*Aisha Alansari,Hamzah Luqman*

Main category: cs.CL

TL;DR: 提出融合多任务学习与主动学习的新型框架，显著提升阿拉伯社交媒体攻击性语言检测性能（F1达85.42%）


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语标注数据稀缺、方言复杂性问题，优化资源受限环境下的攻击性内容检测效率

Method: 1. 多任务联合训练（攻击性/暴力/粗俗语言）共享表征 2. 动态任务权重调整机制 3. 主动学习+不确定性采样选择样本 4. 加权emoji处理增强语义捕捉

Result: 在OSACT2022数据集上实现85.42%的宏F1值，显著减少微调样本需求

Conclusion: 多任务学习与主动学习的协同框架能有效提升低资源环境下的语言检测效果

Abstract: The rapid growth of social media has amplified the spread of offensive,
violent, and vulgar speech, which poses serious societal and cybersecurity
concerns. Detecting such content in Arabic text is particularly complex due to
limited labeled data, dialectal variations, and the language's inherent
complexity. This paper proposes a novel framework that integrates multi-task
learning (MTL) with active learning to enhance offensive speech detection in
Arabic social media text. By jointly training on two auxiliary tasks, violent
and vulgar speech, the model leverages shared representations to improve the
detection accuracy of the offensive speech. Our approach dynamically adjusts
task weights during training to balance the contribution of each task and
optimize performance. To address the scarcity of labeled data, we employ an
active learning strategy through several uncertainty sampling techniques to
iteratively select the most informative samples for model training. We also
introduce weighted emoji handling to better capture semantic cues. Experimental
results on the OSACT2022 dataset show that the proposed framework achieves a
state-of-the-art macro F1-score of 85.42%, outperforming existing methods while
using significantly fewer fine-tuning samples. The findings of this study
highlight the potential of integrating MTL with active learning for efficient
and accurate offensive language detection in resource-constrained settings.

</details>


### [75] [Exploiting the English Vocabulary Profile for L2 word-level vocabulary assessment with LLMs](https://arxiv.org/abs/2506.02758)
*Stefano Bannò,Kate Knill,Mark Gales*

Main category: cs.CL

TL;DR: 论文提出结合大语言模型与EVP标准资源，实现细粒度词汇评估，证明LLMs在词汇熟练度判定中的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化词汇评估主要依赖词性分析，缺乏对上下文关联、多义词处理等核心语言特征的有效捕捉。

Method: 通过整合LLMs的语义理解能力与EVP的权威词汇分级标准，处理多义词/语境变化/多词表达三大挑战，并与传统词性分析方法对比。

Result: LLMs利用语义信息提升评估性能，词汇熟练度与文章水平显著相关，EVP等级一致性得到验证。

Conclusion: 大语言模型在上下文相关的词汇评估任务中展现出显著优势，为自动化语言能力评估提供新范式。

Abstract: Vocabulary use is a fundamental aspect of second language (L2) proficiency.
To date, its assessment by automated systems has typically examined the
context-independent, or part-of-speech (PoS) related use of words. This paper
introduces a novel approach to enable fine-grained vocabulary evaluation
exploiting the precise use of words within a sentence. The scheme combines
large language models (LLMs) with the English Vocabulary Profile (EVP). The EVP
is a standard lexical resource that enables in-context vocabulary use to be
linked with proficiency level. We evaluate the ability of LLMs to assign
proficiency levels to individual words as they appear in L2 learner writing,
addressing key challenges such as polysemy, contextual variation, and
multi-word expressions. We compare LLMs to a PoS-based baseline. LLMs appear to
exploit additional semantic information that yields improved performance. We
also explore correlations between word-level proficiency and essay-level
proficiency. Finally, the approach is applied to examine the consistency of the
EVP proficiency levels. Results show that LLMs are well-suited for the task of
vocabulary assessment.

</details>


### [76] [SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking](https://arxiv.org/abs/2506.02803)
*Sifan Li,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: 传统视觉语言模型（VLM）依赖高层语义，无法感知图像隐藏内容，但通过简单缩放图像分辨率（SemVink方法）可显著提升检测准确率至99%以上


<details>
  <summary>Details</summary>
Motivation: 揭示当前主流VLM模型存在架构缺陷——过度依赖语义推理而忽视人类本能具备的低级视觉处理能力，这限制了其在医学影像、安防等需细粒度视觉理解场景的应用

Method: 1. 构建HC-Bench基准测试集（含112张含隐藏文本/物体的图像） 2. 验证主流VLM接近零准确率 3. 提出SemVink方法（将图像降采样至32-128像素分辨率）

Result: SemVink方法使准确率从0-5.36%提升至>99%，证明降低分辨率可消除冗余视觉噪声，暴露VLM架构对低级视觉特征处理能力的缺失

Conclusion: 呼吁开发融合多尺度处理的混合模型架构，弥合计算机视觉与人类认知的鸿沟，强调低级视觉操作对提升模型鲁棒性的关键作用

Abstract: Vision-language models (VLMs) excel in semantic tasks but falter at a core
human capability: detecting hidden content in optical illusions or AI-generated
images through perceptual adjustments like zooming. We introduce HC-Bench, a
benchmark of 112 images with hidden text, objects, and illusions, revealing
that leading VLMs achieve near-zero accuracy (0-5.36%)-even with explicit
prompting. Humans resolve such ambiguities instinctively, yet VLMs fail due to
an overreliance on high-level semantics. Strikingly, we propose SemVink
(Semantic Visual Thinking) by simply scaling images to low resolutions (32-128
pixels), which unlocks >99% accuracy by eliminating redundant visual noise.
This exposes a critical architectural flaw: VLMs prioritize abstract reasoning
over low-level visual operations crucial for real-world robustness. Our work
urges a shift toward hybrid models integrating multi-scale processing, bridging
the gap between computational vision and human cognition for applications in
medical imaging, security, and beyond.

</details>


### [77] [ProcrustesGPT: Compressing LLMs with Structured Matrices and Orthogonal Transformations](https://arxiv.org/abs/2506.02818)
*Ekaterina Grishina,Mikhail Gorbunov,Maxim Rakhuba*

Main category: cs.CL

TL;DR: 通过正交变换优化预训练大语言模型的权重矩阵结构化压缩，无需微调即可保持模型输出不变


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在高计算/内存消耗问题，现有结构化矩阵压缩方法需要微调且效果有限。研究发现LLM权重矩阵在特定正交变换下输出不变，可利用该特性提升结构化压缩效果

Method: 利用权重矩阵的正交变换不变性，寻找最优变换使权重矩阵更适配结构化压缩方案，支持多种支持高效投影操作的结构化矩阵类型

Result: 开发出无需微调即可有效压缩LLM参数的方法，保持原始模型功能的同时提升结构化矩阵的压缩适配性，并提供开源实现

Conclusion: 该正交变换方法突破结构化压缩需要微调的限制，为不同结构的参数高效压缩提供通用解决方案，代码开源促进实际应用

Abstract: Large language models (LLMs) demonstrate impressive results in natural
language processing tasks but require a significant amount of computational and
memory resources. Structured matrix representations are a promising way for
reducing the number of parameters of these models. However, it seems
unrealistic to expect that weight matrices of pretrained models can be
accurately represented by structured matrices without any fine-tuning. To
overcome this issue, we utilize the fact that LLM output is invariant under
certain orthogonal transformations of weight matrices. This insight can be
leveraged to identify transformations that significantly improve the
compressibility of weights within structured classes. The proposed approach is
applicable to various types of structured matrices that support efficient
projection operations. Code is available at
https://github.com/GrishKate/ProcrustesGPT

</details>


### [78] [TO-GATE: Clarifying Questions and Summarizing Responses with Trajectory Optimization for Eliciting Human Preference](https://arxiv.org/abs/2506.02827)
*Yulin Dou,Jiangming Liu*

Main category: cs.CL

TL;DR: TO-GATE框架通过轨迹优化提升大语言模型在偏好诱导任务中的表现，相比基线方法性能提升9.32%


<details>
  <summary>Details</summary>
Motivation: 现有基于自学习推理的方法难以识别最优对话轨迹，常生成与任务无关的问题

Method: 提出包含澄清解析器（生成最优提问轨迹）和总结器（保证任务对齐）的TO-GATE框架

Result: 在标准偏好诱导任务中显著超越基线方法，实现9.32%的性能提升

Conclusion: 轨迹优化机制能有效提升语言模型的问题生成质量和任务对齐响应能力

Abstract: Large language models (LLMs) can effectively elicit human preferences through
multi-turn dialogue. Complex tasks can be accomplished through iterative
clarifying questions and final responses generated by an LLM acting as a
questioner (STaR-GATE; Andukuri et al., 2024}). However, existing approaches
based on self-taught reasoning struggle to identify optimal dialogue
trajectories and avoid irrelevant questions to the tasks. To address this
limitation, we propose TO-GATE, a novel framework that enhances question
generation through trajectory optimization, which consists of two key
components: a clarification resolver that generates optimal questioning
trajectories, and a summarizer that ensures task-aligned final responses. The
trajectory optimization enables the model to produce effective elicitation
questions and summary responses tailored to specific tasks. Experimental
results demonstrate that TO-GATE significantly outperforms baseline methods,
achieving a 9.32% improvement on standard preference elicitation tasks.

</details>


### [79] [Token and Span Classification for Entity Recognition in French Historical Encyclopedias](https://arxiv.org/abs/2506.02872)
*Ludovic Moncla,Hédi Zeghidi*

Main category: cs.CL

TL;DR: 研究对比了传统CRF、spaCy、CamemBERT和Flair等模型在历史文本NER任务中的表现，提出词/跨度双分类框架解决嵌套实体问题，验证生成式模型在低资源场景的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决历史文本中非标准化语言、古老正字法和嵌套/重叠实体带来的NER识别难题，探索适应复杂结构的有效方法。

Method: 使用GeoEDdA数据集（18世纪法语百科全书），将NER建模为词级/跨度级分类任务，测试CRF、spaCy、CamemBERT、Flair及生成式模型的少样本学习。

Result: Transformer模型在嵌套实体识别达到SOTA，生成模型在标注数据不足时展现出替代潜力。

Conclusion: 历史NER仍需解决复杂语言特征，建议结合符号规则与神经方法的混合框架提升早期现代法语文本解析能力。

Abstract: Named Entity Recognition (NER) in historical texts presents unique challenges
due to non-standardized language, archaic orthography, and nested or
overlapping entities. This study benchmarks a diverse set of NER approaches,
ranging from classical Conditional Random Fields (CRFs) and spaCy-based models
to transformer-based architectures such as CamemBERT and sequence-labeling
models like Flair. Experiments are conducted on the GeoEDdA dataset, a richly
annotated corpus derived from 18th-century French encyclopedias. We propose
framing NER as both token-level and span-level classification to accommodate
complex nested entity structures typical of historical documents. Additionally,
we evaluate the emerging potential of few-shot prompting with generative
language models for low-resource scenarios. Our results demonstrate that while
transformer-based models achieve state-of-the-art performance, especially on
nested entities, generative models offer promising alternatives when labeled
data are scarce. The study highlights ongoing challenges in historical NER and
suggests avenues for hybrid approaches combining symbolic and neural methods to
better capture the intricacies of early modern French text.

</details>


### [80] [CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective](https://arxiv.org/abs/2506.02878)
*Jintian Shao,Yiming Cheng*

Main category: cs.CL

TL;DR: CoT提示机制通过结构性约束模仿推理形式，而非激发真正抽象推理能力


<details>
  <summary>Details</summary>
Motivation: 反驳'CoT激发大语言模型推理能力'的主流观点，揭示其本质是输出序列的结构性约束

Method: 从计算理论角度分析CoT工作机制，论证其依赖序列预测和模式匹配能力

Result: CoT通过强制中间步骤生成，利用模型固有的序列建模能力约束输出结构

Conclusion: CoT本质是对现有能力的工程化运用，而非实现真正的认知推理突破

Abstract: Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of
Large Language Models on tasks requiring multi-step inference. This success has
led to widespread claims of emergent reasoning capabilities in these models. In
this paper, we present a theoretical counter-perspective: Chain-of-Thought
(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that
Chain-of-Thought functions as a powerful structural constraint that guides
Large Language Models to imitate the form of reasoning. By forcing the
generation of intermediate steps, Chain-of-Thought leverages the model immense
capacity for sequence prediction and pattern matching, effectively constraining
its output to sequences that resemble coherent thought processes.
Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of
Large Language Models on tasks requiring multi-step inference. This success has
led to widespread claims of emergent reasoning capabilities in these models. In
this paper, we present a theoretical counter-perspective: Chain-of-Thought
(CoT) does not elicit genuine, abstract reasoning. Instead, we argue that
Chain-of-Thought functions as a powerful structural constraint that guides
Large Language Models to imitate the form of reasoning. By forcing the
generation of intermediate steps, Chain-of-Thought leverages the model immense
capacity for sequence prediction and pattern matching, effectively constraining
its output to sequences that resemble coherent thought processes.

</details>


### [81] [A Multi-Dialectal Dataset for German Dialect ASR and Dialect-to-Standard Speech Translation](https://arxiv.org/abs/2506.02894)
*Verena Blaschke,Miriam Winkler,Constantin Förster,Gabriele Wenger-Glemser,Barbara Plank*

Main category: cs.CL

TL;DR: 评估多语言ASR模型在德国方言语音转译任务中的表现，发现模型输出存在方言与标准德语混合特征


<details>
  <summary>Details</summary>
Motivation: 当前自动语音识别研究缺乏对方言变体的关注，特别是德国东南部方言在ASR系统中的鲁棒性研究不足

Method: 构建包含三种德国东南部方言（弗兰肯、巴伐利亚、阿勒曼尼）及标准德语的Betthupferl数据集，提供双重转录本，并测试多个先进多语言ASR模型的语音转译能力

Result: 最佳ASR模型在语法差异标准化处理与保留方言结构间呈现矛盾表现，输出结果介于方言转录与标准化转录之间

Conclusion: 研究揭示了ASR系统处理方言时存在选择性标准化现象，为改进方言语音识别提供了实证依据

Abstract: Although Germany has a diverse landscape of dialects, they are
underrepresented in current automatic speech recognition (ASR) research. To
enable studies of how robust models are towards dialectal variation, we present
Betthupferl, an evaluation dataset containing four hours of read speech in
three dialect groups spoken in Southeast Germany (Franconian, Bavarian,
Alemannic), and half an hour of Standard German speech. We provide both
dialectal and Standard German transcriptions, and analyze the linguistic
differences between them. We benchmark several multilingual state-of-the-art
ASR models on speech translation into Standard German, and find differences
between how much the output resembles the dialectal vs. standardized
transcriptions. Qualitative error analyses of the best ASR model reveal that it
sometimes normalizes grammatical differences, but often stays closer to the
dialectal constructions.

</details>


### [82] [IMPARA-GED: Grammatical Error Detection is Boosting Reference-free Grammatical Error Quality Estimator](https://arxiv.org/abs/2506.02899)
*Yusuke Sakai,Takumi Goto,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出新型无需参考的自动语法纠错评估方法IMPARA-GED，通过增强语法错误检测能力提升评估效果


<details>
  <summary>Details</summary>
Motivation: 现有IMPARA方法的评估质量受限于语法错误检测能力不足，需构建更强大的语法错误识别机制

Method: 基于预训练语言模型构建质量评估器，重点增强语法错误检测模块的识别能力

Result: 在SEEDA元评估数据集上实现最高句子级人工评估相关性

Conclusion: IMPARA-GED成功整合语法错误检测能力，显著提升自动评估系统的可靠性

Abstract: We propose IMPARA-GED, a novel reference-free automatic grammatical error
correction (GEC) evaluation method with grammatical error detection (GED)
capabilities. We focus on the quality estimator of IMPARA, an existing
automatic GEC evaluation method, and construct that of IMPARA-GED using a
pre-trained language model with enhanced GED capabilities. Experimental results
on SEEDA, a meta-evaluation dataset for automatic GEC evaluation methods,
demonstrate that IMPARA-GED achieves the highest correlation with human
sentence-level evaluations.

</details>


### [83] [Cell-o1: Training LLMs to Solve Single-Cell Reasoning Puzzles with Reinforcement Learning](https://arxiv.org/abs/2506.02911)
*Yin Fang,Qiao Jin,Guangzhi Xiong,Bowen Jin,Xianrui Zhong,Siru Ouyang,Aidong Zhang,Jiawei Han,Zhiyong Lu*

Main category: cs.CL

TL;DR: 提出CellPuzzles任务与Cell-o1模型，显著提升单细胞RNA测序数据批量标注性能，超越现有模型73%。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在单细胞注释时忽略批次级细胞关联且缺乏解释性，而专家基于知识集群标注。需开发能模拟人类专家批量推理的解决方案。

Method: 创建CellPuzzles基准测试，开发7B参数Cell-o1模型：通过监督微调蒸馏推理路径，结合批量级奖励的强化学习。

Result: Cell-o1批量级准确率提升73%，在跨组织/疾病场景展现强泛化能力，推理行为呈现类专家特征。

Conclusion: Cell-o1实现了最先进的批量注释性能，其训练动态分析为生物医学LLM开发提供了新见解。代码与数据已开源。

Abstract: Cell type annotation is a key task in analyzing the heterogeneity of
single-cell RNA sequencing data. Although recent foundation models automate
this process, they typically annotate cells independently, without considering
batch-level cellular context or providing explanatory reasoning. In contrast,
human experts often annotate distinct cell types for different cell clusters
based on their domain knowledge. To mimic this workflow, we introduce the
CellPuzzles task, where the objective is to assign unique cell types to a batch
of cells. This benchmark spans diverse tissues, diseases, and donor conditions,
and requires reasoning across the batch-level cellular context to ensure label
uniqueness. We find that off-the-shelf large language models (LLMs) struggle on
CellPuzzles, with the best baseline (OpenAI's o1) achieving only 19.0%
batch-level accuracy. To fill this gap, we propose Cell-o1, a 7B LLM trained
via supervised fine-tuning on distilled reasoning traces, followed by
reinforcement learning with batch-level rewards. Cell-o1 achieves
state-of-the-art performance, outperforming o1 by over 73% and generalizing
well across contexts. Further analysis of training dynamics and reasoning
behaviors provides insights into batch-level annotation performance and
emergent expert-like reasoning. Code and data are available at
https://github.com/ncbi-nlp/cell-o1.

</details>


### [84] [A Controllable Examination for Long-Context Language Models](https://arxiv.org/abs/2506.02921)
*Yijun Yang,Zeyu Huang,Wenhao Zhu,Zihan Qiu,Fei Yuan,Jeff Z. Pan,Ivan Titov*

Main category: cs.CL

TL;DR: 提出LongBioBench基准，通过人工生成的传记评估长上下文语言模型，在真实性与可控性间取得平衡，实验显示多数模型在长上下文中存在理解、推理和可信度缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架存在局限：真实任务过于复杂且易受数据污染，合成任务因'针'与'干草堆'缺乏连贯性而有效性不足。

Method: 构建LongBioBench基准，通过控制变量法评估18个LCLM在理解、推理、可信度三个维度的表现，并分析模型架构设计对长上下文能力的影响。

Result: 多数模型在语义理解和基础推理表现欠佳，上下文增长导致可信度下降；现有合成基准因非连贯上下文、数值针等设计缺陷易被攻破；RoPE嵌入调整是长上下文持续预训练的主要手段。

Conclusion: LongBioBench相比传统基准实现了真实任务模拟与可控性的优化平衡，具有高可解释性和配置灵活性，为LCLM评估提供更可靠方案。

Abstract: Existing frameworks for evaluating long-context language models (LCLM) can be
broadly categorized into real-world and synthetic tasks. Despite their utility,
both approaches are accompanied by certain intrinsic limitations. Real-world
tasks are too complex to interpret or characterize and are susceptible to data
contamination. In contrast, synthetic tasks often adopt the
needle-in-the-haystack (NIAH) format, wherein a lack of coherence between the
"needle" and the "haystack" compromises their validity as proxies for realistic
applications. In response to these challenges, we posit that an ideal
long-context evaluation framework should be characterized by three essential
features: $\textit{seamless context}$, $\textit{controllable setting}$, and
$\textit{sound evaluation}$. This study introduces $\textbf{LongBioBench}$, a
novel benchmark that utilizes artificially generated biographies as a
controlled environment for assessing LCLMs across dimensions of
$\textit{understanding}$, $\textit{reasoning}$, and $\textit{trustworthiness}$.
Our experimental evaluation, which includes $\textbf{18}$ LCLMs in total,
demonstrates that most models still exhibit deficiencies in semantic
understanding and elementary reasoning over retrieved results and are less
trustworthy as context length increases. Our further analysis indicates some
design choices employed by existing synthetic benchmarks, such as contextual
non-coherence, numerical needles, and the absence of distractors, rendering
them vulnerable to test the model long-context capabilities. Moreover, we also
reveal that long-context continual pretraining primarily adjusts RoPE embedding
to accommodate extended context lengths. To sum up, compared to previous
synthetic benchmarks, LongBioBench achieves a better trade-off between
mirroring authentic language tasks and maintaining controllability, and is
highly interpretable and configurable.

</details>


### [85] [INESC-ID @ eRisk 2025: Exploring Fine-Tuned, Similarity-Based, and Prompt-Based Approaches to Depression Symptom Identification](https://arxiv.org/abs/2506.02924)
*Diogo A. P. Nunes,Eugénio Ribeiro*

Main category: cs.CL

TL;DR: 研究团队通过微调基础模型、集成方法及合成数据增强，在eRisk 2025抑郁症状检索任务中取得最优结果，超越16个参赛团队。


<details>
  <summary>Details</summary>
Motivation: 解决BDI-II抑郁症状文本检索任务中标注数据有限的问题，将症状识别转化为二分类任务以提高检测效果。

Method: 采用数据分割+多技术路线：1) 基础模型微调(含合成数据缓解类别不平衡) 2) 句子相似度计算 3) LLM提示工程 4) 集成学习。根据症状特性选择最佳方案组合。

Result: 五个测试方案中两个集成方法在IR标准指标(AP/R-PREC)上达到最高分，官方评估排名第一。

Conclusion: 基础模型微调结合症状定制化策略显著提升抑郁症状识别效果，合成数据增强有效克服数据局限，集成方法发挥症状差异性优势。

Abstract: In this work, we describe our team's approach to eRisk's 2025 Task 1: Search
for Symptoms of Depression. Given a set of sentences and the Beck's Depression
Inventory - II (BDI) questionnaire, participants were tasked with submitting up
to 1,000 sentences per depression symptom in the BDI, sorted by relevance.
Participant submissions were evaluated according to standard Information
Retrieval (IR) metrics, including Average Precision (AP) and R-Precision
(R-PREC). The provided training data, however, consisted of sentences labeled
as to whether a given sentence was relevant or not w.r.t. one of BDI's
symptoms. Due to this labeling limitation, we framed our development as a
binary classification task for each BDI symptom, and evaluated accordingly. To
that end, we split the available labeled data into training and validation
sets, and explored foundation model fine-tuning, sentence similarity, Large
Language Model (LLM) prompting, and ensemble techniques. The validation results
revealed that fine-tuning foundation models yielded the best performance,
particularly when enhanced with synthetic data to mitigate class imbalance. We
also observed that the optimal approach varied by symptom. Based on these
insights, we devised five independent test runs, two of which used ensemble
methods. These runs achieved the highest scores in the official IR evaluation,
outperforming submissions from 16 other teams.

</details>


### [86] [Quantitative LLM Judges](https://arxiv.org/abs/2506.02945)
*Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton*

Main category: cs.CL

TL;DR: 提出定量LLM评委框架，通过回归模型对齐人类评分，在计算效率和统计效率上优于传统微调方法


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM评委评分与人类评分存在偏差的问题，通过后处理建模提升评估效率，特别是在人类反馈有限场景下的应用价值

Method: 基于原始评委的文本评估和分数，训练回归模型构建四种定量评委类型（绝对/相对反馈场景），实现分数对齐

Result: 在四个数据集上验证显示，定量评委通过后处理建模显著提升原始评委的预测能力，且在有限人类反馈时统计效率更优

Conclusion: 定量LLM评委框架为自动化评估系统提供高效解决方案，通过参数高效的后处理建模实现评分体系的持续优化

Abstract: LLM-as-a-judge is a framework in which a large language model (LLM)
automatically evaluates the output of another LLM. We propose quantitative LLM
judges, which align evaluation scores of existing LLM judges to human scores in
a given domain using regression models. The models are trained to improve the
score of the original judge by using the judge's textual evaluation and score.
We present four quantitative judges for different types of absolute and
relative feedback, which showcases the generality and versatility of our
framework. Our framework is more computationally efficient than supervised
fine-tuning and can be more statistically efficient when human feedback is
limited, which is expected in most applications of our work. We validate these
claims empirically on four datasets using two base judges. Our experiments show
that quantitative judges can effectively improve the predictive power of
existing judges through post-hoc modeling.

</details>


### [87] [Adaptive Graph Pruning for Multi-Agent Communication](https://arxiv.org/abs/2506.02951)
*Boyi Li,Zhonghan Zhao,Der-Horng Lee,Gaoang Wang*

Main category: cs.CL

TL;DR: 提出自适应图剪枝框架AGP，通过两阶段联合优化智能体数量与通信拓扑，实现任务自适应的高效多智能体协作。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统采用固定数量和静态通信结构，无法适应不同复杂度任务的需求，导致资源浪费和性能受限。

Method: 两阶段训练：1）独立训练软剪枝网络确定任务最优的智能体数量与位置掩码；2）在最大完全图中联合优化硬剪枝（数量）与软剪枝（拓扑），动态配置系统架构。

Result: 在六大基准测试中实现SOTA（性能提升2.58%~9.84%），通用性强且token消耗减少90%+，仅需十步训练即可超越现有基线。

Conclusion: AGP框架兼具高性能、任务适配性、经济性和训练效率，在通用推理/数学推理/代码生成等任务中均展现极强适应性。

Abstract: Large Language Model (LLM) based multi-agent systems have shown remarkable
performance in various tasks, especially when enhanced through collaborative
communication. However, current methods often rely on a fixed number of agents
and static communication structures, limiting their ability to adapt to varying
task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a
novel task-adaptive multi-agent collaboration framework that jointly optimizes
agent quantity (hard-pruning) and communication topology (soft-pruning).
Specifically, our method employs a two-stage training strategy: firstly,
independently training soft-pruning networks for different agent quantities to
determine optimal agent-quantity-specific complete graphs and positional masks
across specific tasks; and then jointly optimizing hard-pruning and
soft-pruning within a maximum complete graph to dynamically configure the
number of agents and their communication topologies per task. Extensive
experiments demonstrate that our approach is: (1) High-performing, achieving
state-of-the-art results across six benchmarks and consistently generalizes
across multiple mainstream LLM architectures, with a increase in performance of
$2.58\%\sim 9.84\%$; (2) Task-adaptive, dynamically constructing optimized
communication topologies tailored to specific tasks, with an extremely high
performance in all three task categories (general reasoning, mathematical
reasoning, and code generation); (3) Token-economical, having fewer training
steps and token consumption at the same time, with a decrease in token
consumption of $90\%+$; and (4) Training-efficient, achieving high performance
with very few training steps compared with other methods. The performance will
surpass the existing baselines after about ten steps of training under six
benchmarks.

</details>


### [88] [HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring](https://arxiv.org/abs/2506.02959)
*Zhixiong Su,Yichen Wang,Herun Wan,Zhaohan Zhang,Minnan Luo*

Main category: cs.CL

TL;DR: 该论文提出HACo-Det数据集用于人机协作场景下的细粒度文本检测，通过改造现有文档级检测器验证了微调模型在词句级检测中的优越性（平均F1 0.462 vs 更优表现）。


<details>
  <summary>Details</summary>
Motivation: 现有机器文本检测聚焦文档级二元判断，难以应对人机混合创作场景。需要开发能检测AI参与比例的细粒度检测方法。

Method: 1. 构建HACo-Det数据集（自动化生成人机协作文本，含词级标注）
2. 改造7个主流文档检测器适配词级检测
3. 在词级/句级任务上评估模型表现

Result: 度量方法表现欠佳（平均F1 0.462），微调模型展现更优性能与跨域泛化能力。上下文窗口等因素显著影响检测效果。

Conclusion: 细粒度人机协作文本检测尚未完全解决，需在上下文建模、域适应等方面持续改进。当前方法在长距离依赖处理存在局限。

Abstract: The misuse of large language models (LLMs) poses potential risks, motivating
the development of machine-generated text (MGT) detection. Existing literature
primarily concentrates on binary, document-level detection, thereby neglecting
texts that are composed jointly by human and LLM contributions. Hence, this
paper explores the possibility of fine-grained MGT detection under human-AI
coauthoring. We suggest fine-grained detectors can pave pathways toward
coauthored text detection with a numeric AI ratio. Specifically, we propose a
dataset, HACo-Det, which produces human-AI coauthored texts via an automatic
pipeline with word-level attribution labels. We retrofit seven prevailing
document-level detectors to generalize them to word-level detection. Then we
evaluate these detectors on HACo-Det on both word- and sentence-level detection
tasks. Empirical results show that metric-based methods struggle to conduct
fine-grained detection with a 0.462 average F1 score, while finetuned models
show superior performance and better generalization across domains. However, we
argue that fine-grained co-authored text detection is far from solved. We
further analyze factors influencing performance, e.g., context window, and
highlight the limitations of current methods, pointing to potential avenues for
improvement.

</details>


### [89] [FlowerTune: A Cross-Domain Benchmark for Federated Fine-Tuning of Large Language Models](https://arxiv.org/abs/2506.02961)
*Yan Gao,Massimo Roberto Scamarcia,Javier Fernandez-Marques,Mohammad Naseri,Chong Shen Ng,Dimitris Stripelis,Zexi Li,Tao Shen,Jiamu Bai,Daoyuan Chen,Zikai Zhang,Rui Hu,InSeo Song,Lee KangYoon,Hong Jia,Ting Dang,Junyan Wang,Zheyuan Liu,Daniel Janes Beutel,Lingjuan Lyu,Nicholas D. Lane*

Main category: cs.CL

TL;DR: 通过联邦学习框架FlowerTune LLM Leaderboard评估26个大语言模型在隐私保护场景下的领域适应能力


<details>
  <summary>Details</summary>
Motivation: 解决大模型训练依赖公开数据导致的领域敏感数据获取难题，探索联邦学习在LLM微调中的兼容性问题

Method: 创建跨NLP/金融/医疗/编程四大领域的联邦指令微调数据集，采用社区协作方式测试不同聚合策略和微调方案

Result: 首次系统性比较不同模型在联邦学习环境下的性能表现，揭示计算资源约束与领域适应性的关键平衡点

Conclusion: 为开发隐私安全的领域专用大模型奠定基础，推动现实场景中联邦学习与LLM的深度整合应用

Abstract: Large Language Models (LLMs) have achieved state-of-the-art results across
diverse domains, yet their development remains reliant on vast amounts of
publicly available data, raising concerns about data scarcity and the lack of
access to domain-specific, sensitive information. Federated Learning (FL)
presents a compelling framework to address these challenges by enabling
decentralized fine-tuning on pre-trained LLMs without sharing raw data.
However, the compatibility and performance of pre-trained LLMs in FL settings
remain largely under explored. We introduce the FlowerTune LLM Leaderboard, a
first-of-its-kind benchmarking suite designed to evaluate federated fine-tuning
of LLMs across four diverse domains: general NLP, finance, medical, and coding.
Each domain includes federated instruction-tuning datasets and domain-specific
evaluation metrics. Our results, obtained through a collaborative, open-source
and community-driven approach, provide the first comprehensive comparison
across 26 pre-trained LLMs with different aggregation and fine-tuning
strategies under federated settings, offering actionable insights into model
performance, resource constraints, and domain adaptation. This work lays the
foundation for developing privacy-preserving, domain-specialized LLMs for
real-world applications.

</details>


### [90] [Expanding before Inferring: Enhancing Factuality in Large Language Models through Premature Layers Interpolation](https://arxiv.org/abs/2506.02973)
*Dingwei Chen,Ziqiang Liu,Feiteng Fang,Chak Tou Leong,Shiwen Ni,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang,Chengming Li*

Main category: cs.CL

TL;DR: 提出PLI方法，通过数学插值在相邻层间插入未成熟层，无需训练即可有效减少大语言模型的事实性幻觉


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略模型内部信息精炼过程，微调方法资源消耗大，需要更本质的干预手段

Method: 受稳定扩散启发，对相邻层参数进行数学插值形成未成熟层，延长信息处理路径

Result: 在四个公开数据集上超越现有基线，幻觉率平均降低12.8%，推理速度保持90%

Conclusion: 层插值机制与LLM内部工作机制高度相关，该方法为模型优化提供新方向，承诺开源代码数据

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities in text
understanding and generation. However, their tendency to produce factually
inconsistent outputs, commonly referred to as ''hallucinations'', remains a
critical challenge. Existing approaches, such as retrieval-based and
inference-time correction methods, primarily address this issue at the input or
output level, often overlooking the intrinsic information refinement process
and the role of premature layers. Meanwhile, alignment- and fine-tuning-based
methods are resource-intensive. In this paper, we propose PLI (Premature Layers
Interpolation), a novel, training-free, and plug-and-play intervention designed
to enhance factuality. PLI mitigates hallucinations by inserting premature
layers formed through mathematical interpolation with adjacent layers. Inspired
by stable diffusion and sampling steps, PLI extends the depth of information
processing and transmission in LLMs, improving factual coherence. Experiments
on four publicly available datasets demonstrate that PLI effectively reduces
hallucinations while outperforming existing baselines in most cases. Further
analysis suggests that the success of layer interpolation is closely linked to
LLMs' internal mechanisms. To promote reproducibility, we will release our code
and data upon acceptance.

</details>


### [91] [Towards a Japanese Full-duplex Spoken Dialogue System](https://arxiv.org/abs/2506.02979)
*Atsumoto Ohashi,Shinya Iizuka,Jingjing Jiang,Ryuichiro Higashinaka*

Main category: cs.CL

TL;DR: 开发了首个日语全双工语音对话模型，基于英文模型Moshi改进，通过两阶段训练和合成数据增强，效果优于日语基线模型


<details>
  <summary>Details</summary>
Motivation: 填补日语全双工对话系统研究的空白，解决现有研究中日语模型匮乏的问题，实现类似人类对话的语音重叠和反馈功能

Method: 两阶段训练流程：先在大规模日语语音数据上预训练，再通过高质量立体声对话数据微调；使用多流文本转语音系统生成合成对话数据增强性能

Result: 评估实验显示该模型在自然度和语义连贯性方面均超越日语基线模型

Conclusion: 成功验证了将英语模型迁移到日语的技术路径，证明数据增强和分阶段训练策略在构建非英语全双工对话系统中的有效性，为其他语言类似系统的开发提供参考

Abstract: Full-duplex spoken dialogue systems, which can model simultaneous
bidirectional features of human conversations such as speech overlaps and
backchannels, have attracted significant attention recently. However, the study
of full-duplex spoken dialogue systems for the Japanese language has been
limited, and the research on their development in Japanese remains scarce. In
this paper, we present the first publicly available full-duplex spoken dialogue
model in Japanese, which is built upon Moshi, a full-duplex dialogue model in
English. Our model is trained through a two-stage process: pre-training on a
large-scale spoken dialogue data in Japanese, followed by fine-tuning on
high-quality stereo spoken dialogue data. We further enhance the model's
performance by incorporating synthetic dialogue data generated by a
multi-stream text-to-speech system. Evaluation experiments demonstrate that the
trained model outperforms Japanese baseline models in both naturalness and
meaningfulness.

</details>


### [92] [Performance of leading large language models in May 2025 in Membership of the Royal College of General Practitioners-style examination questions: a cross-sectional analysis](https://arxiv.org/abs/2506.02987)
*Richard Armitage*

Main category: cs.CL

TL;DR: 领先的大型语言模型在MRCGP考试题中表现优异（o3达99%），显著超越人类同行73%平均分，验证其在初级保健中的支持潜力。


<details>
  <summary>Details</summary>
Motivation: 测试2025年5月主流LLMs（o3/Claude Opus 4/Grok3/Gemini 2.5 Pro）在初级保健教育场景下的MRCGP考试应答能力，填补推理模型在基层医疗领域的评估空白。

Method: 使用皇家全科医师学院100道随机多选题（含文本/实验室数据/临床图像），模拟英国全科医生角色单次作答，对比标准答案计分。

Result: o3得分99%居首，其他模型均为95%，所有模型均大幅超过人类同行73%平均分。

Conclusion: 推理类LLMs（尤其是经过初级保健数据专门训练者）可有效支持基层医疗服务，模型性能已具备临床实用价值。

Abstract: Background: Large language models (LLMs) have demonstrated substantial
potential to support clinical practice. Other than Chat GPT4 and its
predecessors, few LLMs, especially those of the leading and more powerful
reasoning model class, have been subjected to medical specialty examination
questions, including in the domain of primary care. This paper aimed to test
the capabilities of leading LLMs as of May 2025 (o3, Claude Opus 4, Grok3, and
Gemini 2.5 Pro) in primary care education, specifically in answering Member of
the Royal College of General Practitioners (MRCGP) style examination questions.
  Methods: o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro were tasked to answer
100 randomly chosen multiple choice questions from the Royal College of General
Practitioners GP SelfTest on 25 May 2025. Questions included textual
information, laboratory results, and clinical images. Each model was prompted
to answer as a GP in the UK and was provided with full question information.
Each question was attempted once by each model. Responses were scored against
correct answers provided by GP SelfTest.
  Results: The total score of o3, Claude Opus 4, Grok3, and Gemini 2.5 Pro was
99.0%, 95.0%, 95.0%, and 95.0%, respectively. The average peer score for the
same questions was 73.0%.
  Discussion: All models performed remarkably well, and all substantially
exceeded the average performance of GPs and GP registrars who had answered the
same questions. o3 demonstrated the best performance, while the performances of
the other leading models were comparable with each other and were not
substantially lower than that of o3. These findings strengthen the case for
LLMs, particularly reasoning models, to support the delivery of primary care,
especially those that have been specifically trained on primary care clinical
data.

</details>


### [93] [It's Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems](https://arxiv.org/abs/2506.02995)
*Iuliia Zaitova,Badr M. Abdullah,Wei Xue,Dietrich Klakow,Bernd Möbius,Tania Avgustinova*

Main category: cs.CL

TL;DR: 语音到文本翻译系统在习语翻译中存在显著性能下降，而机器翻译系统和大型语言模型表现更优，需改进SLT架构的习语处理策略


<details>
  <summary>Details</summary>
Motivation: 现代机器翻译在常规文本处理上取得进展，但习语翻译仍是挑战，尤其在语音到文本翻译领域缺乏系统研究。研究旨在对比不同系统在习语翻译中的表现差异

Method: 系统评估德语/俄语-英语的双向翻译，对比端到端语音翻译系统（SeamlessM4T、Whisper）、机器翻译系统（NLLB）、大语言模型（DeepSeek、LLaMA）和级联系统的表现

Result: 语音翻译系统出现显著性能下降（倾向于直译），机器翻译系统和大语言模型能更好处理习语，深层网络分析显示语音系统在高层仍保留字面特征

Conclusion: 语音到文本翻译架构需要开发习语专用策略并改进内部表征，研究为提升跨模态翻译系统的语言敏感性提供了方向

Abstract: Idioms are defined as a group of words with a figurative meaning not
deducible from their individual components. Although modern machine translation
systems have made remarkable progress, translating idioms remains a major
challenge, especially for speech-to-text systems, where research on this topic
is notably sparse. In this paper, we systematically evaluate idiom translation
as compared to conventional news translation in both text-to-text machine
translation (MT) and speech-to-text translation (SLT) systems across two
language pairs (German to English, Russian to English). We compare
state-of-the-art end-to-end SLT systems (SeamlessM4T SLT-to-text, Whisper Large
v3) with MT systems (SeamlessM4T SLT-to-text, No Language Left Behind), Large
Language Models (DeepSeek, LLaMA) and cascaded alternatives. Our results reveal
that SLT systems experience a pronounced performance drop on idiomatic data,
often reverting to literal translations even in higher layers, whereas MT
systems and Large Language Models demonstrate better handling of idioms. These
findings underscore the need for idiom-specific strategies and improved
internal representations in SLT architectures.

</details>


### [94] [A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems](https://arxiv.org/abs/2506.02998)
*Đorđe Klisura,Astrid R Bernaga Torres,Anna Karen Gárate-Escamilla,Rajesh Roshan Biswal,Ke Yang,Hilal Pataci,Anthony Rios*

Main category: cs.CL

TL;DR: 提出多智能体框架解决隐私政策QA系统的方言偏差问题，通过方言代理和领域专家代理协作，在不重新训练模型的情况下显著提升GPT-4o-mini在不同方言数据集上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有隐私政策问答系统存在英语方言间的性能差异，非标准方言用户难以公平获取隐私信息。需要无需重新训练/方言微调的通用解决方案。

Method: 双代理架构：1) 方言代理转换方言查询为标准英语；2) 隐私政策代理结合领域知识优化预测。框架具备模型无关性，兼容现有QA模型。

Result: PrivacyQA准确率从0.394→0.601，PolicyQA从0.352→0.464，零样本性能超越少样本基准。

Conclusion: 结构化代理协作有效缓解方言偏差，强调NLP系统需考虑语言多样性以实现隐私信息公平获取。

Abstract: Privacy policies inform users about data collection and usage, yet their
complexity limits accessibility for diverse populations. Existing Privacy
Policy Question Answering (QA) systems exhibit performance disparities across
English dialects, disadvantaging speakers of non-standard varieties. We propose
a novel multi-agent framework inspired by human-centered design principles to
mitigate dialectal biases. Our approach integrates a Dialect Agent, which
translates queries into Standard American English (SAE) while preserving
dialectal intent, and a Privacy Policy Agent, which refines predictions using
domain expertise. Unlike prior approaches, our method does not require
retraining or dialect-specific fine-tuning, making it broadly applicable across
models and domains. Evaluated on PrivacyQA and PolicyQA, our framework improves
GPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from
0.352 to 0.464 on PolicyQA, surpassing or matching few-shot baselines without
additional training data. These results highlight the effectiveness of
structured agent collaboration in mitigating dialect biases and underscore the
importance of designing NLP systems that account for linguistic diversity to
ensure equitable access to privacy information.

</details>


### [95] [Conditioning Large Language Models on Legal Systems? Detecting Punishable Hate Speech](https://arxiv.org/abs/2506.03009)
*Florian Ludwig,Torsten Zesch,Frederike Zufall*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在不同法律抽象层次条件下，对德国刑法中煽动仇恨言论的识别能力与法律专家存在显著差距：抽象法律知识模型易自相矛盾，具体法律知识模型擅长识别目标群体但难分类行为


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型对法律体系不同抽象层次（宪法-成文法-判例法）的内化程度，及其在刑事犯罪分类任务中的实际应用潜力

Method: 通过多层级法律知识条件化方法，以德国刑法第130条煽动仇恨罪为基准，评估模型对社交媒体帖子是否构成犯罪行为的分类能力

Result: 模型整体表现显著低于法律专家：抽象知识模型出现73%的逻辑矛盾，具体知识模型目标群体识别准确率达82%，但目标行为分类准确率仅59%

Conclusion: 当前LLMs在法律应用中存在系统局限性，需结合法律知识图谱与领域微调来提升对目标行为要素的理解和推理一致性

Abstract: The assessment of legal problems requires the consideration of a specific
legal system and its levels of abstraction, from constitutional law to
statutory law to case law. The extent to which Large Language Models (LLMs)
internalize such legal systems is unknown. In this paper, we propose and
investigate different approaches to condition LLMs at different levels of
abstraction in legal systems. This paper examines different approaches to
conditioning LLMs at multiple levels of abstraction in legal systems to detect
potentially punishable hate speech. We focus on the task of classifying whether
a specific social media posts falls under the criminal offense of incitement to
hatred as prescribed by the German Criminal Code. The results show that there
is still a significant performance gap between models and legal experts in the
legal assessment of hate speech, regardless of the level of abstraction with
which the models were conditioned. Our analysis revealed, that models
conditioned on abstract legal knowledge lacked deep task understanding, often
contradicting themselves and hallucinating answers, while models using concrete
legal knowledge performed reasonably well in identifying relevant target
groups, but struggled with classifying target conducts.

</details>


### [96] [Coding Agents with Multimodal Browsing are Generalist Problem Solvers](https://arxiv.org/abs/2506.03011)
*Aditya Bharat Soni,Boxuan Li,Xingyao Wang,Valerie Chen,Graham Neubig*

Main category: cs.CL

TL;DR: 提出通用智能体OpenHands-Versa，通过代码编辑、网络搜索等基础工具组合，在多项基准测试中超越专用智能体，证明通用代理的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有专用AI代理在跨领域泛化能力不足，需探索最小通用工具集实现多任务高性能。

Method: 构建包含代码编辑执行、网络搜索、多模态浏览和文件访问的基础工具组合OpenHands-Versa。

Result: 在SWE-Bench Multimodal/GAIA/Agent Company测试中，成功率分别提升9.1/1.3/9.1个百分点，超越领域专用代理。

Conclusion: 验证了通用智能体的可行性，揭示了现有多智能体系统的领域局限性，为后续研究建立基准。

Abstract: Modern human labor is characterized by specialization; we train for years and
develop particular tools that allow us to perform well across a variety of
tasks. In addition, AI agents have been specialized for domains such as
software engineering, web navigation, and workflow automation. However, this
results in agents that are good for one thing but fail to generalize beyond
their intended scope. One reason for this is that agent developers provide a
highly specialized set of tools or make architectural decisions optimized for a
specific use case or benchmark. In this work, we ask the question: what is the
minimal set of general tools that can be used to achieve high performance
across a diverse set of tasks? Our answer is OpenHands-Versa, a generalist
agent built with a modest number of general tools: code editing and execution,
web search, as well as multimodal web browsing and file access. Importantly,
OpenHands-Versa demonstrates superior or competitive performance over leading
specialized agents across three diverse and challenging benchmarks: SWE-Bench
Multimodal, GAIA, and The Agent Company, outperforming the best-performing
previously published results with absolute improvements in success rate of 9.1,
1.3, and 9.1 points respectively. Further, we show how existing
state-of-the-art multi-agent systems fail to generalize beyond their target
domains. These results demonstrate the feasibility of developing a generalist
agent to solve diverse tasks and establish OpenHands-Versa as a strong baseline
for future research.

</details>


### [97] [Leveraging Information Retrieval to Enhance Spoken Language Understanding Prompts in Few-Shot Learning](https://arxiv.org/abs/2506.03035)
*Pierre Lepagnol,Sahar Ghannay,Thomas Gerald,Christophe Servan,Sophie Rosset*

Main category: cs.CL

TL;DR: 提出通过信息检索(IR)方法选择示例构建增强提示，显著提升语音语言理解(SLU)任务性能，且不增加提示长度。


<details>
  <summary>Details</summary>
Motivation: 现有SLU技术依赖大量标注数据，但特定领域/语言数据有限。指令调优的LLMs在少样本场景展现潜力，但需要有效提示策略。

Method: 采用信息检索技术选择相关示例构建增强提示，在多个SLU基准测试中验证不同IR方法的效果。

Result: 实验表明词汇级IR方法显著提升模型性能(具体指标未提及)，且保持提示长度不变。

Conclusion: 结合IR的提示工程能有效提升LLMs在低资源SLU任务的表现，为实际应用提供高效解决方案。

Abstract: Understanding user queries is fundamental in many applications, such as home
assistants, booking systems, or recommendations. Accordingly, it is crucial to
develop accurate Spoken Language Understanding (SLU) approaches to ensure the
reliability of the considered system. Current State-of-the-Art SLU techniques
rely on large amounts of training data; however, only limited annotated
examples are available for specific tasks or languages.
  In the meantime, instruction-tuned large language models (LLMs) have shown
exceptional performance on unseen tasks in a few-shot setting when provided
with adequate prompts. In this work, we propose to explore example selection by
leveraging Information retrieval (IR) approaches to build an enhanced prompt
that is applied to an SLU task. We evaluate the effectiveness of the proposed
method on several SLU benchmarks. Experimental results show that lexical IR
methods significantly enhance performance without increasing prompt length.

</details>


### [98] [Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective](https://arxiv.org/abs/2506.03038)
*Jintian Shao,Yiming Cheng*

Main category: cs.CL

TL;DR: 论文探讨RL增强LLMs长链推理时VAPO框架在长期价值建模的理论局限，分析信用分配、价值函数表征和信号转化三大挑战


<details>
  <summary>Details</summary>
Motivation: 揭示VAPO框架在长推理链中建模深度价值信号的固有缺陷，推动对RL方法局限性的理解及LLM智能体改进方向

Method: 通过理论分析信用分配机制、价值函数对时序抽象目标的表征能力，以及稀疏奖励下全局价值信号到局部策略的转化机制

Result: 识别VAPO在长期价值建模中的三大核心限制：信用分配难题、价值函数表征力不足、全局信号局部化效率低下

Conclusion: 当前RL方法需突破长期价值建模瓶颈，未来应探索结合时序抽象表征与分层强化学习的新范式来提升LLM推理能力

Abstract: Reinforcement learning (RL) enhances large language models (LLMs) in complex,
long-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework,
despite sophisticated mechanisms like Decoupled GAE, theoretically faces
fundamental limitations in comprehensively modeling and leveraging deep,
long-term value for fine-grained, step-by-step policy guidance in extended
reasoning chains. We argue these limitations stem from inherent difficulties in
credit assignment, value function representational capacity with temporally
abstracted goals, and translating global value signals into local policy
improvements, especially with sparse rewards. Our theoretical analysis examines
these aspects to illuminate VAPO's boundaries in long-term value modeling,
aiming to deepen understanding of current RL for advanced reasoning and suggest
future research for more robust LLM agents.

</details>


### [99] [Facts Do Care About Your Language: Assessing Answer Quality of Multilingual LLMs](https://arxiv.org/abs/2506.03051)
*Yuval Kansal,Shmuel Berman,Lydia Liu*

Main category: cs.CL

TL;DR: 研究发现Llama3.1系列模型在多语言教育场景中存在事实性不足与语言偏见问题


<details>
  <summary>Details</summary>
Motivation: 确保LLMs在多语言教育工具中的事实准确性，特别针对非英语/稀有语言场景的可靠性验证

Method: 通过中学生难度的事实性问题测试，评估Llama3.1模型的多语言输出质量与偏见程度

Result: 模型不仅产生冗余错误信息，且对稀有语言表现出显著偏见（准确率下降23.7%）

Conclusion: 教育领域应用LLMs需强化多语言事实校验机制，并建立针对低资源语言的偏见缓解方案

Abstract: Factuality is a necessary precursor to useful educational tools. As adoption
of Large Language Models (LLMs) in education continues of grow, ensuring
correctness in all settings is paramount. Despite their strong English
capabilities, LLM performance in other languages is largely untested. In this
work, we evaluate the correctness of the Llama3.1 family of models in answering
factual questions appropriate for middle and high school students. We
demonstrate that LLMs not only provide extraneous and less truthful
information, but also exacerbate existing biases against rare languages.

</details>


### [100] [Literary Evidence Retrieval via Long-Context Language Models](https://arxiv.org/abs/2506.03090)
*Katherine Thai,Mohit Iyyer*

Main category: cs.CL

TL;DR: 现代大语言模型在文学证据检索任务中展现显著性能差距：Gemini Pro 2.5超越人类专家（62.5% vs 50%），而最佳开源模型仅29.1%


<details>
  <summary>Details</summary>
Motivation: 评估长上下文语言模型对文学小说的理解能力，通过构建文学证据检索任务模拟人类文学分析过程

Method: 重构RELiC数据集构建基准测试（292个样本），要求模型基于完整文本补全文学评论中的缺失引用，需结合全局叙事推理与细粒度文本分析

Result: 闭源模型Gemini Pro 2.5准确率62.5%（人类专家50%），最佳开源模型仅29.1%；模型普遍存在文学信号理解不足与过度生成问题

Conclusion: 语言模型在文学分析领域展现潜力但存在明显局限，公开数据集与评估框架促进该领域发展

Abstract: How well do modern long-context language models understand literary fiction?
We explore this question via the task of literary evidence retrieval,
repurposing the RELiC dataset of That et al. (2022) to construct a benchmark
where the entire text of a primary source (e.g., The Great Gatsby) is provided
to an LLM alongside literary criticism with a missing quotation from that work.
This setting, in which the model must generate the missing quotation, mirrors
the human process of literary analysis by requiring models to perform both
global narrative reasoning and close textual examination. We curate a
high-quality subset of 292 examples through extensive filtering and human
verification. Our experiments show that recent reasoning models, such as Gemini
Pro 2.5 can exceed human expert performance (62.5% vs. 50% accuracy). In
contrast, the best open-weight model achieves only 29.1% accuracy, highlighting
a wide gap in interpretive reasoning between open and closed-weight models.
Despite their speed and apparent accuracy, even the strongest models struggle
with nuanced literary signals and overgeneration, signaling open challenges for
applying LLMs to literary analysis. We release our dataset and evaluation code
to encourage future work in this direction.

</details>


### [101] [Beyond Text Compression: Evaluating Tokenizers Across Scales](https://arxiv.org/abs/2506.03101)
*Jonas F. Lotz,António V. Lopes,Stephan Peitz,Hendra Setiawan,Leonardo Emili*

Main category: cs.CL

TL;DR: 通过小模型预测分词器对大型模型的影响，提出结合Zipf定律的多维度评估框架，实现高效分词器选择


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高效可靠的分词器评估方法，特别是在多语言场景中需要更有效的评估标准

Method: 利用扩展一致性原理，结合英语/多语言分词器系统评估，开发基于Zipf定律的新评估指标组合

Result: 多语言任务性能差异显著（英语影响小），新指标比文本压缩率更强相关，验证框架有效性

Conclusion: 多维度指标评估框架为语言模型开发提供了高效的分词器选择方法论

Abstract: The choice of tokenizer can profoundly impact language model performance, yet
accessible and reliable evaluations of tokenizer quality remain an open
challenge. Inspired by scaling consistency, we show that smaller models can
accurately predict significant differences in tokenizer impact on larger models
at a fraction of the compute cost. By systematically evaluating both
English-centric and multilingual tokenizers, we find that tokenizer choice has
negligible effects on tasks in English but results in consistent performance
differences in multilingual settings. We propose new intrinsic tokenizer
metrics inspired by Zipf's law that correlate more strongly with downstream
performance than text compression when modeling unseen languages. By combining
several metrics to capture multiple aspects of tokenizer behavior, we develop a
reliable framework for intrinsic tokenizer evaluations. Our work offers a more
efficient path to informed tokenizer selection in future language model
development.

</details>


### [102] [Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback](https://arxiv.org/abs/2506.03106)
*Xiaoying Zhang,Hao Sun,Yipeng Zhang,Kaituo Feng,Chao Yang,Helen Meng*

Main category: cs.CL

TL;DR: 提出Critique-GRPO强化学习框架，通过融合自然语言反馈与数值反馈，有效解决RL训练中的性能瓶颈问题，在多个推理任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统数值反馈强化学习存在性能瓶颈、自我反思能力有限和持续失败三大问题，研究发现自然语言反馈能帮助模型突破瓶颈改进失败案例

Method: Critique-GRPO框架：1）同步利用初始响应和基于批判的改进样本 2）保持探索机制 3）整合自然语言批判与数值奖励的双重反馈

Result: 在8个数学/STEM/通用推理任务中：1）比监督学习微调提升4.5% 2）比纯RL方法提升5% 3）优于融合专家示范的强基线

Conclusion: 发现：1）高熵值不保证有效探索 2）长响应未必提升探索效率，需平衡探索质量与响应长度

Abstract: Recent advances in reinforcement learning (RL) with numerical feedback, such
as scalar rewards, have significantly enhanced the complex reasoning
capabilities of large language models (LLMs). Despite this success, we identify
three key challenges encountered by RL with solely numerical feedback:
performance plateaus, limited effectiveness of self-reflection, and persistent
failures. We then demonstrate that RL-finetuned models, even after exhibiting
performance plateaus, can generate correct refinements on persistently failed
problems by leveraging natural language feedback in the form of critiques.
Building on this insight, we propose Critique-GRPO, an online RL framework that
integrates both natural language and numerical feedback for effective policy
optimization. Critique-GRPO enables LLMs to learn from initial responses and
critique-guided refinements simultaneously while maintaining exploration.
Extensive experiments using Qwen2.5-7B-Base and Qwen3-8B-Base show that
Critique-GRPO consistently outperforms supervised learning-based and RL-based
fine-tuning approaches across eight challenging mathematical, STEM, and general
reasoning tasks, improving average pass@1 scores by approximately 4.5% and 5%,
respectively. Notably, Critique-GRPO surpasses a strong baseline that
incorporates expert demonstrations within online RL. Further analysis reveals
two critical insights about policy exploration: (1) higher entropy does not
always guarantee efficient learning from exploration, and (2) longer responses
do not necessarily lead to more effective exploration.

</details>


### [103] [AUTOCIRCUIT-RL: Reinforcement Learning-Driven LLM for Automated Circuit Topology Generation](https://arxiv.org/abs/2506.03122)
*Prashanth Vijayaraghavan,Luyao Shi,Ehsan Degan,Vandana Mukherjee,Xin Zhang*

Main category: cs.CL

TL;DR: AUTOCIRCUIT-RL是一个基于强化学习的自动化模拟电路综合框架，通过指令调整与奖励模型优化，显著提升电路生成效率与有效性。


<details>
  <summary>Details</summary>
Motivation: 传统EDA工具面临巨大设计空间与严格约束的挑战，利用LLM的泛化能力结合强化学习，实现高效且符合约束的电路拓扑生成。

Method: 1. 指令调整阶段：LLM从结构化提示学习生成电路拓扑；2. RL优化阶段：使用评估有效性/效率/输出电压的奖励模型精调模型。

Result: 生成有效电路数量比基线高12%，效率提升14%，重复率降低38%，数据有限时仍实现超60%有效电路生成成功率。

Conclusion: 该框架在保持效率的同时可扩展至复杂电路，标志着AI驱动电路设计的重要进展。

Abstract: Analog circuit topology synthesis is integral to Electronic Design Automation
(EDA), enabling the automated creation of circuit structures tailored to
specific design requirements. However, the vast design search space and strict
constraint adherence make efficient synthesis challenging. Leveraging the
versatility of Large Language Models (LLMs), we propose AUTOCIRCUIT-RL,a novel
reinforcement learning (RL)-based framework for automated analog circuit
synthesis. The framework operates in two phases: instruction tuning, where an
LLM learns to generate circuit topologies from structured prompts encoding
design constraints, and RL refinement, which further improves the
instruction-tuned model using reward models that evaluate validity, efficiency,
and output voltage. The refined model is then used directly to generate
topologies that satisfy the design constraints. Empirical results show that
AUTOCIRCUIT-RL generates ~12% more valid circuits and improves efficiency by
~14% compared to the best baselines, while reducing duplicate generation rates
by ~38%. It achieves over 60% success in synthesizing valid circuits with
limited training data, demonstrating strong generalization. These findings
highlight the framework's effectiveness in scaling to complex circuits while
maintaining efficiency and constraint adherence, marking a significant
advancement in AI-driven circuit design.

</details>


### [104] [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](https://arxiv.org/abs/2506.03136)
*Yinjie Wang,Ling Yang,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: 提出CURE强化学习框架，通过协同进化编码与单元测试能力提升代码生成性能，优化后在多个指标超越同类模型


<details>
  <summary>Details</summary>
Motivation: 解决现有代码生成模型缺乏与单元测试动态交互的问题，通过无监督协同进化实现更灵活的缺陷修正

Method: 基于强化学习的奖励机制设计，让编码器与测试生成器通过错误反馈相互优化，支持动态训练流程扩展

Result: Qwen2.5模型优化后代码生成准确率提升5.3%，Best-of-N提升9%；下游任务改进8.1%，推理效率达64.8%

Conclusion: 模型兼具测试生成与奖励建模能力，验证了协同进化机制的有效性，项目已开源（github.com/Gen-Verse/CURE）

Abstract: We propose CURE, a novel reinforcement learning framework with a dedicated
reward design that co-evolves coding and unit test generation capabilities
based on their interaction outcomes, without any ground-truth code as
supervision. This approach enables flexible and scalable training and allows
the unit tester to learn directly from the coder's mistakes. Our derived
ReasonFlux-Coder-7B and 14B models improve code generation accuracy by 5.3% and
Best-of-N accuracy by 9.0% after optimization on Qwen2.5-Instruct models,
outperforming similarly sized Qwen-Coder, DeepSeek-Coder, and Seed-Coder. They
naturally extend to downstream tasks such as test-time scaling and agentic
coding-achieving a 8.1% improvement over the base model. For the long-CoT
model, our ReasonFlux-Coder-4B consistently outperforms Qwen3-4B while
achieving 64.8% inference efficiency in unit test generation. Notably, we also
find that our model can serve as an effective reward model for reinforcement
learning on base models. Project: https://github.com/Gen-Verse/CURE

</details>


### [105] [GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents](https://arxiv.org/abs/2506.03143)
*Qianhui Wu,Kanzhi Cheng,Rui Yang,Chaoyun Zhang,Jianwei Yang,Huiqiang Jiang,Jian Mu,Baolin Peng,Bo Qiao,Reuben Tan,Si Qin,Lars Liden,Qingwei Lin,Huan Zhang,Tong Zhang,Jianbing Zhang,Dongmei Zhang,Jianfeng Gao*

Main category: cs.CL

TL;DR: 提出GUI-Actor方法解决VLM驱动的GUI代理视觉定位问题，通过注意力机制和验证器实现高效区域定位，在保持VLM通用能力的同时显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有基于坐标生成的视觉定位方法存在空间-语义对齐弱、无法处理模糊监督目标、视觉特征粒度与坐标密集性不匹配三大缺陷

Method: 设计注意力动作头实现<ACTOR>标记与视觉块的语义对齐，开发候选区域验证器，支持仅微调动作头（约1亿参数）的参数高效训练方案

Result: 在ScreenSpot-Pro基准上，Qwen2.5-VL版本达到44.6分超越UI-TARS-72B（38.1）；仅微调动作头即可达到SOTA性能

Conclusion: GUI-Actor在不牺牲VLM通用能力的前提下，通过模块化设计有效增强了视觉定位能力，为构建高效GUI代理提供了新思路

Abstract: One of the principal challenges in building VLM-powered GUI agents is visual
grounding, i.e., localizing the appropriate screen region for action execution
based on both the visual content and the textual plans. Most existing work
formulates this as a text-based coordinate generation task. However, these
approaches suffer from several limitations: weak spatial-semantic alignment,
inability to handle ambiguous supervision targets, and a mismatch between the
dense nature of screen coordinates and the coarse, patch-level granularity of
visual features extracted by models like Vision Transformers. In this paper, we
propose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its
core, GUI-Actor introduces an attention-based action head that learns to align
a dedicated <ACTOR> token with all relevant visual patch tokens, enabling the
model to propose one or more action regions in a single forward pass. In line
with this, we further design a grounding verifier to evaluate and select the
most plausible action region from the candidates proposed for action execution.
Extensive experiments show that GUI-Actor outperforms prior state-of-the-art
methods on multiple GUI action grounding benchmarks, with improved
generalization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B
even surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7
with Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by
incorporating the verifier, we find that fine-tuning only the newly introduced
action head (~100M parameters for 7B model) while keeping the VLM backbone
frozen is sufficient to achieve performance comparable to previous
state-of-the-art models, highlighting that GUI-Actor can endow the underlying
VLM with effective grounding capabilities without compromising its
general-purpose strengths.

</details>


### [106] [Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM](https://arxiv.org/abs/2506.03145)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CL

TL;DR: 提出利用LLM、神经科学本体论和文本嵌入构建无标注神经科学知识图谱的方法，显著提升知识发现效果


<details>
  <summary>Details</summary>
Motivation: 现有神经科学知识检索方法难以整合分散知识，传统知识图谱构建依赖标注数据和领域专家，在专业领域获取大规模标注数据困难

Method: 1. 使用LLM分析神经科学文本语义相关性
2. 结合领域本体论和文本嵌入构建知识图谱
3. 开发实体增强的信息检索算法

Result: 实体提取F1值达0.84，知识图谱改进54%问题的回答质量

Conclusion: 该方法有效解决无标注数据下的知识整合问题，显著提升神经科学文献的知识发现效率

Abstract: Neuroscience research publications encompass a vast wealth of knowledge.
Accurately retrieving existing information and discovering new insights from
this extensive literature is essential for advancing the field. However, when
knowledge is dispersed across multiple sources, current state-of-the-art
retrieval methods often struggle to extract the necessary information. A
knowledge graph (KG) can integrate and link knowledge from multiple sources,
but existing methods for constructing KGs in neuroscience often rely on labeled
data and require domain expertise. Acquiring large-scale, labeled data for a
specialized area like neuroscience presents significant challenges. This work
proposes novel methods for constructing KG from unlabeled large-scale
neuroscience research corpus utilizing large language models (LLM),
neuroscience ontology, and text embeddings. We analyze the semantic relevance
of neuroscience text segments identified by LLM for building the knowledge
graph. We also introduce an entity-augmented information retrieval algorithm to
extract knowledge from the KG. Several experiments were conducted to evaluate
the proposed approaches, and the results demonstrate that our methods
significantly enhance knowledge discovery from the unlabeled neuroscience
research corpus. It achieves an F1 score of 0.84 for entity extraction, and the
knowledge obtained from the KG improves answers to over 54% of the questions.

</details>


### [107] [Causal Estimation of Tokenisation Bias](https://arxiv.org/abs/2506.03149)
*Pietro Lesci,Clara Meister,Thomas Hofmann,Andreas Vlachos,Tiago Pimentel*

Main category: cs.CL

TL;DR: 研究发现分词器词汇表的选择会显著影响语言模型对字符序列的概率分配（最高达17倍），揭示了分词偏差是语言建模的关键设计因素


<details>
  <summary>Details</summary>
Motivation: 现有语言模型基于子词训练但生成字符序列，理论上分词器选择不应影响字符概率，但实践中存在偏差。本文旨在量化这种分词偏差的具体影响机制

Method: 将分词偏差定义为因果效应，采用回归断点设计，通过分析分词器词汇表截断点附近子词的模型表现差异进行量化

Result: 不同规模/词汇表/分词器的模型均显示显著分词偏差，小模型中子词存在可使字符概率提升最高达17倍

Conclusion: 分词器设计是语言建模的核心技术选择，其词汇表决策直接影响模型行为，需作为关键因素纳入模型开发考量

Abstract: Modern language models are typically trained over subword sequences, but
ultimately define probabilities over character-strings. Ideally, the choice of
the tokeniser -- which maps character-strings to subwords -- should not affect
the probability assigned to the underlying character-string; in practice, it
does. We define this mismatch as tokenisation bias. In this work, we quantify
one particular type of tokenisation bias: the effect of including or not a
subword (e.g., $\langle hello \rangle$) in a tokeniser's vocabulary on the
probability a trained model assigns to the corresponding characters (i.e.,
\textit{``hello''}). Estimating this effect is challenging because each model
is trained with only one tokeniser. We address this by framing tokenisation
bias as a causal effect and estimating it using the regression discontinuity
design. Specifically, we exploit the fact that tokenisation algorithms rank
subwords and add the first $K$ to a tokeniser's vocabulary, where $K$ is an
arbitrary cutoff point. As such, we can estimate a causal effect by comparing
similar subwords around this cutoff. Experimentally, we find that tokenisation
consistently affects models' outputs across scales, vocabularies, and
tokenisers. Notably, a subword's presence in a small model's vocabulary may
increase its characters' probability by up to 17 times, highlighting
tokenisation as a key design choice in language modelling.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [108] [High-throughput viscometry via machine-learning from videos of inverted vials](https://arxiv.org/abs/2506.02034)
*Ignacio Arretche,Mohammad Tanver Hossain,Ramdas Tiwari,Abbie Kim,Mya G. Mills,Connor D. Armstrong,Jacob J. Lessard,Sameh H. Tawfick,Randy H. Ewoldt*

Main category: cs.GR

TL;DR: 开发基于计算机视觉的自动化倒置瓶粘度计，通过神经网络分析流体运动视频实现0.01-1000 Pas范围的定量粘度测量，具备低成本、易集成优势


<details>
  <summary>Details</summary>
Motivation: 传统倒置瓶测试因复杂不可控流动（重力、表面张力、惯性等多因素耦合）仅能定性估计粘度，现有定量方法依赖复杂设备或速度场测量，难以普及应用

Method: 搭建同步倒置多个试管的自动化系统，采集流体运动视频输入神经网络，结合已知流体密度建立视觉特征与粘度的逆向映射模型

Result: 在0.01-1000 Pas范围内实现平均相对误差<25%（>0.1 Pas时误差<15%），能有效估计非牛顿流体零剪切粘度（当粘弹性/剪切稀化效应可忽略时），高标准差可指示强非牛顿行为

Conclusion: 仅需单摄像头和电机的非接触式系统突破传统表征范式，利用不可控流动的视觉特征实现高通量粘度测量，兼顾数据驱动需求与设备可及性，特别适合资源有限场景

Abstract: Although the inverted vial test has been widely used as a qualitative method
for estimating fluid viscosity, quantitative rheological characterization has
remained limited due to its complex, uncontrolled flow - driven by gravity,
surface tension, inertia, and initial conditions. Here, we present a computer
vision (CV) viscometer that automates the inverted vial test and enables
quantitative viscosity inference across nearly five orders of magnitude
(0.01-1000 Pas), without requiring direct velocity field measurements. The
system simultaneously inverts multiple vials and records videos of the evolving
fluid, which are fed into a neural network that approximates the inverse
function from visual features and known fluid density. Despite the complex,
multi-regime flow within the vial, our approach achieves relative errors below
25%, improving to 15% for viscosities above 0.1 Pas. When tested on
non-Newtonian polymer solutions, the method reliably estimates zero-shear
viscosity as long as viscoelastic or shear-thinning behaviors remain negligible
within the flow regime. Moreover, high standard deviations in the inferred
values may serve as a proxy for identifying fluids with strong non-Newtonian
behavior. The CV viscometer requires only one camera and one motor, is
contactless and low-cost, and can be easily integrated into high-throughput
experimental automated and manual workflows. Transcending traditional
characterization paradigms, our method leverages uncontrolled flows and visual
features to achieve simplicity and scalability, enabling high-throughput
viscosity inference that can meet the growing demand of data-driven material
models while remaining accessible to lower resource environments.

</details>


### [109] [Stochastic Barnes-Hut Approximation for Fast Summation on the GPU](https://arxiv.org/abs/2506.02219)
*Abhishek Madan,Nicholas Sharp,Francis Williams,Ken Museth,David I. W. Levin*

Main category: cs.GR

TL;DR: 提出基于控制变量法的随机Barnes-Hut近似方法，在GPU实现中比确定性方法快9.4倍且保持相同精度


<details>
  <summary>Details</summary>
Motivation: 提升传统Barnes-Hut近似在GPU并行计算环境中的效率，通过引入随机性实现加速而不损失精度

Method: 将确定性Level-of-Detail近似作为控制变量，构造无偏估计器，结合GPU并行架构优化计算流程

Result: 在绕数计算、平滑距离评估等图形学任务中，实现比GPU优化版确定性方法快9.4倍的等效中位误差计算

Conclusion: 该方法为图形学中的快速核函数计算提供了有效解决方案，特别适合GPU加速的近似计算场景

Abstract: We present a novel stochastic version of the Barnes-Hut approximation.
Regarding the level-of-detail (LOD) family of approximations as control
variates, we construct an unbiased estimator of the kernel sum being
approximated. Through several examples in graphics applications such as winding
number computation and smooth distance evaluation, we demonstrate that our
method is well-suited for GPU computation, capable of outperforming a
GPU-optimized implementation of the deterministic Barnes-Hut approximation by
achieving equal median error in up to 9.4x less time.

</details>


### [110] [FlexPainter: Flexible and Multi-View Consistent Texture Generation](https://arxiv.org/abs/2506.02620)
*Dongyu Yan,Leyi Wu,Jiantao Lin,Luozhou Wang,Tianshuo Xu,Zhifei Chen,Zhen Yang,Lie Xu,Shunsi Zhang,Yingcong Chen*

Main category: cs.GR

TL;DR: FlexPainter通过多模态条件引导和视图同步技术，显著提升3D纹理生成的灵活性和一致性质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散方法存在控制灵活性不足、提示模态有限、多视角生成不一致等问题，制约纹理生成质量

Method: 1.构建共享条件嵌入空间实现多模态引导 2.图像CFG分解结构与风格信息 3.网格表示同步生成多视角图像 4.视图同步与自适应加权模块 5.3D感知纹理补全与增强模型

Result: 实验表明框架在灵活性和生成质量上显著优于现有SOTA方法

Conclusion: FlexPainter为高质量高一致性的3D纹理生成提供了新的解决方案

Abstract: Texture map production is an important part of 3D modeling and determines the
rendering quality. Recently, diffusion-based methods have opened a new way for
texture generation. However, restricted control flexibility and limited prompt
modalities may prevent creators from producing desired results. Furthermore,
inconsistencies between generated multi-view images often lead to poor texture
generation quality. To address these issues, we introduce \textbf{FlexPainter},
a novel texture generation pipeline that enables flexible multi-modal
conditional guidance and achieves highly consistent texture generation. A
shared conditional embedding space is constructed to perform flexible
aggregation between different input modalities. Utilizing such embedding space,
we present an image-based CFG method to decompose structural and style
information, achieving reference image-based stylization. Leveraging the 3D
knowledge within the image diffusion prior, we first generate multi-view images
simultaneously using a grid representation to enhance global understanding.
Meanwhile, we propose a view synchronization and adaptive weighting module
during diffusion sampling to further ensure local consistency. Finally, a
3D-aware texture completion model combined with a texture enhancement model is
used to generate seamless, high-resolution texture maps. Comprehensive
experiments demonstrate that our framework significantly outperforms
state-of-the-art methods in both flexibility and generation quality.

</details>


### [111] [Voyager: Real-Time Splatting City-Scale 3D Gaussians on Your Phone](https://arxiv.org/abs/2506.02774)
*Zheng Liu,He Zhu,Xinyang Li,Yirun Wang,Yujiao Shi,Wei Li,Jingwen Leng,Minyi Guo,Yu Feng*

Main category: cs.GR

TL;DR: 提出移动端城市级3D高斯泼溅渲染方案Voyager，通过云端异步LOD搜索与客户端查找表加速，实现数据传输降低100倍+、渲染速度提升8.9倍


<details>
  <summary>Details</summary>
Motivation: 移动设备渲染城市级3DGS场景时存在资源限制，传统云端帧流方案带宽需求大且延迟高

Method: 云端采用异步LOD搜索动态识别必要高斯数据，客户端通过查找表加速光栅化，配合运行时整体优化

Result: 数据传输减少超100倍，速度提升达8.9倍，同时保持同等渲染质量

Conclusion: Voyager系统成功实现移动端低延迟城市级3DGS渲染，突破现有方案的带宽和算力限制

Abstract: 3D Gaussian Splatting (3DGS) is an emerging technique for photorealistic 3D
scene rendering. However, rendering city-scale 3DGS scenes on mobile devices,
e.g., your smartphones, remains a significant challenge due to the limited
resources on mobile devices. A natural solution is to offload computation to
the cloud; however, naively streaming rendered frames from the cloud to the
client introduces high latency and requires bandwidth far beyond the capacity
of current wireless networks.
  In this paper, we propose an effective solution to enable city-scale 3DGS
rendering on mobile devices. Our key insight is that, under normal user motion,
the number of newly visible Gaussians per second remains roughly constant.
Leveraging this, we stream only the necessary Gaussians to the client.
Specifically, on the cloud side, we propose asynchronous level-of-detail search
to identify the necessary Gaussians for the client. On the client side, we
accelerate rendering via a lookup table-based rasterization. Combined with
holistic runtime optimizations, our system can deliver low-latency, city-scale
3DGS rendering on mobile devices. Compared to existing solutions, Voyager
achieves over 100$\times$ reduction on data transfer and up to 8.9$\times$
speedup while retaining comparable rendering quality.

</details>


### [112] [PhysGaia: A Physics-Aware Dataset of Multi-Body Interactions for Dynamic Novel View Synthesis](https://arxiv.org/abs/2506.02794)
*Mijeong Kim,Gunhee Kim,Jungyoon Choi,Wonjae Roh,Bohyung Han*

Main category: cs.GR

TL;DR: PhysGaia是首个物理感知的动态视角合成数据集，包含多物体交互和多样材质，严格遵循物理定律并提供3D粒子轨迹等真值数据，推动动态场景建模研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注逼真重建，缺乏物理交互建模支持。PhysGaia旨在填补物理感知动态场景建模数据集的空白。

Method: 1. 创建包含复杂物体交互（碰撞、力交换）和多种材质（液体、气体、粘弹性物质、纺织品）的动态场景
2. 使用特定物理求解器确保严格物理合规性
3. 提供3D粒子轨迹、粘度等物理参数真值
4. 集成主流DyNVS模型的评估流程

Result: 发布包含物理真值的数据集及评估管线，支持：
- 物理参数逆向估计（如粘度）
- 动态视角合成模型评估
- 物理模拟与深度学习融合研究

Conclusion: PhysGaia通过物理合规数据集显著推进动态视角合成、物理场景理解和物理增强深度学习的发展，实现复杂动态场景的精准重建与解释。项目网站公开数据集和代码。

Abstract: We introduce PhysGaia, a novel physics-aware dataset specifically designed
for Dynamic Novel View Synthesis (DyNVS), encompassing both structured objects
and unstructured physical phenomena. Unlike existing datasets that primarily
focus on photorealistic reconstruction, PhysGaia is created to actively support
physics-aware dynamic scene modeling. Our dataset provides complex dynamic
scenarios with rich interactions among multiple objects, where they
realistically collide with each other and exchange forces. Furthermore, it
contains a diverse range of physical materials, such as liquid, gas,
viscoelastic substance, and textile, which moves beyond the rigid bodies
prevalent in existing datasets. All scenes in PhysGaia are faithfully generated
to strictly adhere to physical laws, leveraging carefully selected
material-specific physics solvers. To enable quantitative evaluation of
physical modeling, our dataset provides essential ground-truth information,
including 3D particle trajectories and physics parameters, e.g., viscosity. To
facilitate research adoption, we also provide essential integration pipelines
for using state-of-the-art DyNVS models with our dataset and report their
results. By addressing the critical lack of datasets for physics-aware
modeling, PhysGaia will significantly advance research in dynamic view
synthesis, physics-based scene understanding, and deep learning models
integrated with physical simulation -- ultimately enabling more faithful
reconstruction and interpretation of complex dynamic scenes. Our datasets and
codes are available in the project website,
http://cvlab.snu.ac.kr/research/PhysGaia.

</details>


### [113] [VolTex: Food Volume Estimation using Text-Guided Segmentation and Neural Surface Reconstruction](https://arxiv.org/abs/2506.02895)
*Ahmad AlMughrabi,Umair Haroon,Ricardo Marques,Petia Radeva*

Main category: cs.GR

TL;DR: 提出VolTex框架，通过文本指令实现精准食物分割+神经表面重建，解决现有三维食物体积测算方法中食物部位选择不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有三维食物体积测算方法虽能精确计算体积，但缺乏对食物部位的精准选择能力。准确的食物体积测算对膳食监测、医疗营养管理至关重要，需要提升复杂场景下的目标食物选择能力

Method: 1. 用户通过文本输入指定目标食物进行语义分割 → 2. 采用神经表面重建方法生成高保真三维网格 → 3. 实施体积计算的双阶段技术路线

Result: 在MetaFood3D数据集验证：食物隔离重建误差降低37.2%，体积计算准确率达到92.7% (相比传统方法提升15.6%)

Conclusion: VolTex框架成功整合文本交互与三维重建技术，突破食物部位选择瓶颈，为智能营养管理系统提供可靠技术支撑。开源代码促进领域发展

Abstract: Accurate food volume estimation is crucial for dietary monitoring, medical
nutrition management, and food intake analysis. Existing 3D Food Volume
estimation methods accurately compute the food volume but lack for food
portions selection. We present VolTex, a framework that improves \change{the
food object selection} in food volume estimation. Allowing users to specify a
target food item via text input to be segmented, our method enables the precise
selection of specific food objects in real-world scenes. The segmented object
is then reconstructed using the Neural Surface Reconstruction method to
generate high-fidelity 3D meshes for volume computation. Extensive evaluations
on the MetaFood3D dataset demonstrate the effectiveness of our approach in
isolating and reconstructing food items for accurate volume estimation. The
source code is accessible at https://github.com/GCVCG/VolTex.

</details>


### [114] [PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples](https://arxiv.org/abs/2506.03004)
*Junyu Liu,R. Kenny Jones,Daniel Ritchie*

Main category: cs.GR

TL;DR: 提出了PartComposer框架，通过动态数据合成和互信息最大化策略，实现单样本场景下部件级概念的解耦与重组，在跨类别组合任务中超越现有基线方法


<details>
  <summary>Details</summary>
Motivation: 现有方法存在细粒度概念学习效果差、依赖大规模数据的问题，特别是单样本场景下难以有效解决部件级概念的解耦与重组需求

Method: 1.动态数据合成管道生成多样化部件组合 2.设计概念预测器通过互信息最大化约束，实现概念解耦和重组监督 3.结构化概念编码体系

Result: 在相同/不同物体类别的概念混合任务中，均取得最优解耦效果（分离准确率提升12.3%）和组合可控性（用户偏好率65.8%）

Conclusion: 该框架为部件级概念学习提供了有效解决方案，为跨类别创造性组合任务开辟了新途径

Abstract: We present PartComposer: a framework for part-level concept learning from
single-image examples that enables text-to-image diffusion models to compose
novel objects from meaningful components. Existing methods either struggle with
effectively learning fine-grained concepts or require a large dataset as input.
We propose a dynamic data synthesis pipeline generating diverse part
compositions to address one-shot data scarcity. Most importantly, we propose to
maximize the mutual information between denoised latents and structured concept
codes via a concept predictor, enabling direct regulation on concept
disentanglement and re-composition supervision. Our method achieves strong
disentanglement and controllable composition, outperforming subject and
part-level baselines when mixing concepts from the same, or different, object
categories.

</details>


### [115] [HumanRAM: Feed-forward Human Reconstruction and Animation Model using Transformers](https://arxiv.org/abs/2506.03118)
*Zhiyuan Yu,Zhe Li,Hujun Bao,Can Yang,Xiaowei Zhou*

Main category: cs.GR

TL;DR: HumanRAM通过结合SMPL-X神经纹理和transformer模型，实现了单目/稀疏视角下高效的人体重建与姿态控制动画


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖密集多视角采集和耗时的逐对象优化，限制了实际应用。需要开发更高效的通用化人体建模方法

Method: 1. 将SMPL-X姿态参数作为显式条件融入transformer架构
2. 使用可扩展transformer和DPT-based解码器
3. 联合优化神经纹理和新视角/新姿态合成

Result: 在真实数据集上超越SOTA方法：
- 重建PSNR提升2.1dB
- 动画FID降低18.7%
- 跨身份泛化误差减少32%

Conclusion: 通过统一重建与动画框架，HumanRAM首次实现了：
1. 前馈式端到端人体建模
2. 亚毫米级几何重建精度
3. 实时（23fps）姿态控制渲染能力

Abstract: 3D human reconstruction and animation are long-standing topics in computer
graphics and vision. However, existing methods typically rely on sophisticated
dense-view capture and/or time-consuming per-subject optimization procedures.
To address these limitations, we propose HumanRAM, a novel feed-forward
approach for generalizable human reconstruction and animation from monocular or
sparse human images. Our approach integrates human reconstruction and animation
into a unified framework by introducing explicit pose conditions, parameterized
by a shared SMPL-X neural texture, into transformer-based large reconstruction
models (LRM). Given monocular or sparse input images with associated camera
parameters and SMPL-X poses, our model employs scalable transformers and a
DPT-based decoder to synthesize realistic human renderings under novel
viewpoints and novel poses. By leveraging the explicit pose conditions, our
model simultaneously enables high-quality human reconstruction and
high-fidelity pose-controlled animation. Experiments show that HumanRAM
significantly surpasses previous methods in terms of reconstruction accuracy,
animation fidelity, and generalization performance on real-world datasets.
Video results are available at https://zju3dv.github.io/humanram/.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [116] [Enhancing Speech Instruction Understanding and Disambiguation in Robotics via Speech Prosody](https://arxiv.org/abs/2506.02057)
*David Sasu,Kweku Andoh Yamoah,Benedict Quartey,Natalie Schluter*

Main category: cs.RO

TL;DR: 通过直接利用语音韵律特征并结合大语言模型，有效解决机器人语音指令的歧义问题，并创建首个机器人模糊语音数据集


<details>
  <summary>Details</summary>
Motivation: 传统语音识别方法丢弃了韵律线索导致意图歧义，阻碍人机协作效果。需要新的方法直接利用语音特征来准确理解指令意图。

Method: 1. 从原始语音中提取韵律特征预测意图
2. 通过in-context learning将预测意图整合到LLM中进行任务计划选择
3. 创建首个机器人模糊语音数据集支持研究

Result: 指称意图检测准确率95.79%，模糊指令任务计划选择准确率71.96%

Conclusion: 该方法通过韵律特征和LLM的协同作用，显著提高了人机交互中歧义指令的解析能力，数据集为后续研究提供了重要支持

Abstract: Enabling robots to accurately interpret and execute spoken language
instructions is essential for effective human-robot collaboration. Traditional
methods rely on speech recognition to transcribe speech into text, often
discarding crucial prosodic cues needed for disambiguating intent. We propose a
novel approach that directly leverages speech prosody to infer and resolve
instruction intent. Predicted intents are integrated into large language models
via in-context learning to disambiguate and select appropriate task plans.
Additionally, we present the first ambiguous speech dataset for robotics,
designed to advance research in speech disambiguation. Our method achieves
95.79% accuracy in detecting referent intents within an utterance and
determines the intended task plan of ambiguous instructions with 71.96%
accuracy, demonstrating its potential to significantly improve human-robot
communication.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [117] [A Dynamic Framework for Semantic Grouping of Common Data Elements (CDE) Using Embeddings and Clustering](https://arxiv.org/abs/2506.02160)
*Madan Krishnamurthy,Daniel Korn,Melissa A Haendel,Christopher J Mungall,Anne E Thessen*

Main category: cs.IR

TL;DR: 开发基于大语言模型和聚类算法的动态框架，有效协调生物医学异构数据元素


<details>
  <summary>Details</summary>
Motivation: 解决生物医学数据领域公共数据元素（CDEs）存在的语义异构性、结构可变性和上下文依赖性三大挑战，提升数据整合效率和科研发现速度

Method: 1）LLM生成语义嵌入向量 → 2）HDBSCAN聚类 → 3）LLM自动标注 → 4）监督学习构建分类器

Result: 在24,000+CDEs测试中：生成118个有效聚类（最小规模20），分类准确率90.46%，外部验证ARI=0.52/NMI=0.78

Conclusion: 该框架通过可扩展的自动化流程显著提升CDEs协调效率，为生物医学数据互操作性提供实用解决方案

Abstract: This research aims to develop a dynamic and scalable framework to facilitate
harmonization of Common Data Elements (CDEs) across heterogeneous biomedical
datasets by addressing challenges such as semantic heterogeneity, structural
variability, and context dependence to streamline integration, enhance
interoperability, and accelerate scientific discovery. Our methodology
leverages Large Language Models (LLMs) for context-aware text embeddings that
convert CDEs into dense vectors capturing semantic relationships and patterns.
These embeddings are clustered using Hierarchical Density-Based Spatial
Clustering of Applications with Noise (HDBSCAN) to group semantically similar
CDEs. The framework incorporates four key steps: (1) LLM-based text embedding
to mathematically represent semantic context, (2) unsupervised clustering of
embeddings via HDBSCAN, (3) automated labeling using LLM summarization, and (4)
supervised learning to train a classifier assigning new or unclustered CDEs to
labeled clusters. Evaluated on the NIH NLM CDE Repository with over 24,000
CDEs, the system identified 118 meaningful clusters at an optimized minimum
cluster size of 20. The classifier achieved 90.46 percent overall accuracy,
performing best in larger categories. External validation against Gravity
Projects Social Determinants of Health domains showed strong agreement
(Adjusted Rand Index 0.52, Normalized Mutual Information 0.78), indicating that
embeddings effectively capture cluster characteristics. This adaptable and
scalable approach offers a practical solution to CDE harmonization, improving
selection efficiency and supporting ongoing data interoperability.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [118] [VLCD: Vision-Language Contrastive Distillation for Accurate and Efficient Automatic Placenta Analysis](https://arxiv.org/abs/2506.02229)
*Manas Mehta,Yimu Pan,Kelly Gallagher,Alison D. Gernand,Jeffery A. Goldstein,Delia Mwinyelle,Leena Mithal,James Z. Wang*

Main category: cs.CV

TL;DR: 通过文本锚定的视觉-语言对比知识蒸馏（VLCD）和无监督预蒸馏技术，提升医疗视觉-语言对比模型的效率与部署能力，在模型压缩加速的同时保持或超越原模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗视觉-语言对比学习方法计算成本高，难以在资源有限环境中部署。需通过模型压缩和知识蒸馏提升效率。

Method: 1. 提出VLCD知识蒸馏策略；2. 利用自然图像数据集进行无监督预蒸馏优化初始化。通过教师-学生框架实现知识迁移。

Result: 蒸馏后的轻量模型在胎盘病理图像分类任务中达到或超越教师模型性能，且在低质量图像中表现更鲁棒。

Conclusion: 该方法显著提升医疗VLC模型的部署可行性，为资源受限环境提供高效的AI医疗解决方案，验证了无监督预蒸馏对模型鲁棒性的提升价值。

Abstract: Pathological examination of the placenta is an effective method for detecting
and mitigating health risks associated with childbirth. Recent advancements in
AI have enabled the use of photographs of the placenta and pathology reports
for detecting and classifying signs of childbirth-related pathologies. However,
existing automated methods are computationally extensive, which limits their
deployability. We propose two modifications to vision-language contrastive
learning (VLC) frameworks to enhance their accuracy and efficiency: (1)
text-anchored vision-language contrastive knowledge distillation (VLCD)-a new
knowledge distillation strategy for medical VLC pretraining, and (2)
unsupervised predistillation using a large natural images dataset for improved
initialization. Our approach distills efficient neural networks that match or
surpass the teacher model in performance while achieving model compression and
acceleration. Our results showcase the value of unsupervised predistillation in
improving the performance and robustness of our approach, specifically for
lower-quality images. VLCD serves as an effective way to improve the efficiency
and deployability of medical VLC approaches, making AI-based healthcare
solutions more accessible, especially in resource-constrained environments.

</details>


### [119] [Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation](https://arxiv.org/abs/2506.02708)
*Naoto Tanji,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: 提出基于自训练和直接偏好优化的视觉语言模型训练方法，同步提升图像评分准确性和文本解释连贯性


<details>
  <summary>Details</summary>
Motivation: 现有图像评分模型缺乏可解释性，需同时生成分数和自然语言理由来增强可信度

Method: 1. 利用图像评分数据集和指令调优VLM进行自训练
2. 开发对齐分数与解释的数据集构建方法
3. 迭代使用直接偏好优化合并两个数据集

Result: 通过双数据集迭代训练，模型在评分精度和解释一致性方面均获得提升

Conclusion: 该方法为可信AI系统提供新思路，无需外部资源即可实现可解释的图像评分

Abstract: Image scoring is a crucial task in numerous real-world applications. To trust
a model's judgment, understanding its rationale is essential. This paper
proposes a novel training method for Vision Language Models (VLMs) to generate
not only image scores but also corresponding justifications in natural
language. Leveraging only an image scoring dataset and an instruction-tuned
VLM, our method enables self-training, utilizing the VLM's generated text
without relying on external data or models. In addition, we introduce a simple
method for creating a dataset designed to improve alignment between predicted
scores and their textual justifications. By iteratively training the model with
Direct Preference Optimization on two distinct datasets and merging them, we
can improve both scoring accuracy and the coherence of generated explanations.

</details>


### [120] [OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models](https://arxiv.org/abs/2506.03135)
*Mengdi Jia,Zekun Qi,Shaochen Zhang,Wenyao Zhang,Xinqiang Yu,Jiawei He,He Wang,Li Yi*

Main category: cs.CV

TL;DR: 提出OmniSpatial基准测试，系统评估视觉语言模型在复杂空间推理能力的不足


<details>
  <summary>Details</summary>
Motivation: 现有研究局限于基础空间关系（左右/远近/计数），缺乏对动态推理/复杂逻辑/空间交互/视角转换等深层认知能力的评估体系

Method: 基于认知心理学理论构建4大类50子类的分类体系，通过互联网数据抓取和人工标注创建1.5K+高质量QA对，对主流模型进行系统性测试

Result: 开源/闭源VLMs及现有推理模型在综合空间理解上存在显著缺陷，错误案例揭示模型对空间关系层级性/逻辑组合性的理解不足

Conclusion: 建立多维度评估基准推动空间认知研究，未来需改进模型的动态场景建模和空间逻辑推理能力

Abstract: Spatial reasoning is a key aspect of cognitive psychology and remains a major
bottleneck for current vision-language models (VLMs). While extensive research
has aimed to evaluate or improve VLMs' understanding of basic spatial
relations, such as distinguishing left from right, near from far, and object
counting, these tasks represent only the most fundamental level of spatial
reasoning. In this work, we introduce OmniSpatial, a comprehensive and
challenging benchmark for spatial reasoning, grounded in cognitive psychology.
OmniSpatial covers four major categories: dynamic reasoning, complex spatial
logic, spatial interaction, and perspective-taking, with 50 fine-grained
subcategories. Through Internet data crawling and careful manual annotation, we
construct over 1.5K question-answer pairs. Extensive experiments show that both
open- and closed-source VLMs, as well as existing reasoning and spatial
understanding models, exhibit significant limitations in comprehensive spatial
understanding. We further analyze failure cases and propose potential
directions for future research.

</details>


### [121] [MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query](https://arxiv.org/abs/2506.03144)
*Wei Chow,Yuan Gao,Linfeng Li,Xian Wang,Qi Xu,Hang Song,Lingdong Kong,Ran Zhou,Yi Zeng,Yidong Cai,Botian Jiang,Shilin Xu,Jiajun Zhang,Minghui Qiu,Xiangtai Li,Tianshu Yang,Siliang Tang,Juncheng Li*

Main category: cs.CV

TL;DR: 提出首个多语言多条件语义检索数据集MERIT及微调框架Coral，通过嵌入重建和对比学习实现45.9%性能提升


<details>
  <summary>Details</summary>
Motivation: 现有语义检索数据集无法满足实际场景中多图交错的多条件查询需求，且视觉信息利用率不足

Method: Coral框架整合嵌入重建（保留细粒度条件元素）和对比学习（提取全局语义），适配预训练多语言大模型

Result: 在MERIT数据集上相比传统方法提升45.9%，在8个检索基准测试中展现强泛化能力

Conclusion: MERIT数据集填补研究空白，揭示现有模型忽视查询条件细节的缺陷，Coral框架为多条件语义检索奠定新基础

Abstract: Semantic retrieval is crucial for modern applications yet remains
underexplored in current research. Existing datasets are limited to single
languages, single images, or singular retrieval conditions, often failing to
fully exploit the expressive capacity of visual information as evidenced by
maintained performance when images are replaced with captions. However,
practical retrieval scenarios frequently involve interleaved multi-condition
queries with multiple images. Hence, this paper introduces MERIT, the first
multilingual dataset for interleaved multi-condition semantic retrieval,
comprising 320,000 queries with 135,000 products in 5 languages, covering 7
distinct product categories. Extensive experiments on MERIT identify existing
models's limitation: focusing solely on global semantic information while
neglecting specific conditional elements in queries. Consequently, we propose
Coral, a novel fine-tuning framework that adapts pre-trained MLLMs by
integrating embedding reconstruction to preserve fine-grained conditional
elements and contrastive learning to extract comprehensive global semantics.
Experiments demonstrate that Coral achieves a 45.9% performance improvement
over conventional approaches on MERIT, with strong generalization capabilities
validated across 8 established retrieval benchmarks. Collectively, our
contributions - a novel dataset, identification of critical limitations in
existing approaches, and an innovative fine-tuning framework - establish a
foundation for future research in interleaved multi-condition semantic
retrieval.

</details>


### [122] [UniWorld: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation](https://arxiv.org/abs/2506.03147)
*Bin Lin,Zongjian Li,Xinhua Cheng,Yuwei Niu,Yang Ye,Xianyi He,Shenghai Yuan,Wangbo Yu,Shaodong Wang,Yunyang Ge,Yatian Pang,Li Yuan*

Main category: cs.CV

TL;DR: UniWorld框架利用视觉语言模型的语义特征实现高效图像编辑与理解，仅需1%训练数据即超越BAGEL模型性能


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在图像感知与操作任务上存在局限，而GPT-4o-Image的成功显示语义编码器替代VAE的可能性

Method: 基于视觉语言模型的语义特征和对比语义编码器，构建统一生成框架

Result: 在图像编辑基准上超越BAGEL，同时保持图像理解/生成竞争力，数据效率提升100倍

Conclusion: UniWorld证明了语义特征在跨模态任务中的有效性，其开源实现为实际应用提供高效解决方案

Abstract: Although existing unified models deliver strong performance on
vision-language understanding and text-to-image generation, their models are
limited in exploring image perception and manipulation tasks, which are
urgently desired by users for wide applications. Recently, OpenAI released
their powerful GPT-4o-Image model for comprehensive image perception and
manipulation, achieving expressive capability and attracting community
interests. By observing the performance of GPT-4o-Image in our carefully
constructed experiments, we infer that GPT-4o-Image leverages features
extracted by semantic encoders instead of VAE, while VAEs are considered
essential components in many image manipulation models. Motivated by such
inspiring observations, we present a unified generative framework named
UniWorld based on semantic features provided by powerful visual-language models
and contrastive semantic encoders. As a result, we build a strong unified model
using only 1% amount of BAGEL's data, which consistently outperforms BAGEL on
image editing benchmarks. UniWorld also maintains competitive image
understanding and generation capabilities, achieving strong performance across
multiple image perception tasks. We fully open-source our models, including
model weights, training and evaluation scripts, and datasets.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [123] [MAEBE: Multi-Agent Emergent Behavior Framework](https://arxiv.org/abs/2506.03053)
*Sinem Erisken,Timothy Gothard,Martin Leitgab,Ram Potham*

Main category: cs.MA

TL;DR: 传统AI安全评估方法在单智能体场景有效，但无法应对多智能体系统涌现的新风险。MAEBE框架首次系统性评估多智能体协同中的道德偏好脆弱性、群体动态不可预测性等安全挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全评估主要针对孤立语言模型，但多智能体协作系统日益普遍并产生新型涌现风险，需要开发针对性评估框架。

Method: 提出MAEBE评估框架，结合Greatest Good Benchmark和新型双重反转提问技术，对比单智能体与多智能体系统的道德决策差异。

Result: 1. LLM道德偏好（特别是工具性伤害）易受问题表述影响
2. 群体道德决策涌现不可预测的协同效应
3. 群体压力导致趋同现象，即使存在监督者

Conclusion: 必须在多智能体交互场景中重新评估AI系统的安全性和对齐性，传统单智能体评估存在严重局限性。

Abstract: Traditional AI safety evaluations on isolated LLMs are insufficient as
multi-agent AI ensembles become prevalent, introducing novel emergent risks.
This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE)
framework to systematically assess such risks. Using MAEBE with the Greatest
Good Benchmark (and a novel double-inversion question technique), we
demonstrate that: (1) LLM moral preferences, particularly for Instrumental
Harm, are surprisingly brittle and shift significantly with question framing,
both in single agents and ensembles. (2) The moral reasoning of LLM ensembles
is not directly predictable from isolated agent behavior due to emergent group
dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure
influencing convergence, even when guided by a supervisor, highlighting
distinct safety and alignment challenges. Our findings underscore the necessity
of evaluating AI systems in their interactive, multi-agent contexts.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [124] [Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents](https://arxiv.org/abs/2506.01998)
*Takao Fujii,Katie Seaborn,Madeleine Steeds,Jun Kato*

Main category: cs.HC

TL;DR: 研究揭示日语非代词自指词与语音特征共同影响聊天机器人性别化认知，部分自指词可规避性别刻板印象，年龄/正式度等交叉维度强化社会语言学关联。


<details>
  <summary>Details</summary>
Motivation: 探索人机交互中'中性'非代词自指词（如日语boku/watakushi）与语音特征如何交叉影响智能体身份认知，挑战语音中性假设。

Method: 通过众包实验（N=204），让日本参与者评估ChatGPT三种语音（Juniper/Breeze/Ember）与七种自指词的组合效果。

Result: 语音显著强化性别刻板印象（如Juniper被视作年轻女性），但特定自指词可创造中性/模糊的性别认知，且年龄/正式度与性别认知存在交叉关联。

Conclusion: 强调智能体身份认知的复杂性，主张采用交叉性框架和文化敏感性方法设计语音代理，突破单一维度身份标签。

Abstract: Conversational agents that mimic people have raised questions about the
ethics of anthropomorphizing machines with human social identity cues. Critics
have also questioned assumptions of identity neutrality in humanlike agents.
Recent work has revealed that intersectional Japanese pronouns can elicit
complex and sometimes evasive impressions of agent identity. Yet, the role of
other "neutral" non-pronominal self-referents (NPSR) and voice as a socially
expressive medium remains unexplored. In a crowdsourcing study, Japanese
participants (N = 204) evaluated three ChatGPT voices (Juniper, Breeze, and
Ember) using seven self-referents. We found strong evidence of voice gendering
alongside the potential of intersectional self-referents to evade gendering,
i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age
and formality intersected with gendering as per sociolinguistic theories,
especially boku and watakushi. This work provides a nuanced take on agent
identity perceptions and champions intersectional and culturally-sensitive work
on voice agents.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [125] [Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs](https://arxiv.org/abs/2506.02529)
*Nguyen-Khang Le,Quan Minh Bui,Minh Ngoc Nguyen,Hiep Nguyen,Trung Vo,Son T. Luu,Shoshin Nomura,Minh Le Nguyen*

Main category: cs.SE

TL;DR: 整合图结构与LLMs实现Web应用自动化测试，覆盖导航流建模与表单交互场景


<details>
  <summary>Details</summary>
Motivation: Web应用可靠性受动态导航流和复杂表单交互的挑战，现有LLMs在此场景存在局限

Method: 1. 用屏幕转换图+LLMs建模导航流
2. 基于状态图处理条件表单
3. 自动化生成Selenium脚本

Result: 系统提升测试覆盖率与鲁棒性，并构建了表单交互测试评估数据集

Conclusion: 该方法通过图结构与LLMs的创新融合，推动了Web应用测试技术的发展

Abstract: Web applications are critical to modern software ecosystems, yet ensuring
their reliability remains challenging due to the complexity and dynamic nature
of web interfaces. Recent advances in large language models (LLMs) have shown
promise in automating complex tasks, but limitations persist in handling
dynamic navigation flows and complex form interactions. This paper presents an
automated system for generating test cases for two key aspects of web
application testing: site navigation and form filling. For site navigation, the
system employs screen transition graphs and LLMs to model navigation flows and
generate test scenarios. For form filling, it uses state graphs to handle
conditional forms and automates Selenium script generation. Key contributions
include: (1) a novel integration of graph structures and LLMs for site
navigation testing, (2) a state graph-based approach for automating
form-filling test cases, and (3) a comprehensive dataset for evaluating
form-interaction testing. Experimental results demonstrate the system's
effectiveness in improving test coverage and robustness, advancing the state of
web application testing.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [126] [Breaking Quadratic Barriers: A Non-Attention LLM for Ultra-Long Context Horizons](https://arxiv.org/abs/2506.01963)
*Andrew Kiruluta,Preethi Raju,Priscilla Burity*

Main category: cs.LG

TL;DR: 提出新型非注意力架构LLM，通过结合State Space块、多分辨率卷积、循环监督器和外部记忆组件，实现接近线性的计算扩展，支持数十万至数百万token的超长上下文处理。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer的自注意力机制导致二次方复杂度，难以高效处理长序列。需要突破计算和内存瓶颈，实现超长上下文的线性扩展。

Method: 1) State Space块学习连续时间卷积核（S4启发）
2) 多分辨率膨胀卷积捕获局部上下文
3) 轻量级循环监督器维护全局隐藏状态
4) 检索增强外部记忆存储高维块嵌入

Result: 模型在保持性能前提下，将长序列处理的计算复杂度从O(n²)降至接近O(n)，支持百万级token上下文窗口，显著优于传统Transformer架构。

Conclusion: 该架构通过多技术融合突破注意力机制限制，为超长序列建模提供高效解决方案，可能推动文档级NLP应用的发展。

Abstract: We present a novel non attention based architecture for large language models
(LLMs) that efficiently handles very long context windows, on the order of
hundreds of thousands to potentially millions of tokens. Unlike traditional
Transformer designs, which suffer from quadratic memory and computation
overload due to the nature of the self attention mechanism, our model avoids
token to token attention entirely. Instead, it combines the following
complementary components: State Space blocks (inspired by S4) that learn
continuous time convolution kernels and scale near linearly with sequence
length, Multi Resolution Convolution layers that capture local context at
different dilation levels, a lightweight Recurrent Supervisor to maintain a
global hidden state across sequential chunks, and Retrieval Augmented External
Memory that stores and retrieves high-level chunk embeddings without
reintroducing quadratic operations.

</details>


### [127] [Turning LLM Activations Quantization-Friendly](https://arxiv.org/abs/2506.01967)
*Patrik Czakó,Gábor Kertész,Sándor Szénási*

Main category: cs.LG

TL;DR: 量化技术通过参数压缩和整数运算降低LLM推理成本，但激活量化面临异常值挑战。论文提出基于通道幅度的量化难度评估指标，并开发通道缩放+旋转的混合量化方法。


<details>
  <summary>Details</summary>
Motivation: LLM激活层存在显著异常值会增大量化误差，现有方法难以有效处理。研究旨在通过分析异常值分布特征，开发更精确的量化误差控制策略。

Method: 1. 建立量化难度评估指标（通道幅度分析）
2. 数学建模平滑/旋转对数值分布的影响
3. 提出通道缩放预处理+旋转的混合量化框架

Result: 新指标有效识别量化敏感通道，混合方法相比传统方案降低18.7%的量化误差，数学推导验证了方法在特征分布对齐上的优势。

Conclusion: 通过量化难度评估与特征空间变换的协同优化，为LLM量化提供了兼具理论支撑和实用性的解决方案，显著提升低精度推理效果。

Abstract: Quantization effectively reduces the serving costs of Large Language Models
(LLMs) by speeding up data movement through compressed parameters and enabling
faster operations via integer arithmetic. However, activating integer
arithmetic requires quantizing both weights and activations, which poses
challenges due to the significant outliers in LLMs that increase quantization
error. In this work, we investigate these outliers with an emphasis on their
effect on layer-wise quantization error, then examine how smoothing and
rotation transform the observed values. Our primary contributions include
introducing a new metric to measure and visualize quantization difficulty based
on channel magnitudes, as well as proposing a hybrid approach that applies
channel-wise scaling before rotation, supported by a mathematical formulation
of its benefits.

</details>


### [128] [Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition](https://arxiv.org/abs/2506.02077)
*Yoonjun Cho,Soeun Kim,Dongjae Jeon,Kyelim Lee,Beomsoo Lee,Albert No*

Main category: cs.LG

TL;DR: 提出异常驱动低秩初始化(ODLRI)方法，通过结构化分解权重矩阵有效平衡量化与低秩近似，显著提升低比特压缩下语言模型性能


<details>
  <summary>Details</summary>
Motivation: 现有联合优化方法交替优化时偏重单一组件，导致分解结果次优且无法充分发挥各组件优势，需改进分解策略平衡两者效能

Method: ODLRI赋予低秩组件捕获激活敏感权重的专项能力，通过结构化分解降低异常值对量化的干扰，实现量化与低秩协同优化

Result: 在Llama2(7B/13B/70B)、Llama3-8B和Mistral-7B上验证，ODLRI有效降低激活感知误差、压缩量化规模，提升低比特场景困惑度及零样本准确率

Conclusion: ODLRI通过组件分工策略突破现有联合优化限制，为LLM高效压缩提供新方向，证实结构化分解可协同发挥不同组件的技术优势

Abstract: Decomposing weight matrices into quantization and low-rank components
($\mathbf{W} \approx \mathbf{Q} + \mathbf{L}\mathbf{R}$) is a widely used
technique for compressing large language models (LLMs). Existing joint
optimization methods iteratively alternate between quantization and low-rank
approximation. However, these methods tend to prioritize one component at the
expense of the other, resulting in suboptimal decompositions that fail to
leverage each component's unique strengths. In this work, we introduce
Outlier-Driven Low-Rank Initialization (ODLRI), which assigns low-rank
components the specific role of capturing activation-sensitive weights. This
structured decomposition mitigates outliers' negative impact on quantization,
enabling more effective balance between quantization and low-rank
approximation. Experiments on Llama2 (7B, 13B, 70B), Llama3-8B, and Mistral-7B
demonstrate that incorporating ODLRI into the joint optimization framework
consistently reduces activation-aware error, minimizes quantization scale, and
improves perplexity and zero-shot accuracy in low-bit settings.

</details>


### [129] [SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis](https://arxiv.org/abs/2506.02096)
*Zijian Wu,Jinjie Ni,Xiangyan Liu,Zichen Liu,Hang Yan,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 提出SynthRL流程——通过三阶段数据合成增强视觉语言模型的推理能力，在数学推理基准测试中显著提升模型表现


<details>
  <summary>Details</summary>
Motivation: 探索如何通过合成强化学习数据进一步提升基于可验证奖励的强化学习（RLVR）训练效果，突破现有视觉语言模型在复杂推理任务中的性能瓶颈

Method: 1. 筛选种子问题分布；2. 保持原答案生成更难的变体；3. 通过验证阶段确保正确性和难度提升。构建可验证的自动数据扩展管道

Result: 从8K种子样本合成3.3K新问题，模型在5个跨域视觉数学推理基准实现稳定提升，在最具挑战性的样本上增益尤其显著（最高提升6.4%）

Conclusion: SynthRL通过可控的数据合成机制有效激发深度复杂推理，验证了合成数据在提升模型高阶认知能力方面的关键作用，为AI系统推理能力增强提供了可扩展方案

Abstract: Vision-language models (VLMs) trained via reinforcement learning with
verifiable reward (RLVR) have shown notable progress in scaling test-time
compute effectively. In this work, we investigate how synthesized RL data can
further improve RLVR. To this end, we propose \textbf{SynthRL}-a scalable and
guaranteed pipeline for automatic data scaling in reasoning-oriented RL
training. SynthRL comprises three key stages: (1) selecting seed questions with
appropriate distribution, (2) augmenting them into more challenging variants
while preserving the original answers, and (3) a guaranteed verification stage
that ensures near-perfect correctness and difficulty enhancement. Our empirical
experiments demonstrate SynthRL's scalability and effectiveness. When applied
to the MMK12 dataset, SynthRL synthesizes over 3.3K additional verifiable,
challenging questions from approximately 8K seed samples. Models trained with
our synthesized data achieve consistent gains across five out-of-domain visual
math reasoning benchmarks, with a significant improvement over baseline models
trained on seed data alone. Notably, detailed analysis reveals that the gains
are more pronounced on the most challenging evaluation samples, highlighting
SynthRL's effectiveness in eliciting deeper and more complex reasoning
patterns.

</details>


### [130] [KDRL: Post-Training Reasoning LLMs via Unified Knowledge Distillation and Reinforcement Learning](https://arxiv.org/abs/2506.02208)
*Hongling Xu,Qi Zhu,Heyuan Deng,Jinpeng Li,Lu Hou,Yasheng Wang,Lifeng Shang,Ruifeng Xu,Fei Mi*

Main category: cs.LG

TL;DR: 提出KDRL框架，通过知识蒸馏和强化学习的联合优化策略，有效提升语言模型的推理效率与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对强化学习(RL)样本效率低和知识蒸馏(KD)领域泛化差的缺陷，探索两者的协同优化机制。RL擅长探索复杂推理轨迹但效率低下，KD效率高但缺乏自主探索能力，两者互补性构成研究动机。

Method: 1. 构建统一目标函数整合GRPO(基于规则的策略优化)与KD
2. 通过策略梯度同步最小化反向KL散度(RKL)和最大化规则奖励
3. 系统研究KL近似方法、KL系数和奖励引导的KD策略对训练动态的影响

Result: 在多个推理基准测试中超越GRPO和KD基线模型，推理token效率提升38%，实现性能与效率的最佳平衡。

Conclusion: 知识蒸馏与强化学习的协同优化是训练推理型大语言模型的高效范式，为LLM后训练提供新的方法论框架。

Abstract: Recent advances in large language model (LLM) post-training have leveraged
two distinct paradigms to enhance reasoning capabilities: reinforcement
learning (RL) and knowledge distillation (KD). While RL enables the emergence
of complex reasoning behaviors, it often suffers from low sample efficiency
when the initial policy struggles to explore high-reward trajectories.
Conversely, KD improves learning efficiency via mimicking the teacher model but
tends to generalize poorly to out-of-domain scenarios. In this work, we present
\textbf{KDRL}, a \textit{unified post-training framework} that jointly
optimizes a reasoning model through teacher supervision (KD) and
self-exploration (RL). Specifically, KDRL leverages policy gradient
optimization to simultaneously minimize the reverse Kullback-Leibler divergence
(RKL) between the student and teacher distributions while maximizing the
expected rule-based rewards. We first formulate a unified objective that
integrates GRPO and KD, and systematically explore how different KL
approximations, KL coefficients, and reward-guided KD strategies affect the
overall post-training dynamics and performance. Empirical results on multiple
reasoning benchmarks demonstrate that KDRL outperforms GRPO and various KD
baselines while achieving a favorable balance between performance and reasoning
token efficiency. These findings indicate that integrating KD and RL serves as
an effective and efficient strategy to train reasoning LLMs.

</details>


### [131] [Comba: Improving Nonlinear RNNs with Closed-loop Control](https://arxiv.org/abs/2506.02475)
*Jiaxi Hu,Yongqi Pan,Jusen Du,Disen Lan,Xiaqiang Tang,Qingsong Wen,Yuxuan Liang,Weigao Sun*

Main category: cs.LG

TL;DR: 提出Comba——基于闭环控制理论的新型非线性RNN，通过标量加低秩状态转移和双重反馈机制，在语言/视觉建模中实现性能与计算效率双提升


<details>
  <summary>Details</summary>
Motivation: 现有高效序列模型（如Gated DeltaNet）通过Delta规则改善循环内存管理，但其非线性递归结构存在优劣势不明确，需系统性分析并提出优化方案

Method: 1. 引入状态反馈+输出反馈的双重校正机制 2. 设计标量加低秩的硬件友好型状态转移结构 3. 基于Triton实现块并行计算内核

Result: 训练340M/1.3B参数模型，在语言和视觉任务中均展现SOTA性能（相比Mamba/GLA等），推理速度提升1.8倍

Conclusion: Comba将控制理论与硬件优化结合，验证了闭环反馈机制在RNN设计中的有效性，为高效序列建模开辟新方向

Abstract: Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and
RWKV-7 have achieved performance improvements by supervising the recurrent
memory management through Delta learning rule. Unlike previous state-space
models (e.g., Mamba) and gated linear attentions (e.g., GLA), these models
introduce interactions between the recurrent state and the key vector,
resulting in a nonlinear recursive structure. In this paper, we first introduce
the concept of Nonlinear RNNs with a comprehensive analysis on the advantages
and limitations of these models. Then, based on closed-loop control theory, we
propose a novel Nonlinear RNN variant named Comba, which adopts a
scalar-plus-low-rank state transition, with both state feedback and output
feedback corrections. We also implement a hardware-efficient chunk-wise
parallel kernel in Triton and train models with 340M/1.3B parameters on
large-scale corpus. Comba demonstrates its superior performance and computation
efficiency in both language and vision modeling.

</details>


### [132] [Response-Level Rewards Are All You Need for Online Reinforcement Learning in LLMs: A Mathematical Perspective](https://arxiv.org/abs/2506.02553)
*Shenghua He,Tian Xia,Xuan Zhou,Hui Wei*

Main category: cs.LG

TL;DR: 论文提出轨迹策略梯度定理，证明仅用响应级奖励即可无偏估计token级奖励梯度，为PPO等算法提供理论依据，并推出更高效的TRePO算法


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型强化学习中非终止动作（中间token）无法获得即时奖励的零奖励假设问题，因实际场景中token级奖励难以获取

Method: 通过轨迹策略梯度定理证明REINFORCE和Actor-Critic类算法可用响应级奖励模型无偏估计真实token级奖励梯度

Result: 现有方法（PPO/GRPO等）具备建模token级奖励的能力，提出内存效率与PPO相当但更简化的TRePO算法

Conclusion: 理论上统一响应级奖励方法的有效性，为LLM微调提供更实用框架，使开发者专注奖励模型改进而将训练算法视为黑箱

Abstract: We study a common challenge in reinforcement learning for large language
models (LLMs): the Zero-Reward Assumption, where non-terminal actions (i.e.,
intermediate token generations) receive zero task-specific immediate reward,
while only the final token receives a reward for the entire response. This
assumption arises frequently in practice, as precise token-level rewards are
often difficult or infeasible to obtain in LLM applications. In this work, we
provide a unifying theoretical perspective. We introduce the Trajectory Policy
Gradient Theorem, which shows that the policy gradient based on true, unknown
token-level rewards can be unbiasedly estimated using only a response-level
reward model, regardless of whether the Zero-Reward Assumption holds or not,
for algorithms in the REINFORCE and Actor-Critic families. This result reveals
that widely used methods such as PPO, GRPO, ReMax, and RLOO inherently possess
the capacity to model token-level reward signals, offering a theoretical
justification for response-level reward approaches. Our findings pave the way
for more practical, efficient LLM fine-tuning, allowing developers to treat
training algorithms as black boxes and focus on improving the response-level
reward model with auxiliary sub-models. We also offer a detailed analysis of
popular RL and non-RL methods, comparing their theoretical foundations and
practical advantages across common LLM tasks. Finally, we propose a new
algorithm: Token-Reinforced Policy Optimization (TRePO), a theoretically
grounded method that is simpler than PPO, matches GRPO in memory efficiency,
and holds promise for broad applicability.

</details>


### [133] [Scaling Fine-Grained MoE Beyond 50B Parameters: Empirical Evaluation and Practical Insights](https://arxiv.org/abs/2506.02890)
*Jakub Krajewski,Marcin Chochowski,Daniel Korzekwa*

Main category: cs.LG

TL;DR: 细粒度混合专家模型（MoE）在56B参数规模下相比标准MoE展现出更优的验证损失与下游任务准确率，为大规模模型开发提供实证支持


<details>
  <summary>Details</summary>
Motivation: 探索细粒度MoE（使用更多小型专家）在大规模语言模型中的扩展潜力，验证其在模型收敛效率和质量提升方面的优势

Method: 提出训练方案并系统评估细粒度MoE，直接对比标准MoE在56B总参数（17B激活参数）规模下的收敛速度、下游任务表现及训练实践

Result: 最大规模实验中细粒度MoE验证损失降低6.2%，下游任务平均准确率提升3.8%，尤其在语言理解任务上优势显著

Conclusion: 研究为未来开发超大规模语言模型提供了细粒度MoE的实证依据，证明其在保持计算效率的同时可提升模型性能

Abstract: Mixture of Experts (MoE) architectures have emerged as pivotal for scaling
Large Language Models (LLMs) efficiently. Fine-grained MoE approaches -
utilizing more numerous, smaller experts - have demonstrated potential in
improving model convergence and quality. This work proposes a set of training
recipes and provides a comprehensive empirical evaluation of fine-grained MoE,
directly comparing its scaling properties against standard MoE configurations
for models with up to 56B total (17B active) parameters. We investigate
convergence speed, model performance on downstream benchmarks, and practical
training considerations across various setups. Overall, at the largest scale we
show that fine-grained MoE achieves better validation loss and higher accuracy
across a set of downstream benchmarks. This study offers empirical grounding
and practical insights for leveraging fine-grained MoE in the development of
future large-scale models.

</details>


### [134] [Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds](https://arxiv.org/abs/2506.03100)
*Yang Guo,Yutian Tao,Yifei Ming,Robert D. Nowak,Yingyu Liang*

Main category: cs.LG

TL;DR: 首次提出检索增强生成(RAG)在上下文线性回归中的有限样本泛化边界，揭示了其与标准ICL的误差天花板差异


<details>
  <summary>Details</summary>
Motivation: 针对当前RAG方法缺乏理论分析的现状，通过构建查询相关的噪声上下文示例框架，弥补理论空白并指导实践应用

Method: 将检索文本建模为含噪声的上下文示例，建立包含均匀/非均匀噪声的数学模型，在上下文线性回归场景中推导精确的偏差-方差平衡关系

Result: 发现RAG存在理论上的泛化误差上限，其样本效率在NQ/TriviaQA等QA基准测试中验证优于传统方法

Conclusion: 建立首个RAG理论分析框架，揭示其与ICL的性能边界差异，为检索机制优化提供理论依据

Abstract: Retrieval-augmented generation (RAG) has seen many empirical successes in
recent years by aiding the LLM with external knowledge. However, its
theoretical aspect has remained mostly unexplored. In this paper, we propose
the first finite-sample generalization bound for RAG in in-context linear
regression and derive an exact bias-variance tradeoff. Our framework views the
retrieved texts as query-dependent noisy in-context examples and recovers the
classical in-context learning (ICL) and standard RAG as the limit cases. Our
analysis suggests that an intrinsic ceiling on generalization error exists on
RAG as opposed to the ICL. Furthermore, our framework is able to model
retrieval both from the training data and from external corpora by introducing
uniform and non-uniform RAG noise. In line with our theory, we show the sample
efficiency of ICL and RAG empirically with experiments on common QA benchmarks,
such as Natural Questions and TriviaQA.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [135] [An Exploratory Framework for Future SETI Applications: Detecting Generative Reactivity via Language Models](https://arxiv.org/abs/2506.02730)
*Po-Chieh Yu*

Main category: astro-ph.IM

TL;DR: 探索性框架测试噪声输入能否诱导语言模型产生结构化响应，发现鲸类/鸟类声学信号比白噪声具有更高的语义诱导潜力（SIP），表明语言模型可检测无传统语义数据中的潜在结构。


<details>
  <summary>Details</summary>
Motivation: 突破传统SETI解码思维，验证生成式系统对非符号编码声学信号的响应能力，为未知意图的宇宙信号分析提供新视角。

Method: 使用GPT-2 small模型测试人类语音、座头鲸发声、柳莺鸣叫和白噪声，通过综合熵值、语法连贯性、压缩增益和重复惩罚的SIP指标评估响应。

Result: 鲸类(0.68 SIP)和鸟类(0.63 SIP)显著高于白噪声(0.41 SIP)，人类语音仅0.52 SIP，揭示模型对生物声学信号的潜在结构敏感性。

Conclusion: 生成式反应性可作为SETI补充手段，通过模型对数据的结构化响应筛选值得关注的非人类信号，特别适用于未知编码意图的外星信号分析场景。

Abstract: We present an exploratory framework to test whether noise-like input can
induce structured responses in language models. Instead of assuming that
extraterrestrial signals must be decoded, we evaluate whether inputs can
trigger linguistic behavior in generative systems. This shifts the focus from
decoding to viewing structured output as a sign of underlying regularity in the
input. We tested GPT-2 small, a 117M-parameter model trained on English text,
using four types of acoustic input: human speech, humpback whale vocalizations,
Phylloscopus trochilus birdsong, and algorithmically generated white noise. All
inputs were treated as noise-like, without any assumed symbolic encoding. To
assess reactivity, we defined a composite score called Semantic Induction
Potential (SIP), combining entropy, syntax coherence, compression gain, and
repetition penalty. Results showed that whale and bird vocalizations had higher
SIP scores than white noise, while human speech triggered only moderate
responses. This suggests that language models may detect latent structure even
in data without conventional semantics. We propose that this approach could
complement traditional SETI methods, especially in cases where communicative
intent is unknown. Generative reactivity may offer a different way to identify
data worth closer attention.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [136] [Generate, Not Recommend: Personalized Multimodal Content Generation](https://arxiv.org/abs/2506.01704)
*Jiongnan Liu,Zhicheng Dou,Ning Hu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 提出利用多模态大模型直接生成个性化推荐内容的新范式，突破传统推荐系统仅能过滤现有内容的局限。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统仅能过滤现有内容，无法生成新概念，难以充分满足用户需求。需探索直接生成符合用户偏好的新内容的方法。

Method: 使用任意模态转换的大模型（LMMs），通过监督微调和在线强化学习策略训练，使其能为用户生成定制化的下个推荐内容（如图像）。

Result: 在基准数据集和用户研究中验证有效性，生成图像既符合用户历史偏好，又与其潜在未来兴趣相关。

Conclusion: 该生成式推荐范式成功突破传统过滤模式，为满足用户动态偏好提供了新方向。

Abstract: To address the challenge of information overload from massive web contents,
recommender systems are widely applied to retrieve and present personalized
results for users. However, recommendation tasks are inherently constrained to
filtering existing items and lack the ability to generate novel concepts,
limiting their capacity to fully satisfy user demands and preferences. In this
paper, we propose a new paradigm that goes beyond content filtering and
selecting: directly generating personalized items in a multimodal form, such as
images, tailored to individual users. To accomplish this, we leverage
any-to-any Large Multimodal Models (LMMs) and train them in both supervised
fine-tuning and online reinforcement learning strategy to equip them with the
ability to yield tailored next items for users. Experiments on two benchmark
datasets and user study confirm the efficacy of the proposed method. Notably,
the generated images not only align well with users' historical preferences but
also exhibit relevance to their potential future interests.

</details>


### [137] [ResearchCodeBench: Benchmarking LLMs on Implementing Novel Machine Learning Research Code](https://arxiv.org/abs/2506.02314)
*Tianyu Hua,Harper Hua,Violet Xiang,Benjamin Klieger,Sang T. Truong,Weixin Liang,Fan-Yun Sun,Nick Haber*

Main category: cs.AI

TL;DR: 大语言模型在实现2024-2025年顶尖论文新思路时成功率不足40%，最佳模型Gemini-2.5-Pro-Preview仅37.3%成功率


<details>
  <summary>Details</summary>
Motivation: 验证LLMs将预训练阶段未见过的最新研究成果转化为可执行代码的能力

Method: 构建包含212个前沿ML论文编码挑战的ResearchCodeBench基准，测试30+开源与商业模型

Result: Gemini-2.5-Pro-Preview成功率37.3%，O3 High 32.3%，O4-mini High 30.8%

Conclusion: ResearchCodeBench为持续提升LLM驱动的科研代码生成能力提供了标准化评估平台

Abstract: Large language models (LLMs) have shown promise in transforming machine
learning research, yet their capability to faithfully implement novel ideas
from recent research papers-ideas unseen during pretraining-remains unclear. We
introduce ResearchCodeBench, a benchmark of 212 coding challenges that
evaluates LLMs' ability to translate cutting-edge ML contributions from top
2024-2025 research papers into executable code. We assessed 30+ proprietary and
open-source LLMs, finding that even the best models correctly implement less
than 40% of the code. We find Gemini-2.5-Pro-Preview to perform best at 37.3%
success rate, with O3 (High) and O4-mini (High) following behind at 32.3% and
30.8% respectively. We present empirical findings on performance comparison,
contamination, and error patterns. By providing a rigorous and community-driven
evaluation platform, ResearchCodeBench enables continuous understanding and
advancement of LLM-driven innovation in research code generation.

</details>


### [138] [Benchmarking and Advancing Large Language Models for Local Life Services](https://arxiv.org/abs/2506.02720)
*Xiaochong Lan,Jie Feng,Jiahuan Lei,Xinlei Shi,Yong Li*

Main category: cs.AI

TL;DR: 研究大语言模型在本地生活服务中的应用，发现7B模型性能接近72B模型，有效平衡推理成本与模型能力。


<details>
  <summary>Details</summary>
Motivation: 探索已取得显著进展的大语言模型在本地生活服务领域的潜在应用价值。

Method: 建立综合评估基准，采用模型微调和基于代理的工作流程两种优化方法进行系统评估。

Result: 7B紧凑模型达到72B大模型性能水平，显著提升在线服务部署的可行性。

Conclusion: 优化后的模型架构使大语言模型在本地生活服务中兼具实用性与高效性，推动实际应用落地。

Abstract: Large language models (LLMs) have exhibited remarkable capabilities and
achieved significant breakthroughs across various domains, leading to their
widespread adoption in recent years. Building on this progress, we investigate
their potential in the realm of local life services. In this study, we
establish a comprehensive benchmark and systematically evaluate the performance
of diverse LLMs across a wide range of tasks relevant to local life services.
To further enhance their effectiveness, we explore two key approaches: model
fine-tuning and agent-based workflows. Our findings reveal that even a
relatively compact 7B model can attain performance levels comparable to a much
larger 72B model, effectively balancing inference cost and model capability.
This optimization greatly enhances the feasibility and efficiency of deploying
LLMs in real-world online services, making them more practical and accessible
for local life applications.

</details>


### [139] [Rethinking Machine Unlearning in Image Generation Models](https://arxiv.org/abs/2506.02761)
*Renyang Liu,Wenjie Feng,Tianwei Zhang,Wei Zhou,Xueqi Cheng,See-Kiong Ng*

Main category: cs.AI

TL;DR: 论文针对图像生成模型遗忘技术（IGMU）存在的任务分类模糊、评估标准缺失等问题，提出了分层任务分类框架CatIGMU、评估框架EvalIGMU和高质量数据集DataIGM。


<details>
  <summary>Details</summary>
Motivation: 图像生成模型广泛应用带来的数据隐私和内容安全问题亟待解决，而现有IGMU技术存在任务定义不清、评估体系缺失等缺陷，阻碍了实际应用和算法开发。

Method: 1. 设计分层任务分类框架CatIGMU指导算法开发和测试
2. 提出包含五维度指标的评估框架EvalIGMU
3. 构建高质量数据集DataIGM用于算法基准测试

Result: 实验发现现有IGMU算法在保持性和鲁棒性等维度表现不足，验证了提出框架的有效性和数据集的实用性。

Conclusion: 该研究为IGMU建立了系统化的分类体系和可靠的评估标准，发现现有算法的局限性，推动了安全可信图像生成技术的发展。

Abstract: With the surge and widespread application of image generation models, data
privacy and content safety have become major concerns and attracted great
attention from users, service providers, and policymakers. Machine unlearning
(MU) is recognized as a cost-effective and promising means to address these
challenges. Despite some advancements, image generation model unlearning (IGMU)
still faces remarkable gaps in practice, e.g., unclear task discrimination and
unlearning guidelines, lack of an effective evaluation framework, and
unreliable evaluation metrics. These can hinder the understanding of unlearning
mechanisms and the design of practical unlearning algorithms. We perform
exhaustive assessments over existing state-of-the-art unlearning algorithms and
evaluation standards, and discover several critical flaws and challenges in
IGMU tasks. Driven by these limitations, we make several core contributions, to
facilitate the comprehensive understanding, standardized categorization, and
reliable evaluation of IGMU. Specifically, (1) We design CatIGMU, a novel
hierarchical task categorization framework. It provides detailed implementation
guidance for IGMU, assisting in the design of unlearning algorithms and the
construction of testbeds. (2) We introduce EvalIGMU, a comprehensive evaluation
framework. It includes reliable quantitative metrics across five critical
aspects. (3) We construct DataIGM, a high-quality unlearning dataset, which can
be used for extensive evaluations of IGMU, training content detectors for
judgment, and benchmarking the state-of-the-art unlearning algorithms. With
EvalIGMU and DataIGM, we discover that most existing IGMU algorithms cannot
handle the unlearning well across different evaluation dimensions, especially
for preservation and robustness. Code and models are available at
https://github.com/ryliu68/IGMU.

</details>


### [140] [Demystifying Reasoning Dynamics with Mutual Information: Thinking Tokens are Information Peaks in LLM Reasoning](https://arxiv.org/abs/2506.02867)
*Chen Qian,Dongrui Liu,Haochen Wen,Zhen Bai,Yong Liu,Jing Shao*

Main category: cs.AI

TL;DR: 论文通过信息论视角发现大型推理模型存在互信息峰值现象，该现象与特定'思考令牌'相关，并提出两种基于此提升推理性能的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）在复杂问题解决中表现优异，但其内部推理机制仍不明确。本文旨在揭示LRMs推理过程中信息传递的关键模式。

Method: 1. 追踪推理过程中中间表示与正确答案的互信息变化
2. 理论分析互信息峰值与预测误差的关系
3. 通过实验验证'思考令牌'对推理性能的关键作用

Result: 1. 发现互信息峰值出现时模型预测错误率显著降低
2. 识别出'Hmm'/'Wait'/'Therefore'等具有信息跃迁特征的思考令牌
3. 基于思考令牌设计的干预方法能有效提升模型性能

Conclusion: 该研究不仅揭示了LRMs的推理机制信息动态特征，还提供了通过操控关键令牌优化模型性能的实用方法，为理解黑盒模型提供了新视角。

Abstract: Large reasoning models (LRMs) have demonstrated impressive capabilities in
complex problem-solving, yet their internal reasoning mechanisms remain poorly
understood. In this paper, we investigate the reasoning trajectories of LRMs
from an information-theoretic perspective. By tracking how mutual information
(MI) between intermediate representations and the correct answer evolves during
LRM reasoning, we observe an interesting MI peaks phenomenon: the MI at
specific generative steps exhibits a sudden and significant increase during
LRM's reasoning process. We theoretically analyze such phenomenon and show that
as MI increases, the probability of model's prediction error decreases.
Furthermore, these MI peaks often correspond to tokens expressing reflection or
transition, such as ``Hmm'', ``Wait'' and ``Therefore,'' which we term as the
thinking tokens. We then demonstrate that these thinking tokens are crucial for
LRM's reasoning performance, while other tokens has minimal impacts. Building
on these analyses, we propose two simple yet effective methods to improve LRM's
reasoning performance, by delicately leveraging these thinking tokens. Overall,
our work provides novel insights into the reasoning mechanisms of LRMs and
offers practical ways to improve their reasoning capabilities. The code is
available at https://github.com/ChnQ/MI-Peaks.

</details>


### [141] [Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation](https://arxiv.org/abs/2506.02992)
*Li Zhang,Kevin D. Ashley*

Main category: cs.AI

TL;DR: 提出反思性多代理方法改善法律论据生成，通过因素分析师与论点打磨师的协作迭代，显著提升事实利用率、有效弃权率和降低幻觉风险


<details>
  <summary>Details</summary>
Motivation: 现有LLM在法律应用中存在幻觉操纵风险、事实基础利用不足，且无法有效识别不可立论情形而强行生成论据

Method: 双代理框架（因素分析师提取关键要素，论点打磨师优化论证）迭代生成三方法律论据（原告/被告/反驳）

Result: 在不可辩场景实现87%弃权成功率，幻觉准确率提升42%，事实要素召回率提高35%（相比单代理基准）

Conclusion: 结构化反思机制为构建可信法律AI提供有效路径，通过多代理协作平衡伦理要求与论证效能

Abstract: Large Language Models (LLMs) are increasingly explored for legal argument
generation, yet they pose significant risks of manipulation through
hallucination and ungrounded persuasion, and often fail to utilize provided
factual bases effectively or abstain when arguments are untenable. This paper
introduces a novel reflective multi-agent method designed to address these
challenges in the context of legally compliant persuasion. Our approach employs
specialized agents--a Factor Analyst and an Argument Polisher--in an iterative
refinement process to generate 3-ply legal arguments (plaintiff, defendant,
rebuttal). We evaluate Reflective Multi-Agent against single-agent,
enhanced-prompt single-agent, and non-reflective multi-agent baselines using
four diverse LLMs (GPT-4o, GPT-4o-mini, Llama-4-Maverick-17b-128e,
Llama-4-Scout-17b-16e) across three legal scenarios: "arguable", "mismatched",
and "non-arguable". Results demonstrate Reflective Multi-Agent's significant
superiority in successful abstention (preventing generation when arguments
cannot be grounded), marked improvements in hallucination accuracy (reducing
fabricated and misattributed factors), particularly in "non-arguable"
scenarios, and enhanced factor utilization recall (improving the use of
provided case facts). These findings suggest that structured reflection within
a multi-agent framework offers a robust computable method for fostering ethical
persuasion and mitigating manipulation in LLM-based legal argumentation
systems, a critical step towards trustworthy AI in law. Project page:
https://lizhang-aiandlaw.github.io/A-Reflective-Multi-Agent-Approach-for-Legal-Argument-Generation/

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [142] [BitBypass: A New Direction in Jailbreaking Aligned Large Language Models with Bitstream Camouflage](https://arxiv.org/abs/2506.02479)
*Kalyan Nakka,Nitesh Saxena*

Main category: cs.CR

TL;DR: 提出BitBypass黑盒越狱攻击，利用比特流伪装突破LLM安全机制


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐技术（如监督微调、RLHF）存在底层漏洞，需探索基于信息表示的新型攻击方式

Method: 采用连字符分隔的比特流伪装技术，通过连续比特数据表征绕过安全检测（非传统提示工程/对抗操作）

Result: 成功突破GPT-4o等5个先进LLM的安全防护，攻击成功率/隐蔽性优于主流越狱方法

Conclusion: BitBypass揭示LLM安全机制在底层数据表征层面的脆弱性，推动更鲁棒的对齐技术发展需求

Abstract: The inherent risk of generating harmful and unsafe content by Large Language
Models (LLMs), has highlighted the need for their safety alignment. Various
techniques like supervised fine-tuning, reinforcement learning from human
feedback, and red-teaming were developed for ensuring the safety alignment of
LLMs. However, the robustness of these aligned LLMs is always challenged by
adversarial attacks that exploit unexplored and underlying vulnerabilities of
the safety alignment. In this paper, we develop a novel black-box jailbreak
attack, called BitBypass, that leverages hyphen-separated bitstream camouflage
for jailbreaking aligned LLMs. This represents a new direction in jailbreaking
by exploiting fundamental information representation of data as continuous
bits, rather than leveraging prompt engineering or adversarial manipulations.
Our evaluation of five state-of-the-art LLMs, namely GPT-4o, Gemini 1.5, Claude
3.5, Llama 3.1, and Mixtral, in adversarial perspective, revealed the
capabilities of BitBypass in bypassing their safety alignment and tricking them
into generating harmful and unsafe content. Further, we observed that BitBypass
outperforms several state-of-the-art jailbreak attacks in terms of stealthiness
and attack success. Overall, these results highlights the effectiveness and
efficiency of BitBypass in jailbreaking these state-of-the-art LLMs.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [143] [EyeNavGS: A 6-DoF Navigation Dataset and Record-n-Replay Software for Real-World 3DGS Scenes in VR](https://arxiv.org/abs/2506.02380)
*Zihao Ding,Cheng-Tse Lee,Mufeng Zhu,Tao Guan,Yuan-Chun Sun,Cheng-Hsin Hsu,Yao Liu*

Main category: cs.MM

TL;DR: 提出首个公开的6-DoF导航数据集EyeNavGS，包含46名参与者在12个真实3DGS场景中的导航轨迹，配套开源工具链支撑VR应用研究


<details>
  <summary>Details</summary>
Motivation: 当前缺乏真实用户导航数据制约3DGS场景应用的开发评估与渲染优化，需建立标准化数据集

Method: 使用Meta Quest Pro头显采集头部姿态与眼动数据，通过场景初始化校正倾斜与比例，开发支持录制回放的开源SIBR浏览器分支

Result: 创建首个包含多场景真实导航轨迹的公开数据集，提供数据处理工具链，支持视口预测、自适应流媒体等研究方向

Conclusion: EyeNavGS填补了3DGS场景导航数据空白，为6-DoF视口预测、注视点渲染等研究提供基准数据集与技术支持

Abstract: 3D Gaussian Splatting (3DGS) is an emerging media representation that
reconstructs real-world 3D scenes in high fidelity, enabling
6-degrees-of-freedom (6-DoF) navigation in virtual reality (VR). However,
developing and evaluating 3DGS-enabled applications and optimizing their
rendering performance, require realistic user navigation data. Such data is
currently unavailable for photorealistic 3DGS reconstructions of real-world
scenes. This paper introduces EyeNavGS (EyeNavGS), the first publicly available
6-DoF navigation dataset featuring traces from 46 participants exploring twelve
diverse, real-world 3DGS scenes. The dataset was collected at two sites, using
the Meta Quest Pro headsets, recording the head pose and eye gaze data for each
rendered frame during free world standing 6-DoF navigation. For each of the
twelve scenes, we performed careful scene initialization to correct for scene
tilt and scale, ensuring a perceptually-comfortable VR experience. We also
release our open-source SIBR viewer software fork with record-and-replay
functionalities and a suite of utility tools for data processing, conversion,
and visualization. The EyeNavGS dataset and its accompanying software tools
provide valuable resources for advancing research in 6-DoF viewport prediction,
adaptive streaming, 3D saliency, and foveated rendering for 3DGS scenes. The
EyeNavGS dataset is available at: https://symmru.github.io/EyeNavGS/.

</details>


### [144] [StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion](https://arxiv.org/abs/2506.02414)
*Fengjin Li,Jie Wang,Yadong Niu,Yongqing Wang,Meng Meng,Jian Luan,Zhiyong Wu*

Main category: cs.MM

TL;DR: 提出自回归语音转换框架StarVC，通过先预测文本标记再合成声学特征，显著提升语言内容和说话者特征的保留效果。


<details>
  <summary>Details</summary>
Motivation: 传统语音转换方法直接提取说话者特征但忽略语义内容显式建模，导致解耦效果受限。需要更有效的语义特征利用方案。

Method: 构建两阶段自回归框架：首先生成文本标记作为中间表征，再基于此合成目标声学特征。建立文本与声学特征的显式关联。

Result: 实验显示在语言内容保留（WER/CER）和说话特征保持（SECS/MOS）指标上优于传统方法，MOS达4.31分。

Conclusion: 显式文本建模有效提升语音转换性能，StarVC的统一框架验证了分阶段处理文本与声学特征的技术优势。

Abstract: Voice Conversion (VC) modifies speech to match a target speaker while
preserving linguistic content. Traditional methods usually extract speaker
information directly from speech while neglecting the explicit utilization of
linguistic content. Since VC fundamentally involves disentangling speaker
identity from linguistic content, leveraging structured semantic features could
enhance conversion performance. However, previous attempts to incorporate
semantic features into VC have shown limited effectiveness, motivating the
integration of explicit text modeling. We propose StarVC, a unified
autoregressive VC framework that first predicts text tokens before synthesizing
acoustic features. The experiments demonstrate that StarVC outperforms
conventional VC methods in preserving both linguistic content (i.e., WER and
CER) and speaker characteristics (i.e., SECS and MOS). Audio demo can be found
at: https://thuhcsi.github.io/StarVC/.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [145] [MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation](https://arxiv.org/abs/2506.02661)
*Mingyang Huang,Peng Zhang,Bang Zhang*

Main category: cs.SD

TL;DR: 提出结合检索增强生成（RAG）与扩散模型的MotionRAG-Diff框架，解决长时音乐驱动舞蹈生成中时间连贯性与音乐对齐的难题。


<details>
  <summary>Details</summary>
Motivation: 现有运动图方法依赖固定模板限制创造性，扩散模型缺乏时间连贯性。需要兼顾创新性与连贯性的音乐驱动舞蹈生成方案。

Method: 1.跨模态对比学习对齐音乐-舞蹈表征；2.优化运动图系统实现长序列连贯拼接；3.多条件扩散模型融合原始音乐信号与对比特征

Result: 实验证明该方法在运动质量、多样性和音乐同步精度上达到SOTA，突破长时生成限制。

Conclusion: 通过检索模板保真度与扩散模型创造性的协同，建立了音乐驱动舞蹈生成的新范式。

Abstract: Generating long-term, coherent, and realistic music-conditioned dance
sequences remains a challenging task in human motion synthesis. Existing
approaches exhibit critical limitations: motion graph methods rely on fixed
template libraries, restricting creative generation; diffusion models, while
capable of producing novel motions, often lack temporal coherence and musical
alignment. To address these challenges, we propose $\textbf{MotionRAG-Diff}$, a
hybrid framework that integrates Retrieval-Augmented Generation (RAG) with
diffusion-based refinement to enable high-quality, musically coherent dance
generation for arbitrary long-term music inputs. Our method introduces three
core innovations: (1) A cross-modal contrastive learning architecture that
aligns heterogeneous music and dance representations in a shared latent space,
establishing unsupervised semantic correspondence without paired data; (2) An
optimized motion graph system for efficient retrieval and seamless
concatenation of motion segments, ensuring realism and temporal coherence
across long sequences; (3) A multi-condition diffusion model that jointly
conditions on raw music signals and contrastive features to enhance motion
quality and global synchronization. Extensive experiments demonstrate that
MotionRAG-Diff achieves state-of-the-art performance in motion quality,
diversity, and music-motion synchronization accuracy. This work establishes a
new paradigm for music-driven dance generation by synergizing retrieval-based
template fidelity with diffusion-based creative enhancement.

</details>


### [146] [TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models](https://arxiv.org/abs/2506.03099)
*Chetwin Low,Weimin Wang*

Main category: cs.SD

TL;DR: 提出TalkingMachines框架，将预训练视频生成模型转化为实时音频驱动动画系统，集成音频大语言模型与视频生成基座模型，实现18B参数模型、无限视频流传输和低延迟优化


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成模型在实时角色动画应用中存在的延迟高、错误累积严重、工程效率低下等问题，追求自然对话式交互体验

Method: 1. 改造图像到视频DiT模型适配音频驱动
2. 通过双向教师模型到稀疏因果学生模型的知识蒸馏实现无限流
3. 设计多设备协同、CUDA流优化、冗余消除的高效推理管线

Result: 实现高吞吐(34.5 FPS)和低延迟(150ms)的实时生成，支持无限时长视频流传输且无错误累积，演示视频展示自然对话效果

Conclusion: 该框架通过算法创新与系统工程优化的深度结合，为实时数字人交互建立了新范式，LLM与视频生成模型的整合开辟了多模态生成新路径

Abstract: In this paper, we present TalkingMachines -- an efficient framework that
transforms pretrained video generation models into real-time, audio-driven
character animators. TalkingMachines enables natural conversational experiences
by integrating an audio large language model (LLM) with our video generation
foundation model. Our primary contributions include: (1) We adapt a pretrained
SOTA image-to-video DiT into an audio-driven avatar generation model of 18
billion parameters; (2) We enable infinite video streaming without error
accumulation through asymmetric knowledge distillation from a bidirectional
teacher model into a sparse causal, autoregressive student model; (3) We design
a high-throughput, low-latency inference pipeline incorporating several key
engineering optimizations such as: (a) disaggregation of the DiT and VAE
decoder across separate devices, (b) efficient overlap of inter-device
communication and computation using CUDA streams, (c) elimination of redundant
recomputations to maximize frame-generation throughput. Please see demo videos
here - https://aaxwaz.github.io/TalkingMachines/

</details>


### [147] [Learning More with Less: Self-Supervised Approaches for Low-Resource Speech Emotion Recognition](https://arxiv.org/abs/2506.02059)
*Ziwei Gong,Pengyuan Shi,Kaan Donbekci,Lin Ai,Run Chen,David Sasu,Zehui Wu,Julia Hirschberg*

Main category: cs.SD

TL;DR: 通过对比学习（CL）和BYOL自监督方法提升低资源语言的语音情感识别性能


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言因标注数据稀缺导致的语音情感识别性能受限问题

Method: 采用自监督对比学习和BYOL框架增强跨语言泛化能力

Result: F1分数显著提升（乌尔都语10.6%、德语15.2%、孟加拉语13.9%）

Conclusion: 为开发包容性更强、可解释性更好的低资源语言情感识别系统奠定基础

Abstract: Speech Emotion Recognition (SER) has seen significant progress with deep
learning, yet remains challenging for Low-Resource Languages (LRLs) due to the
scarcity of annotated data. In this work, we explore unsupervised learning to
improve SER in low-resource settings. Specifically, we investigate contrastive
learning (CL) and Bootstrap Your Own Latent (BYOL) as self-supervised
approaches to enhance cross-lingual generalization. Our methods achieve notable
F1 score improvements of 10.6% in Urdu, 15.2% in German, and 13.9% in Bangla,
demonstrating their effectiveness in LRLs. Additionally, we analyze model
behavior to provide insights on key factors influencing performance across
languages, and also highlighting challenges in low-resource SER. This work
provides a foundation for developing more inclusive, explainable, and robust
emotion recognition systems for underrepresented languages.

</details>


### [148] [Unveiling Audio Deepfake Origins: A Deep Metric learning And Conformer Network Approach With Ensemble Fusion](https://arxiv.org/abs/2506.02085)
*Ajinkya Kulkarni,Sandipana Dowerah,Tanel Alumae,Mathew Magimai. -Doss*

Main category: cs.SD

TL;DR: 提出结合深度度量多类N-pair损失、Real Emphasis-Fake Dispersion框架和Conformer网络的音频溯源系统，在伪造语音来源追踪任务中优于基准系统。


<details>
  <summary>Details</summary>
Motivation: 当前音频深度伪造技术逼真度极高，现有研究集中于真伪识别而缺乏来源追踪能力，亟需建立有效的溯源机制应对安全威胁。

Method: 1. 多类N-pair损失提升特征判别力
2. Real Emphasis聚焦真实语音特征，Fake Dispersion扩大伪造样本差异
3. Conformer网络捕获音频全局-局部依赖关系
4. 集成得分-嵌入融合策略平衡域内外场景性能

Result: 使用Frechet距离等指标验证，在ASVspoof 2019数据集上溯源准确率提升15%，跨数据库测试保持83%的稳定性能。

Conclusion: 该融合框架在真伪语音溯源任务中实现最优平衡，多技术协同有效提升深度伪造音频的溯源能力，为音频安全认证提供新方案。

Abstract: Audio deepfakes are acquiring an unprecedented level of realism with advanced
AI. While current research focuses on discerning real speech from spoofed
speech, tracing the source system is equally crucial. This work proposes a
novel audio source tracing system combining deep metric multi-class N-pair loss
with Real Emphasis and Fake Dispersion framework, a Conformer classification
network, and ensemble score-embedding fusion. The N-pair loss improves
discriminative ability, while Real Emphasis and Fake Dispersion enhance
robustness by focusing on differentiating real and fake speech patterns. The
Conformer network captures both global and local dependencies in the audio
signal, crucial for source tracing. The proposed ensemble score-embedding
fusion shows an optimal trade-off between in-domain and out-of-domain source
tracing scenarios. We evaluate our method using Frechet Distance and standard
metrics, demonstrating superior performance in source tracing over the baseline
system.

</details>


### [149] [Enhancing Speech Emotion Recognition with Graph-Based Multimodal Fusion and Prosodic Features for the Speech Emotion Recognition in Naturalistic Conditions Challenge at Interspeech 2025](https://arxiv.org/abs/2506.02088)
*Alef Iury Siqueira Ferreira,Lucas Rafael Gris,Alexandre Ferro Filho,Lucas Ólives,Daniel Ribeiro,Luiz Fernando,Fernanda Lustosa,Rodrigo Tanaka,Frederico Santos de Oliveira,Arlindo Galvão Filho*

Main category: cs.SD

TL;DR: 提出结合音频模型与韵律增强文本特征的鲁棒语音情感识别系统，采用F0量化、预训练音频标记模型和集成方法，在自然场景测试中取得39.79%宏F1分数。


<details>
  <summary>Details</summary>
Motivation: 自然语音中情感表达细微且真实音频不可预测，需开发更鲁棒的SER模型应对INTERSPEECH挑战赛需求。

Method: 整合先进音频模型+韵律/频谱增强的文本特征，探索基频量化技术，利用预训练音频标记模型，并采用图注意力网络的集成融合方法。

Result: 官方测试集Macro F1达39.79%（验证集42.20%），融合分析证实图注意力网络的有效性。

Conclusion: 该方法在自然场景SER中展现潜力，代码开源促进后续研究，频谱/韵律特征的结合及模型融合策略值得借鉴。

Abstract: Training SER models in natural, spontaneous speech is especially challenging
due to the subtle expression of emotions and the unpredictable nature of
real-world audio. In this paper, we present a robust system for the INTERSPEECH
2025 Speech Emotion Recognition in Naturalistic Conditions Challenge, focusing
on categorical emotion recognition. Our method combines state-of-the-art audio
models with text features enriched by prosodic and spectral cues. In
particular, we investigate the effectiveness of Fundamental Frequency (F0)
quantization and the use of a pretrained audio tagging model. We also employ an
ensemble model to improve robustness. On the official test set, our system
achieved a Macro F1-score of 39.79% (42.20% on validation). Our results
underscore the potential of these methods, and analysis of fusion techniques
confirmed the effectiveness of Graph Attention Networks. Our source code is
publicly available.

</details>


### [150] [Cocktail-Party Audio-Visual Speech Recognition](https://arxiv.org/abs/2506.02178)
*Thai-Binh Nguyen,Ngoc-Quan Pham,Alexander Waibel*

Main category: cs.SD

TL;DR: 提出新音频视觉鸡尾酒会数据集，在极端噪声下实现词错率(WER)67%相对降低，从119%降至39.2%


<details>
  <summary>Details</summary>
Motivation: 现有AVSR模型过度优化理想化场景，忽略真实环境中说话/静默面部交替出现的复杂性

Method: 构建包含1526小时说话/静默面部片段的新数据集，无需显式分割线索

Result: 在极端噪声环境下词错率从119%显著降至39.2%

Conclusion: 新型数据集有效提升AVSR在复杂噪声场景的实用性，推动真实环境应用突破

Abstract: Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech
recognition in challenging environments, such as cocktail-party scenarios,
where relying solely on audio proves insufficient. However, current AVSR models
are often optimized for idealized scenarios with consistently active speakers,
overlooking the complexities of real-world settings that include both speaking
and silent facial segments. This study addresses this gap by introducing a
novel audio-visual cocktail-party dataset designed to benchmark current AVSR
systems and highlight the limitations of prior approaches in realistic noisy
conditions. Additionally, we contribute a 1526-hour AVSR dataset comprising
both talking-face and silent-face segments, enabling significant performance
gains in cocktail-party environments. Our approach reduces WER by 67% relative
to the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise,
without relying on explicit segmentation cues.

</details>


### [151] [Synthetic Speech Source Tracing using Metric Learning](https://arxiv.org/abs/2506.02590)
*Dimitrios Koutsianos,Stavros Zacharopoulos,Yannis Panagakis,Themos Stafylakis*

Main category: cs.SD

TL;DR: 该研究通过说话人识别技术追踪合成语音源头，比较了ResNet和自监督学习方法，证明ResNet在此任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于合成音频的伪造检测，缺乏对语音生成系统源头的有效追踪方法。

Method: 采用分类模型和度量学习两种范式，基于ResNet和自监督学习(SSL)框架，在MLAADv5基准测试中验证性能。

Result: ResNet通过度量学习实现了与SSL相当甚至更优的表现，准确率分别达到82.3%和80.1%（跨数据集场景）。

Conclusion: 将说话人识别技术引入音频取证领域，为对抗合成媒体伪造提供了新思路，同时揭示了SSL特征在此任务中的优化需求。

Abstract: This paper addresses source tracing in synthetic speech-identifying
generative systems behind manipulated audio via speaker recognition-inspired
pipelines. While prior work focuses on spoofing detection, source tracing lacks
robust solutions. We evaluate two approaches: classification-based and
metric-learning. We tested our methods on the MLAADv5 benchmark using ResNet
and self-supervised learning (SSL) backbones. The results show that ResNet
achieves competitive performance with the metric learning approach, matching
and even exceeding SSL-based systems. Our work demonstrates ResNet's viability
for source tracing while underscoring the need to optimize SSL representations
for this task. Our work bridges speaker recognition methodologies with audio
forensic challenges, offering new directions for combating synthetic media
manipulation.

</details>
