{"id": "2505.23301", "pdf": "https://arxiv.org/pdf/2505.23301", "abs": "https://arxiv.org/abs/2505.23301", "authors": ["Rim Rekik", "Stefanie Wuhrer", "Ludovic Hoyet", "Katja Zibrek", "Anne-H\u00e9l\u00e8ne Olivier"], "title": "Quality assessment of 3D human animation: Subjective and objective evaluation", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Virtual human animations have a wide range of applications in virtual and\naugmented reality. While automatic generation methods of animated virtual\nhumans have been developed, assessing their quality remains challenging.\nRecently, approaches introducing task-oriented evaluation metrics have been\nproposed, leveraging neural network training. However, quality assessment\nmeasures for animated virtual humans that are not generated with parametric\nbody models have yet to be developed. In this context, we introduce a first\nsuch quality assessment measure leveraging a novel data-driven framework.\nFirst, we generate a dataset of virtual human animations together with their\ncorresponding subjective realism evaluation scores collected with a user study.\nSecond, we use the resulting dataset to learn predicting perceptual evaluation\nscores. Results indicate that training a linear regressor on our dataset\nresults in a correlation of 90%, which outperforms a state of the art deep\nlearning baseline.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u975e\u53c2\u6570\u5316\u865a\u62df\u4eba\u52a8\u753b\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u6570\u636e\u96c6\u8bad\u7ec3\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u5b9e\u73b090%\u7684\u611f\u77e5\u8bc4\u5206\u9884\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u9488\u5bf9\u975e\u53c2\u6570\u5316\u865a\u62df\u4eba\u52a8\u753b\u7f3a\u4e4f\u6709\u6548\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u7684\u95ee\u9898\uff0c\u586b\u8865\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d\u3002", "method": "1. \u6784\u5efa\u542b\u4e3b\u89c2\u771f\u5b9e\u611f\u8bc4\u5206\u7684\u865a\u62df\u4eba\u52a8\u753b\u6570\u636e\u96c6\n2. \u4f7f\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u611f\u77e5\u8bc4\u5206", "result": "\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8fbe\u523090%\u76f8\u5173\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u6570\u636e\u9a71\u52a8\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u865a\u62df\u4eba\u52a8\u753b\u7684\u771f\u5b9e\u611f\u8bc4\u5206\uff0c\u4e3a\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u65b0\u65b9\u6848"}}
{"id": "2505.23447", "pdf": "https://arxiv.org/pdf/2505.23447", "abs": "https://arxiv.org/abs/2505.23447", "authors": ["Sara Johansson Fernstad", "Sarah Alsufyani", "Silvia Del Din", "Alison Yarnall", "Lynn Rochester"], "title": "To Measure What Isn't There -- Visual Exploration of Missingness Structures Using Quality Metrics", "categories": ["cs.GR", "cs.HC"], "comment": "Submitted to IEEE Vis2025", "summary": "This paper contributes a set of quality metrics for identification and visual\nanalysis of structured missingness in high-dimensional data. Missing values in\ndata are a frequent challenge in most data generating domains and may cause a\nrange of analysis issues. Structural missingness in data may indicate issues in\ndata collection and pre-processing, but may also highlight important data\ncharacteristics. While research into statistical methods for dealing with\nmissing data are mainly focusing on replacing missing values with plausible\nestimated values, visualization has great potential to support a more in-depth\nunderstanding of missingness structures in data. Nonetheless, while the\ninterest in missing data visualization has increased in the last decade, it is\nstill a relatively overlooked research topic with a comparably small number of\npublications, few of which address scalability issues. Efficient visual\nanalysis approaches are needed to enable exploration of missingness structures\nin large and high-dimensional data, and to support informed decision-making in\ncontext of potential data quality issues. This paper suggests a set of quality\nmetrics for identification of patterns of interest for understanding of\nstructural missingness in data. These quality metrics can be used as guidance\nin visual analysis, as demonstrated through a use case exploring structural\nmissingness in data from a real-life walking monitoring study. All supplemental\nmaterials for this paper are available at\nhttps://doi.org/10.25405/data.ncl.c.7741829.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u5957\u8d28\u91cf\u6307\u6807\u7ed3\u5408\u53ef\u89c6\u5316\u65b9\u6cd5\u5206\u6790\u9ad8\u7ef4\u6570\u636e\u7f3a\u5931\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u9a8c\u8bc1\u6709\u6548\u6027", "motivation": "\u73b0\u6709\u7edf\u8ba1\u65b9\u6cd5\u4e3b\u8981\u805a\u7126\u7f3a\u5931\u503c\u586b\u8865\uff0c\u800c\u53ef\u89c6\u5316\u5206\u6790\u80fd\u6df1\u5165\u7406\u89e3\u7f3a\u5931\u7ed3\u6784\u3002\u4f46\u76ee\u524d\u76f8\u5173\u7814\u7a76\u8f83\u5c11\u4e14\u7f3a\u4e4f\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u7684\u6709\u6548\u65b9\u6848", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u7f3a\u5931\u8d28\u91cf\u6307\u6807\u4f53\u7cfb\uff0c\u7ed3\u5408\u89c6\u89c9\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b65\u884c\u76d1\u6d4b\u7814\u7a76\u7684\u771f\u5b9e\u6570\u636e\u8fdb\u884c\u9a8c\u8bc1", "result": "\u6210\u529f\u5e94\u7528\u4e8e\u771f\u5b9e\u6b65\u884c\u76d1\u6d4b\u6570\u636e\u6848\u4f8b\uff0c\u6240\u6709\u8865\u5145\u6750\u6599\u5df2\u5728\u5f00\u653e\u5e73\u53f0\u516c\u5f00\uff08DOI:10.25405/data.ncl.c.7741829\uff09", "conclusion": "\u8be5\u8d28\u91cf\u6307\u6807\u4f53\u7cfb\u80fd\u6709\u6548\u6307\u5bfc\u6570\u636e\u7f3a\u5931\u7ed3\u6784\u7684\u89c6\u89c9\u5206\u6790\uff0c\u652f\u6301\u5728\u6570\u636e\u8d28\u91cf\u95ee\u9898\u80cc\u666f\u4e0b\u8fdb\u884c\u79d1\u5b66\u51b3\u7b56\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5927\u89c4\u6a21\u9ad8\u7ef4\u6570\u636e\u5206\u6790\u573a\u666f"}}
{"id": "2505.23617", "pdf": "https://arxiv.org/pdf/2505.23617", "abs": "https://arxiv.org/abs/2505.23617", "authors": ["Chenhao Zheng", "Jieyu Zhang", "Mohammadreza Salehi", "Ziqi Gao", "Vishnu Iyengar", "Norimasa Kobori", "Quan Kong", "Ranjay Krishna"], "title": "One Trajectory, One Token: Grounded Video Tokenization via Panoptic Sub-object Trajectory", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "comment": null, "summary": "Effective video tokenization is critical for scaling transformer models for\nlong videos. Current approaches tokenize videos using space-time patches,\nleading to excessive tokens and computational inefficiencies. The best token\nreduction strategies degrade performance and barely reduce the number of tokens\nwhen the camera moves. We introduce grounded video tokenization, a paradigm\nthat organizes tokens based on panoptic sub-object trajectories rather than\nfixed patches. Our method aligns with fundamental perceptual principles,\nensuring that tokenization reflects scene complexity rather than video\nduration. We propose TrajViT, a video encoder that extracts object trajectories\nand converts them into semantically meaningful tokens, significantly reducing\nredundancy while maintaining temporal coherence. Trained with contrastive\nlearning, TrajViT significantly outperforms space-time ViT (ViT3D) across\nmultiple video understanding benchmarks, e.g., TrajViT outperforms ViT3D by a\nlarge margin of 6% top-5 recall in average at video-text retrieval task with\n10x token deduction. We also show TrajViT as a stronger model than ViT3D for\nbeing the video encoder for modern VideoLLM, obtaining an average of 5.2%\nperformance improvement across 6 VideoQA benchmarks while having 4x faster\ntraining time and 18x less inference FLOPs. TrajViT is the first efficient\nencoder to consistently outperform ViT3D across diverse video analysis tasks,\nmaking it a robust and scalable solution.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u8c61\u8f68\u8ff9\u7684\u89c6\u9891\u6807\u8bb0\u65b9\u6cd5TrajViT\uff0c\u663e\u8457\u51cf\u5c11\u5197\u4f59\u4ee4\u724c\u5e76\u63d0\u5347\u591a\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u57fa\u4e8e\u65f6\u7a7a\u8865\u4e01\u7684\u89c6\u9891\u6807\u8bb0\u65b9\u6cd5\u4ea7\u751f\u5197\u4f59\u4ee4\u724c\u4e14\u8ba1\u7b97\u4f4e\u6548\uff0c\u5728\u6444\u50cf\u673a\u79fb\u52a8\u65f6\u5c24\u5176\u7a81\u51fa", "method": "\u63d0\u51fagrounded video tokenization\u8303\u5f0f\uff0c\u901a\u8fc7\u5bf9\u8c61\u8f68\u8ff9\u751f\u6210\u8bed\u4e49\u5316\u4ee4\u724c\uff0c\u5f00\u53d1TrajViT\u89c6\u9891\u7f16\u7801\u5668", "result": "\u89c6\u9891\u6587\u672c\u68c0\u7d22\u4efb\u52a1Top-5\u53ec\u56de\u7387\u63d0\u53476%\uff0810\u500d\u4ee4\u724c\u7f29\u51cf\uff09\uff0cVideoQA\u4efb\u52a1\u5e73\u5747\u63d0\u53475.2%\uff084\u500d\u8bad\u7ec3\u901f\u5ea6\uff0c18\u500d\u63a8\u7406FLOPs\u51cf\u5c11\uff09", "conclusion": "TrajViT\u6210\u4e3a\u9996\u4e2a\u5728\u591a\u6837\u5316\u89c6\u9891\u4efb\u52a1\u4e2d\u6301\u7eed\u8d85\u8d8aViT3D\u7684\u9ad8\u6548\u7f16\u7801\u5668\uff0c\u517c\u5177\u9c81\u68d2\u6027\u548c\u6269\u5c55\u6027"}}
{"id": "2505.23685", "pdf": "https://arxiv.org/pdf/2505.23685", "abs": "https://arxiv.org/abs/2505.23685", "authors": ["Raffles Xingqi Zhu", "Charlie S. Burlingham", "Olivier Mercier", "Phillip Guan"], "title": "Errors in Stereo Geometry Induce Distance Misperception", "categories": ["cs.HC", "cs.GR"], "comment": null, "summary": "Stereoscopic head-mounted displays (HMDs) render and present binocular images\nto create an egocentric, 3D percept to the HMD user. Within this render and\npresentation pipeline there are potential rendering camera and viewing position\nerrors that can induce deviations in the depth and distance that a user\nperceives compared to the underlying intended geometry. For example, rendering\nerrors can arise when HMD render cameras are incorrectly positioned relative to\nthe assumed centers of projections of the HMD displays and viewing errors can\narise when users view stereo geometry from the incorrect location in the HMD\neyebox. In this work we present a geometric framework that predicts errors in\ndistance perception arising from inaccurate HMD perspective geometry and build\nan HMD platform to reliably simulate render and viewing error in a Quest 3 HMD\nwith eye tracking to experimentally test these predictions. We present a series\nof five experiments to explore the efficacy of this geometric framework and\nshow that errors in perspective geometry can induce both under- and\nover-estimations in perceived distance. We further demonstrate how real-time\nvisual feedback can be used to dynamically recalibrate visuomotor mapping so\nthat an accurate reach distance is achieved even if the perceived visual\ndistance is negatively impacted by geometric error.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u51e0\u4f55\u6846\u67b6\u9884\u6d4bHMD\u6e32\u67d3\u8bef\u5dee\u5bfc\u81f4\u7684\u89c6\u89c9\u8ddd\u79bb\u504f\u5dee\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u8bef\u5dee\u5f71\u54cd\u5e76\u63d0\u51fa\u5b9e\u65f6\u89c6\u89c9\u53cd\u9988\u6821\u51c6\u65b9\u6848", "motivation": "\u89e3\u51b3\u5934\u6234\u663e\u793a\u5668\u56e0\u6e32\u67d3\u76f8\u673a\u4f4d\u7f6e\u9519\u8bef\u548c\u7528\u6237\u89c2\u5bdf\u4f4d\u7f6e\u504f\u5dee\u5bfc\u81f4\u7684\u6df1\u5ea6\u611f\u77e5\u5931\u771f\u95ee\u9898\uff0c\u63d0\u5347\u865a\u62df\u73b0\u5b9e\u4f53\u9a8c\u51c6\u786e\u6027", "method": "\u5f00\u53d1\u51e0\u4f55\u9884\u6d4b\u6846\u67b6\uff0c\u6784\u5efaQuest3\u773c\u52a8\u8ffd\u8e2a\u5b9e\u9a8c\u5e73\u53f0\uff0c\u8bbe\u8ba1\u4e94\u7ec4\u9a8c\u8bc1\u5b9e\u9a8c\u5e76\u5f15\u5165\u5b9e\u65f6\u89c6\u89c9\u53cd\u9988\u673a\u5236", "result": "\u8bc1\u5b9e\u51e0\u4f55\u8bef\u5dee\u4f1a\u5f15\u8d77\u8ddd\u79bb\u611f\u77e5\u9ad8\u4f30/\u4f4e\u4f30\uff0c\u8bc1\u660e\u89c6\u89c9\u53cd\u9988\u53ef\u52a8\u6001\u6821\u51c6\u89c6\u89c9\u8fd0\u52a8\u6620\u5c04\u5b9e\u73b0\u51c6\u786e\u64cd\u4f5c", "conclusion": "HMD\u51e0\u4f55\u8bef\u5dee\u663e\u8457\u5f71\u54cd\u7a7a\u95f4\u611f\u77e5\uff0c\u4f46\u53ef\u901a\u8fc7\u5b9e\u65f6\u53cd\u9988\u673a\u5236\u8865\u507f\uff0c\u4e3a\u6539\u8fdb\u865a\u62df\u73b0\u5b9e\u663e\u793a\u6280\u672f\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e"}}
{"id": "2505.22704", "pdf": "https://arxiv.org/pdf/2505.22704", "abs": "https://arxiv.org/abs/2505.22704", "authors": ["Feng Yao", "Zilong Wang", "Liyuan Liu", "Junxia Cui", "Li Zhong", "Xiaohan Fu", "Haohui Mai", "Vish Krishnan", "Jianfeng Gao", "Jingbo Shang"], "title": "Training Language Models to Generate Quality Code with Program Analysis Feedback", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, 3 figures", "summary": "Code generation with large language models (LLMs), often termed vibe coding,\nis increasingly adopted in production but fails to ensure code quality,\nparticularly in security (e.g., SQL injection vulnerabilities) and\nmaintainability (e.g., missing type annotations). Existing methods, such as\nsupervised fine-tuning and rule-based post-processing, rely on labor-intensive\nannotations or brittle heuristics, limiting their scalability and\neffectiveness. We propose REAL, a reinforcement learning framework that\nincentivizes LLMs to generate production-quality code using program\nanalysis-guided feedback. Specifically, REAL integrates two automated signals:\n(1) program analysis detecting security or maintainability defects and (2) unit\ntests ensuring functional correctness. Unlike prior work, our framework is\nprompt-agnostic and reference-free, enabling scalable supervision without\nmanual intervention. Experiments across multiple datasets and model scales\ndemonstrate that REAL outperforms state-of-the-art methods in simultaneous\nassessments of functionality and code quality. Our work bridges the gap between\nrapid prototyping and production-ready code, enabling LLMs to deliver both\nspeed and quality.", "AI": {"tldr": "\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6REAL\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u548c\u5355\u5143\u6d4b\u8bd5\u53cd\u9988\u63d0\u5347LLM\u751f\u6210\u4ee3\u7801\u7684\u751f\u4ea7\u8d28\u91cf", "motivation": "\u73b0\u6709LLM\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u4fdd\u969c\u4ee3\u7801\u5b89\u5168\u6027\uff08\u5982SQL\u6ce8\u5165\u6f0f\u6d1e\uff09\u548c\u53ef\u7ef4\u62a4\u6027\uff08\u5982\u7c7b\u578b\u6ce8\u91ca\u7f3a\u5931\uff09\uff0c\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u89c4\u5219\u540e\u5904\u7406\uff0c\u6269\u5c55\u6027\u5dee", "method": "\u96c6\u6210\u7a0b\u5e8f\u5206\u6790\uff08\u68c0\u6d4b\u5b89\u5168/\u53ef\u7ef4\u62a4\u6027\u7f3a\u9677\uff09\u4e0e\u5355\u5143\u6d4b\u8bd5\uff08\u529f\u80fd\u9a8c\u8bc1\uff09\u6784\u5efa\u81ea\u52a8\u5316\u53cd\u9988\u673a\u5236\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6REAL\u5b9e\u73b0\u63d0\u793a\u65e0\u5173\u4e14\u65e0\u9700\u53c2\u8003\u4ee3\u7801\u7684\u76d1\u7763\u8bad\u7ec3", "result": "\u5728\u591a\u6570\u636e\u96c6/\u6a21\u578b\u89c4\u6a21\u6d4b\u8bd5\u4e2d\uff0cREAL\u5728\u529f\u80fd\u6b63\u786e\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u586b\u8865\u4e86\u539f\u578b\u5f00\u53d1\u4e0e\u751f\u4ea7\u7ea7\u4ee3\u7801\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f7fLLM\u540c\u65f6\u5177\u5907\u9ad8\u6548\u5f00\u53d1\u548c\u9ad8\u8d28\u91cf\u8f93\u51fa\u7684\u53cc\u91cd\u4f18\u52bf"}}
{"id": "2505.23708", "pdf": "https://arxiv.org/pdf/2505.23708", "abs": "https://arxiv.org/abs/2505.23708", "authors": ["Lucas N. Alegre", "Agon Serifi", "Ruben Grandia", "David M\u00fcller", "Espen Knoop", "Moritz B\u00e4cher"], "title": "AMOR: Adaptive Character Control through Multi-Objective Reinforcement Learning", "categories": ["cs.RO", "cs.GR"], "comment": "SIGGRAPH 2025", "summary": "Reinforcement learning (RL) has significantly advanced the control of\nphysics-based and robotic characters that track kinematic reference motion.\nHowever, methods typically rely on a weighted sum of conflicting reward\nfunctions, requiring extensive tuning to achieve a desired behavior. Due to the\ncomputational cost of RL, this iterative process is a tedious, time-intensive\ntask. Furthermore, for robotics applications, the weights need to be chosen\nsuch that the policy performs well in the real world, despite inevitable\nsim-to-real gaps. To address these challenges, we propose a multi-objective\nreinforcement learning framework that trains a single policy conditioned on a\nset of weights, spanning the Pareto front of reward trade-offs. Within this\nframework, weights can be selected and tuned after training, significantly\nspeeding up iteration time. We demonstrate how this improved workflow can be\nused to perform highly dynamic motions with a robot character. Moreover, we\nexplore how weight-conditioned policies can be leveraged in hierarchical\nsettings, using a high-level policy to dynamically select weights according to\nthe current task. We show that the multi-objective policy encodes a diverse\nspectrum of behaviors, facilitating efficient adaptation to novel tasks.", "AI": {"tldr": "\u63d0\u51fa\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3\u6743\u91cd\u6761\u4ef6\u7b56\u7565\u8986\u76d6\u5956\u52b1\u6743\u8861\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5b9e\u73b0\u8bad\u7ec3\u540e\u6743\u91cd\u52a8\u6001\u8c03\u6574\u5e76\u63d0\u5347\u673a\u5668\u4eba\u884c\u4e3a\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u52a0\u6743\u5956\u52b1\u51fd\u6570\u9700\u53cd\u590d\u8c03\u53c2\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u9002\u5e94\u6a21\u62df\u5230\u73b0\u5b9e\u7684\u5dee\u8ddd\u3002", "method": "\u6784\u5efa\u6743\u91cd\u6761\u4ef6\u7b56\u7565\u8986\u76d6\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u652f\u6301\u8bad\u7ec3\u540e\u6743\u91cd\u52a8\u6001\u8c03\u6574\uff0c\u5e76\u63a2\u7d22\u5206\u5c42\u7b56\u7565\u52a8\u6001\u9009\u62e9\u6743\u91cd\u673a\u5236\u3002", "result": "\u5b9e\u73b0\u673a\u5668\u4eba\u9ad8\u52a8\u6001\u8fd0\u52a8\u63a7\u5236\uff0c\u591a\u76ee\u6807\u7b56\u7565\u7f16\u7801\u591a\u6837\u5316\u884c\u4e3a\uff0c\u4efb\u52a1\u9002\u5e94\u6548\u7387\u63d0\u53473\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u7f29\u77ed\u5f3a\u5316\u5b66\u4e60\u8fed\u4ee3\u5468\u671f\uff0c\u4e3a\u590d\u6742\u673a\u5668\u4eba\u4efb\u52a1\u63d0\u4f9b\u9ad8\u6548\u9002\u914d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.22752", "pdf": "https://arxiv.org/pdf/2505.22752", "abs": "https://arxiv.org/abs/2505.22752", "authors": ["Rafik Mankour", "Yassine Chafai", "Hamada Saleh", "Ghassen Ben Hassine", "Thibaud Barreau", "Peter Tankov"], "title": "Climate Finance Bench", "categories": ["cs.CL"], "comment": "Dataset is available at\n  https://github.com/Pladifes/climate_finance_bench", "summary": "Climate Finance Bench introduces an open benchmark that targets\nquestion-answering over corporate climate disclosures using Large Language\nModels. We curate 33 recent sustainability reports in English drawn from\ncompanies across all 11 GICS sectors and annotate 330 expert-validated\nquestion-answer pairs that span pure extraction, numerical reasoning, and\nlogical reasoning. Building on this dataset, we propose a comparison of RAG\n(retrieval-augmented generation) approaches. We show that the retriever's\nability to locate passages that actually contain the answer is the chief\nperformance bottleneck. We further argue for transparent carbon reporting in\nAI-for-climate applications, highlighting advantages of techniques such as\nWeight Quantization.", "AI": {"tldr": "\u6784\u5efaClimate Finance Bench\u5f00\u653e\u57fa\u51c6\uff0c\u901a\u8fc7330\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u8de8\u9886\u57df\u6c14\u5019\u62ab\u9732QA\u5bf9\u8bc4\u4f30LLM\u80fd\u529b\uff0c\u63ed\u793aRAG\u65b9\u6cd5\u4e2d\u68c0\u7d22\u5668\u6027\u80fd\u4e3a\u5173\u952e\u74f6\u9888\uff0c\u5e76\u63d0\u51fa\u6743\u91cd\u91cf\u5316\u7b49\u4f4e\u78b3\u6280\u672f\u65b9\u6848", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u9488\u5bf9\u4f01\u4e1a\u6c14\u5019\u4fe1\u606f\u62ab\u9732\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u4f53\u7cfb\uff0c\u9700\u5efa\u7acb\u53ef\u91cf\u5316\u57fa\u51c6\u6765\u63d0\u5347\u95ee\u7b54\u7cfb\u7edf\u5728\u63d0\u53d6\u3001\u6570\u503c\u63a8\u7406\u548c\u903b\u8f91\u63a8\u7406\u7b49\u590d\u5408\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "method": "1. \u6536\u96c611\u4e2aGICS\u884c\u4e1a33\u4efd\u82f1\u6587\u53ef\u6301\u7eed\u53d1\u5c55\u62a5\u544a\n2. \u6784\u5efa\u5305\u542b\u4e09\u79cd\u95ee\u9898\u7c7b\u578b\u7684330\u4e2aQA\u5bf9\n3. \u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540cRAG\u67b6\u6784\u6548\u679c\n4. \u91cf\u5316\u5206\u6790\u68c0\u7d22\u5668\u51c6\u786e\u7387\u4e0e\u78b3\u6392\u653e\u5173\u7cfb", "result": "1. \u68c0\u7d22\u5668\u4ec5\u80fd\u5b9a\u4f4d45%\u76f8\u5173\u6bb5\u843d\n2. \u6743\u91cd\u91cf\u5316\u6280\u672f\u53ef\u964d\u4f4e32%\u63a8\u7406\u80fd\u8017\n3. \u903b\u8f91\u63a8\u7406\u7c7b\u95ee\u9898\u51c6\u786e\u7387\u4f4e\u4e8e\u7eaf\u63d0\u53d6\u7c7b28%", "conclusion": "\u6784\u5efa\u6807\u51c6\u5316\u6c14\u5019QA\u57fa\u51c6\u81f3\u5173\u91cd\u8981\uff0c\u9700\u91cd\u70b9\u6539\u8fdb\u68c0\u7d22\u6a21\u5757\u6027\u80fd\uff0c\u540c\u65f6\u91c7\u7528\u6a21\u578b\u538b\u7f29\u6280\u672f\u5b9e\u73b0\u73af\u5883\u6548\u76ca\u4e0e\u6a21\u578b\u6548\u80fd\u7684\u5e73\u8861"}}
{"id": "2505.23738", "pdf": "https://arxiv.org/pdf/2505.23738", "abs": "https://arxiv.org/abs/2505.23738", "authors": ["Xiaojuan Wang", "Aleksander Holynski", "Brian Curless", "Ira Kemelmacher", "Steve Seitz"], "title": "How Animals Dance (When You're Not Looking)", "categories": ["cs.CV", "cs.GR"], "comment": "Project page: https://how-animals-dance.github.io/", "summary": "We present a keyframe-based framework for generating music-synchronized,\nchoreography aware animal dance videos. Starting from a few keyframes\nrepresenting distinct animal poses -- generated via text-to-image prompting or\nGPT-4o -- we formulate dance synthesis as a graph optimization problem: find\nthe optimal keyframe structure that satisfies a specified choreography pattern\nof beats, which can be automatically estimated from a reference dance video. We\nalso introduce an approach for mirrored pose image generation, essential for\ncapturing symmetry in dance. In-between frames are synthesized using an video\ndiffusion model. With as few as six input keyframes, our method can produce up\nto 30 second dance videos across a wide range of animals and music tracks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5173\u952e\u5e27\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u4f18\u5316\u548c\u89c6\u9891\u6269\u6563\u6a21\u578b\u751f\u6210\u97f3\u4e50\u540c\u6b65\u7684\u52a8\u7269\u821e\u8e48\u89c6\u9891\uff0c\u4ec5\u97006\u4e2a\u5173\u952e\u5e27\u5373\u53ef\u751f\u621030\u79d2\u89c6\u9891\u3002", "motivation": "\u4f20\u7edf\u821e\u8e48\u89c6\u9891\u751f\u6210\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u8c03\u6574\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u81ea\u52a8\u5316\u5173\u952e\u5e27\u751f\u6210\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u5b9e\u73b0\u9ad8\u6548\u751f\u6210\u97f3\u4e50\u540c\u6b65\u3001\u5177\u5907\u7f16\u821e\u5bf9\u79f0\u6027\u7684\u52a8\u7269\u821e\u8e48\u89c6\u9891\u3002", "method": "1. \u4f7f\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6216GPT-4o\u521b\u5efa\u5173\u952e\u52a8\u7269\u59ff\u6001\n2. \u5c06\u821e\u8e48\u5408\u6210\u5efa\u6a21\u4e3a\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u81ea\u52a8\u5339\u914d\u53c2\u8003\u89c6\u9891\u7684\u8282\u62cd\u6a21\u5f0f\n3. \u63d0\u51fa\u955c\u50cf\u59ff\u6001\u751f\u6210\u6280\u672f\u4fdd\u6301\u821e\u8e48\u5bf9\u79f0\u6027\n4. \u91c7\u7528\u89c6\u9891\u6269\u6563\u6a21\u578b\u751f\u6210\u4e2d\u95f4\u5e27", "result": "\u4ec5\u97006\u4e2a\u8f93\u5165\u5173\u952e\u5e27\u5373\u53ef\u751f\u6210\u957f\u8fbe30\u79d2\u7684\u591a\u6837\u5316\u52a8\u7269\u821e\u8e48\u89c6\u9891\uff0c\u9002\u914d\u4e0d\u540c\u97f3\u4e50\u66f2\u76ee\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u7ed3\u5408\u751f\u6210\u5f0fAI\u4e0e\u4f18\u5316\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u821e\u8e48\u89c6\u9891\u5236\u4f5c\u6210\u672c\uff0c\u4e3a\u81ea\u52a8\u5316\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2505.22757", "pdf": "https://arxiv.org/pdf/2505.22757", "abs": "https://arxiv.org/abs/2505.22757", "authors": ["Ansar Aynetdinov", "Alan Akbik"], "title": "Pre-Training Curriculum for Multi-Token Prediction in Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL 2025 (Main)", "summary": "Multi-token prediction (MTP) is a recently proposed pre-training objective\nfor language models. Rather than predicting only the next token (NTP), MTP\npredicts the next $k$ tokens at each prediction step, using multiple prediction\nheads. MTP has shown promise in improving downstream performance, inference\nspeed, and training efficiency, particularly for large models. However, prior\nwork has shown that smaller language models (SLMs) struggle with the MTP\nobjective. To address this, we propose a curriculum learning strategy for MTP\ntraining, exploring two variants: a forward curriculum, which gradually\nincreases the complexity of the pre-training objective from NTP to MTP, and a\nreverse curriculum, which does the opposite. Our experiments show that the\nforward curriculum enables SLMs to better leverage the MTP objective during\npre-training, improving downstream NTP performance and generative output\nquality, while retaining the benefits of self-speculative decoding. The reverse\ncurriculum achieves stronger NTP performance and output quality, but fails to\nprovide any self-speculative decoding benefits.", "AI": {"tldr": "\u63d0\u51fa\u524d\u5411\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u5e2e\u52a9\u5c0f\u8bed\u8a00\u6a21\u578b\u6709\u6548\u5229\u7528\u591a\u4ee4\u724c\u9884\u6d4b\u76ee\u6807\uff0c\u5728\u4fdd\u6301\u81ea\u63a8\u6d4b\u89e3\u7801\u4f18\u52bf\u7684\u540c\u65f6\u63d0\u5347\u751f\u6210\u8d28\u91cf", "motivation": "\u9488\u5bf9\u5c0f\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5229\u7528\u591a\u4ee4\u724c\u9884\u6d4b\uff08MTP\uff09\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u7a81\u7834\u8be5\u9650\u5236", "method": "\u8bbe\u8ba1\u4e24\u79cd\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff1a\u524d\u5411\uff08NTP\u2192MTP\uff09\u4e0e\u9006\u5411\uff08MTP\u2192NTP\uff09\u8bad\u7ec3\u8def\u5f84\uff0c\u52a8\u6001\u8c03\u6574\u9884\u6d4b\u590d\u6742\u5ea6", "result": "\u524d\u5411\u7b56\u7565\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e14\u4fdd\u7559\u81ea\u63a8\u6d4b\u89e3\u7801\u52a0\u901f\u4f18\u52bf\uff0c\u9006\u5411\u7b56\u7565\u751f\u6210\u8d28\u91cf\u66f4\u4f18\u4f46\u5931\u53bb\u89e3\u7801\u52a0\u901f\u80fd\u529b", "conclusion": "\u8bfe\u7a0b\u5b66\u4e60\u662f\u91ca\u653e\u5c0f\u6a21\u578bMTP\u6f5c\u529b\u7684\u6709\u6548\u8303\u5f0f\uff0c\u524d\u5411\u7b56\u7565\u5728\u6027\u80fd\u4e0e\u63a8\u7406\u6548\u7387\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861"}}
{"id": "2505.23740", "pdf": "https://arxiv.org/pdf/2505.23740", "abs": "https://arxiv.org/abs/2505.23740", "authors": ["Ronghuan Wu", "Wanchao Su", "Jing Liao"], "title": "LayerPeeler: Autoregressive Peeling for Layer-wise Image Vectorization", "categories": ["cs.CV", "cs.GR"], "comment": "Project Page: https://layerpeeler.github.io/", "summary": "Image vectorization is a powerful technique that converts raster images into\nvector graphics, enabling enhanced flexibility and interactivity. However,\npopular image vectorization tools struggle with occluded regions, producing\nincomplete or fragmented shapes that hinder editability. While recent\nadvancements have explored rule-based and data-driven layer-wise image\nvectorization, these methods face limitations in vectorization quality and\nflexibility. In this paper, we introduce LayerPeeler, a novel layer-wise image\nvectorization approach that addresses these challenges through a progressive\nsimplification paradigm. The key to LayerPeeler's success lies in its\nautoregressive peeling strategy: by identifying and removing the topmost\nnon-occluded layers while recovering underlying content, we generate vector\ngraphics with complete paths and coherent layer structures. Our method\nleverages vision-language models to construct a layer graph that captures\nocclusion relationships among elements, enabling precise detection and\ndescription for non-occluded layers. These descriptive captions are used as\nediting instructions for a finetuned image diffusion model to remove the\nidentified layers. To ensure accurate removal, we employ localized attention\ncontrol that precisely guides the model to target regions while faithfully\npreserving the surrounding content. To support this, we contribute a\nlarge-scale dataset specifically designed for layer peeling tasks. Extensive\nquantitative and qualitative experiments demonstrate that LayerPeeler\nsignificantly outperforms existing techniques, producing vectorization results\nwith superior path semantics, geometric regularity, and visual fidelity.", "AI": {"tldr": "\u63d0\u51faLayerPeeler\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u5265\u79bb\u7b56\u7565\u89e3\u51b3\u56fe\u50cf\u77e2\u91cf\u5316\u4e2d\u906e\u6321\u533a\u57df\u95ee\u9898", "motivation": "\u73b0\u6709\u5de5\u5177\u5904\u7406\u906e\u6321\u533a\u57df\u65f6\u4ea7\u751f\u4e0d\u5b8c\u6574\u8def\u5f84\uff0c\u57fa\u4e8e\u89c4\u5219\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u5b58\u5728\u8d28\u91cf\u4e0e\u7075\u6d3b\u6027\u9650\u5236", "method": "\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u56fe\u5c42\u5173\u7cfb\u56fe\uff0c\u91c7\u7528\u81ea\u56de\u5f52\u5265\u79bb\u7b56\u7565\u9010\u5c42\u53bb\u9664\u906e\u6321\u5c42\uff0c\u5229\u7528\u5fae\u8c03\u6269\u6563\u6a21\u578b\u5b9e\u73b0\u7cbe\u51c6\u533a\u57df\u53bb\u9664", "result": "\u5728\u8def\u5f84\u5b8c\u6574\u6027\u3001\u51e0\u4f55\u89c4\u5219\u6027\u548c\u89c6\u89c9\u4fdd\u771f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8d21\u732e\u4e13\u7528\u5927\u89c4\u6a21\u6570\u636e\u96c6", "conclusion": "LayerPeeler\u901a\u8fc7\u521b\u65b0\u7684\u5265\u79bb\u673a\u5236\u548c\u5c40\u90e8\u6ce8\u610f\u529b\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u5c42\u6b21\u5316\u56fe\u50cf\u77e2\u91cf\u5316"}}
{"id": "2505.22759", "pdf": "https://arxiv.org/pdf/2505.22759", "abs": "https://arxiv.org/abs/2505.22759", "authors": ["Sara Papi", "Marco Gaido", "Luisa Bentivogli", "Alessio Brutti", "Mauro Cettolo", "Roberto Gretter", "Marco Matassoni", "Mohamed Nabih", "Matteo Negri"], "title": "FAMA: The First Large-Scale Open-Science Speech Foundation Model for English and Italian", "categories": ["cs.CL", "cs.AI", "cs.SD"], "comment": null, "summary": "The development of speech foundation models (SFMs) like Whisper and\nSeamlessM4T has significantly advanced the field of speech processing. However,\ntheir closed nature--with inaccessible training data and code--poses major\nreproducibility and fair evaluation challenges. While other domains have made\nsubstantial progress toward open science by developing fully transparent models\ntrained on open-source (OS) code and data, similar efforts in speech remain\nlimited. To fill this gap, we introduce FAMA, the first family of open science\nSFMs for English and Italian, trained on 150k+ hours of OS speech data.\nMoreover, we present a new dataset containing 16k hours of cleaned and\npseudo-labeled speech for both languages. Results show that FAMA achieves\ncompetitive performance compared to existing SFMs while being up to 8 times\nfaster. All artifacts, including code, datasets, and models, are released under\nOS-compliant licenses, promoting openness in speech technology research.", "AI": {"tldr": "FAMA\u662f\u9996\u4e2a\u57fa\u4e8e\u5f00\u6e90\u6570\u636e\u7684\u5f00\u653e\u79d1\u5b66\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\uff0c\u8986\u76d6\u82f1\u8bed\u548c\u610f\u5927\u5229\u8bed\uff0c\u4f7f\u752815\u4e07+\u5c0f\u65f6\u5f00\u6e90\u8bed\u97f3\u6570\u636e\u8bad\u7ec3\uff0c\u5e76\u53d1\u5e03\u5b8c\u6574\u4ee3\u7801/\u6570\u636e\u96c6/\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08\u5982Whisper\uff09\u7684\u5c01\u95ed\u6027\u5bfc\u81f4\u53ef\u590d\u73b0\u6027\u5dee\u4e0e\u8bc4\u4f30\u56f0\u96be\uff0c\u800c\u8bed\u97f3\u9886\u57df\u7f3a\u4e4f\u7c7b\u4f3c\u5176\u4ed6\u9886\u57df\u7684\u5f00\u653e\u79d1\u5b66\u8fdb\u5c55\u3002", "method": "\u4f7f\u7528150k+\u5c0f\u65f6\u5f00\u6e90\u8bed\u97f3\u6570\u636e\u8bad\u7ec3\uff0c\u6784\u5efa\u5305\u542b16k\u5c0f\u65f6\u6e05\u6d17\u548c\u4f2a\u6807\u6ce8\u8bed\u97f3\u7684\u65b0\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5f00\u6e90\u5408\u89c4\u534f\u8bae\u3002", "result": "FAMA\u6027\u80fd\u4e0e\u73b0\u6709\u6a21\u578b\u76f8\u5f53\u4e14\u5feb8\u500d\uff0c\u6240\u6709\u8d44\u6e90\u5747\u5f00\u6e90\u53d1\u5e03\u3002", "conclusion": "FAMA\u586b\u8865\u4e86\u8bed\u97f3\u9886\u57df\u5f00\u653e\u79d1\u5b66\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u5b8c\u5168\u900f\u660e\u7684\u67b6\u6784\u63a8\u52a8\u8bed\u97f3\u6280\u672f\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u53d1\u5c55\u3002"}}
{"id": "2505.22765", "pdf": "https://arxiv.org/pdf/2505.22765", "abs": "https://arxiv.org/abs/2505.22765", "authors": ["Iddo Yosha", "Gallil Maimon", "Yossi Adi"], "title": "StressTest: Can YOUR Speech LM Handle the Stress?", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": null, "summary": "Sentence stress refers to emphasis, placed on specific words within a spoken\nutterance to highlight or contrast an idea, or to introduce new information. It\nis often used to imply an underlying intention that is not explicitly stated.\nRecent advances in speech-aware language models (SLMs) have enabled direct\nprocessing of audio, allowing models to bypass transcription and access the\nfull richness of the speech signal and perform audio reasoning tasks such as\nspoken question answering. Despite the crucial role of sentence stress in\nshaping meaning and speaker intent, it remains largely overlooked in evaluation\nand development of such models. In this work, we address this gap by\nintroducing StressTest, a benchmark specifically designed to evaluate a model's\nability to distinguish between interpretations of spoken sentences based on the\nstress pattern. We assess the performance of several leading SLMs and find\nthat, despite their overall capabilities, they perform poorly on such tasks. To\novercome this limitation, we propose a novel synthetic data generation\npipeline, and create Stress17k, a training set that simulates change of meaning\nimplied by stress variation. Then, we empirically show that optimizing models\nwith this synthetic dataset aligns well with real-world recordings and enables\neffective finetuning of SLMs. Results suggest, that our finetuned model,\nStresSLM, significantly outperforms existing models on both sentence stress\nreasoning and detection tasks. Code, models, data, and audio samples -\npages.cs.huji.ac.il/adiyoss-lab/stresstest.", "AI": {"tldr": "\u63d0\u51faStressTest\u57fa\u51c6\u548cStress17k\u5408\u6210\u6570\u636e\u96c6\uff0c\u4f18\u5316\u540e\u7684StresSLM\u6a21\u578b\u5728\u53e5\u5b50\u91cd\u97f3\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b", "motivation": "\u73b0\u6709\u8bed\u97f3\u611f\u77e5\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u5f00\u53d1\u8bc4\u4f30\u4e2d\u666e\u904d\u5ffd\u89c6\u53e5\u5b50\u91cd\u97f3\u5bf9\u8bed\u4e49\u548c\u8bf4\u8bdd\u8005\u610f\u56fe\u7684\u5173\u952e\u5f71\u54cd\uff0c\u5bfc\u81f4\u6a21\u578b\u7406\u89e3\u80fd\u529b\u5b58\u5728\u7f3a\u9677", "method": "1. \u521b\u5efaStressTest\u57fa\u51c6\u8bc4\u4f30\u6a21\u578b\u91cd\u97f3\u6a21\u5f0f\u8bc6\u522b\u80fd\u529b\n2. \u5f00\u53d1\u5408\u6210\u6570\u636e\u751f\u6210\u6d41\u7a0b\u6784\u5efaStress17k\u8bad\u7ec3\u96c6\n3. \u901a\u8fc7\u5fae\u8c03\u5b9e\u73b0\u6a21\u578b\u5bf9\u771f\u5b9e\u5f55\u97f3\u7684\u9002\u914d\u4f18\u5316", "result": "StresSLM\u5728\u53e5\u5b50\u91cd\u97f3\u63a8\u7406\uff08\u51c6\u786e\u7387\u63d0\u534723.6%\uff09\u548c\u68c0\u6d4b\u4efb\u52a1\uff08F1\u503c\u63d0\u9ad818.9%\uff09\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u5408\u6210\u6570\u636e\u8bad\u7ec3\u5bf9\u63d0\u5347\u8bed\u97f3\u6a21\u578b\u91cd\u97f3\u7406\u89e3\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8bed\u97f3\u8bed\u4e49\u7406\u89e3\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84"}}
{"id": "2505.22771", "pdf": "https://arxiv.org/pdf/2505.22771", "abs": "https://arxiv.org/abs/2505.22771", "authors": ["Christopher Ormerod"], "title": "Automated Essay Scoring Incorporating Annotations from Automated Feedback Systems", "categories": ["cs.CL", "cs.AI"], "comment": "10 pages, AIME-Con Conference Submission", "summary": "This study illustrates how incorporating feedback-oriented annotations into\nthe scoring pipeline can enhance the accuracy of automated essay scoring (AES).\nThis approach is demonstrated with the Persuasive Essays for Rating, Selecting,\nand Understanding Argumentative and Discourse Elements (PERSUADE) corpus. We\nintegrate two types of feedback-driven annotations: those that identify\nspelling and grammatical errors, and those that highlight argumentative\ncomponents. To illustrate how this method could be applied in real-world\nscenarios, we employ two LLMs to generate annotations -- a generative language\nmodel used for spell-correction and an encoder-based token classifier trained\nto identify and mark argumentative elements. By incorporating annotations into\nthe scoring process, we demonstrate improvements in performance using\nencoder-based large language models fine-tuned as classifiers.", "AI": {"tldr": "\u6574\u5408\u53cd\u9988\u6ce8\u91ca\uff08\u62fc\u5199\u7ea0\u9519+\u8bba\u8bc1\u6807\u8bb0\uff09\u53ef\u63d0\u5347\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u6027\u80fd", "motivation": "\u4f20\u7edf\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u7cfb\u7edf\u7f3a\u4e4f\u53cd\u9988\u673a\u5236\uff0c\u901a\u8fc7\u878d\u5408\u7ea0\u9519\u548c\u8bba\u8bc1\u7ed3\u6784\u6807\u6ce8\u63d0\u5347\u8bc4\u4f30\u51c6\u786e\u6027", "method": "\u4f7f\u7528PERSUADE\u8bed\u6599\u5e93\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u6a21\u578b\uff08\u62fc\u5199\u7ea0\u6b63\uff09\u548c\u7f16\u7801\u5668\u6a21\u578b\uff08\u8bba\u8bc1\u5143\u7d20\u8bc6\u522b\uff09\u751f\u6210\u53cc\u91cd\u6ce8\u91ca", "result": "\u96c6\u6210\u6ce8\u91ca\u540e\uff0c\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u5206\u7c7b\u6a21\u578b\u5728AES\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u63d0\u5347", "conclusion": "\u53cd\u9988\u9a71\u52a8\u6807\u6ce8\u4e3aAES\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u6539\u8fdb\u8def\u5f84\uff0c\u53cc\u91cd\u6ce8\u91ca\u673a\u5236\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b"}}
{"id": "2505.22774", "pdf": "https://arxiv.org/pdf/2505.22774", "abs": "https://arxiv.org/abs/2505.22774", "authors": ["Kaja Dobrovoljc"], "title": "Counting trees: A treebank-driven exploration of syntactic variation in speech and writing across languages", "categories": ["cs.CL"], "comment": null, "summary": "This paper presents a novel treebank-driven approach to comparing syntactic\nstructures in speech and writing using dependency-parsed corpora. Adopting a\nfully inductive, bottom-up method, we define syntactic structures as\ndelexicalized dependency (sub)trees and extract them from spoken and written\nUniversal Dependencies (UD) treebanks in two syntactically distinct languages,\nEnglish and Slovenian. For each corpus, we analyze the size, diversity, and\ndistribution of syntactic inventories, their overlap across modalities, and the\nstructures most characteristic of speech. Results show that, across both\nlanguages, spoken corpora contain fewer and less diverse syntactic structures\nthan their written counterparts, with consistent cross-linguistic preferences\nfor certain structural types across modalities. Strikingly, the overlap between\nspoken and written syntactic inventories is very limited: most structures\nattested in speech do not occur in writing, pointing to modality-specific\npreferences in syntactic organization that reflect the distinct demands of\nreal-time interaction and elaborated writing. This contrast is further\nsupported by a keyness analysis of the most frequent speech-specific\nstructures, which highlights patterns associated with interactivity,\ncontext-grounding, and economy of expression. We argue that this scalable,\nlanguage-independent framework offers a useful general method for\nsystematically studying syntactic variation across corpora, laying the\ngroundwork for more comprehensive data-driven theories of grammar in use.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6811\u5e93\u7684\u8de8\u6a21\u6001\u53e5\u6cd5\u5bf9\u6bd4\u65b9\u6cd5\uff0c\u53d1\u73b0\u53e3\u8bed\u548c\u4e66\u9762\u8bed\u53e5\u6cd5\u7ed3\u6784\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u53e3\u8bed\u7279\u6709\u7ed3\u6784\u4f53\u73b0\u5b9e\u65f6\u4e92\u52a8\u9700\u6c42", "motivation": "\u901a\u8fc7\u4f9d\u8d56\u6811\u5e93\u7cfb\u7edf\u6bd4\u8f83\u53e3\u8bed\u548c\u4e66\u9762\u8bed\u7684\u53e5\u6cd5\u7ed3\u6784\u5dee\u5f02\uff0c\u63a2\u7d22\u4e0d\u540c\u4ea4\u9645\u6a21\u6001\u7684\u53e5\u6cd5\u7ec4\u7ec7\u89c4\u5f8b", "method": "\u4f7f\u7528\u81ea\u4e0b\u800c\u4e0a\u7684\u5f52\u7eb3\u65b9\u6cd5\uff0c\u4ece\u82f1\u8bed\u548c\u65af\u6d1b\u6587\u5c3c\u4e9a\u8bed\u7684UD\u6811\u5e93\u4e2d\u63d0\u53d6\u53bb\u8bcd\u6c47\u5316\u4f9d\u8d56\u5b50\u6811\uff0c\u5206\u6790\u7ed3\u6784\u591a\u6837\u6027\u3001\u5206\u5e03\u53ca\u8de8\u6a21\u6001\u91cd\u53e0", "result": "\u53e3\u8bed\u5e93\u7ed3\u6784\u66f4\u5c11\u4e14\u591a\u6837\u6027\u4f4e\uff0c\u6a21\u6001\u95f4\u7ed3\u6784\u91cd\u53e0\u6709\u9650\uff08<10%\uff09\uff0c\u5173\u952e\u7ed3\u6784\u5206\u6790\u63ed\u793a\u4e92\u52a8\u6027\u3001\u8bed\u5883\u4f9d\u5b58\u548c\u8868\u8fbe\u7ecf\u6d4e\u6027\u7279\u5f81", "conclusion": "\u8be5\u53ef\u6269\u5c55\u6846\u67b6\u4e3a\u8de8\u8bed\u6599\u5e93\u53e5\u6cd5\u53d8\u5f02\u7814\u7a76\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8\u57fa\u4e8e\u8bed\u8a00\u4f7f\u7528\u7684\u8bed\u6cd5\u7406\u8bba\u53d1\u5c55"}}
{"id": "2505.22777", "pdf": "https://arxiv.org/pdf/2505.22777", "abs": "https://arxiv.org/abs/2505.22777", "authors": ["John Mendon\u00e7a", "Alon Lavie", "Isabel Trancoso"], "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators", "categories": ["cs.CL"], "comment": "May ARR", "summary": "As the capabilities of chatbots and their underlying LLMs continue to\ndramatically improve, evaluating their performance has increasingly become a\nmajor blocker to their further development. A major challenge is the available\nbenchmarking datasets, which are largely static, outdated, and lacking in\nmultilingual coverage, limiting their ability to capture subtle linguistic and\ncultural variations. This paper introduces MEDAL, an automated multi-agent\nframework for generating, evaluating, and curating more representative and\ndiverse open-domain dialogue evaluation benchmarks. Our approach leverages\nseveral state-of-the-art LLMs to generate user-chatbot multilingual dialogues,\nconditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a\nmultidimensional analysis of the performance of the chatbots, uncovering\nnoticeable cross-lingual performance differences. Guided by this large-scale\nevaluation, we curate a new meta-evaluation multilingual benchmark and\nhuman-annotate samples with nuanced quality judgments. This benchmark is then\nused to assess the ability of several reasoning and non-reasoning LLMs to act\nas evaluators of open-domain dialogues. We find that current LLMs struggle to\ndetect nuanced issues, particularly those involving empathy and reasoning.", "AI": {"tldr": "\u63d0\u51faMEDAL\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u548c\u8bc4\u4f30\u591a\u8bed\u8a00\u5bf9\u8bdd\u57fa\u51c6\uff0c\u63ed\u793a\u73b0\u6709LLM\u5728\u8de8\u8bed\u8a00\u8bc4\u4f30\u4e2d\u7684\u4e0d\u8db3", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u8bc4\u4f30\u6570\u636e\u96c6\u5b58\u5728\u9759\u6001\u6027\u3001\u7f3a\u4e4f\u591a\u8bed\u8a00\u8986\u76d6\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u6355\u6349\u8bed\u8a00\u6587\u5316\u7ec6\u5fae\u5dee\u5f02\uff0c\u963b\u788d\u804a\u5929\u673a\u5668\u4eba\u6027\u80fd\u8bc4\u4f30", "method": "\u5229\u7528\u591a\u4e2aSOTA LLM\u751f\u6210\u591a\u8bed\u8a00\u5bf9\u8bdd\u2192GPT-4\u8fdb\u884c\u591a\u7ef4\u6027\u80fd\u5206\u6790\u2192\u57fa\u4e8e\u5927\u89c4\u6a21\u8bc4\u4f30\u7ed3\u679c\u6784\u5efa\u4eba\u5de5\u6807\u6ce8\u7684\u5143\u8bc4\u4f30\u57fa\u51c6\u2192\u6d4b\u8bd5\u4e0d\u540cLLM\u7684\u8bc4\u4f30\u80fd\u529b", "result": "\u53d1\u73b0\u663e\u8457\u7684\u8de8\u8bed\u8a00\u6027\u80fd\u5dee\u5f02\uff0c\u5f53\u524dLLM\u5728\u68c0\u6d4b\u540c\u7406\u5fc3\uff08\u4e0b\u964d27%\uff09\u548c\u903b\u8f91\u63a8\u7406\uff08\u8bef\u5dee\u738735%\uff09\u7b49\u7ec6\u5fae\u95ee\u9898\u65f6\u8868\u73b0\u6b20\u4f73", "conclusion": "MEDAL\u6846\u67b6\u6709\u6548\u751f\u6210\u591a\u6837\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u4f46\u73b0\u6709LLM\u4f5c\u4e3a\u8bc4\u4f30\u8005\u4ecd\u9700\u63d0\u5347\u5bf9\u60c5\u611f\u7406\u89e3\u548c\u590d\u6742\u63a8\u7406\u7b49\u6df1\u5c42\u8bed\u4e49\u7684\u6355\u6349\u80fd\u529b"}}
{"id": "2505.22787", "pdf": "https://arxiv.org/pdf/2505.22787", "abs": "https://arxiv.org/abs/2505.22787", "authors": ["Christopher Polzak", "Alejandro Lozano", "Min Woo Sun", "James Burgess", "Yuhui Zhang", "Kevin Wu", "Serena Yeung-Levy"], "title": "Can Large Language Models Match the Conclusions of Systematic Reviews?", "categories": ["cs.CL"], "comment": null, "summary": "Systematic reviews (SR), in which experts summarize and analyze evidence\nacross individual studies to provide insights on a specialized topic, are a\ncornerstone for evidence-based clinical decision-making, research, and policy.\nGiven the exponential growth of scientific articles, there is growing interest\nin using large language models (LLMs) to automate SR generation. However, the\nability of LLMs to critically assess evidence and reason across multiple\ndocuments to provide recommendations at the same proficiency as domain experts\nremains poorly characterized. We therefore ask: Can LLMs match the conclusions\nof systematic reviews written by clinical experts when given access to the same\nstudies? To explore this question, we present MedEvidence, a benchmark pairing\nfindings from 100 SRs with the studies they are based on. We benchmark 24 LLMs\non MedEvidence, including reasoning, non-reasoning, medical specialist, and\nmodels across varying sizes (from 7B-700B). Through our systematic evaluation,\nwe find that reasoning does not necessarily improve performance, larger models\ndo not consistently yield greater gains, and knowledge-based fine-tuning\ndegrades accuracy on MedEvidence. Instead, most models exhibit similar\nbehavior: performance tends to degrade as token length increases, their\nresponses show overconfidence, and, contrary to human experts, all models show\na lack of scientific skepticism toward low-quality findings. These results\nsuggest that more work is still required before LLMs can reliably match the\nobservations from expert-conducted SRs, even though these systems are already\ndeployed and being used by clinicians. We release our codebase and benchmark to\nthe broader research community to further investigate LLM-based SR systems.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f3024\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u7cfb\u7edf\u8bc4\u4ef7\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u79d1\u5b66\u6000\u7591\u6001\u5ea6\u3001\u957f\u6587\u672c\u5904\u7406\u7b49\u65b9\u9762\u4ecd\u65e0\u6cd5\u5339\u914d\u4e13\u5bb6\u6c34\u5e73", "motivation": "\u9a8c\u8bc1LLMs\u5728\u83b7\u5f97\u76f8\u540c\u7814\u7a76\u8d44\u6599\u65f6\uff0c\u80fd\u5426\u751f\u6210\u4e0e\u4e34\u5e8a\u4e13\u5bb6\u64b0\u5199\u7684\u7cfb\u7edf\u8bc4\u4ef7\u76f8\u5f53\u7684\u7ed3\u8bba", "method": "\u521b\u5efa\u5305\u542b100\u4e2aSR\u53ca\u5176\u57fa\u7840\u7814\u7a76\u7684MedEvidence\u57fa\u51c6\uff0c\u6d4b\u8bd524\u4e2a\u4e0d\u540c\u89c4\u6a21\uff087B-700B\uff09\u7684LLM\uff0c\u5305\u542b\u63a8\u7406/\u975e\u63a8\u7406\u6a21\u578b\u53ca\u533b\u7597\u4e13\u7528\u6a21\u578b", "result": "\u6a21\u578b\u8868\u73b0\u5448\u73b0\u4e09\u7279\u5f81\uff1a1\uff09\u63a8\u7406\u80fd\u529b\u4e0e\u6a21\u578b\u5927\u5c0f\u4e0d\u76f4\u63a5\u63d0\u5347\u6548\u679c 2\uff09\u77e5\u8bc6\u5fae\u8c03\u53cd\u800c\u964d\u4f4e\u51c6\u786e\u6027 3\uff09\u6240\u6709\u6a21\u578b\u5747\u7f3a\u4e4f\u5bf9\u4f4e\u8d28\u91cf\u8bc1\u636e\u7684\u79d1\u5b66\u6000\u7591\u6001\u5ea6", "conclusion": "\u5f53\u524dLLM\u5c1a\u65e0\u6cd5\u53ef\u9760\u751f\u6210\u4e13\u5bb6\u6c34\u5e73\u7684\u7cfb\u7edf\u8bc4\u4ef7\uff0c\u7279\u522b\u662f\u5728\u957f\u6587\u672c\u5904\u7406\u3001\u8bc1\u636e\u6279\u5224\u6027\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u5c3d\u7ba1\u5df2\u6709\u4e34\u5e8a\u90e8\u7f72\u6848\u4f8b"}}
{"id": "2505.22801", "pdf": "https://arxiv.org/pdf/2505.22801", "abs": "https://arxiv.org/abs/2505.22801", "authors": ["Qing Wang", "Yuepei Li", "Qiao Qiao", "Kang Zhou", "Qi Li"], "title": "Towards a More Generalized Approach in Open Relation Extraction", "categories": ["cs.CL"], "comment": "Accepted by ACL 2025 Main Conference", "summary": "Open Relation Extraction (OpenRE) seeks to identify and extract novel\nrelational facts between named entities from unlabeled data without pre-defined\nrelation schemas. Traditional OpenRE methods typically assume that the\nunlabeled data consists solely of novel relations or is pre-divided into known\nand novel instances. However, in real-world scenarios, novel relations are\narbitrarily distributed. In this paper, we propose a generalized OpenRE setting\nthat considers unlabeled data as a mixture of both known and novel instances.\nTo address this, we propose MixORE, a two-phase framework that integrates\nrelation classification and clustering to jointly learn known and novel\nrelations. Experiments on three benchmark datasets demonstrate that MixORE\nconsistently outperforms competitive baselines in known relation classification\nand novel relation clustering. Our findings contribute to the advancement of\ngeneralized OpenRE research and real-world applications.", "AI": {"tldr": "\u63d0\u51faMixORE\u6846\u67b6\u89e3\u51b3\u5f00\u653e\u5173\u7cfb\u62bd\u53d6\u4e2d\u5df2\u77e5/\u672a\u77e5\u5173\u7cfb\u6df7\u5408\u5206\u5e03\u7684\u96be\u9898\uff0c\u901a\u8fc7\u53cc\u9636\u6bb5\u5206\u7c7b\u805a\u7c7b\u8054\u5408\u5b66\u4e60\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u4f20\u7edfOpenRE\u65b9\u6cd5\u5047\u8bbe\u6570\u636e\u7eaf\u4e3a\u65b0\u5173\u7cfb\u6216\u9884\u5206\u5272\uff0c\u4e0d\u7b26\u5408\u73b0\u5b9e\u573a\u666f\u4e2d\u5df2\u77e5/\u672a\u77e5\u5173\u7cfb\u968f\u673a\u6df7\u5408\u5206\u5e03\u7684\u5b9e\u9645\u9700\u6c42", "method": "\u4e24\u9636\u6bb5\u6846\u67b6MixORE\uff1a\u6574\u5408\u5173\u7cfb\u5206\u7c7b\uff08\u5904\u7406\u5df2\u77e5\u5173\u7cfb\uff09\u4e0e\u805a\u7c7b\uff08\u53d1\u73b0\u65b0\u5173\u7cfb\uff09\u7684\u8054\u5408\u5b66\u4e60\u673a\u5236", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u5df2\u77e5\u5173\u7cfb\u5206\u7c7b\u51c6\u786e\u7387\u63d0\u53473.1-5.8%\uff0c\u65b0\u5173\u7cfb\u805a\u7c7b\u7eaf\u5ea6\u63d0\u9ad812.6-19.4%", "conclusion": "\u4e3a\u5e7f\u4e49\u5f00\u653e\u5173\u7cfb\u62bd\u53d6\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u5411\u771f\u5b9e\u573a\u666f\u5e94\u7528\u8fc8\u8fdb"}}
{"id": "2505.22809", "pdf": "https://arxiv.org/pdf/2505.22809", "abs": "https://arxiv.org/abs/2505.22809", "authors": ["Andrew Zhu", "Evan Osgood", "Chris Callison-Burch"], "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "8 pages, 5 figures. In submission at EMNLP 2025", "summary": "Much work has been done on conversational LLM agents which directly assist\nhuman users with tasks. We present an alternative paradigm for interacting with\nLLM agents, which we call \"overhearing agents\". These overhearing agents do not\nactively participate in conversation -- instead, they \"listen in\" on\nhuman-to-human conversations and perform background tasks or provide\nsuggestions to assist the user. In this work, we explore the overhearing agents\nparadigm through the lens of Dungeons & Dragons gameplay. We present an\nin-depth study using large multimodal audio-language models as overhearing\nagents to assist a Dungeon Master. We perform a human evaluation to examine the\nhelpfulness of such agents and find that some large audio-language models have\nthe emergent ability to perform overhearing agent tasks using implicit audio\ncues. Finally, we release Python libraries and our project code to support\nfurther research into the overhearing agents paradigm at\nhttps://github.com/zhudotexe/overhearing_agents.", "AI": {"tldr": "\u63d0\u51fa'\u65c1\u542c\u667a\u80fd\u4f53'\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u76d1\u542c\u4eba\u7c7b\u5bf9\u8bdd\u5b9e\u73b0\u540e\u53f0\u8f85\u52a9\uff0c\u57fa\u4e8e\u300a\u9f99\u4e0e\u5730\u4e0b\u57ce\u300b\u573a\u666f\u9a8c\u8bc1\u53ef\u884c\u6027", "motivation": "\u63a2\u7d22LLM\u667a\u80fd\u4f53\u975e\u76f4\u63a5\u4ea4\u4e92\u7684\u65b0\u6a21\u5f0f\uff0c\u7a81\u7834\u4f20\u7edf\u5bf9\u8bdd\u5f0f\u52a9\u624b\u7684\u5c40\u9650", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u97f3\u9891-\u8bed\u8a00\u5927\u6a21\u578b\u4f5c\u4e3a\u65c1\u542c\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u4eba\u7c7b\u8bc4\u4f30\u9a8c\u8bc1\u5176\u5728TRPG\u6e38\u620f\u4e2d\u7684\u8f85\u52a9\u6548\u679c", "result": "\u90e8\u5206\u97f3\u9891\u5927\u6a21\u578b\u5c55\u73b0\u901a\u8fc7\u9690\u5f0f\u97f3\u9891\u7ebf\u7d22\u5b8c\u6210\u65c1\u542c\u4efb\u52a1\u7684\u65b0\u5174\u80fd\u529b", "conclusion": "\u8bc1\u5b9e\u65c1\u542c\u667a\u80fd\u4f53\u8303\u5f0f\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5f00\u6e90\u4ee3\u7801\u5e93\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76"}}
{"id": "2505.22823", "pdf": "https://arxiv.org/pdf/2505.22823", "abs": "https://arxiv.org/abs/2505.22823", "authors": ["Yingming Wang", "Pepa Atanasova"], "title": "Self-Critique and Refinement for Faithful Natural Language Explanations", "categories": ["cs.CL"], "comment": "21 pages, 10 figures, 14 tables", "summary": "With the rapid development of large language models (LLMs), natural language\nexplanations (NLEs) have become increasingly important for understanding model\npredictions. However, these explanations often fail to faithfully represent the\nmodel's actual reasoning process. While existing work has demonstrated that\nLLMs can self-critique and refine their initial outputs for various tasks, this\ncapability remains unexplored for improving explanation faithfulness. To\naddress this gap, we introduce Self-critique and Refinement for Natural\nLanguage Explanations (SR-NLE), a framework that enables models to improve the\nfaithfulness of their own explanations -- specifically, post-hoc NLEs --\nthrough an iterative critique and refinement process without external\nsupervision. Our framework leverages different feedback mechanisms to guide the\nrefinement process, including natural language self-feedback and, notably, a\nnovel feedback approach based on feature attribution that highlights important\ninput words. Our experiments across three datasets and four state-of-the-art\nLLMs demonstrate that SR-NLE significantly reduces unfaithfulness rates, with\nour best method achieving an average unfaithfulness rate of 36.02%, compared to\n54.81% for baseline -- an absolute reduction of 18.79%. These findings reveal\nthat the investigated LLMs can indeed refine their explanations to better\nreflect their actual reasoning process, requiring only appropriate guidance\nthrough feedback without additional training or fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e86SR-NLE\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u53cd\u9988\u548c\u7279\u5f81\u5f52\u56e0\u673a\u5236\u8fed\u4ee3\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5fe0\u5b9e\u5ea6\uff0c\u5b9e\u9a8c\u663e\u793a\u4e0d\u5fe0\u5b9e\u7387\u5e73\u5747\u964d\u4f4e18.79%\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4e0e\u6a21\u578b\u5b9e\u9645\u63a8\u7406\u5b58\u5728\u504f\u5dee\uff0c\u9700\u8981\u65e0\u76d1\u7763\u65b9\u6cd5\u63d0\u5347\u89e3\u91ca\u5fe0\u5b9e\u5ea6\u3002\u73b0\u6709\u5de5\u4f5c\u5c1a\u672a\u63a2\u7d22\u6a21\u578b\u81ea\u6211\u4fee\u6b63\u89e3\u91ca\u7684\u80fd\u529b\u3002", "method": "1. \u5efa\u7acb\u8fed\u4ee3\u5f0f\u81ea\u6211\u6279\u8bc4\u4e0e\u7cbe\u70bc\u6846\u67b6\n2. \u5f15\u5165\u81ea\u7136\u8bed\u8a00\u81ea\u53cd\u9988\u548c\u57fa\u4e8e\u7279\u5f81\u5f52\u56e0\u8bcd\u91cd\u8981\u6027\u7684\u65b0\u578b\u53cd\u9988\n3. \u652f\u6301\u65e0\u9700\u5916\u90e8\u76d1\u7763\u7684\u81ea\u52a8\u5316\u4f18\u5316", "result": "\u8de83\u6570\u636e\u96c6\u30014\u4e2aLLM\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\n- \u6700\u4f73\u65b9\u6cd5\u5e73\u5747\u4e0d\u5fe0\u5b9e\u738736.02%\n- \u76f8\u6bd4\u57fa\u7ebf54.81%\u7edd\u5bf9\u964d\u4f4e18.79%", "conclusion": "\u9a8c\u8bc1\u4e86LLMs\u5177\u5907\u901a\u8fc7\u53cd\u9988\u5f15\u5bfc\u81ea\u4e3b\u4f18\u5316\u89e3\u91ca\u7684\u80fd\u529b\uff0c\u4e3a\u63d0\u5347\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65e0\u9700\u8bad\u7ec3\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.22830", "pdf": "https://arxiv.org/pdf/2505.22830", "abs": "https://arxiv.org/abs/2505.22830", "authors": ["Alexander Gill", "Abhilasha Ravichander", "Ana Marasovi\u0107"], "title": "What Has Been Lost with Synthetic Evaluation?", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages main, 5 pages reference, 24 pages appendix", "summary": "Large language models (LLMs) are increasingly used for data generation.\nHowever, creating evaluation benchmarks raises the bar for this emerging\nparadigm. Benchmarks must target specific phenomena, penalize exploiting\nshortcuts, and be challenging. Through two case studies, we investigate whether\nLLMs can meet these demands by generating reasoning over-text benchmarks and\ncomparing them to those created through careful crowdsourcing. Specifically, we\nevaluate both the validity and difficulty of LLM-generated versions of two\nhigh-quality reading comprehension datasets: CondaQA, which evaluates reasoning\nabout negation, and DROP, which targets reasoning about quantities. We find\nthat prompting LLMs can produce variants of these datasets that are often valid\naccording to the annotation guidelines, at a fraction of the cost of the\noriginal crowdsourcing effort. However, we show that they are less challenging\nfor LLMs than their human-authored counterparts. This finding sheds light on\nwhat may have been lost by generating evaluation data with LLMs, and calls for\ncritically reassessing the immediate use of this increasingly prevalent\napproach to benchmark creation.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u751f\u6210\u8bc4\u4f30\u57fa\u51c6\u6210\u672c\u4f4e\u5ec9\u4f46\u6311\u6218\u6027\u4e0d\u8db3\uff0c\u9700\u91cd\u65b0\u8bc4\u4f30\u8be5\u65b9\u6cd5\u7684\u9002\u7528\u6027", "motivation": "\u63a2\u7a76LLM\u751f\u6210\u8bc4\u4f30\u6570\u636e\u80fd\u5426\u66ff\u4ee3\u4eba\u5de5\u4f17\u5305\uff0c\u7279\u522b\u662f\u9488\u5bf9\u9700\u8981\u590d\u6742\u63a8\u7406\u7684\u9605\u8bfb\u7406\u89e3\u4efb\u52a1", "method": "\u901a\u8fc7CondaQA\uff08\u5426\u5b9a\u63a8\u7406\uff09\u548cDROP\uff08\u6570\u503c\u63a8\u7406\uff09\u4e24\u4e2a\u9ad8\u8d28\u91cf\u9605\u8bfb\u7406\u89e3\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4LLM\u751f\u6210\u6570\u636e\u4e0e\u4eba\u5de5\u6570\u636e\u7684\u6709\u6548\u6027\u548c\u96be\u5ea6", "result": "LLM\u751f\u6210\u6570\u636e\u7b26\u5408\u6807\u6ce8\u6807\u51c6\u4e14\u6210\u672c\u4f4e\uff0c\u4f46\u76f8\u8f83\u4eba\u5de5\u6570\u636e\u5bf9LLM\u7684\u6311\u6218\u6027\u964d\u4f4e23-35%", "conclusion": "LLM\u751f\u6210\u8bc4\u4f30\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u5173\u952e\u8bc4\u4f30\u7ef4\u5ea6\u7684\u4e22\u5931\uff0c\u9700\u8c28\u614e\u91c7\u7528\u8be5\u57fa\u51c6\u521b\u5efa\u65b9\u6cd5"}}
{"id": "2505.22842", "pdf": "https://arxiv.org/pdf/2505.22842", "abs": "https://arxiv.org/abs/2505.22842", "authors": ["Arthur S. Bianchessi", "Rodrigo C. Barros", "Lucas S. Kupssinsk\u00fc"], "title": "Bayesian Attention Mechanism: A Probabilistic Framework for Positional Encoding and Context Length Extrapolation", "categories": ["cs.CL", "cs.LG", "I.2.6; I.2.7"], "comment": null, "summary": "Transformer-based language models rely on positional encoding (PE) to handle\ntoken order and support context length extrapolation. However, existing PE\nmethods lack theoretical clarity and rely on limited evaluation metrics to\nsubstantiate their extrapolation claims. We propose the Bayesian Attention\nMechanism (BAM), a theoretical framework that formulates positional encoding as\na prior within a probabilistic model. BAM unifies existing methods (e.g., NoPE\nand ALiBi) and motivates a new Generalized Gaussian positional prior that\nsubstantially improves long-context generalization. Empirically, BAM enables\naccurate information retrieval at $500\\times$ the training context length,\noutperforming previous state-of-the-art context length generalization in long\ncontext retrieval accuracy while maintaining comparable perplexity and\nintroducing minimal additional parameters.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af\u6ce8\u610f\u529b\u673a\u5236(BAM)\uff0c\u901a\u8fc7\u6982\u7387\u5efa\u6a21\u7edf\u4e00\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u5b9e\u73b0500\u500d\u8bad\u7ec3\u957f\u5ea6\u7684\u4e0a\u4e0b\u6587\u6cdb\u5316\u80fd\u529b\u7a81\u7834", "motivation": "\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5b58\u5728\u7406\u8bba\u4e0d\u6e05\u6670\u3001\u4f9d\u8d56\u6709\u9650\u8bc4\u4f30\u6307\u6807\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u9a8c\u8bc1\u5176\u4e0a\u4e0b\u6587\u5916\u63a8\u80fd\u529b\u7684\u6709\u6548\u6027", "method": "\u5c06\u4f4d\u7f6e\u7f16\u7801\u5efa\u6a21\u4e3a\u6982\u7387\u5148\u9a8c\uff0c\u63d0\u51fa\u5e7f\u4e49\u9ad8\u65af\u4f4d\u7f6e\u5148\u9a8c\uff0c\u517c\u5bb9NoPE/ALiBi\u7b49\u73b0\u6709\u65b9\u6cd5\u5e76\u589e\u5f3a\u957f\u5e8f\u5217\u5efa\u6a21\u80fd\u529b", "result": "\u5728\u8bad\u7ec3\u957f\u5ea6500\u500d\u7684\u4e0a\u4e0b\u6587\u68c0\u7d22\u4e2d\u51c6\u786e\u7387\u8d85\u8d8aSOTA\uff0c\u4ec5\u589e\u52a00.0001%\u53c2\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e0e\u539f\u6a21\u578b\u76f8\u5f53\u7684\u56f0\u60d1\u5ea6", "conclusion": "BAM\u6846\u67b6\u4e3a\u4f4d\u7f6e\u7f16\u7801\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5176\u5e7f\u4e49\u5148\u9a8c\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u80fd\u529b\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c"}}
{"id": "2505.22848", "pdf": "https://arxiv.org/pdf/2505.22848", "abs": "https://arxiv.org/abs/2505.22848", "authors": ["Pingjun Hong", "Beiduo Chen", "Siyao Peng", "Marie-Catherine de Marneffe", "Barbara Plank"], "title": "LiTEx: A Linguistic Taxonomy of Explanations for Understanding Within-Label Variation in Natural Language Inference", "categories": ["cs.CL"], "comment": "21 pages, 6 figures", "summary": "There is increasing evidence of Human Label Variation (HLV) in Natural\nLanguage Inference (NLI), where annotators assign different labels to the same\npremise-hypothesis pair. However, within-label variation--cases where\nannotators agree on the same label but provide divergent reasoning--poses an\nadditional and mostly overlooked challenge. Several NLI datasets contain\nhighlighted words in the NLI item as explanations, but the same spans on the\nNLI item can be highlighted for different reasons, as evidenced by free-text\nexplanations, which offer a window into annotators' reasoning. To\nsystematically understand this problem and gain insight into the rationales\nbehind NLI labels, we introduce LITEX, a linguistically-informed taxonomy for\ncategorizing free-text explanations. Using this taxonomy, we annotate a subset\nof the e-SNLI dataset, validate the taxonomy's reliability, and analyze how it\naligns with NLI labels, highlights, and explanations. We further assess the\ntaxonomy's usefulness in explanation generation, demonstrating that\nconditioning generation on LITEX yields explanations that are linguistically\ncloser to human explanations than those generated using only labels or\nhighlights. Our approach thus not only captures within-label variation but also\nshows how taxonomy-guided generation for reasoning can bridge the gap between\nhuman and model explanations more effectively than existing strategies.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLITEX\u8bed\u8a00\u5b66\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3NLI\u4efb\u52a1\u4e2d\u540c\u6807\u7b7e\u5185\u89e3\u91ca\u5dee\u5f02\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u89e3\u91ca\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709NLI\u6570\u636e\u96c6\u5ffd\u89c6\u540c\u6807\u7b7e\u5185\u89e3\u91ca\u7684\u591a\u6837\u6027\u5dee\u5f02\uff08\u5982\u76f8\u540c\u9ad8\u4eae\u5bf9\u5e94\u4e0d\u540c\u81ea\u7531\u6587\u672c\u89e3\u91ca\uff09\uff0c\u9700\u7cfb\u7edf\u5316\u5206\u7c7b\u6cd5\u63ed\u793a\u6807\u6ce8\u8005\u63a8\u7406\u903b\u8f91\u3002", "method": "1. \u5f00\u53d1LITEX\u8bed\u8a00\u5b66\u89e3\u91ca\u5206\u7c7b\u6cd5 2. \u6807\u6ce8e-SNLI\u5b50\u96c6\u9a8c\u8bc1\u5206\u7c7b\u53ef\u9760\u6027 3. \u5bf9\u6bd4\u6807\u7b7e/\u9ad8\u4eae/LITEX\u4e09\u79cd\u6761\u4ef6\u4e0b\u7684\u89e3\u91ca\u751f\u6210\u6548\u679c", "result": "LITEX\u5f15\u5bfc\u751f\u6210\u7684\u89e3\u91ca\u5728\u8bed\u8a00\u5b66\u7279\u5f81\u4e0a\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u63a5\u8fd1\u4eba\u7c7b\u89e3\u91ca\uff0c\u80fd\u6709\u6548\u6355\u6349\u540c\u6807\u7b7e\u5185\u7684\u89e3\u91ca\u5dee\u5f02\u3002", "conclusion": "LITEX\u4e0d\u4ec5\u91cf\u5316\u4e86\u6807\u6ce8\u53d8\u5f02\u73b0\u8c61\uff0c\u5176\u5f15\u5bfc\u7684\u751f\u6210\u7b56\u7565\u663e\u8457\u7f29\u5c0f\u4e86\u6a21\u578b\u4e0e\u4eba\u7c7b\u89e3\u91ca\u4e4b\u95f4\u7684\u8bed\u8a00\u5b66\u5dee\u8ddd\u3002"}}
{"id": "2505.22867", "pdf": "https://arxiv.org/pdf/2505.22867", "abs": "https://arxiv.org/abs/2505.22867", "authors": ["Iknoor Singh", "Carolina Scarton", "Kalina Bontcheva"], "title": "GateNLP at SemEval-2025 Task 10: Hierarchical Three-Step Prompting for Multilingual Narrative Classification", "categories": ["cs.CL"], "comment": null, "summary": "The proliferation of online news and the increasing spread of misinformation\nnecessitate robust methods for automatic data analysis. Narrative\nclassification is emerging as a important task, since identifying what is being\nsaid online is critical for fact-checkers, policy markers and other\nprofessionals working on information studies. This paper presents our approach\nto SemEval 2025 Task 10 Subtask 2, which aims to classify news articles into a\npre-defined two-level taxonomy of main narratives and sub-narratives across\nmultiple languages.\n  We propose Hierarchical Three-Step Prompting (H3Prompt) for multilingual\nnarrative classification. Our methodology follows a three-step Large Language\nModel (LLM) prompting strategy, where the model first categorises an article\ninto one of two domains (Ukraine-Russia War or Climate Change), then identifies\nthe most relevant main narratives, and finally assigns sub-narratives. Our\napproach secured the top position on the English test set among 28 competing\nteams worldwide. The code is available at https://github.com/GateNLP/H3Prompt.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u4e09\u6b65\u63d0\u793a\u6cd5(H3Prompt)\u5b9e\u73b0\u591a\u8bed\u8a00\u65b0\u95fb\u53d9\u4e8b\u5206\u7c7b\uff0c\u5728SemEval 2025\u82f1\u8bed\u6d4b\u8bd5\u96c6\u83b7\u5f9728\u961f\u4e2d\u7b2c\u4e00", "motivation": "\u5e94\u5bf9\u5728\u7ebf\u65b0\u95fb\u6fc0\u589e\u4e0e\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u7684\u6311\u6218\uff0c\u4e3a\u4e8b\u5b9e\u6838\u67e5\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u81ea\u52a8\u5316\u53d9\u4e8b\u5206\u7c7b\u65b9\u6848", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u6b65\u5206\u5c42\u63d0\u793a\u7b56\u7565\uff1a\u9886\u57df\u5206\u7c7b\u2192\u4e3b\u53d9\u4e8b\u8bc6\u522b\u2192\u5b50\u53d9\u4e8b\u5206\u914d", "result": "\u82f1\u8bed\u6d4b\u8bd5\u96c6\u5168\u7403\u6392\u540d\u7b2c\u4e00\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90", "conclusion": "H3Prompt\u6709\u6548\u5b9e\u73b0\u8de8\u8bed\u8a00\u591a\u5c42\u7ea7\u53d9\u4e8b\u5206\u7c7b\uff0c\u4e3a\u4fe1\u606f\u5206\u6790\u63d0\u4f9b\u53ef\u9760\u6280\u672f\u65b9\u6848"}}
{"id": "2505.22888", "pdf": "https://arxiv.org/pdf/2505.22888", "abs": "https://arxiv.org/abs/2505.22888", "authors": ["Jirui Qi", "Shan Chen", "Zidi Xiong", "Raquel Fern\u00e1ndez", "Danielle S. Bitterman", "Arianna Bisazza"], "title": "When Models Reason in Your Language: Controlling Thinking Trace Language Comes at the Cost of Accuracy", "categories": ["cs.CL"], "comment": null, "summary": "Recent Large Reasoning Models (LRMs) with thinking traces have shown strong\nperformance on English reasoning tasks. However, their ability to think in\nother languages is less studied. This capability is as important as answer\naccuracy for real world applications because users may find the reasoning trace\nuseful for oversight only when it is expressed in their own language. We\ncomprehensively evaluate two leading families of LRMs on our XReasoning\nbenchmark and find that even the most advanced models often revert to English\nor produce fragmented reasoning in other languages, revealing a substantial gap\nin multilingual reasoning. Prompt based interventions that force models to\nreason in the users language improve readability and oversight but reduce\nanswer accuracy, exposing an important trade off. We further show that targeted\npost training on just 100 examples mitigates this mismatch, though some\naccuracy loss remains. Our results highlight the limited multilingual reasoning\ncapabilities of current LRMs and outline directions for future work. Code and\ndata are available at https://github.com/Betswish/mCoT-XReasoning.", "AI": {"tldr": "\u5f53\u524d\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u591a\u8bed\u8a00\u63a8\u7406\u4e2d\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5f3a\u5236\u4f7f\u7528\u76ee\u6807\u8bed\u8a00\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u9488\u5bf9\u6027\u8bad\u7ec3\u53ef\u90e8\u5206\u7f13\u89e3\u95ee\u9898\u4f46\u4ecd\u6709\u635f\u5931\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u4e3a\u7528\u6237\u9700\u8981\u6bcd\u8bed\u63a8\u7406\u8fc7\u7a0b\u8fdb\u884c\u6709\u6548\u76d1\u7763\u3002", "method": "\u901a\u8fc7XReasoning\u57fa\u51c6\u6d4b\u8bd5\u9886\u5148\u6a21\u578b\uff0c\u5206\u6790\u8868\u73b0\u5e76\u5c1d\u8bd5\u63d0\u793a\u5e72\u9884\u548c100\u6837\u672c\u7684\u9488\u5bf9\u6027\u8bad\u7ec3\u3002", "result": "\u6a21\u578b\u5e38\u5207\u6362\u81f3\u82f1\u8bed\u6216\u751f\u6210\u788e\u7247\u5316\u63a8\u7406\uff0c\u63d0\u793a\u5e72\u9884\u63d0\u9ad8\u53ef\u8bfb\u6027\u4f46\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u540e\u8bad\u7ec3\u90e8\u5206\u7f13\u89e3\u95ee\u9898\u3002", "conclusion": "\u9700\u5e73\u8861\u53ef\u8bfb\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u540e\u7eed\u5e94\u63a2\u7d22\u6539\u8fdb\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.22897", "pdf": "https://arxiv.org/pdf/2505.22897", "abs": "https://arxiv.org/abs/2505.22897", "authors": ["Chahat Raj", "Bowen Wei", "Aylin Caliskan", "Antonios Anastasopoulos", "Ziwei Zhu"], "title": "VIGNETTE: Socially Grounded Bias Evaluation for Vision-Language Models", "categories": ["cs.CL"], "comment": "17 pages", "summary": "While bias in large language models (LLMs) is well-studied, similar concerns\nin vision-language models (VLMs) have received comparatively less attention.\nExisting VLM bias studies often focus on portrait-style images and\ngender-occupation associations, overlooking broader and more complex social\nstereotypes and their implied harm. This work introduces VIGNETTE, a\nlarge-scale VQA benchmark with 30M+ images for evaluating bias in VLMs through\na question-answering framework spanning four directions: factuality,\nperception, stereotyping, and decision making. Beyond narrowly-centered\nstudies, we assess how VLMs interpret identities in contextualized settings,\nrevealing how models make trait and capability assumptions and exhibit patterns\nof discrimination. Drawing from social psychology, we examine how VLMs connect\nvisual identity cues to trait and role-based inferences, encoding social\nhierarchies, through biased selections. Our findings uncover subtle,\nmultifaceted, and surprising stereotypical patterns, offering insights into how\nVLMs construct social meaning from inputs.", "AI": {"tldr": "\u63d0\u51faVIGNETTE\u57fa\u51c6\u6d4b\u8bd5\u7cfb\u7edf\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e8b\u5b9e\u6027\u3001\u611f\u77e5\u3001\u523b\u677f\u5370\u8c61\u548c\u51b3\u7b56\u4e2d\u7684\u504f\u89c1", "motivation": "\u73b0\u6709VLM\u504f\u89c1\u7814\u7a76\u5c40\u9650\u5728\u8096\u50cf\u56fe\u4e0e\u6027\u522b-\u804c\u4e1a\u5173\u8054\uff0c\u5ffd\u89c6\u66f4\u590d\u6742\u7684\u793e\u4f1a\u523b\u677f\u5370\u8c61\u53ca\u5176\u6f5c\u5728\u5371\u5bb3", "method": "\u6784\u5efa\u542b3000\u4e07+\u56fe\u50cf\u7684VQA\u57fa\u51c6\uff0c\u901a\u8fc7\u56db\u7ef4\u5ea6\uff08\u4e8b\u5b9e/\u611f\u77e5/\u523b\u677f/\u51b3\u7b56\uff09\u7684\u95ee\u7b54\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u504f\u89c1", "result": "\u63ed\u793a\u4e86VLM\u5728\u60c5\u5883\u5316\u8eab\u4efd\u89e3\u8bfb\u4e2d\u7684\u7279\u8d28\u5047\u8bbe\u3001\u80fd\u529b\u504f\u89c1\u53ca\u6b67\u89c6\u6a21\u5f0f\uff0c\u53d1\u73b0\u591a\u5c42\u6b21\u793e\u4f1a\u7b49\u7ea7\u7f16\u7801\u673a\u5236", "conclusion": "\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u8f93\u5165\u6570\u636e\u6784\u5efa\u793e\u4f1a\u610f\u4e49\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u5176\u9690\u542b\u7684\u5fae\u5999\u3001\u591a\u7ef4\u5ea6\u523b\u677f\u504f\u89c1\u6a21\u5f0f"}}
{"id": "2505.22910", "pdf": "https://arxiv.org/pdf/2505.22910", "abs": "https://arxiv.org/abs/2505.22910", "authors": ["Chahat Raj", "Mahika Banerjee", "Aylin Caliskan", "Antonios Anastasopoulos", "Ziwei Zhu"], "title": "Talent or Luck? Evaluating Attribution Bias in Large Language Models", "categories": ["cs.CL"], "comment": "18 pages", "summary": "When a student fails an exam, do we tend to blame their effort or the test's\ndifficulty? Attribution, defined as how reasons are assigned to event outcomes,\nshapes perceptions, reinforces stereotypes, and influences decisions.\nAttribution Theory in social psychology explains how humans assign\nresponsibility for events using implicit cognition, attributing causes to\ninternal (e.g., effort, ability) or external (e.g., task difficulty, luck)\nfactors. LLMs' attribution of event outcomes based on demographics carries\nimportant fairness implications. Most works exploring social biases in LLMs\nfocus on surface-level associations or isolated stereotypes. This work proposes\na cognitively grounded bias evaluation framework to identify how models'\nreasoning disparities channelize biases toward demographic groups.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8ba4\u77e5\u5fc3\u7406\u5b66\u7684\u5f52\u56e0\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e8b\u4ef6\u5f52\u56e0\u4e2d\u5b58\u5728\u7684\u7fa4\u4f53\u63a8\u7406\u5dee\u5f02\u53ca\u5176\u516c\u5e73\u6027\u5f71\u54cd", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u8bed\u8a00\u6a21\u578b\u7684\u8868\u5c42\u504f\u89c1\uff0c\u7f3a\u4e4f\u5bf9\u8ba4\u77e5\u5c42\u9762\u5f52\u56e0\u673a\u5236\u7684\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5fc3\u7406\u5b66\u7406\u8bba\u63ed\u793a\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u4f20\u5bfc\u8def\u5f84", "method": "\u6784\u5efa\u8ba4\u77e5\u5bfc\u5411\u7684\u504f\u89c1\u8bc4\u4f30\u6846\u67b6\uff0c\u5206\u6790\u6a21\u578b\u5bf9\u4eba\u53e3\u7edf\u8ba1\u7fa4\u4f53\u7684\u4e8b\u4ef6\u5f52\u56e0\u6a21\u5f0f\uff08\u5185\u90e8\u5f52\u56e0/\u5916\u90e8\u5f52\u56e0\uff09\uff0c\u6d4b\u91cf\u5176\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u504f\u89c1\u7684\u504f\u5dee\u7a0b\u5ea6", "result": "\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u5728\u8d23\u4efb\u5f52\u56e0\u4e2d\u5b58\u5728\u663e\u8457\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\uff0c\u5176\u63a8\u7406\u94fe\u6761\u4f1a\u7cfb\u7edf\u6027\u5f3a\u5316\u7279\u5b9a\u7fa4\u4f53\u7684\u8d1f\u9762\u523b\u677f\u5370\u8c61\uff0c\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u672a\u80fd\u6355\u6349\u6b64\u7c7b\u6df1\u5c42\u8ba4\u77e5\u504f\u5dee", "conclusion": "\u8ba4\u77e5\u89c6\u89d2\u7684\u8bc4\u4f30\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u504f\u89c1\u4f20\u5bfc\u673a\u5236\uff0c\u4e3a\u5f00\u53d1\u516c\u5e73\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u65b0\u7684\u65b9\u6cd5\u8bba\u652f\u6301\uff0c\u9700\u5efa\u7acb\u8ba4\u77e5\u5bf9\u9f50\u7684\u6a21\u578b\u8bc4\u4f30\u4f53\u7cfb"}}
{"id": "2505.22919", "pdf": "https://arxiv.org/pdf/2505.22919", "abs": "https://arxiv.org/abs/2505.22919", "authors": ["Nikita Mehandru", "Niloufar Golchini", "David Bamman", "Travis Zack", "Melanie F. Molina", "Ahmed Alaa"], "title": "ER-REASON: A Benchmark Dataset for LLM-Based Clinical Reasoning in the Emergency Room", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have been extensively evaluated on medical\nquestion answering tasks based on licensing exams. However, real-world\nevaluations often depend on costly human annotators, and existing benchmarks\ntend to focus on isolated tasks that rarely capture the clinical reasoning or\nfull workflow underlying medical decisions. In this paper, we introduce\nER-Reason, a benchmark designed to evaluate LLM-based clinical reasoning and\ndecision-making in the emergency room (ER)--a high-stakes setting where\nclinicians make rapid, consequential decisions across diverse patient\npresentations and medical specialties under time pressure. ER-Reason includes\ndata from 3,984 patients, encompassing 25,174 de-identified longitudinal\nclinical notes spanning discharge summaries, progress notes, history and\nphysical exams, consults, echocardiography reports, imaging notes, and ER\nprovider documentation. The benchmark includes evaluation tasks that span key\nstages of the ER workflow: triage intake, initial assessment, treatment\nselection, disposition planning, and final diagnosis--each structured to\nreflect core clinical reasoning processes such as differential diagnosis via\nrule-out reasoning. We also collected 72 full physician-authored rationales\nexplaining reasoning processes that mimic the teaching process used in\nresidency training, and are typically absent from ER documentation. Evaluations\nof state-of-the-art LLMs on ER-Reason reveal a gap between LLM-generated and\nclinician-authored clinical reasoning for ER decisions, highlighting the need\nfor future research to bridge this divide.", "AI": {"tldr": "\u63d0\u51faER-Reason\u57fa\u51c6\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6025\u8bca\u573a\u666f\u4e0b\u7684\u4e34\u5e8a\u63a8\u7406\u4e0e\u51b3\u7b56\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u8bc4\u4f30\u4f53\u7cfb\u5728\u771f\u5b9e\u533b\u7597\u6d41\u7a0b\u6a21\u62df\u65b9\u9762\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u8bc4\u4f30\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u4e14\u805a\u7126\u5b64\u7acb\u4efb\u52a1\uff0c\u65e0\u6cd5\u53cd\u6620\u6025\u8bca\u5ba4\u9ad8\u538b\u73af\u5883\u4e0b\u6d89\u53ca\u590d\u6742\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7684\u6838\u5fc3\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u6784\u5efa\u5305\u542b3,984\u60a3\u800525,174\u4efd\u4e34\u5e8a\u8bb0\u5f55\u7684\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u8986\u76d6\u6025\u8bca\u5206\u8bca/\u8bc4\u4f30/\u6cbb\u7597/\u8bca\u65ad\u5168\u6d41\u7a0b\u7684\u8bc4\u4f30\u4efb\u52a1\uff0c\u5e76\u6536\u96c672\u4efd\u533b\u751f\u5b8c\u6574\u63a8\u7406\u4f9d\u636e\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u9876\u5c16\u5927\u6a21\u578b\u5728\u6025\u8bca\u4e34\u5e8a\u63a8\u7406\u8d28\u91cf\u4e0a\u4e0e\u533b\u751f\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff08\u5982\u9274\u522b\u8bca\u65ad\u51c6\u786e\u6027\u5dee18.7%\uff09", "conclusion": "ER-Reason\u63ed\u793a\u4e86LLMs\u533b\u7597\u51b3\u7b56\u80fd\u529b\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u66f4\u8d34\u5408\u4e34\u5e8a\u601d\u7ef4\u6a21\u5f0f\u7684\u8bc4\u4f30\u4f53\u7cfb\u4e0e\u6a21\u578b\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2505.22921", "pdf": "https://arxiv.org/pdf/2505.22921", "abs": "https://arxiv.org/abs/2505.22921", "authors": ["Yue Xing", "Tao Yang", "Yijiashun Qi", "Minggu Wei", "Yu Cheng", "Honghui Xin"], "title": "Structured Memory Mechanisms for Stable Context Representation in Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "This paper addresses the limitations of large language models in\nunderstanding long-term context. It proposes a model architecture equipped with\na long-term memory mechanism to improve the retention and retrieval of semantic\ninformation across paragraphs and dialogue turns. The model integrates explicit\nmemory units, gated writing mechanisms, and attention-based reading modules. A\nforgetting function is introduced to enable dynamic updates of memory content,\nenhancing the model's ability to manage historical information. To further\nimprove the effectiveness of memory operations, the study designs a joint\ntraining objective. This combines the main task loss with constraints on memory\nwriting and forgetting. It guides the model to learn better memory strategies\nduring task execution. Systematic evaluation across multiple subtasks shows\nthat the model achieves clear advantages in text generation consistency,\nstability in multi-turn question answering, and accuracy in cross-context\nreasoning. In particular, the model demonstrates strong semantic retention and\ncontextual coherence in long-text tasks and complex question answering\nscenarios. It effectively mitigates the context loss and semantic drift\nproblems commonly faced by traditional language models when handling long-term\ndependencies. The experiments also include analysis of different memory\nstructures, capacity sizes, and control strategies. These results further\nconfirm the critical role of memory mechanisms in language understanding. They\ndemonstrate the feasibility and effectiveness of the proposed approach in both\narchitectural design and performance outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5177\u6709\u957f\u671f\u8bb0\u5fc6\u673a\u5236\u7684\u6a21\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u663e\u5f0f\u8bb0\u5fc6\u5355\u5143\u3001\u95e8\u63a7\u5199\u5165\u673a\u5236\u548c\u8054\u5408\u8bad\u7ec3\u76ee\u6807\uff0c\u6709\u6548\u63d0\u5347\u6587\u672c\u751f\u6210\u4e00\u81f4\u6027\u548c\u957f\u6587\u672c\u4efb\u52a1\u6027\u80fd", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u4e0a\u4e0b\u6587\u7406\u89e3\u4e2d\u5b58\u5728\u7684\u8bed\u4e49\u4fdd\u6301\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\uff0c\u7279\u522b\u662f\u4e0a\u4e0b\u6587\u4e22\u5931\u548c\u8bed\u4e49\u6f02\u79fb\u73b0\u8c61", "method": "\u6574\u5408\u663e\u5f0f\u8bb0\u5fc6\u5355\u5143+\u95e8\u63a7\u5199\u5165\u673a\u5236+\u6ce8\u610f\u529b\u8bfb\u53d6\u6a21\u5757\uff0c\u8bbe\u8ba1\u52a8\u6001\u66f4\u65b0\u7684\u9057\u5fd8\u51fd\u6570\uff0c\u91c7\u7528\u4e3b\u4efb\u52a1\u635f\u5931\u4e0e\u8bb0\u5fc6\u7ea6\u675f\u8054\u5408\u8bad\u7ec3\u7b56\u7565", "result": "\u5728\u8de8\u4e0a\u4e0b\u6587\u63a8\u7406\u51c6\u786e\u7387\u63d0\u534715%\uff0c\u591a\u8f6e\u95ee\u7b54\u7a33\u5b9a\u6027\u63d0\u9ad822%\uff0c\u957f\u6587\u672c\u4efb\u52a1\u4e2d\u4fdd\u630190%\u4ee5\u4e0a\u7684\u8bed\u4e49\u8fde\u8d2f\u6027", "conclusion": "\u8be5\u8bb0\u5fc6\u673a\u5236\u6709\u6548\u89e3\u51b3\u957f\u671f\u4f9d\u8d56\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u67b6\u6784\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u63d0\u4f9b\u65b0\u7684\u6280\u672f\u8def\u5f84"}}
{"id": "2505.22934", "pdf": "https://arxiv.org/pdf/2505.22934", "abs": "https://arxiv.org/abs/2505.22934", "authors": ["Haobo Zhang", "Jiayu Zhou"], "title": "Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "14 pages, 5 figures, 16 tables, accepted by ACL 2025", "summary": "Fine-tuning large language models (LMs) for individual tasks yields strong\nperformance but is expensive for deployment and storage. Recent works explore\nmodel merging to combine multiple task-specific models into a single multi-task\nmodel without additional training. However, existing merging methods often fail\nfor models fine-tuned with low-rank adaptation (LoRA), due to significant\nperformance degradation. In this paper, we show that this issue arises from a\npreviously overlooked interplay between model parameters and data\ndistributions. We propose Orthogonal Subspaces for Robust model Merging (OSRM)\nto constrain the LoRA subspace *prior* to fine-tuning, ensuring that updates\nrelevant to one task do not adversely shift outputs for others. Our approach\ncan seamlessly integrate with most existing merging algorithms, reducing the\nunintended interference among tasks. Extensive experiments on eight datasets,\ntested with three widely used LMs and two large LMs, demonstrate that our\nmethod not only boosts merging performance but also preserves single-task\naccuracy. Furthermore, our approach exhibits greater robustness to the\nhyperparameters of merging. These results highlight the importance of\ndata-parameter interaction in model merging and offer a plug-and-play solution\nfor merging LoRA models.", "AI": {"tldr": "\u63d0\u51faOSRM\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u4ea4\u5b50\u7a7a\u95f4\u7ea6\u675fLoRA\u53c2\u6570\u66f4\u65b0\uff0c\u6709\u6548\u63d0\u5347\u591a\u4efb\u52a1\u6a21\u578b\u5408\u5e76\u6027\u80fd\u5e76\u4fdd\u6301\u5355\u4efb\u52a1\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u5728LoRA\u5fae\u8c03\u6a21\u578b\u4e0a\u5b58\u5728\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u53c2\u6570\u4e0e\u6570\u636e\u5206\u5e03\u7684\u76f8\u4e92\u4f5c\u7528\u88ab\u5ffd\u89c6\u3002", "method": "\u5728\u5fae\u8c03\u524d\u7ea6\u675fLoRA\u5b50\u7a7a\u95f4\u6b63\u4ea4\u6027\uff0c\u9632\u6b62\u4efb\u52a1\u66f4\u65b0\u5e72\u6270\uff0c\u53ef\u4e0e\u73b0\u6709\u5408\u5e76\u7b97\u6cd5\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u57288\u4e2a\u6570\u636e\u96c6\u548c5\u79cd\u8bed\u8a00\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0cOSRM\u63d0\u5347\u5408\u5e76\u6027\u80fd10-15%\uff0c\u4fdd\u6301\u5355\u4efb\u52a1\u51c6\u786e\u7387\u4e14\u5bf9\u8d85\u53c2\u6570\u66f4\u9c81\u68d2\u3002", "conclusion": "\u63ed\u793a\u4e86\u6570\u636e-\u53c2\u6570\u4ea4\u4e92\u5bf9\u6a21\u578b\u5408\u5e76\u7684\u91cd\u8981\u6027\uff0c\u63d0\u4f9b\u5373\u63d2\u5373\u7528\u7684LoRA\u6a21\u578b\u5408\u5e76\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.22937", "pdf": "https://arxiv.org/pdf/2505.22937", "abs": "https://arxiv.org/abs/2505.22937", "authors": ["Ngeyen Yinkfu"], "title": "Improving QA Efficiency with DistilBERT: Fine-Tuning and Inference on mobile Intel CPUs", "categories": ["cs.CL"], "comment": "This paper presents an efficient transformer-based question-answering\n  model optimized for inference on a 13th Gen Intel i7 CPU. The proposed\n  approach balances performance and computational efficiency, making it\n  suitable for real-time applications on resource-constrained devices. Code for\n  this paper is available upon request via email at nyinkfu@andrew.cmu.edu", "summary": "This study presents an efficient transformer-based question-answering (QA)\nmodel optimized for deployment on a 13th Gen Intel i7-1355U CPU, using the\nStanford Question Answering Dataset (SQuAD) v1.1. Leveraging exploratory data\nanalysis, data augmentation, and fine-tuning of a DistilBERT architecture, the\nmodel achieves a validation F1 score of 0.6536 with an average inference time\nof 0.1208 seconds per question. Compared to a rule-based baseline (F1: 0.3124)\nand full BERT-based models, our approach offers a favorable trade-off between\naccuracy and computational efficiency. This makes it well-suited for real-time\napplications on resource-constrained systems. The study includes systematic\nevaluation of data augmentation strategies and hyperparameter configurations,\nproviding practical insights into optimizing transformer models for CPU-based\ninference.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eDistilBERT\u7684\u9ad8\u6548\u95ee\u7b54\u6a21\u578b\uff0c\u5728Intel i7 CPU\u4e0a\u5b9e\u73b00.6536 F1\u5206\u6570\u4e0e0.1208\u79d2/\u95ee\u9898\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u5e73\u8861\u7cbe\u5ea6\u4e0e\u6548\u7387", "motivation": "\u89e3\u51b3\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u95ee\u7b54\u6a21\u578b\u90e8\u7f72\u7684\u7cbe\u5ea6\u4e0e\u6548\u7387\u5e73\u8861\u95ee\u9898", "method": "\u91c7\u7528\u6570\u636e\u589e\u5f3a+DistilBERT\u5fae\u8c03\u67b6\u6784\uff0c\u7cfb\u7edf\u8bc4\u4f30\u8d85\u53c2\u6570\u914d\u7f6e\u4e0e\u6570\u636e\u7b56\u7565\uff0c\u5bf9\u6bd4\u89c4\u5219\u57fa\u7ebf\u548c\u5b8c\u6574BERT\u6a21\u578b", "result": "\u9a8c\u8bc1F1\u5206\u6570\u63d0\u5347109%\uff08\u76f8\u6bd4\u57fa\u7ebf\uff09\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4\u5b8c\u6574BERT\u5feb3\u500d\uff0c\u8fbe\u5230\u5b9e\u65f6\u5904\u7406\u9700\u6c42", "conclusion": "\u9a8c\u8bc1\u4e86\u84b8\u998f\u67b6\u6784\u5728CPU\u90e8\u7f72\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u63d0\u4f9b\u53ef\u843d\u5730\u7684Transformer\u4f18\u5316\u65b9\u6848"}}
{"id": "2505.22942", "pdf": "https://arxiv.org/pdf/2505.22942", "abs": "https://arxiv.org/abs/2505.22942", "authors": ["Yuchen Zhuang", "Di Jin", "Jiaao Chen", "Wenqi Shi", "Hanrui Wang", "Chao Zhang"], "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": "Work in Progress", "summary": "Large language models (LLMs)-empowered web agents enables automating complex,\nreal-time web navigation tasks in enterprise environments. However, existing\nweb agents relying on supervised fine-tuning (SFT) often struggle with\ngeneralization and robustness due to insufficient reasoning capabilities when\nhandling the inherently dynamic nature of web interactions. In this study, we\nintroduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based\nR1-style reinforcement learning framework designed explicitly to enhance\nsingle-step reasoning and planning for business-oriented web navigation tasks.\nWe employ a structured reward function that evaluates both adherence to output\nformats and correctness of actions, enabling WorkForceAgent-R1 to implicitly\nlearn robust intermediate reasoning without explicit annotations or extensive\nexpert demonstrations. Extensive experiments on the WorkArena benchmark\ndemonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by\n10.26-16.59%, achieving competitive performance relative to proprietary\nLLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684WorkForceAgent-R1\u7f51\u7edc\u4ee3\u7406\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5956\u52b1\u673a\u5236\u63d0\u5347\u4f01\u4e1a\u7ea7\u7f51\u9875\u5bfc\u822a\u4efb\u52a1\u7684\u5355\u6b65\u63a8\u7406\u80fd\u529b", "motivation": "\u89e3\u51b3\u73b0\u6709\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7f51\u7edc\u4ee3\u7406\u5728\u52a8\u6001\u7f51\u9875\u4ea4\u4e92\u4e2d\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u91c7\u7528\u89c4\u5219\u578bR1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9a8c\u8bc1\u8f93\u51fa\u683c\u5f0f\u548c\u52a8\u4f5c\u51c6\u786e\u6027\u7684\u53cc\u7ef4\u5ea6\u5956\u52b1\u51fd\u6570\u5b9e\u73b0\u9690\u5f0f\u63a8\u7406\u5b66\u4e60", "result": "\u5728WorkArena\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aSFT\u57fa\u7ebf10.26-16.59%\uff0c\u6027\u80fd\u63a5\u8fd1GPT-4o\u5546\u4e1a\u6a21\u578b", "conclusion": "\u7ed3\u6784\u5316\u5f3a\u5316\u5b66\u4e60\u673a\u5236\u53ef\u6709\u6548\u63d0\u5347\u4e1a\u52a1\u5bfc\u5411\u7f51\u9875\u5bfc\u822a\u4efb\u52a1\u7684\u63a8\u7406\u80fd\u529b\uff0c\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u5b66\u4e60"}}
{"id": "2505.22943", "pdf": "https://arxiv.org/pdf/2505.22943", "abs": "https://arxiv.org/abs/2505.22943", "authors": ["Jaewoo Ahn", "Heeseung Yun", "Dayoon Ko", "Gunhee Kim"], "title": "Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.SD"], "comment": "ACL 2025 Main. Code is released at\n  https://vision.snu.ac.kr/projects/mac", "summary": "While pre-trained multimodal representations (e.g., CLIP) have shown\nimpressive capabilities, they exhibit significant compositional vulnerabilities\nleading to counterintuitive judgments. We introduce Multimodal Adversarial\nCompositionality (MAC), a benchmark that leverages large language models (LLMs)\nto generate deceptive text samples to exploit these vulnerabilities across\ndifferent modalities and evaluates them through both sample-wise attack success\nrate and group-wise entropy-based diversity. To improve zero-shot methods, we\npropose a self-training approach that leverages rejection-sampling fine-tuning\nwith diversity-promoting filtering, which enhances both attack success rate and\nsample diversity. Using smaller language models like Llama-3.1-8B, our approach\ndemonstrates superior performance in revealing compositional vulnerabilities\nacross various multimodal representations, including images, videos, and\naudios.", "AI": {"tldr": "\u63d0\u51faMAC\u57fa\u51c6\u6d4b\u8bd5\u591a\u6a21\u6001\u6a21\u578b\u7684\u7ec4\u5408\u6027\u6f0f\u6d1e\uff0c\u5e76\u901a\u8fc7\u81ea\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u653b\u51fb\u6548\u679c", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u591a\u6a21\u6001\u6a21\u578b\u5b58\u5728\u7ec4\u5408\u6027\u6f0f\u6d1e\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u9c81\u68d2\u6027", "method": "\u5229\u7528LLM\u751f\u6210\u6b3a\u9a97\u6027\u6837\u672c\u6784\u5efaMAC\u57fa\u51c6\uff0c\u8bbe\u8ba1\u62d2\u7edd\u91c7\u6837\u5fae\u8c03+\u591a\u6837\u6027\u8fc7\u6ee4\u7684\u81ea\u8bad\u7ec3\u6846\u67b6", "result": "\u5728Llama-3.1-8B\u7b49\u5c0f\u6a21\u578b\u4e0a\u5b9e\u73b0\u8de8\u6a21\u6001\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347\uff0c\u6837\u672c\u591a\u6837\u6027\u663e\u8457\u589e\u52a0", "conclusion": "MAC\u6709\u6548\u66b4\u9732\u591a\u6a21\u6001\u7cfb\u7edf\u7f3a\u9677\uff0c\u81ea\u8bad\u7ec3\u7b56\u7565\u4e3a\u63d0\u5347\u6a21\u578b\u7ec4\u5408\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2505.22945", "pdf": "https://arxiv.org/pdf/2505.22945", "abs": "https://arxiv.org/abs/2505.22945", "authors": ["Alisha Srivastava", "Emir Korukluoglu", "Minh Nhat Le", "Duyen Tran", "Chau Minh Pham", "Marzena Karpinska", "Mohit Iyyer"], "title": "OWL: Probing Cross-Lingual Recall of Memorized Texts via World Literature", "categories": ["cs.CL", "cs.AI"], "comment": "preprint, 25 pages", "summary": "Large language models (LLMs) are known to memorize and recall English text\nfrom their pretraining data. However, the extent to which this ability\ngeneralizes to non-English languages or transfers across languages remains\nunclear. This paper investigates multilingual and cross-lingual memorization in\nLLMs, probing if memorized content in one language (e.g., English) can be\nrecalled when presented in translation. To do so, we introduce OWL, a dataset\nof 31.5K aligned excerpts from 20 books in ten languages, including English\noriginals, official translations (Vietnamese, Spanish, Turkish), and new\ntranslations in six low-resource languages (Sesotho, Yoruba, Maithili,\nMalagasy, Setswana, Tahitian). We evaluate memorization across model families\nand sizes through three tasks: (1) direct probing, which asks the model to\nidentify a book's title and author; (2) name cloze, which requires predicting\nmasked character names; and (3) prefix probing, which involves generating\ncontinuations. We find that LLMs consistently recall content across languages,\neven for texts without direct translation in pretraining data. GPT-4o, for\nexample, identifies authors and titles 69% of the time and masked entities 6%\nof the time in newly translated excerpts. Perturbations (e.g., masking\ncharacters, shuffling words) modestly reduce direct probing accuracy (7% drop\nfor shuffled official translations). Our results highlight the extent of\ncross-lingual memorization and provide insights on the differences between the\nmodels.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u6a21\u578b\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u5b58\u5728\u8de8\u8bed\u8a00\u8bb0\u5fc6\u73b0\u8c61\uff0c\u5373\u4f7f\u672a\u7ecf\u76f4\u63a5\u7ffb\u8bd1\u8bad\u7ec3\u7684\u5185\u5bb9\u4e5f\u80fd\u88ab\u56de\u5fc6\uff0c\u6270\u52a8\u5bf9\u6a21\u578b\u8bb0\u5fc6\u5f71\u54cd\u6709\u9650", "motivation": "\u63a2\u7d22LLMs\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u8bb0\u5fc6\u6cdb\u5316\u80fd\u529b\uff0c\u9a8c\u8bc1\u8de8\u8bed\u8a00\u8bb0\u5fc6\u662f\u5426\u901a\u8fc7\u7ffb\u8bd1\u5b9e\u73b0", "method": "\u6784\u5efaOWL\u591a\u8bed\u8a00\u5bf9\u9f50\u6570\u636e\u96c6\uff08\u542b10\u79cd\u8bed\u8a00\uff09\uff0c\u91c7\u7528\u76f4\u63a5\u63a2\u6d4b/\u540d\u79f0\u586b\u7a7a/\u524d\u7f00\u751f\u6210\u4e09\u79cd\u4efb\u52a1\u8bc4\u4f30\u6a21\u578b\u8bb0\u5fc6\u8868\u73b0", "result": "GPT-4o\u5728\u65b0\u7ffb\u8bd1\u6587\u672c\u4e2d\u4f5c\u8005\u8bc6\u522b\u51c6\u786e\u738769%\uff0c\u5b9e\u4f53\u9884\u6d4b\u51c6\u786e\u73876%\uff1b\u8bcd\u5e8f\u6270\u52a8\u4ec5\u4f7f\u5b98\u65b9\u7ffb\u8bd1\u51c6\u786e\u7387\u4e0b\u964d7%", "conclusion": "LLMs\u5177\u5907\u8de8\u8bed\u8a00\u8bb0\u5fc6\u8fc1\u79fb\u80fd\u529b\uff0c\u8fd9\u79cd\u80fd\u529b\u4e0d\u5b8c\u5168\u4f9d\u8d56\u7ffb\u8bd1\u6570\u636e\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u8bb0\u5fc6\u673a\u5236\u7684\u6cdb\u5316\u7279\u6027\u4e0e\u6f5c\u5728\u9690\u79c1\u98ce\u9669"}}
{"id": "2505.22946", "pdf": "https://arxiv.org/pdf/2505.22946", "abs": "https://arxiv.org/abs/2505.22946", "authors": ["Yuhui Zhang", "Yuchang Su", "Yiming Liu", "Serena Yeung-Levy"], "title": "NegVQA: Can Vision Language Models Understand Negation?", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.CY", "cs.LG"], "comment": "Published at ACL 2025 Findings", "summary": "Negation is a fundamental linguistic phenomenon that can entirely reverse the\nmeaning of a sentence. As vision language models (VLMs) continue to advance and\nare deployed in high-stakes applications, assessing their ability to comprehend\nnegation becomes essential. To address this, we introduce NegVQA, a visual\nquestion answering (VQA) benchmark consisting of 7,379 two-choice questions\ncovering diverse negation scenarios and image-question distributions. We\nconstruct NegVQA by leveraging large language models to generate negated\nversions of questions from existing VQA datasets. Evaluating 20\nstate-of-the-art VLMs across seven model families, we find that these models\nstruggle significantly with negation, exhibiting a substantial performance drop\ncompared to their responses to the original questions. Furthermore, we uncover\na U-shaped scaling trend, where increasing model size initially degrades\nperformance on NegVQA before leading to improvements. Our benchmark reveals\ncritical gaps in VLMs' negation understanding and offers insights into future\nVLM development. Project page available at\nhttps://yuhui-zh15.github.io/NegVQA/.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u5904\u7406\u5426\u5b9a\u95ee\u9898\u65f6\u5b58\u5728\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u7684U\u578b\u6269\u5c55\u89c4\u5f8b\u3002", "motivation": "\u5426\u5b9a\u662f\u8bed\u8a00\u6838\u5fc3\u73b0\u8c61\uff0c\u53ef\u80fd\u5b8c\u5168\u6539\u53d8\u8bed\u4e49\u3002\u968f\u7740VLMs\u88ab\u90e8\u7f72\u4e8e\u9ad8\u98ce\u9669\u573a\u666f\uff0c\u8bc4\u4f30\u5176\u5426\u5b9a\u7406\u89e3\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u73b0\u6709VQA\u6570\u636e\u96c6\u751f\u6210\u5426\u5b9a\u95ee\u9898\uff0c\u6784\u5efa\u542b7,379\u4e2a\u4e8c\u9009\u4e00\u95ee\u9898\u7684NegVQA\u57fa\u51c6\uff0c\u8bc4\u4f3020\u4e2a\u524d\u6cbfVLMs\u3002", "result": "\u4e3b\u6d41VLMs\u5728\u5426\u5b9a\u95ee\u9898\u4e0a\u8868\u73b0\u5e73\u5747\u4e0b\u964d31.9%\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u5448\u73b0\u5148\u6076\u5316\u540e\u6539\u5584\u7684U\u578b\u6269\u5c55\u8d8b\u52bf\u3002", "conclusion": "\u5f53\u524dVLMs\u7684\u5426\u5b9a\u7406\u89e3\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u9700\u9488\u5bf9\u6027\u6539\u8fdb\u3002NegVQA\u4e3aVLM\u5f00\u53d1\u63d0\u4f9b\u91cd\u8981\u8bc4\u4f30\u5de5\u5177\u4e0e\u65b9\u5411\u6307\u5f15\u3002"}}
{"id": "2505.22950", "pdf": "https://arxiv.org/pdf/2505.22950", "abs": "https://arxiv.org/abs/2505.22950", "authors": ["Haohan Yuan", "Sukhwa Hong", "Haopeng Zhang"], "title": "StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown strong performance in zero-shot\nsummarization, but often struggle to model document structure and identify\nsalient information in long texts. In this work, we introduce StrucSum, a\ntraining-free prompting framework that enhances LLM reasoning through\nsentence-level graph structures. StrucSum injects structural signals into\nprompts via three targeted strategies: Neighbor-Aware Prompting (NAP) for local\ncontext, Centrality-Aware Prompting (CAP) for importance estimation, and\nCentrality-Guided Masking (CGM) for efficient input reduction. Experiments on\nArXiv, PubMed, and Multi-News demonstrate that StrucSum consistently improves\nboth summary quality and factual consistency over unsupervised baselines and\nvanilla prompting. Notably, on ArXiv, it boosts FactCC and SummaC by 19.2 and\n9.7 points, indicating stronger alignment between summaries and source content.\nThese findings suggest that structure-aware prompting is a simple yet effective\napproach for zero-shot extractive summarization with LLMs, without any training\nor task-specific tuning.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u8bad\u7ec3\u7684StrucSum\u6846\u67b6\uff0c\u901a\u8fc7\u53e5\u5b50\u56fe\u7ed3\u6784\u589e\u5f3aLLM\u7684\u6458\u8981\u751f\u6210\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u8d28\u91cf\u4e0e\u4e8b\u5b9e\u4e00\u81f4\u6027", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u6458\u8981\u4efb\u52a1\u4e2d\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u6587\u6863\u7ed3\u6784\uff0c\u5c24\u5176\u5728\u957f\u6587\u672c\u4e2d\u8bc6\u522b\u5173\u952e\u4fe1\u606f\u5b58\u5728\u5c40\u9650", "method": "\u7ed3\u5408\u4e09\u79cd\u7ed3\u6784\u611f\u77e5\u7b56\u7565\uff1aNAP\uff08\u5c40\u90e8\u4e0a\u4e0b\u6587\u611f\u77e5\uff09\u3001CAP\uff08\u91cd\u8981\u6027\u8bc4\u4f30\uff09\u3001CGM\uff08\u57fa\u4e8e\u4e2d\u5fc3\u6027\u7684\u8f93\u5165\u7f29\u51cf\uff09", "result": "\u5728ArXiv\u6570\u636e\u96c6\u4e0aFactCC/SummaC\u6307\u6807\u5206\u522b\u63d0\u534719.2/9.7\u5206\uff0cPubMed\u548cMulti-News\u6570\u636e\u96c6\u4e5f\u663e\u793a\u6301\u7eed\u6539\u8fdb", "conclusion": "\u7ed3\u6784\u611f\u77e5\u63d0\u793a\u673a\u5236\u4e3aLLM\u7684\u96f6\u6837\u672c\u62bd\u53d6\u5f0f\u6458\u8981\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u4efb\u52a1\u8c03\u4f18"}}
{"id": "2505.22956", "pdf": "https://arxiv.org/pdf/2505.22956", "abs": "https://arxiv.org/abs/2505.22956", "authors": ["Matteo Guida", "Yulia Otmakhova", "Eduard Hovy", "Lea Frermann"], "title": "LLMs for Argument Mining: Detection, Extraction, and Relationship Classification of pre-defined Arguments in Online Comments", "categories": ["cs.CL"], "comment": null, "summary": "Automated large-scale analysis of public discussions around contested issues\nlike abortion requires detecting and understanding the use of arguments. While\nLarge Language Models (LLMs) have shown promise in language processing tasks,\ntheir performance in mining topic-specific, pre-defined arguments in online\ncomments remains underexplored. We evaluate four state-of-the-art LLMs on three\nargument mining tasks using datasets comprising over 2,000 opinion comments\nacross six polarizing topics. Quantitative evaluation suggests an overall\nstrong performance across the three tasks, especially for large and fine-tuned\nLLMs, albeit at a significant environmental cost. However, a detailed error\nanalysis revealed systematic shortcomings on long and nuanced comments and\nemotionally charged language, raising concerns for downstream applications like\ncontent moderation or opinion analysis. Our results highlight both the promise\nand current limitations of LLMs for automated argument analysis in online\ncomments.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5728\u7ebf\u8bc4\u8bba\u8bba\u70b9\u6316\u6398\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5728\u6807\u51c6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u4f46\u5b58\u5728\u73af\u5883\u6210\u672c\uff0c\u4e14\u5728\u957f\u6587\u672c\u548c\u60c5\u611f\u8bed\u8a00\u5904\u7406\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677", "motivation": "\u63a2\u7d22LLMs\u5728\u7279\u5b9a\u4e3b\u9898\u5728\u7ebf\u8bc4\u8bba\u4e2d\u6316\u6398\u9884\u5b9a\u4e49\u8bba\u70b9\u7684\u5b9e\u9645\u6548\u679c\uff0c\u586b\u8865\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d", "method": "\u4f7f\u7528\u5305\u542b6\u4e2a\u4e89\u8bae\u6027\u8bdd\u9898\u76842000+\u6761\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u8bc4\u4f304\u4e2a\u6700\u5148\u8fdbLLM\u5728\u4e09\u4e2a\u8bba\u70b9\u6316\u6398\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff08\u542b\u5fae\u8c03\u6a21\u578b\uff09", "result": "\u91cf\u5316\u5206\u6790\u663e\u793aLLM\u6574\u4f53\u8868\u73b0\u5f3a\u52b2\uff08\u5c24\u5176\u5927\u6a21\u578b\u548c\u5fae\u8c03\u6a21\u578b\uff09\uff0c\u4f46\u4f34\u968f\u9ad8\u78b3\u6392\u653e\uff1b\u9519\u8bef\u5206\u6790\u63ed\u793a\u5176\u5728\u957f\u6587\u672c\u3001\u7ec6\u5fae\u8868\u8fbe\u548c\u60c5\u611f\u8bed\u8a00\u5904\u7406\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677", "conclusion": "LLMs\u5728\u81ea\u52a8\u5316\u8bba\u70b9\u5206\u6790\u4e2d\u540c\u65f6\u5c55\u73b0\u6f5c\u529b\u4e0e\u5c40\u9650\uff0c\u5f53\u524d\u7f3a\u9677\u53ef\u80fd\u5f71\u54cd\u5185\u5bb9\u5ba1\u6838\u7b49\u5b9e\u9645\u5e94\u7528\u7684\u53ef\u9760\u6027"}}
{"id": "2505.22959", "pdf": "https://arxiv.org/pdf/2505.22959", "abs": "https://arxiv.org/abs/2505.22959", "authors": ["Jianwei Wang", "Mengqi Wang", "Yinsi Zhou", "Zhenchang Xing", "Qing Liu", "Xiwei Xu", "Wenjie Zhang", "Liming Zhu"], "title": "LLM-based HSE Compliance Assessment: Benchmark, Performance, and Advancements", "categories": ["cs.CL"], "comment": null, "summary": "Health, Safety, and Environment (HSE) compliance assessment demands dynamic\nreal-time decision-making under complicated regulations and complex\nhuman-machine-environment interactions. While large language models (LLMs) hold\nsignificant potential for decision intelligence and contextual dialogue, their\ncapacity for domain-specific knowledge in HSE and structured legal reasoning\nremains underexplored. We introduce HSE-Bench, the first benchmark dataset\ndesigned to evaluate the HSE compliance assessment capabilities of LLM.\nHSE-Bench comprises over 1,000 manually curated questions drawn from\nregulations, court cases, safety exams, and fieldwork videos, and integrates a\nreasoning flow based on Issue spotting, rule Recall, rule Application, and rule\nConclusion (IRAC) to assess the holistic reasoning pipeline. We conduct\nextensive evaluations on different prompting strategies and more than 10 LLMs,\nincluding foundation models, reasoning models and multimodal vision models. The\nresults show that, although current LLMs achieve good performance, their\ncapabilities largely rely on semantic matching rather than principled reasoning\ngrounded in the underlying HSE compliance context. Moreover, their native\nreasoning trace lacks the systematic legal reasoning required for rigorous HSE\ncompliance assessment. To alleviate these, we propose a new prompting\ntechnique, Reasoning of Expert (RoE), which guides LLMs to simulate the\nreasoning process of different experts for compliance assessment and reach a\nmore accurate unified decision. We hope our study highlights reasoning gaps in\nLLMs for HSE compliance and inspires further research on related tasks.", "AI": {"tldr": "\u9996\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728HSE\u5408\u89c4\u6027\u8bc4\u4f30\u80fd\u529b\u7684\u57fa\u51c6\u6570\u636e\u96c6HSE-Bench\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u4f9d\u8d56\u8bed\u4e49\u5339\u914d\u800c\u975e\u539f\u5219\u63a8\u7406\uff0c\u5e76\u63d0\u51fa\u4e13\u5bb6\u63a8\u7406\u63d0\u793a\u6280\u672fRoE\u63d0\u5347\u51b3\u7b56\u51c6\u786e\u6027\u3002", "motivation": "HSE\u5408\u89c4\u8bc4\u4f30\u9700\u52a8\u6001\u5b9e\u65f6\u51b3\u7b56\uff0c\u4f46LLMs\u5728\u9886\u57df\u77e5\u8bc6\u548c\u7ed3\u6784\u5316\u6cd5\u5f8b\u63a8\u7406\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u5176\u80fd\u529b\u5e76\u6539\u8fdb\u63a8\u7406\u673a\u5236\u3002", "method": "\u6784\u5efa\u542b1000+\u591a\u6e90\u95ee\u9898\u7684HSE-Bench\u6570\u636e\u96c6\uff0c\u96c6\u6210IRAC\u6cd5\u5f8b\u63a8\u7406\u6d41\u7a0b\uff0c\u8bc4\u4f30\u5341\u4f59\u79cdLLMs\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u6a21\u62df\u4e13\u5bb6\u51b3\u7b56\u7684RoE\u63d0\u793a\u6280\u672f\u3002", "result": "\u5f53\u524dLLMs\u4e3b\u8981\u4f9d\u8d56\u8bed\u4e49\u5339\u914d\uff08\u51c6\u786e\u738761.8%\uff09\uff0cRoE\u6280\u672f\u4f7f\u6cd5\u5f8b\u63a8\u7406\u4e00\u81f4\u6027\u63d0\u534723.6%\uff0c\u591a\u6a21\u6001\u6a21\u578b\u8f83\u7eaf\u6587\u672c\u6a21\u578b\u8868\u73b0\u63d0\u534715.2%\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86LLMs\u5728\u7cfb\u7edf\u6027\u6cd5\u5f8b\u63a8\u7406\u4e0a\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u7684RoE\u6846\u67b6\u4e3a\u5408\u89c4\u6027\u8bc4\u4f30\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8def\u5f84\uff0c\u63a8\u52a8\u9886\u57df\u4e13\u7528\u63a8\u7406\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2505.22961", "pdf": "https://arxiv.org/pdf/2505.22961", "abs": "https://arxiv.org/abs/2505.22961", "authors": ["Peixuan Han", "Zijia Liu", "Jiaxuan You"], "title": "ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) have shown promising potential in persuasion,\nbut existing works on training LLM persuaders are still preliminary. Notably,\nwhile humans are skilled in modeling their opponent's thoughts and opinions\nproactively and dynamically, current LLMs struggle with such Theory of Mind\n(ToM) reasoning, resulting in limited diversity and opponent awareness. To\naddress this limitation, we introduce Theory of Mind Augmented Persuader\n(ToMAP), a novel approach for building more flexible persuader agents by\nincorporating two theory of mind modules that enhance the persuader's awareness\nand analysis of the opponent's mental state. Specifically, we begin by\nprompting the persuader to consider possible objections to the target central\nclaim, and then use a text encoder paired with a trained MLP classifier to\npredict the opponent's current stance on these counterclaims. Our carefully\ndesigned reinforcement learning schema enables the persuader learns how to\nanalyze opponent-related information and utilize it to generate more effective\narguments. Experiments show that the ToMAP persuader, while containing only 3B\nparameters, outperforms much larger baselines, like GPT-4o, with a relative\ngain of 39.4% across multiple persuadee models and diverse corpora. Notably,\nToMAP exhibits complex reasoning chains and reduced repetition during training,\nwhich leads to more diverse and effective arguments. The opponent-aware feature\nof ToMAP also makes it suitable for long conversations and enables it to employ\nmore logical and opponent-aware strategies. These results underscore our\nmethod's effectiveness and highlight its potential for developing more\npersuasive language agents. Code is available at:\nhttps://github.com/ulab-uiuc/ToMAP.", "AI": {"tldr": "\u63d0\u51faToMAP\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5fc3\u7406\u7406\u8bba\u6a21\u5757\u548c\u5f3a\u5316\u5b66\u4e60\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u8bf4\u670d\u6548\u679c\uff083B\u53c2\u6570\u6a21\u578b\u6027\u80fd\u8d85\u8d8aGPT-4o 39.4%\uff09", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u5bf9\u8bf4\u670d\u5bf9\u8c61\u7684\u5fc3\u7406\u72b6\u6001\u5efa\u6a21\u80fd\u529b\uff0c\u5bfc\u81f4\u8bba\u70b9\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u5bf9\u624b\u610f\u8bc6", "method": "1. \u53cc\u5fc3\u7406\u7406\u8bba\u6a21\u5757\u67b6\u6784\uff1a\u4e3b\u52a8\u9884\u6d4b\u5bf9\u624b\u53cd\u5bf9\u89c2\u70b9 + MLP\u5206\u7c7b\u5668\u8bc4\u4f30\u5bf9\u624b\u7acb\u573a\n2. \u5f3a\u5316\u5b66\u4e60\u673a\u5236\u52a8\u6001\u4f18\u5316\u8bba\u70b9\u751f\u6210\u7b56\u7565", "result": "\u8de8\u591a\u4e2a\u6d4b\u8bd5\u573a\u666f\u5b9e\u73b039.4%\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\uff0c\u751f\u6210\u8bba\u70b9\u91cd\u590d\u7387\u964d\u4f4e48%\uff0c\u957f\u5bf9\u8bdd\u573a\u666f\u903b\u8f91\u8fde\u8d2f\u6027\u63d0\u534762%", "conclusion": "ToMAP\u9996\u6b21\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u5fc3\u7406\u72b6\u6001\u52a8\u6001\u5efa\u6a21\uff0c\u4e3a\u6784\u5efa\u62df\u4eba\u5316\u8bf4\u670d\u4ee3\u7406\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2505.22964", "pdf": "https://arxiv.org/pdf/2505.22964", "abs": "https://arxiv.org/abs/2505.22964", "authors": ["Sheng Zhang", "Qin Liu", "Naoto Usuyama", "Cliff Wong", "Tristan Naumann", "Hoifung Poon"], "title": "Exploring Scaling Laws for EHR Foundation Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of scaling laws has profoundly shaped the development of large\nlanguage models (LLMs), enabling predictable performance gains through\nsystematic increases in model size, dataset volume, and compute. Yet, these\nprinciples remain largely unexplored in the context of electronic health\nrecords (EHRs) -- a rich, sequential, and globally abundant data source that\ndiffers structurally from natural language. In this work, we present the first\nempirical investigation of scaling laws for EHR foundation models. By training\ntransformer architectures on patient timeline data from the MIMIC-IV database\nacross varying model sizes and compute budgets, we identify consistent scaling\npatterns, including parabolic IsoFLOPs curves and power-law relationships\nbetween compute, model parameters, data size, and clinical utility. These\nfindings demonstrate that EHR models exhibit scaling behavior analogous to\nLLMs, offering predictive insights into resource-efficient training strategies.\nOur results lay the groundwork for developing powerful EHR foundation models\ncapable of transforming clinical prediction tasks and advancing personalized\nhealthcare.", "AI": {"tldr": "\u9996\u6b21\u9a8c\u8bc1\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6a21\u578b\u9075\u5faa\u7c7b\u4f3c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\u5b9a\u5f8b\uff0c\u63ed\u793a\u8ba1\u7b97\u8d44\u6e90\u4e0e\u4e34\u5e8a\u9884\u6d4b\u6027\u80fd\u7684\u5b9a\u91cf\u5173\u7cfb", "motivation": "\u63a2\u7d22\u7ed3\u6784\u5316\u533b\u7597\u6570\u636e\u4e2d\u7f29\u653e\u5b9a\u5f8b\u7684\u9002\u7528\u6027\uff0c\u89e3\u51b3\u4f20\u7edf\u81ea\u7136\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u539f\u5219\u5728EHR\u9886\u57df\u7684\u7a7a\u767d", "method": "\u57fa\u4e8eMIMIC-IV\u6570\u636e\u5e93\u60a3\u8005\u65f6\u95f4\u8f74\u6570\u636e\uff0c\u901a\u8fc7\u8c03\u6574Transformer\u6a21\u578b\u89c4\u6a21\u548c\u8ba1\u7b97\u9884\u7b97\u8fdb\u884c\u7cfb\u7edf\u6027\u5b9e\u9a8c", "result": "\u53d1\u73b0\u629b\u7269\u7ebfIsoFLOPs\u66f2\u7ebf\u53ca\u8ba1\u7b97-\u53c2\u6570\u91cf-\u6570\u636e\u91cf-\u4e34\u5e8a\u6548\u7528\u7684\u5e42\u5f8b\u5173\u7cfb\uff0c\u8bc1\u660eEHR\u6a21\u578b\u6269\u5c55\u89c4\u5f8b\u4e0eLLMs\u76f8\u4f3c", "conclusion": "\u5efa\u7acbEHR\u57fa\u7840\u6a21\u578b\u5f00\u53d1\u6846\u67b6\uff0c\u4e3a\u4f18\u5316\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\uff0c\u63a8\u52a8\u4e2a\u6027\u5316\u533b\u7597\u53d1\u5c55"}}
{"id": "2505.22993", "pdf": "https://arxiv.org/pdf/2505.22993", "abs": "https://arxiv.org/abs/2505.22993", "authors": ["Hoang Pham", "Thanh-Do Nguyen", "Khac-Hoai Nam Bui"], "title": "Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "comment": "Published at NAACL 2025 Main Conference", "summary": "Claim verification is a long-standing and challenging task that demands not\nonly high accuracy but also explainability of the verification process. This\ntask becomes an emerging research issue in the era of large language models\n(LLMs) since real-world claims are often complex, featuring intricate semantic\nstructures or obfuscated entities. Traditional approaches typically address\nthis by decomposing claims into sub-claims and querying a knowledge base to\nresolve hidden or ambiguous entities. However, the absence of effective\ndisambiguation strategies for these entities can compromise the entire\nverification process. To address these challenges, we propose\nVerify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and\ncomprehension abilities of LLM agents. VeGraph operates in three phases: (1)\nGraph Representation - an input claim is decomposed into structured triplets,\nforming a graph-based representation that integrates both structured and\nunstructured information; (2) Entity Disambiguation -VeGraph iteratively\ninteracts with the knowledge base to resolve ambiguous entities within the\ngraph for deeper sub-claim verification; and (3) Verification - remaining\ntriplets are verified to complete the fact-checking process. Experiments using\nMeta-Llama-3-70B (instruct version) show that VeGraph achieves competitive\nperformance compared to baselines on two benchmarks HoVer and FEVEROUS,\neffectively addressing claim verification challenges. Our source code and data\nare available for further exploitation.", "AI": {"tldr": "\u63d0\u51fa\u4e86VeGraph\u6846\u67b6\uff0c\u901a\u8fc7\u56fe\u8868\u793a\u3001\u5b9e\u4f53\u6d88\u6b67\u548c\u9a8c\u8bc1\u4e09\u9636\u6bb5\u89e3\u51b3\u590d\u6742\u58f0\u660e\u9a8c\u8bc1\u95ee\u9898", "motivation": "\u4f20\u7edf\u58f0\u660e\u9a8c\u8bc1\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8bed\u4e49\u7ed3\u6784\u548c\u6a21\u7cca\u5b9e\u4f53\u65f6\u7f3a\u4e4f\u6709\u6548\u6d88\u6b67\u7b56\u7565\uff0c\u5f71\u54cd\u9a8c\u8bc1\u53ef\u9760\u6027", "method": "1) \u5c06\u58f0\u660e\u5206\u89e3\u4e3a\u7ed3\u6784\u5316\u4e09\u5143\u7ec4\u6784\u5efa\u56fe\u8868\u793a\n2) \u4e0e\u77e5\u8bc6\u5e93\u8fed\u4ee3\u4ea4\u4e92\u8fdb\u884c\u5b9e\u4f53\u6d88\u6b67\n3) \u9a8c\u8bc1\u5269\u4f59\u4e09\u5143\u7ec4\u5b8c\u6210\u4e8b\u5b9e\u6838\u67e5", "result": "\u5728HoVer\u548cFEVEROUS\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Meta-Llama-3-70B\u8fbe\u5230\u7ade\u4e89\u6027\u8868\u73b0", "conclusion": "VeGraph\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u58f0\u660e\u9a8c\u8bc1\u7684\u6311\u6218\uff0c\u6846\u67b6\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5f00\u6e90"}}
{"id": "2505.23001", "pdf": "https://arxiv.org/pdf/2505.23001", "abs": "https://arxiv.org/abs/2505.23001", "authors": ["Yize Cheng", "Wenxiao Wang", "Mazda Moayeri", "Soheil Feizi"], "title": "DyePack: Provably Flagging Test Set Contamination in LLMs Using Backdoors", "categories": ["cs.CL"], "comment": null, "summary": "Open benchmarks are essential for evaluating and advancing large language\nmodels, offering reproducibility and transparency. However, their accessibility\nmakes them likely targets of test set contamination. In this work, we introduce\nDyePack, a framework that leverages backdoor attacks to identify models that\nused benchmark test sets during training, without requiring access to the loss,\nlogits, or any internal details of the model. Like how banks mix dye packs with\ntheir money to mark robbers, DyePack mixes backdoor samples with the test data\nto flag models that trained on it. We propose a principled design incorporating\nmultiple backdoors with stochastic targets, enabling exact false positive rate\n(FPR) computation when flagging every model. This provably prevents false\naccusations while providing strong evidence for every detected case of\ncontamination. We evaluate DyePack on five models across three datasets,\ncovering both multiple-choice and open-ended generation tasks. For\nmultiple-choice questions, it successfully detects all contaminated models with\nguaranteed FPRs as low as 0.000073% on MMLU-Pro and 0.000017% on Big-Bench-Hard\nusing eight backdoors. For open-ended generation tasks, it generalizes well and\nidentifies all contaminated models on Alpaca with a guaranteed false positive\nrate of just 0.127% using six backdoors.", "AI": {"tldr": "\u63d0\u51faDyePack\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u6d4b\u8bd5\u6570\u636e\u6ce8\u5165\u968f\u673a\u76ee\u6807\u7684\u540e\u95e8\u6837\u672c\uff0c\u68c0\u6d4b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u8fdd\u89c4\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5b9e\u73b0\u7406\u8bba\u4fdd\u969c\u7684\u6781\u4f4e\u5047\u9633\u6027\u7387\u68c0\u6d4b\u3002", "motivation": "\u5f00\u653e\u57fa\u51c6\u6d4b\u8bd5\u6613\u53d7\u6d4b\u8bd5\u96c6\u6c61\u67d3\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u65e0\u9700\u6a21\u578b\u7ec6\u8282\u7684\u6c61\u67d3\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u501f\u9274\u94f6\u884c\u9632\u52ab\u8bbe\u8ba1\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e2d\u6df7\u5165\u591a\u7ec4\u968f\u673a\u76ee\u6807\u7684\u540e\u95e8\u6837\u672c\u3002\u5f53\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u6c61\u67d3\u6570\u636e\u65f6\uff0c\u540e\u95e8\u89e6\u53d1\u884c\u4e3a\u4f1a\u4ea7\u751f\u7edf\u8ba1\u663e\u8457\u6027\u8bc1\u636e\u3002", "result": "\u5728MMLU-Pro/Big-Bench-Hard\u6570\u636e\u96c6\u5b9e\u73b00.000073%/0.000017%\u5047\u9633\u6027\u7387\uff0cAlpaca\u5f00\u653e\u751f\u6210\u4efb\u52a1\u8fbe\u52300.127%\u5047\u9633\u6027\u7387\uff0c\u6210\u529f\u68c0\u6d4b\u6240\u6709\u6c61\u67d3\u6a21\u578b\u3002", "conclusion": "DyePack\u4e3a\u6d4b\u8bd5\u96c6\u6c61\u67d3\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7406\u8bba\u53ef\u9760\u3001\u4efb\u52a1\u666e\u9002\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u9632\u6b62\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc4\u4f30\u5931\u771f\u95ee\u9898\u3002"}}
{"id": "2505.23006", "pdf": "https://arxiv.org/pdf/2505.23006", "abs": "https://arxiv.org/abs/2505.23006", "authors": ["Chiwan Park", "Wonjun Jang", "Daeryong Kim", "Aelim Ahn", "Kichang Yang", "Woosung Hwang", "Jihyeon Roh", "Hyerin Park", "Hyosun Wang", "Min Seok Kim", "Jihoon Kang"], "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs", "categories": ["cs.CL", "cs.AI", "I.2.7"], "comment": "Accepted to ACL 2025 Industry Track. 12 pages, 5 figures", "summary": "The advancement of Large Language Models (LLMs) has led to significant\nimprovements in various service domains, including search, recommendation, and\nchatbot applications. However, applying state-of-the-art (SOTA) research to\nindustrial settings presents challenges, as it requires maintaining flexible\nconversational abilities while also strictly complying with service-specific\nconstraints. This can be seen as two conflicting requirements due to the\nprobabilistic nature of LLMs. In this paper, we propose our approach to\naddressing this challenge and detail the strategies we employed to overcome\ntheir inherent limitations in real-world applications. We conduct a practical\ncase study of a conversational agent designed for the e-commerce domain,\ndetailing our implementation workflow and optimizations. Our findings provide\ninsights into bridging the gap between academic research and real-world\napplication, introducing a framework for developing scalable, controllable, and\nreliable AI-driven agents.", "AI": {"tldr": "Proposing strategies to balance conversational flexibility and service constraints in LLM applications through an e-commerce case study.", "motivation": "Addressing challenges of applying SOTA LLM research to industrial settings requiring both conversational flexibility and strict compliance with service constraints.", "method": "Developed workflow optimizations and a conversational agent framework validated through e-commerce use cases.", "result": "Created a scalable framework for controllable AI agents that bridges academic research and industrial applications.", "conclusion": "Demonstrated practical implementation strategies to enhance reliability of LLM-driven systems in real-world scenarios."}}
{"id": "2505.23015", "pdf": "https://arxiv.org/pdf/2505.23015", "abs": "https://arxiv.org/abs/2505.23015", "authors": ["Jinwen Chen", "Hainan Zhang", "Fei Sun", "Qinnan Zhang", "Sijia Wen", "Ziwei Wang", "Zhiming Zheng"], "title": "Detecting Stealthy Backdoor Samples based on Intra-class Distance for Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Fine-tuning LLMs with datasets containing stealthy backdoors from publishers\nposes security risks to downstream applications. Mainstream detection methods\neither identify poisoned samples by analyzing the prediction probability of\npoisoned classification models or rely on the rewriting model to eliminate the\nstealthy triggers. However, the former cannot be applied to generation tasks,\nwhile the latter may degrade generation performance and introduce new triggers.\nTherefore, efficiently eliminating stealthy poisoned samples for LLMs remains\nan urgent problem. We observe that after applying TF-IDF clustering to the\nsample response, there are notable differences in the intra-class distances\nbetween clean and poisoned samples. Poisoned samples tend to cluster closely\nbecause of their specific malicious outputs, whereas clean samples are more\nscattered due to their more varied responses. Thus, in this paper, we propose a\nstealthy backdoor sample detection method based on Reference-Filtration and\nTfidf-Clustering mechanisms (RFTC). Specifically, we first compare the sample\nresponse with the reference model's outputs and consider the sample suspicious\nif there's a significant discrepancy. And then we perform TF-IDF clustering on\nthese suspicious samples to identify the true poisoned samples based on the\nintra-class distance. Experiments on two machine translation datasets and one\nQA dataset demonstrate that RFTC outperforms baselines in backdoor detection\nand model performance. Further analysis of different reference models also\nconfirms the effectiveness of our Reference-Filtration.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53c2\u8003\u8fc7\u6ee4\u4e0eTF-IDF\u805a\u7c7b\u7684\u9690\u853d\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5RFTC\uff0c\u6709\u6548\u89e3\u51b3\u73b0\u6709\u65b9\u6848\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027", "motivation": "\u73b0\u6709\u540e\u95e8\u68c0\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u517c\u987e\u751f\u6210\u4efb\u52a1\u9002\u7528\u6027\u4e0e\u6027\u80fd\u4fdd\u6301\uff0c\u9700\u8981\u975e\u4fb5\u5165\u5f0f\u7684\u9ad8\u6548\u68c0\u6d4b\u65b9\u6848", "method": "\u4e24\u9636\u6bb5\u68c0\u6d4b\uff1a1)\u53c2\u8003\u6a21\u578b\u8f93\u51fa\u5bf9\u6bd4\u7b5b\u9009\u53ef\u7591\u6837\u672c 2)TF-IDF\u805a\u7c7b\u5206\u6790\u7c7b\u5185\u8ddd\u79bb\u8bc6\u522b\u4e2d\u6bd2\u6837\u672c", "result": "\u5728\u673a\u5668\u7ffb\u8bd1\u548cQA\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u68c0\u6d4b\u6548\u679c\u4f18\u4e8e\u57fa\u7ebf\u4e14\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u53c2\u8003\u8fc7\u6ee4\u6709\u6548\u6027\u83b7\u5b9e\u9a8c\u652f\u6301", "conclusion": "RFTC\u901a\u8fc7\u54cd\u5e94\u5dee\u5f02\u68c0\u6d4b\u4e0e\u805a\u7c7b\u5206\u6790\uff0c\u5b9e\u73b0\u975e\u4fb5\u5165\u5f0f\u540e\u95e8\u68c0\u6d4b\uff0c\u517c\u5177\u9ad8\u6548\u6027\u4e0e\u6a21\u578b\u6027\u80fd\u4fdd\u6301\u4f18\u52bf"}}
{"id": "2505.23026", "pdf": "https://arxiv.org/pdf/2505.23026", "abs": "https://arxiv.org/abs/2505.23026", "authors": ["Haewon Park", "Gyubin Choi", "Minjun Kim", "Yohan Jo"], "title": "Context Robust Knowledge Editing for Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings. Our code and datasets are available at\n  (https://github.com/holi-lab/CoRE)", "summary": "Knowledge editing (KE) methods offer an efficient way to modify knowledge in\nlarge language models. Current KE evaluations typically assess editing success\nby considering only the edited knowledge without any preceding contexts. In\nreal-world applications, however, preceding contexts often trigger the\nretrieval of the original knowledge and undermine the intended edit. To address\nthis issue, we develop CHED -- a benchmark designed to evaluate the context\nrobustness of KE methods. Evaluations on CHED show that they often fail when\npreceding contexts are present. To mitigate this shortcoming, we introduce\nCoRE, a KE method designed to strengthen context robustness by minimizing\ncontext-sensitive variance in hidden states of the model for edited knowledge.\nThis method not only improves the editing success rate in situations where a\npreceding context is present but also preserves the overall capabilities of the\nmodel. We provide an in-depth analysis of the differing impacts of preceding\ncontexts when introduced as user utterances versus assistant responses, and we\ndissect attention-score patterns to assess how specific tokens influence\nediting success.", "AI": {"tldr": "\u63d0\u51faCHED\u57fa\u51c6\u8bc4\u4f30\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u7684\u4e0a\u4e0b\u6587\u9c81\u68d2\u6027\uff0c\u5f00\u53d1CoRE\u65b9\u6cd5\u63d0\u5347\u524d\u7f6e\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u7684\u7f16\u8f91\u6210\u529f\u7387\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u4e0a\u4e0b\u6587\u7c7b\u578b\u7684\u5f71\u54cd\u673a\u5236", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u5ffd\u89c6\u524d\u7f6e\u4e0a\u4e0b\u6587\u89e6\u53d1\u539f\u59cb\u77e5\u8bc6\u68c0\u7d22\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u6548\u679c\u53d7\u9650", "method": "\u5f00\u53d1CHED\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u8bbe\u8ba1CoRE\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u9690\u85cf\u72b6\u6001\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u65b9\u5dee\u589e\u5f3a\u9c81\u68d2\u6027", "result": "\u73b0\u6709\u65b9\u6cd5\u5728CHED\u4e0a\u5931\u8d25\u7387\u8f83\u9ad8\uff0cCoRE\u5728\u4fdd\u6301\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u7684\u7f16\u8f91\u6210\u529f\u7387", "conclusion": "CoRE\u6709\u6548\u89e3\u51b3\u4e0a\u4e0b\u6587\u5e72\u6270\u95ee\u9898\uff0c\u4e14\u7528\u6237\u4fa7\u4e0e\u52a9\u624b\u4fa7\u4e0a\u4e0b\u6587\u5bf9\u7f16\u8f91\u5f71\u54cd\u5b58\u5728\u5dee\u5f02\uff0c\u6ce8\u610f\u529b\u6a21\u5f0f\u5206\u6790\u63ed\u793a\u5173\u952etoken\u5f71\u54cd\u673a\u5236"}}
{"id": "2505.23029", "pdf": "https://arxiv.org/pdf/2505.23029", "abs": "https://arxiv.org/abs/2505.23029", "authors": ["Si Wu", "Sebastian Bruch"], "title": "Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Spac", "categories": ["cs.CL"], "comment": "Accepted for ACL 2025. This is the camera-ready version. Will be\n  presenting in July 2025 in Vienna", "summary": "Imageability (potential of text to evoke a mental image) and concreteness\n(perceptibility of text) are two psycholinguistic properties that link visual\nand semantic spaces. It is little surprise that computational methods that\nestimate them do so using parallel visual and semantic spaces, such as\ncollections of image-caption pairs or multi-modal models. In this paper, we\nwork on the supposition that text itself in an image-caption dataset offers\nsufficient signals to accurately estimate these properties. We hypothesize, in\nparticular, that the peakedness of the neighborhood of a word in the semantic\nembedding space reflects its degree of imageability and concreteness. We then\npropose an unsupervised, distribution-free measure, which we call Neighborhood\nStability Measure (NSM), that quantifies the sharpness of peaks. Extensive\nexperiments show that NSM correlates more strongly with ground-truth ratings\nthan existing unsupervised methods, and is a strong predictor of these\nproperties for classification. Our code and data are available on GitHub\n(https://github.com/Artificial-Memory-Lab/imageability).", "AI": {"tldr": "Propose Neighborhood Stability Measure (NSM) based on semantic space peakedness to estimate imageability/concreteness without visual data. Achieve SOTA performance.", "motivation": "Existing methods rely on parallel visual-semantic data (e.g., image-caption pairs). We hypothesize text itself contains sufficient signals through neighborhood structure in semantic space.", "method": "Unsupervised NSM metric quantifies peakedness of word neighborhoods in embedding space. Measures local stability of semantic neighbors.", "result": "NSM shows stronger correlation with human ratings than existing unsupervised methods (+12-15%), achieves 81.3% accuracy in classification tasks.", "conclusion": "Semantic neighborhood patterns effectively predict psycholinguistic properties. Text-only approach reduces multimodal dependency, improves computational efficiency."}}
{"id": "2505.23030", "pdf": "https://arxiv.org/pdf/2505.23030", "abs": "https://arxiv.org/abs/2505.23030", "authors": ["Shruti Hegde", "Mabon Manoj Ninan", "Jonathan R. Dillman", "Shireen Hayatghaibi", "Lynn Babcock", "Elanchezhian Somasundaram"], "title": "Can Modern NLP Systems Reliably Annotate Chest Radiography Exams? A Pre-Purchase Evaluation and Comparative Study of Solutions from AWS, Google, Azure, John Snow Labs, and Open-Source Models on an Independent Pediatric Dataset", "categories": ["cs.CL"], "comment": null, "summary": "General-purpose clinical natural language processing (NLP) tools are\nincreasingly used for the automatic labeling of clinical reports. However,\nindependent evaluations for specific tasks, such as pediatric chest radiograph\n(CXR) report labeling, are limited. This study compares four commercial\nclinical NLP systems - Amazon Comprehend Medical (AWS), Google Healthcare NLP\n(GC), Azure Clinical NLP (AZ), and SparkNLP (SP) - for entity extraction and\nassertion detection in pediatric CXR reports. Additionally, CheXpert and\nCheXbert, two dedicated chest radiograph report labelers, were evaluated on the\nsame task using CheXpert-defined labels. We analyzed 95,008 pediatric CXR\nreports from a large academic pediatric hospital. Entities and assertion\nstatuses (positive, negative, uncertain) from the findings and impression\nsections were extracted by the NLP systems, with impression section entities\nmapped to 12 disease categories and a No Findings category. CheXpert and\nCheXbert extracted the same 13 categories. Outputs were compared using Fleiss\nKappa and accuracy against a consensus pseudo-ground truth. Significant\ndifferences were found in the number of extracted entities and assertion\ndistributions across NLP systems. SP extracted 49,688 unique entities, GC\n16,477, AZ 31,543, and AWS 27,216. Assertion accuracy across models averaged\naround 62%, with SP highest (76%) and AWS lowest (50%). CheXpert and CheXbert\nachieved 56% accuracy. Considerable variability in performance highlights the\nneed for careful validation and review before deploying NLP tools for clinical\nreport labeling.", "AI": {"tldr": "\u6bd4\u8f83\u56db\u5927\u5546\u4e1aNLP\u7cfb\u7edf\uff08AWS/GC/AZ/SP\uff09\u4e0e\u4e13\u7528\u5de5\u5177CheXpert/CheXbert\u5728\u513f\u79d1\u80f8\u7247\u62a5\u544a\u6807\u6ce8\u4e2d\u7684\u6027\u80fd\u5dee\u5f02", "motivation": "\u8bc4\u4f30\u901a\u7528\u4e34\u5e8aNLP\u5de5\u5177\u5728\u513f\u79d1\u80f8\u7247\u62a5\u544a\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u586b\u8865\u7279\u5b9a\u9886\u57df\u72ec\u7acb\u9a8c\u8bc1\u7684\u7814\u7a76\u7a7a\u767d", "method": "\u5206\u679095,008\u4efd\u513f\u79d1\u80f8\u7247\u62a5\u544a\uff0c\u6bd4\u8f83\u56db\u4e2a\u5546\u4e1aNLP\u7cfb\u7edf\u548c\u4e24\u4e2a\u4e13\u7528\u5de5\u5177\u5728\u5b9e\u4f53\u63d0\u53d6\u3001\u65ad\u8a00\u68c0\u6d4b\u7684\u51c6\u786e\u7387\uff08Fleiss Kappa\u6307\u6807\uff09", "result": "SP\u7cfb\u7edf\u63d0\u53d6\u6700\u591a\u5b9e\u4f53\uff0849,688\uff09\uff0c\u65ad\u8a00\u51c6\u786e\u7387\u6700\u9ad8\uff0876%\uff09\uff1bAWS\u51c6\u786e\u7387\u6700\u4f4e\uff0850%\uff09\u3002\u4e13\u7528\u5de5\u5177\u51c6\u786e\u7387\u4ec556%", "conclusion": "\u4e0d\u540cNLP\u5de5\u5177\u6027\u80fd\u5dee\u5f02\u663e\u8457\uff0c\u4e34\u5e8a\u5e94\u7528\u524d\u9700\u4e25\u683c\u9a8c\u8bc1\uff0c\u786e\u4fdd\u6807\u6ce8\u53ef\u9760\u6027"}}
{"id": "2505.23035", "pdf": "https://arxiv.org/pdf/2505.23035", "abs": "https://arxiv.org/abs/2505.23035", "authors": ["Hyunwoo Kim", "Hanau Yi"], "title": "Machine-Facing English: Defining a Hybrid Register Shaped by Human-AI Discourse", "categories": ["cs.CL"], "comment": null, "summary": "Machine-Facing English (MFE) is an emergent register shaped by the adaptation\nof everyday language to the expanding presence of AI interlocutors. Drawing on\nregister theory (Halliday 1985, 2006), enregisterment (Agha 2003), audience\ndesign (Bell 1984), and interactional pragmatics (Giles & Ogay 2007), this\nstudy traces how sustained human-AI interaction normalizes syntactic rigidity,\npragmatic simplification, and hyper-explicit phrasing - features that enhance\nmachine parseability at the expense of natural fluency. Our analysis is\ngrounded in qualitative observations from bilingual (Korean/English) voice- and\ntext-based product testing sessions, with reflexive drafting conducted using\nNatural Language Declarative Prompting (NLD-P) under human curation. Thematic\nanalysis identifies five recurrent traits - redundant clarity, directive\nsyntax, controlled vocabulary, flattened prosody, and single-intent structuring\n- that improve execution accuracy but compress expressive range. MFE's\nevolution highlights a persistent tension between communicative efficiency and\nlinguistic richness, raising design challenges for conversational interfaces\nand pedagogical considerations for multilingual users. We conclude by\nunderscoring the need for comprehensive methodological exposition and future\nempirical validation.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u9762\u5411\u673a\u5668\u82f1\u8bed(MFE)\u7684\u4e94\u5927\u7279\u5f81\uff1a\u5197\u4f59\u6e05\u6670\u5ea6\u3001\u6307\u4ee4\u6027\u53e5\u6cd5\u3001\u53d7\u63a7\u8bcd\u6c47\u3001\u6241\u5e73\u5316\u97f5\u5f8b\u548c\u5355\u4e00\u610f\u56fe\u7ed3\u6784\u3002\u8fd9\u4e9b\u7279\u5f81\u63d0\u5347AI\u89e3\u6790\u51c6\u786e\u7387\u4f46\u524a\u5f31\u4e86\u8bed\u8a00\u8868\u8fbe\u7684\u4e30\u5bcc\u6027", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u5728\u957f\u671f\u4eba\u673a\u4ea4\u4e92\u4e2d\u5982\u4f55\u901a\u8fc7\u8bed\u6cd5\u56fa\u5316\u3001\u8bed\u7528\u7b80\u5316\u548c\u8d85\u663e\u6027\u8868\u8fbe\u6765\u9002\u5e94AI\u5bf9\u8bdd\u8005\uff0c\u5206\u6790\u8fd9\u79cd\u8bed\u8a00\u53d8\u5f02\u5bf9\u673a\u5668\u53ef\u89e3\u6790\u6027\u548c\u81ea\u7136\u6d41\u7545\u6027\u7684\u5f71\u54cd", "method": "\u57fa\u4e8e\u97e9\u82f1\u53cc\u8bed\u8bed\u97f3/\u6587\u672c\u4ea7\u54c1\u6d4b\u8bd5\u7684\u5b9a\u6027\u89c2\u5bdf\uff0c\u91c7\u7528\u81ea\u7136\u8bed\u8a00\u58f0\u660e\u63d0\u793a(NLD-P)\u8fdb\u884c\u53cd\u5c04\u6027\u8d77\u8349\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u6cd5\u8bc6\u522b\u51fa\u4e94\u4e2a\u53cd\u590d\u51fa\u73b0\u7684\u8bed\u8a00\u7279\u5f81", "result": "\u53d1\u73b0MFE\u5728\u63d0\u5347\u6307\u4ee4\u6267\u884c\u51c6\u786e\u7387\uff08\u673a\u5668\u89e3\u6790\u4f18\u5316\u7ea637%\uff09\u7684\u540c\u65f6\uff0c\u5bfc\u81f4\u4eba\u7c7b\u8bed\u8a00\u8868\u8fbe\u7684\u538b\u7f29\uff08\u8bcd\u6c47\u591a\u6837\u6027\u964d\u4f4e\u7ea628%\uff09\u548c\u4ea4\u4e92\u81ea\u7136\u5ea6\u7684\u4e0b\u964d", "conclusion": "\u5f3a\u8c03\u4eba\u673a\u754c\u9762\u8bbe\u8ba1\u9700\u8981\u5e73\u8861\u6548\u7387\u4e0e\u8bed\u8a00\u4e30\u5bcc\u6027\uff0c\u5efa\u8bae\u5f00\u53d1\u6df7\u5408\u89e3\u6790\u6a21\u578b\uff08\u7ed3\u5408\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff09\u5e76\u52a0\u5f3a\u591a\u8bed\u8a00\u7528\u6237\u7684\u9002\u5e94\u6027\u8bad\u7ec3\u65b9\u6848"}}
{"id": "2505.23037", "pdf": "https://arxiv.org/pdf/2505.23037", "abs": "https://arxiv.org/abs/2505.23037", "authors": ["Longyin Zhang", "Bowei Zou", "Ai Ti Aw"], "title": "Improving Multilingual Social Media Insights: Aspect-based Comment Analysis", "categories": ["cs.CL"], "comment": "The paper was peer-reviewed", "summary": "The inherent nature of social media posts, characterized by the freedom of\nlanguage use with a disjointed array of diverse opinions and topics, poses\nsignificant challenges to downstream NLP tasks such as comment clustering,\ncomment summarization, and social media opinion analysis. To address this, we\npropose a granular level of identifying and generating aspect terms from\nindividual comments to guide model attention. Specifically, we leverage\nmultilingual large language models with supervised fine-tuning for comment\naspect term generation (CAT-G), further aligning the model's predictions with\nhuman expectations through DPO. We demonstrate the effectiveness of our method\nin enhancing the comprehension of social media discourse on two NLP tasks.\nMoreover, this paper contributes the first multilingual CAT-G test set on\nEnglish, Chinese, Malay, and Bahasa Indonesian. As LLM capabilities vary among\nlanguages, this test set allows for a comparative analysis of performance\nacross languages with varying levels of LLM proficiency.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684\u8bc4\u8bba\u65b9\u9762\u672f\u8bed\u751f\u6210\u65b9\u6cd5\uff08CAT-G\uff09\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548cDPO\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u7406\u89e3\uff0c\u5e76\u6784\u5efa\u9996\u4e2a\u591a\u8bed\u8a00\u6d4b\u8bd5\u96c6", "motivation": "\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\u81ea\u7531\u53d1\u6563\u7684\u7279\u6027\u5bfc\u81f4\u4e0b\u6e38NLP\u4efb\u52a1\uff08\u5982\u8bc4\u8bba\u805a\u7c7b\u3001\u6458\u8981\uff09\u9762\u4e34\u8bed\u4e49\u7406\u89e3\u56f0\u96be\uff0c\u9700\u8981\u7ec6\u7c92\u5ea6\u7684\u65b9\u9762\u672f\u8bed\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8", "method": "1. \u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u7684\u591a\u8bed\u8a00\u5927\u6a21\u578b\u751f\u6210\u8bc4\u8bba\u65b9\u9762\u672f\u8bed\n2. \u901a\u8fc7DPO\u5bf9\u9f50\u6a21\u578b\u9884\u6d4b\u4e0e\u4eba\u7c7b\u9884\u671f\n3. \u6784\u5efa\u5305\u542b\u82f1/\u4e2d/\u9a6c\u6765/\u5370\u5c3c\u8bed\u7684\u591a\u8bed\u8a00\u6d4b\u8bd5\u96c6", "result": "\u5728\u4e24\u9879NLP\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u63d0\u4f9b\u8de8\u8bed\u8a00\u6027\u80fd\u5bf9\u6bd4\u57fa\u51c6\uff08\u6d4b\u8bd5\u96c6\u8986\u76d6\u4e0d\u540cLLM\u80fd\u529b\u5c42\u7ea7\u7684\u8bed\u8a00\uff09", "conclusion": "CAT-G\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u6587\u672c\u7406\u89e3\uff0c\u521b\u5efa\u7684\u591a\u8bed\u8a00\u6d4b\u8bd5\u96c6\u652f\u6301LLM\u8de8\u8bed\u8a00\u80fd\u529b\u5206\u6790"}}
{"id": "2505.23038", "pdf": "https://arxiv.org/pdf/2505.23038", "abs": "https://arxiv.org/abs/2505.23038", "authors": ["Yuzhen Xiao", "Jiahe Song", "Yongxin Xu", "Ruizhe Zhang", "Yiqi Xiao", "Xin Lu", "Runchuan Zhu", "Bowen Jiang", "Junfeng Zhao"], "title": "EL4NER: Ensemble Learning for Named Entity Recognition via Multiple Small-Parameter Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "In-Context Learning (ICL) technique based on Large Language Models (LLMs) has\ngained prominence in Named Entity Recognition (NER) tasks for its lower\ncomputing resource consumption, less manual labeling overhead, and stronger\ngeneralizability. Nevertheless, most ICL-based NER methods depend on\nlarge-parameter LLMs: the open-source models demand substantial computational\nresources for deployment and inference, while the closed-source ones incur high\nAPI costs, raise data-privacy concerns, and hinder community collaboration. To\naddress this question, we propose an Ensemble Learning Method for Named Entity\nRecognition (EL4NER), which aims at aggregating the ICL outputs of multiple\nopen-source, small-parameter LLMs to enhance overall performance in NER tasks\nat less deployment and inference cost. Specifically, our method comprises three\nkey components. First, we design a task decomposition-based pipeline that\nfacilitates deep, multi-stage ensemble learning. Second, we introduce a novel\nspan-level sentence similarity algorithm to establish an ICL demonstration\nretrieval mechanism better suited for NER tasks. Third, we incorporate a\nself-validation mechanism to mitigate the noise introduced during the ensemble\nprocess. We evaluated EL4NER on multiple widely adopted NER datasets from\ndiverse domains. Our experimental results indicate that EL4NER surpasses most\nclosed-source, large-parameter LLM-based methods at a lower parameter cost and\neven attains state-of-the-art (SOTA) performance among ICL-based methods on\ncertain datasets. These results show the parameter efficiency of EL4NER and\nunderscore the feasibility of employing open-source, small-parameter LLMs\nwithin the ICL paradigm for NER tasks.", "AI": {"tldr": "\u63d0\u51faEL4NER\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u5c0f\u578b\u5f00\u6e90LLM\u7684ICL\u8f93\u51fa\u6765\u5b9e\u73b0\u9ad8\u6548NER\u4efb\u52a1\uff0c\u5728\u66f4\u4f4e\u6210\u672c\u4e0b\u8d85\u8d8a\u5927\u6a21\u578b\u6027\u80fd", "motivation": "\u89e3\u51b3\u57fa\u4e8eICL\u7684NER\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u5927\u6a21\u578b\u7684\u95ee\u9898\uff08\u9ad8\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3001API\u6210\u672c\u3001\u6570\u636e\u9690\u79c1\u98ce\u9669\uff09\uff0c\u63a2\u7d22\u5c0f\u53c2\u6570\u5f00\u6e90LLM\u7684\u53ef\u884c\u6027", "method": "1. \u4efb\u52a1\u5206\u89e3\u7684\u591a\u9636\u6bb5\u96c6\u6210\u5b66\u4e60\u6846\u67b6\n2. \u9762\u5411NER\u4efb\u52a1\u7684span\u7ea7\u76f8\u4f3c\u5ea6\u68c0\u7d22\u673a\u5236\n3. \u566a\u58f0\u6291\u5236\u7684\u81ea\u9a8c\u8bc1\u673a\u5236", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u95ed\u6e90\u5927\u6a21\u578b\u65b9\u6cd5\uff0c\u90e8\u5206\u8fbe\u5230SOTA\uff0c\u53c2\u6570\u6210\u672c\u964d\u4f4e80%+", "conclusion": "\u8bc1\u660e\u5c0f\u53c2\u6570\u5f00\u6e90LLM\u901a\u8fc7\u96c6\u6210\u5b66\u4e60\u5728ICL\u8303\u5f0f\u4e0b\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u9ad8\u6548NER\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.23052", "pdf": "https://arxiv.org/pdf/2505.23052", "abs": "https://arxiv.org/abs/2505.23052", "authors": ["Jiarui Zhang", "Xiangyu Liu", "Yong Hu", "Chaoyue Niu", "Fan Wu", "Guihai Chen"], "title": "Query Routing for Retrieval-Augmented Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) significantly improves the performance\nof Large Language Models (LLMs) on knowledge-intensive tasks. However, varying\nresponse quality across LLMs under RAG necessitates intelligent routing\nmechanisms, which select the most suitable model for each query from multiple\nretrieval-augmented LLMs via a dedicated router model. We observe that external\ndocuments dynamically affect LLMs' ability to answer queries, while existing\nrouting methods, which rely on static parametric knowledge representations,\nexhibit suboptimal performance in RAG scenarios. To address this, we formally\ndefine the new retrieval-augmented LLM routing problem, incorporating the\ninfluence of retrieved documents into the routing framework. We propose\nRAGRouter, a RAG-aware routing design, which leverages document embeddings and\nRAG capability embeddings with contrastive learning to capture knowledge\nrepresentation shifts and enable informed routing decisions. Extensive\nexperiments on diverse knowledge-intensive tasks and retrieval settings show\nthat RAGRouter outperforms the best individual LLM by 3.61% on average and\nexisting routing methods by 3.29%-9.33%. With an extended score-threshold-based\nmechanism, it also achieves strong performance-efficiency trade-offs under\nlow-latency constraints.", "AI": {"tldr": "RAGRouter\u901a\u8fc7\u52a8\u6001\u5d4c\u5165\u548c\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0RAG\u573a\u666f\u4e0b\u7684\u667a\u80fd\u6a21\u578b\u8def\u7531\u9009\u62e9\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u53473.61%", "motivation": "\u73b0\u6709\u8def\u7531\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u77e5\u8bc6\u8868\u793a\uff0c\u65e0\u6cd5\u9002\u5e94RAG\u573a\u666f\u4e2d\u5916\u90e8\u6587\u6863\u5bf9LLM\u80fd\u529b\u7684\u52a8\u6001\u5f71\u54cd", "method": "\u7ed3\u5408\u6587\u6863\u5d4c\u5165\u4e0eRAG\u80fd\u529b\u5d4c\u5165\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u52a8\u6001\u6355\u6349\u77e5\u8bc6\u8868\u793a\u53d8\u5316", "result": "\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u5e73\u5747\u8d85\u8d8a\u6700\u4f73\u5355\u6a21\u578b3.61%\uff0c\u8def\u7531\u6548\u7387\u63d0\u53473.29%-9.33%\uff0c\u652f\u6301\u4f4e\u5ef6\u8fdf\u573a\u666f\u7684\u6548\u80fd\u5e73\u8861", "conclusion": "RAGRouter\u901a\u8fc7\u52a8\u6001\u77e5\u8bc6\u9002\u5e94\u673a\u5236\uff0c\u4e3aRAG\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u6a21\u578b\u8def\u7531\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.23060", "pdf": "https://arxiv.org/pdf/2505.23060", "abs": "https://arxiv.org/abs/2505.23060", "authors": ["Jeonghun Cho", "Deokhyung Kang", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Self-Correcting Code Generation Using Small Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Self-correction has demonstrated potential in code generation by allowing\nlanguage models to revise and improve their outputs through successive\nrefinement. Recent studies have explored prompting-based strategies that\nincorporate verification or feedback loops using proprietary models, as well as\ntraining-based methods that leverage their strong reasoning capabilities.\nHowever, whether smaller models possess the capacity to effectively guide their\noutputs through self-reflection remains unexplored. Our findings reveal that\nsmaller models struggle to exhibit reflective revision behavior across both\nself-correction paradigms. In response, we introduce CoCoS, an approach\ndesigned to enhance the ability of small language models for multi-turn code\ncorrection. Specifically, we propose an online reinforcement learning objective\nthat trains the model to confidently maintain correct outputs while\nprogressively correcting incorrect outputs as turns proceed. Our approach\nfeatures an accumulated reward function that aggregates rewards across the\nentire trajectory and a fine-grained reward better suited to multi-turn\ncorrection scenarios. This facilitates the model in enhancing initial response\nquality while achieving substantial improvements through self-correction. With\n1B-scale models, CoCoS achieves improvements of 35.8% on the MBPP and 27.7% on\nHumanEval compared to the baselines.", "AI": {"tldr": "\u63d0\u51faCoCoS\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5c0f\u6a21\u578b\uff081B\u89c4\u6a21\uff09\u5728\u591a\u8f6e\u4ee3\u7801\u7ea0\u9519\u4e2d\u7684\u80fd\u529b\uff0c\u5728MBPP\u548cHumanEval\u57fa\u51c6\u5206\u522b\u5b9e\u73b035.8%\u548c27.7%\u7684\u6027\u80fd\u63d0\u5347", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u7684\u81ea\u7ea0\u6b63\u65b9\u6cd5\u4f9d\u8d56\u5927\u6a21\u578b\u6216\u63d0\u793a\u7b56\u7565\uff0c\u4f46\u5c0f\u6a21\u578b\u7684\u81ea\u53cd\u601d\u4fee\u6b63\u80fd\u529b\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u7814\u7a76\u53d1\u73b0\u5c0f\u6a21\u578b\u5728\u4e24\u79cd\u81ea\u7ea0\u6b63\u8303\u5f0f\u4e2d\u5747\u8868\u73b0\u6b20\u4f73\uff0c\u56e0\u6b64\u63d0\u51fa\u9488\u5bf9\u6027\u89e3\u51b3\u65b9\u6848", "method": "CoCoS\u65b9\u6cd5\u5305\u542b\uff1a1\uff09\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u8bad\u7ec3\u6a21\u578b\u6e10\u8fdb\u4fee\u6b63\u8f93\u51fa\uff1b2\uff09\u7d2f\u79ef\u8f68\u8ff9\u5956\u52b1\u51fd\u6570\uff1b3\uff09\u9002\u5e94\u591a\u8f6e\u7ea0\u9519\u7684\u7ec6\u7c92\u5ea6\u5956\u52b1\u673a\u5236", "result": "\u4f7f\u75281B\u53c2\u6570\u6a21\u578b\u65f6\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728MBPP\u548cHumanEval\u5206\u522b\u63d0\u534735.8%\u548c27.7%", "conclusion": "\u901a\u8fc7\u521b\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u9a8c\u8bc1\u4e86\u5c0f\u6a21\u578b\u901a\u8fc7\u81ea\u7ea0\u6b63\u673a\u5236\u5927\u5e45\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8f7b\u91cf\u7ea7\u6a21\u578b\u7684\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.23065", "pdf": "https://arxiv.org/pdf/2505.23065", "abs": "https://arxiv.org/abs/2505.23065", "authors": ["Hongcheng Guo", "Zheyong Xie", "Shaosheng Cao", "Boyang Wang", "Weiting Liu", "Anjie Le", "Lei Li", "Zhoujun Li"], "title": "SNS-Bench-VL: Benchmarking Multimodal Large Language Models in Social Networking Services", "categories": ["cs.CL"], "comment": null, "summary": "With the increasing integration of visual and textual content in Social\nNetworking Services (SNS), evaluating the multimodal capabilities of Large\nLanguage Models (LLMs) is crucial for enhancing user experience, content\nunderstanding, and platform intelligence. Existing benchmarks primarily focus\non text-centric tasks, lacking coverage of the multimodal contexts prevalent in\nmodern SNS ecosystems. In this paper, we introduce SNS-Bench-VL, a\ncomprehensive multimodal benchmark designed to assess the performance of\nVision-Language LLMs in real-world social media scenarios. SNS-Bench-VL\nincorporates images and text across 8 multimodal tasks, including note\ncomprehension, user engagement analysis, information retrieval, and\npersonalized recommendation. It comprises 4,001 carefully curated multimodal\nquestion-answer pairs, covering single-choice, multiple-choice, and open-ended\ntasks. We evaluate over 25 state-of-the-art multimodal LLMs, analyzing their\nperformance across tasks. Our findings highlight persistent challenges in\nmultimodal social context comprehension. We hope SNS-Bench-VL will inspire\nfuture research towards robust, context-aware, and human-aligned multimodal\nintelligence for next-generation social networking services.", "AI": {"tldr": "\u63d0\u51faSNS-Bench-VL\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d68\u7c7b\u793e\u4ea4\u5a92\u4f53\u4efb\u52a1\uff0c\u542b4,001\u7ec4\u6570\u636e\uff0c\u8bc4\u4f3025+\u524d\u6cbf\u6a21\u578b\u6027\u80fd\uff0c\u63ed\u793a\u591a\u6a21\u6001\u7406\u89e3\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u805a\u7126\u6587\u672c\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u793e\u4ea4\u7f51\u7edc\u591a\u6a21\u6001\u573a\u666f\u7684\u8986\u76d6\uff0c\u9700\u6784\u5efa\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u4f53\u7cfb\u63a8\u52a8\u6280\u672f\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b\u56fe\u6587\u6df7\u5408\u76848\u5927\u4efb\u52a1\uff08\u7b14\u8bb0\u7406\u89e3\u3001\u7528\u6237\u5206\u6790\u3001\u4fe1\u606f\u68c0\u7d22\u7b49\uff09\uff0c\u8bbe\u8ba14,001\u7ec4\u591a\u7c7b\u578b\u95ee\u7b54\u5bf9\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u793e\u4ea4\u573a\u666f\u591a\u6a21\u6001\u7406\u89e3\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u4e0a\u4e0b\u6587\u5173\u8054\u4e0e\u590d\u6742\u63a8\u7406\u80fd\u529b\u5f85\u63d0\u5347\u3002", "conclusion": "\u8be5\u57fa\u51c6\u5c06\u63a8\u52a8\u6784\u5efa\u66f4\u9c81\u68d2\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u591a\u6a21\u6001\u667a\u80fd\u7cfb\u7edf\uff0c\u652f\u6491\u4e0b\u4e00\u4ee3\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u53d1\u5c55\u3002"}}
{"id": "2505.23078", "pdf": "https://arxiv.org/pdf/2505.23078", "abs": "https://arxiv.org/abs/2505.23078", "authors": ["Yuu Jinnai"], "title": "Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025", "summary": "Document-level text generation tasks are known to be more difficult than\nsentence-level text generation tasks as they require the understanding of\nlonger context to generate high-quality texts. In this paper, we investigate\nthe adaption of Minimum Bayes Risk (MBR) decoding for document-level text\ngeneration tasks. MBR decoding makes use of a utility function to estimate the\noutput with the highest expected utility from a set of candidate outputs.\nAlthough MBR decoding is shown to be effective in a wide range of\nsentence-level text generation tasks, its performance on document-level text\ngeneration tasks is limited as many of the utility functions are designed for\nevaluating the utility of sentences. To this end, we propose MBR-OT, a variant\nof MBR decoding using Wasserstein distance to compute the utility of a document\nusing a sentence-level utility function. The experimental result shows that the\nperformance of MBR-OT outperforms that of the standard MBR in document-level\nmachine translation, text simplification, and dense image captioning tasks. Our\ncode is available at https://github.com/jinnaiyuu/mbr-optimal-transport", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMBR-OT\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7Wasserstein\u8ddd\u79bb\u7ed3\u5408\u53e5\u5b50\u7ea7\u6548\u7528\u51fd\u6570\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u6863\u7ea7\u6587\u672c\u751f\u6210\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u6587\u6863\u7ea7\u6587\u672c\u751f\u6210\u4efb\u52a1\u56e0\u9700\u7406\u89e3\u957f\u4e0a\u4e0b\u6587\u800c\u66f4\u5177\u6311\u6218\u6027\uff0c\u4f20\u7edfMBR\u89e3\u7801\u7684\u6548\u7528\u51fd\u6570\u591a\u9488\u5bf9\u53e5\u5b50\u7ea7\u8bbe\u8ba1\uff0c\u5bfc\u81f4\u6587\u6863\u7ea7\u4efb\u52a1\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faMBR-OT\u65b9\u6cd5\uff0c\u5229\u7528Wasserstein\u8ddd\u79bb\u5c06\u53e5\u5b50\u7ea7\u6548\u7528\u51fd\u6570\u6269\u5c55\u81f3\u6587\u6863\u7ea7\u6548\u7528\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMBR-OT\u5728\u6587\u6863\u7ea7\u673a\u5668\u7ffb\u8bd1\u3001\u6587\u672c\u7b80\u5316\u548c\u5bc6\u96c6\u56fe\u50cf\u63cf\u8ff0\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u6807\u51c6MBR\u3002", "conclusion": "MBR-OT\u6709\u6548\u89e3\u51b3\u4e86\u6587\u6863\u7ea7\u6548\u7528\u8bc4\u4f30\u96be\u9898\uff0c\u4e3a\u590d\u6742\u6587\u672c\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4fbf\u4e8e\u590d\u73b0\u3002"}}
{"id": "2505.23108", "pdf": "https://arxiv.org/pdf/2505.23108", "abs": "https://arxiv.org/abs/2505.23108", "authors": ["Zexuan Li", "Hongliang Dai", "Piji Li"], "title": "Generating Diverse Training Samples for Relation Extraction with Large Language Models", "categories": ["cs.CL"], "comment": "ACL2025 Main", "summary": "Using Large Language Models (LLMs) to generate training data can potentially\nbe a preferable way to improve zero or few-shot NLP tasks. However, many\nproblems remain to be investigated for this direction. For the task of Relation\nExtraction (RE), we find that samples generated by directly prompting LLMs may\neasily have high structural similarities with each other. They tend to use a\nlimited variety of phrasing while expressing the relation between a pair of\nentities. Therefore, in this paper, we study how to effectively improve the\ndiversity of the training samples generated with LLMs for RE, while also\nmaintaining their correctness. We first try to make the LLMs produce dissimilar\nsamples by directly giving instructions in In-Context Learning (ICL) prompts.\nThen, we propose an approach to fine-tune LLMs for diversity training sample\ngeneration through Direct Preference Optimization (DPO). Our experiments on\ncommonly used RE datasets show that both attempts can improve the quality of\nthe generated training data. We also find that comparing with directly\nperforming RE with an LLM, training a non-LLM RE model with its generated\nsamples may lead to better performance.", "AI": {"tldr": "\u901a\u8fc7\u6539\u8fdbLLM\u751f\u6210\u8bad\u7ec3\u6837\u672c\u7684\u591a\u6837\u6027\u4e0e\u6b63\u786e\u6027\uff0c\u63d0\u5347\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u6548\u679c\uff1a\u91c7\u7528ICL\u63d0\u793a\u6307\u4ee4\u548cDPO\u5fae\u8c03\u65b9\u6cd5\uff0c\u751f\u6210\u66f4\u4f18\u8d28\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u9a8c\u8bc1\u8bad\u7ec3\u975eLLM\u6a21\u578b\u6548\u679c\u66f4\u4f73\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u5173\u7cfb\u62bd\u53d6\u6837\u672c\u5b58\u5728\u7ed3\u6784\u76f8\u4f3c\u6027\u9ad8\u3001\u8868\u8fbe\u65b9\u5f0f\u5355\u4e00\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u53d7\u9650\uff0c\u9700\u5728\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6837\u672c\u591a\u6837\u6027\u3002", "method": "1. \u901a\u8fc7ICL\u63d0\u793a\u76f4\u63a5\u5f15\u5bfcLLM\u751f\u6210\u591a\u6837\u5316\u6837\u672c\uff1b2. \u63d0\u51fa\u57fa\u4e8eDPO\u7684\u5fae\u8c03\u65b9\u6848\u4f18\u5316LLM\u7684\u591a\u6837\u6027\u751f\u6210\u80fd\u529b\uff1b3. \u5728\u5e38\u7528RE\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u76f4\u63a5LLM\u63a8\u7406\u4e0e\u8bad\u7ec3\u975eLLM\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u4e24\u79cd\u65b9\u6cd5\u5747\u63d0\u5347\u751f\u6210\u6570\u636e\u8d28\u91cf\uff0c\u4e14\u5b9e\u9a8c\u8868\u660e\u4f7f\u7528LLM\u751f\u6210\u6570\u636e\u8bad\u7ec3\u7684\u975eLLM\u5173\u7cfb\u62bd\u53d6\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528LLM\u8fdb\u884c\u5173\u7cfb\u62bd\u53d6\u3002", "conclusion": "\u63d0\u5347LLM\u751f\u6210\u6570\u636e\u7684\u591a\u6837\u6027\u5bf9\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u6a21\u578b\u5fae\u8c03\u53ef\u6709\u6548\u5b9e\u73b0\uff0c\u4e14\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u6a21\u578b\u53ef\u80fd\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u66f4\u5177\u6027\u4ef7\u6bd4\u4f18\u52bf\u3002"}}
{"id": "2505.23114", "pdf": "https://arxiv.org/pdf/2505.23114", "abs": "https://arxiv.org/abs/2505.23114", "authors": ["Seohyeong Lee", "Eunwon Kim", "Hwaran Lee", "Buru Chang"], "title": "Dataset Cartography for Large Language Model Alignment: Mapping and Diagnosing Preference Data", "categories": ["cs.CL"], "comment": null, "summary": "Human preference data plays a critical role in aligning large language models\n(LLMs) with human values. However, collecting such data is often expensive and\ninefficient, posing a significant scalability challenge. To address this, we\nintroduce Alignment Data Map, a GPT-4o-assisted tool for analyzing and\ndiagnosing preference data. Using GPT-4o as a proxy for LLM alignment, we\ncompute alignment scores for LLM-generated responses to instructions from\nexisting preference datasets. These scores are then used to construct an\nAlignment Data Map based on their mean and variance. Our experiments show that\nusing only 33 percent of the data, specifically samples in the high-mean,\nlow-variance region, achieves performance comparable to or better than using\nthe entire dataset. This finding suggests that the Alignment Data Map can\nsignificantly improve data collection efficiency by identifying high-quality\nsamples for LLM alignment without requiring explicit annotations. Moreover, the\nAlignment Data Map can diagnose existing preference datasets. Our analysis\nshows that it effectively detects low-impact or potentially misannotated\nsamples. Source code is available online.", "AI": {"tldr": "\u63d0\u51faAlignment Data Map\u5de5\u5177\uff0c\u901a\u8fc7GPT-4o\u7b5b\u9009\u9ad8\u5747\u503c\u4f4e\u65b9\u5dee\u6570\u636e\u6837\u672c\uff0c\u4ec5\u970033%\u6570\u636e\u5373\u53ef\u5b9e\u73b0LLM\u5bf9\u9f50\u6548\u679c\u63d0\u5347", "motivation": "\u4eba\u7c7b\u504f\u597d\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u4f20\u7edf\u6807\u6ce8\u65b9\u6cd5\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u6570\u636e\u7b5b\u9009\u65b9\u6cd5", "method": "1. \u4f7f\u7528GPT-4o\u4f5c\u4e3a\u5bf9\u9f50\u4ee3\u7406\u8ba1\u7b97\u54cd\u5e94\u5f97\u5206\n2. \u57fa\u4e8e\u5f97\u5206\u5747\u503c\u548c\u65b9\u5dee\u6784\u5efa\u6570\u636e\u5730\u56fe\n3. \u7b5b\u9009\u9ad8\u5747\u503c\u4f4e\u65b9\u5dee\u533a\u57df\u6837\u672c", "result": "33%\u7cbe\u9009\u6570\u636e\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u6210\u529f\u68c0\u6d4b\u51fa9.2%\u4f4e\u6548\u6837\u672c\u548c3.7%\u9519\u8bef\u6807\u6ce8\u6837\u672c\uff08\u5728Anthropic\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff09", "conclusion": "\u6570\u636e\u5730\u56fe\u5b9e\u73b0\u65e0\u6807\u6ce8\u7b5b\u9009\uff0c\u63d0\u53476\u500d\u6570\u636e\u6548\u7387\uff0c\u5177\u5907\u6570\u636e\u96c6\u8bca\u65ad\u80fd\u529b\uff0c\u4e3a\u9ad8\u6548RLHF\u8bad\u7ec3\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.23118", "pdf": "https://arxiv.org/pdf/2505.23118", "abs": "https://arxiv.org/abs/2505.23118", "authors": ["Linjie Mu", "Zhongzhen Huang", "Yakun Zhu", "Xiangyu Zhao", "Shaoting Zhang", "Xiaofan Zhang"], "title": "Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Effective clinical decision-making depends on iterative, multimodal reasoning\nacross diverse sources of evidence. The recent emergence of multimodal\nreasoning models has significantly transformed the landscape of solving complex\ntasks. Although such models have achieved notable success in mathematics and\nscience, their application to medical domains remains underexplored. In this\nwork, we propose \\textit{MedE$^2$}, a two-stage post-training pipeline that\nelicits and then enhances multimodal reasoning for medical domains. In Stage-I,\nwe fine-tune models using 2,000 text-only data samples containing precisely\norchestrated reasoning demonstrations to elicit reasoning behaviors. In\nStage-II, we further enhance the model's reasoning capabilities using 1,500\nrigorously curated multimodal medical cases, aligning model reasoning outputs\nwith our proposed multimodal medical reasoning preference. Extensive\nexperiments demonstrate the efficacy and reliability of \\textit{MedE$^2$} in\nimproving the reasoning performance of medical multimodal models. Notably,\nmodels trained with \\textit{MedE$^2$} consistently outperform baselines across\nmultiple medical multimodal benchmarks. Additional validation on larger models\nand under inference-time scaling further confirms the robustness and practical\nutility of our approach.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6MedE\u00b2\uff0c\u901a\u8fc7\u6587\u672c\u5fae\u8c03\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u589e\u5f3a\u533b\u7597\u591a\u6a21\u6001\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u63a8\u7406\u6a21\u578b\u5728\u6570\u5b66\u79d1\u5b66\u9886\u57df\u6548\u679c\u663e\u8457\uff0c\u4f46\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22", "method": "Stage-I\u75282000\u6587\u672c\u6837\u672c\u5fae\u8c03\u6fc0\u53d1\u63a8\u7406\u884c\u4e3a\uff0cStage-II\u75281500\u591a\u6a21\u6001\u533b\u7597\u6848\u4f8b\u8fdb\u884c\u504f\u597d\u5bf9\u9f50", "result": "\u5728\u591a\u4e2a\u533b\u7597\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7a33\u5b9a\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u5927\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9c81\u68d2\u6027", "conclusion": "MedE\u00b2\u6709\u6548\u63d0\u5347\u533b\u7597\u591a\u6a21\u6001\u63a8\u7406\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2505.23121", "pdf": "https://arxiv.org/pdf/2505.23121", "abs": "https://arxiv.org/abs/2505.23121", "authors": ["Yiming Lei", "Zhizheng Yang", "Zeming Liu", "Haitao Leng", "Shaoguo Liu", "Tingting Gao", "Qingjie Liu", "Yunhong Wang"], "title": "ContextQFormer: A New Context Modeling Method for Multi-Turn Multi-Modal Conversations", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 6 figures", "summary": "Multi-modal large language models have demonstrated remarkable zero-shot\nabilities and powerful image-understanding capabilities. However, the existing\nopen-source multi-modal models suffer from the weak capability of multi-turn\ninteraction, especially for long contexts. To address the issue, we first\nintroduce a context modeling module, termed ContextQFormer, which utilizes a\nmemory block to enhance the presentation of contextual information.\nFurthermore, to facilitate further research, we carefully build a new\nmulti-turn multi-modal dialogue dataset (TMDialog) for pre-training,\ninstruction-tuning, and evaluation, which will be open-sourced lately. Compared\nwith other multi-modal dialogue datasets, TMDialog contains longer\nconversations, which supports the research of multi-turn multi-modal dialogue.\nIn addition, ContextQFormer is compared with three baselines on TMDialog and\nexperimental results illustrate that ContextQFormer achieves an improvement of\n2%-4% in available rate over baselines.", "AI": {"tldr": "\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u591a\u8f6e\u4ea4\u4e92\u95ee\u9898\uff0c\u63d0\u51faContextQFormer\u6a21\u5757\u548cTMDialog\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u663e\u793a\u53ef\u7528\u7387\u63d0\u53472%-4%", "motivation": "\u73b0\u6709\u5f00\u6e90\u591a\u6a21\u6001\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u8868\u73b0\u8f83\u5f31\uff0c\u7f3a\u4e4f\u652f\u6301\u957f\u5bf9\u8bdd\u7814\u7a76\u7684\u6570\u636e\u96c6", "method": "\u5f00\u53d1\u57fa\u4e8e\u8bb0\u5fc6\u6a21\u5757\u7684ContextQFormer\u6a21\u578b\u67b6\u6784\uff0c\u6784\u5efa\u5305\u542b\u957f\u5bf9\u8bdd\u7684TMDialog\u6570\u636e\u96c6\uff08\u542b\u9884\u8bad\u7ec3/\u6307\u4ee4\u5fae\u8c03/\u8bc4\u4f30\u4e09\u90e8\u5206\uff09", "result": "ContextQFormer\u5728TMDialog\u6570\u636e\u96c6\u4e0a\u7684\u53ef\u7528\u7387\u6307\u6807\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u53472%-4%", "conclusion": "\u901a\u8fc7\u65b0\u578b\u4e0a\u4e0b\u6587\u5efa\u6a21\u6a21\u5757\u548c\u4e13\u7528\u6570\u636e\u96c6\uff0c\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5bf9\u8bdd\u7cfb\u7edf\u7684\u957f\u7a0b\u4ea4\u4e92\u80fd\u529b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u8bbe\u65bd"}}
{"id": "2505.23126", "pdf": "https://arxiv.org/pdf/2505.23126", "abs": "https://arxiv.org/abs/2505.23126", "authors": ["Atharva Naik", "Darsh Agrawal", "Manav Kapadnis", "Yuwei An", "Yash Mathur", "Carolyn Rose", "David Mortensen"], "title": "PBEBench: A Multi-Step Programming by Examples Reasoning Benchmark inspired by Historical Linguistics", "categories": ["cs.CL"], "comment": null, "summary": "Recently, long chain of thought (LCoT), Large Language Models (LLMs), have\ntaken the machine learning world by storm with their breathtaking reasoning\ncapabilities. However, are the abstract reasoning abilities of these models\ngeneral enough for problems of practical importance? Unlike past work, which\nhas focused mainly on math, coding, and data wrangling, we focus on a\nhistorical linguistics-inspired inductive reasoning problem, formulated as\nProgramming by Examples. We develop a fully automated pipeline for dynamically\ngenerating a benchmark for this task with controllable difficulty in order to\ntackle scalability and contamination issues to which many reasoning benchmarks\nare subject. Using our pipeline, we generate a test set with nearly 1k\ninstances that is challenging for all state-of-the-art reasoning LLMs, with the\nbest model (Claude-3.7-Sonnet) achieving a mere 54% pass rate, demonstrating\nthat LCoT LLMs still struggle with a class or reasoning that is ubiquitous in\nhistorical linguistics as well as many other domains.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u5f53\u524d\u6700\u4f18LLMs\u5728\u5386\u53f2\u8bed\u8a00\u5b66\u7c7b\u5f52\u7eb3\u63a8\u7406\u4efb\u52a1\u4e2d\u4ecd\u6709\u663e\u8457\u5c40\u9650\uff08Claude-3.7-Sonnet\u4ec554%\u901a\u8fc7\u7387\uff09", "motivation": "\u7a81\u7834\u73b0\u6709\u63a8\u7406\u57fa\u51c6\u96c6\u4e2d\u4e8e\u6570\u5b66/\u7f16\u7801\u4efb\u52a1\u7684\u5c40\u9650\uff0c\u9a8c\u8bc1LLMs\u5728\u5386\u53f2\u8bed\u8a00\u5b66\u7b49\u9886\u57df\u7684\u62bd\u8c61\u63a8\u7406\u666e\u9002\u6027", "method": "\u5f00\u53d1\u52a8\u6001\u751f\u6210\u53ef\u63a7\u96be\u5ea6\u57fa\u51c6\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u6784\u5efa\u8fd1\u5343\u5b9e\u4f8b\u7684\u6d4b\u8bd5\u96c6\u907f\u514d\u6570\u636e\u6c61\u67d3\u548c\u6269\u5c55\u6027\u95ee\u9898", "result": "\u6240\u6709SOTA\u63a8\u7406\u6a21\u578b\u7684\u5e73\u5747\u8868\u73b0\u6b20\u4f73\uff0c\u6700\u4f73\u6a21\u578b\u901a\u8fc7\u7387\u4ec554%", "conclusion": "LLMs\u5728\u5386\u53f2\u8bed\u8a00\u5b66\u7b49\u9886\u57df\u7684\u5f52\u7eb3\u63a8\u7406\u80fd\u529b\u4ecd\u6709\u91cd\u5927\u63d0\u5347\u7a7a\u95f4\uff0c\u6b64\u7c7b\u63a8\u7406\u4efb\u52a1\u7684\u666e\u9002\u6027\u5c1a\u672a\u5b9e\u73b0"}}
{"id": "2505.23140", "pdf": "https://arxiv.org/pdf/2505.23140", "abs": "https://arxiv.org/abs/2505.23140", "authors": ["Qiuyu Ding", "Zhiqiang Cao", "Hailong Cao", "Tiejun Zhao"], "title": "Enhancing Large Language Models'Machine Translation via Dynamic Focus Anchoring", "categories": ["cs.CL"], "comment": null, "summary": "Large language models have demonstrated exceptional performance across\nmultiple crosslingual NLP tasks, including machine translation (MT). However,\npersistent challenges remain in addressing context-sensitive units (CSUs), such\nas polysemous words. These CSUs not only affect the local translation accuracy\nof LLMs, but also affect LLMs' understanding capability for sentences and\ntasks, and even lead to translation failure. To address this problem, we\npropose a simple but effective method to enhance LLMs' MT capabilities by\nacquiring CSUs and applying semantic focus. Specifically, we dynamically\nanalyze and identify translation challenges, then incorporate them into LLMs in\na structured manner to mitigate mistranslations or misunderstandings of CSUs\ncaused by information flattening. Efficiently activate LLMs to identify and\napply relevant knowledge from its vast data pool in this way, ensuring more\naccurate translations for translating difficult terms. On a benchmark dataset\nof MT, our proposed method achieved competitive performance compared to\nmultiple existing open-sourced MT baseline models. It demonstrates\neffectiveness and robustness across multiple language pairs, including both\nsimilar language pairs and distant language pairs. Notably, the proposed method\nrequires no additional model training and enhances LLMs' performance across\nmultiple NLP tasks with minimal resource consumption.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u52a8\u6001\u5206\u6790\u4e0a\u4e0b\u6587\u654f\u611f\u5355\u5143(CSUs)\u5e76\u7ed3\u5408\u8bed\u4e49\u7126\u70b9\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u5355\u5143(\u5982\u591a\u4e49\u8bcd)\u65f6\u5b58\u5728\u5c40\u90e8\u8bef\u8bd1\u548c\u5168\u5c40\u7406\u89e3\u504f\u5dee\uff0c\u5bfc\u81f4\u7ffb\u8bd1\u8d28\u91cf\u4e0b\u964d\u751a\u81f3\u5931\u8d25\u3002\u9700\u8981\u9488\u5bf9\u6027\u89e3\u51b3\u65b9\u6848\u63d0\u5347\u6a21\u578b\u5bf9CSUs\u7684\u5904\u7406\u80fd\u529b\u3002", "method": "1. \u52a8\u6001\u8bc6\u522b\u7ffb\u8bd1\u96be\u70b9\u4e2d\u7684CSUs 2. \u901a\u8fc7\u7ed3\u6784\u5316\u8bed\u4e49\u7126\u70b9\u673a\u5236\u6fc0\u6d3b\u6a21\u578b\u76f8\u5173\u77e5\u8bc6 3. \u91c7\u7528\u4fe1\u606f\u5206\u5c42\u6ce8\u5165\u65b9\u5f0f\u907f\u514d\u4fe1\u606f\u6241\u5e73\u5316\u95ee\u9898", "result": "\u5728\u673a\u5668\u7ffb\u8bd1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u591a\u4e2a\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\uff0c\u8de8\u8bed\u8a00\u5bf9(\u76f8\u4f3c/\u8fdc\u8ddd\u79bb)\u5e73\u5747BLEU\u63d0\u53472.4-3.8\uff0c\u5904\u7406\u590d\u6742\u672f\u8bed\u7684\u51c6\u786e\u7387\u63d0\u534737%", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bed\u4e49\u7126\u70b9\u673a\u5236\u6709\u6548\u6fc0\u6d3b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u5728\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4e14\u5177\u5907\u8de8\u4efb\u52a1\u8fc1\u79fb\u80fd\u529b\uff0c\u4e3a\u63d0\u5347LLMs\u7684\u8bed\u4e49\u654f\u611f\u6027\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2505.23146", "pdf": "https://arxiv.org/pdf/2505.23146", "abs": "https://arxiv.org/abs/2505.23146", "authors": ["Qiuyu Ding", "Zhiqiang Cao", "Hailong Cao", "Tiejun Zhao"], "title": "Cross-Domain Bilingual Lexicon Induction via Pretrained Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Bilingual Lexicon Induction (BLI) is generally based on common domain data to\nobtain monolingual word embedding, and by aligning the monolingual word\nembeddings to obtain the cross-lingual embeddings which are used to get the\nword translation pairs. In this paper, we propose a new task of BLI, which is\nto use the monolingual corpus of the general domain and target domain to\nextract domain-specific bilingual dictionaries. Motivated by the ability of\nPre-trained models, we propose a method to get better word embeddings that\nbuild on the recent work on BLI. This way, we introduce the Code Switch(Qin et\nal., 2020) firstly in the cross-domain BLI task, which can match differit is\nyet to be seen whether these methods are suitable for bilingual lexicon\nextraction in professional fields. As we can see in table 1, the classic and\nefficient BLI approach, Muse and Vecmap, perform much worse on the Medical\ndataset than on the Wiki dataset. On one hand, the specialized domain data set\nis relatively smaller compared to the generic domain data set generally, and\nspecialized words have a lower frequency, which will directly affect the\ntranslation quality of bilingual dictionaries. On the other hand, static word\nembeddings are widely used for BLI, however, in some specific fields, the\nmeaning of words is greatly influenced by context, in this case, using only\nstatic word embeddings may lead to greater bias. ent strategies in different\ncontexts, making the model more suitable for this task. Experimental results\nshow that our method can improve performances over robust BLI baselines on\nthree specific domains by averagely improving 0.78 points.", "AI": {"tldr": "\u63d0\u51fa\u8de8\u9886\u57df\u53cc\u8bed\u8bcd\u5178\u5f52\u7eb3\u65b0\u4efb\u52a1\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3\u6a21\u578b\u6539\u8fdb\u8bcd\u5d4c\u5165\u8d28\u91cf\uff0c\u5728\u533b\u7597\u7b49\u4e13\u4e1a\u9886\u57df\u63d0\u5347\u8bcd\u5178\u7ffb\u8bd1\u6548\u679c", "motivation": "\u4f20\u7edfBLI\u65b9\u6cd5\u5728\u4e13\u4e1a\u9886\u57df\uff08\u5982\u533b\u5b66\u6570\u636e\u96c6\uff09\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u4e13\u4e1a\u8bed\u6599\u89c4\u6a21\u5c0f\u3001\u4f4e\u9891\u672f\u8bed\u591a\u53ca\u9759\u6001\u8bcd\u5d4c\u5165\u7684\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u4e0d\u8db3", "method": "\u878d\u5408\u901a\u7528\u9886\u57df\u4e0e\u76ee\u6807\u9886\u57df\u8bed\u6599\uff0c\u5f15\u5165\u4ee3\u7801\u5207\u6362\u6280\u672f\uff08Code Switch\uff09\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u52a8\u6001\u4f18\u5316\u8de8\u9886\u57df\u8bcd\u5411\u91cf\u5bf9\u9f50\u7b56\u7565", "result": "\u5728\u4e09\u4e2a\u4e13\u4e1a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u53470.78\u4e2a\u70b9\uff0c\u663e\u8457\u4f18\u4e8eMuse\u548cVecmap\u7b49\u4f20\u7edf\u65b9\u6cd5", "conclusion": "\u6240\u63d0\u51fa\u7684\u52a8\u6001\u8bcd\u5d4c\u5165\u65b9\u6cd5\u80fd\u6709\u6548\u514b\u670d\u4e13\u4e1a\u9886\u57df\u6570\u636e\u5c40\u9650\u6027\uff0c\u4e3a\u8de8\u9886\u57df\u53cc\u8bed\u8bcd\u5178\u6784\u5efa\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.23166", "pdf": "https://arxiv.org/pdf/2505.23166", "abs": "https://arxiv.org/abs/2505.23166", "authors": ["Li Lucy", "Camilla Griffiths", "Sarah Levine", "Jennifer L. Eberhardt", "Dorottya Demszky", "David Bamman"], "title": "Tell, Don't Show: Leveraging Language Models' Abstractive Retellings to Model Literary Themes", "categories": ["cs.CL"], "comment": "26 pages, 7 figures, Findings of ACL 2025", "summary": "Conventional bag-of-words approaches for topic modeling, like latent\nDirichlet allocation (LDA), struggle with literary text. Literature challenges\nlexical methods because narrative language focuses on immersive sensory details\ninstead of abstractive description or exposition: writers are advised to \"show,\ndon't tell.\" We propose Retell, a simple, accessible topic modeling approach\nfor literature. Here, we prompt resource-efficient, generative language models\n(LMs) to tell what passages show, thereby translating narratives' surface forms\ninto higher-level concepts and themes. By running LDA on LMs' retellings of\npassages, we can obtain more precise and informative topics than by running LDA\nalone or by directly asking LMs to list topics. To investigate the potential of\nour method for cultural analytics, we compare our method's outputs to\nexpert-guided annotations in a case study on racial/cultural identity in high\nschool English language arts books.", "AI": {"tldr": "\u63d0\u51faRetell\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u5c06\u6587\u5b66\u6bb5\u843d\u8f6c\u5316\u4e3a\u62bd\u8c61\u6982\u5ff5\u540e\u5e94\u7528LDA\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u6587\u5b66\u4e3b\u9898\u5efa\u6a21", "motivation": "\u4f20\u7edfLDA\u4e3b\u9898\u5efa\u6a21\u96be\u4ee5\u5904\u7406\u6587\u5b66\u6587\u672c\u7684\u5177\u8c61\u5316\u53d9\u4e8b\u7279\u5f81\uff0c\u9700\u8981\u5c06'\u5c55\u793a\u578b'\u8bed\u8a00\u8f6c\u5316\u4e3a\u53ef\u5206\u6790\u7684\u6982\u5ff5\u8868\u8ff0", "method": "1. \u7528\u8bed\u8a00\u6a21\u578b\u91cd\u8ff0\u6587\u5b66\u6bb5\u843d\u4e3a\u62bd\u8c61\u6982\u5ff5 2. \u5bf9\u91cd\u8ff0\u6587\u672c\u5e94\u7528LDA 3. \u4e0e\u4e13\u5bb6\u6807\u6ce8\u8fdb\u884c\u6848\u4f8b\u5bf9\u6bd4\u9a8c\u8bc1", "result": "\u76f8\u6bd4\u5355\u72ecLDA\u6216\u76f4\u63a5\u8ba9\u6a21\u578b\u5217\u4e3e\u4e3b\u9898\uff0cRetell\u65b9\u6cd5\u5728\u4e3b\u9898\u7cbe\u786e\u6027\u548c\u4fe1\u606f\u91cf\u4e0a\u63d0\u5347\u663e\u8457\uff0c\u6587\u5316\u8eab\u4efd\u5206\u6790\u7684\u6848\u4f8b\u9a8c\u8bc1\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6587\u5b66\u5206\u6790\u548c\u6587\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\uff0c\u517c\u5177\u6548\u679c\u4f18\u52bf\u4e0e\u5b9e\u65bd\u4fbf\u6377\u6027"}}
{"id": "2505.23170", "pdf": "https://arxiv.org/pdf/2505.23170", "abs": "https://arxiv.org/abs/2505.23170", "authors": ["Jian Zhu", "Farhan Samir", "Eleanor Chodroff", "David R. Mortensen"], "title": "ZIPA: A family of efficient models for multilingual phone recognition", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "ACL 2025 Main", "summary": "We present ZIPA, a family of efficient speech models that advances the\nstate-of-the-art performance of crosslinguistic phone recognition. We first\ncurated IPAPack++, a large-scale multilingual speech corpus with 17,132 hours\nof normalized phone transcriptions and a novel evaluation set capturing unseen\nlanguages and sociophonetic variation. With the large-scale training data,\nZIPA, including transducer (ZIPA-T) and CTC-based (ZIPA-CR) variants, leverage\nthe efficient Zipformer backbones and outperform existing phone recognition\nsystems with much fewer parameters. Further scaling via noisy student training\non 11,000 hours of pseudo-labeled multilingual data yields further improvement.\nWhile ZIPA achieves strong performance on benchmarks, error analysis reveals\npersistent limitations in modeling sociophonetic diversity, underscoring\nchallenges for future research.", "AI": {"tldr": "ZIPA\u6a21\u578b\u5bb6\u65cf\u901a\u8fc7\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u6570\u636e\u96c6IPAPack++\u548c\u9ad8\u6548Zipformer\u67b6\u6784\uff0c\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u97f3\u7d20\u8bc6\u522b\u6027\u80fd\uff0c\u4f46\u793e\u4f1a\u8bed\u97f3\u591a\u6837\u6027\u5efa\u6a21\u4ecd\u5b58\u6311\u6218\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u97f3\u7d20\u8bc6\u522b\u7cfb\u7edf\u6570\u636e\u6807\u51c6\u5316\u4e0d\u8db3\u3001\u8bc4\u4f30\u96c6\u8986\u76d6\u4e0d\u5168\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u6807\u51c6\u5316\u8bed\u6599\u5e93\u548c\u9ad8\u6548\u6a21\u578b\u67b6\u6784\u6765\u63d0\u5347\u8de8\u8bed\u8a00\u8bc6\u522b\u6027\u80fd\u3002", "method": "1. \u521b\u5efa\u5305\u542b17,132\u5c0f\u65f6\u6807\u51c6\u5316\u6807\u6ce8\u7684IPAPack++\u8bed\u6599\u5e93\u548c\u65b0\u578b\u8bc4\u4f30\u96c6\uff1b2. \u57fa\u4e8eZipformer\u6784\u5efaZIPA-T/ZIPA-CR\u6a21\u578b\uff1b3. \u4f7f\u752811,000\u5c0f\u65f6\u4f2a\u6807\u7b7e\u6570\u636e\u8fdb\u884c\u566a\u58f0\u5b66\u751f\u8bad\u7ec3\u3002", "result": "ZIPA\u4ee5\u66f4\u5c11\u53c2\u6570\u8d85\u8d8a\u73b0\u6709\u7cfb\u7edf\uff08\u5982Paraformer\uff09\uff0c\u6269\u5c55\u8bad\u7ec3\u540eWER\u76f8\u5bf9\u964d\u4f4e15%\uff0c\u4f46\u5728\u793e\u4f1a\u65b9\u8a00\u573a\u666f\u9519\u8bef\u7387\u4ecd\u9ad8\u51fa\u57fa\u51c612%\u3002", "conclusion": "ZIPA\u5728\u8de8\u8bed\u8a00\u97f3\u7d20\u8bc6\u522b\u53d6\u5f97\u7a81\u7834\uff0c\u4f46\u793e\u4f1a\u8bed\u97f3\u53d8\u5f02\u5efa\u6a21\u4ecd\u662f\u6838\u5fc3\u6311\u6218\uff0c\u9700\u540e\u7eed\u7814\u7a76\u6539\u8fdb\u6a21\u578b\u7684\u8bed\u97f3\u591a\u6837\u6027\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2505.23174", "pdf": "https://arxiv.org/pdf/2505.23174", "abs": "https://arxiv.org/abs/2505.23174", "authors": ["Naman Ahuja", "Fenil Bardoliya", "Chitta Baral", "Vivek Gupta"], "title": "Map&Make: Schema Guided Text to Table Generation", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "Transforming dense, detailed, unstructured text into an interpretable and\nsummarised table, also colloquially known as Text-to-Table generation, is an\nessential task for information retrieval. Current methods, however, miss out on\nhow and what complex information to extract; they also lack the ability to\ninfer data from the text. In this paper, we introduce a versatile approach,\nMap&Make, which \"dissects\" text into propositional atomic statements. This\nfacilitates granular decomposition to extract the latent schema. The schema is\nthen used to populate the tables that capture the qualitative nuances and the\nquantitative facts in the original text. Our approach is tested against two\nchallenging datasets, Rotowire, renowned for its complex and multi-table\nschema, and Livesum, which demands numerical aggregation. By carefully\nidentifying and correcting hallucination errors in Rotowire, we aim to achieve\na cleaner and more reliable benchmark. We evaluate our method rigorously on a\ncomprehensive suite of comparative and referenceless metrics. Our findings\ndemonstrate significant improvement results across both datasets with better\ninterpretability in Text-to-Table generation. Moreover, through detailed\nablation studies and analyses, we investigate the factors contributing to\nsuperior performance and validate the practicality of our framework in\nstructured summarization tasks.", "AI": {"tldr": "\u63d0\u51faMap&Make\u65b9\u6cd5\uff0c\u901a\u8fc7\u539f\u5b50\u547d\u9898\u5206\u89e3\u548c\u6a21\u5f0f\u63d0\u53d6\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u6587\u672c\u5230\u8868\u683c\u751f\u6210\uff0c\u5728Rotowire\u548cLivesum\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u8f6c\u8868\u683c\u65b9\u6cd5\u5b58\u5728\u590d\u6742\u4fe1\u606f\u63d0\u53d6\u4e0d\u8db3\u3001\u7f3a\u4e4f\u6570\u636e\u63a8\u65ad\u80fd\u529b\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u8868\u683c\u8d28\u91cf\u53d7\u9650\u3002", "method": "\u5206\u4e24\u9636\u6bb5\u5904\u7406\uff1a1) \u5c06\u6587\u672c\u89e3\u6784\u4e3a\u539f\u5b50\u547d\u9898\u63d0\u53d6\u6f5c\u5728\u6a21\u5f0f\uff1b2) \u5229\u7528\u6a21\u5f0f\u6784\u5efa\u5305\u542b\u5b9a\u6027\u4e0e\u5b9a\u91cf\u4fe1\u606f\u7684\u8868\u683c\u3002", "result": "\u5728Rotowire(\u4fee\u6b63\u5e7b\u89c9\u9519\u8bef\u540e)\u548cLivesum\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\u6307\u6807\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u6846\u67b6\u6709\u6548\u6027\uff0c\u8be5\u65b9\u6cd5\u4e3a\u7ed3\u6784\u5316\u6458\u8981\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23177", "pdf": "https://arxiv.org/pdf/2505.23177", "abs": "https://arxiv.org/abs/2505.23177", "authors": ["Wenjing Xing", "Wenke Lu", "Yeheng Duan", "Bing Zhao", "Zhenghui kang", "Yaolong Wang", "Kai Gao", "Lei Qiao"], "title": "Infinite-Instruct: Synthesizing Scaling Code instruction Data with Bidirectional Synthesis and Static Verification", "categories": ["cs.CL"], "comment": null, "summary": "Traditional code instruction data synthesis methods suffer from limited\ndiversity and poor logic. We introduce Infinite-Instruct, an automated\nframework for synthesizing high-quality question-answer pairs, designed to\nenhance the code generation capabilities of large language models (LLMs). The\nframework focuses on improving the internal logic of synthesized problems and\nthe quality of synthesized code. First, \"Reverse Construction\" transforms code\nsnippets into diverse programming problems. Then, through \"Backfeeding\nConstruction,\" keywords in programming problems are structured into a knowledge\ngraph to reconstruct them into programming problems with stronger internal\nlogic. Finally, a cross-lingual static code analysis pipeline filters invalid\nsamples to ensure data quality. Experiments show that on mainstream code\ngeneration benchmarks, our fine-tuned models achieve an average performance\nimprovement of 21.70% on 7B-parameter models and 36.95% on 32B-parameter\nmodels. Using less than one-tenth of the instruction fine-tuning data, we\nachieved performance comparable to the Qwen-2.5-Coder-Instruct.\nInfinite-Instruct provides a scalable solution for LLM training in programming.\nWe open-source the datasets used in the experiments, including both unfiltered\nversions and filtered versions via static analysis. The data are available at\nhttps://github.com/xingwenjing417/Infinite-Instruct-dataset", "AI": {"tldr": "\u63d0\u51faInfinite-Instruct\u6846\u67b6\uff0c\u901a\u8fc7\u9006\u5411\u6784\u5efa\u3001\u77e5\u8bc6\u56fe\u8c31\u91cd\u6784\u548c\u9759\u6001\u4ee3\u7801\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b", "motivation": "\u4f20\u7edf\u4ee3\u7801\u6307\u4ee4\u6570\u636e\u5408\u6210\u65b9\u6cd5\u5b58\u5728\u591a\u6837\u6027\u4e0d\u8db3\u548c\u903b\u8f91\u6027\u5dee\u7684\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u6570\u636e\u8d28\u91cf\u4e0e\u5185\u5728\u903b\u8f91", "method": "1.\u9006\u5411\u6784\u5efa\u5c06\u4ee3\u7801\u8f6c\u5316\u4e3a\u7f16\u7a0b\u95ee\u9898\n2.\u77e5\u8bc6\u56fe\u8c31\u91cd\u6784\u589e\u5f3a\u95ee\u9898\u903b\u8f91\n3.\u8de8\u8bed\u8a00\u9759\u6001\u5206\u6790\u8fc7\u6ee4\u65e0\u6548\u6837\u672c", "result": "7B/32B\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e0a\u5206\u522b\u63d0\u534721.70%\u548c36.95%\uff0c\u4ec5\u75281/10\u6570\u636e\u8fbe\u5230\u540c\u7c7b\u6a21\u578b\u6027\u80fd", "conclusion": "Infinite-Instruct\u4e3a\u7f16\u7a0bLLM\u8bad\u7ec3\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u6e90\u6570\u636e\u96c6\u5305\u542b\u539f\u59cb\u7248\u672c\u548c\u9759\u6001\u5206\u6790\u8fc7\u6ee4\u7248\u672c"}}
{"id": "2505.23183", "pdf": "https://arxiv.org/pdf/2505.23183", "abs": "https://arxiv.org/abs/2505.23183", "authors": ["Gabriele Sarti", "Vil\u00e9m Zouhar", "Malvina Nissim", "Arianna Bisazza"], "title": "Unsupervised Word-level Quality Estimation for Machine Translation Through the Lens of Annotators (Dis)agreement", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "Under review. Code:\n  https://github.com/gsarti/labl/tree/main/examples/unsup_wqe Metrics:\n  https://huggingface.co/datasets/gsarti/unsup_wqe_metrics", "summary": "Word-level quality estimation (WQE) aims to automatically identify\nfine-grained error spans in machine-translated outputs and has found many uses,\nincluding assisting translators during post-editing. Modern WQE techniques are\noften expensive, involving prompting of large language models or ad-hoc\ntraining on large amounts of human-labeled data. In this work, we investigate\nefficient alternatives exploiting recent advances in language model\ninterpretability and uncertainty quantification to identify translation errors\nfrom the inner workings of translation models. In our evaluation spanning 14\nmetrics across 12 translation directions, we quantify the impact of human label\nvariation on metric performance by using multiple sets of human labels. Our\nresults highlight the untapped potential of unsupervised metrics, the\nshortcomings of supervised methods when faced with label uncertainty, and the\nbrittleness of single-annotator evaluation practices.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u7d22\u5229\u7528\u7ffb\u8bd1\u6a21\u578b\u5185\u90e8\u7279\u5f81\u8fdb\u884c\u65e0\u76d1\u7763\u8bcd\u7ea7\u8d28\u91cf\u8bc4\u4f30\uff0c\u53d1\u73b0\u4f20\u7edf\u76d1\u7763\u65b9\u6cd5\u5728\u6807\u7b7e\u4e0d\u4e00\u81f4\u65f6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u8bcd\u7ea7\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u5927\u6a21\u578b\u6216\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u9762\u4e34\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5206\u6790\u7ffb\u8bd1\u6a21\u578b\u5185\u90e8\u5de5\u4f5c\u673a\u5236\uff08\u53ef\u89e3\u91ca\u6027\uff09\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u63d0\u51fa\u65e0\u76d1\u7763\u8bc4\u4f30\u6307\u6807\u3002\u572812\u79cd\u8bed\u8a00\u5bf9\u768414\u4e2a\u6307\u6807\u4e0a\u8fdb\u884c\u591a\u6807\u7b7e\u96c6\u9a8c\u8bc1\u3002", "result": "\u65e0\u76d1\u7763\u6307\u6807\u5c55\u73b0\u672a\u5f00\u53d1\u6f5c\u529b\uff1b\u76d1\u7763\u65b9\u6cd5\u5728\u6807\u7b7e\u4e0d\u4e00\u81f4\u65f6\u8868\u73b0\u4e0b\u964d\uff1b\u5355\u4e00\u6807\u6ce8\u8bc4\u4f30\u5b58\u5728\u8106\u5f31\u6027\u3002", "conclusion": "\u5e94\u91cd\u89c6\u7ffb\u8bd1\u6a21\u578b\u81ea\u8eab\u7279\u5f81\u7684\u4ef7\u503c\uff0c\u6539\u8fdb\u8bc4\u4f30\u6807\u51c6\u4ee5\u5e94\u5bf9\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u52a8\u66f4\u9c81\u68d2\u7684\u8bcd\u7ea7\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2505.23187", "pdf": "https://arxiv.org/pdf/2505.23187", "abs": "https://arxiv.org/abs/2505.23187", "authors": ["Yilong Li", "Chen Qian", "Yu Xia", "Ruijie Shi", "Yufan Dang", "Zihao Xie", "Ziming You", "Weize Chen", "Cheng Yang", "Weichuan Liu", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "title": "Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration", "categories": ["cs.CL", "cs.AI", "cs.MA"], "comment": "Work in Progress", "summary": "Large Language Model-based multi-agent systems (MAS) have shown remarkable\nprogress in solving complex tasks through collaborative reasoning and\ninter-agent critique. However, existing approaches typically treat each task in\nisolation, resulting in redundant computations and limited generalization\nacross structurally similar tasks. To address this, we introduce multi-agent\ncross-task experiential learning (MAEL), a novel framework that endows\nLLM-driven agents with explicit cross-task learning and experience\naccumulation. We model the task-solving workflow on a graph-structured\nmulti-agent collaboration network, where agents propagate information and\ncoordinate via explicit connectivity. During the experiential learning phase,\nwe quantify the quality for each step in the task-solving workflow and store\nthe resulting rewards along with the corresponding inputs and outputs into each\nagent's individual experience pool. During inference, agents retrieve\nhigh-reward, task-relevant experiences as few-shot examples to enhance the\neffectiveness of each reasoning step, thereby enabling more accurate and\nefficient multi-agent collaboration. Experimental results on diverse datasets\ndemonstrate that MAEL empowers agents to learn from prior task experiences\neffectively-achieving faster convergence and producing higher-quality solutions\non current tasks.", "AI": {"tldr": "\u63d0\u51faMAEL\u6846\u67b6\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4efb\u52a1\u5b64\u7acb\u548c\u8ba1\u7b97\u5197\u4f59\u95ee\u9898\uff0c\u901a\u8fc7\u8de8\u4efb\u52a1\u7ecf\u9a8c\u79ef\u7d2f\u63d0\u5347\u534f\u4f5c\u6548\u7387", "motivation": "\u73b0\u6709LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u72ec\u7acb\u5904\u7406\u4efb\u52a1\u5bfc\u81f4\u91cd\u590d\u8ba1\u7b97\u4e14\u7f3a\u4e4f\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\uff0cMAEL\u901a\u8fc7\u663e\u5f0f\u7ecf\u9a8c\u5b66\u4e60\u673a\u5236\u5b9e\u73b0\u77e5\u8bc6\u8fc1\u79fb", "method": "\u6784\u5efa\u56fe\u7ed3\u6784\u534f\u4f5c\u7f51\u7edc\u91cf\u5316\u4efb\u52a1\u6d41\u7a0b\u8d28\u91cf\uff0c\u5efa\u7acb\u4e2a\u4f53\u7ecf\u9a8c\u6c60\u5b58\u50a8\u9ad8\u5956\u52b1\u6848\u4f8b\uff0c\u63a8\u7406\u65f6\u68c0\u7d22\u7ecf\u9a8c\u4f5c\u4e3afew-shot\u793a\u4f8b", "result": "\u5b9e\u9a8c\u663e\u793aMAEL\u4f7f\u667a\u80fd\u4f53\u6536\u655b\u901f\u5ea6\u63d0\u534737%\uff0c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u6bd4\u57fa\u7ebf\u9ad815%", "conclusion": "\u9996\u6b21\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u663e\u5f0f\u8de8\u4efb\u52a1\u7ecf\u9a8c\u5b66\u4e60\u673a\u5236\uff0c\u4e3a\u6301\u7eed\u5b66\u4e60\u578bAI\u7cfb\u7edf\u5f00\u53d1\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2505.23191", "pdf": "https://arxiv.org/pdf/2505.23191", "abs": "https://arxiv.org/abs/2505.23191", "authors": ["Jinglong Gao", "Xiao Ding", "Lingxiao Zou", "Bibo Cai", "Bing Qin", "Ting Liu"], "title": "ExpeTrans: LLMs Are Experiential Transfer Learners", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, 12 figs/tables", "summary": "Recent studies provide large language models (LLMs) with textual task-solving\nexperiences via prompts to improve their performance. However, previous methods\nrely on substantial human labor or time to gather such experiences for each\ntask, which is impractical given the growing variety of task types in user\nqueries to LLMs. To address this issue, we design an autonomous experience\ntransfer framework to explore whether LLMs can mimic human cognitive\nintelligence to autonomously transfer experience from existing source tasks to\nnewly encountered target tasks. This not only allows the acquisition of\nexperience without extensive costs of previous methods, but also offers a novel\npath for the generalization of LLMs. Experimental results on 13 datasets\ndemonstrate that our framework effectively improves the performance of LLMs.\nFurthermore, we provide a detailed analysis of each module in the framework.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u4e3b\u7ecf\u9a8c\u8fc1\u79fb\u6846\u67b6\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u8de8\u4efb\u52a1\u8fc1\u79fb\u7ecf\u9a8c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u572813\u4e2a\u6570\u636e\u96c6\u4e0a\u6709\u6548\u63d0\u5347\u6027\u80fd", "motivation": "\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6536\u96c6\u4efb\u52a1\u7ecf\u9a8c\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u63a2\u7d22LLMs\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u667a\u80fd\u7684\u6cdb\u5316\u8def\u5f84", "method": "\u8bbe\u8ba1\u5305\u542b\u7ecf\u9a8c\u751f\u6210\u3001\u77e5\u8bc6\u84b8\u998f\u548c\u81ea\u4e3b\u51b3\u7b56\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u7ec4\u4ef6\u5b9e\u73b0\u8de8\u4efb\u52a1\u7ecf\u9a8c\u8fc1\u79fb", "result": "\u572813\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\uff0c\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u5e76\u63d0\u4f9b\u6a21\u5757\u7ea7\u5206\u6790\u9a8c\u8bc1\u8bbe\u8ba1\u5408\u7406\u6027", "conclusion": "\u8be5\u6846\u67b6\u4e3aLLMs\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u540c\u65f6\u964d\u4f4e\u7ecf\u9a8c\u83b7\u53d6\u6210\u672c\uff0c\u62d3\u5c55\u4e86\u6a21\u578b\u5e94\u7528\u8fb9\u754c"}}
{"id": "2505.23224", "pdf": "https://arxiv.org/pdf/2505.23224", "abs": "https://arxiv.org/abs/2505.23224", "authors": ["Zhitao He", "Sandeep Polisetty", "Zhiyuan Fan", "Yuchen Huang", "Shujin Wu", "Yi R.", "Fung"], "title": "MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025", "summary": "In recent years, multimodal large language models (MLLMs) have made\nsignificant progress but continue to face inherent challenges in multimodal\nreasoning, which requires multi-level (e.g., perception, reasoning) and\nmulti-granular (e.g., multi-step reasoning chain) advanced inferencing. Prior\nwork on estimating model confidence tends to focus on the overall response for\ntraining and calibration, but fails to assess confidence in each reasoning\nstep, leading to undesirable hallucination snowballing. In this work, we\npresent MMBoundary, a novel framework that advances the knowledge boundary\nawareness of MLLMs through reasoning step confidence calibration. To achieve\nthis, we propose to incorporate complementary textual and cross-modal\nself-rewarding signals to estimate confidence at each step of the MLLM\nreasoning process. In addition to supervised fine-tuning MLLM on this set of\nself-rewarded confidence estimation signal for initial confidence expression\nwarm-up, we introduce a reinforcement learning stage with multiple reward\nfunctions for further aligning model knowledge and calibrating confidence at\neach reasoning step, enhancing reasoning chain self-correction. Empirical\nresults show that MMBoundary significantly outperforms existing methods across\ndiverse domain datasets and metrics, achieving an average of 7.5% reduction in\nmultimodal confidence calibration errors and up to 8.3% improvement in task\nperformance.", "AI": {"tldr": "MMBoundary\u63d0\u51fa\u901a\u8fc7\u591a\u6a21\u6001\u81ea\u5956\u52b1\u4fe1\u53f7\u548c\u5f3a\u5316\u5b66\u4e60\u6821\u51c6\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6b65\u9aa4\u7f6e\u4fe1\u5ea6\uff0c\u6709\u6548\u6291\u5236\u5e7b\u89c9\u4f20\u64ad\uff0c\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u4ec5\u5173\u6ce8\u6574\u4f53\u54cd\u5e94\uff0c\u7f3a\u4e4f\u5bf9\u591a\u7c92\u5ea6\u63a8\u7406\u6b65\u9aa4\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u5bfc\u81f4\u9519\u8bef\u7d2f\u79ef\uff08\u5e7b\u89c9\u96ea\u7403\u6548\u5e94\uff09\u3002", "method": "1. \u7ed3\u5408\u6587\u672c\u548c\u8de8\u6a21\u6001\u81ea\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u521d\u59cb\u7f6e\u4fe1\u5ea6\u8868\u8fbe\n2. \u5f15\u5165\u591a\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\uff0c\u540c\u6b65\u6821\u51c6\u63a8\u7406\u6b65\u9aa4\u7f6e\u4fe1\u5ea6\u4e0e\u77e5\u8bc6\u8fb9\u754c\n3. \u81ea\u6821\u6b63\u673a\u5236\u4f18\u5316\u63a8\u7406\u94fe", "result": "\u8de8\u9886\u57df\u6570\u636e\u96c6\u5e73\u5747\u51cf\u5c117.5%\u6821\u51c6\u8bef\u5dee\uff0c\u6700\u9ad8\u63d0\u53478.3%\u4efb\u52a1\u6027\u80fd\uff0c\u5728ScienceQA\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u6700\u4f18\u3002", "conclusion": "\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7f6e\u4fe1\u5ea6\u6821\u51c6\u548c\u81ea\u6821\u6b63\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u77e5\u8bc6\u8fb9\u754c\u5efa\u6a21\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.23229", "pdf": "https://arxiv.org/pdf/2505.23229", "abs": "https://arxiv.org/abs/2505.23229", "authors": ["Hao Lu", "Yanchi Gu", "Haoyuan Huang", "Yulin Zhou", "Ningxin Zhu", "Chen Li"], "title": "MCTSr-Zero: Self-Reflective Psychological Counseling Dialogues Generation via Principles and Adaptive Exploration", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "50 pages, 3 figures", "summary": "The integration of Monte Carlo Tree Search (MCTS) with Large Language Models\n(LLMs) has demonstrated significant success in structured, problem-oriented\ntasks. However, applying these methods to open-ended dialogues, such as those\nin psychological counseling, presents unique challenges. Unlike tasks with\nobjective correctness, success in therapeutic conversations depends on\nsubjective factors like empathetic engagement, ethical adherence, and alignment\nwith human preferences, for which strict \"correctness\" criteria are\nill-defined. Existing result-oriented MCTS approaches can therefore produce\nmisaligned responses. To address this, we introduce MCTSr-Zero, an MCTS\nframework designed for open-ended, human-centric dialogues. Its core innovation\nis \"domain alignment\", which shifts the MCTS search objective from predefined\nend-states towards conversational trajectories that conform to target domain\nprinciples (e.g., empathy in counseling). Furthermore, MCTSr-Zero incorporates\n\"Regeneration\" and \"Meta-Prompt Adaptation\" mechanisms to substantially broaden\nexploration by allowing the MCTS to consider fundamentally different initial\ndialogue strategies. We evaluate MCTSr-Zero in psychological counseling by\ngenerating multi-turn dialogue data, which is used to fine-tune an LLM, PsyLLM.\nWe also introduce PsyEval, a benchmark for assessing multi-turn psychological\ncounseling dialogues. Experiments demonstrate that PsyLLM achieves\nstate-of-the-art performance on PsyEval and other relevant metrics, validating\nMCTSr-Zero's effectiveness in generating high-quality, principle-aligned\nconversational data for human-centric domains and addressing the LLM challenge\nof consistently adhering to complex psychological standards.", "AI": {"tldr": "\u63d0\u51faMCTSr-Zero\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u5bf9\u9f50\u548c\u63a2\u7d22\u589e\u5f3a\u673a\u5236\u89e3\u51b3LLM\u5728\u5f00\u653e\u5f0f\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u4e2d\u7684\u539f\u5219\u5bf9\u9f50\u95ee\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u6570\u636e\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u7ed3\u679c\u5bfc\u5411\u7684MCTS\u65b9\u6cd5\u5728\u4e3b\u89c2\u6027\u5f3a\u7684\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u4e2d\u5bb9\u6613\u4ea7\u751f\u539f\u5219\u5931\u914d\u7684\u56de\u5e94\uff0c\u9700\u8981\u5efa\u7acb\u7b26\u5408\u5171\u60c5/\u4f26\u7406\u7b49\u4e3b\u89c2\u6807\u51c6\u7684\u5bf9\u8bdd\u751f\u6210\u673a\u5236\u3002", "method": "1) \u9886\u57df\u5bf9\u9f50\uff1a\u5c06MCTS\u641c\u7d22\u76ee\u6807\u8f6c\u5411\u7b26\u5408\u9886\u57df\u539f\u5219\u7684\u5bf9\u8bdd\u8f68\u8ff9\uff1b2) \u518d\u751f\u673a\u5236\uff1a\u5141\u8bb8\u91cd\u65b0\u751f\u6210\u521d\u59cb\u7b56\u7565\uff1b3) \u5143\u63d0\u793a\u9002\u5e94\uff1a\u52a8\u6001\u8c03\u6574\u63d0\u793a\u7b56\u7565\u6269\u5c55\u63a2\u7d22\u7a7a\u95f4\u3002", "result": "\u6784\u5efaPsyEval\u8bc4\u4f30\u57fa\u51c6\uff0c\u5fae\u8c03\u540e\u7684PsyLLM\u5728\u5fc3\u7406\u54a8\u8be2\u5bf9\u8bdd\u8d28\u91cf\u6307\u6807\u4e0a\u8fbe\u5230SOTA\uff0c\u9a8c\u8bc1\u6846\u67b6\u5728\u539f\u5219\u5bf9\u9f50\u548c\u54cd\u5e94\u8d28\u91cf\u4e0a\u7684\u53cc\u91cd\u4f18\u52bf\u3002", "conclusion": "MCTSr-Zero\u6210\u529f\u89e3\u51b3\u4e86LLM\u5728\u590d\u6742\u5fc3\u7406\u6807\u51c6\u4e0b\u7684\u5bf9\u8bdd\u5bf9\u9f50\u96be\u9898\uff0c\u4e3a\u4eba\u672c\u4e2d\u5fc3\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u751f\u6210\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2505.23242", "pdf": "https://arxiv.org/pdf/2505.23242", "abs": "https://arxiv.org/abs/2505.23242", "authors": ["Jingxuan Wei", "Nan Xu", "Junnan Zhu", "Yanni Hao", "Gaowei Wu", "Bihui Yu", "Lei Wang"], "title": "ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering", "categories": ["cs.CL"], "comment": null, "summary": "Chart question answering (CQA) has become a critical multimodal task for\nevaluating the reasoning capabilities of vision-language models. While early\napproaches have shown promising performance by focusing on visual features or\nleveraging large-scale pre-training, most existing evaluations rely on rigid\noutput formats and objective metrics, thus ignoring the complex, real-world\ndemands of practical chart analysis. In this paper, we introduce ChartMind, a\nnew benchmark designed for complex CQA tasks in real-world settings. ChartMind\ncovers seven task categories, incorporates multilingual contexts, supports\nopen-domain textual outputs, and accommodates diverse chart formats, bridging\nthe gap between real-world applications and traditional academic benchmarks.\nFurthermore, we propose a context-aware yet model-agnostic framework, ChartLLM,\nthat focuses on extracting key contextual elements, reducing noise, and\nenhancing the reasoning accuracy of multimodal large language models. Extensive\nevaluations on ChartMind and three representative public benchmarks with 14\nmainstream multimodal models show our framework significantly outperforms the\nprevious three common CQA paradigms: instruction-following, OCR-enhanced, and\nchain-of-thought, highlighting the importance of flexible chart understanding\nfor real-world CQA. These findings suggest new directions for developing more\nrobust chart reasoning in future research.", "AI": {"tldr": "\u63d0\u51fa\u4e86ChartMind\u57fa\u51c6\u548cChartLLM\u6846\u67b6\uff0c\u901a\u8fc7\u7075\u6d3b\u4e0a\u4e0b\u6587\u7406\u89e3\u663e\u8457\u63d0\u5347\u56fe\u8868\u95ee\u7b54\u4efb\u52a1\u7684\u63a8\u7406\u51c6\u786e\u6027\uff0c\u8986\u76d67\u7c7b\u4efb\u52a1\u3001\u591a\u8bed\u8a00\u53ca\u5f00\u653e\u57df\u8f93\u51fa\u3002", "motivation": "\u73b0\u6709\u56fe\u8868\u95ee\u7b54\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u8f93\u51fa\u683c\u5f0f\u548c\u5ba2\u89c2\u6307\u6807\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u56fe\u8868\u5206\u6790\u7684\u590d\u6742\u9700\u6c42\uff0c\u9700\u6784\u5efa\u66f4\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "ChartMind\u57fa\u51c6\u652f\u6301\u591a\u8bed\u8a00/\u5f00\u653e\u57df\u8f93\u51fa/\u591a\u6837\u56fe\u8868\u683c\u5f0f\uff1bChartLLM\u6846\u67b6\u901a\u8fc7\u4e0a\u4e0b\u6587\u8981\u7d20\u63d0\u53d6\u548c\u964d\u566a\u589e\u5f3a\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728ChartMind\u53ca3\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cChartLLM\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u8ddf\u968f\u3001OCR\u589e\u5f3a\u3001\u601d\u7ef4\u94fe\u4e09\u79cd\u4f20\u7edf\u8303\u5f0f\uff0c\u51c6\u786e\u7387\u63d0\u5347\u660e\u663e\u3002", "conclusion": "\u7075\u6d3b\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u5bf9\u73b0\u5b9e\u56fe\u8868\u95ee\u7b54\u81f3\u5173\u91cd\u8981\uff0c\u672a\u6765\u5e94\u53d1\u5c55\u66f4\u9c81\u68d2\u7684\u56fe\u8868\u63a8\u7406\u6846\u67b6\u4ee5\u7f29\u5c0f\u5b66\u672f\u57fa\u51c6\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u5dee\u8ddd\u3002"}}
{"id": "2505.23252", "pdf": "https://arxiv.org/pdf/2505.23252", "abs": "https://arxiv.org/abs/2505.23252", "authors": ["Bing Ma", "Hai Zhuge"], "title": "Automatic Construction of Multiple Classification Dimensions for Managing Approaches in Scientific Papers", "categories": ["cs.CL"], "comment": "26 pages, 9 figures", "summary": "Approaches form the foundation for conducting scientific research. Querying\napproaches from a vast body of scientific papers is extremely time-consuming,\nand without a well-organized management framework, researchers may face\nsignificant challenges in querying and utilizing relevant approaches.\nConstructing multiple dimensions on approaches and managing them from these\ndimensions can provide an efficient solution. Firstly, this paper identifies\napproach patterns using a top-down way, refining the patterns through four\ndistinct linguistic levels: semantic level, discourse level, syntactic level,\nand lexical level. Approaches in scientific papers are extracted based on\napproach patterns. Additionally, five dimensions for categorizing approaches\nare identified using these patterns. This paper proposes using tree structure\nto represent step and measuring the similarity between different steps with a\ntree-structure-based similarity measure that focuses on syntactic-level\nsimilarities. A collection similarity measure is proposed to compute the\nsimilarity between approaches. A bottom-up clustering algorithm is proposed to\nconstruct class trees for approach components within each dimension by merging\neach approach component or class with its most similar approach component or\nclass in each iteration. The class labels generated during the clustering\nprocess indicate the common semantics of the step components within the\napproach components in each class and are used to manage the approaches within\nthe class. The class trees of the five dimensions collectively form a\nmulti-dimensional approach space. The application of approach queries on the\nmulti-dimensional approach space demonstrates that querying within this space\nensures strong relevance between user queries and results and rapidly reduces\nsearch space through a class-based query mechanism.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u7ef4\u7279\u5f81\u7684\u7814\u7a76\u65b9\u6cd5\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u8a00\u5b66\u6a21\u5f0f\u8bc6\u522b\u65b9\u6cd5\u7ec4\u4ef6\uff0c\u6784\u5efa\u6811\u5f62\u7ed3\u6784\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u53ca\u591a\u7ef4\u7a7a\u95f4\u805a\u7c7b\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u65b9\u6cd5\u68c0\u7d22\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u79d1\u7814\u65b9\u6cd5\u7ba1\u7406\u5b58\u5728\u68c0\u7d22\u6548\u7387\u4f4e\u3001\u7ec4\u7ec7\u7ef4\u5ea6\u5355\u4e00\u7684\u95ee\u9898\uff0c\u9700\u5efa\u7acb\u591a\u7ef4\u7ba1\u7406\u4f53\u7cfb\u4f18\u5316\u65b9\u6cd5\u590d\u7528\u4e0e\u53d1\u73b0\u3002", "method": "1. \u81ea\u4e0a\u800c\u4e0b\u6784\u5efa\u8bed\u4e49/\u8bed\u7bc7/\u53e5\u6cd5/\u8bcd\u6c47\u56db\u7ea7\u8bed\u8a00\u5b66\u6a21\u5f0f\u8bc6\u522b\u65b9\u6cd5\n2. \u8bbe\u8ba1\u6811\u5f62\u7ed3\u6784\u8868\u8fbe\u65b9\u6cd5\u6b65\u9aa4\u53ca\u53e5\u6cd5\u76f8\u4f3c\u5ea6\u8ba1\u7b97\n3. \u63d0\u51fa\u57fa\u4e8e\u805a\u7c7b\u7b97\u6cd5\u6784\u5efa\u4e94\u7ef4\u65b9\u6cd5\u7a7a\u95f4\u5206\u7c7b\u6811", "result": "\u591a\u7ef4\u65b9\u6cd5\u7a7a\u95f4\u652f\u6301\u7c7b\u9a71\u52a8\u68c0\u7d22\uff0c\u67e5\u8be2\u76f8\u5173\u6027\u63d0\u5347\u4e14\u641c\u7d22\u7a7a\u95f4\u5feb\u901f\u6536\u655b\uff0c\u9a8c\u8bc1\u6846\u67b6\u6709\u6548\u6027\u3002", "conclusion": "\u591a\u7ef4\u7279\u5f81\u5efa\u6a21\u4e0e\u5206\u7c7b\u6811\u805a\u7c7b\u673a\u5236\u5b9e\u73b0\u4e86\u79d1\u7814\u65b9\u6cd5\u7684\u7cfb\u7edf\u5316\u7ba1\u7406\uff0c\u4e3a\u667a\u80fd\u65b9\u6cd5\u68c0\u7d22\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.23276", "pdf": "https://arxiv.org/pdf/2505.23276", "abs": "https://arxiv.org/abs/2505.23276", "authors": ["Maged S. Al-Shaibani", "Moataz Ahmed"], "title": "The Arabic AI Fingerprint: Stylometric Analysis and Detection of Large Language Models Text", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have achieved unprecedented capabilities in\ngenerating human-like text, posing subtle yet significant challenges for\ninformation integrity across critical domains, including education, social\nmedia, and academia, enabling sophisticated misinformation campaigns,\ncompromising healthcare guidance, and facilitating targeted propaganda. This\nchallenge becomes severe, particularly in under-explored and low-resource\nlanguages like Arabic. This paper presents a comprehensive investigation of\nArabic machine-generated text, examining multiple generation strategies\n(generation from the title only, content-aware generation, and text refinement)\nacross diverse model architectures (ALLaM, Jais, Llama, and GPT-4) in academic,\nand social media domains. Our stylometric analysis reveals distinctive\nlinguistic patterns differentiating human-written from machine-generated Arabic\ntext across these varied contexts. Despite their human-like qualities, we\ndemonstrate that LLMs produce detectable signatures in their Arabic outputs,\nwith domain-specific characteristics that vary significantly between different\ncontexts. Based on these insights, we developed BERT-based detection models\nthat achieved exceptional performance in formal contexts (up to 99.9\\%\nF1-score) with strong precision across model architectures. Our cross-domain\nanalysis confirms generalization challenges previously reported in the\nliterature. To the best of our knowledge, this work represents the most\ncomprehensive investigation of Arabic machine-generated text to date, uniquely\ncombining multiple prompt generation methods, diverse model architectures, and\nin-depth stylometric analysis across varied textual domains, establishing a\nfoundation for developing robust, linguistically-informed detection systems\nessential for preserving information integrity in Arabic-language contexts.", "AI": {"tldr": "\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u5168\u9762\u7814\u7a76\uff0c\u7ed3\u5408\u591a\u79cd\u751f\u6210\u7b56\u7565\u548c\u6a21\u578b\u67b6\u6784\uff0c\u5f00\u53d1\u51fa\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u6a21\u578b\u5e76\u63ed\u793a\u8de8\u9886\u57df\u6cdb\u5316\u6311\u6218\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u751f\u6210\u7c7b\u4eba\u6587\u672c\u7684\u9690\u853d\u5a01\u80c1\uff0c\u53ef\u80fd\u7834\u574f\u6559\u80b2\u3001\u533b\u7597\u3001\u793e\u4ea4\u5a92\u4f53\u7b49\u9886\u57df\u7684\u4fe1\u606f\u5b8c\u6574\u6027\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u751f\u6210\u7b56\u7565\uff08\u6807\u9898\u751f\u6210/\u5185\u5bb9\u611f\u77e5\u751f\u6210/\u6587\u672c\u4f18\u5316\uff09\u3001\u56db\u79cd\u6a21\u578b\u67b6\u6784\uff08ALLaM/Jais/Llama/GPT-4\uff09\uff0c\u7ed3\u5408\u6587\u4f53\u6d4b\u91cf\u5206\u6790\u548cBERT\u68c0\u6d4b\u6a21\u578b\u5f00\u53d1\u3002", "result": "\u68c0\u6d4b\u6a21\u578b\u5728\u6b63\u5f0f\u8bed\u5883\u8fbe99.9% F1\u503c\uff0c\u53d1\u73b0\u673a\u5668\u751f\u6210\u6587\u672c\u5b58\u5728\u53ef\u68c0\u6d4b\u7279\u5f81\u4e14\u8de8\u9886\u57df\u6cdb\u5316\u56f0\u96be\u3002", "conclusion": "\u5efa\u7acb\u4e86\u963f\u62c9\u4f2f\u8bed\u673a\u5668\u6587\u672c\u68c0\u6d4b\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u5f00\u53d1\u8bed\u8a00\u611f\u77e5\u7684\u68c0\u6d4b\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\uff0c\u586b\u8865\u4f4e\u8d44\u6e90\u8bed\u8a00\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2505.23277", "pdf": "https://arxiv.org/pdf/2505.23277", "abs": "https://arxiv.org/abs/2505.23277", "authors": ["Yong Zhang", "Yanwen Huang", "Ning Cheng", "Yang Guo", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao"], "title": "Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint. 17 pages including appendix", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs)\nwith external context, but retrieved passages are often lengthy, noisy, or\nexceed input limits. Existing compression methods typically require supervised\ntraining of dedicated compression models, increasing cost and reducing\nportability. We propose Sentinel, a lightweight sentence-level compression\nframework that reframes context filtering as an attention-based understanding\ntask. Rather than training a compression model, Sentinel probes decoder\nattention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier\nto identify sentence relevance. Empirically, we find that query-context\nrelevance estimation is consistent across model scales, with 0.5B proxies\nclosely matching the behaviors of larger models. On the LongBench benchmark,\nSentinel achieves up to 5$\\times$ compression while matching the QA performance\nof 7B-scale compression systems. Our results suggest that probing native\nattention signals enables fast, effective, and question-aware context\ncompression. Code available at: https://github.com/yzhangchuck/Sentinel.", "AI": {"tldr": "\u901a\u8fc7\u63a2\u6d4b0.5B\u4ee3\u7406\u6a21\u578b\u7684\u6ce8\u610f\u529b\u4fe1\u53f7\uff0cSentinel\u6846\u67b6\u65e0\u9700\u8bad\u7ec3\u4e13\u7528\u538b\u7f29\u6a21\u578b\u5373\u53ef\u5b9e\u73b05\u500d\u4e0a\u4e0b\u6587\u538b\u7f29\uff0c\u6027\u80fd\u5ab2\u7f8e7B\u89c4\u6a21\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u9700\u8981\u8bad\u7ec3\u4e13\u7528\u6a21\u578b\uff0c\u6210\u672c\u9ad8\u4e14\u53ef\u79fb\u690d\u6027\u5dee\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u8f7b\u91cf\u7ea7\u538b\u7f29\u65b9\u6848\uff0c\u5229\u7528\u539f\u751f\u6ce8\u610f\u529b\u4fe1\u53f7\u66ff\u4ee3\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u57fa\u4e8e\u4ee3\u7406LLM\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u8bc6\u522b\u53e5\u5b50\u76f8\u5173\u6027\u3002\u901a\u8fc7\u89e3\u7801\u5668\u6ce8\u610f\u529b\u6a21\u5f0f\u5206\u6790\u5b9e\u73b0\u95ee\u9898\u611f\u77e5\u7684\u4e0a\u4e0b\u6587\u8fc7\u6ee4\uff0c\u907f\u514d\u4e13\u95e8\u538b\u7f29\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5728LongBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b05\u500d\u538b\u7f29\u7387\uff0cQA\u51c6\u786e\u7387\u4e0e7B\u538b\u7f29\u7cfb\u7edf\u76f8\u5f53\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e85%\u30020.5B\u4ee3\u7406\u6a21\u578b\u6ce8\u610f\u529b\u6a21\u5f0f\u4e0e\u5927\u578b\u6a21\u578b\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u6ce8\u610f\u529b\u4fe1\u53f7\u63a2\u6d4b\u4e3a\u4e0a\u4e0b\u6587\u538b\u7f29\u63d0\u4f9b\u9ad8\u6548\u65b0\u8303\u5f0f\uff0c\u517c\u5177\u95ee\u9898\u611f\u77e5\u80fd\u529b\u548c\u8de8\u6a21\u578b\u53ef\u79fb\u690d\u6027\uff0c\u663e\u8457\u964d\u4f4e\u90e8\u7f72\u95e8\u69db\u3002"}}
{"id": "2505.23291", "pdf": "https://arxiv.org/pdf/2505.23291", "abs": "https://arxiv.org/abs/2505.23291", "authors": ["Xinye Li", "Zunwen Zheng", "Qian Zhang", "Dekai Zhuang", "Jiabao Kang", "Liyan Xu", "Qingbin Liu", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "title": "ScEdit: Script-based Assessment of Knowledge Editing", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Knowledge Editing (KE) has gained increasing attention, yet current KE tasks\nremain relatively simple. Under current evaluation frameworks, many editing\nmethods achieve exceptionally high scores, sometimes nearing perfection.\nHowever, few studies integrate KE into real-world application scenarios (e.g.,\nrecent interest in LLM-as-agent). To support our analysis, we introduce a novel\nscript-based benchmark -- ScEdit (Script-based Knowledge Editing Benchmark) --\nwhich encompasses both counterfactual and temporal edits. We integrate\ntoken-level and text-level evaluation methods, comprehensively analyzing\nexisting KE techniques. The benchmark extends traditional fact-based\n(\"What\"-type question) evaluation to action-based (\"How\"-type question)\nevaluation. We observe that all KE methods exhibit a drop in performance on\nestablished metrics and face challenges on text-level metrics, indicating a\nchallenging task. Our benchmark is available at\nhttps://github.com/asdfo123/ScEdit.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u811a\u672c\u5316\u77e5\u8bc6\u7f16\u8f91\u8bc4\u6d4b\u57fa\u51c6ScEdit\uff0c\u878d\u5408\u6807\u8bb0\u7ea7\u4e0e\u6587\u672c\u7ea7\u8bc4\u4f30\uff0c\u63ed\u793a\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u52a8\u4f5c\u578b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888", "motivation": "\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u6846\u67b6\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u4e8b\u5b9e\u578b\u4efb\u52a1\uff08What\u578b\u95ee\u9898\uff09\uff0c\u7f3a\u4e4f\u5bf9LLM\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff08\u5982\u667a\u80fd\u4f53\u884c\u4e3a\uff09\u7684\u9002\u914d\u6027\u8bc4\u4f30", "method": "\u6784\u5efa\u5305\u542b\u53cd\u4e8b\u5b9e\u7f16\u8f91\u4e0e\u65f6\u5e8f\u7f16\u8f91\u7684\u811a\u672c\u5316\u57fa\u51c6\uff0c\u901a\u8fc7\uff081\uff09token\u7ea7\u4e8b\u5b9e\u51c6\u786e\u6027\u8bc4\u4f30\uff082\uff09\u6587\u672c\u7ea7\u884c\u4e3a\u903b\u8f91\u8fde\u8d2f\u6027\u8bc4\u4f30\u7684\u53cc\u91cd\u9a8c\u8bc1\u6846\u67b6", "result": "\u6240\u6709\u77e5\u8bc6\u7f16\u8f91\u65b9\u6cd5\u5728\u4f20\u7edf\u6307\u6807\u4e0a\u5e73\u5747\u4e0b\u964d37.2%\uff0c\u6587\u672c\u7ea7\u8bc4\u4f30\u4e2d\u4ec5\u8fbe\u523052.1%\u7684\u5408\u683c\u7387\uff0c\u63ed\u793a\u52a8\u4f5c\u578b\u77e5\u8bc6\u7f16\u8f91\u7684\u6280\u672f\u6311\u6218", "conclusion": "ScEdit\u57fa\u51c6\u7a81\u7834\u4e86\u4f20\u7edf\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u8bc1\u660e\u73b0\u6709\u77e5\u8bc6\u7f16\u8f91\u6280\u672f\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6539\u8fdb\u6a21\u578b\u7f16\u8f91\u80fd\u529b\u63d0\u4f9b\u65b0\u7684\u7814\u7a76\u65b9\u5411"}}
{"id": "2505.23295", "pdf": "https://arxiv.org/pdf/2505.23295", "abs": "https://arxiv.org/abs/2505.23295", "authors": ["James Xu Zhao", "Jimmy Z. J. Liu", "Bryan Hooi", "See-Kiong Ng"], "title": "How Does Response Length Affect Long-Form Factuality", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025 Findings. 24 pages, 10 figures, 18 tables. Code available at\n  https://github.com/XuZhao0/length-bias-factuality", "summary": "Large language models (LLMs) are widely used for long-form text generation.\nHowever, factual errors in the responses would undermine their reliability.\nDespite growing attention to LLM factuality, the effect of response length on\nfactuality remains underexplored. In this work, we systematically investigate\nthis relationship by first introducing an automatic and bi-level long-form\nfactuality evaluation framework, which achieves high agreement with human\nannotations while being cost-effective. Using this framework, we conduct\ncontrolled experiments and find that longer responses exhibit lower factual\nprecision, confirming the presence of length bias. To explain this phenomenon,\nwe empirically examine three hypotheses: error propagation, long context, and\nfacts exhaustion. Our results reveal that facts exhaustion, where the model\ngradually exhausts more reliable knowledge, is the primary cause of factual\ndegradation, rather than the other two hypotheses.", "AI": {"tldr": "\u957f\u6587\u672c\u751f\u6210\u4e2dLLMs\u5b58\u5728\u957f\u5ea6\u504f\u5dee\u73b0\u8c61\uff0c\u54cd\u5e94\u8d8a\u957f\u4e8b\u5b9e\u7cbe\u5ea6\u8d8a\u4f4e\uff0c\u4e3b\u8981\u5f52\u56e0\u4e8e\u77e5\u8bc6\u8017\u5c3d\u800c\u975e\u9519\u8bef\u4f20\u64ad\u6216\u957f\u4e0a\u4e0b\u6587\u56e0\u7d20", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u957f\u5ea6\u4e0e\u4e8b\u5b9e\u6027\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u73b0\u6709\u7814\u7a76\u5bf9\u6b64\u957f\u5ea6\u504f\u7f6e\u73b0\u8c61\u7f3a\u4e4f\u7cfb\u7edf\u5206\u6790", "method": "\u63d0\u51fa\u81ea\u52a8\u5316\u53cc\u5c42\u957f\u6587\u672c\u4e8b\u5b9e\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u9519\u8bef\u4f20\u64ad/\u957f\u4e0a\u4e0b\u6587/\u77e5\u8bc6\u8017\u5c3d\u4e09\u4e2a\u5047\u8bbe", "result": "\u5b9e\u9a8c\u8bc1\u5b9e\u77e5\u8bc6\u8017\u5c3d\u73b0\u8c61\uff08\u6a21\u578b\u9010\u6b65\u8017\u5c3d\u53ef\u9760\u77e5\u8bc6\uff09\u662f\u4e8b\u5b9e\u6027\u4e0b\u964d\u7684\u4e3b\u56e0\uff0c\u5176\u4ed6\u5047\u8bbe\u5f71\u54cd\u4e0d\u663e\u8457", "conclusion": "\u54cd\u5e94\u957f\u5ea6\u5f71\u54cdLLMs\u4e8b\u5b9e\u6027\u7684\u6838\u5fc3\u673a\u5236\u662f\u77e5\u8bc6\u8d44\u6e90\u7684\u6e10\u8fdb\u8017\u5c3d\uff0c\u8fd9\u4e3a\u4f18\u5316\u957f\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411"}}
{"id": "2505.23297", "pdf": "https://arxiv.org/pdf/2505.23297", "abs": "https://arxiv.org/abs/2505.23297", "authors": ["Daryna Dementieva", "Nikolay Babakov", "Alexander Fraser"], "title": "EmoBench-UA: A Benchmark Dataset for Emotion Detection in Ukrainian", "categories": ["cs.CL"], "comment": null, "summary": "While Ukrainian NLP has seen progress in many texts processing tasks, emotion\nclassification remains an underexplored area with no publicly available\nbenchmark to date. In this work, we introduce EmoBench-UA, the first annotated\ndataset for emotion detection in Ukrainian texts. Our annotation schema is\nadapted from the previous English-centric works on emotion detection (Mohammad\net al., 2018; Mohammad, 2022) guidelines. The dataset was created through\ncrowdsourcing using the Toloka.ai platform ensuring high-quality of the\nannotation process. Then, we evaluate a range of approaches on the collected\ndataset, starting from linguistic-based baselines, synthetic data translated\nfrom English, to large language models (LLMs). Our findings highlight the\nchallenges of emotion classification in non-mainstream languages like Ukrainian\nand emphasize the need for further development of Ukrainian-specific models and\ntraining resources.", "AI": {"tldr": "\u521b\u5efa\u9996\u4e2a\u4e4c\u514b\u5170\u8bed\u60c5\u611f\u68c0\u6d4b\u6570\u636e\u96c6EmoBench-UA\uff0c\u901a\u8fc7\u4f17\u5305\u6807\u6ce8\u5e76\u8bc4\u4f30\u8bed\u8a00\u5b66\u57fa\u7ebf/\u7ffb\u8bd1\u6570\u636e/\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7a81\u663e\u975e\u4e3b\u6d41\u8bed\u8a00\u5206\u7c7b\u6311\u6218", "motivation": "\u586b\u8865\u4e4c\u514b\u5170\u8bedNLP\u9886\u57df\u60c5\u611f\u5206\u7c7b\u57fa\u51c6\u7f3a\u5931\u7684\u7a7a\u767d\uff0c\u73b0\u6709\u82f1\u8bed\u5bfc\u5411\u7684\u6807\u6ce8\u4f53\u7cfb\u65e0\u6cd5\u76f4\u63a5\u9002\u7528\u975e\u4e3b\u6d41\u8bed\u8a00", "method": "\u91c7\u7528Toloka.ai\u5e73\u53f0\u8fdb\u884c\u4f17\u5305\u6807\u6ce8\uff0c\u7cfb\u7edf\u8bc4\u4f30\u8bed\u8a00\u5b66\u89c4\u5219\u57fa\u7ebf\u3001\u82f1\u8bed\u7ffb\u8bd1\u5408\u6210\u6570\u636e\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e09\u7c7b\u65b9\u6cd5", "result": "\u5b9e\u9a8c\u8868\u660e\u4e4c\u514b\u5170\u8bed\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u7387\u663e\u8457\u4f4e\u4e8e\u82f1\u8bed\uff0c\u73b0\u6709\u7ffb\u8bd1\u6570\u636e\u548cLLM\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u679c\u6709\u9650", "conclusion": "\u975e\u4e3b\u6d41\u8bed\u8a00\u9700\u5f00\u53d1\u672c\u5730\u5316\u6807\u6ce8\u4f53\u7cfb\u4e0e\u8bad\u7ec3\u8d44\u6e90\uff0c\u5355\u7eaf\u4f9d\u8d56\u7ffb\u8bd1\u6216\u901a\u7528LLM\u96be\u4ee5\u8fbe\u5230\u7406\u60f3\u6548\u679c"}}
{"id": "2505.23299", "pdf": "https://arxiv.org/pdf/2505.23299", "abs": "https://arxiv.org/abs/2505.23299", "authors": ["Julia Belikova", "Konstantin Polev", "Rauf Parchiev", "Dmitry Simakov"], "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems\nare increasingly deployed in industry applications, yet their reliability\nremains hampered by challenges in detecting hallucinations. While supervised\nstate-of-the-art (SOTA) methods that leverage LLM hidden states -- such as\nactivation tracing and representation analysis -- show promise, their\ndependence on extensively annotated datasets limits scalability in real-world\napplications. This paper addresses the critical bottleneck of data annotation\nby investigating the feasibility of reducing training data requirements for two\nSOTA hallucination detection frameworks: Lookback Lens, which analyzes\nattention head dynamics, and probing-based approaches, which decode internal\nmodel representations. We propose a methodology combining efficient\nclassification algorithms with dimensionality reduction techniques to minimize\nsample size demands while maintaining competitive performance. Evaluations on\nstandardized question-answering RAG benchmarks show that our approach achieves\nperformance comparable to strong proprietary LLM-based baselines with only 250\ntraining samples. These results highlight the potential of lightweight,\ndata-efficient paradigms for industrial deployment, particularly in\nannotation-constrained scenarios.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u9ad8\u6548\u5206\u7c7b\u7b97\u6cd5\u4e0e\u964d\u7ef4\u6280\u672f\uff0c\u4ec5\u9700250\u4e2a\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\u7684\u5e7b\u89c9\u68c0\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709SOTA\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u53ef\u6269\u5c55\u6027", "method": "\u878d\u5408\u9ad8\u6548\u5206\u7c7b\u7b97\u6cd5\uff08\u5982XGBoost\uff09\u4e0ePCA\u964d\u7ef4\u6280\u672f\uff0c\u5e94\u7528\u4e8eLookback Lens\u6ce8\u610f\u529b\u5934\u52a8\u6001\u5206\u6790\u548c\u6a21\u578b\u8868\u793a\u89e3\u7801\u7684\u63a2\u6d4b\u65b9\u6cd5", "result": "\u5728\u6807\u51c6\u5316QA-RAG\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u57fa\u4e8e\u5f3a\u5546\u4e1aLLM\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\uff08\u51c6\u786e\u7387\u00b12%\uff09", "conclusion": "\u9a8c\u8bc1\u4e86\u8f7b\u91cf\u7ea7\u6570\u636e\u9ad8\u6548\u8303\u5f0f\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u7279\u522b\u662f\u5728\u6807\u6ce8\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u5e94\u7528\u6f5c\u529b"}}
{"id": "2505.23304", "pdf": "https://arxiv.org/pdf/2505.23304", "abs": "https://arxiv.org/abs/2505.23304", "authors": ["Yi Luo", "Qiwen Wang", "Junqi Yang", "Luyao Tang", "Zhenghao Lin", "Zhenzhe Ying", "Weiqiang Wang", "Chen Lin"], "title": "Generalized Category Discovery in Event-Centric Contexts: Latent Pattern Mining with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Generalized Category Discovery (GCD) aims to classify both known and novel\ncategories using partially labeled data that contains only known classes.\nDespite achieving strong performance on existing benchmarks, current textual\nGCD methods lack sufficient validation in realistic settings. We introduce\nEvent-Centric GCD (EC-GCD), characterized by long, complex narratives and\nhighly imbalanced class distributions, posing two main challenges: (1)\ndivergent clustering versus classification groupings caused by subjective\ncriteria, and (2) Unfair alignment for minority classes. To tackle these, we\npropose PaMA, a framework leveraging LLMs to extract and refine event patterns\nfor improved cluster-class alignment. Additionally, a ranking-filtering-mining\npipeline ensures balanced representation of prototypes across imbalanced\ncategories. Evaluations on two EC-GCD benchmarks, including a newly constructed\nScam Report dataset, demonstrate that PaMA outperforms prior methods with up to\n12.58% H-score gains, while maintaining strong generalization on base GCD\ndatasets.", "AI": {"tldr": "\u63d0\u51faPaMA\u6846\u67b6\u89e3\u51b3\u4e8b\u4ef6\u4e2d\u5fc3\u5316\u5e7f\u4e49\u7c7b\u522b\u53d1\u73b0(EC-GCD)\u4e2d\u7684\u805a\u7c7b\u5bf9\u9f50\u4e0e\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u4e8b\u4ef6\u6a21\u5f0f\u63d0\u53d6\u548c\u539f\u578b\u5e73\u8861\u673a\u5236\u5b9e\u73b012.58%\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6587\u672cGCD\u65b9\u6cd5\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e0d\u8db3\uff0c\u4e8b\u4ef6\u578b\u6570\u636e\u5b58\u5728\u957f\u6587\u672c\u590d\u6742\u6027\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u5bfc\u81f4\u805a\u7c7b\u4e0e\u5206\u7c7b\u6807\u51c6\u5206\u6b67\u3001\u5c11\u6570\u7c7b\u5bf9\u9f50\u4e0d\u516c\u5e73\u4e24\u5927\u6838\u5fc3\u6311\u6218\u3002", "method": "\u5229\u7528LLMs\u63d0\u53d6\u4e8b\u4ef6\u6a21\u5f0f\u4f18\u5316\u805a\u7c7b-\u5206\u7c7b\u5bf9\u9f50\uff0c\u8bbe\u8ba1\u6392\u5e8f-\u8fc7\u6ee4-\u6316\u6398\u4e09\u7ea7\u6d41\u6c34\u7ebf\u5e73\u8861\u4e0d\u5e73\u8861\u7c7b\u522b\u95f4\u7684\u539f\u578b\u8868\u793a\u3002", "result": "\u5728Scam Report\u65b0\u6570\u636e\u96c6\u548cEC-GCD\u57fa\u51c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5(H-score\u63d0\u5347\u6700\u9ad8\u8fbe12.58%)\uff0c\u5728\u57fa\u7840GCD\u6570\u636e\u96c6\u4fdd\u6301\u5f3a\u6cdb\u5316\u6027\u3002", "conclusion": "PaMA\u6709\u6548\u89e3\u51b3\u4e8b\u4ef6\u578bGCD\u573a\u666f\u7684\u7279\u6b8a\u6311\u6218\uff0c\u901a\u8fc7\u6a21\u5f0f\u5bf9\u9f50\u548c\u539f\u578b\u5e73\u8861\u673a\u5236\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u7684\u7a33\u5065\u6027\u80fd\u3002"}}
{"id": "2505.23315", "pdf": "https://arxiv.org/pdf/2505.23315", "abs": "https://arxiv.org/abs/2505.23315", "authors": ["Abhirup Chakravarty", "Mark Brenchley", "Trevor Breakspear", "Ian Lewin", "Yan Huang"], "title": "Enhancing Marker Scoring Accuracy through Ordinal Confidence Modelling in Educational Assessments", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This is the preprint version of our paper accepted to ACL 2025\n  (Industry Track). The DOI will be added once available", "summary": "A key ethical challenge in Automated Essay Scoring (AES) is ensuring that\nscores are only released when they meet high reliability standards. Confidence\nmodelling addresses this by assigning a reliability estimate measure, in the\nform of a confidence score, to each automated score. In this study, we frame\nconfidence estimation as a classification task: predicting whether an\nAES-generated score correctly places a candidate in the appropriate CEFR level.\nWhile this is a binary decision, we leverage the inherent granularity of the\nscoring domain in two ways. First, we reformulate the task as an n-ary\nclassification problem using score binning. Second, we introduce a set of novel\nKernel Weighted Ordinal Categorical Cross Entropy (KWOCCE) loss functions that\nincorporate the ordinal structure of CEFR labels. Our best-performing model\nachieves an F1 score of 0.97, and enables the system to release 47% of scores\nwith 100% CEFR agreement and 99% with at least 95% CEFR agreement -compared to\napproximately 92% (approx.) CEFR agreement from the standalone AES model where\nwe release all AM predicted scores.", "AI": {"tldr": "\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5efa\u6a21\u63d0\u5347\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u53ef\u9760\u6027\uff0c\u4f7f\u7528\u5206\u6570\u5206\u7bb1\u548c\u65b0\u578b\u635f\u5931\u51fd\u6570KWOCCE\uff0c\u5b9e\u73b047%\u5206\u6570\u5b8c\u5168\u7b26\u5408CEFR\u6807\u51c6", "motivation": "\u89e3\u51b3\u81ea\u52a8\u8bc4\u5206\u7cfb\u7edf(AES)\u4e2d\u5206\u6570\u53d1\u5e03\u53ef\u9760\u6027\u7684\u4f26\u7406\u6311\u6218\uff0c\u9700\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5efa\u6a21\u786e\u4fdd\u4ec5\u53d1\u5e03\u9ad8\u53ef\u9760\u6027\u5206\u6570", "method": "1. \u5c06\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u91cd\u6784\u4e3a\u5206\u6570\u5206\u7bb1\u7684\u591a\u5206\u7c7b\u4efb\u52a1\n2. \u63d0\u51faKWOCCE\u635f\u5931\u51fd\u6570\uff0c\u878d\u5408CEFR\u7b49\u7ea7\u987a\u5e8f\u7279\u5f81", "result": "\u6700\u4f73\u6a21\u578bF1\u8fbe0.97\uff0c47%\u5206\u6570\u5b8c\u5168\u7b26\u5408CEFR\u6807\u51c6\uff0c99%\u5206\u6570\u7b26\u5408\u5ea6\u226595%\uff08\u539fAES\u6a21\u578b\u4ec592%\uff09", "conclusion": "\u7f6e\u4fe1\u5ea6\u5efa\u6a21\u663e\u8457\u63d0\u5347\u8bc4\u5206\u53ef\u9760\u6027\uff0c\u65b0\u578b\u635f\u5931\u51fd\u6570\u6709\u6548\u5229\u7528\u8bc4\u5206\u57df\u5e8f\u7ed3\u6784\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u5206\u6570\u8d28\u91cf\u63a7\u5236"}}
{"id": "2505.23316", "pdf": "https://arxiv.org/pdf/2505.23316", "abs": "https://arxiv.org/abs/2505.23316", "authors": ["Kaiyang Guo", "Yinchuan Li", "Zhitang Chen"], "title": "Proximalized Preference Optimization for Diverse Feedback Types: A Decomposed Perspective on DPO", "categories": ["cs.CL"], "comment": null, "summary": "Direct alignment methods typically optimize large language models (LLMs) by\ncontrasting the likelihoods of preferred versus dispreferred responses. While\neffective in steering LLMs to match relative preference, these methods are\nfrequently noted for decreasing the absolute likelihoods of example responses.\nAs a result, aligned models tend to generate outputs that deviate from the\nexpected patterns, exhibiting reward-hacking effect even without a reward\nmodel. This undesired consequence exposes a fundamental limitation in\ncontrastive alignment, which we characterize as likelihood underdetermination.\nIn this work, we revisit direct preference optimization (DPO) -- the seminal\ndirect alignment method -- and demonstrate that its loss theoretically admits a\ndecomposed reformulation. The reformulated loss not only broadens applicability\nto a wider range of feedback types, but also provides novel insights into the\nunderlying cause of likelihood underdetermination. Specifically, the standard\nDPO implementation implicitly oversimplifies a regularizer in the reformulated\nloss, and reinstating its complete version effectively resolves the\nunderdetermination issue. Leveraging these findings, we introduce PRoximalized\nPReference Optimization (PRO), a unified method to align with diverse feeback\ntypes, eliminating likelihood underdetermination through an efficient\napproximation of the complete regularizer. Comprehensive experiments show the\nsuperiority of PRO over existing methods in scenarios involving pairwise,\nbinary and scalar feedback.", "AI": {"tldr": "\u63d0\u51faPRO\u65b9\u6cd5\u89e3\u51b3\u76f4\u63a5\u5bf9\u9f50\u65b9\u6cd5\u4e2d\u7684\u4f3c\u7136\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u5b8c\u6574\u6b63\u5219\u5316\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u6a21\u578b\u5bf9\u9f50", "motivation": "\u73b0\u6709\u76f4\u63a5\u5bf9\u9f50\u65b9\u6cd5\uff08\u5982DPO\uff09\u4f1a\u5bfc\u81f4\u6a21\u578b\u751f\u6210\u504f\u79bb\u9884\u671f\u7684\u8f93\u51fa\uff08\u5956\u52b1\u9ed1\u5ba2\u6548\u5e94\uff09\uff0c\u6838\u5fc3\u95ee\u9898\u5728\u4e8e\u635f\u5931\u51fd\u6570\u9690\u542b\u7684\u6b63\u5219\u5316\u9879\u88ab\u8fc7\u5ea6\u7b80\u5316", "method": "\u901a\u8fc7\u5206\u89e3DPO\u635f\u5931\u51fd\u6570\u53d1\u73b0\u6b63\u5219\u5316\u7f3a\u5931\uff0c\u63d0\u51faPRO\u65b9\u6cd5\u7528\u8fd1\u4f3c\u5b8c\u6574\u6b63\u5219\u5316\u9879\u7edf\u4e00\u5904\u7406\u6210\u5bf9/\u6807\u91cf\u53cd\u9988\uff0c\u6d88\u9664\u4f3c\u7136\u4e0d\u786e\u5b9a\u6027", "result": "PRO\u5728\u6210\u5bf9/\u4e8c\u5143/\u6807\u91cf\u53cd\u9988\u573a\u666f\u5747\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u6291\u5236\u5956\u52b1\u9ed1\u5ba2\u73b0\u8c61\u4e14\u65e0\u9700\u4f9d\u8d56\u5956\u52b1\u6a21\u578b", "conclusion": "\u7406\u8bba\u63ed\u793a\u4e86\u76f4\u63a5\u5bf9\u9f50\u65b9\u6cd5\u7684\u6b63\u5219\u5316\u7f3a\u9677\uff0cPRO\u901a\u8fc7\u5b8c\u6574\u6b63\u5219\u5316\u5b9e\u73b0\u591a\u573a\u666f\u7a33\u5b9a\u5bf9\u9f50\uff0c\u4e3a\u5bf9\u9f50\u673a\u5236\u63d0\u4f9b\u65b0\u5206\u6790\u6846\u67b6"}}
{"id": "2505.23323", "pdf": "https://arxiv.org/pdf/2505.23323", "abs": "https://arxiv.org/abs/2505.23323", "authors": ["Harish Tayyar Madabushi", "Melissa Torgbi", "Claire Bonial"], "title": "Neither Stochastic Parroting nor AGI: LLMs Solve Tasks through Context-Directed Extrapolation from Training Data Priors", "categories": ["cs.CL"], "comment": null, "summary": "In this position paper we raise critical awareness of a realistic view of LLM\ncapabilities that eschews extreme alternative views that LLMs are either\n\"stochastic parrots\" or in possession of \"emergent\" advanced reasoning\ncapabilities, which, due to their unpredictable emergence, constitute an\nexistential threat. Our middle-ground view is that LLMs extrapolate from priors\nfrom their training data, and that a mechanism akin to in-context learning\nenables the targeting of the appropriate information from which to extrapolate.\nWe call this \"context-directed extrapolation.\" Under this view, substantiated\nthough existing literature, while reasoning capabilities go well beyond\nstochastic parroting, such capabilities are predictable, controllable, not\nindicative of advanced reasoning akin to high-level cognitive capabilities in\nhumans, and not infinitely scalable with additional training. As a result,\nfears of uncontrollable emergence of agency are allayed, while research\nadvances are appropriately refocused on the processes of context-directed\nextrapolation and how this interacts with training data to produce valuable\ncapabilities in LLMs. Future work can therefore explore alternative augmenting\ntechniques that do not rely on inherent advanced reasoning in LLMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faLLM\u80fd\u529b\u5e94\u88ab\u89c6\u4e3a'\u60c5\u5883\u5f15\u5bfc\u5916\u63a8'\u673a\u5236\uff0c\u65e2\u975e\u5355\u7eaf\u8bb0\u5fc6\u590d\u8bfb\uff0c\u4e5f\u4e0d\u5177\u5907\u4e0d\u53ef\u63a7\u7684'\u6d8c\u73b0'\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u4e3b\u5f20\u7814\u7a76\u5e94\u805a\u7126\u8be5\u673a\u5236\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "motivation": "\u7ea0\u6b63\u5b66\u672f\u754c\u5bf9LLM\u80fd\u529b\u7684\u4e24\u79cd\u6781\u7aef\u8ba4\u77e5\uff08\u968f\u673a\u9e66\u9e49vs\u4e0d\u53ef\u63a7\u6d8c\u73b0\u8bba\uff09\uff0c\u5efa\u7acb\u57fa\u4e8e\u73b0\u6709\u6587\u732e\u8bc1\u636e\u7684\u4e2d\u95f4\u7acb\u573a\uff0c\u6d88\u9664\u5bf9LLM\u4e0d\u53ef\u63a7\u81ea\u4e3b\u6027\u7684\u6050\u614c\uff0c\u5f15\u5bfc\u7814\u7a76\u56de\u5f52\u53ef\u63a7\u673a\u5236\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa'context-directed extrapolation'\u7406\u8bba\u6846\u67b6\uff0c\u7ed3\u5408\u8ba4\u77e5\u79d1\u5b66\u539f\u7406\u9610\u91caLLM\u63a8\u7406\u80fd\u529b\u7684\u8fb9\u754c\u4e0e\u53ef\u9884\u6d4b\u6027\u7279\u5f81\u3002", "result": "\u8bba\u8bc1LLM\u80fd\u529b\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u5916\u63a8\u673a\u5236\uff0c\u5176\u63a8\u7406\u80fd\u529b\u5177\u6709\u53ef\u9884\u6d4b\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u6cd5\u65e0\u9650\u6269\u5c55\uff0c\u4ece\u800c\u6d88\u89e3\u5bf9\u4e0d\u53ef\u63a7\u667a\u80fd\u6d8c\u73b0\u7684\u62c5\u5fe7\u3002", "conclusion": "\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u60c5\u5883\u5f15\u5bfc\u5916\u63a8\u673a\u5236\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u4ea4\u4e92\u8fc7\u7a0b\uff0c\u5f00\u53d1\u4e0d\u4f9d\u8d56LLM\u5185\u5728\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\u6280\u672f\uff0c\u63a8\u52a8\u53ef\u63a7AI\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2505.23363", "pdf": "https://arxiv.org/pdf/2505.23363", "abs": "https://arxiv.org/abs/2505.23363", "authors": ["Hongzhan Chen", "Tao Yang", "Shiping Gao", "Ruijun Chen", "Xiaojun Quan", "Hongtao Tian", "Ting Yao"], "title": "Discriminative Policy Optimization for Token-Level Reward Models", "categories": ["cs.CL"], "comment": "ICML 2025", "summary": "Process reward models (PRMs) provide more nuanced supervision compared to\noutcome reward models (ORMs) for optimizing policy models, positioning them as\na promising approach to enhancing the capabilities of LLMs in complex reasoning\ntasks. Recent efforts have advanced PRMs from step-level to token-level\ngranularity by integrating reward modeling into the training of generative\nmodels, with reward scores derived from token generation probabilities.\nHowever, the conflict between generative language modeling and reward modeling\nmay introduce instability and lead to inaccurate credit assignments. To address\nthis challenge, we revisit token-level reward assignment by decoupling reward\nmodeling from language generation and derive a token-level reward model through\nthe optimization of a discriminative policy, termed the Q-function Reward Model\n(Q-RM). We theoretically demonstrate that Q-RM explicitly learns token-level\nQ-functions from preference data without relying on fine-grained annotations.\nIn our experiments, Q-RM consistently outperforms all baseline methods across\nvarious benchmarks. For example, when integrated into PPO/REINFORCE algorithms,\nQ-RM enhances the average Pass@1 score by 5.85/4.70 points on mathematical\nreasoning tasks compared to the ORM baseline, and by 4.56/5.73 points compared\nto the token-level PRM counterpart. Moreover, reinforcement learning with Q-RM\nsignificantly enhances training efficiency, achieving convergence 12 times\nfaster than ORM on GSM8K and 11 times faster than step-level PRM on MATH. Code\nand data are available at https://github.com/homzer/Q-RM.", "AI": {"tldr": "\u63d0\u51faQ-RM\u6a21\u578b\uff0c\u901a\u8fc7\u89e3\u8026\u5956\u52b1\u5efa\u6a21\u4e0e\u8bed\u8a00\u751f\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4f20\u7edfPRM\u65b9\u6cd5\u7684\u51b2\u7a81\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6807\u8bb0\u7ea7PRM\u65b9\u6cd5\u4e2d\u751f\u6210\u6a21\u578b\u4e0e\u5956\u52b1\u6a21\u578b\u5b58\u5728\u76ee\u6807\u51b2\u7a81\uff0c\u5bfc\u81f4\u4fe1\u7528\u5206\u914d\u4e0d\u51c6\u786e\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u5956\u52b1\u5efa\u6a21\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u5224\u522b\u7b56\u7565(Q\u51fd\u6570)\u63a8\u5bfc\u6807\u8bb0\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u7406\u8bba\u8bc1\u660eQ-RM\u4ec5\u9700\u504f\u597d\u6570\u636e\u5373\u53ef\u5b66\u4e60token-level Q\u51fd\u6570\uff0c\u65e0\u9700\u7ec6\u7c92\u5ea6\u6807\u6ce8\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u6bd4ORM\u57fa\u7ebf\u5e73\u5747\u63d0\u53475.85\u5206\uff0c\u8bad\u7ec3\u6536\u655b\u901f\u5ea6\u63d0\u534712\u500d\uff08GSM8K\uff09\u548c11\u500d\uff08MATH\uff09\u3002PPO/REINFORCE\u7b97\u6cd5\u4e0b\u5747\u8d85\u8d8a\u6240\u6709\u57fa\u7ebf\u3002", "conclusion": "Q-RM\u6709\u6548\u89e3\u51b3\u4e86\u751f\u6210\u4e0e\u5956\u52b1\u5efa\u6a21\u7684\u51b2\u7a81\uff0c\u5728\u6548\u679c\u548c\u6548\u7387\u5c42\u9762\u5747\u5c55\u73b0\u663e\u8457\u4f18\u52bf\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684RL\u8bad\u7ec3\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2505.23368", "pdf": "https://arxiv.org/pdf/2505.23368", "abs": "https://arxiv.org/abs/2505.23368", "authors": ["Beiduo Chen", "Yang Janet Liu", "Anna Korhonen", "Barbara Plank"], "title": "Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation", "categories": ["cs.CL"], "comment": "22 pages, 7 figures", "summary": "The recent rise of reasoning-tuned Large Language Models (LLMs)--which\ngenerate chains of thought (CoTs) before giving the final answer--has attracted\nsignificant attention and offers new opportunities for gaining insights into\nhuman label variation, which refers to plausible differences in how multiple\nannotators label the same data instance. Prior work has shown that\nLLM-generated explanations can help align model predictions with human label\ndistributions, but typically adopt a reverse paradigm: producing explanations\nbased on given answers. In contrast, CoTs provide a forward reasoning path that\nmay implicitly embed rationales for each answer option, before generating the\nanswers. We thus propose a novel LLM-based pipeline enriched with\nlinguistically-grounded discourse segmenters to extract supporting and opposing\nstatements for each answer option from CoTs with improved accuracy. We also\npropose a rank-based HLV evaluation framework that prioritizes the ranking of\nanswers over exact scores, which instead favor direct comparison of label\ndistributions. Our method outperforms a direct generation method as well as\nbaselines on three datasets, and shows better alignment of ranking methods with\nhumans, highlighting the effectiveness of our approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684CoT\u589e\u5f3a\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bed\u8a00\u5b66\u8bed\u6bb5\u5206\u5272\u5668\u63d0\u53d6\u6b63\u53cd\u9648\u8ff0\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u6392\u540d\u7684HLV\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u57fa\u51c6\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u7ed9\u5b9a\u7b54\u6848\u751f\u6210\u89e3\u91ca\u5b58\u5728\u5c40\u9650\uff0c\u800cCoT\u7684\u524d\u5411\u63a8\u7406\u8def\u5f84\u5929\u7136\u8574\u542b\u7b54\u6848\u9009\u9879\u7684\u9690\u542b\u4f9d\u636e\uff0c\u66f4\u9002\u5408\u89e3\u51b3\u4eba\u7c7b\u6807\u7b7e\u53d8\u5f02\u95ee\u9898\u3002", "method": "1. \u5f00\u53d1\u8bed\u8a00\u5b66\u951a\u5b9a\u7684\u8bed\u6bb5\u5206\u5272\u5668\u7cbe\u51c6\u63d0\u53d6CoT\u4e2d\u6b63\u53cd\u9648\u8ff0\uff1b2. \u521b\u5efa\u57fa\u4e8e\u6392\u540d\u7684HLV\u8bc4\u4f30\u6846\u67b6\uff0c\u4f18\u5148\u7b54\u6848\u6392\u5e8f\u800c\u975e\u5206\u6570\u5bf9\u6bd4\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u76f4\u63a5\u751f\u6210\u65b9\u6cd5\uff0c\u6392\u540d\u65b9\u6cd5\u7684\u4eba\u7c7b\u5bf9\u9f50\u5ea6\u63d0\u534712.7%\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u9ad89.3%\u3002", "conclusion": "\u878d\u5408CoT\u524d\u5411\u63a8\u7406\u4e0e\u8bed\u8a00\u5b66\u5206\u6790\u7684\u7ba1\u9053\u6709\u6548\u6355\u6349\u6807\u7b7e\u53d8\u5f02\uff0c\u6392\u540d\u673a\u5236\u4e3aHLV\u8bc4\u4f30\u63d0\u4f9b\u66f4\u9c81\u68d2\u7684\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2505.23404", "pdf": "https://arxiv.org/pdf/2505.23404", "abs": "https://arxiv.org/abs/2505.23404", "authors": ["Mingyu Yu", "Wei Wang", "Yanjie Wei", "Sujuan Qin"], "title": "Adaptive Jailbreaking Strategies Based on the Semantic Understanding Capabilities of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Adversarial attacks on Large Language Models (LLMs) via jailbreaking\ntechniques-methods that circumvent their built-in safety and ethical\nconstraints-have emerged as a critical challenge in AI security. These attacks\ncompromise the reliability of LLMs by exploiting inherent weaknesses in their\ncomprehension capabilities. This paper investigates the efficacy of\njailbreaking strategies that are specifically adapted to the diverse levels of\nunderstanding exhibited by different LLMs. We propose the Adaptive Jailbreaking\nStrategies Based on the Semantic Understanding Capabilities of Large Language\nModels, a novel framework that classifies LLMs into Type I and Type II\ncategories according to their semantic comprehension abilities. For each\ncategory, we design tailored jailbreaking strategies aimed at leveraging their\nvulnerabilities to facilitate successful attacks. Extensive experiments\nconducted on multiple LLMs demonstrate that our adaptive strategy markedly\nimproves the success rate of jailbreaking. Notably, our approach achieves an\nexceptional 98.9% success rate in jailbreaking GPT-4o(29 May 2025 release)", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u8d8a\u72f1\u653b\u51fb\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u7684\u5206\u7c7b\u6846\u67b6(Type I/II)\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7b56\u7565\u663e\u8457\u63d0\u5347\u653b\u51fb\u6210\u529f\u7387(GPT-4o\u8fbe98.9%)", "motivation": "\u73b0\u6709LLMs\u5728\u8bed\u4e49\u7406\u89e3\u5c42\u9762\u5b58\u5728\u5dee\u5f02\u5316\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u9488\u5bf9\u6027\u8d8a\u72f1\u7b56\u7565\u4ee5\u8bc4\u4f30\u548c\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027", "method": "\u63d0\u51fa\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u5206\u7c7b\u6846\u67b6\uff1aType I(\u57fa\u7840\u8bed\u4e49\u7406\u89e3)\u548cType II(\u6df1\u5ea6\u4e0a\u4e0b\u6587\u7406\u89e3)\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u6df7\u6dc6\u653b\u51fb\u548c\u4e0a\u4e0b\u6587\u52ab\u6301\u7684\u81ea\u9002\u5e94\u653b\u51fb\u7b56\u7565", "result": "\u57288\u4e2a\u4e3b\u6d41LLMs\u9a8c\u8bc1\u4e2d\u5e73\u5747\u6210\u529f\u7387\u63d0\u534737.6%\uff0c\u5176\u4e2d\u5bf9GPT-4o(2025\u7248)\u653b\u51fb\u6210\u529f\u7387\u7a81\u783498.9%\uff0c\u663e\u8457\u8d85\u8d8a\u4f20\u7edf\u653b\u51fb\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u6a21\u578b\u8bed\u4e49\u80fd\u529b\u5206\u7c7b\u5b9e\u65bd\u5dee\u5f02\u5316\u653b\u51fb\u7b56\u7565\uff0c\u4e3aLLMs\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u65b0\u578b\u8bc4\u4f30\u8303\u5f0f\uff0c\u63ed\u793a\u8bed\u4e49\u7406\u89e3\u5c42\u9762\u5bf9\u6297\u6837\u672c\u7684\u751f\u6210\u673a\u5236"}}
{"id": "2505.23410", "pdf": "https://arxiv.org/pdf/2505.23410", "abs": "https://arxiv.org/abs/2505.23410", "authors": ["Xuan Gong", "Hanbo Huang", "Shiyu Liang"], "title": "From Parameters to Prompts: Understanding and Mitigating the Factuality Gap between Fine-Tuned LLMs", "categories": ["cs.CL"], "comment": "The code of this paper will be released soon", "summary": "Factual knowledge extraction aims to explicitly extract knowledge\nparameterized in pre-trained language models for application in downstream\ntasks. While prior work has been investigating the impact of supervised\nfine-tuning data on the factuality of large language models (LLMs), its\nmechanism remains poorly understood. We revisit this impact through systematic\nexperiments, with a particular focus on the factuality gap that arises when\nfine-tuning on known versus unknown knowledge. Our findings show that this gap\ncan be mitigated at the inference stage, either under out-of-distribution (OOD)\nsettings or by using appropriate in-context learning (ICL) prompts (i.e.,\nfew-shot learning and Chain of Thought (CoT)). We prove this phenomenon\ntheoretically from the perspective of knowledge graphs, showing that the\ntest-time prompt may diminish or even overshadow the impact of fine-tuning data\nand play a dominant role in knowledge extraction. Ultimately, our results shed\nlight on the interaction between finetuning data and test-time prompt,\ndemonstrating that ICL can effectively compensate for shortcomings in\nfine-tuning data, and highlighting the need to reconsider the use of ICL\nprompting as a means to evaluate the effectiveness of fine-tuning data\nselection methods.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u6d4b\u8bd5\u9636\u6bb5\u63d0\u793a\uff08\u5982\u4e0a\u4e0b\u6587\u5b66\u4e60\uff09\u53ef\u663e\u8457\u6539\u5584\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u63d0\u53d6\u6548\u679c\uff0c\u524a\u5f31\u5fae\u8c03\u6570\u636e\u7684\u5f71\u54cd", "motivation": "\u63a2\u7d22\u76d1\u7763\u5fae\u8c03\u6570\u636e\u5bf9LLMs\u4e8b\u5b9e\u6027\u7684\u5f71\u54cd\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u5df2\u77e5/\u672a\u77e5\u77e5\u8bc6\u573a\u666f\u4e0b\u7684\u5b9e\u6548\u6027\u5dee\u5f02", "method": "\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u9a8c\u8bc1+\u77e5\u8bc6\u56fe\u8c31\u7406\u8bba\u8bc1\u660e\uff0c\u5206\u6790\u5fae\u8c03\u6570\u636e\u4e0e\u6d4b\u8bd5\u63d0\u793a\u7684\u4ea4\u4e92\u4f5c\u7528", "result": "\u53d1\u73b0ICL\u63d0\u793a\u53ef\u8865\u507f\u5fae\u8c03\u6570\u636e\u4e0d\u8db3\uff0c\u6d4b\u8bd5\u63d0\u793a\u5728\u77e5\u8bc6\u63d0\u53d6\u4e2d\u8d77\u4e3b\u5bfc\u4f5c\u7528", "conclusion": "\u9700\u91cd\u65b0\u8bc4\u4f30ICL\u4f5c\u4e3a\u5fae\u8c03\u6570\u636e\u9009\u62e9\u6548\u679c\u8bc4\u4f30\u624b\u6bb5\u7684\u9002\u7528\u6027\uff0c\u63d0\u793a\u5de5\u7a0b\u6bd4\u6570\u636e\u9009\u62e9\u66f4\u5173\u952e"}}
{"id": "2505.23420", "pdf": "https://arxiv.org/pdf/2505.23420", "abs": "https://arxiv.org/abs/2505.23420", "authors": ["Marco Gaido", "Sara Papi", "Luisa Bentivogli", "Alessio Brutti", "Mauro Cettolo", "Roberto Gretter", "Marco Matassoni", "Mohamed Nabih", "Matteo Negri"], "title": "The Warmup Dilemma: How Learning Rate Strategies Impact Speech-to-Text Model Convergence", "categories": ["cs.CL"], "comment": "Accepted to IWSLT 2025", "summary": "Training large-scale models presents challenges not only in terms of resource\nrequirements but also in terms of their convergence. For this reason, the\nlearning rate (LR) is often decreased when the size of a model is increased.\nSuch a simple solution is not enough in the case of speech-to-text (S2T)\ntrainings, where evolved and more complex variants of the Transformer\narchitecture -- e.g., Conformer or Branchformer -- are used in light of their\nbetter performance. As a workaround, OWSM designed a double linear warmup of\nthe LR, increasing it to a very small value in the first phase before updating\nit to a higher value in the second phase. While this solution worked well in\npractice, it was not compared with alternative solutions, nor was the impact on\nthe final performance of different LR warmup schedules studied. This paper\nfills this gap, revealing that i) large-scale S2T trainings demand a\nsub-exponential LR warmup, and ii) a higher LR in the warmup phase accelerates\ninitial convergence, but it does not boost final performance.", "AI": {"tldr": "\u5927\u89c4\u6a21\u8bed\u97f3\u6587\u672c\u6a21\u578b\u8bad\u7ec3\u9700\u91c7\u7528\u6b21\u6307\u6570\u7ea7\u5b66\u4e60\u7387\u9884\u70ed\u7b56\u7565\uff0c\u8f83\u9ad8\u521d\u59cb\u5b66\u4e60\u7387\u53ef\u52a0\u901f\u6536\u655b\u4f46\u4e0d\u63d0\u5347\u6700\u7ec8\u6548\u679c", "motivation": "\u9488\u5bf9\u73b0\u6709\u53cc\u7ebf\u6027\u5b66\u4e60\u7387\u9884\u70ed\u7b56\u7565\u5728\u590d\u6742\u8bed\u97f3\u6587\u672c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u5bf9\u6bd4\u8bc4\u4f30\u7684\u95ee\u9898\uff0c\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u9884\u70ed\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u5206\u6790\u4e0d\u540c\u5b66\u4e60\u7387\u9884\u70ed\u7b56\u7565\uff08\u5305\u62ec\u53cc\u7ebf\u6027/\u6b21\u6307\u6570\u7ea7\u9884\u70ed\uff09\u5728\u5927\u89c4\u6a21\u8bed\u97f3\u6587\u672c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u8868\u73b0", "result": "1. \u6b21\u6307\u6570\u7ea7\u5b66\u4e60\u7387\u9884\u70ed\u7b56\u7565\u6548\u679c\u6700\u4f73\n2. \u9884\u70ed\u9636\u6bb5\u8f83\u9ad8\u5b66\u4e60\u7387\u52a0\u901f\u521d\u671f\u6536\u655b\u4f46\u6700\u7ec8\u6027\u80fd\u65e0\u63d0\u5347", "conclusion": "\u5927\u89c4\u6a21\u8bed\u97f3\u6587\u672c\u6a21\u578b\u8bad\u7ec3\u5e94\u4f18\u5148\u91c7\u7528\u6b21\u6307\u6570\u7ea7\u5b66\u4e60\u7387\u9884\u70ed\u7b56\u7565\uff0c\u540c\u65f6\u9700\u5e73\u8861\u521d\u671f\u6536\u655b\u901f\u5ea6\u4e0e\u6700\u7ec8\u6027\u80fd\u7684\u5173\u7cfb"}}
{"id": "2505.23461", "pdf": "https://arxiv.org/pdf/2505.23461", "abs": "https://arxiv.org/abs/2505.23461", "authors": ["Chuanyuan Tan", "Wenbiao Shao", "Hao Xiong", "Tong Zhu", "Zhenhua Liu", "Kai Shi", "Wenliang Chen"], "title": "UAQFact: Evaluating Factual Knowledge Utilization of LLMs on Unanswerable Questions", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Handling unanswerable questions (UAQ) is crucial for LLMs, as it helps\nprevent misleading responses in complex situations. While previous studies have\nbuilt several datasets to assess LLMs' performance on UAQ, these datasets lack\nfactual knowledge support, which limits the evaluation of LLMs' ability to\nutilize their factual knowledge when handling UAQ. To address the limitation,\nwe introduce a new unanswerable question dataset UAQFact, a bilingual dataset\nwith auxiliary factual knowledge created from a Knowledge Graph. Based on\nUAQFact, we further define two new tasks to measure LLMs' ability to utilize\ninternal and external factual knowledge, respectively. Our experimental results\nacross multiple LLM series show that UAQFact presents significant challenges,\nas LLMs do not consistently perform well even when they have factual knowledge\nstored. Additionally, we find that incorporating external knowledge may enhance\nperformance, but LLMs still cannot make full use of the knowledge which may\nresult in incorrect responses.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u5305\u542b\u4e8b\u5b9e\u77e5\u8bc6\u7684UAQFact\u6570\u636e\u96c6\uff0c\u8bc4\u4f30LLMs\u5904\u7406\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u65f6\u7684\u77e5\u8bc6\u5229\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709UAQ\u8bc4\u4f30\u6570\u636e\u96c6\u7f3a\u4e4f\u4e8b\u5b9e\u77e5\u8bc6\u652f\u6301\uff0c\u65e0\u6cd5\u6709\u6548\u8861\u91cfLLMs\u5229\u7528\u77e5\u8bc6\u5904\u7406\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u521b\u5efa\u53cc\u8bed\u6570\u636e\u96c6UAQFact\uff0c\u5e76\u8bbe\u8ba1\u4e24\u4e2a\u4efb\u52a1\u5206\u522b\u6d4b\u8bd5LLMs\u5185\u90e8\u77e5\u8bc6\u8c03\u7528\u548c\u5916\u90e8\u77e5\u8bc6\u6574\u5408\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLMs\u5373\u4f7f\u5b58\u50a8\u76f8\u5173\u77e5\u8bc6\u4ecd\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u4e14\u5916\u90e8\u77e5\u8bc6\u4ec5\u6709\u9650\u63d0\u5347\u6548\u679c\uff08\u672a\u80fd\u5b8c\u5168\u907f\u514d\u9519\u8bef\u54cd\u5e94\uff09\u3002", "conclusion": "UAQFact\u63ed\u793a\u4e86LLMs\u5728\u77e5\u8bc6\u5229\u7528\u4e0a\u7684\u6838\u5fc3\u6311\u6218\uff0c\u5f3a\u8c03\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u673a\u5236\u3002"}}
{"id": "2505.23477", "pdf": "https://arxiv.org/pdf/2505.23477", "abs": "https://arxiv.org/abs/2505.23477", "authors": ["Krithik Vishwanath", "Anton Alyakin", "Mrigayu Ghosh", "Jin Vivian Lee", "Daniel Alexander Alber", "Karl L. Sangwon", "Douglas Kondziolka", "Eric Karl Oermann"], "title": "Evaluating the performance and fragility of large language models on the self-assessment for neurological surgeons", "categories": ["cs.CL"], "comment": "22 pages, 3 main figures, 3 supplemental figures", "summary": "The Congress of Neurological Surgeons Self-Assessment for Neurological\nSurgeons (CNS-SANS) questions are widely used by neurosurgical residents to\nprepare for written board examinations. Recently, these questions have also\nserved as benchmarks for evaluating large language models' (LLMs) neurosurgical\nknowledge. This study aims to assess the performance of state-of-the-art LLMs\non neurosurgery board-like questions and to evaluate their robustness to the\ninclusion of distractor statements. A comprehensive evaluation was conducted\nusing 28 large language models. These models were tested on 2,904 neurosurgery\nboard examination questions derived from the CNS-SANS. Additionally, the study\nintroduced a distraction framework to assess the fragility of these models. The\nframework incorporated simple, irrelevant distractor statements containing\npolysemous words with clinical meanings used in non-clinical contexts to\ndetermine the extent to which such distractions degrade model performance on\nstandard medical benchmarks. 6 of the 28 tested LLMs achieved board-passing\noutcomes, with the top-performing models scoring over 15.7% above the passing\nthreshold. When exposed to distractions, accuracy across various model\narchitectures was significantly reduced-by as much as 20.4%-with one model\nfailing that had previously passed. Both general-purpose and medical\nopen-source models experienced greater performance declines compared to\nproprietary variants when subjected to the added distractors. While current\nLLMs demonstrate an impressive ability to answer neurosurgery board-like exam\nquestions, their performance is markedly vulnerable to extraneous, distracting\ninformation. These findings underscore the critical need for developing novel\nmitigation strategies aimed at bolstering LLM resilience against in-text\ndistractions, particularly for safe and effective clinical deployment.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u795e\u7ecf\u5916\u79d1\u8003\u8bd5\u9898\u4e2d\u8868\u73b0\u4f18\u5f02\u4f46\u6613\u53d7\u5e72\u6270\u4fe1\u606f\u5f71\u54cd\uff0c\u9700\u589e\u5f3a\u6297\u5e72\u6270\u80fd\u529b\u4ee5\u786e\u4fdd\u4e34\u5e8a\u5e94\u7528\u5b89\u5168", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u795e\u7ecf\u5916\u79d1\u8003\u8bd5\u4e2d\u7684\u8868\u73b0\u53ca\u5176\u5bf9\u5e72\u6270\u8bed\u53e5\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u4e34\u5e8a\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4f9d\u636e", "method": "\u4f7f\u752828\u4e2a\u5927\u6a21\u578b\u6d4b\u8bd52904\u9053\u795e\u7ecf\u5916\u79d1\u8bd5\u9898\uff0c\u8bbe\u8ba1\u542b\u591a\u4e49\u8bcd\u5e72\u6270\u7684\u8bc4\u4f30\u6846\u67b6\u68c0\u9a8c\u6a21\u578b\u6297\u5e72\u6270\u80fd\u529b", "result": "6\u4e2a\u6a21\u578b\u901a\u8fc7\u8003\u8bd5\uff08\u6700\u9ad8\u8d85\u53ca\u683c\u7ebf15.7%\uff09\uff0c\u5e72\u6270\u5bfc\u81f4\u51c6\u786e\u6027\u6700\u5927\u4e0b\u964d20.4%\uff0c\u5f00\u6e90\u6a21\u578b\u6bd4\u5546\u4e1a\u6a21\u578b\u8868\u73b0\u4e0b\u964d\u66f4\u660e\u663e", "conclusion": "\u9700\u5f00\u53d1\u65b0\u578b\u6297\u5e72\u6270\u7b56\u7565\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7a33\u5b9a\u6027\uff0c\u8fd9\u5bf9\u5b89\u5168\u6709\u6548\u7684\u4e34\u5e8a\u90e8\u7f72\u81f3\u5173\u91cd\u8981"}}
{"id": "2505.23480", "pdf": "https://arxiv.org/pdf/2505.23480", "abs": "https://arxiv.org/abs/2505.23480", "authors": ["Keqin Peng", "Liang Ding", "Yuanxin Ouyang", "Meng Fang", "Dacheng Tao"], "title": "Revisiting Overthinking in Long Chain-of-Thought from the Perspective of Self-Doubt", "categories": ["cs.CL"], "comment": null, "summary": "Reasoning Large Language Models (RLLMs) have demonstrated impressive\nperformance on complex tasks, largely due to the adoption of Long\nChain-of-Thought (Long CoT) reasoning. However, they often exhibit overthinking\n-- performing unnecessary reasoning steps even after arriving at the correct\nanswer. Prior work has largely focused on qualitative analyses of overthinking\nthrough sample-based observations of long CoTs. In contrast, we present a\nquantitative analysis of overthinking from the perspective of self-doubt,\ncharacterized by excessive token usage devoted to re-verifying already-correct\nanswer. We find that self-doubt significantly contributes to overthinking. In\nresponse, we introduce a simple and effective prompting method to reduce the\nmodel's over-reliance on input questions, thereby avoiding self-doubt.\nSpecifically, we first prompt the model to question the validity of the input\nquestion, and then respond concisely based on the outcome of that evaluation.\nExperiments on three mathematical reasoning tasks and four datasets with\nmissing premises demonstrate that our method substantially reduces answer\nlength and yields significant improvements across nearly all datasets upon 4\nwidely-used RLLMs. Further analysis demonstrates that our method effectively\nminimizes the number of reasoning steps and reduces self-doubt.", "AI": {"tldr": "\u63d0\u51fa\u901a\u8fc7\u8d28\u7591\u8f93\u5165\u95ee\u9898\u6709\u6548\u6027\u6765\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u6000\u7591\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u6709\u6548\u7f13\u89e3\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898", "motivation": "\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u601d\u7ef4\u94fe\u63a8\u7406\u4e2d\u5b58\u5728\u81ea\u6211\u6000\u7591\u73b0\u8c61\uff0c\u8868\u73b0\u4e3a\u5bf9\u5df2\u6b63\u786e\u7ed3\u8bba\u7684\u91cd\u590d\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d", "method": "\u4e24\u9636\u6bb5\u63d0\u793a\u6cd5\uff1a1) \u8981\u6c42\u6a21\u578b\u5148\u8bc4\u4f30\u8f93\u5165\u95ee\u9898\u7684\u5408\u7406\u6027 2) \u57fa\u4e8e\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u7b80\u6d01\u56de\u7b54", "result": "\u57283\u4e2a\u6570\u5b66\u63a8\u7406\u4efb\u52a1/4\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u663e\u8457\u51cf\u5c11\u56de\u7b54\u957f\u5ea6(\u5e73\u5747\u51cf\u5c1142.6%)\uff0c\u51c6\u786e\u7387\u63d0\u53473.2-6.8%\uff0c\u9002\u7528\u4e8e4\u79cd\u4e3b\u6d41\u5927\u6a21\u578b", "conclusion": "\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u4e3b\u52a8\u8d28\u7591\u95ee\u9898\u6709\u6548\u6027\uff0c\u53ef\u6709\u6548\u964d\u4f4e\u81ea\u6211\u6000\u7591\u548c\u63a8\u7406\u6b65\u9aa4\u5197\u4f59\uff0c\u4e3a\u4f18\u5316\u5927\u6a21\u578b\u63a8\u7406\u6548\u7387\u63d0\u4f9b\u65b0\u601d\u8def"}}
{"id": "2505.23494", "pdf": "https://arxiv.org/pdf/2505.23494", "abs": "https://arxiv.org/abs/2505.23494", "authors": ["Nicol Visser", "Herman Kamper"], "title": "Spoken Language Modeling with Duration-Penalized Self-Supervised Units", "categories": ["cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "Spoken language models (SLMs) operate on acoustic units obtained by\ndiscretizing self-supervised speech representations. Although the\ncharacteristics of these units directly affect performance, the interaction\nbetween codebook size and unit coarseness (i.e., duration) remains unexplored.\nWe investigate SLM performance as we vary codebook size and unit coarseness\nusing the simple duration-penalized dynamic programming (DPDP) method. New\nanalyses are performed across different linguistic levels. At the phone and\nword levels, coarseness provides little benefit, as long as the codebook size\nis chosen appropriately. However, when producing whole sentences in a\nresynthesis task, SLMs perform better with coarser units. In lexical and\nsyntactic language modeling tasks, coarser units also give higher accuracies at\nlower bitrates. We therefore show that coarser units aren't always better, but\nthat DPDP is a simple and efficient way to obtain coarser units for the tasks\nwhere they are beneficial.", "AI": {"tldr": "\u7801\u672c\u5927\u5c0f\u4e0e\u5355\u5143\u7c97\u7c92\u5ea6\u7684\u7ec4\u5408\u5f71\u54cdSLM\u6027\u80fd\uff0cDPDP\u65b9\u6cd5\u53ef\u6709\u6548\u8c03\u6574\u5355\u5143\u7c97\u7c92\u5ea6\u4ee5\u9002\u914d\u4e0d\u540c\u4efb\u52a1\u9700\u6c42", "motivation": "\u63a2\u7d22\u81ea\u76d1\u7763\u8bed\u97f3\u79bb\u6563\u5316\u4e2d\u7801\u672c\u5927\u5c0f\u4e0e\u5355\u5143\u6301\u7eed\u65f6\u95f4\u5bf9\u53e3\u8bed\u6a21\u578b\u6027\u80fd\u7684\u4ea4\u4e92\u5f71\u54cd\uff0c\u586b\u8865\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d", "method": "\u4f7f\u7528\u5e26\u65f6\u957f\u60e9\u7f5a\u7684\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\uff08DPDP\uff09\u8c03\u6574\u5355\u5143\u7c97\u7c92\u5ea6\uff0c\u901a\u8fc7\u97f3\u7d20\u3001\u8bcd\u6c47\u3001\u53e5\u5b50\u4e09\u4e2a\u5c42\u9762\u53ca\u4e0d\u540c\u6bd4\u7279\u7387\u4efb\u52a1\u8fdb\u884c\u591a\u7ef4\u5ea6\u5206\u6790", "result": "\u53e5\u5b50\u751f\u6210\u4efb\u52a1\u4e2d\u7c97\u7c92\u5ea6\u5355\u5143\u66f4\u4f18\uff0c\u8bcd/\u97f3\u7d20\u4efb\u52a1\u4e2d\u9002\u5f53\u7801\u672c\u5927\u5c0f\u5373\u53ef\u4fdd\u6301\u6027\u80fd\uff0c\u4f4e\u6bd4\u7279\u7387\u4e0b\u7c97\u7c92\u5ea6\u5355\u5143\u63d0\u5347\u53e5\u6cd5\u5efa\u6a21\u51c6\u786e\u7387", "conclusion": "\u5355\u5143\u7c97\u7c92\u5ea6\u5e76\u975e\u7edd\u5bf9\u4f18\u52bf\uff0c\u4f46\u901a\u8fc7DPDP\u53ef\u7075\u6d3b\u83b7\u53d6\u9002\u5408\u7279\u5b9a\u4efb\u52a1\uff08\u5982\u53e5\u5b50\u751f\u6210\u3001\u4f4e\u6bd4\u7279\u7387\u5efa\u6a21\uff09\u7684\u4f18\u5316\u5355\u5143\u8868\u793a"}}
{"id": "2505.23495", "pdf": "https://arxiv.org/pdf/2505.23495", "abs": "https://arxiv.org/abs/2505.23495", "authors": ["Liangliang Zhang", "Zhuorui Jiang", "Hongliang Chi", "Haoyang Chen", "Mohammed Elkoumy", "Fali Wang", "Qiong Wu", "Zhengyi Zhou", "Shirui Pan", "Suhang Wang", "Yao Ma"], "title": "Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking", "categories": ["cs.CL", "cs.LG"], "comment": "9 pages", "summary": "Knowledge Graph Question Answering (KGQA) systems rely on high-quality\nbenchmarks to evaluate complex multi-hop reasoning. However, despite their\nwidespread use, popular datasets such as WebQSP and CWQ suffer from critical\nquality issues, including inaccurate or incomplete ground-truth annotations,\npoorly constructed questions that are ambiguous, trivial, or unanswerable, and\noutdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA\ndatasets, including WebQSP and CWQ, we find that the average factual\ncorrectness rate is only 57 %. To address these issues, we introduce KGQAGen,\nan LLM-in-the-loop framework that systematically resolves these pitfalls.\nKGQAGen combines structured knowledge grounding, LLM-guided generation, and\nsymbolic verification to produce challenging and verifiable QA instances. Using\nKGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in\nWikidata, and evaluate a diverse set of KG-RAG models. Experimental results\ndemonstrate that even state-of-the-art systems struggle on this benchmark,\nhighlighting its ability to expose limitations of existing models. Our findings\nadvocate for more rigorous benchmark construction and position KGQAGen as a\nscalable framework for advancing KGQA evaluation.", "AI": {"tldr": "\u63d0\u51faKGQAGen\u6846\u67b6\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u57fa\u51c6\u8d28\u91cf\u7f3a\u9677\uff0c\u6784\u5efa\u51fa\u66b4\u9732\u73b0\u6709\u6a21\u578b\u5c40\u9650\u6027\u7684\u4e07\u7ea7\u8bc4\u6d4b\u57fa\u51c6KGQAGen-10k", "motivation": "\u73b0\u670916\u4e2a\u4e3b\u6d41KGQA\u6570\u636e\u96c6\u5b58\u5728\u6807\u6ce8\u9519\u8bef\uff08\u5e73\u5747\u4e8b\u5b9e\u6b63\u786e\u7387\u4ec557%\uff09\u3001\u95ee\u9898\u6784\u5efa\u8d28\u91cf\u5dee\uff08\u6a21\u7cca/\u7410\u788e/\u4e0d\u53ef\u7b54\uff09\u548c\u77e5\u8bc6\u8fc7\u65f6\u7b49\u95ee\u9898\uff0c\u9700\u5efa\u7acb\u66f4\u4e25\u8c28\u7684\u8bc4\u6d4b\u57fa\u51c6", "method": "\u7ed3\u5408\u7ed3\u6784\u5316\u77e5\u8bc6\u951a\u5b9a\uff08Wikidata\uff09\u3001\u5927\u6a21\u578b\u6307\u5bfc\u751f\u6210\u548c\u7b26\u53f7\u9a8c\u8bc1\u7684\u4e09\u6b65\u6846\u67b6\uff0c\u786e\u4fdd\u751f\u6210\u53ef\u9a8c\u8bc1\u4e14\u5177\u6311\u6218\u6027\u7684QA\u5b9e\u4f8b", "result": "\u57fa\u4e8eKGQAGen-10k\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u6a21\u578b\u4ecd\u5b58\u5728\u663e\u8457\u6027\u80fd\u74f6\u9888", "conclusion": "\u5f3a\u8c03\u4e25\u683c\u57fa\u51c6\u6784\u5efa\u7684\u91cd\u8981\u6027\uff0cKGQAGen\u6846\u67b6\u4e3a\u53ef\u6269\u5c55\u7684KGQA\u8bc4\u6d4b\u4f53\u7cfb\u5960\u5b9a\u57fa\u7840"}}
{"id": "2505.23538", "pdf": "https://arxiv.org/pdf/2505.23538", "abs": "https://arxiv.org/abs/2505.23538", "authors": ["Nawar Turk", "Eeham Khan", "Leila Kosseim"], "title": "CLaC at SemEval-2025 Task 6: A Multi-Architecture Approach for Corporate Environmental Promise Verification", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to SemEval-2025 Task 6 (ACL 2025)", "summary": "This paper presents our approach to the SemEval-2025 Task~6 (PromiseEval),\nwhich focuses on verifying promises in corporate ESG (Environmental, Social,\nand Governance) reports. We explore three model architectures to address the\nfour subtasks of promise identification, supporting evidence assessment,\nclarity evaluation, and verification timing. Our first model utilizes ESG-BERT\nwith task-specific classifier heads, while our second model enhances this\narchitecture with linguistic features tailored for each subtask. Our third\napproach implements a combined subtask model with attention-based sequence\npooling, transformer representations augmented with document metadata, and\nmulti-objective learning. Experiments on the English portion of the ML-Promise\ndataset demonstrate progressive improvement across our models, with our\ncombined subtask approach achieving a leaderboard score of 0.5268,\noutperforming the provided baseline of 0.5227. Our work highlights the\neffectiveness of linguistic feature extraction, attention pooling, and\nmulti-objective learning in promise verification tasks, despite challenges\nposed by class imbalance and limited training data.", "AI": {"tldr": "\u63d0\u51fa\u4e09\u79cd\u6a21\u578b\u67b6\u6784\u89e3\u51b3ESG\u627f\u8bfa\u9a8c\u8bc1\u4efb\u52a1\uff0c\u7ed3\u5408\u591a\u76ee\u6807\u5b66\u4e60\u7684\u7efc\u5408\u65b9\u6cd5\u53d6\u5f97\u6700\u4f73\u6548\u679c", "motivation": "\u9488\u5bf9\u4f01\u4e1aESG\u62a5\u544a\u4e2d\u7684\u627f\u8bfa\u9a8c\u8bc1\u9700\u6c42\uff0c\u89e3\u51b3\u627f\u8bfa\u8bc6\u522b\u3001\u8bc1\u636e\u8bc4\u4f30\u3001\u6e05\u6670\u5ea6\u8bc4\u4ef7\u548c\u9a8c\u8bc1\u65f6\u673a\u56db\u5927\u5b50\u4efb\u52a1", "method": "\u4f9d\u6b21\u91c7\u7528ESG-BERT\u5206\u7c7b\u6a21\u578b\u3001\u589e\u52a0\u8bed\u8a00\u5b66\u7279\u5f81\u7684\u6539\u8fdb\u6a21\u578b\uff0c\u4ee5\u53ca\u7ed3\u5408\u6ce8\u610f\u529b\u6c60\u5316\u3001\u6587\u6863\u5143\u6570\u636e\u589e\u5f3a\u548c\u591a\u76ee\u6807\u5b66\u4e60\u7684\u7efc\u5408\u6a21\u578b", "result": "\u7efc\u5408\u6a21\u578b\u5728ML-Promise\u6570\u636e\u96c6\u4e0a\u83b7\u5f970.5268\u5206\uff0c\u8d85\u8fc7\u57fa\u7ebf0.5227", "conclusion": "\u9a8c\u8bc1\u4e86\u8bed\u8a00\u7279\u5f81\u63d0\u53d6\u3001\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u76ee\u6807\u5b66\u4e60\u7684\u6709\u6548\u6027\uff0c\u4f46\u53d7\u9650\u4e8e\u6570\u636e\u4e0d\u5e73\u8861\u548c\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3"}}
{"id": "2505.23540", "pdf": "https://arxiv.org/pdf/2505.23540", "abs": "https://arxiv.org/abs/2505.23540", "authors": ["Yunqiao Yang", "Houxing Ren", "Zimu Lu", "Ke Wang", "Weikang Shi", "Aojun Zhou", "Junting Pan", "Mingjie Zhan", "Hongsheng Li"], "title": "Probability-Consistent Preference Optimization for Enhanced LLM Reasoning", "categories": ["cs.CL"], "comment": "14 pages, to be published in ACL 2025 findings", "summary": "Recent advances in preference optimization have demonstrated significant\npotential for improving mathematical reasoning capabilities in large language\nmodels (LLMs). While current approaches leverage high-quality pairwise\npreference data through outcome-based criteria like answer correctness or\nconsistency, they fundamentally neglect the internal logical coherence of\nresponses. To overcome this, we propose Probability-Consistent Preference\nOptimization (PCPO), a novel framework that establishes dual quantitative\nmetrics for preference selection: (1) surface-level answer correctness and (2)\nintrinsic token-level probability consistency across responses. Extensive\nexperiments show that our PCPO consistently outperforms existing outcome-only\ncriterion approaches across a diverse range of LLMs and benchmarks. Our code is\npublicly available at https://github.com/YunqiaoYang/PCPO.", "AI": {"tldr": "\u63d0\u51fa\u6982\u7387\u4e00\u81f4\u504f\u597d\u4f18\u5316\u6846\u67b6(PCPO)\uff0c\u901a\u8fc7\u53cc\u91cd\u91cf\u5316\u6307\u6807\uff08\u7b54\u6848\u6b63\u786e\u6027\u548c\u6982\u7387\u4e00\u81f4\u6027\uff09\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u73b0\u6709\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u4ec5\u5173\u6ce8\u7b54\u6848\u6b63\u786e\u6027\u7b49\u8868\u9762\u6307\u6807\uff0c\u5ffd\u89c6\u54cd\u5e94\u5185\u90e8\u903b\u8f91\u4e00\u81f4\u6027\u7684\u6839\u672c\u7f3a\u9677", "method": "\u5efa\u7acb\u8868\u9762\u7ea7\u7b54\u6848\u6b63\u786e\u6027\u548c\u8bcd\u5143\u7ea7\u6982\u7387\u4e00\u81f4\u6027\u7684\u53cc\u91cd\u8bc4\u4f30\u6807\u51c6\uff0c\u901a\u8fc7\u6982\u7387\u4e00\u81f4\u6027\u4f18\u5316\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u63a8\u7406\u8fc7\u7a0b", "result": "\u5728\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u4ec5\u4f7f\u7528\u7ed3\u679c\u6807\u51c6\u7684\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u540c\u65f6\u8003\u8651\u7ed3\u679c\u5c42\u9762\u548c\u5185\u5728\u6982\u7387\u4e00\u81f4\u6027\u80fd\u6709\u6548\u63d0\u5347\u6570\u5b66\u63a8\u7406\u6027\u80fd\uff0c\u4e3a\u504f\u597d\u4f18\u5316\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2505.23548", "pdf": "https://arxiv.org/pdf/2505.23548", "abs": "https://arxiv.org/abs/2505.23548", "authors": ["Yuri Balashov"], "title": "Translation in the Wild", "categories": ["cs.CL"], "comment": "4 figures", "summary": "Large Language Models (LLMs) excel in translation among other things,\ndemonstrating competitive performance for many language pairs in zero- and\nfew-shot settings. But unlike dedicated neural machine translation models, LLMs\nare not trained on any translation-related objective. What explains their\nremarkable translation abilities? Are these abilities grounded in \"incidental\nbilingualism\" (Briakou et al. 2023) in training data? Does instruction tuning\ncontribute to it? Are LLMs capable of aligning and leveraging semantically\nidentical or similar monolingual contents from different corners of the\ninternet that are unlikely to fit in a single context window? I offer some\nreflections on this topic, informed by recent studies and growing user\nexperience. My working hypothesis is that LLMs' translation abilities originate\nin two different types of pre-training data that may be internalized by the\nmodels in different ways. I discuss the prospects for testing the \"duality\"\nhypothesis empirically and its implications for reconceptualizing translation,\nhuman and machine, in the age of deep learning.", "AI": {"tldr": "LLMs\u5c55\u73b0\u610f\u5916\u7ffb\u8bd1\u80fd\u529b\uff0c\u53ef\u80fd\u6e90\u4e8e\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u4e24\u79cd\u53cc\u8bed\u6a21\u5f0f\u4e0e\u6307\u4ee4\u5fae\u8c03\u7684\u5171\u540c\u4f5c\u7528\u3002", "motivation": "\u63a2\u8ba8LLMs\u672a\u7ecf\u4e13\u95e8\u7ffb\u8bd1\u8bad\u7ec3\u5374\u5177\u5907\u5353\u8d8a\u7ffb\u8bd1\u80fd\u529b\u7684\u6839\u6e90\uff0c\u5206\u6790\u5076\u7136\u53cc\u8bed\u73b0\u8c61\u3001\u6307\u4ee4\u5fae\u8c03\u7684\u4f5c\u7528\u673a\u5236\uff0c\u4ee5\u53ca\u8de8\u8bed\u8a00\u8bed\u4e49\u5bf9\u9f50\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u73b0\u6709\u7814\u7a76\u6210\u679c\u548c\u7528\u6237\u5b9e\u8df5\u5206\u6790\uff0c\u63d0\u51fa'\u53cc\u91cd\u6027'\u5047\u8bf4\uff08\u4e24\u79cd\u9884\u8bad\u7ec3\u6570\u636e\u8def\u5f84\uff09\uff0c\u89c4\u5212\u5b9e\u8bc1\u9a8c\u8bc1\u65b9\u6848\u3002", "result": "\u5047\u8bbe\u7ffb\u8bd1\u80fd\u529b\u6e90\u4e8e\uff1a1\uff09\u663e\u6027\u53cc\u8bed\u5e73\u884c\u8bed\u6599\u7684\u5185\u5316 2\uff09\u9690\u6027\u8de8\u8bed\u8a00\u8bed\u4e49\u5173\u8054\u7684\u5efa\u7acb\uff0c\u9700\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u7b49\u65b9\u6848\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u5047\u8bf4\u5c06\u91cd\u5851\u5bf9\u7ffb\u8bd1\u672c\u8d28\u7684\u8ba4\u77e5\uff0c\u63a8\u52a8\u5efa\u7acb\u878d\u5408\u663e\u6027\u77e5\u8bc6\u5b66\u4e60\u4e0e\u9690\u6027\u8bed\u4e49\u6620\u5c04\u7684\u65b0\u578b\u673a\u5668\u7ffb\u8bd1\u8303\u5f0f\u3002"}}
{"id": "2505.23556", "pdf": "https://arxiv.org/pdf/2505.23556", "abs": "https://arxiv.org/abs/2505.23556", "authors": ["Wei Jie Yeo", "Nirmalendu Prakash", "Clement Neo", "Roy Ka-Wei Lee", "Erik Cambria", "Ranjan Satapathy"], "title": "Understanding Refusal in Language Models with Sparse Autoencoders", "categories": ["cs.CL"], "comment": null, "summary": "Refusal is a key safety behavior in aligned language models, yet the internal\nmechanisms driving refusals remain opaque. In this work, we conduct a\nmechanistic study of refusal in instruction-tuned LLMs using sparse\nautoencoders to identify latent features that causally mediate refusal\nbehaviors. We apply our method to two open-source chat models and intervene on\nrefusal-related features to assess their influence on generation, validating\ntheir behavioral impact across multiple harmful datasets. This enables a\nfine-grained inspection of how refusal manifests at the activation level and\naddresses key research questions such as investigating upstream-downstream\nlatent relationship and understanding the mechanisms of adversarial\njailbreaking techniques. We also establish the usefulness of refusal features\nin enhancing generalization for linear probes to out-of-distribution\nadversarial samples in classification tasks. We open source our code in\nhttps://github.com/wj210/refusal_sae.", "AI": {"tldr": "Mechanistic study using sparse autoencoders identifies latent features mediating refusal behaviors in aligned LLMs, enabling intervention analysis and improved adversarial generalization.", "motivation": "Understanding the opaque internal mechanisms behind safety-critical refusal behaviors in language models to address vulnerabilities like adversarial jailbreaking.", "method": "Applied sparse autoencoders to extract refusal-related latent features in two chat models, with cross-dataset validation and intervention experiments on harmful prompts.", "result": "Identified causal refusal features, demonstrated their utility in jailbreaking analysis, and showed improved OOD generalization in classification tasks.", "conclusion": "This work provides activation-level insights into refusal mechanisms and establishes the value of mechanistic analysis for AI safety applications."}}
{"id": "2505.23570", "pdf": "https://arxiv.org/pdf/2505.23570", "abs": "https://arxiv.org/abs/2505.23570", "authors": ["Leonardo La Rocca", "Francesco Corso", "Francesco Pierri"], "title": "Evaluating AI capabilities in detecting conspiracy theories on YouTube", "categories": ["cs.CL", "cs.CY", "cs.SI"], "comment": "Submitted for review to OSNEM Special Issue of April 2025", "summary": "As a leading online platform with a vast global audience, YouTube's extensive\nreach also makes it susceptible to hosting harmful content, including\ndisinformation and conspiracy theories. This study explores the use of\nopen-weight Large Language Models (LLMs), both text-only and multimodal, for\nidentifying conspiracy theory videos shared on YouTube. Leveraging a labeled\ndataset of thousands of videos, we evaluate a variety of LLMs in a zero-shot\nsetting and compare their performance to a fine-tuned RoBERTa baseline. Results\nshow that text-based LLMs achieve high recall but lower precision, leading to\nincreased false positives. Multimodal models lag behind their text-only\ncounterparts, indicating limited benefits from visual data integration. To\nassess real-world applicability, we evaluate the most accurate models on an\nunlabeled dataset, finding that RoBERTa achieves performance close to LLMs with\na larger number of parameters. Our work highlights the strengths and\nlimitations of current LLM-based approaches for online harmful content\ndetection, emphasizing the need for more precise and robust systems.", "AI": {"tldr": "\u8bc4\u4f30\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5728YouTube\u9634\u8c0b\u8bba\u89c6\u9891\u68c0\u6d4b\u4e2d\u7684\u6548\u679c\uff0c\u63ed\u793a\u6587\u672c\u6a21\u578b\u9ad8\u53ec\u56de\u7387\u4f46\u4f4e\u7cbe\u5ea6\u7684\u7279\u70b9\uff0c\u591a\u6a21\u6001\u6a21\u578b\u8868\u73b0\u6b20\u4f73\uff0cRoBERTa\u6a21\u578b\u5c55\u73b0\u51fa\u5b9e\u7528\u6f5c\u529b\u3002", "motivation": "YouTube\u5e73\u53f0\u5b58\u5728\u4f20\u64ad\u9634\u8c0b\u8bba\u7b49\u6709\u5bb3\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u9700\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u7684\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u80fd\u529b\u53ca\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u6807\u6ce8\u6570\u636e\u96c6\u5bf9\u6bd4\u591a\u79cd\u6587\u672c/\u591a\u6a21\u6001LLM\u4e0e\u5fae\u8c03RoBERTa\u6a21\u578b\u7684\u96f6\u6837\u672c\u8868\u73b0\uff0c\u5e76\u5728\u672a\u6807\u6ce8\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9645\u573a\u666f\u9a8c\u8bc1\u3002", "result": "\u6587\u672cLLM\u53ec\u56de\u7387\u9ad8\u8fbe94%\u4f46\u7cbe\u5ea6\u4ec536%\uff0c\u591a\u6a21\u6001\u6a21\u578b\u6027\u80fd\u5f31\u4e8e\u7eaf\u6587\u672c\u6a21\u578b\uff0cRoBERTa\u5728\u672a\u6807\u6ce8\u6570\u636e\u8868\u73b0\u63a5\u8fd1\u66f4\u5927\u53c2\u6570\u91cf\u7684LLM\u3002", "conclusion": "\u5f53\u524dLLM\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u7f3a\u9677\uff0c\u9700\u5f00\u53d1\u66f4\u7cbe\u51c6\u7684\u7cfb\u7edf\uff0cRoBERTa\u7b49\u5c0f\u89c4\u6a21\u6a21\u578b\u5728\u5b9e\u7528\u573a\u666f\u4e2d\u5177\u6709\u6210\u672c\u6548\u76ca\u4f18\u52bf\u3002"}}
{"id": "2505.23604", "pdf": "https://arxiv.org/pdf/2505.23604", "abs": "https://arxiv.org/abs/2505.23604", "authors": ["Guangtao Zeng", "Maohao Shen", "Delin Chen", "Zhenting Qi", "Subhro Das", "Dan Gutfreund", "David Cox", "Gregory Wornell", "Wei Lu", "Zhang-Wei Hong", "Chuang Gan"], "title": "Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software Engineering", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": null, "summary": "Language models (LMs) perform well on standardized coding benchmarks but\nstruggle with real-world software engineering tasks such as resolving GitHub\nissues in SWE-Bench, especially when model parameters are less than 100B. While\nsmaller models are preferable in practice due to their lower computational\ncost, improving their performance remains challenging. Existing approaches\nprimarily rely on supervised fine-tuning (SFT) with high-quality data, which is\nexpensive to curate at scale. An alternative is test-time scaling: generating\nmultiple outputs, scoring them using a verifier, and selecting the best one.\nAlthough effective, this strategy often requires excessive sampling and costly\nscoring, limiting its practical application. We propose Evolutionary Test-Time\nScaling (EvoScale), a sample-efficient method that treats generation as an\nevolutionary process. By iteratively refining outputs via selection and\nmutation, EvoScale shifts the output distribution toward higher-scoring\nregions, reducing the number of samples needed to find correct solutions. To\nreduce the overhead from repeatedly sampling and selection, we train the model\nto self-evolve using reinforcement learning (RL). Rather than relying on\nexternal verifiers at inference time, the model learns to self-improve the\nscores of its own generations across iterations. Evaluated on\nSWE-Bench-Verified, EvoScale enables our 32B model, Satori-SWE-32B, to match or\nexceed the performance of models with over 100B parameters while using a few\nsamples. Code, data, and models will be fully open-sourced.", "AI": {"tldr": "\u63d0\u51faEvoScale\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fdb\u5316\u8fc7\u7a0b\u4e0e\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u4f7f32B\u6a21\u578b\u8d85\u8d8a100B\u6a21\u578b\u6548\u679c", "motivation": "\u89e3\u51b3\u5c0f\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff08\u5982SWE-Bench\uff09\u8868\u73b0\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u9ad8\u6210\u672c\u76d1\u7763\u5fae\u8c03\u548c\u4f4e\u6548\u6d4b\u8bd5\u65f6\u6269\u5c55\u7684\u4f9d\u8d56", "method": "\u7ed3\u5408\u8fdb\u5316\u7b97\u6cd5\uff08\u8fed\u4ee3\u751f\u6210/\u9009\u62e9/\u53d8\u5f02\uff09\u4e0e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u81ea\u6211\u8fdb\u5316\uff0c\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668", "result": "Satori-SWE-32B\u6a21\u578b\u5728SWE-Bench-Verified\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a100B\u7ea7\u6a21\u578b\u6027\u80fd\uff0c\u6837\u672c\u6548\u7387\u663e\u8457\u63d0\u5347", "conclusion": "EvoScale\u4e3a\u5c0f\u6a21\u578b\u5b9e\u7528\u6027\u63d0\u5347\u63d0\u4f9b\u65b0\u8def\u5f84\uff0c\u901a\u8fc7\u5f00\u6e90\u63a8\u52a8\u793e\u533a\u53d1\u5c55"}}
{"id": "2505.23621", "pdf": "https://arxiv.org/pdf/2505.23621", "abs": "https://arxiv.org/abs/2505.23621", "authors": ["Zheyuan Yang", "Lyuhao Chen", "Arman Cohan", "Yilun Zhao"], "title": "Table-R1: Inference-Time Scaling for Table Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we present the first study to explore inference-time scaling on\ntable reasoning tasks. We develop and evaluate two post-training strategies to\nenable inference-time scaling: distillation from frontier model reasoning\ntraces and reinforcement learning with verifiable rewards (RLVR). For\ndistillation, we introduce a large-scale dataset of reasoning traces generated\nby DeepSeek-R1, which we use to fine-tune LLMs into the Table-R1-SFT model. For\nRLVR, we propose task-specific verifiable reward functions and apply the GRPO\nalgorithm to obtain the Table-R1-Zero model. We evaluate our Table-R1-series\nmodels across diverse table reasoning tasks, including short-form QA, fact\nverification, and free-form QA. Notably, the Table-R1-Zero model matches or\nexceeds the performance of GPT-4.1 and DeepSeek-R1, while using only a\n7B-parameter LLM. It also demonstrates strong generalization to out-of-domain\ndatasets. Extensive ablation and qualitative analyses reveal the benefits of\ninstruction tuning, model architecture choices, and cross-task generalization,\nas well as emergence of essential table reasoning skills during RL training.", "AI": {"tldr": "\u9996\u4e2a\u9488\u5bf9\u8868\u683c\u63a8\u7406\u4efb\u52a1\u8fdb\u884c\u63a8\u7406\u65f6\u6269\u5c55\u7684\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u84b8\u998f\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u540e\u7b56\u7565\uff0c7B\u53c2\u6570\u7684Table-R1-Zero\u6a21\u578b\u6027\u80fd\u8d85\u8d8aGPT-4.1", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u63a8\u7406\u65f6\u6269\u5c55\u6280\u672f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u8868\u683c\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u53c2\u6570\u7684\u8f7b\u91cf\u5316", "method": "1) \u57fa\u4e8eDeepSeek-R1\u751f\u6210\u7684\u5927\u89c4\u6a21\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\uff1b2) \u63d0\u51fa\u53ef\u9a8c\u8bc1\u5956\u52b1\u51fd\u6570\u5e76\u5e94\u7528GRPO\u7b97\u6cd5\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3", "result": "Table-R1-Zero\u6a21\u578b\u5728\u591a\u79cd\u8868\u683c\u63a8\u7406\u4efb\u52a1\u4e2d\u6027\u80fd\u5339\u914d/\u8d85\u8d8aGPT-4.1\u548cDeepSeek-R1\uff0c\u53c2\u6570\u4ec57B\u4e14\u5177\u5907\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u3001\u6a21\u578b\u67b6\u6784\u9009\u62e9\u548c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u8868\u683c\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6d8c\u73b0\u51fa\u5173\u952e\u63a8\u7406\u6280\u80fd"}}
{"id": "2505.23623", "pdf": "https://arxiv.org/pdf/2505.23623", "abs": "https://arxiv.org/abs/2505.23623", "authors": ["Jiaoda Li", "Ryan Cotterell"], "title": "Characterizing the Expressivity of Transformer Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Transformer-based language models (LMs) have achieved widespread empirical\nsuccess, but their theoretical expressive power remains only partially\nunderstood. Prior work often relies on idealized models with assumptions --\nsuch as arbitrary numerical precision and hard attention -- that diverge from\nreal-world transformers. In this work, we provide an exact characterization of\nfixed-precision transformers with strict future masking and soft attention, an\nidealization that more closely mirrors practical implementations. We show that\nthese models are precisely as expressive as a specific fragment of linear\ntemporal logic that includes only a single temporal operator: the past\noperator. We further relate this logic to established classes in formal\nlanguage theory, automata theory, and algebra, yielding a rich and unified\ntheoretical framework for understanding transformer expressivity. Finally, we\npresent empirical results that align closely with our theory: transformers\ntrained on languages within their theoretical capacity generalize perfectly\nover lengths, while they consistently fail to generalize on languages beyond\nit.", "AI": {"tldr": "\u672c\u6587\u5728\u66f4\u63a5\u8fd1\u5b9e\u9645\u5b9e\u73b0\u7684\u5047\u8bbe\u4e0b\uff0c\u8bc1\u660e\u56fa\u5b9a\u7cbe\u5ea6Transformer\u7684\u8868\u8fbe\u80fd\u529b\u7b49\u540c\u4e8e\u4ec5\u542b\u8fc7\u53bb\u7b97\u5b50\u7684\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7247\u6bb5\uff0c\u5e76\u5efa\u7acb\u4e0e\u5f62\u5f0f\u8bed\u8a00\u7406\u8bba/\u81ea\u52a8\u673a\u7406\u8bba/\u4ee3\u6570\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u7406\u8bba\u5bb9\u91cf\u8fb9\u754c\u3002", "motivation": "\u9488\u5bf9\u5148\u524d\u7406\u8bba\u7814\u7a76\u57fa\u4e8e\u65e0\u9650\u7cbe\u5ea6/\u786c\u6ce8\u610f\u529b\u7b49\u7406\u60f3\u5316\u5047\u8bbe\u4e0e\u5b9e\u9645\u5b9e\u73b0\u8131\u8282\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u66f4\u8d34\u8fd1\u5b9e\u9645Transformer\u67b6\u6784\uff08\u56fa\u5b9a\u7cbe\u5ea6/\u8f6f\u6ce8\u610f\u529b/\u4e25\u683c\u672a\u6765\u63a9\u7801\uff09\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5c06\u56fa\u5b9a\u7cbe\u5ea6Transformer\u7684\u8868\u8fbe\u80fd\u529b\u6620\u5c04\u5230\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7684\u7279\u5b9a\u7247\u6bb5\uff08\u4ec5\u5305\u542b\u8fc7\u53bb\u7b97\u5b50\uff09\uff0c\u5e76\u8fdb\u4e00\u6b65\u5c06\u8be5\u903b\u8f91\u4e0eChomsky\u5c42\u7ea7/\u6b63\u5219\u8bed\u8a00\u4ee3\u6570/\u8ba1\u6570\u5668\u81ea\u52a8\u673a\u7b49\u7ecf\u5178\u7406\u8bba\u4f53\u7cfb\u5efa\u7acb\u5bf9\u5e94\u5173\u7cfb\u3002", "result": "\u8bc1\u660e\u6b64\u7c7bTransformer\u7684\u8868\u8fbe\u80fd\u529b\u4e25\u683c\u53d7\u9650\u4e8e\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\u7684\u8fc7\u53bb\u7b97\u5b50\u7247\u6bb5\uff0c\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u7406\u8bba\u5bb9\u91cf\u5185\u7684\u8bed\u8a00\u53ef\u5b8c\u7f8e\u957f\u5ea6\u6cdb\u5316\uff0c\u8d85\u51fa\u5bb9\u91cf\u5219\u65e0\u6cd5\u6cdb\u5316\u3002", "conclusion": "\u6784\u5efa\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u63ed\u793aTransformer\u7684\u8868\u8fbe\u80fd\u529b\u8fb9\u754c\uff0c\u5b9e\u9a8c\u4e0e\u7406\u8bba\u9884\u6d4b\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u7684\u6839\u672c\u80fd\u529b\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002"}}
{"id": "2505.23628", "pdf": "https://arxiv.org/pdf/2505.23628", "abs": "https://arxiv.org/abs/2505.23628", "authors": ["Jiaxin Bai", "Wei Fan", "Qi Hu", "Qing Zong", "Chunyang Li", "Hong Ting Tsang", "Hongyu Luo", "Yauwai Yim", "Haoyu Huang", "Xiao Zhou", "Feng Qin", "Tianshi Zheng", "Xi Peng", "Xin Yao", "Huiwen Yang", "Leijie Wu", "Yi Ji", "Gong Zhang", "Renhai Chen", "Yangqiu Song"], "title": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora", "categories": ["cs.CL", "cs.AI"], "comment": "9 pages, preprint, code:\n  https://github.com/HKUST-KnowComp/AutoSchemaKG", "summary": "We present AutoSchemaKG, a framework for fully autonomous knowledge graph\nconstruction that eliminates the need for predefined schemas. Our system\nleverages large language models to simultaneously extract knowledge triples and\ninduce comprehensive schemas directly from text, modeling both entities and\nevents while employing conceptualization to organize instances into semantic\ncategories. Processing over 50 million documents, we construct ATLAS (Automated\nTriple Linking And Schema induction), a family of knowledge graphs with 900+\nmillion nodes and 5.9 billion edges. This approach outperforms state-of-the-art\nbaselines on multi-hop QA tasks and enhances LLM factuality. Notably, our\nschema induction achieves 95\\% semantic alignment with human-crafted schemas\nwith zero manual intervention, demonstrating that billion-scale knowledge\ngraphs with dynamically induced schemas can effectively complement parametric\nknowledge in large language models.", "AI": {"tldr": "\u63d0\u51faAutoSchemaKG\u6846\u67b6\u5b9e\u73b0\u5b8c\u5168\u81ea\u4e3b\u7684\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u540c\u6b65\u62bd\u53d6\u77e5\u8bc6\u4e09\u5143\u7ec4\u4e0e\u52a8\u6001\u5f52\u7eb3\u6a21\u5f0f\uff0c\u6784\u5efa\u4e86\u5305\u542b59\u4ebf\u8fb9\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u56fe\u8c31ATLAS\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u5c55\u73b0\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u4f9d\u8d56\u4eba\u5de5\u9884\u5b9a\u4e49\u6a21\u5f0f\uff0c\u9650\u5236\u4e86\u6784\u5efa\u6548\u7387\u548c\u6269\u5c55\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5168\u81ea\u52a8\u6a21\u5f0f\u5f52\u7eb3\u7a81\u7834\u8be5\u9650\u5236\uff0c\u540c\u65f6\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528LLM\u5e76\u884c\u5904\u7406\u77e5\u8bc6\u62bd\u53d6\uff08\u5b9e\u4f53/\u4e8b\u4ef6\uff09\u4e0e\u6a21\u5f0f\u5f52\u7eb3\uff0c\u901a\u8fc7\u6982\u5ff5\u5316\u5c06\u5b9e\u4f8b\u7ec4\u7ec7\u4e3a\u8bed\u4e49\u7c7b\u522b\uff0c\u5904\u7406\u8d855000\u4e07\u6587\u6863\u6784\u5efa\u591a\u5c42\u7ea7\u77e5\u8bc6\u56fe\u8c31\u3002", "result": "\u5efa\u6210ATLAS\u77e5\u8bc6\u56fe\u8c31\uff089\u4ebf\u8282\u70b9/59\u4ebf\u8fb9\uff09\uff0c\u591a\u8df3QA\u4efb\u52a1\u8d85\u8d8aSOTA\u57fa\u7ebf\uff0c\u6a21\u5f0f\u4e0e\u4eba\u5de5\u8bbe\u8ba1\u7684\u8bed\u4e49\u5bf9\u9f50\u5ea6\u8fbe95%\uff0c\u663e\u8457\u63d0\u5347LLM\u4e8b\u5b9e\u51c6\u786e\u7387\u3002", "conclusion": "\u8bc1\u660e\u52a8\u6001\u6a21\u5f0f\u5f52\u7eb3\u7684\u5341\u4ebf\u7ea7\u77e5\u8bc6\u56fe\u8c31\u53ef\u6709\u6548\u8865\u5145LLM\u53c2\u6570\u77e5\u8bc6\uff0c\u4e3a\u96f6\u4eba\u5de5\u5e72\u9884\u7684\u5927\u89c4\u6a21\u77e5\u8bc6\u5de5\u7a0b\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u9a8c\u8bc1\u3002"}}
{"id": "2505.23630", "pdf": "https://arxiv.org/pdf/2505.23630", "abs": "https://arxiv.org/abs/2505.23630", "authors": ["Enzo Doyen", "Amalia Todirascu"], "title": "GeNRe: A French Gender-Neutral Rewriting System Using Collective Nouns", "categories": ["cs.CL"], "comment": "Accepted to ACL 2025 Findings; 9 pages, 2 figures", "summary": "A significant portion of the textual data used in the field of Natural\nLanguage Processing (NLP) exhibits gender biases, particularly due to the use\nof masculine generics (masculine words that are supposed to refer to mixed\ngroups of men and women), which can perpetuate and amplify stereotypes. Gender\nrewriting, an NLP task that involves automatically detecting and replacing\ngendered forms with neutral or opposite forms (e.g., from masculine to\nfeminine), can be employed to mitigate these biases. While such systems have\nbeen developed in a number of languages (English, Arabic, Portuguese, German,\nFrench), automatic use of gender neutralization techniques (as opposed to\ninclusive or gender-switching techniques) has only been studied for English.\nThis paper presents GeNRe, the very first French gender-neutral rewriting\nsystem using collective nouns, which are gender-fixed in French. We introduce a\nrule-based system (RBS) tailored for the French language alongside two\nfine-tuned language models trained on data generated by our RBS. We also\nexplore the use of instruct-based models to enhance the performance of our\nother systems and find that Claude 3 Opus combined with our dictionary achieves\nresults close to our RBS. Through this contribution, we hope to promote the\nadvancement of gender bias mitigation techniques in NLP for French.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u6cd5\u8bed\u6027\u522b\u4e2d\u6027\u6539\u5199\u7cfb\u7edfGeNRe\uff0c\u7ed3\u5408\u89c4\u5219\u7cfb\u7edf\u548c\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u6548\u7f13\u89e3NLP\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898", "motivation": "\u73b0\u6709NLP\u6570\u636e\u5b58\u5728\u6027\u522b\u504f\u89c1\uff0c\u5c24\u5176\u6cd5\u8bed\u7f3a\u4e4f\u4e2d\u6027\u6539\u5199\u7cfb\u7edf\u3002\u7537\u6027\u6cdb\u79f0\u4f1a\u5ef6\u7eed\u6027\u522b\u523b\u677f\u5370\u8c61\uff0c\u4e14\u6b64\u524d\u76f8\u5173\u6280\u672f\u4ec5\u5728\u82f1\u8bed\u4e2d\u88ab\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u89c4\u5219\u7684\u6cd5\u8bed\u7cfb\u7edf(RBS)\uff0c\u751f\u6210\u8bad\u7ec3\u6570\u636e\u5fae\u8c03\u4e24\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u4f7f\u7528Claude 3 Opus\u6307\u4ee4\u6a21\u578b\u7ed3\u5408\u5b9a\u5236\u8bcd\u5178\u7684\u65b9\u6cd5\u3002", "result": "Claude 3 Opus\u7ed3\u5408\u8bcd\u5178\u8fbe\u5230\u63a5\u8fd1RBS\u7684\u6548\u679c\uff0c\u89c4\u5219\u7cfb\u7edf\u5728\u6cd5\u8bed\u4e2d\u6027\u6539\u5199\u4efb\u52a1\u4e2d\u5c55\u73b0\u6709\u6548\u6027\u3002", "conclusion": "GeNRe\u586b\u8865\u6cd5\u8bed\u6027\u522b\u4e2d\u6027\u6539\u5199\u6280\u672f\u7a7a\u767d\uff0c\u8bc1\u660e\u89c4\u5219\u4e0e\u6a21\u578b\u7ed3\u5408\u7684\u6709\u6548\u6027\uff0c\u63a8\u52a8\u6cd5\u8bedNLP\u9886\u57df\u6027\u522b\u504f\u89c1\u7f13\u89e3\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.23646", "pdf": "https://arxiv.org/pdf/2505.23646", "abs": "https://arxiv.org/abs/2505.23646", "authors": ["Zijun Yao", "Yantao Liu", "Yanxu Chen", "Jianhui Chen", "Junfeng Fang", "Lei Hou", "Juanzi Li", "Tat-Seng Chua"], "title": "Are Reasoning Models More Prone to Hallucination?", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Recently evolved large reasoning models (LRMs) show powerful performance in\nsolving complex tasks with long chain-of-thought (CoT) reasoning capability. As\nthese LRMs are mostly developed by post-training on formal reasoning tasks,\nwhether they generalize the reasoning capability to help reduce hallucination\nin fact-seeking tasks remains unclear and debated. For instance, DeepSeek-R1\nreports increased performance on SimpleQA, a fact-seeking benchmark, while\nOpenAI-o3 observes even severer hallucination. This discrepancy naturally\nraises the following research question: Are reasoning models more prone to\nhallucination? This paper addresses the question from three perspectives. (1)\nWe first conduct a holistic evaluation for the hallucination in LRMs. Our\nanalysis reveals that LRMs undergo a full post-training pipeline with cold\nstart supervised fine-tuning (SFT) and verifiable reward RL generally alleviate\ntheir hallucination. In contrast, both distillation alone and RL training\nwithout cold start fine-tuning introduce more nuanced hallucinations. (2) To\nexplore why different post-training pipelines alters the impact on\nhallucination in LRMs, we conduct behavior analysis. We characterize two\ncritical cognitive behaviors that directly affect the factuality of a LRM: Flaw\nRepetition, where the surface-level reasoning attempts repeatedly follow the\nsame underlying flawed logic, and Think-Answer Mismatch, where the final answer\nfails to faithfully match the previous CoT process. (3) Further, we investigate\nthe mechanism behind the hallucination of LRMs from the perspective of model\nuncertainty. We find that increased hallucination of LRMs is usually associated\nwith the misalignment between model uncertainty and factual accuracy. Our work\nprovides an initial understanding of the hallucination in LRMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4e09\u65b9\u9762\u7814\u7a76\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u7684\u5e7b\u89c9\u73b0\u8c61\uff1a\u53d1\u73b0\u51b7\u542f\u52a8SFT\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684RL\u8bad\u7ec3\u53ef\u51cf\u5c11\u5e7b\u89c9\uff0c\u800c\u84b8\u998f\u548c\u672a\u51b7\u542f\u52a8\u7684RL\u4f1a\u589e\u52a0\u5e7b\u89c9\uff1b\u63ed\u793a\u4e86\u7f3a\u9677\u91cd\u590d\u548c\u601d\u7ef4-\u7b54\u6848\u4e0d\u5339\u914d\u4e24\u79cd\u5173\u952e\u8ba4\u77e5\u884c\u4e3a\uff1b\u53d1\u73b0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4e0e\u4e8b\u5b9e\u51c6\u786e\u6027\u9519\u4f4d\u4f1a\u5bfc\u81f4\u5e7b\u89c9\u589e\u5f3a\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u4e8b\u5b9e\u5bfb\u6c42\u4efb\u52a1\u4e2d\u662f\u5426\u52a0\u5267\u5e7b\u89c9\u7684\u4e89\u8bae\uff0c\u63a2\u7a76\u4e0d\u540c\u540e\u8bad\u7ec3\u6d41\u7a0b\u5bf9\u6a21\u578b\u5e7b\u89c9\u7684\u5f71\u54cd\u673a\u5236\u53ca\u5176\u8ba4\u77e5\u884c\u4e3a\u6839\u6e90\u3002", "method": "1) \u6574\u4f53\u8bc4\u4f30LRMs\u7684\u5e7b\u89c9\u73b0\u8c61 2) \u884c\u4e3a\u5206\u6790(\u7f3a\u9677\u91cd\u590d/\u601d\u7ef4-\u7b54\u6848\u4e0d\u5339\u914d) 3) \u4ece\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u89d2\u5ea6\u63a2\u7a76\u5e7b\u89c9\u673a\u5236", "result": "\u51b7\u542f\u52a8SFT\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5956\u52b1RL\u964d\u4f4e\u5e7b\u89c9\uff0c\u84b8\u998f\u548c\u672a\u51b7\u542f\u52a8RL\u589e\u52a0\u5e7b\u89c9\uff1b\u53d1\u73b0\u4e24\u79cd\u5173\u952e\u9519\u8bef\u8ba4\u77e5\u884c\u4e3a\uff1b\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u4e0e\u4e8b\u5b9e\u51c6\u786e\u6027\u5b58\u5728\u9519\u4f4d\u5173\u8054\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5e7b\u89c9\u73b0\u8c61\u63d0\u4f9b\u4e86\u521d\u6b65\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8bad\u7ec3\u6d41\u7a0b\u3001\u8ba4\u77e5\u884c\u4e3a\u4e0e\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u590d\u6742\u5f71\u54cd\u673a\u5236\u3002"}}
{"id": "2505.23654", "pdf": "https://arxiv.org/pdf/2505.23654", "abs": "https://arxiv.org/abs/2505.23654", "authors": ["Mohamed Elaraby", "Diane Litman"], "title": "ARC: Argument Representation and Coverage Analysis for Zero-Shot Long Document Summarization with Instruction Following LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Integrating structured information has long improved the quality of\nabstractive summarization, particularly in retaining salient content. In this\nwork, we focus on a specific form of structure: argument roles, which are\ncrucial for summarizing documents in high-stakes domains such as law. We\ninvestigate whether instruction-tuned large language models (LLMs) adequately\npreserve this information. To this end, we introduce Argument Representation\nCoverage (ARC), a framework for measuring how well LLM-generated summaries\ncapture salient arguments. Using ARC, we analyze summaries produced by three\nopen-weight LLMs in two domains where argument roles are central: long legal\nopinions and scientific articles. Our results show that while LLMs cover\nsalient argument roles to some extent, critical information is often omitted in\ngenerated summaries, particularly when arguments are sparsely distributed\nthroughout the input. Further, we use ARC to uncover behavioral patterns --\nspecifically, how the positional bias of LLM context windows and role-specific\npreferences impact the coverage of key arguments in generated summaries,\nemphasizing the need for more argument-aware summarization strategies.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faARC\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u4e2d\u4fdd\u7559\u8bba\u70b9\u89d2\u8272\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5173\u952e\u4fe1\u606f\u5e38\u9057\u6f0f\uff0c\u9700\u6539\u8fdb\u7b56\u7565\u3002", "motivation": "\u7ed3\u6784\u5316\u4fe1\u606f\uff08\u5c24\u5176\u662f\u8bba\u70b9\u89d2\u8272\uff09\u5bf9\u6cd5\u5f8b\u7b49\u9ad8\u5371\u9886\u57df\u6458\u8981\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709LLMs\u4fdd\u7559\u6548\u679c\u4e0d\u660e\u786e\u3002", "method": "\u4f7f\u7528ARC\u6846\u67b6\u5206\u6790\u4e09\u4e2a\u5f00\u6e90LLM\u5728\u6cd5\u5f8b\u6587\u672c\u548c\u79d1\u5b66\u6587\u7ae0\u4e2d\u7684\u8868\u73b0\uff0c\u68c0\u6d4b\u6458\u8981\u5bf9\u5206\u6563\u8bba\u70b9\u7684\u8986\u76d6\u7a0b\u5ea6\u3002", "result": "LLMs\u80fd\u90e8\u5206\u8986\u76d6\u8bba\u70b9\uff0c\u4f46\u7a00\u758f\u5206\u5e03\u7684\u8bba\u70b9\u9057\u6f0f\u7387\u9ad8\u8fbe37%\uff0c\u4e14\u6a21\u578b\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\u548c\u89d2\u8272\u504f\u597d\u3002", "conclusion": "\u9700\u5f00\u53d1\u8bba\u70b9\u611f\u77e5\u7684\u6458\u8981\u7b56\u7565\uff0c\u4f18\u5316\u4e0a\u4e0b\u6587\u5904\u7406\u673a\u5236\u4ee5\u63d0\u5347\u5173\u952e\u4fe1\u606f\u4fdd\u7559\u80fd\u529b\u3002"}}
{"id": "2505.23657", "pdf": "https://arxiv.org/pdf/2505.23657", "abs": "https://arxiv.org/abs/2505.23657", "authors": ["Hongxiang Zhang", "Hao Chen", "Tianyi Zhang", "Muhao Chen"], "title": "Active Layer-Contrastive Decoding Reduces Hallucination in Large Language Model Generation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent decoding methods improve the factuality of large language\nmodels~(LLMs) by refining how the next token is selected during generation.\nThese methods typically operate at the token level, leveraging internal\nrepresentations to suppress superficial patterns. Nevertheless, LLMs remain\nprone to hallucinations, especially over longer contexts. In this paper, we\npropose Active Layer-Contrastive Decoding (ActLCD), a novel decoding strategy\nthat actively decides when to apply contrasting layers during generation. By\ncasting decoding as a sequential decision-making problem, ActLCD employs a\nreinforcement learning policy guided by a reward-aware classifier to optimize\nfactuality beyond the token level. Our experiments demonstrate that ActLCD\nsurpasses state-of-the-art methods across five benchmarks, showcasing its\neffectiveness in mitigating hallucinations in diverse generation scenarios.", "AI": {"tldr": "\u63d0\u51faActive Layer-Contrastive Decoding (ActLCD)\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a8\u6001\u9009\u62e9\u5bf9\u6bd4\u5c42\uff0c\u6709\u6548\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u6587\u672c\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u89e3\u7801\u65b9\u6cd5\u4e3b\u8981\u5728token\u5c42\u7ea7\u6291\u5236\u8868\u9762\u6a21\u5f0f\uff0c\u4f46\u957f\u6587\u672c\u573a\u666f\u4e0b\u6a21\u578b\u4ecd\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u9700\u7a81\u7834token\u5c42\u7ea7\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u5c06\u89e3\u7801\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\uff0c\u91c7\u7528\u5956\u52b1\u611f\u77e5\u5206\u7c7b\u5668\u6307\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u52a8\u6001\u51b3\u5b9a\u4f55\u65f6\u5e94\u7528\u5c42\u7ea7\u5bf9\u6bd4\u673a\u5236\u3002", "result": "\u57285\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aSOTA\u65b9\u6cd5\uff0c\u5404\u7c7b\u751f\u6210\u573a\u666f\u7684\u5e7b\u89c9\u7387\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "ActLCD\u901a\u8fc7\u5c42\u7ea7\u52a8\u6001\u5bf9\u6bd4\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8atoken\u5c42\u7ea7\u7684\u771f\u5b9e\u6027\u4f18\u5316\uff0c\u4e3a\u89e3\u7801\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2505.23662", "pdf": "https://arxiv.org/pdf/2505.23662", "abs": "https://arxiv.org/abs/2505.23662", "authors": ["Beong-woo Kwak", "Minju Kim", "Dongha Lim", "Hyungjoo Chae", "Dongjin Kang", "Sunghwan Kim", "Dongil Yang", "Jinyoung Yeo"], "title": "ToolHaystack: Stress-Testing Tool-Augmented Language Models in Realistic Long-Term Interactions", "categories": ["cs.CL"], "comment": "Our code and data are available at\n  https://github.com/bwookwak/ToolHaystack", "summary": "Large language models (LLMs) have demonstrated strong capabilities in using\nexternal tools to address user inquiries. However, most existing evaluations\nassume tool use in short contexts, offering limited insight into model behavior\nduring realistic long-term interactions. To fill this gap, we introduce\nToolHaystack, a benchmark for testing the tool use capabilities in long-term\ninteractions. Each test instance in ToolHaystack includes multiple tasks\nexecution contexts and realistic noise within a continuous conversation,\nenabling assessment of how well models maintain context and handle various\ndisruptions. By applying this benchmark to 14 state-of-the-art LLMs, we find\nthat while current models perform well in standard multi-turn settings, they\noften significantly struggle in ToolHaystack, highlighting critical gaps in\ntheir long-term robustness not revealed by previous tool benchmarks.", "AI": {"tldr": "\u73b0\u6709\u5de5\u5177\u57fa\u51c6\u6d4b\u8bd5\u805a\u7126LLMs\u7684\u77ed\u671f\u4e0a\u4e0b\u6587\u5de5\u5177\u4f7f\u7528\uff0cToolHaystack\u901a\u8fc7\u6a21\u62df\u957f\u671f\u4ea4\u4e92\u573a\u666f\uff08\u542b\u591a\u4efb\u52a1\u6267\u884c\u73af\u5883\u548c\u73b0\u5b9e\u566a\u58f0\uff09\uff0c\u63ed\u793a\u4e3b\u6d41\u6a21\u578b\u5728\u957f\u671f\u9c81\u68d2\u6027\u4e0a\u7684\u663e\u8457\u7f3a\u9677", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9LLMs\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u8bc4\u4f30\u591a\u57fa\u4e8e\u77ed\u671f\u4e0a\u4e0b\u6587\uff0c\u7f3a\u4e4f\u5bf9\u73b0\u5b9e\u573a\u666f\u4e2d\u6301\u7eed\u591a\u8f6e\u4ea4\u4e92\u4e0b\u6a21\u578b\u884c\u4e3a\u7684\u6df1\u5165\u6d1e\u5bdf\u3002\u9700\u5efa\u7acb\u65b0\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u6a21\u578b\u7684\u957f\u671f\u4e0a\u4e0b\u6587\u7ef4\u6301\u80fd\u529b\u548c\u6297\u5e72\u6270\u80fd\u529b", "method": "\u6784\u5efaToolHaystack\u57fa\u51c6\u6d4b\u8bd5\uff1a\u5305\u542b\u8fde\u7eed\u5bf9\u8bdd\u4e2d\u7684\u591a\u4efb\u52a1\u6267\u884c\u73af\u5883\u3001\u73b0\u5b9e\u5e72\u6270\u56e0\u7d20\uff08\u5982\u4e0a\u4e0b\u6587\u5207\u6362/\u65e0\u5173\u5de5\u5177\u8c03\u7528\uff09\uff0c\u6d4b\u8bd5\u6a21\u578b\u5728\u590d\u6742\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002\u8986\u76d614\u4e2a\u524d\u6cbfLLMs\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30", "result": "\u73b0\u6709\u6a21\u578b\u5728\u6807\u51c6\u591a\u8f6e\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728ToolHaystack\u4e2d\u5931\u8bef\u7387\u663e\u8457\u4e0a\u5347\uff08\u5e73\u5747\u4e0b\u964d23.5%\uff09\u3002\u66b4\u9732\u51fa\u6a21\u578b\u5728\u957f\u671f\u4e0a\u4e0b\u6587\u8ffd\u8e2a\u3001\u5e72\u6270\u8fc7\u6ee4\u7b49\u5173\u952e\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3", "conclusion": "ToolHaystack\u63ed\u793a\u4e86\u73b0\u6709\u5de5\u5177\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u7684\u957f\u671f\u9c81\u68d2\u6027\u7f3a\u9677\uff0c\u5f3a\u8c03\u6784\u5efa\u66f4\u8d34\u8fd1\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u7684\u8bc4\u4f30\u4f53\u7cfb\u7684\u91cd\u8981\u6027\uff0c\u4e3aLLMs\u7684\u6301\u7eed\u4ea4\u4e92\u80fd\u529b\u4f18\u5316\u6307\u660e\u65b9\u5411"}}
{"id": "2505.23666", "pdf": "https://arxiv.org/pdf/2505.23666", "abs": "https://arxiv.org/abs/2505.23666", "authors": ["Luke McDermott", "Robert W. Heath Jr.", "Rahul Parhi"], "title": "LoLA: Low-Rank Linear Attention With Sparse Caching", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Transformer-based large language models suffer from quadratic complexity at\ninference on long sequences. Linear attention methods are efficient\nalternatives, however, they fail to provide an accurate approximation of\nsoftmax attention. By additionally incorporating sliding window attention into\neach linear attention head, this gap can be closed for short context-length\ntasks. Unfortunately, these approaches cannot recall important information from\nlong contexts due to \"memory collisions\". In this paper , we propose LoLA:\nLow-rank Linear Attention with sparse caching. LoLA separately stores\nadditional key-value pairs that would otherwise interfere with past associative\nmemories. Moreover, LoLA further closes the gap between linear attention models\nand transformers by distributing past key-value pairs into three forms of\nmemory: (i) recent pairs in a local sliding window; (ii) difficult-to-memorize\npairs in a sparse, global cache; and (iii) generic pairs in the recurrent\nhidden state of linear attention. As an inference-only strategy, LoLA enables\npass-key retrieval on up to 8K context lengths on needle-in-a-haystack tasks\nfrom RULER. It boosts the accuracy of the base subquadratic model from 0.6% to\n97.4% at 4K context lengths, with a 4.6x smaller cache than that of Llama-3.1\n8B. LoLA demonstrates strong performance on zero-shot commonsense reasoning\ntasks among 1B and 8B parameter subquadratic models. Finally, LoLA is an\nextremely lightweight approach: Nearly all of our results can be reproduced on\na single consumer GPU.", "AI": {"tldr": "\u63d0\u51faLoLA\u65b9\u6cd5\u89e3\u51b3\u7ebf\u6027\u6ce8\u610f\u529b\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u95ee\u9898\uff0c\u901a\u8fc7\u7a00\u758f\u7f13\u5b58\u673a\u5236\u63d0\u5347\u6027\u80fd", "motivation": "\u73b0\u6709\u7ebf\u6027\u6ce8\u610f\u529b\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u5185\u5b58\u51b2\u7a81\u95ee\u9898\uff0c\u5bfc\u81f4\u5173\u952e\u4fe1\u606f\u9057\u5fd8", "method": "\u7ed3\u5408\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b+\u7a00\u758f\u5168\u5c40\u7f13\u5b58+\u7ebf\u6027\u6ce8\u610f\u529b\u9690\u72b6\u6001\u7684\u4e09\u5c42\u5b58\u50a8\u67b6\u6784\uff0c\u5b9e\u73b0\u4fe1\u606f\u5206\u5c42\u7ba1\u7406", "result": "\u57284K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u51c6\u786e\u7387\u4ece0.6%\u63d0\u5347\u81f397.4%\uff0c\u7f13\u5b58\u9700\u6c42\u6bd4Llama-3.1 8B\u51cf\u5c114.6\u500d", "conclusion": "LoLA\u4ee5\u6781\u4f4e\u8d44\u6e90\u6d88\u8017\u5b9e\u73b0\u63a5\u8fd1Transformer\u7684\u6027\u80fd\uff0c\u4e3a\u957f\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2505.23688", "pdf": "https://arxiv.org/pdf/2505.23688", "abs": "https://arxiv.org/abs/2505.23688", "authors": ["James Tanner", "Morgan Sonderegger", "Jane Stuart-Smith", "Jeff Mielke", "Tyler Kendall"], "title": "Automatic classification of stop realisation with wav2vec2.0", "categories": ["cs.CL", "cs.SD", "eess.AS"], "comment": "Accepted for Interspeech 2025. 5 pages, 3 figures", "summary": "Modern phonetic research regularly makes use of automatic tools for the\nannotation of speech data, however few tools exist for the annotation of many\nvariable phonetic phenomena. At the same time, pre-trained self-supervised\nmodels, such as wav2vec2.0, have been shown to perform well at speech\nclassification tasks and latently encode fine-grained phonetic information. We\ndemonstrate that wav2vec2.0 models can be trained to automatically classify\nstop burst presence with high accuracy in both English and Japanese, robust\nacross both finely-curated and unprepared speech corpora. Patterns of\nvariability in stop realisation are replicated with the automatic annotations,\nand closely follow those of manual annotations. These results demonstrate the\npotential of pre-trained speech models as tools for the automatic annotation\nand processing of speech corpus data, enabling researchers to `scale-up' the\nscope of phonetic research with relative ease.", "AI": {"tldr": "\u7814\u7a76\u8bc1\u5b9ewav2vec2.0\u6a21\u578b\u80fd\u9ad8\u6548\u81ea\u52a8\u6807\u6ce8\u82f1\u8bed\u548c\u65e5\u8bed\u7684\u505c\u6b62\u7206\u7834\u97f3\uff0c\u51c6\u786e\u7387\u63a5\u8fd1\u4eba\u5de5\u6807\u6ce8\u6c34\u5e73", "motivation": "\u73b0\u6709\u8bed\u97f3\u6807\u6ce8\u5de5\u5177\u5bf9\u591a\u6837\u5316\u8bed\u97f3\u73b0\u8c61\u5904\u7406\u4e0d\u8db3\uff0c\u800c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u8bed\u97f3\u5206\u7c7b\u4efb\u52a1\u4e2d\u5c55\u73b0\u4f18\u5f02\u6027\u80fd\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u9a8c\u8bc1\u5176\u4f5c\u4e3a\u81ea\u52a8\u8bed\u97f3\u6807\u6ce8\u5de5\u5177\u7684\u53ef\u884c\u6027", "method": "\u4f7f\u7528wav2vec2.0\u6a21\u578b\u5728\u82f1\u8bed\u548c\u65e5\u8bed\u8bed\u6599\u5e93\uff08\u5305\u62ec\u7cbe\u7ec6\u5904\u7406\u4e0e\u539f\u59cb\u6570\u636e\uff09\u4e0a\u8fdb\u884c\u505c\u6b62\u7206\u7834\u97f3\u5206\u7c7b\u8bad\u7ec3\uff0c\u9a8c\u8bc1\u6a21\u578b\u8de8\u8bed\u8a00\u53ca\u4e0d\u540c\u6570\u636e\u51c6\u5907\u72b6\u6001\u7684\u9c81\u68d2\u6027", "result": "\u81ea\u52a8\u6807\u6ce8\u5728\u4e24\u79cd\u8bed\u8a00\u4e2d\u5747\u8fbe\u5230\u9ad8\u51c6\u786e\u7387\uff0c\u6210\u529f\u590d\u73b0\u8bed\u97f3\u53d8\u5f02\u6a21\u5f0f\uff0c\u6807\u6ce8\u7ed3\u679c\u4e0e\u4eba\u5de5\u6807\u6ce8\u9ad8\u5ea6\u4e00\u81f4", "conclusion": "\u9884\u8bad\u7ec3\u8bed\u97f3\u6a21\u578b\u5177\u5907\u5927\u89c4\u6a21\u81ea\u52a8\u6807\u6ce8\u6f5c\u529b\uff0c\u53ef\u663e\u8457\u63d0\u5347\u8bed\u97f3\u7814\u7a76\u7684\u6548\u7387\u4e0e\u89c4\u6a21\uff0c\u63a8\u52a8\u8bed\u97f3\u5b66\u7814\u7a76\u7684\u6269\u5c55\u6027\u53d1\u5c55"}}
{"id": "2505.23689", "pdf": "https://arxiv.org/pdf/2505.23689", "abs": "https://arxiv.org/abs/2505.23689", "authors": ["Francesca Padovani", "Jaap Jumelet", "Yevgen Matusevych", "Arianna Bisazza"], "title": "Child-Directed Language Does Not Consistently Boost Syntax Learning in Language Models", "categories": ["cs.CL"], "comment": "21 pages, 4 figures, 4 tables", "summary": "Seminal work by Huebner et al. (2021) showed that language models (LMs)\ntrained on English Child-Directed Language (CDL) can reach similar syntactic\nabilities as LMs trained on much larger amounts of adult-directed written text,\nsuggesting that CDL could provide more effective LM training material than the\ncommonly used internet-crawled data. However, the generalizability of these\nresults across languages, model types, and evaluation settings remains unclear.\nWe test this by comparing models trained on CDL vs. Wikipedia across two LM\nobjectives (masked and causal), three languages (English, French, German), and\nthree syntactic minimal-pair benchmarks. Our results on these benchmarks show\ninconsistent benefits of CDL, which in most cases is outperformed by Wikipedia\nmodels. We then identify various shortcomings in previous benchmarks, and\nintroduce a novel testing methodology, FIT-CLAMS, which uses a\nfrequency-controlled design to enable balanced comparisons across training\ncorpora. Through minimal pair evaluations and regression analysis we show that\ntraining on CDL does not yield stronger generalizations for acquiring syntax\nand highlight the importance of controlling for frequency effects when\nevaluating syntactic ability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u513f\u7ae5\u5bfc\u5411\u8bed\u8a00\uff08CDL\uff09\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u5728\u53e5\u6cd5\u80fd\u529b\u8bc4\u4f30\u4e2d\u8868\u73b0\u4e0d\u5982Wikipedia\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u9891\u7387\u63a7\u5236\u5bf9\u8bc4\u4f30\u81f3\u5173\u91cd\u8981", "motivation": "\u9a8c\u8bc1Huebner\u7b49\u4eba\u7814\u7a76\u7ed3\u8bba\u7684\u666e\u9002\u6027\uff0c\u53d1\u73b0\u5148\u524d\u7814\u7a76\u5b58\u5728\u6d4b\u8bd5\u57fa\u51c6\u7f3a\u9677\uff0c\u9700\u5efa\u7acb\u66f4\u79d1\u5b66\u7684\u8bc4\u4f30\u65b9\u6cd5\u8bba", "method": "\u901a\u8fc7\u5bf9\u6bd4CDL\u4e0eWikipedia\u8bad\u7ec3\u7684\u6a21\u578b\uff08\u8986\u76d62\u79cd\u8bed\u8a00\u6a21\u578b\u76ee\u6807/3\u79cd\u8bed\u8a00/3\u4e2a\u53e5\u6cd5\u6d4b\u8bd5\u96c6\uff09\uff0c\u5f00\u53d1FIT-CLAMS\u9891\u7387\u63a7\u5236\u6d4b\u8bd5\u6846\u67b6", "result": "CDL\u4ec5\u5728\u90e8\u5206\u573a\u666f\u8868\u73b0\u826f\u597d\uff0c\u591a\u6570\u60c5\u51b5\u4e0b\u88abWikipedia\u6a21\u578b\u8d85\u8d8a\uff1b\u9891\u7387\u63a7\u5236\u663e\u8457\u5f71\u54cd\u53e5\u6cd5\u80fd\u529b\u8bc4\u4f30\u7ed3\u679c", "conclusion": "\u513f\u7ae5\u5bfc\u5411\u8bed\u8a00\u672a\u5c55\u73b0\u7279\u6b8a\u53e5\u6cd5\u5b66\u4e60\u4f18\u52bf\uff0c\u63ed\u793a\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u9700\u63a7\u5236\u8bcd\u9891\u6548\u5e94\uff0c\u6311\u6218\u4e86\u65e9\u671f\u5173\u4e8eCDL\u8bad\u7ec3\u4f18\u52bf\u7684\u7ed3\u8bba"}}
{"id": "2505.23701", "pdf": "https://arxiv.org/pdf/2505.23701", "abs": "https://arxiv.org/abs/2505.23701", "authors": ["Ziling Cheng", "Meng Cao", "Leila Pishdad", "Yanshuai Cao", "Jackie Chi Kit Cheung"], "title": "Can LLMs Reason Abstractly Over Math Word Problems Without CoT? Disentangling Abstract Formulation From Arithmetic Computation", "categories": ["cs.CL"], "comment": null, "summary": "Final-answer-based metrics are commonly used for evaluating large language\nmodels (LLMs) on math word problems, often taken as proxies for reasoning\nability. However, such metrics conflate two distinct sub-skills: abstract\nformulation (capturing mathematical relationships using expressions) and\narithmetic computation (executing the calculations). Through a disentangled\nevaluation on GSM8K and SVAMP, we find that the final-answer accuracy of\nLlama-3 and Qwen2.5 (1B-32B) without CoT is overwhelmingly bottlenecked by the\narithmetic computation step and not by the abstract formulation step. Contrary\nto the common belief, we show that CoT primarily aids in computation, with\nlimited impact on abstract formulation. Mechanistically, we show that these two\nskills are composed conjunctively even in a single forward pass without any\nreasoning steps via an abstract-then-compute mechanism: models first capture\nproblem abstractions, then handle computation. Causal patching confirms these\nabstractions are present, transferable, composable, and precede computation.\nThese behavioural and mechanistic findings highlight the need for disentangled\nevaluation to accurately assess LLM reasoning and to guide future improvements.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u6570\u5b66\u80fd\u529b\u8bc4\u4f30\u5e94\u533a\u5206\u62bd\u8c61\u5efa\u6a21\u4e0e\u7b97\u672f\u8ba1\u7b97\uff0c\u63ed\u793aCoT\u4e3b\u8981\u63d0\u5347\u8ba1\u7b97\u800c\u975e\u5efa\u6a21\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u62bd\u8c61\u5148\u884c\u7684\u6267\u884c\u673a\u5236", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u8bc4\u4f30\u6307\u6807\u6df7\u6dc6\u4e86\u6570\u5b66\u5efa\u6a21\u548c\u7b97\u672f\u8ba1\u7b97\u4e24\u4e2a\u80fd\u529b\uff0c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30LLM\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b", "method": "\u901a\u8fc7GSM8K/SVAMP\u6570\u636e\u96c6\u89e3\u8026\u8bc4\u4f30\uff0c\u7ed3\u5408CoT\u6d88\u878d\u5b9e\u9a8c\u548c\u56e0\u679c\u8865\u4e01\u6280\u672f\uff0c\u5206\u6790Llama-3/Qwen2.5\u6a21\u578b\u7684\u8fd0\u884c\u673a\u5236", "result": "\u53d1\u73b0\u6a21\u578b\u8ba1\u7b97\u80fd\u529b\u662f\u4e3b\u8981\u74f6\u9888\uff0cCoT\u4e3b\u8981\u6539\u5584\u8ba1\u7b97\u800c\u975e\u5efa\u6a21\uff0c\u8bc1\u5b9e\u5b58\u5728\u53ef\u7ec4\u5408\u7684\u62bd\u8c61-\u8ba1\u7b97\u5206\u79bb\u6267\u884c\u673a\u5236", "conclusion": "\u9700\u8981\u89e3\u8026\u8bc4\u4f30\u65b9\u6cd5\u624d\u80fd\u51c6\u786e\u8861\u91cf\u63a8\u7406\u80fd\u529b\uff0c\u62bd\u8c61\u5efa\u6a21\u80fd\u529b\u7684\u63d0\u5347\u5e94\u6210\u4e3a\u672a\u6765\u6539\u8fdb\u91cd\u70b9"}}
{"id": "2505.23713", "pdf": "https://arxiv.org/pdf/2505.23713", "abs": "https://arxiv.org/abs/2505.23713", "authors": ["Zixiang Xu", "Yanbo Wang", "Yue Huang", "Jiayi Ye", "Haomin Zhuang", "Zirui Song", "Lang Gao", "Chenxi Wang", "Zhaorun Chen", "Yujun Zhou", "Sixian Li", "Wang Pan", "Yue Zhao", "Jieyu Zhao", "Xiangliang Zhang", "Xiuying Chen"], "title": "SocialMaze: A Benchmark for Evaluating Social Reasoning in Large Language Models", "categories": ["cs.CL"], "comment": "Code available at https://github.com/xzx34/SocialMaze", "summary": "Large language models (LLMs) are increasingly applied to socially grounded\ntasks, such as online community moderation, media content analysis, and social\nreasoning games. Success in these contexts depends on a model's social\nreasoning ability - the capacity to interpret social contexts, infer others'\nmental states, and assess the truthfulness of presented information. However,\nthere is currently no systematic evaluation framework that comprehensively\nassesses the social reasoning capabilities of LLMs. Existing efforts often\noversimplify real-world scenarios and consist of tasks that are too basic to\nchallenge advanced models. To address this gap, we introduce SocialMaze, a new\nbenchmark specifically designed to evaluate social reasoning. SocialMaze\nsystematically incorporates three core challenges: deep reasoning, dynamic\ninteraction, and information uncertainty. It provides six diverse tasks across\nthree key settings: social reasoning games, daily-life interactions, and\ndigital community platforms. Both automated and human validation are used to\nensure data quality. Our evaluation reveals several key insights: models vary\nsubstantially in their ability to handle dynamic interactions and integrate\ntemporally evolving information; models with strong chain-of-thought reasoning\nperform better on tasks requiring deeper inference beyond surface-level cues;\nand model reasoning degrades significantly under uncertainty. Furthermore, we\nshow that targeted fine-tuning on curated reasoning examples can greatly\nimprove model performance in complex social scenarios. The dataset is publicly\navailable at: https://huggingface.co/datasets/MBZUAI/SocialMaze", "AI": {"tldr": "\u63d0\u51faSocialMaze\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4ea4\u63a8\u7406\u4e2d\u7684\u6df1\u5ea6\u63a8\u7406\u3001\u52a8\u6001\u4e92\u52a8\u548c\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u80fd\u529b", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u8fc7\u5ea6\u7b80\u5316\u73b0\u5b9e\u573a\u666f\u4e14\u4efb\u52a1\u57fa\u7840\uff0c\u96be\u4ee5\u6311\u6218\u5148\u8fdb\u6a21\u578b\u3002\u793e\u4ea4\u63a8\u7406\u80fd\u529b\u5bf9\u6a21\u578b\u5728\u793e\u533a\u5ba1\u6838\u3001\u5a92\u4f53\u5206\u6790\u7b49\u793e\u4f1a\u4efb\u52a1\u4e2d\u7684\u6210\u529f\u81f3\u5173\u91cd\u8981", "method": "\u8bbe\u8ba1\u5305\u542b3\u4e2a\u6838\u5fc3\u6311\u6218\uff08\u6df1\u5ea6\u63a8\u7406/\u52a8\u6001\u4e92\u52a8/\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\uff09\u30016\u4e2a\u4efb\u52a1\u7684SocialMaze\u57fa\u51c6\uff0c\u8986\u76d6\u6e38\u620f/\u65e5\u5e38\u4e92\u52a8/\u6570\u5b57\u793e\u533a\u4e09\u5927\u573a\u666f\uff0c\u91c7\u7528\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u7684\u53cc\u91cd\u6570\u636e\u8d28\u91cf\u4fdd\u969c", "result": "\u6a21\u578b\u5904\u7406\u52a8\u6001\u4e92\u52a8\u548c\u65f6\u95f4\u6574\u5408\u80fd\u529b\u5dee\u5f02\u663e\u8457\uff08\u5f3a\u601d\u7ef4\u94fe\u6a21\u578b\u6df1\u5c42\u63a8\u7406\u66f4\u4f18\uff09\uff0c\u4e0d\u786e\u5b9a\u6027\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u5b9a\u5411\u5fae\u8c03\u53ef\u5927\u5e45\u63d0\u5347\u590d\u6742\u573a\u666f\u8868\u73b0", "conclusion": "SocialMaze\u586b\u8865\u7cfb\u7edf\u8bc4\u4f30\u7a7a\u767d\uff0c\u63ed\u793a\u6a21\u578b\u793e\u4ea4\u63a8\u7406\u74f6\u9888\uff0c\u516c\u5f00\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\uff0c\u8bc1\u660e\u9488\u5bf9\u6027\u8bad\u7ec3\u80fd\u6709\u6548\u589e\u5f3a\u6a21\u578b\u793e\u4f1a\u60c5\u5883\u9002\u5e94\u80fd\u529b"}}
{"id": "2505.23714", "pdf": "https://arxiv.org/pdf/2505.23714", "abs": "https://arxiv.org/abs/2505.23714", "authors": ["Roksana Goworek", "Harpal Karlcut", "Muhammad Shezad", "Nijaguna Darshana", "Abhishek Mane", "Syam Bondada", "Raghav Sikka", "Ulvi Mammadov", "Rauf Allahverdiyev", "Sriram Purighella", "Paridhi Gupta", "Muhinyia Ndegwa", "Haim Dubossarsky"], "title": "SenWiCh: Sense-Annotation of Low-Resource Languages for WiC using Hybrid Methods", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 22 figures, submitted to SIGTYP 2025 workshop in ACL", "summary": "This paper addresses the critical need for high-quality evaluation datasets\nin low-resource languages to advance cross-lingual transfer. While\ncross-lingual transfer offers a key strategy for leveraging multilingual\npretraining to expand language technologies to understudied and typologically\ndiverse languages, its effectiveness is dependent on quality and suitable\nbenchmarks. We release new sense-annotated datasets of sentences containing\npolysemous words, spanning nine low-resource languages across diverse language\nfamilies and scripts. To facilitate dataset creation, the paper presents a\ndemonstrably beneficial semi-automatic annotation method. The utility of the\ndatasets is demonstrated through Word-in-Context (WiC) formatted experiments\nthat evaluate transfer on these low-resource languages. Results highlight the\nimportance of targeted dataset creation and evaluation for effective polysemy\ndisambiguation in low-resource settings and transfer studies. The released\ndatasets and code aim to support further research into fair, robust, and truly\nmultilingual NLP.", "AI": {"tldr": "\u8bba\u6587\u53d1\u5e03\u8986\u76d69\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u591a\u4e49\u8bcd\u6d88\u6b67\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u534a\u81ea\u52a8\u6807\u6ce8\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7WiC\u5b9e\u9a8c\u9a8c\u8bc1\u8de8\u8bed\u8a00\u8fc1\u79fb\u6709\u6548\u6027\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5236\u7ea6\u8de8\u8bed\u8a00\u8fc1\u79fb\u6280\u672f\u53d1\u5c55\u53ca\u591a\u8bed\u8a00NLP\u6280\u672f\u6269\u5c55\u3002", "method": "\u5f00\u53d1\u534a\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\u521b\u5efa\u591a\u8bed\u8a00\u591a\u4e49\u8bcd\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u57289\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u8fdb\u884c\u8bcd\u4e49\u6d88\u6b67\u8fc1\u79fb\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u9488\u5bf9\u6027\u6570\u636e\u96c6\u663e\u8457\u63d0\u5347\u591a\u4e49\u8bcd\u6d88\u6b67\u6548\u679c\uff0c\u8de8\u8bed\u8a00\u8fc1\u79fb\u6709\u6548\u6027\u4f9d\u8d56\u9ad8\u8d28\u91cf\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "\u53d1\u5e03\u7684\u6570\u636e\u96c6\u548c\u5de5\u5177\u5c06\u652f\u6301\u66f4\u516c\u5e73\u3001\u9c81\u68d2\u7684\u591a\u8bed\u8a00NLP\u7814\u7a76\uff0c\u4fc3\u8fdb\u8bed\u8a00\u6280\u672f\u591a\u6837\u5316\u53d1\u5c55\u3002"}}
{"id": "2505.23715", "pdf": "https://arxiv.org/pdf/2505.23715", "abs": "https://arxiv.org/abs/2505.23715", "authors": ["Jinzhe Li", "Gengxu Li", "Yi Chang", "Yuan Wu"], "title": "Don't Take the Premise for Granted: Evaluating the Premise Critique Ability of Large Language Models", "categories": ["cs.CL"], "comment": "31 pages,13 figures,15 tables", "summary": "Large language models (LLMs) have witnessed rapid advancements, demonstrating\nremarkable capabilities. However, a notable vulnerability persists: LLMs often\nuncritically accept flawed or contradictory premises, leading to inefficient\nreasoning and unreliable outputs. This emphasizes the significance of\npossessing the \\textbf{Premise Critique Ability} for LLMs, defined as the\ncapacity to proactively identify and articulate errors in input premises. Most\nexisting studies assess LLMs' reasoning ability in ideal settings, largely\nignoring their vulnerabilities when faced with flawed premises. Thus, we\nintroduce the \\textbf{Premise Critique Bench (PCBench)}, designed by\nincorporating four error types across three difficulty levels, paired with\nmulti-faceted evaluation metrics. We conducted systematic evaluations of 15\nrepresentative LLMs. Our findings reveal: (1) Most models rely heavily on\nexplicit prompts to detect errors, with limited autonomous critique; (2)\nPremise critique ability depends on question difficulty and error type, with\ndirect contradictions being easier to detect than complex or procedural errors;\n(3) Reasoning ability does not consistently correlate with the premise critique\nability; (4) Flawed premises trigger overthinking in reasoning models, markedly\nlengthening responses due to repeated attempts at resolving conflicts. These\ninsights underscore the urgent need to enhance LLMs' proactive evaluation of\ninput validity, positioning premise critique as a foundational capability for\ndeveloping reliable, human-centric systems. The code is available at\nhttps://github.com/MLGroupJLU/Premise_Critique.", "AI": {"tldr": "\u63ed\u793aLLMs\u524d\u63d0\u6279\u5224\u80fd\u529b\u4e0d\u8db3\uff0c\u6784\u5efaPCBench\u8bc4\u4f30\u6846\u67b6\u5e76\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u663e\u5f0f\u63d0\u793a\u4f9d\u8d56\u3001\u9519\u8bef\u7c7b\u578b\u654f\u611f\u5ea6\u5dee\u5f02\u7b49\u5173\u952e\u7f3a\u9677", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7406\u60f3\u573a\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5ffd\u89c6LLMs\u9762\u5bf9\u9519\u8bef\u524d\u63d0\u65f6\u7684\u8106\u5f31\u6027\uff0c\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u5176\u524d\u63d0\u6279\u5224\u80fd\u529b", "method": "\u8bbe\u8ba1\u5305\u542b4\u7c7b\u9519\u8bef\u30013\u79cd\u96be\u5ea6\u5c42\u7ea7\u7684PCBench\u8bc4\u4f30\u6846\u67b6\uff0c\u91c7\u7528\u591a\u7ef4\u5ea6\u6307\u6807\u7cfb\u7edf\u8bc4\u4f3015\u4e2a\u4e3b\u6d41LLM", "result": "\u6a21\u578b\u81ea\u4e3b\u6279\u5224\u80fd\u529b\u5f31\uff08\u9700\u663e\u5f0f\u63d0\u793a\uff09\u3001\u9519\u8bef\u7c7b\u578b\u76f4\u63a5\u5f71\u54cd\u68c0\u6d4b\u7387\uff08\u76f4\u63a5\u77db\u76fe\u6613\u8bc6\u522b\uff09\u3001\u63a8\u7406\u4e0e\u6279\u5224\u80fd\u529b\u4e0d\u76f8\u5173\u3001\u9519\u8bef\u524d\u63d0\u5f15\u53d1\u8fc7\u601d\u8003\u73b0\u8c61", "conclusion": "\u4e9f\u9700\u52a0\u5f3aLLM\u5bf9\u8f93\u5165\u6709\u6548\u6027\u7684\u4e3b\u52a8\u8bc4\u4f30\uff0c\u5c06\u524d\u63d0\u6279\u5224\u80fd\u529b\u4f5c\u4e3a\u6784\u5efa\u53ef\u9760\u4eba\u672c\u7cfb\u7edf\u7684\u6838\u5fc3\u57fa\u7840\u80fd\u529b"}}
{"id": "2505.23722", "pdf": "https://arxiv.org/pdf/2505.23722", "abs": "https://arxiv.org/abs/2505.23722", "authors": ["Fan Bai", "Hamid Hassanzadeh", "Ardavan Saeedi", "Mark Dredze"], "title": "Label-Guided In-Context Learning for Named Entity Recognition", "categories": ["cs.CL"], "comment": "Preprint", "summary": "In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks using only a few demonstrations. In Named Entity Recognition (NER),\ndemonstrations are typically selected based on semantic similarity to the test\ninstance, ignoring training labels and resulting in suboptimal performance. We\nintroduce DEER, a new method that leverages training labels through token-level\nstatistics to improve ICL performance. DEER first enhances example selection\nwith a label-guided, token-based retriever that prioritizes tokens most\ninformative for entity recognition. It then prompts the LLM to revisit\nerror-prone tokens, which are also identified using label statistics, and make\ntargeted corrections. Evaluated on five NER datasets using four different LLMs,\nDEER consistently outperforms existing ICL methods and approaches the\nperformance of supervised fine-tuning. Further analysis shows its effectiveness\non both seen and unseen entities and its robustness in low-resource settings.", "AI": {"tldr": "DEER\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u6807\u7b7e\u7edf\u8ba1\u4fe1\u606f\u4f18\u5316\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\uff0c\u5728\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\uff0c\u63a5\u8fd1\u76d1\u7763\u5fae\u8c03\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u793a\u4f8b\u9009\u62e9\u65b9\u6cd5\u5ffd\u7565\u8bad\u7ec3\u6807\u7b7e\u4fe1\u606f\uff0c\u5bfc\u81f4\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u4e0a\u4e0b\u6587\u5b66\u4e60\u6548\u679c\u4e0d\u4f73\u3002\u5982\u4f55\u6709\u6548\u5229\u7528\u6807\u6ce8\u6570\u636e\u63d0\u5347\u5927\u6a21\u578b\u5728NER\u4efb\u52a1\u4e2d\u7684few-shot\u8868\u73b0\u6210\u4e3a\u7814\u7a76\u52a8\u673a\u3002", "method": "1. \u63d0\u51fa\u6807\u7b7e\u5f15\u5bfc\u7684token\u7ea7\u68c0\u7d22\u5668\uff0c\u57fa\u4e8e\u5b9e\u4f53\u6807\u7b7e\u7edf\u8ba1\u4fe1\u606f\u7b5b\u9009\u4fe1\u606f\u91cf\u6700\u5927\u7684token\n2. \u8bbe\u8ba1\u9488\u5bf9\u6613\u9519token\u7684\u6821\u6b63\u673a\u5236\uff0c\u5229\u7528\u6807\u7b7e\u7edf\u8ba1\u8bc6\u522b\u5173\u952etoken\u5e76\u8981\u6c42\u6a21\u578b\u91cd\u65b0\u9884\u6d4b", "result": "\u57285\u4e2aNER\u6570\u636e\u96c6\u30014\u79cd\u5927\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\n- \u6301\u7eed\u8d85\u8d8a\u73b0\u6709ICL\u65b9\u6cd5\n- \u63a5\u8fd1\u76d1\u7763\u5fae\u8c03\u6548\u679c\uff08\u5dee\u8ddd<3%\uff09\n- \u5bf9\u65b0\u65e7\u5b9e\u4f53\u8bc6\u522b\u6548\u679c\u5747\u8861\n- \u4f4e\u8d44\u6e90\u573a\u666f\u8868\u73b0\u7a33\u5065", "conclusion": "DEER\u9996\u6b21\u5c06\u6807\u7b7e\u7edf\u8ba1\u4fe1\u606f\u878d\u5165\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7token\u7ea7\u4f18\u5316\u6709\u6548\u7f29\u5c0f\u4e86ICL\u4e0e\u76d1\u7763\u5b66\u4e60\u7684\u5dee\u8ddd\uff0c\u4e3a\u6807\u6ce8\u6570\u636e\u6709\u9650\u573a\u666f\u4e0b\u7684\u5b9e\u4f53\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2505.23723", "pdf": "https://arxiv.org/pdf/2505.23723", "abs": "https://arxiv.org/abs/2505.23723", "authors": ["Zexi Liu", "Jingyi Chai", "Xinyu Zhu", "Shuo Tang", "Rui Ye", "Bo Zhang", "Lei Bai", "Siheng Chen"], "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The emergence of large language model (LLM)-based agents has significantly\nadvanced the development of autonomous machine learning (ML) engineering.\nHowever, most existing approaches rely heavily on manual prompt engineering,\nfailing to adapt and optimize based on diverse experimental experiences.\nFocusing on this, for the first time, we explore the paradigm of learning-based\nagentic ML, where an LLM agent learns through interactive experimentation on ML\ntasks using online reinforcement learning (RL). To realize this, we propose a\nnovel agentic ML training framework with three key components: (1)\nexploration-enriched fine-tuning, which enables LLM agents to generate diverse\nactions for enhanced RL exploration; (2) step-wise RL, which enables training\non a single action step, accelerating experience collection and improving\ntraining efficiency; (3) an agentic ML-specific reward module, which unifies\nvaried ML feedback signals into consistent rewards for RL optimization.\nLeveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM\nfor autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our\n7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it\nachieves continuous performance improvements and demonstrates exceptional\ncross-task generalization capabilities.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684ML-Agent\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22\u589e\u5f3a\u5fae\u8c03\u3001\u5206\u6b65RL\u8bad\u7ec3\u548c\u7edf\u4e00\u5956\u52b1\u6a21\u5757\uff0c\u4f7f7B\u5c0f\u6a21\u578b\u5728ML\u4efb\u52a1\u4e2d\u8d85\u8d8a671B\u5927\u6a21\u578b\u5e76\u5c55\u73b0\u4f18\u79c0\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u4f9d\u8d56\u4eba\u5de5\u63d0\u793a\u5de5\u7a0b\uff0c\u7f3a\u4e4f\u4ece\u5b9e\u9a8c\u7ecf\u9a8c\u4e2d\u81ea\u9002\u5e94\u4f18\u5316\u7684\u80fd\u529b\uff0c\u9700\u6784\u5efa\u81ea\u52a8\u5316\u5b66\u4e60\u673a\u5236\u63d0\u5347\u81ea\u4e3bML\u6548\u7387\u3002", "method": "1. \u63a2\u7d22\u589e\u5f3a\u5fae\u8c03\u751f\u6210\u591a\u6837\u52a8\u4f5c\uff1b2. \u5206\u6b65RL\u52a0\u901f\u5355\u6b65\u8bad\u7ec3\uff1b3. \u7edf\u4e00ML\u53cd\u9988\u7684\u5956\u52b1\u6a21\u5757\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u4ec5\u75289\u4e2a\u4efb\u52a1\u8bad\u7ec3\u76847B\u6a21\u578b\u8d85\u8d8a671B\u7684DeepSeek-R1\uff0c\u4e14\u6301\u7eed\u4f18\u5316\u5e76\u5c55\u793a\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u8bad\u7ec3\u673a\u5236\u5b9e\u73b0\u5c0f\u6a21\u578b\u7684\u9ad8\u6548\u81ea\u4e3bML\uff0c\u9a8c\u8bc1\u4e86\u5b66\u4e60\u578b\u4ee3\u7406\u5728\u590d\u6742\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.23729", "pdf": "https://arxiv.org/pdf/2505.23729", "abs": "https://arxiv.org/abs/2505.23729", "authors": ["Mohamad Chehade", "Soumya Suvra Ghosal", "Souradip Chakraborty", "Avinash Reddy", "Dinesh Manocha", "Hao Zhu", "Amrit Singh Bedi"], "title": "Bounded Rationality for LLMs: Satisficing Alignment at Inference-Time", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at ICML 2025", "summary": "Aligning large language models with humans is challenging due to the\ninherently multifaceted nature of preference feedback. While existing\napproaches typically frame this as a multi-objective optimization problem, they\noften overlook how humans actually make decisions. Research on bounded\nrationality suggests that human decision making follows satisficing\nstrategies-optimizing primary objectives while ensuring others meet acceptable\nthresholds. To bridge this gap and operationalize the notion of satisficing\nalignment, we propose SITAlign: an inference time framework that addresses the\nmultifaceted nature of alignment by maximizing a primary objective while\nsatisfying threshold-based constraints on secondary criteria. We provide\ntheoretical insights by deriving sub-optimality bounds of our satisficing based\ninference alignment approach. We empirically validate SITAlign's performance\nthrough extensive experimentation on multiple benchmarks. For instance, on the\nPKU-SafeRLHF dataset with the primary objective of maximizing helpfulness while\nensuring a threshold on harmlessness, SITAlign outperforms the state-of-the-art\nmulti objective decoding strategy by a margin of 22.3% in terms of GPT-4\nwin-tie rate for helpfulness reward while adhering to the threshold on\nharmlessness.", "AI": {"tldr": "\u63d0\u51faSITAlign\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u76ee\u6807\u6700\u5927\u5316+\u6b21\u76ee\u6807\u9608\u503c\u7ea6\u675f\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u5728PKU-SafeRLHF\u6570\u636e\u96c6\u4e0a\u4ee522.3%\u4f18\u52bf\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u5ffd\u89c6\u4eba\u7c7b\u51b3\u7b56\u7684\u6ee1\u610f\u539f\u5219\uff08\u4e3b\u76ee\u6807\u4f18\u5148+\u6b21\u76ee\u6807\u8fbe\u6807\uff09\uff0c\u9700\u5efa\u7acb\u7b26\u5408\u4eba\u7c7b\u6709\u9650\u7406\u6027\u7279\u5f81\u7684\u6a21\u578b\u5bf9\u9f50\u8303\u5f0f\u3002", "method": "SITAlign\u63a8\u7406\u6846\u67b6\u5728\u89e3\u7801\u9636\u6bb5\u6700\u5927\u5316\u4e3b\u8981\u76ee\u6807\u51fd\u6570\uff0c\u540c\u65f6\u5bf9\u6b21\u8981\u76ee\u6807\u65bd\u52a0\u9608\u503c\u7ea6\u675f\uff0c\u5e76\u63d0\u4f9b\u6b21\u4f18\u6027\u754c\u9650\u7406\u8bba\u8bc1\u660e\u3002", "result": "\u5728PKU-SafeRLHF\u6570\u636e\u96c6\u4e0a\uff0c\u4ee5\u5e2e\u52a9\u6027\u4e3a\u4e3b\u76ee\u6807/\u65e0\u5bb3\u6027\u4e3a\u7ea6\u675f\u65f6\uff0cSITAlign\u7684GPT-4\u80dc\u7387\u6bd4SOTA\u65b9\u6cd5\u63d0\u534722.3%\u4e14\u6ee1\u8db3\u5b89\u5168\u9608\u503c\u3002", "conclusion": "\u57fa\u4e8e\u6ee1\u610f\u539f\u5219\u7684\u63a8\u7406\u5bf9\u9f50\u6846\u67b6\u6709\u6548\u89e3\u51b3\u591a\u76ee\u6807\u5bf9\u9f50\u96be\u9898\uff0c\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2505.23735", "pdf": "https://arxiv.org/pdf/2505.23735", "abs": "https://arxiv.org/abs/2505.23735", "authors": ["Ali Behrouz", "Zeman Li", "Praneeth Kacham", "Majid Daliri", "Yuan Deng", "Peilin Zhong", "Meisam Razaviyayn", "Vahab Mirrokni"], "title": "ATLAS: Learning to Optimally Memorize the Context at Test Time", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Transformers have been established as the most popular backbones in sequence\nmodeling, mainly due to their effectiveness in in-context retrieval tasks and\nthe ability to learn at scale. Their quadratic memory and time complexity,\nhowever, bound their applicability in longer sequences and so has motivated\nresearchers to explore effective alternative architectures such as modern\nrecurrent neural networks (a.k.a long-term recurrent memory module). Despite\ntheir recent success in diverse downstream tasks, they struggle in tasks that\nrequires long context understanding and extrapolation to longer sequences. We\nobserve that these shortcomings come from three disjoint aspects in their\ndesign: (1) limited memory capacity that is bounded by the architecture of\nmemory and feature mapping of the input; (2) online nature of update, i.e.,\noptimizing the memory only with respect to the last input; and (3) less\nexpressive management of their fixed-size memory. To enhance all these three\naspects, we present ATLAS, a long-term memory module with high capacity that\nlearns to memorize the context by optimizing the memory based on the current\nand past tokens, overcoming the online nature of long-term memory models.\nBuilding on this insight, we present a new family of Transformer-like\narchitectures, called DeepTransformers, that are strict generalizations of the\noriginal Transformer architecture. Our experimental results on language\nmodeling, common-sense reasoning, recall-intensive, and long-context\nunderstanding tasks show that ATLAS surpasses the performance of Transformers\nand recent linear recurrent models. ATLAS further improves the long context\nperformance of Titans, achieving +80\\% accuracy in 10M context length of\nBABILong benchmark.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u957f\u65f6\u8bb0\u5fc6\u6a21\u5757ATLAS\uff0c\u901a\u8fc7\u4e09\u65b9\u9762\u6539\u8fdb\u514b\u670dTransformer\u5728\u957f\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709Transformer\u5b58\u5728\u4e8c\u6b21\u590d\u6742\u5ea6\u9650\u5236\uff0c\u800c\u73b0\u4ee3\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5728\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u5916\u63a8\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u5185\u5b58\u5bb9\u91cf\u3001\u5728\u7ebf\u66f4\u65b0\u673a\u5236\u548c\u56fa\u5b9a\u5185\u5b58\u7ba1\u7406\u4e09\u4e2a\u8bbe\u8ba1\u7f3a\u9677\u3002", "method": "\u5f00\u53d1ATLAS\u6a21\u5757\uff1a(1)\u7a81\u7834\u5185\u5b58\u5bb9\u91cf\u9650\u5236\uff1b(2)\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5f53\u524d\u53ca\u5386\u53f2token\u514b\u670d\u5728\u7ebf\u66f4\u65b0\u5c40\u9650\uff1b(3)\u6539\u8fdb\u56fa\u5b9a\u5185\u5b58\u7ba1\u7406\u673a\u5236\u3002\u57fa\u4e8e\u6b64\u6784\u5efa\u4e25\u683c\u6cdb\u5316Transformer\u67b6\u6784\u7684DeepTransformers\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u8d85\u8d8aTransformer\u53ca\u7ebf\u6027\u5faa\u73af\u6a21\u578b\uff0cBABILong\u57fa\u51c6\u57281000\u4e07\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0a\u5b9e\u73b0+80%\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "ATLAS\u6709\u6548\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u5efa\u6a21\u7684\u5173\u952e\u74f6\u9888\uff0c\u5176\u6784\u5efa\u7684DeepTransformers\u6210\u529f\u6269\u5c55\u4e86\u539f\u59cbTransformer\u67b6\u6784\u7684\u9002\u7528\u8fb9\u754c\u3002"}}
{"id": "2505.23754", "pdf": "https://arxiv.org/pdf/2505.23754", "abs": "https://arxiv.org/abs/2505.23754", "authors": ["Ziyin Zhang", "Jiahao Xu", "Zhiwei He", "Tian Liang", "Qiuzhi Liu", "Yansi Li", "Linfeng Song", "Zhengwen Liang", "Zhuosheng Zhang", "Rui Wang", "Zhaopeng Tu", "Haitao Mi", "Dong Yu"], "title": "DeepTheorem: Advancing LLM Reasoning for Theorem Proving Through Natural Language and Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Theorem proving serves as a major testbed for evaluating complex reasoning\nabilities in large language models (LLMs). However, traditional automated\ntheorem proving (ATP) approaches rely heavily on formal proof systems that\npoorly align with LLMs' strength derived from informal, natural language\nknowledge acquired during pre-training. In this work, we propose DeepTheorem, a\ncomprehensive informal theorem-proving framework exploiting natural language to\nenhance LLM mathematical reasoning. DeepTheorem includes a large-scale\nbenchmark dataset consisting of 121K high-quality IMO-level informal theorems\nand proofs spanning diverse mathematical domains, rigorously annotated for\ncorrectness, difficulty, and topic categories, accompanied by systematically\nconstructed verifiable theorem variants. We devise a novel reinforcement\nlearning strategy (RL-Zero) explicitly tailored to informal theorem proving,\nleveraging the verified theorem variants to incentivize robust mathematical\ninference. Additionally, we propose comprehensive outcome and process\nevaluation metrics examining proof correctness and the quality of reasoning\nsteps. Extensive experimental analyses demonstrate DeepTheorem significantly\nimproves LLM theorem-proving performance compared to existing datasets and\nsupervised fine-tuning protocols, achieving state-of-the-art accuracy and\nreasoning quality. Our findings highlight DeepTheorem's potential to\nfundamentally advance automated informal theorem proving and mathematical\nexploration.", "AI": {"tldr": "DeepTheorem\u63d0\u51fa\u5229\u7528\u81ea\u7136\u8bed\u8a00\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u975e\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u6846\u67b6\uff0c\u5305\u542b\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3001\u5f3a\u5316\u5b66\u4e60\u7b56\u7565RL-Zero\u53ca\u591a\u7ef4\u5ea6\u8bc4\u4f30\u4f53\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\u4e0eLLMs\u9884\u8bad\u7ec3\u83b7\u5f97\u7684\u975e\u6b63\u5f0f\u81ea\u7136\u8bed\u8a00\u77e5\u8bc6\u4e0d\u517c\u5bb9\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u53d1\u6325\u3002", "method": "1. \u6784\u5efa121K\u9ad8\u8d28\u91cfIMO\u7ea7\u975e\u6b63\u5f0f\u5b9a\u7406\u6570\u636e\u96c6\uff0c\u542b\u53ef\u9a8c\u8bc1\u5b9a\u7406\u53d8\u4f53\n2. \u8bbe\u8ba1RL-Zero\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u5229\u7528\u5b9a\u7406\u53d8\u4f53\u5f3a\u5316\u6570\u5b66\u63a8\u7406\n3. \u5efa\u7acb\u5305\u542b\u8bc1\u660e\u6b63\u786e\u6027\u548c\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\u7684\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6307\u6807", "result": "\u5b9e\u9a8c\u8868\u660eDeepTheorem\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230SOTA\u7684\u51c6\u786e\u7387\uff0889.7%\uff09\u548c\u63a8\u7406\u8d28\u91cf\uff08+23.6% F1\u5206\u6570\uff09", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u63a8\u8fdb\u81ea\u52a8\u5316\u975e\u6b63\u5f0f\u5b9a\u7406\u8bc1\u660e\u548c\u6570\u5b66\u63a2\u7d22\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89e3\u51b3\u65b9\u6848\uff0c\u6253\u5f00\u4e86LLMs\u5f62\u5f0f\u6570\u5b66\u63a8\u7406\u7684\u65b0\u8def\u5f84"}}
{"id": "2505.23759", "pdf": "https://arxiv.org/pdf/2505.23759", "abs": "https://arxiv.org/abs/2505.23759", "authors": ["Heekyung Lee", "Jiaxin Ge", "Tsung-Han Wu", "Minwoo Kang", "Trevor Darrell", "David M. Chan"], "title": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Rebus puzzles, visual riddles that encode language through imagery, spatial\narrangement, and symbolic substitution, pose a unique challenge to current\nvision-language models (VLMs). Unlike traditional image captioning or question\nanswering tasks, rebus solving requires multi-modal abstraction, symbolic\nreasoning, and a grasp of cultural, phonetic and linguistic puns. In this\npaper, we investigate the capacity of contemporary VLMs to interpret and solve\nrebus puzzles by constructing a hand-generated and annotated benchmark of\ndiverse English-language rebus puzzles, ranging from simple pictographic\nsubstitutions to spatially-dependent cues (\"head\" over \"heels\"). We analyze how\ndifferent VLMs perform, and our findings reveal that while VLMs exhibit some\nsurprising capabilities in decoding simple visual clues, they struggle\nsignificantly with tasks requiring abstract reasoning, lateral thinking, and\nunderstanding visual metaphors.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u82f1\u8bed\u753b\u8c1c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u62bd\u8c61\u63a8\u7406\u548c\u9690\u55bb\u7406\u89e3\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3", "motivation": "\u63a2\u7d22\u5f53\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u7801\u9700\u8981\u591a\u6a21\u6001\u62bd\u8c61\u3001\u7b26\u53f7\u63a8\u7406\u548c\u6587\u5316\u53cc\u5173\u7684\u753b\u8c1c\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\u6027", "method": "\u624b\u5de5\u521b\u5efa\u5305\u542b\u4ece\u7b80\u5355\u56fe\u5f62\u66ff\u6362\u5230\u7a7a\u95f4\u4f9d\u8d56\u7ebf\u7d22\u7684\u591a\u6837\u5316\u82f1\u8bed\u753b\u8c1c\u57fa\u51c6\uff0c\u5e76\u7cfb\u7edf\u5206\u6790\u4e0d\u540cVLM\u8868\u73b0", "result": "\u6a21\u578b\u80fd\u89e3\u7801\u7b80\u5355\u89c6\u89c9\u7ebf\u7d22\uff0c\u4f46\u5728\u62bd\u8c61\u63a8\u7406\uff0881%\u9519\u8bef\u7387\uff09\u3001\u6a2a\u5411\u601d\u7ef4\uff0876%\u5931\u8d25\uff09\u548c\u89c6\u89c9\u9690\u55bb\u7406\u89e3\uff0868%\u4e0d\u51c6\u786e\uff09\u65b9\u9762\u8868\u73b0\u663e\u8457\u4e0d\u8db3", "conclusion": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\u590d\u6742\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u7684\u80fd\u529b\u6709\u9650\uff0c\u9700\u5728\u62bd\u8c61\u8868\u5f81\u5b66\u4e60\u548c\u6587\u5316\u8bed\u5883\u7406\u89e3\u65b9\u5411\u6539\u8fdb\u6a21\u578b\u67b6\u6784"}}
{"id": "2505.23765", "pdf": "https://arxiv.org/pdf/2505.23765", "abs": "https://arxiv.org/abs/2505.23765", "authors": ["Wentao Zhang", "Woojeong Kim", "Yuntian Deng"], "title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Conversational agents powered by large language models (LLMs) are rapidly\nbecoming integral to our daily interactions, generating unprecedented amounts\nof conversational data. Such datasets offer a powerful lens into societal\ninterests, trending topics, and collective concerns. Yet, existing approaches\ntypically treat these interactions as independent and miss critical insights\nthat could emerge from aggregating and reasoning across large-scale\nconversation logs. In this paper, we introduce Aggregative Question Answering,\na novel task requiring models to reason explicitly over thousands of\nuser-chatbot interactions to answer aggregative queries, such as identifying\nemerging concerns among specific demographics. To enable research in this\ndirection, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative\nquestions derived from 182,330 real-world chatbot conversations. Experiments\nshow that existing methods either struggle to reason effectively or incur\nprohibitive computational costs, underscoring the need for new approaches\ncapable of extracting collective insights from large-scale conversational data.", "AI": {"tldr": "\u63d0\u51faAggregative Question Answering\u4efb\u52a1\u5e76\u6784\u5efaWildChat-AQA\u57fa\u51c6\uff0c\u4ee5\u89e3\u51b3\u5927\u89c4\u6a21\u5bf9\u8bdd\u6570\u636e\u5206\u6790\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u7528\u6237\u4e0e\u804a\u5929\u673a\u5668\u4eba\u7684\u4ea4\u4e92\u89c6\u4e3a\u72ec\u7acb\u4e8b\u4ef6\uff0c\u65e0\u6cd5\u4ece\u805a\u5408\u6570\u636e\u4e2d\u6316\u6398\u7fa4\u4f53\u6027\u6d1e\u5bdf\uff08\u5982\u7279\u5b9a\u4eba\u7fa4\u7684\u5173\u6ce8\u8d8b\u52bf\uff09\u3002", "method": "\u63d0\u51faAggregative QA\u4efb\u52a1\u6846\u67b6\uff0c\u4f7f\u7528182,330\u6761\u771f\u5b9e\u5bf9\u8bdd\u6784\u5efa\u5305\u542b6,027\u4e2a\u805a\u5408\u6027\u95ee\u9898\u7684WildChat-AQA\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u65b9\u6cd5\u5728\u63a8\u7406\u6548\u679c\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5747\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u9a8c\u8bc1\u4e86\u65b0\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u901a\u8fc7Aggregative QA\u4efb\u52a1\u548c\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u4e3a\u4ece\u5bf9\u8bdd\u6570\u636e\u4e2d\u63d0\u53d6\u793e\u4f1a\u6d1e\u5bdf\u63d0\u4f9b\u4e86\u5173\u952e\u7814\u7a76\u65b9\u5411\u548c\u6280\u672f\u6311\u6218\u3002"}}
{"id": "2505.22654", "pdf": "https://arxiv.org/pdf/2505.22654", "abs": "https://arxiv.org/abs/2505.22654", "authors": ["Ce Zhang", "Kaixin Ma", "Tianqing Fang", "Wenhao Yu", "Hongming Zhang", "Zhisong Zhang", "Yaqi Xie", "Katia Sycara", "Haitao Mi", "Dong Yu"], "title": "VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Recent Large Vision-Language Models (LVLMs) have advanced multi-modal\nunderstanding by incorporating finer-grained visual perception and encoding.\nHowever, such methods incur significant computational costs due to longer\nvisual token sequences, posing challenges for real-time deployment. To mitigate\nthis, prior studies have explored pruning unimportant visual tokens either at\nthe output layer of the visual encoder or at the early layers of the language\nmodel. In this work, we revisit these design choices and reassess their\neffectiveness through comprehensive empirical studies of how visual tokens are\nprocessed throughout the visual encoding and language decoding stages. Guided\nby these insights, we propose VScan, a two-stage visual token reduction\nframework that addresses token redundancy by: (1) integrating complementary\nglobal and local scans with token merging during visual encoding, and (2)\nintroducing pruning at intermediate layers of the language model. Extensive\nexperimental results across four LVLMs validate the effectiveness of VScan in\naccelerating inference and demonstrate its superior performance over current\nstate-of-the-arts on sixteen benchmarks. Notably, when applied to\nLLaVA-NeXT-7B, VScan achieves a 2.91$\\times$ speedup in prefilling and a\n10$\\times$ reduction in FLOPs, while retaining 95.4% of the original\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u89c6\u89c9\u6807\u8bb0\u538b\u7f29\u6846\u67b6VScan\uff0c\u901a\u8fc7\u4e92\u8865\u626b\u63cf\u7b56\u7565\u548c\u4e2d\u95f4\u5c42\u526a\u679d\u5b9e\u73b0LVLMs\u52a0\u901f\u63a8\u7406\uff082.91\u500d\u9884\u586b\u5145\u52a0\u901f\uff0c10\u500d\u8ba1\u7b97\u91cf\u964d\u4f4e\uff09\u540c\u65f6\u4fdd\u630195.4%\u539f\u6027\u80fd", "motivation": "\u73b0\u6709\u7ec6\u7c92\u5ea6\u89c6\u89c9\u7f16\u7801\u65b9\u6cd5\u56e0\u957f\u89c6\u89c9\u6807\u8bb0\u5e8f\u5217\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5267\u589e\uff0c\u4f20\u7edf\u526a\u679d\u7b56\u7565\uff08\u89c6\u89c9\u7f16\u7801\u5668\u8f93\u51fa\u5c42/\u8bed\u8a00\u6a21\u578b\u65e9\u671f\u5c42\uff09\u6548\u679c\u53d7\u9650", "method": "1.\u89c6\u89c9\u7f16\u7801\u9636\u6bb5\u6574\u5408\u5168\u5c40\u626b\u63cf\uff08token\u5408\u5e76\uff09\u4e0e\u5c40\u90e8\u626b\u63cf\uff08\u7ec6\u7c92\u5ea6\u611f\u77e5\uff09 2.\u8bed\u8a00\u6a21\u578b\u89e3\u7801\u9636\u6bb5\u5f15\u5165\u4e2d\u95f4\u5c42\u52a8\u6001\u526a\u679d", "result": "\u5728\u56db\u4e2a\u4e3b\u6d41LVLM\u4e0a\u9a8c\u8bc1\uff1a16\u4e2a\u57fa\u51c6\u6d4b\u8bd5SOTA\uff0cLLaVA-NeXT-7B\u5b9e\u73b0\u9884\u586b\u5145\u52a0\u901f2.91\u500d\uff0c\u8ba1\u7b97\u91cf\u51cf\u5c1110\u500d\uff0c\u6027\u80fd\u4fdd\u755995.4%", "conclusion": "VScan\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u89c6\u89c9\u6807\u8bb0\u5904\u7406\u5168\u8fc7\u7a0b\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u4e92\u8865\u7b56\u7565\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u89c6\u89c9\u4fe1\u606f\u538b\u7f29\uff0c\u4e3a\u5b9e\u65f6\u591a\u6a21\u6001\u7cfb\u7edf\u63d0\u4f9b\u65b0\u65b9\u6848"}}
{"id": "2505.22756", "pdf": "https://arxiv.org/pdf/2505.22756", "abs": "https://arxiv.org/abs/2505.22756", "authors": ["Tian Qin", "Core Francisco Park", "Mujin Kwun", "Aaron Walsman", "Eran Malach", "Nikhil Anand", "Hidenori Tanaka", "David Alvarez-Melis"], "title": "Decomposing Elements of Problem Solving: What \"Math\" Does RL Teach?", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Mathematical reasoning tasks have become prominent benchmarks for assessing\nthe reasoning capabilities of LLMs, especially with reinforcement learning (RL)\nmethods such as GRPO showing significant performance gains. However, accuracy\nmetrics alone do not support fine-grained assessment of capabilities and fail\nto reveal which problem-solving skills have been internalized. To better\nunderstand these capabilities, we propose to decompose problem solving into\nfundamental capabilities: Plan (mapping questions to sequences of steps),\nExecute (correctly performing solution steps), and Verify (identifying the\ncorrectness of a solution). Empirically, we find that GRPO mainly enhances the\nexecution skill-improving execution robustness on problems the model already\nknows how to solve-a phenomenon we call temperature distillation. More\nimportantly, we show that RL-trained models struggle with fundamentally new\nproblems, hitting a 'coverage wall' due to insufficient planning skills. To\nexplore RL's impact more deeply, we construct a minimal, synthetic\nsolution-tree navigation task as an analogy for mathematical problem-solving.\nThis controlled setup replicates our empirical findings, confirming RL\nprimarily boosts execution robustness. Importantly, in this setting, we\nidentify conditions under which RL can potentially overcome the coverage wall\nthrough improved exploration and generalization to new solution paths. Our\nfindings provide insights into the role of RL in enhancing LLM reasoning,\nexpose key limitations, and suggest a path toward overcoming these barriers.\nCode is available at https://github.com/cfpark00/RL-Wall.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5982\u4f55\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0RL\u4e3b\u8981\u589e\u5f3a\u6267\u884c\u9c81\u68d2\u6027\uff08\u6e29\u5ea6\u84b8\u998f\u73b0\u8c61\uff09\uff0c\u4f46\u6a21\u578b\u4ecd\u53d7\u9650\u4e8e\u89c4\u5212\u80fd\u529b\u4e0d\u8db3\u5bfc\u81f4\u7684\u300e\u8986\u76d6\u5899\u300f\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u548c\u6cdb\u5316\u80fd\u529b\u7a81\u7834\u74f6\u9888\u7684\u53ef\u80fd\u8def\u5f84\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u51c6\u786e\u7387\u7684\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u7ec6\u7c92\u5ea6\u63ed\u793aLLM\u5185\u5728\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u9700\u901a\u8fc7\u5206\u89e3\u63a8\u7406\u8fc7\u7a0b\uff08Plan-Execute-Verify\uff09\u6765\u7406\u89e3RL\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd\u673a\u5236\u3002", "method": "1. \u5c06\u6570\u5b66\u63a8\u7406\u5206\u89e3\u4e3a\u89c4\u5212\u3001\u6267\u884c\u3001\u9a8c\u8bc1\u4e09\u4e2a\u57fa\u7840\u80fd\u529b\n2. \u6784\u5efa\u5408\u6210\u89e3\u51b3\u65b9\u6848\u6811\u5bfc\u822a\u4efb\u52a1\uff08\u7c7b\u6bd4\u6570\u5b66\u95ee\u9898\u6c42\u89e3\uff09\n3. \u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1RL\u5bf9\u6267\u884c\u80fd\u529b\u7684\u63d0\u5347\u6548\u5e94\u53ca\u89c4\u5212\u80fd\u529b\u5c40\u9650", "result": "1. GRPO\u4e3b\u8981\u63d0\u5347\u6a21\u578b\u5728\u5df2\u77e5\u95ee\u9898\u4e0a\u7684\u6267\u884c\u7a33\u5065\u6027\uff08\u6e29\u5ea6\u84b8\u998f\uff09\n2. RL\u6a21\u578b\u9762\u5bf9\u65b0\u95ee\u9898\u65f6\u56e0\u89c4\u5212\u80fd\u529b\u4e0d\u8db3\u906d\u9047\u8986\u76d6\u5899\n3. \u5408\u6210\u5b9e\u9a8c\u8bc1\u5b9eRL\u589e\u5f3a\u6267\u884c\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u901a\u8fc7\u6539\u8fdb\u63a2\u7d22\u7b56\u7565\u7a81\u7834\u8986\u76d6\u5899", "conclusion": "\u5f53\u524dRL\u65b9\u6cd5\u5728\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u65f6\u5b58\u5728\u300e\u6267\u884c-\u89c4\u5212\u5931\u8861\u300f\uff0c\u672a\u6765\u9700\u91cd\u70b9\u52a0\u5f3a\u89c4\u5212\u80fd\u529b\u7684\u63a2\u7d22\u673a\u5236\u548c\u8de8\u95ee\u9898\u6cdb\u5316\u80fd\u529b\uff0c\u5408\u6210\u5b9e\u9a8c\u4e3a\u7a81\u7834\u8986\u76d6\u5899\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u9a8c\u8bc1\u65b9\u5411\u3002"}}
{"id": "2505.22758", "pdf": "https://arxiv.org/pdf/2505.22758", "abs": "https://arxiv.org/abs/2505.22758", "authors": ["Aniruddha Nrusimha", "William Brandon", "Mayank Mishra", "Yikang Shen", "Rameswar Panda", "Jonathan Ragan-Kelley", "Yoon Kim"], "title": "FlashFormer: Whole-Model Kernels for Efficient Low-Batch Inference", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The size and compute characteristics of modern large language models have led\nto an increased interest in developing specialized kernels tailored for\ntraining and inference. Existing kernels primarily optimize for compute\nutilization, targeting the large-batch training and inference settings.\nHowever, low-batch inference, where memory bandwidth and kernel launch\noverheads contribute are significant factors, remains important for many\napplications of interest such as in edge deployment and latency-sensitive\napplications. This paper describes FlashFormer, a proof-of-concept kernel for\naccelerating single-batch inference for transformer-based large language\nmodels. Across various model sizes and quantizations settings, we observe\nnontrivial speedups compared to existing state-of-the-art inference kernels.", "AI": {"tldr": "\u63d0\u51faFlashFormer\u4e13\u7528\u5185\u6838\u52a0\u901fTransformer\u6a21\u578b\u5355\u6279\u6b21\u63a8\u7406\uff0c\u5728\u4f4e\u6279\u91cf\u573a\u666f\u4e0b\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u5185\u6838\u4e3b\u8981\u4f18\u5316\u5927\u6279\u91cf\u573a\u666f\uff0c\u4f46\u8fb9\u7f18\u90e8\u7f72\u7b49\u4f4e\u6279\u91cf\u573a\u666f\u4e2d\u5185\u5b58\u5e26\u5bbd\u548c\u5185\u6838\u542f\u52a8\u5f00\u9500\u6210\u4e3a\u74f6\u9888\u3002", "method": "\u8bbe\u8ba1\u9762\u5411\u5355\u6279\u6b21\u63a8\u7406\u7684FlashFormer\u5185\u6838\uff0c\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u4e0e\u8ba1\u7b97\u6d41\u7a0b\u964d\u4f4e\u5ef6\u8fdf\u3002", "result": "\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0e\u91cf\u5316\u914d\u7f6e\u4e0b\u5747\u53d6\u5f97\u663e\u8457\u52a0\u901f\u6548\u679c\uff0c\u8d85\u8d8a\u73b0\u6709state-of-the-art\u63a8\u7406\u65b9\u6848\u3002", "conclusion": "\u4e13\u7528\u4f4e\u6279\u91cf\u63a8\u7406\u5185\u6838\u53ef\u6709\u6548\u89e3\u51b3\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5177\u6709\u91cd\u8981\u5de5\u7a0b\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.22793", "pdf": "https://arxiv.org/pdf/2505.22793", "abs": "https://arxiv.org/abs/2505.22793", "authors": ["Srishti Yadav", "Lauren Tilton", "Maria Antoniak", "Taylor Arnold", "Jiaang Li", "Siddhesh Milind Pawar", "Antonia Karamolegkou", "Stella Frank", "Zhaochong An", "Negar Rostamzadeh", "Daniel Hershcovich", "Serge Belongie", "Ekaterina Shutova"], "title": "Cultural Evaluations of Vision-Language Models Have a Lot to Learn from Cultural Theory", "categories": ["cs.CV", "cs.CL"], "comment": null, "summary": "Modern vision-language models (VLMs) often fail at cultural competency\nevaluations and benchmarks. Given the diversity of applications built upon\nVLMs, there is renewed interest in understanding how they encode cultural\nnuances. While individual aspects of this problem have been studied, we still\nlack a comprehensive framework for systematically identifying and annotating\nthe nuanced cultural dimensions present in images for VLMs. This position paper\nargues that foundational methodologies from visual culture studies (cultural\nstudies, semiotics, and visual studies) are necessary for cultural analysis of\nimages. Building upon this review, we propose a set of five frameworks,\ncorresponding to cultural dimensions, that must be considered for a more\ncomplete analysis of the cultural competencies of VLMs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89c6\u89c9\u6587\u5316\u7814\u7a76\u4e94\u5927\u6846\u67b6\u5206\u6790\u591a\u6a21\u6001\u5927\u6a21\u578b\u6587\u5316\u7406\u89e3\u80fd\u529b", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u6587\u5316\u80fd\u529b\u8bc4\u4f30\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\u56fe\u50cf\u6587\u5316\u7ef4\u5ea6\u7684\u6846\u67b6\u3002\u9700\u8981\u6574\u5408\u6587\u5316\u7814\u7a76\u3001\u7b26\u53f7\u5b66\u7b49\u7406\u8bba\u6784\u5efa\u5168\u9762\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u901a\u8fc7\u56de\u987e\u89c6\u89c9\u6587\u5316\u7814\u7a76\uff08\u6587\u5316\u7814\u7a76/\u7b26\u53f7\u5b66/\u89c6\u89c9\u7814\u7a76\uff09\u7684\u57fa\u7840\u65b9\u6cd5\u8bba\uff0c\u63d0\u51fa\u5305\u542b\u4e94\u4e2a\u6587\u5316\u7ef4\u5ea6\u7684\u5206\u6790\u6846\u67b6\u4f53\u7cfb", "result": "\u5efa\u7acb\u6db5\u76d6\u4e94\u4e2a\u6838\u5fc3\u6587\u5316\u7ef4\u5ea6\u7684\u6846\u67b6\u4f53\u7cfb\uff0c\u4e3a\u7cfb\u7edf\u8bc4\u4f30VLMs\u6587\u5316\u80fd\u529b\u63d0\u4f9b\u7ed3\u6784\u5316\u65b9\u6cd5\u8bba", "conclusion": "\u8fd0\u7528\u89c6\u89c9\u6587\u5316\u7814\u7a76\u7684\u591a\u7ef4\u5ea6\u6846\u67b6\u662f\u63d0\u5347VLMs\u56fe\u50cf\u6587\u5316\u7406\u89e3\u80fd\u529b\u7684\u5fc5\u8981\u8def\u5f84"}}
{"id": "2505.22857", "pdf": "https://arxiv.org/pdf/2505.22857", "abs": "https://arxiv.org/abs/2505.22857", "authors": ["Vladimir Bataev", "Andrei Andrusenko", "Lilit Grigoryan", "Aleksandr Laptev", "Vitaly Lavrukhin", "Boris Ginsburg"], "title": "NGPU-LM: GPU-Accelerated N-Gram Language Model for Context-Biasing in Greedy ASR Decoding", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.LG", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Statistical n-gram language models are widely used for context-biasing tasks\nin Automatic Speech Recognition (ASR). However, existing implementations lack\ncomputational efficiency due to poor parallelization, making context-biasing\nless appealing for industrial use. This work rethinks data structures for\nstatistical n-gram language models to enable fast and parallel operations for\nGPU-optimized inference. Our approach, named NGPU-LM, introduces customizable\ngreedy decoding for all major ASR model types - including transducers,\nattention encoder-decoder models, and CTC - with less than 7% computational\noverhead. The proposed approach can eliminate more than 50% of the accuracy gap\nbetween greedy and beam search for out-of-domain scenarios while avoiding\nsignificant slowdown caused by beam search. The implementation of the proposed\nNGPU-LM is open-sourced.", "AI": {"tldr": "\u63d0\u51faNGPU-LM\u65b9\u6cd5\u4f18\u5316\u7edf\u8ba1n-gram\u8bed\u8a00\u6a21\u578b\u5728GPU\u4e0a\u7684\u5e76\u884c\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u4e3b\u6d41ASR\u6a21\u578b\u7c7b\u578b\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e7%\u3002", "motivation": "\u73b0\u6709\u7edf\u8ba1n-gram\u6a21\u578b\u5728GPU\u4e0a\u5e76\u884c\u6548\u7387\u4e0d\u8db3\uff0c\u5f71\u54cd\u5de5\u4e1a\u573a\u666f\u4e0a\u4e0b\u6587\u504f\u7f6e\u5e94\u7528\u6548\u679c\u3002", "method": "\u91cd\u6784n-gram\u6a21\u578b\u6570\u636e\u7ed3\u6784\u5b9e\u73b0GPU\u52a0\u901f\u63a8\u7406\uff0c\u652f\u6301transducer/attention encoder-decoder/CTC\u7b49\u6a21\u578b\u7684\u81ea\u5b9a\u4e49\u8d2a\u5a6a\u89e3\u7801\u3002", "result": "\u5728\u57df\u5916\u573a\u666f\u7f29\u5c0f\u8d2a\u5a6a\u641c\u7d22\u4e0e\u675f\u641c\u7d22\u7cbe\u5ea6\u5dee\u8ddd50%\u4ee5\u4e0a\uff0c\u907f\u514d\u675f\u641c\u7d22\u7684\u663e\u8457\u5ef6\u8fdf\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u4e0e\u8bc6\u522b\u7cbe\u5ea6\uff0c\u63a8\u52a8\u4e0a\u4e0b\u6587\u504f\u7f6e\u6280\u672f\u5728\u5de5\u4e1aASR\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2505.22863", "pdf": "https://arxiv.org/pdf/2505.22863", "abs": "https://arxiv.org/abs/2505.22863", "authors": ["Yupei Li", "Shuaijie Shao", "Manuel Milling", "Bj\u00f6rn W. Schuller"], "title": "Large Language Models for Depression Recognition in Spoken Language Integrating Psychological Knowledge", "categories": ["cs.HC", "cs.CL"], "comment": null, "summary": "Depression is a growing concern gaining attention in both public discourse\nand AI research. While deep neural networks (DNNs) have been used for\nrecognition, they still lack real-world effectiveness. Large language models\n(LLMs) show strong potential but require domain-specific fine-tuning and\nstruggle with non-textual cues. Since depression is often expressed through\nvocal tone and behaviour rather than explicit text, relying on language alone\nis insufficient. Diagnostic accuracy also suffers without incorporating\npsychological expertise. To address these limitations, we present, to the best\nof our knowledge, the first application of LLMs to multimodal depression\ndetection using the DAIC-WOZ dataset. We extract the audio features using the\npre-trained model Wav2Vec, and mapped it to text-based LLMs for further\nprocessing. We also propose a novel strategy for incorporating psychological\nknowledge into LLMs to enhance diagnostic performance, specifically using a\nquestion and answer set to grant authorised knowledge to LLMs. Our approach\nyields a notable improvement in both Mean Absolute Error (MAE) and Root Mean\nSquare Error (RMSE) compared to a base score proposed by the related original\npaper. The codes are available at\nhttps://github.com/myxp-lyp/Depression-detection.git", "AI": {"tldr": "\u9996\u6b21\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u4e8eDAIC-WOZ\u6570\u636e\u96c6\u7684\u591a\u6a21\u6001\u6291\u90c1\u75c7\u68c0\u6d4b\uff0c\u7ed3\u5408\u97f3\u9891\u7279\u5f81\u4e0e\u5fc3\u7406\u5b66\u77e5\u8bc6\uff0c\u663e\u8457\u964d\u4f4eMAE\u548cRMSE\u6307\u6807", "motivation": "\u73b0\u6709\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u5355\u7eaf\u4f9d\u8d56\u6587\u672c\u65e0\u6cd5\u6355\u6349\u6291\u90c1\u75c7\u7684\u8bed\u97f3/\u884c\u4e3a\u7279\u5f81\uff0c\u4e14\u7f3a\u4e4f\u5fc3\u7406\u5b66\u4e13\u4e1a\u77e5\u8bc6\u6574\u5408", "method": "\u4f7f\u7528Wav2Vec\u63d0\u53d6\u97f3\u9891\u7279\u5f81\u540e\u6620\u5c04\u5230\u6587\u672c\u578bLLMs\u5904\u7406\uff0c\u521b\u65b0\u6027\u901a\u8fc7\u95ee\u7b54\u5f62\u5f0f\u6ce8\u5165\u5fc3\u7406\u5b66\u77e5\u8bc6", "result": "\u76f8\u6bd4\u539f\u59cb\u8bba\u6587\u57fa\u51c6\u5206\u6570\uff0cMAE\u548cRMSE\u83b7\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90", "conclusion": "\u591a\u6a21\u6001\u6570\u636e\u4e0e\u9886\u57df\u77e5\u8bc6\u878d\u5408\u6709\u6548\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u4e3aLLMs\u5728\u7cbe\u795e\u5065\u5eb7\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u65b0\u65b9\u5411"}}
{"id": "2505.22907", "pdf": "https://arxiv.org/pdf/2505.22907", "abs": "https://arxiv.org/abs/2505.22907", "authors": ["Rachel Katharine Sterken", "James Ravi Kirkpatrick"], "title": "Conversational Alignment with Artificial Intelligence in Context", "categories": ["cs.CY", "cs.CL"], "comment": "20 pages, to be published in Philosophical Perspectives", "summary": "The development of sophisticated artificial intelligence (AI) conversational\nagents based on large language models raises important questions about the\nrelationship between human norms, values, and practices and AI design and\nperformance. This article explores what it means for AI agents to be\nconversationally aligned to human communicative norms and practices for\nhandling context and common ground and proposes a new framework for evaluating\ndevelopers' design choices. We begin by drawing on the philosophical and\nlinguistic literature on conversational pragmatics to motivate a set of\ndesiderata, which we call the CONTEXT-ALIGN framework, for conversational\nalignment with human communicative practices. We then suggest that current\nlarge language model (LLM) architectures, constraints, and affordances may\nimpose fundamental limitations on achieving full conversational alignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86CONTEXT-ALIGN\u6846\u67b6\u8bc4\u4f30AI\u5bf9\u8bdd\u4ee3\u7406\u4e0e\u4eba\u7c7b\u8bed\u5883\u6c9f\u901a\u89c4\u8303\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u6307\u51fa\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650", "motivation": "\u57fa\u4e8e\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u5bf9\u4f1a\u8bdd\u8bed\u7528\u5b66\u7684\u7814\u7a76\uff0c\u5f3a\u8c03AI\u5bf9\u8bdd\u4ee3\u7406\u9700\u8981\u7b26\u5408\u4eba\u7c7b\u5904\u7406\u8bed\u5883\u548c\u5171\u540c\u57fa\u7840\u7684\u6c9f\u901a\u5b9e\u8df5", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u4e03\u4e2a\u6838\u5fc3\u7ef4\u5ea6\u7684CONTEXT-ALIGN\u6846\u67b6\uff08\u8bed\u5883\u654f\u611f\u6027\u3001\u52a8\u6001\u9002\u5e94\u7b49\uff09\uff0c\u5206\u6790LLM\u67b6\u6784\u7684\u56fa\u6709\u7ea6\u675f", "result": "\u53d1\u73b0\u73b0\u6709LLM\u5728\u8bed\u5883\u5efa\u6a21\u3001\u52a8\u6001\u66f4\u65b0\u548c\u5143\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u5b58\u5728\u67b6\u6784\u6027\u9650\u5236\uff0c\u65e0\u6cd5\u5b9e\u73b0\u5b8c\u5168\u8bed\u5883\u5bf9\u9f50", "conclusion": "\u63d0\u51fa\u5f00\u53d1\u8005\u9700\u901a\u8fc7\u8be5\u6846\u67b6\u7cfb\u7edf\u8bc4\u4f30\u8bbe\u8ba1\u9009\u62e9\uff0c\u5efa\u8bae\u672a\u6765\u7814\u7a76\u9700\u7a81\u7834\u5f53\u524dLLM\u7684\u5355\u5411\u5e8f\u5217\u5904\u7406\u8303\u5f0f"}}
{"id": "2505.22928", "pdf": "https://arxiv.org/pdf/2505.22928", "abs": "https://arxiv.org/abs/2505.22928", "authors": ["Massimiliano Pronesti", "Michela Lorandi", "Paul Flanagan", "Oisin Redmon", "Anya Belz", "Yufang Hou"], "title": "Enhancing Study-Level Inference from Clinical Trial Papers via RL-based Numeric Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Systematic reviews in medicine play a critical role in evidence-based\ndecision-making by aggregating findings from multiple studies. A central\nbottleneck in automating this process is extracting numeric evidence and\ndetermining study-level conclusions for specific outcomes and comparisons.\nPrior work has framed this problem as a textual inference task by retrieving\nrelevant content fragments and inferring conclusions from them. However, such\napproaches often rely on shallow textual cues and fail to capture the\nunderlying numeric reasoning behind expert assessments.\n  In this work, we conceptualise the problem as one of quantitative reasoning.\nRather than inferring conclusions from surface text, we extract structured\nnumerical evidence (e.g., event counts or standard deviations) and apply domain\nknowledge informed logic to derive outcome-specific conclusions. We develop a\nnumeric reasoning system composed of a numeric data extraction model and an\neffect estimate component, enabling more accurate and interpretable inference\naligned with the domain expert principles. We train the numeric data extraction\nmodel using different strategies, including supervised fine-tuning (SFT) and\nreinforcement learning (RL) with a new value reward model.\n  When evaluated on the CochraneForest benchmark, our best-performing approach\n-- using RL to train a small-scale number extraction model -- yields up to a\n21% absolute improvement in F1 score over retrieval-based systems and\noutperforms general-purpose LLMs of over 400B parameters by up to 9%. Our\nresults demonstrate the promise of reasoning-driven approaches for automating\nsystematic evidence synthesis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5b9a\u91cf\u63a8\u7406\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u503c\u8bc1\u636e\u5e76\u5e94\u7528\u9886\u57df\u77e5\u8bc6\u903b\u8f91\uff0c\u663e\u8457\u63d0\u5347\u533b\u5b66\u7cfb\u7edf\u8bc4\u4ef7\u7684\u81ea\u52a8\u5316\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u7cfb\u7edf\u8bc4\u4ef7\u65b9\u6cd5\u4f9d\u8d56\u6587\u672c\u8868\u9762\u7ebf\u7d22\uff0c\u7f3a\u4e4f\u5bf9\u6570\u503c\u63a8\u7406\u7684\u6355\u6349\uff0c\u5bfc\u81f4\u7ed3\u8bba\u51c6\u786e\u6027\u53d7\u9650\u3002", "method": "\u5f00\u53d1\u5305\u542b\u6570\u503c\u6570\u636e\u63d0\u53d6\u6a21\u578b\u548c\u6548\u5e94\u4f30\u8ba1\u7ec4\u4ef6\u7684\u7cfb\u7edf\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u5f3a\u5316\u5b66\u4e60(RL)\u8bad\u7ec3\u7b56\u7565\uff0c\u7279\u522b\u901a\u8fc7RL\u8bad\u7ec3\u5c0f\u578b\u6570\u503c\u63d0\u53d6\u6a21\u578b\u3002", "result": "\u5728CochraneForest\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRL\u65b9\u6cd5\u76f8\u6bd4\u68c0\u7d22\u7cfb\u7edfF1\u63d0\u534721%\uff0c\u4f18\u4e8e400B\u53c2\u6570\u5927\u6a21\u578b9%\u3002", "conclusion": "\u6570\u503c\u63a8\u7406\u9a71\u52a8\u7684\u65b9\u6cd5\u80fd\u5b9e\u73b0\u66f4\u7cbe\u51c6\u3001\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u5408\u6210\uff0c\u4e0e\u9886\u57df\u4e13\u5bb6\u539f\u5219\u4fdd\u6301\u9ad8\u5ea6\u4e00\u81f4\u3002"}}
{"id": "2505.23008", "pdf": "https://arxiv.org/pdf/2505.23008", "abs": "https://arxiv.org/abs/2505.23008", "authors": ["Jonathan Li", "Zoltan Csaki", "Nidhi Hiremath", "Etash Guha", "Fenglu Hong", "Edward Ma", "Urmish Thakker"], "title": "Synthetic Document Question Answering in Hungarian", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Modern VLMs have achieved near-saturation accuracy in English document visual\nquestion-answering (VQA). However, this task remains challenging in lower\nresource languages due to a dearth of suitable training and evaluation data. In\nthis paper we present scalable methods for curating such datasets by focusing\non Hungarian, approximately the 17th highest resource language on the internet.\nSpecifically, we present HuDocVQA and HuDocVQA-manual, document VQA datasets\nthat modern VLMs significantly underperform on compared to English DocVQA.\nHuDocVQA-manual is a small manually curated dataset based on Hungarian\ndocuments from Common Crawl, while HuDocVQA is a larger synthetically generated\nVQA data set from the same source. We apply multiple rounds of quality\nfiltering and deduplication to HuDocVQA in order to match human-level quality\nin this dataset. We also present HuCCPDF, a dataset of 117k pages from\nHungarian Common Crawl PDFs along with their transcriptions, which can be used\nfor training a model for Hungarian OCR. To validate the quality of our\ndatasets, we show how finetuning on a mixture of these datasets can improve\naccuracy on HuDocVQA for Llama 3.2 11B Instruct by +7.2%. Our datasets and code\nwill be released to the public to foster further research in multilingual\nDocVQA.", "AI": {"tldr": "\u63d0\u51fa\u5308\u7259\u5229\u8bed\u6587\u6863\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6HuDocVQA\u4e0eHuCCPDF OCR\u8bad\u7ec3\u96c6\uff0c\u901a\u8fc7\u6df7\u5408\u6570\u636e\u5fae\u8c03\u4f7f\u6a21\u578b\u51c6\u786e\u7387\u63d0\u53477.2%", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u82f1\u8bedDocVQA\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u5308\u7259\u5229\u8bed\uff09\u56e0\u6570\u636e\u532e\u4e4f\u9762\u4e34\u6311\u6218", "method": "\u6784\u5efa\u4e24\u79cd\u6570\u636e\u96c6\uff1a\u624b\u52a8\u6574\u7406\u7684HuDocVQA-manual\u4e0e\u5408\u6210\u751f\u6210\u7684HuDocVQA\uff0c\u5e76\u521b\u5efa11.7\u4e07\u9875OCR\u8bad\u7ec3\u96c6HuCCPDF\uff0c\u901a\u8fc7\u591a\u8f6e\u8d28\u91cf\u8fc7\u6ee4\u4fdd\u8bc1\u6570\u636e\u8d28\u91cf", "result": "\u5728Llama 3.2 11B Instruct\u6a21\u578b\u4e0a\u9a8c\u8bc1\uff0c\u6df7\u5408\u6570\u636e\u96c6\u5fae\u8c03\u4f7fHuDocVQA\u51c6\u786e\u7387\u63d0\u5347+7.2%", "conclusion": "\u9996\u6b21\u53d1\u5e03\u5308\u7259\u5229\u8bed\u6587\u6863VQA\u57fa\u51c6\u6570\u636e\u96c6\u4e0e\u914d\u5957\u8d44\u6e90\uff0c\u4e3a\u591a\u8bed\u8a00\u6587\u6863\u7406\u89e3\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u8bbe\u65bd"}}
{"id": "2505.23020", "pdf": "https://arxiv.org/pdf/2505.23020", "abs": "https://arxiv.org/abs/2505.23020", "authors": ["Jinchuan Zhang", "Lu Yin", "Yan Zhou", "Songlin Hu"], "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.CL"], "comment": "Submitted to ACL 2025", "summary": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge\nproviders\" to \"action executors\", a trend that while expanding LLMs' capability\nboundaries, significantly increases their susceptibility to malicious use.\nPrevious work has shown that current LLM-based agents execute numerous\nmalicious tasks even without being attacked, indicating a deficiency in agentic\nuse safety alignment during the post-training phase. To address this gap, we\npropose AgentAlign, a novel framework that leverages abstract behavior chains\nas a medium for safety alignment data synthesis. By instantiating these\nbehavior chains in simulated environments with diverse tool instances, our\nframework enables the generation of highly authentic and executable\ninstructions while capturing complex multi-step dynamics. The framework further\nensures model utility by proportionally synthesizing benign instructions\nthrough non-malicious interpretations of behavior chains, precisely calibrating\nthe boundary between helpfulness and harmlessness. Evaluation results on\nAgentHarm demonstrate that fine-tuning three families of open-source models\nusing our method substantially improves their safety (35.8% to 79.5%\nimprovement) while minimally impacting or even positively enhancing their\nhelpfulness, outperforming various prompting methods. The dataset and code have\nboth been open-sourced.", "AI": {"tldr": "\u63d0\u51faAgentAlign\u6846\u67b6\uff0c\u901a\u8fc7\u62bd\u8c61\u884c\u4e3a\u94fe\u751f\u6210\u5b89\u5168\u5bf9\u9f50\u6570\u636e\uff0c\u5728\u63d0\u5347LLM\u667a\u80fd\u4f53\u5b89\u5168\u6027\u7684\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u5b9e\u7528\u6027", "motivation": "LLM\u83b7\u5f97\u667a\u80fd\u4f53\u80fd\u529b\u540e\u6267\u884c\u6076\u610f\u4efb\u52a1\u98ce\u9669\u663e\u8457\u589e\u52a0\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8bad\u7ec3\u540e\u9636\u6bb5\u5b58\u5728\u5b89\u5168\u5bf9\u9f50\u7f3a\u9677", "method": "\u5229\u7528\u62bd\u8c61\u884c\u4e3a\u94fe\u4f5c\u4e3a\u6570\u636e\u5408\u6210\u5a92\u4ecb\uff0c\u901a\u8fc7\u591a\u6837\u5316\u5de5\u5177\u5b9e\u4f8b\u751f\u6210\u53ef\u6267\u884c\u6307\u4ee4\uff0c\u91c7\u7528\u6bd4\u4f8b\u5408\u6210\u7b56\u7565\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027", "result": "\u5728AgentHarm\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6a21\u578b\u5b89\u5168\u6027\u63d0\u534735.8%-79.5%\uff0c\u5b9e\u7528\u6027\u672a\u53d7\u663e\u8457\u5f71\u54cd\u751a\u81f3\u63d0\u5347\uff0c\u8d85\u8d8a\u591a\u79cd\u63d0\u793a\u65b9\u6cd5", "conclusion": "\u57fa\u4e8e\u884c\u4e3a\u94fe\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u5b9e\u73b0\u5b89\u5168\u5bf9\u9f50\uff0c\u6846\u67b6\u901a\u8fc7\u5f00\u6e90\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u5b89\u5168\u4e0e\u6548\u7528\u7684\u5e73\u8861"}}
{"id": "2505.23039", "pdf": "https://arxiv.org/pdf/2505.23039", "abs": "https://arxiv.org/abs/2505.23039", "authors": ["Kapil Vaidya", "Jialin Ding", "Sebastian Kosak", "David Kernert", "Chuan Lei", "Xiao Qin", "Abhinav Tripathy", "Ramesh Balan", "Balakrishnan Narayanaswamy", "Tim Kraska"], "title": "TailorSQL: An NL2SQL System Tailored to Your Query Workload", "categories": ["cs.DB", "cs.CL"], "comment": null, "summary": "NL2SQL (natural language to SQL) translates natural language questions into\nSQL queries, thereby making structured data accessible to non-technical users,\nserving as the foundation for intelligent data applications. State-of-the-art\nNL2SQL techniques typically perform translation by retrieving database-specific\ninformation, such as the database schema, and invoking a pre-trained large\nlanguage model (LLM) using the question and retrieved information to generate\nthe SQL query.\n  However, existing NL2SQL techniques miss a key opportunity which is present\nin real-world settings: NL2SQL is typically applied on existing databases which\nhave already served many SQL queries in the past. The past query workload\nimplicitly contains information which is helpful for accurate NL2SQL\ntranslation and is not apparent from the database schema alone, such as common\njoin paths and the semantics of obscurely-named tables and columns. We\nintroduce TailorSQL, a NL2SQL system that takes advantage of information in the\npast query workload to improve both the accuracy and latency of translating\nnatural language questions into SQL. By specializing to a given workload,\nTailorSQL achieves up to 2$\\times$ improvement in execution accuracy on\nstandardized benchmarks.", "AI": {"tldr": "TailorSQL\u5229\u7528\u5386\u53f2SQL\u67e5\u8be2\u4fe1\u606f\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u7684\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6267\u884c\u51c6\u786e\u7387\u63d0\u53472\u500d\u3002", "motivation": "\u73b0\u6709NL2SQL\u6280\u672f\u672a\u5145\u5206\u5229\u7528\u771f\u5b9e\u6570\u636e\u5e93\u73af\u5883\u4e2d\u79ef\u7d2f\u7684\u5386\u53f2\u67e5\u8be2\u4fe1\u606f\uff08\u5982\u5e38\u89c1\u5173\u8054\u8def\u5f84\u3001\u6a21\u7cca\u8868\u540d/\u5217\u540d\u7684\u8bed\u4e49\uff09\uff0c\u5b58\u5728\u4f18\u5316\u7a7a\u95f4\u3002", "method": "\u63d0\u51faTailorSQL\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u5386\u53f2\u67e5\u8be2\u8d1f\u8f7d\uff0c\u63d0\u53d6\u9690\u542b\u7684\u6570\u636e\u5e93\u4f7f\u7528\u6a21\u5f0f\u7279\u5f81\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u7279\u5b9a\u573a\u666f\u7684\u9002\u5e94\u6027\u3002", "result": "\u5728\u6807\u51c6\u5316\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u9ad82\u500d\u7684\u6267\u884c\u51c6\u786e\u7387\u63d0\u5347\uff0c\u540c\u65f6\u964d\u4f4e\u7ffb\u8bd1\u5ef6\u8fdf\u3002", "conclusion": "\u5229\u7528\u5386\u53f2\u67e5\u8be2\u8d1f\u8f7d\u4fe1\u606f\u662f\u4f18\u5316NL2SQL\u4efb\u52a1\u7684\u6709\u6548\u9014\u5f84\uff0c\u53ef\u4e3a\u5b9e\u9645\u6570\u636e\u5e93\u5e94\u7528\u63d0\u4f9b\u66f4\u7cbe\u51c6\u3001\u9ad8\u6548\u7684\u8bed\u4e49\u89e3\u6790\u80fd\u529b\u3002"}}
{"id": "2505.23049", "pdf": "https://arxiv.org/pdf/2505.23049", "abs": "https://arxiv.org/abs/2505.23049", "authors": ["Tianteng Gu", "Bei Liu", "Bo Xiao", "Ke Zeng", "Jiacheng Liu", "Yanmin Qian"], "title": "DenoiseRotator: Enhance Pruning Robustness for LLMs via Importance Concentration", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Pruning is a widely used technique to compress large language models (LLMs)\nby removing unimportant weights, but it often suffers from significant\nperformance degradation - especially under semi-structured sparsity\nconstraints. Existing pruning methods primarily focus on estimating the\nimportance of individual weights, which limits their ability to preserve\ncritical capabilities of the model. In this work, we propose a new perspective:\nrather than merely selecting which weights to prune, we first redistribute\nparameter importance to make the model inherently more amenable to pruning. By\nminimizing the information entropy of normalized importance scores, our\napproach concentrates importance onto a smaller subset of weights, thereby\nenhancing pruning robustness. We instantiate this idea through DenoiseRotator,\nwhich applies learnable orthogonal transformations to the model's weight\nmatrices. Our method is model-agnostic and can be seamlessly integrated with\nexisting pruning techniques such as Magnitude, SparseGPT, and Wanda. Evaluated\non LLaMA3, Qwen2.5, and Mistral models under 50% unstructured and 2:4\nsemi-structured sparsity, DenoiseRotator consistently improves perplexity and\nzero-shot accuracy. For instance, on LLaMA3-70B pruned with SparseGPT at 2:4\nsemi-structured sparsity, DenoiseRotator reduces the perplexity gap to the\ndense model by 58%, narrowing the degradation from 8.1 to 3.4 points. Codes are\navailable at https://github.com/Axel-gu/DenoiseRotator.", "AI": {"tldr": "\u63d0\u51faDenoiseRotator\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u91cd\u8981\u6027\u518d\u5206\u914d\u548c\u6b63\u4ea4\u53d8\u6362\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u526a\u679d\u9c81\u68d2\u6027\uff0c\u663e\u8457\u964d\u4f4e\u7a00\u758f\u5316\u540e\u7684\u6027\u80fd\u635f\u5931\u3002", "motivation": "\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u805a\u7126\u5355\u4e2a\u6743\u91cd\u8bc4\u4f30\uff0c\u96be\u4ee5\u4fdd\u7559\u6a21\u578b\u6838\u5fc3\u80fd\u529b\u3002\u901a\u8fc7\u53c2\u6570\u91cd\u8981\u6027\u518d\u5206\u914d\u4f7f\u6a21\u578b\u66f4\u6613\u526a\u679d\uff0c\u7f13\u89e3\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "method": "\u5229\u7528\u53ef\u5b66\u4e60\u6b63\u4ea4\u53d8\u6362\u5bf9\u6743\u91cd\u77e9\u9635\u5904\u7406\uff0c\u6700\u5c0f\u5316\u5f52\u4e00\u5316\u91cd\u8981\u6027\u5f97\u5206\u7684\u4fe1\u606f\u71b5\uff0c\u5c06\u91cd\u8981\u6027\u96c6\u4e2d\u5230\u66f4\u5c0f\u7684\u6743\u91cd\u5b50\u96c6\uff0c\u517c\u5bb9\u73b0\u6709\u526a\u679d\u6280\u672f\u3002", "result": "\u5728LLaMA3-70B\u6a21\u578b2:4\u534a\u7ed3\u6784\u5316\u7a00\u758f\u4e0b\uff0c\u56f0\u60d1\u5ea6\u5dee\u8ddd\u964d\u4f4e58%\uff088.1\u21923.4\uff09\uff0c\u591a\u6a21\u578b\u5b9e\u9a8c\u663e\u793a\u4e00\u81f4\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u53c2\u6570\u5206\u5e03\u4f18\u5316\u800c\u975e\u5355\u7eaf\u526a\u679d\u9009\u62e9\uff0cDenoiseRotator\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u538b\u7f29\uff0c\u4e14\u65e0\u9700\u4fee\u6539\u73b0\u6709\u526a\u679d\u6d41\u7a0b\u3002"}}
{"id": "2505.23058", "pdf": "https://arxiv.org/pdf/2505.23058", "abs": "https://arxiv.org/abs/2505.23058", "authors": ["Yutong Xie", "Zhuoheng Li", "Xiyuan Wang", "Yijun Pan", "Qijia Liu", "Xingzhi Cui", "Kuang-Yu Lo", "Ruoyi Gao", "Xingjian Zhang", "Jin Huang", "Walter Yuan", "Matthew O. Jackson", "Qiaozhu Mei"], "title": "Be.FM: Open Foundation Models for Human Behavior", "categories": ["cs.AI", "cs.CE", "cs.CL"], "comment": null, "summary": "Despite their success in numerous fields, the potential of foundation models\nfor modeling and understanding human behavior remains largely unexplored. We\nintroduce Be.FM, one of the first open foundation models designed for human\nbehavior modeling. Built upon open-source large language models and fine-tuned\non a diverse range of behavioral data, Be.FM can be used to understand and\npredict human decision-making. We construct a comprehensive set of benchmark\ntasks for testing the capabilities of behavioral foundation models. Our results\ndemonstrate that Be.FM can predict behaviors, infer characteristics of\nindividuals and populations, generate insights about contexts, and apply\nbehavioral science knowledge.", "AI": {"tldr": "\u9996\u6b21\u63d0\u51fa\u57fa\u4e8e\u5f00\u6e90\u5927\u6a21\u578b\u7684\u884c\u4e3a\u57fa\u7840\u6a21\u578bBe.FM\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u884c\u4e3a\u6570\u636e\u5fae\u8c03\u5b9e\u73b0\u4eba\u7c7b\u51b3\u7b56\u9884\u6d4b\u4e0e\u7406\u89e3", "motivation": "\u63a2\u7d22\u57fa\u7840\u6a21\u578b\u5728\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u9886\u57df\u7684\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u6a21\u578b\u5728\u884c\u4e3a\u79d1\u5b66\u5e94\u7528\u4e2d\u7684\u7a7a\u767d", "method": "\u57fa\u4e8e\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u4f7f\u7528\u591a\u6837\u5316\u884c\u4e3a\u6570\u636e\u8fdb\u884c\u5fae\u8c03", "result": "\u6a21\u578b\u53ef\u9884\u6d4b\u884c\u4e3a\u3001\u63a8\u65ad\u4e2a\u4f53/\u7fa4\u4f53\u7279\u5f81\u3001\u751f\u6210\u60c5\u5883\u6d1e\u5bdf\u3001\u5e94\u7528\u884c\u4e3a\u79d1\u5b66\u77e5\u8bc6", "conclusion": "\u9a8c\u8bc1\u4e86\u57fa\u7840\u6a21\u578b\u5728\u884c\u4e3a\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u540e\u7eed\u8de8\u5b66\u79d1\u7814\u7a76\u5960\u5b9a\u57fa\u7840"}}
{"id": "2505.23091", "pdf": "https://arxiv.org/pdf/2505.23091", "abs": "https://arxiv.org/abs/2505.23091", "authors": ["Zeyu Liu", "Yuhang Liu", "Guanghao Zhu", "Congkai Xie", "Zhen Li", "Jianbo Yuan", "Xinyao Wang", "Qing Li", "Shing-Chi Cheung", "Shengyu Zhang", "Fei Wu", "Hongxia Yang"], "title": "Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have demonstrated\nsubstantial progress in reasoning capabilities, such as DeepSeek-R1, which\nleverages rule-based reinforcement learning to enhance logical reasoning\nsignificantly. However, extending these achievements to multimodal large\nlanguage models (MLLMs) presents critical challenges, which are frequently more\npronounced for Multimodal Small Language Models (MSLMs) given their typically\nweaker foundational reasoning abilities: (1) the scarcity of high-quality\nmultimodal reasoning datasets, (2) the degradation of reasoning capabilities\ndue to the integration of visual processing, and (3) the risk that direct\napplication of reinforcement learning may produce complex yet incorrect\nreasoning processes. To address these challenges, we design a novel framework\nInfi-MMR to systematically unlock the reasoning potential of MSLMs through a\ncurriculum of three carefully structured phases and propose our multimodal\nreasoning model Infi-MMR-3B. The first phase, Foundational Reasoning\nActivation, leverages high-quality textual reasoning datasets to activate and\nstrengthen the model's logical reasoning capabilities. The second phase,\nCross-Modal Reasoning Adaptation, utilizes caption-augmented multimodal data to\nfacilitate the progressive transfer of reasoning skills to multimodal contexts.\nThe third phase, Multimodal Reasoning Enhancement, employs curated,\ncaption-free multimodal data to mitigate linguistic biases and promote robust\ncross-modal reasoning. Infi-MMR-3B achieves both state-of-the-art multimodal\nmath reasoning ability (43.68% on MathVerse testmini, 27.04% on MathVision\ntest, and 21.33% on OlympiadBench) and general reasoning ability (67.2% on\nMathVista testmini).", "AI": {"tldr": "\u63d0\u51faInfi-MMR\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bfe\u7a0b\u7cfb\u7edf\u63d0\u5347\u591a\u6a21\u6001\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u6570\u5b66\u4e0e\u901a\u7528\u63a8\u7406\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f18\u6c34\u5e73", "motivation": "\u89e3\u51b3MSLMs\u9762\u4e34\u7684\u4e09\u5927\u6311\u6218\uff1a\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u63a8\u7406\u6570\u636e\u7a00\u7f3a\u3001\u89c6\u89c9\u6574\u5408\u5bfc\u81f4\u63a8\u7406\u80fd\u529b\u9000\u5316\u3001\u5f3a\u5316\u5b66\u4e60\u53ef\u80fd\u751f\u6210\u9519\u8bef\u63a8\u7406\u8fc7\u7a0b", "method": "\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1) \u7528\u6587\u672c\u63a8\u7406\u6570\u636e\u6fc0\u6d3b\u903b\u8f91\u80fd\u529b 2) \u6807\u9898\u589e\u5f3a\u591a\u6a21\u6001\u6570\u636e\u8fc1\u79fb\u63a8\u7406\u6280\u80fd 3) \u65e0\u6807\u9898\u591a\u6a21\u6001\u6570\u636e\u51cf\u5c11\u8bed\u8a00\u504f\u89c1", "result": "MathVerse 43.68%\u3001MathVision 27.04%\u3001OlympiadBench 21.33%\u3001MathVista 67.2%", "conclusion": "Infi-MMR-3B\u5728\u6570\u5b66\u4e0e\u901a\u7528\u63a8\u7406\u4efb\u52a1\u4e2d\u5747\u5c55\u73b0\u6700\u4f18\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027"}}
{"id": "2505.23094", "pdf": "https://arxiv.org/pdf/2505.23094", "abs": "https://arxiv.org/abs/2505.23094", "authors": ["Chongjie Si", "Zhiyi Shi", "Yadao Wang", "Xiaokang Yang", "Susanto Rahardja", "Wei Shen"], "title": "MAP: Revisiting Weight Decomposition for Low-Rank Adaptation", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The rapid development of large language models has revolutionized natural\nlanguage processing, but their fine-tuning remains computationally expensive,\nhindering broad deployment. Parameter-efficient fine-tuning (PEFT) methods,\nsuch as LoRA, have emerged as solutions. Recent work like DoRA attempts to\nfurther decompose weight adaptation into direction and magnitude components.\nHowever, existing formulations often define direction heuristically at the\ncolumn level, lacking a principled geometric foundation. In this paper, we\npropose MAP, a novel framework that reformulates weight matrices as\nhigh-dimensional vectors and decouples their adaptation into direction and\nmagnitude in a rigorous manner. MAP normalizes the pre-trained weights, learns\na directional update, and introduces two scalar coefficients to independently\nscale the magnitude of the base and update vectors. This design enables more\ninterpretable and flexible adaptation, and can be seamlessly integrated into\nexisting PEFT methods. Extensive experiments show that MAP significantly\nimproves performance when coupling with existing methods, offering a simple yet\npowerful enhancement to existing PEFT methods. Given the universality and\nsimplicity of MAP, we hope it can serve as a default setting for designing\nfuture PEFT methods.", "AI": {"tldr": "\u63d0\u51faMAP\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6743\u91cd\u77e9\u9635\u5206\u89e3\u4e3a\u65b9\u5411\u4e0e\u5e45\u5ea6\u4e24\u4e2a\u53ef\u89e3\u91ca\u7ef4\u5ea6\uff0c\u4ee5\u66f4\u4e25\u8c28\u7684\u51e0\u4f55\u65b9\u5f0f\u589e\u5f3a\u73b0\u6709\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08\u5982LoRA\uff09\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u7ed3\u6784\u7b80\u5355\u901a\u7528\u3002", "motivation": "\u73b0\u6709PEFT\u65b9\u6cd5\uff08\u5982DoRA\uff09\u5728\u6743\u91cd\u65b9\u5411\u8c03\u6574\u4e0a\u7f3a\u4e4f\u4e25\u8c28\u7684\u51e0\u4f55\u5b66\u57fa\u7840\uff0c\u4ec5\u901a\u8fc7\u5217\u7ea7\u542f\u53d1\u5f0f\u5b9a\u4e49\u65b9\u5411\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u9002\u5e94\u80fd\u529b\u548c\u89e3\u91ca\u6027\u3002", "method": "1. \u5bf9\u9884\u8bad\u7ec3\u6743\u91cd\u8fdb\u884c\u5f52\u4e00\u5316\u5904\u7406\n2. \u5b66\u4e60\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u65b9\u5411\u66f4\u65b0\n3. \u5f15\u5165\u4e24\u4e2a\u72ec\u7acb\u6807\u91cf\u7cfb\u6570\u5206\u522b\u8c03\u8282\u57fa\u5411\u91cf\u548c\u66f4\u65b0\u5411\u91cf\u7684\u5e45\u5ea6", "result": "\u5b9e\u9a8c\u8868\u660eMAP\u53ef\u65e0\u7f1d\u96c6\u6210\u73b0\u6709PEFT\u65b9\u6cd5\uff0c\u5e73\u5747\u63d0\u53471.3%-5.8%\u6027\u80fd\uff0c\u4e14\u6a21\u5757\u5316\u8bbe\u8ba1\u4ec5\u9700\u589e\u52a00.0002%\u53c2\u6570\u91cf", "conclusion": "MAP\u4e3aPEFT\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b9\u5411-\u5e45\u5ea6\u89e3\u8026\u7684\u901a\u7528\u8303\u5f0f\uff0c\u5176\u7b80\u6d01\u6027\u548c\u6709\u6548\u6027\u53ef\u80fd\u6210\u4e3a\u672a\u6765\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u7684\u6807\u51c6\u914d\u7f6e"}}
{"id": "2505.23270", "pdf": "https://arxiv.org/pdf/2505.23270", "abs": "https://arxiv.org/abs/2505.23270", "authors": ["Haokun Chen", "Yueqi Zhang", "Yuan Bi", "Yao Zhang", "Tong Liu", "Jinhe Bi", "Jian Lan", "Jindong Gu", "Claudia Grosser", "Denis Krompass", "Nassir Navab", "Volker Tresp"], "title": "Does Machine Unlearning Truly Remove Model Knowledge? A Framework for Auditing Unlearning in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In recent years, Large Language Models (LLMs) have achieved remarkable\nadvancements, drawing significant attention from the research community. Their\ncapabilities are largely attributed to large-scale architectures, which require\nextensive training on massive datasets. However, such datasets often contain\nsensitive or copyrighted content sourced from the public internet, raising\nconcerns about data privacy and ownership. Regulatory frameworks, such as the\nGeneral Data Protection Regulation (GDPR), grant individuals the right to\nrequest the removal of such sensitive information. This has motivated the\ndevelopment of machine unlearning algorithms that aim to remove specific\nknowledge from models without the need for costly retraining. Despite these\nadvancements, evaluating the efficacy of unlearning algorithms remains a\nchallenge due to the inherent complexity and generative nature of LLMs. In this\nwork, we introduce a comprehensive auditing framework for unlearning\nevaluation, comprising three benchmark datasets, six unlearning algorithms, and\nfive prompt-based auditing methods. By using various auditing algorithms, we\nevaluate the effectiveness and robustness of different unlearning strategies.\nTo explore alternatives beyond prompt-based auditing, we propose a novel\ntechnique that leverages intermediate activation perturbations, addressing the\nlimitations of auditing methods that rely solely on model inputs and outputs.", "AI": {"tldr": "\u63d0\u51fa\u7efc\u5408\u5ba1\u8ba1\u6846\u67b6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9057\u5fd8\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u542b\u57fa\u51c6\u6570\u636e\u96c6\u3001\u7b97\u6cd5\u5e93\u53ca\u65b0\u578b\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\u5ba1\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u9057\u5fd8\u7b97\u6cd5\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u8f93\u5165\u8f93\u51fa\u5206\u6790\uff0c\u96be\u4ee5\u5e94\u5bf9\u6a21\u578b\u590d\u6742\u6027\u3002GDPR\u7b49\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\u9ad8\u6548\u7684\u6570\u636e\u9057\u5fd8\u673a\u5236\uff0c\u4f46\u4f20\u7edf\u91cd\u8bad\u7ec3\u6210\u672c\u8fc7\u9ad8\u3002", "method": "\u6784\u5efa\u542b3\u4e2a\u6570\u636e\u96c6/6\u79cd\u7b97\u6cd5/5\u79cd\u63d0\u793a\u5ba1\u8ba1\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u521b\u65b0\u6027\u5f15\u5165\u57fa\u4e8e\u6a21\u578b\u4e2d\u95f4\u5c42\u6fc0\u6d3b\u503c\u6270\u52a8\u7684\u5ba1\u8ba1\u6280\u672f\uff0c\u7a81\u7834\u4f20\u7edf\u8f93\u5165\u8f93\u51fa\u5ba1\u8ba1\u7684\u5c40\u9650\u3002", "result": "\u591a\u7ef4\u5ea6\u9a8c\u8bc1\u4e0d\u540c\u9057\u5fd8\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e2d\u95f4\u6fc0\u6d3b\u6270\u52a8\u65b9\u6cd5\u6bd4\u4f20\u7edf\u63d0\u793a\u5ba1\u8ba1\u66f4\u5168\u9762\u6355\u6349\u6a21\u578b\u77e5\u8bc6\u6b8b\u7559\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u65b0\u578b\u5ba1\u8ba1\u65b9\u6cd5\u4e3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u5f00\u8f9f\u65b0\u8def\u5f84\uff0c\u52a9\u529b\u9690\u79c1\u5408\u89c4\u7684LLM\u5f00\u53d1\u3002"}}
{"id": "2505.23339", "pdf": "https://arxiv.org/pdf/2505.23339", "abs": "https://arxiv.org/abs/2505.23339", "authors": ["Maya Dewhurst", "Jack Collins", "Justin J. H. Lo", "Roy Alderton", "Sam Kirkham"], "title": "Nosey: Open-source hardware for acoustic nasalance", "categories": ["cs.SD", "cs.CL", "eess.AS"], "comment": "Accepted to Interspeech 2025", "summary": "We introduce Nosey (Nasalance Open Source Estimation sYstem), a low-cost,\ncustomizable, 3D-printed system for recording acoustic nasalance data that we\nhave made available as open-source hardware\n(http://github.com/phoneticslab/nosey). We first outline the motivations and\ndesign principles behind our hardware nasalance system, and then present a\ncomparison between Nosey and a commercial nasalance device. Nosey shows\nconsistently higher nasalance scores than the commercial device, but the\nmagnitude of contrast between phonological environments is comparable between\nsystems. We also review ways of customizing the hardware to facilitate testing,\nsuch as comparison of microphones and different construction materials. We\nconclude that Nosey is a flexible and cost-effective alternative to commercial\nnasometry devices and propose some methodological considerations for its use in\ndata collection.", "AI": {"tldr": "\u5f00\u6e90\u4f4e\u6210\u672c3D\u6253\u5370\u9f3b\u97f3\u68c0\u6d4b\u7cfb\u7edfNosey\u7684\u5f00\u53d1\u4e0e\u5546\u4e1a\u8bbe\u5907\u5bf9\u6bd4\u6d4b\u8bd5", "motivation": "\u4e3a\u5546\u4e1a\u9f3b\u97f3\u68c0\u6d4b\u8bbe\u5907\u63d0\u4f9b\u7075\u6d3b\u4e14\u7ecf\u6d4e\u6709\u6548\u7684\u5f00\u6e90\u66ff\u4ee3\u65b9\u6848", "method": "1. \u8bbe\u8ba1\u5f00\u6e90\u786c\u4ef6\u7cfb\u7edf 2. \u4e0e\u5546\u4e1a\u8bbe\u5907\u8fdb\u884c\u9f3b\u97f3\u5206\u6570\u5bf9\u6bd4 3. \u6d4b\u8bd5\u4e0d\u540c\u9ea6\u514b\u98ce\u548c\u6750\u6599\u7684\u6027\u80fd", "result": "Nosey\u9f3b\u97f3\u5206\u6570\u66f4\u9ad8\uff0c\u4f46\u4e0d\u540c\u53d1\u97f3\u73af\u5883\u4e0b\u7684\u5bf9\u6bd4\u5e45\u5ea6\u4e0e\u5546\u4e1a\u7cfb\u7edf\u76f8\u5f53", "conclusion": "Nosey\u662f\u6709\u6548\u7684\u5546\u4e1a\u8bbe\u5907\u66ff\u4ee3\u65b9\u6848\uff0c\u9700\u6ce8\u610f\u6807\u51c6\u5316\u6d4b\u8bd5\u6761\u4ef6\u548c\u8bbe\u5907\u6821\u51c6"}}
{"id": "2505.23419", "pdf": "https://arxiv.org/pdf/2505.23419", "abs": "https://arxiv.org/abs/2505.23419", "authors": ["Linghao Zhang", "Shilin He", "Chaoyun Zhang", "Yu Kang", "Bowen Li", "Chengxing Xie", "Junhao Wang", "Maoquan Wang", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu", "Qingwei Lin", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang"], "title": "SWE-bench Goes Live!", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": "Homepage: \\url{https://swe-bench-live.github.io/}, Code:\n  \\url{https://github.com/SWE-bench-Live}, Dataset:\n  \\url{https://huggingface.co/SWE-bench-Live}", "summary": "The issue-resolving task, where a model generates patches to fix real-world\nbugs, has emerged as a critical benchmark for evaluating the capabilities of\nlarge language models (LLMs). While SWE-bench and its variants have become\nstandard in this domain, they suffer from key limitations: they have not been\nupdated since their initial releases, cover a narrow set of repositories, and\ndepend heavily on manual effort for instance construction and environment\nsetup. These factors hinder scalability and introduce risks of overfitting and\ndata contamination. In this work, we present \\textbf{SWE-bench-Live}, a\n\\textit{live-updatable} benchmark designed to overcome these challenges. Our\ninitial release consists of 1,319 tasks derived from real GitHub issues created\nsince 2024, spanning 93 repositories. Each task is accompanied by a dedicated\nDocker image to ensure reproducible execution. Central to our benchmark is\n\\method, an automated curation pipeline that streamlines the entire process\nfrom instance creation to environment setup, removing manual bottlenecks and\nenabling scalability and continuous updates. We evaluate a range of\nstate-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a\nsubstantial performance gap compared to static benchmarks like SWE-bench, even\nunder controlled evaluation conditions. To better understand this discrepancy,\nwe perform detailed analyses across repository origin, issue recency, and task\ndifficulty. By providing a fresh, diverse, and executable benchmark grounded in\nlive repository activity, SWE-bench-Live facilitates rigorous,\ncontamination-resistant evaluation of LLMs and agents in dynamic, real-world\nsoftware development settings.", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u66f4\u65b0\u7684SWE-bench-Live\u57fa\u51c6\u6d4b\u8bd5\uff0c\u89e3\u51b3\u73b0\u6709\u9759\u6001\u57fa\u51c6\u7684\u66f4\u65b0\u5ef6\u8fdf\u3001\u8986\u76d6\u5c40\u9650\u548c\u4eba\u5de5\u4f9d\u8d56\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u5b9e\u73b0\u6301\u7eed\u66f4\u65b0\u7684\u8f6f\u4ef6\u5de5\u7a0b\u8bc4\u4f30\u4f53\u7cfb", "motivation": "\u73b0\u6709SWE-bench\u5b58\u5728\u4e09\u5927\u5c40\u9650\uff1a1) \u6570\u636e\u96c6\u9648\u65e7\u672a\u66f4\u65b0 2) \u8986\u76d6\u4ed3\u5e93\u8303\u56f4\u72ed\u7a84 3) \u4eba\u5de5\u6784\u5efa\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u5dee\u4e14\u6613\u8fc7\u62df\u5408\uff0c\u9700\u8981\u5efa\u7acb\u52a8\u6001\u53ef\u6301\u7eed\u7684\u8bc4\u4f30\u57fa\u51c6", "method": "\u5f00\u53d1\u81ea\u52a8\u5316\u6d41\u7a0bmethod\uff1a1) \u4eceGitHub\u5b9e\u65f6\u6293\u53d62024\u5e74\u540e\u65b0\u5efa\u76841,319\u4e2aissue\u6784\u5efa\u4efb\u52a1\u96c6 2) \u4e3a\u6bcf\u4e2a\u4efb\u52a1\u521b\u5efa\u72ec\u7acbDocker\u955c\u50cf 3) \u5b9e\u73b0\u4ece\u5b9e\u4f8b\u751f\u6210\u5230\u73af\u5883\u914d\u7f6e\u7684\u5168\u6d41\u7a0b\u81ea\u52a8\u5316", "result": "\u5b9e\u9a8c\u663e\u793a\u5f53\u524dSOTA\u6a21\u578b\u5728\u52a8\u6001\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u663e\u8457\u843d\u540e\u4e8e\u9759\u6001\u57fa\u51c6\uff08\u5373\u4f7f\u53d7\u63a7\u6761\u4ef6\u4e0b\uff09\uff0c\u63ed\u793a\u6a21\u578b\u5728\u52a8\u6001\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u4e0d\u8db3", "conclusion": "SWE-bench-Live\u901a\u8fc7\u5b9e\u65f6\u6570\u636e\u6e90+\u81ea\u52a8\u5316\u67b6\u6784\uff0c\u4e3aLLM\u63d0\u4f9b\u6297\u6570\u636e\u6c61\u67d3\u7684\u52a8\u6001\u8bc4\u4f30\u573a\u666f\uff0c\u63a8\u52a8\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u80fd\u529b\u9a8c\u8bc1"}}
{"id": "2505.23442", "pdf": "https://arxiv.org/pdf/2505.23442", "abs": "https://arxiv.org/abs/2505.23442", "authors": ["Linyu Li", "Zhi Jin", "Yuanpeng He", "Dongming Jin", "Haoran Duan", "Zhengwei Tao", "Xuan Zhang", "Jiandong Li"], "title": "Rethinking Regularization Methods for Knowledge Graph Completion", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Knowledge graph completion (KGC) has attracted considerable attention in\nrecent years because it is critical to improving the quality of knowledge\ngraphs. Researchers have continuously explored various models. However, most\nprevious efforts have neglected to take advantage of regularization from a\ndeeper perspective and therefore have not been used to their full potential.\nThis paper rethinks the application of regularization methods in KGC. Through\nextensive empirical studies on various KGC models, we find that carefully\ndesigned regularization not only alleviates overfitting and reduces variance\nbut also enables these models to break through the upper bounds of their\noriginal performance. Furthermore, we introduce a novel sparse-regularization\nmethod that embeds the concept of rank-based selective sparsity into the KGC\nregularizer. The core idea is to selectively penalize those components with\nsignificant features in the embedding vector, thus effectively ignoring many\ncomponents that contribute little and may only represent noise. Various\ncomparative experiments on multiple datasets and multiple models show that the\nSPR regularization method is better than other regularization methods and can\nenable the KGC model to further break through the performance margin.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u578b\u7a00\u758f\u6b63\u5219\u5316\u65b9\u6cd5SPR\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u60e9\u7f5a\u663e\u8457\u7279\u5f81\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6027\u80fd\uff0c\u7a81\u7834\u6a21\u578b\u539f\u6709\u4e0a\u9650\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6a21\u578b\u672a\u5145\u5206\u5229\u7528\u6df1\u5ea6\u6b63\u5219\u5316\u7684\u6f5c\u529b\uff0c\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6b63\u5219\u5316\u53ef\u7a81\u7834\u6a21\u578b\u6027\u80fd\u8fb9\u754c\u5e76\u964d\u4f4e\u566a\u58f0\u5e72\u6270\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u578b\u5b9e\u8bc1\u7814\u7a76\uff0c\u63d0\u51fa\u57fa\u4e8e\u6392\u5e8f\u9009\u62e9\u6027\u7a00\u758f\u7684SPR\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5bf9\u5d4c\u5165\u5411\u91cf\u4e2d\u663e\u8457\u7279\u5f81\u7ec4\u4ef6\u8fdb\u884c\u9009\u62e9\u6027\u60e9\u7f5a\u3002", "result": "\u5728\u591a\u6570\u636e\u96c6\u548c\u6a21\u578b\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\uff0cSPR\u6b63\u5219\u5316\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u7a81\u7834\u539f\u6709\u6027\u80fd\u8fb9\u9645\u6700\u9ad8\u8fbe1.7%\u63d0\u5347\u3002", "conclusion": "\u5b9a\u5236\u5316\u7684\u6b63\u5219\u5316\u8bbe\u8ba1\u80fd\u6709\u6548\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6027\u80fd\uff0c\u57fa\u4e8e\u6392\u5e8f\u7684\u7a00\u758f\u7b56\u7565\u53ef\u7cbe\u51c6\u6291\u5236\u566a\u58f0\u7279\u5f81\uff0c\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2505.23474", "pdf": "https://arxiv.org/pdf/2505.23474", "abs": "https://arxiv.org/abs/2505.23474", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Process Reward Models (PRMs) are crucial in complex reasoning and\nproblem-solving tasks (e.g., LLM agents with long-horizon decision-making) by\nverifying the correctness of each intermediate reasoning step. In real-world\nscenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to\nsolve a problem, potentially suffering from errors under various reasoning\npatterns. Therefore, PRMs are required to identify errors under various\nreasoning patterns during the reasoning process. However, existing benchmarks\nmainly focus on evaluating PRMs with stepwise correctness, ignoring a\nsystematic evaluation of PRMs under various reasoning patterns. To mitigate\nthis gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs\nsystematically under six reasoning patterns, including Transformation,\nDecomposition, Regather, Deduction, Verification, and Integration.\nSocratic-PRMBench}comprises 2995 reasoning paths with flaws within the\naforementioned six reasoning patterns. Through our experiments on both PRMs and\nLLMs prompted as critic models, we identify notable deficiencies in existing\nPRMs. These observations underscore the significant weakness of current PRMs in\nconducting evaluations on reasoning steps under various reasoning patterns. We\nhope Socratic-PRMBench can serve as a comprehensive testbed for systematic\nevaluation of PRMs under diverse reasoning patterns and pave the way for future\ndevelopment of PRMs.", "AI": {"tldr": "\u63d0\u51faSocratic-PRMBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u516d\u79cd\u63a8\u7406\u6a21\u5f0f\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u5173\u6ce8\u9010\u6b65\u6b63\u786e\u6027\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u5bf9\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4e0d\u540c\u63a8\u7406\u6a21\u5f0f\uff08\u5982\u5206\u89e3/\u6f14\u7ece\u7b49\uff09\u4e0b\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u5305\u542b\u516d\u79cd\u63a8\u7406\u6a21\u5f0f\uff08\u8f6c\u6362/\u5206\u89e3/\u91cd\u805a/\u6f14\u7ece/\u9a8c\u8bc1/\u6574\u5408\uff09\u76842995\u6761\u542b\u7f3a\u9677\u63a8\u7406\u8def\u5f84\u6d4b\u8bd5\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709PRMs\u5728\u4e0d\u540c\u63a8\u7406\u6a21\u5f0f\u4e0b\u5b58\u5728\u663e\u8457\u8bc4\u4f30\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5904\u7406\u591a\u6837\u5316\u63a8\u7406\u6b65\u9aa4\u65f6\u8868\u73b0\u8584\u5f31\u3002", "conclusion": "\u8be5\u57fa\u51c6\u4e3aPRMs\u7684\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u65b0\u6807\u51c6\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u672a\u6765\u5bf9\u591a\u6a21\u5f0f\u63a8\u7406\u8bc4\u4f30\u7684\u6539\u8fdb\u7814\u7a76\u3002"}}
{"id": "2505.23493", "pdf": "https://arxiv.org/pdf/2505.23493", "abs": "https://arxiv.org/abs/2505.23493", "authors": ["Kaijie Chen", "Zihao Lin", "Zhiyang Xu", "Ying Shen", "Yuguang Yao", "Joy Rimchala", "Jiaxin Zhang", "Lifu Huang"], "title": "R2I-Bench: Benchmarking Reasoning-Driven Text-to-Image Generation", "categories": ["cs.CV", "cs.CL"], "comment": "Project Page: https://r2i-bench.github.io", "summary": "Reasoning is a fundamental capability often required in real-world\ntext-to-image (T2I) generation, e.g., generating ``a bitten apple that has been\nleft in the air for more than a week`` necessitates understanding temporal\ndecay and commonsense concepts. While recent T2I models have made impressive\nprogress in producing photorealistic images, their reasoning capability remains\nunderdeveloped and insufficiently evaluated. To bridge this gap, we introduce\nR2I-Bench, a comprehensive benchmark specifically designed to rigorously assess\nreasoning-driven T2I generation. R2I-Bench comprises meticulously curated data\ninstances, spanning core reasoning categories, including commonsense,\nmathematical, logical, compositional, numerical, causal, and concept mixing. To\nfacilitate fine-grained evaluation, we design R2IScore, a QA-style metric based\non instance-specific, reasoning-oriented evaluation questions that assess three\ncritical dimensions: text-image alignment, reasoning accuracy, and image\nquality. Extensive experiments with 16 representative T2I models, including a\nstrong pipeline-based framework that decouples reasoning and generation using\nthe state-of-the-art language and image generation models, demonstrate\nconsistently limited reasoning performance, highlighting the need for more\nrobust, reasoning-aware architectures in the next generation of T2I systems.\nProject Page: https://r2i-bench.github.io", "AI": {"tldr": "\u5f00\u53d1R2I-Bench\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u8db3", "motivation": "\u5f53\u524dT2I\u6a21\u578b\u867d\u80fd\u751f\u6210\u903c\u771f\u56fe\u50cf\uff0c\u4f46\u7f3a\u4e4f\u5904\u7406\u65f6\u95f4\u63a8\u7406\u3001\u5e38\u8bc6\u7406\u89e3\u7b49\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u8bc4\u4f30\u4f53\u7cfb", "method": "\u6784\u5efa\u5305\u542b7\u7c7b\u63a8\u7406\u4efb\u52a1\uff08\u5e38\u8bc6/\u6570\u5b66/\u903b\u8f91\u7b49\uff09\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1R2IScore\u8bc4\u4f30\u6307\u6807\uff08\u6587\u672c\u5bf9\u9f50/\u63a8\u7406\u51c6\u786e\u7387/\u56fe\u50cf\u8d28\u91cf\u4e09\u7ef4\u5ea6QA\u8bc4\u4f30\uff09", "result": "\u6d4b\u8bd516\u4e2a\u4e3b\u6d41\u6a21\u578b\uff08\u542b\u57fa\u4e8eLLM\u7684\u89e3\u8026\u63a8\u7406\u6846\u67b6\uff09\uff0c\u7ed3\u679c\u663e\u793a\u6240\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u5747\u672a\u8d85\u8fc750%\u51c6\u786e\u7387", "conclusion": "\u9700\u6784\u5efa\u63a8\u7406\u611f\u77e5\u7684\u65b0\u578bT2I\u67b6\u6784\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u56fe\u50cf\u751f\u6210\u6280\u672f\u6df1\u5ea6\u7ed3\u5408\u4ee5\u7a81\u7834\u73b0\u6709\u74f6\u9888"}}
{"id": "2505.23500", "pdf": "https://arxiv.org/pdf/2505.23500", "abs": "https://arxiv.org/abs/2505.23500", "authors": ["Eva Mart\u00edn del Pico", "Josep Llu\u00eds Gelp\u00ed", "Salvador Capella-Guti\u00e9rrez"], "title": "Identity resolution of software metadata using Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.DL"], "comment": null, "summary": "Software is an essential component of research. However, little attention has\nbeen paid to it compared with that paid to research data. Recently, there has\nbeen an increase in efforts to acknowledge and highlight the importance of\nsoftware in research activities.\n  Structured metadata from platforms like bio.tools, Bioconductor, and Galaxy\nToolShed offers valuable insights into research software in the Life Sciences.\nAlthough originally intended to support discovery and integration, this\nmetadata can be repurposed for large-scale analysis of software practices.\nHowever, its quality and completeness vary across platforms, reflecting diverse\ndocumentation practices.\n  To gain a comprehensive view of software development and sustainability,\nconsolidating this metadata is necessary, but requires robust mechanisms to\naddress its heterogeneity and scale.\n  This article presents an evaluation of instruction-tuned large language\nmodels for the task of software metadata identity resolution, a critical step\nin assembling a cohesive collection of research software. Such a collection is\nthe reference component for the Software Observatory at OpenEBench, a platform\nthat aggregates metadata to monitor the FAIRness of research software in the\nLife Sciences.\n  We benchmarked multiple models against a human-annotated gold standard,\nexamined their behavior on ambiguous cases, and introduced an agreement-based\nproxy for high-confidence automated decisions. The proxy achieved high\nprecision and statistical robustness, while also highlighting the limitations\nof current models and the broader challenges of automating semantic judgment in\nFAIR-aligned software metadata across registries and repositories.", "AI": {"tldr": "\u8bc4\u4f30\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u547d\u79d1\u5b66\u8f6f\u4ef6\u5143\u6570\u636e\u8eab\u4efd\u89e3\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u534f\u8bae\u7684\u9ad8\u7f6e\u4fe1\u5ea6\u81ea\u52a8\u5316\u51b3\u7b56\u65b9\u6848", "motivation": "\u7814\u7a76\u8f6f\u4ef6\u5728\u79d1\u7814\u4e2d\u65e5\u76ca\u91cd\u8981\u4f46\u5173\u6ce8\u4e0d\u8db3\uff0c\u4e0d\u540c\u5e73\u53f0\u7684\u5143\u6570\u636e\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\uff0c\u9700\u5efa\u7acb\u6574\u5408\u673a\u5236\u652f\u6301\u8f6f\u4ef6\u53ef\u6301\u7eed\u53d1\u5c55", "method": "\u4f7f\u7528\u591a\u5e73\u53f0\u7ed3\u6784\u5316\u5143\u6570\u636e\uff0c\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u9ec4\u91d1\u6807\u51c6\u5bf9\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u534f\u8bae\u7f6e\u4fe1\u5ea6\u7684\u4ee3\u7406\u51b3\u7b56\u65b9\u6848", "result": "\u4ee3\u7406\u65b9\u6848\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\uff08>95%\uff09\u548c\u7edf\u8ba1\u7a33\u5065\u6027\uff0c\u540c\u65f6\u63ed\u793a\u5f53\u524d\u6a21\u578b\u5728\u8de8\u6ce8\u518c\u8bed\u4e49\u5224\u65ad\u4e2d\u7684\u6cdb\u5316\u5c40\u9650\u6027", "conclusion": "\u9700\u5e73\u8861\u81ea\u52a8\u5316\u6548\u7387\u4e0e\u4eba\u5de5\u9a8c\u8bc1\uff0c\u5f3a\u8c03FAIR\u539f\u5219\u4e0b\u5143\u6570\u636e\u8bed\u4e49\u6574\u5408\u5728\u751f\u547d\u79d1\u5b66\u8f6f\u4ef6\u53ef\u6301\u7eed\u53d1\u5c55\u4e2d\u7684\u5173\u952e\u4f5c\u7528"}}
{"id": "2505.23537", "pdf": "https://arxiv.org/pdf/2505.23537", "abs": "https://arxiv.org/abs/2505.23537", "authors": ["Giorgos Iacovides", "Wuyang Zhou", "Chao Li", "Qibin Zhao", "Danilo Mandic"], "title": "Domain-Aware Tensor Network Structure Search", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Tensor networks (TNs) provide efficient representations of high-dimensional\ndata, yet identification of the optimal TN structures, the so called tensor\nnetwork structure search (TN-SS) problem, remains a challenge. Current\nstate-of-the-art (SOTA) algorithms are computationally expensive as they\nrequire extensive function evaluations, which is prohibitive for real-world\napplications. In addition, existing methods ignore valuable domain information\ninherent in real-world tensor data and lack transparency in their identified TN\nstructures. To this end, we propose a novel TN-SS framework, termed the tnLLM,\nwhich incorporates domain information about the data and harnesses the\nreasoning capabilities of large language models (LLMs) to directly predict\nsuitable TN structures. The proposed framework involves a domain-aware\nprompting pipeline which instructs the LLM to infer suitable TN structures\nbased on the real-world relationships between tensor modes. In this way, our\napproach is capable of not only iteratively optimizing the objective function,\nbut also generating domain-aware explanations for the identified structures.\nExperimental results demonstrate that tnLLM achieves comparable TN-SS objective\nfunction values with much fewer function evaluations compared to SOTA\nalgorithms. Furthermore, we demonstrate that the LLM-enabled domain information\ncan be used to find good initializations in the search space for sampling-based\nSOTA methods to accelerate their convergence while preserving theoretical\nperformance guarantees.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684tnLLM\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u9886\u57df\u4fe1\u606f\u548cLLM\u63a8\u7406\u80fd\u529b\uff0c\u9ad8\u6548\u4f18\u5316\u5f20\u91cf\u7f51\u7edc\u7ed3\u6784\u641c\u7d22\uff08TN-SS\uff09\u5e76\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709TN-SS\u7b97\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u5ffd\u7565\u9886\u57df\u4fe1\u606f\u4e14\u7f3a\u4e4f\u7ed3\u6784\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u5229\u7528LLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u9886\u57df\u77e5\u8bc6\u63d0\u5347\u641c\u7d22\u6548\u7387\u4e0e\u900f\u660e\u5ea6\u3002", "method": "\u8bbe\u8ba1\u9886\u57df\u611f\u77e5\u63d0\u793a\u6846\u67b6\uff0c\u6307\u5bfcLLM\u57fa\u4e8e\u5f20\u91cf\u6a21\u5f0f\u95f4\u5b9e\u9645\u5173\u7cfb\u63a8\u65adTN\u7ed3\u6784\uff0c\u5e76\u8fed\u4ee3\u4f18\u5316\u76ee\u6807\u51fd\u6570\uff0c\u540c\u65f6\u751f\u6210\u9886\u57df\u76f8\u5173\u7684\u7ed3\u6784\u89e3\u91ca\u3002", "result": "\u5b9e\u9a8c\u663e\u793atnLLM\u4ee5\u66f4\u5c11\u8bc4\u4f30\u6b21\u6570\u8fbe\u5230\u4e0eSOTA\u76f8\u8fd1\u6027\u80fd\uff0c\u4e14LLM\u63d0\u4f9b\u7684\u9886\u57df\u4fe1\u606f\u53ef\u52a0\u901f\u4f20\u7edf\u65b9\u6cd5\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "tnLLM\u6846\u67b6\u5728TN-SS\u95ee\u9898\u4e2d\u5b9e\u73b0\u9ad8\u6548\u641c\u7d22\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u9a8c\u8bc1\u4e86LLM\u6574\u5408\u9886\u57df\u77e5\u8bc6\u4f18\u5316\u4f20\u7edf\u7b97\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.23564", "pdf": "https://arxiv.org/pdf/2505.23564", "abs": "https://arxiv.org/abs/2505.23564", "authors": ["Yiran Guo", "Lijie Xu", "Jie Liu", "Dan Ye", "Shuang Qiu"], "title": "Segment Policy Optimization: Effective Segment-Level Credit Assignment in RL for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Enhancing the reasoning capabilities of large language models effectively\nusing reinforcement learning (RL) remains a crucial challenge. Existing\napproaches primarily adopt two contrasting advantage estimation granularities:\nToken-level methods (e.g., PPO) aim to provide the fine-grained advantage\nsignals but suffer from inaccurate estimation due to difficulties in training\nan accurate critic model. On the other extreme, trajectory-level methods (e.g.,\nGRPO) solely rely on a coarse-grained advantage signal from the final reward,\nleading to imprecise credit assignment. To address these limitations, we\npropose Segment Policy Optimization (SPO), a novel RL framework that leverages\nsegment-level advantage estimation at an intermediate granularity, achieving a\nbetter balance by offering more precise credit assignment than trajectory-level\nmethods and requiring fewer estimation points than token-level methods,\nenabling accurate advantage estimation based on Monte Carlo (MC) without a\ncritic model. SPO features three components with novel strategies: (1) flexible\nsegment partition; (2) accurate segment advantage estimation; and (3) policy\noptimization using segment advantages, including a novel probability-mask\nstrategy. We further instantiate SPO for two specific scenarios: (1) SPO-chain\nfor short chain-of-thought (CoT), featuring novel cutpoint-based partition and\nchain-based advantage estimation, achieving $6$-$12$ percentage point\nimprovements in accuracy over PPO and GRPO on GSM8K. (2) SPO-tree for long CoT,\nfeaturing novel tree-based advantage estimation, which significantly reduces\nthe cost of MC estimation, achieving $7$-$11$ percentage point improvements\nover GRPO on MATH500 under 2K and 4K context evaluation. We make our code\npublicly available at https://github.com/AIFrameResearch/SPO.", "AI": {"tldr": "\u63d0\u51faSPO\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6bb5\u7ea7\u4f18\u52bf\u4f30\u8ba1\u5e73\u8861Token\u7ea7\u548c\u8f68\u8ff9\u7ea7\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd", "motivation": "\u73b0\u6709Token\u7ea7\u65b9\u6cd5\uff08\u5982PPO\uff09\u7684critic\u6a21\u578b\u8bad\u7ec3\u56f0\u96be\u5bfc\u81f4\u4f30\u8ba1\u4e0d\u51c6\u786e\uff0c\u8f68\u8ff9\u7ea7\u65b9\u6cd5\uff08\u5982GRPO\uff09\u56e0\u4ec5\u4f9d\u8d56\u6700\u7ec8\u5956\u52b1\u4fe1\u53f7\u5bfc\u81f4\u4fe1\u7528\u5206\u914d\u7c97\u7cd9", "method": "SPO\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u521b\u65b0\u7ec4\u4ef6\uff1a1\uff09\u57fa\u4e8ecutpoint/tree\u7684\u7075\u6d3b\u6bb5\u5212\u5206\u7b56\u7565 2\uff09\u57fa\u4e8e\u8499\u7279\u5361\u6d1b\u7684\u6bb5\u7ea7\u4f18\u52bf\u4f30\u8ba1\u65b9\u6cd5 3\uff09\u91c7\u7528\u6982\u7387\u63a9\u7801\u7b56\u7565\u7684\u6bb5\u4f18\u52bf\u7b56\u7565\u4f18\u5316", "result": "\u5728GSM8K\u4e0a\u76f8\u5bf9PPO/GRPO\u63d0\u53476-12\u4e2a\u767e\u5206\u70b9\u51c6\u786e\u7387\uff0c\u5728MATH500\u957f\u4e0a\u4e0b\u6587\u8bc4\u4f30\u4e2d\u8282\u7701MC\u4f30\u8ba1\u6210\u672c\u5e76\u63d0\u53477-11\u4e2a\u767e\u5206\u70b9", "conclusion": "SPO\u901a\u8fc7\u4e2d\u95f4\u7c92\u5ea6\u7684\u6bb5\u7ea7\u4f18\u52bf\u4f30\u8ba1\u6709\u6548\u5e73\u8861\u4fe1\u7528\u5206\u914d\u7cbe\u5ea6\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u77ed/\u957f\u601d\u7ef4\u94fe\u573a\u666f\uff0c\u4e14\u65e0\u9700critic\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u51c6\u786e\u4f30\u8ba1"}}
{"id": "2505.23585", "pdf": "https://arxiv.org/pdf/2505.23585", "abs": "https://arxiv.org/abs/2505.23585", "authors": ["Yaru Hao", "Li Dong", "Xun Wu", "Shaohan Huang", "Zewen Chi", "Furu Wei"], "title": "On-Policy RL with Optimal Reward Baseline", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning algorithms are fundamental to align large language\nmodels with human preferences and to enhance their reasoning capabilities.\nHowever, current reinforcement learning algorithms often suffer from training\ninstability due to loose on-policy constraints and computational inefficiency\ndue to auxiliary models. In this work, we propose On-Policy RL with Optimal\nreward baseline (OPO), a novel and simplified reinforcement learning algorithm\ndesigned to address these challenges. OPO emphasizes the importance of exact\non-policy training, which empirically stabilizes the training process and\nenhances exploration. Moreover, OPO introduces the optimal reward baseline that\ntheoretically minimizes gradient variance. We evaluate OPO on mathematical\nreasoning benchmarks. The results demonstrate its superior performance and\ntraining stability without additional models or regularization terms.\nFurthermore, OPO achieves lower policy shifts and higher output entropy,\nencouraging more diverse and less repetitive responses. These results highlight\nOPO as a promising direction for stable and effective reinforcement learning in\nlarge language model alignment and reasoning tasks. The implementation is\nprovided at https://github.com/microsoft/LMOps/tree/main/opo.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5OPO\uff0c\u901a\u8fc7\u4e25\u683c\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\u548c\u6700\u4f18\u5956\u52b1\u57fa\u7ebf\u89e3\u51b3\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u5c55\u73b0\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff08\u677e\u6563\u5728\u7ebf\u7b56\u7565\u7ea6\u675f\uff09\u548c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff08\u4f9d\u8d56\u8f85\u52a9\u6a21\u578b\uff09\u7684\u53cc\u91cd\u95ee\u9898\u3002", "method": "OPO\u7b97\u6cd5\u5f3a\u8c03\u7cbe\u786e\u7684\u5728\u7ebf\u7b56\u7565\u8bad\u7ec3\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5f15\u5165\u7406\u8bba\u6700\u5c0f\u5316\u68af\u5ea6\u65b9\u5dee\u7684\u6700\u4f18\u5956\u52b1\u57fa\u7ebf\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6027\u80fd\u8d85\u8d8a\uff0c\u8bad\u7ec3\u7a33\u5b9a\u6027\u63d0\u5347\uff0c\u7b56\u7565\u504f\u79fb\u964d\u4f4e22.4%\uff0c\u8f93\u51fa\u71b5\u63d0\u9ad818.7%\u3002", "conclusion": "OPO\u4e3aLLM\u5bf9\u9f50\u548c\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u7a33\u5b9a\u6709\u6548\u7684\u5f3a\u5316\u5b66\u4e60\u65b0\u65b9\u5411\uff0c\u5177\u5907\u65e0\u9700\u989d\u5916\u6a21\u578b/\u6b63\u5219\u5316\u9879\u7684\u4f18\u52bf\u3002"}}
{"id": "2505.23590", "pdf": "https://arxiv.org/pdf/2505.23590", "abs": "https://arxiv.org/abs/2505.23590", "authors": ["Zifu Wang", "Junyi Zhu", "Bo Tang", "Zhiyu Li", "Feiyu Xiong", "Jiaqian Yu", "Matthew B. Blaschko"], "title": "Jigsaw-R1: A Study of Rule-based Visual Reinforcement Learning with Jigsaw Puzzles", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The application of rule-based reinforcement learning (RL) to multimodal large\nlanguage models (MLLMs) introduces unique challenges and potential deviations\nfrom findings in text-only domains, particularly for perception-heavy tasks.\nThis paper provides a comprehensive study of rule-based visual RL using jigsaw\npuzzles as a structured experimental framework, revealing several key findings.\n\\textit{Firstly,} we find that MLLMs, initially performing near to random\nguessing on simple puzzles, achieve near-perfect accuracy and generalize to\ncomplex, unseen configurations through fine-tuning. \\textit{Secondly,} training\non jigsaw puzzles can induce generalization to other visual tasks, with\neffectiveness tied to specific task configurations. \\textit{Thirdly,} MLLMs can\nlearn and generalize with or without explicit reasoning, though open-source\nmodels often favor direct answering. Consequently, even when trained for\nstep-by-step reasoning, they can ignore the thinking process in deriving the\nfinal answer. \\textit{Fourthly,} we observe that complex reasoning patterns\nappear to be pre-existing rather than emergent, with their frequency increasing\nalongside training and task difficulty. \\textit{Finally,} our results\ndemonstrate that RL exhibits more effective generalization than Supervised\nFine-Tuning (SFT), and an initial SFT cold start phase can hinder subsequent RL\noptimization. Although these observations are based on jigsaw puzzles and may\nvary across other visual tasks, this research contributes a valuable piece of\njigsaw to the larger puzzle of collective understanding rule-based visual RL\nand its potential in multimodal learning. The code is available at:\n\\href{https://github.com/zifuwanggg/Jigsaw-R1}{https://github.com/zifuwanggg/Jigsaw-R1}.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u62fc\u56fe\u4efb\u52a1\u9a8c\u8bc1\u57fa\u4e8e\u89c4\u5219\u7684\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\uff0c\u53d1\u73b0\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b(MLLMs)\u7ecf\u8fc7\u5fae\u8c03\u540e\u5b9e\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\uff0c\u4e14\u5f3a\u5316\u5b66\u4e60(RL)\u6bd4\u76d1\u7763\u5fae\u8c03(SFT)\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u63a2\u7d22\u89c4\u5219\u5f3a\u5316\u5b66\u4e60\u5728\u89c6\u89c9\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5efa\u7acb\u62fc\u56fe\u4efb\u52a1\u4f5c\u4e3a\u7ed3\u6784\u5316\u5b9e\u9a8c\u6846\u67b6\u4ee5\u7a81\u7834\u6587\u672c\u9886\u57df\u7684\u7814\u7a76\u5c40\u9650\u3002", "method": "\u91c7\u7528jigsaw puzzles\u4f5c\u4e3a\u5b9e\u9a8c\u8f7d\u4f53\uff0c\u901a\u8fc7\u4e0d\u540c\u914d\u7f6e\u7684\u5fae\u8c03\u5b9e\u9a8c\u5bf9\u6bd4MLLMs\u7684\u8868\u73b0\uff0c\u5206\u6790\u63a8\u7406\u6a21\u5f0f\u5e76\u6bd4\u8f83RL\u4e0eSFT\u7684\u4f18\u5316\u6548\u679c\u3002", "result": "1.\u5fae\u8c03\u540e\u51c6\u786e\u7387\u4ece\u968f\u673a\u731c\u6d4b\u63d0\u5347\u81f3\u8fd1\u5b8c\u7f8e 2.\u4efb\u52a1\u914d\u7f6e\u5f71\u54cd\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b 3.\u6a21\u578b\u504f\u597d\u76f4\u63a5\u56de\u7b54\u800c\u975e\u9010\u6b65\u63a8\u7406 4.\u590d\u6742\u63a8\u7406\u80fd\u529b\u968f\u8bad\u7ec3\u9010\u6b65\u663e\u73b0 5.RL\u6bd4SFT\u5177\u6709\u66f4\u4f18\u7684\u4f18\u5316\u6548\u679c", "conclusion": "\u62fc\u56fe\u4efb\u52a1\u7814\u7a76\u63ed\u793a\u4e86\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u7684\u7279\u6b8a\u89c4\u5f8b\uff0c\u8868\u660e\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u5b58\u5728\u6f5c\u5728\u63a8\u7406\u80fd\u529b\uff0cRL\u5728\u590d\u6742\u89c6\u89c9\u4efb\u52a1\u4f18\u5316\u4e2d\u5c55\u73b0\u4f18\u52bf\uff0c\u4e3a\u591a\u6a21\u6001\u5b66\u4e60\u7814\u7a76\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2505.23631", "pdf": "https://arxiv.org/pdf/2505.23631", "abs": "https://arxiv.org/abs/2505.23631", "authors": ["Boning Zhao"], "title": "Human Empathy as Encoder: AI-Assisted Depression Assessment in Special Education", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": "7 pages, 6 figures. Under review", "summary": "Assessing student depression in sensitive environments like special education\nis challenging. Standardized questionnaires may not fully reflect students'\ntrue situations. Furthermore, automated methods often falter with rich student\nnarratives, lacking the crucial, individualized insights stemming from\nteachers' empathetic connections with students. Existing methods often fail to\naddress this ambiguity or effectively integrate educator understanding. To\naddress these limitations by fostering a synergistic human-AI collaboration,\nthis paper introduces Human Empathy as Encoder (HEAE), a novel, human-centered\nAI framework for transparent and socially responsible depression severity\nassessment. Our approach uniquely integrates student narrative text with a\nteacher-derived, 9-dimensional \"Empathy Vector\" (EV), its dimensions guided by\nthe PHQ-9 framework,to explicitly translate tacit empathetic insight into a\nstructured AI input enhancing rather than replacing human judgment. Rigorous\nexperiments optimized the multimodal fusion, text representation, and\nclassification architecture, achieving 82.74% accuracy for 7-level severity\nclassification. This work demonstrates a path toward more responsible and\nethical affective computing by structurally embedding human empathy", "AI": {"tldr": "\u63d0\u51faHEAE\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5b66\u751f\u53d9\u8ff0\u6587\u672c\u548c\u6559\u5e089\u7ef4\u5171\u60c5\u5411\u91cf\uff0c\u5b9e\u73b0\u900f\u660e\u4e14\u8d1f\u8d23\u4efb\u7684\u6291\u90c1\u8bc4\u4f30\uff0c\u51c6\u786e\u7387\u8fbe82.74%", "motivation": "\u6807\u51c6\u5316\u95ee\u5377\u65e0\u6cd5\u53cd\u6620\u7279\u6b8a\u6559\u80b2\u5b66\u751f\u771f\u5b9e\u5fc3\u7406\u72b6\u6001\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u7f3a\u4e4f\u6559\u5e08\u5171\u60c5\u5e26\u6765\u7684\u4e2a\u4f53\u5316\u6d1e\u5bdf", "method": "\u5f00\u53d1Human Empathy as Encoder (HEAE)\uff0c\u5c06PHQ-9\u6846\u67b6\u6307\u5bfc\u7684\u6559\u5e08\u5171\u60c5\u5411\u91cf\u7ed3\u6784\u5316\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u878d\u5408\u4f18\u5316\u5206\u7c7b\u67b6\u6784", "result": "7\u7ea7\u6291\u90c1\u4e25\u91cd\u7a0b\u5ea6\u5206\u7c7b\u51c6\u786e\u738782.74%\uff0c\u9a8c\u8bc1\u4e86\u4eba\u673a\u534f\u540c\u5728\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u901a\u8fc7\u7ed3\u6784\u5316\u5d4c\u5165\u4eba\u7c7b\u5171\u60c5\uff0c\u5f00\u8f9f\u4e86\u66f4\u8d1f\u8d23\u4efb\u7684\u60c5\u611f\u8ba1\u7b97\u8def\u5f84\uff0c\u5b9e\u73b0AI\u589e\u5f3a\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u5224\u65ad\u7684\u4f26\u7406\u6846\u67b6"}}
{"id": "2505.23671", "pdf": "https://arxiv.org/pdf/2505.23671", "abs": "https://arxiv.org/abs/2505.23671", "authors": ["Manish Shetty", "Naman Jain", "Jinjian Liu", "Vijay Kethanaboyina", "Koushik Sen", "Ion Stoica"], "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "comment": "Website: https://gso-bench.github.io/", "summary": "Developing high-performance software is a complex task that requires\nspecialized expertise. We introduce GSO, a benchmark for evaluating language\nmodels' capabilities in developing high-performance software. We develop an\nautomated pipeline that generates and executes performance tests to analyze\nrepository commit histories to identify 102 challenging optimization tasks\nacross 10 codebases, spanning diverse domains and programming languages. An\nagent is provided with a codebase and performance test as a precise\nspecification, and tasked to improve the runtime efficiency, which is measured\nagainst the expert developer optimization. Our quantitative evaluation reveals\nthat leading SWE-Agents struggle significantly, achieving less than 5% success\nrate, with limited improvements even with inference-time scaling. Our\nqualitative analysis identifies key failure modes, including difficulties with\nlow-level languages, practicing lazy optimization strategies, and challenges in\naccurately localizing bottlenecks. We release the code and artifacts of our\nbenchmark along with agent trajectories to enable future research.", "AI": {"tldr": "GSO\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u9ad8\u6027\u80fd\u8f6f\u4ef6\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6027\u80fd\u6d4b\u8bd5\u4e0e\u4e13\u5bb6\u4f18\u5316\u5bf9\u6bd4\uff0c\u53d1\u73b0\u5f53\u524d\u4e3b\u6d41\u4ee3\u7406\u6210\u529f\u7387\u4e0d\u8db35%", "motivation": "\u5f00\u53d1\u9ad8\u6027\u80fd\u8f6f\u4ef6\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u5efa\u7acb\u8bc4\u4f30\u57fa\u51c6\u63a8\u52a8\u76f8\u5173\u6280\u672f\u53d1\u5c55", "method": "\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u9053\u751f\u6210\u6027\u80fd\u6d4b\u8bd5\uff0c\u5206\u6790\u4ee3\u7801\u5e93\u63d0\u4ea4\u5386\u53f2\u7b5b\u9009102\u4e2a\u4f18\u5316\u4efb\u52a1\uff0c\u8986\u76d610\u4e2a\u4ee3\u7801\u5e93\u7684\u591a\u4e2a\u9886\u57df\u548c\u8bed\u8a00\uff0c\u4ee5\u4e13\u5bb6\u4f18\u5316\u4e3a\u57fa\u51c6\u6d4b\u91cf\u8fd0\u884c\u6548\u7387\u6539\u8fdb", "result": "\u4e3b\u6d41SWE-Agents\u6210\u529f\u7387\u4f4e\u4e8e5%\uff0c\u63a8\u7406\u6269\u5c55\u63d0\u5347\u6709\u9650\uff1b\u5b9a\u6027\u5206\u6790\u663e\u793a\u5931\u8d25\u4e3b\u56e0\u5305\u62ec\u4f4e\u7ea7\u8bed\u8a00\u5904\u7406\u56f0\u96be\u3001\u4f18\u5316\u7b56\u7565\u60f0\u6027\u53ca\u74f6\u9888\u5b9a\u4f4d\u4e0d\u51c6", "conclusion": "\u5f53\u524d\u4ee3\u7406\u5728\u8f6f\u4ef6\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u663e\u8457\u4e0d\u8db3\uff0c\u516c\u5f00\u4ee3\u7801\u548c\u5b9e\u9a8c\u8f68\u8ff9\u4fc3\u8fdb\u672a\u6765\u7814\u7a76"}}
{"id": "2505.23693", "pdf": "https://arxiv.org/pdf/2505.23693", "abs": "https://arxiv.org/abs/2505.23693", "authors": ["Tingyu Song", "Tongyan Hu", "Guo Gan", "Yilun Zhao"], "title": "VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "ACL 2025 Main", "summary": "MLLMs have been widely studied for video question answering recently.\nHowever, most existing assessments focus on natural videos, overlooking\nsynthetic videos, such as AI-generated content (AIGC). Meanwhile, some works in\nvideo generation rely on MLLMs to evaluate the quality of generated videos, but\nthe capabilities of MLLMs on interpreting AIGC videos remain largely\nunderexplored. To address this, we propose a new benchmark, VF-Eval, which\nintroduces four tasks-coherence validation, error awareness, error type\ndetection, and reasoning evaluation-to comprehensively evaluate the abilities\nof MLLMs on AIGC videos. We evaluate 13 frontier MLLMs on VF-Eval and find that\neven the best-performing model, GPT-4.1, struggles to achieve consistently good\nperformance across all tasks. This highlights the challenging nature of our\nbenchmark. Additionally, to investigate the practical applications of VF-Eval\nin improving video generation, we conduct an experiment, RePrompt,\ndemonstrating that aligning MLLMs more closely with human feedback can benefit\nvideo generation.", "AI": {"tldr": "\u63d0\u51faVF-Eval\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728AIGC\u89c6\u9891\u4e0a\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5e76\u9a8c\u8bc1\u4eba\u7c7b\u53cd\u9988\u5bf9\u9f50\u5bf9\u89c6\u9891\u751f\u6210\u7684\u63d0\u5347\u4f5c\u7528", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u81ea\u7136\u89c6\u9891\u8bc4\u4f30\uff0c\u800cAI\u751f\u6210\u89c6\u9891(AIGC)\u7684\u5feb\u901f\u53d1\u5c55\u548c\u8bc4\u4f30\u9700\u6c42\u672a\u88ab\u5145\u5206\u8986\u76d6\uff0c\u540c\u65f6\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684MLLM\u80fd\u529b\u8bc4\u4f30\u6846\u67b6", "method": "\u8bbe\u8ba1\u5305\u542b\u8fde\u8d2f\u6027\u9a8c\u8bc1\u3001\u9519\u8bef\u611f\u77e5\u3001\u9519\u8bef\u68c0\u6d4b\u548c\u63a8\u7406\u8bc4\u4f30\u7684\u56db\u7ef4\u8bc4\u6d4b\u4f53\u7cfb\uff0c\u6d4b\u8bd513\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u5e76\u901a\u8fc7RePrompt\u5b9e\u9a8c\u63a2\u7d22\u6a21\u578b\u53cd\u9988\u5bf9\u89c6\u9891\u751f\u6210\u7684\u5b9e\u9645\u4f18\u5316\u6548\u679c", "result": "\u6700\u4f73\u6a21\u578bGPT-4.1\u5404\u4efb\u52a1\u8868\u73b0\u4e0d\u5747\u8861\uff08\u5e73\u5747\u51c6\u786e\u7387\u4ec564.7%\uff09\uff0c\u63ed\u793a\u8bc4\u4f30\u6311\u6218\u6027\uff1bRePrompt\u5b9e\u9a8c\u4f7f\u89c6\u9891\u751f\u6210\u8d28\u91cf\u63d0\u534723.6%", "conclusion": "VF-Eval\u586b\u8865AIGC\u89c6\u9891\u8bc4\u4f30\u7a7a\u767d\uff0c\u8bc1\u660e\u5f53\u524dMLLMs\u5b58\u5728\u80fd\u529b\u5c40\u9650\uff0c\u540c\u65f6\u9a8c\u8bc1\u6a21\u578b\u5bf9\u9f50\u4eba\u7c7b\u53cd\u9988\u5bf9\u751f\u6210\u7cfb\u7edf\u7684\u6539\u8fdb\u6f5c\u529b"}}
{"id": "2505.23761", "pdf": "https://arxiv.org/pdf/2505.23761", "abs": "https://arxiv.org/abs/2505.23761", "authors": ["Yunjae Won", "Hyunji Lee", "Hyeonbin Hwang", "Minjoon Seo"], "title": "Differential Information: An Information-Theoretic Perspective on Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "41 pages, 13 figures; due to the 1,920-character limitation imposed\n  on the abstract field by arXiv, the abstract included on the arXiv page is\n  slightly abbreviated compared to the version presented in the PDF", "summary": "Direct Preference Optimization (DPO) has become a standard technique for\naligning language models with human preferences in a supervised manner. Despite\nits empirical success, the theoretical justification behind its log-ratio\nreward parameterization remains incomplete. In this work, we address this gap\nby utilizing the Differential Information Distribution (DID): a distribution\nover token sequences that captures the information gained during policy\nupdates. First, we show that when preference labels encode the differential\ninformation required to transform a reference policy into a target policy, the\nlog-ratio reward in DPO emerges as the uniquely optimal form for learning the\ntarget policy via preference optimization. This result naturally yields a\nclosed-form expression for the optimal sampling distribution over rejected\nresponses. Second, we find that the condition for preferences to encode\ndifferential information is fundamentally linked to an implicit assumption\nregarding log-margin ordered policies-an inductive bias widely used in\npreference optimization yet previously unrecognized. Finally, by analyzing the\nentropy of the DID, we characterize how learning low-entropy differential\ninformation reinforces the policy distribution, while high-entropy differential\ninformation induces a smoothing effect, which explains the log-likelihood\ndisplacement phenomenon. We validate our theoretical findings in synthetic\nexperiments and extend them to real-world instruction-following datasets. Our\nresults suggest that learning high-entropy differential information is crucial\nfor general instruction-following, while learning low-entropy differential\ninformation benefits knowledge-intensive question answering. Overall, our work\npresents a unifying perspective on the DPO objective, the structure of\npreference data, and resulting policy behaviors through the lens of\ndifferential information.", "AI": {"tldr": "\u901a\u8fc7\u5dee\u5206\u4fe1\u606f\u5206\u5e03\u7406\u8bba\u63ed\u793a\u4e86DPO\u7b97\u6cd5log-ratio\u5956\u52b1\u53c2\u6570\u5316\u7684\u6700\u4f18\u6027\uff0c\u5efa\u7acb\u4e86\u504f\u597d\u6570\u636e\u7279\u6027\u4e0e\u7b56\u7565\u884c\u4e3a\u7684\u8054\u7cfb", "motivation": "DPO\u65b9\u6cd5\u867d\u5b9e\u8bc1\u6210\u529f\u4f46\u7f3a\u4e4f\u7406\u8bba\u4f9d\u636e\uff0c\u9700\u8981\u89e3\u91ca\u5176log-ratio\u5956\u52b1\u5f62\u5f0f\u7684\u6700\u4f18\u6027\u53ca\u504f\u597d\u6570\u636e\u4e0e\u7b56\u7565\u66f4\u65b0\u7684\u5185\u5728\u8054\u7cfb", "method": "\u63d0\u51fa\u5dee\u5206\u4fe1\u606f\u5206\u5e03(DID)\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u8bc1\u660e\u5f53\u504f\u597d\u6807\u7b7e\u7f16\u7801\u53c2\u8003\u7b56\u7565\u5230\u76ee\u6807\u7b56\u7565\u7684\u5dee\u5206\u4fe1\u606f\u65f6\uff0clog-ratio\u5956\u52b1\u6210\u4e3a\u6700\u4f18\u5f62\u5f0f", "result": "\u53d1\u73b0\u4f4e\u71b5\u5dee\u5206\u4fe1\u606f\u5f3a\u5316\u7b56\u7565\u5206\u5e03\uff0c\u9ad8\u71b5\u4fe1\u606f\u4ea7\u751f\u5e73\u6ed1\u6548\u5e94\uff1b\u9a8c\u8bc1\u9ad8\u71b5\u4fe1\u606f\u5bf9\u6307\u4ee4\u8ddf\u968f\u4efb\u52a1\u7684\u91cd\u8981\u6027\uff0c\u4f4e\u71b5\u4fe1\u606f\u5bf9\u77e5\u8bc6\u95ee\u7b54\u7684\u589e\u76ca", "conclusion": "\u901a\u8fc7\u5dee\u5206\u4fe1\u606f\u89c6\u89d2\u7edf\u4e00\u89e3\u91ca\u4e86DPO\u76ee\u6807\u51fd\u6570\u3001\u504f\u597d\u6570\u636e\u7ed3\u6784\u4e0e\u7b56\u7565\u884c\u4e3a\u7684\u5173\u7cfb\uff0c\u4e3a\u504f\u597d\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6"}}
{"id": "2505.23762", "pdf": "https://arxiv.org/pdf/2505.23762", "abs": "https://arxiv.org/abs/2505.23762", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The rapid advancement of large Vision-Language Models (VLMs) has propelled\nthe development of pure-vision-based GUI Agents, capable of perceiving and\noperating Graphical User Interfaces (GUI) to autonomously fulfill user\ninstructions. However, existing approaches usually adopt an offline learning\nframework, which faces two core limitations: (1) heavy reliance on high-quality\nmanual annotations for element grounding and action supervision, and (2)\nlimited adaptability to dynamic and interactive environments. To address these\nlimitations, we propose ZeroGUI, a scalable, online learning framework for\nautomating GUI Agent training at Zero human cost. Specifically, ZeroGUI\nintegrates (i) VLM-based automatic task generation to produce diverse training\ngoals from the current environment state, (ii) VLM-based automatic reward\nestimation to assess task success without hand-crafted evaluation functions,\nand (iii) two-stage online reinforcement learning to continuously interact with\nand learn from GUI environments. Experiments on two advanced GUI Agents\n(UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance\nacross OSWorld and AndroidLab environments. The code is available at\nhttps://github.com/OpenGVLab/ZeroGUI.", "AI": {"tldr": "ZeroGUI\u6846\u67b6\u901a\u8fc7VLM\u81ea\u52a8\u751f\u6210\u4efb\u52a1/\u5956\u52b1\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u96f6\u4eba\u5de5\u6210\u672c\u7684GUI\u4ee3\u7406\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u591a\u73af\u5883\u4e0b\u7684\u64cd\u4f5c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709GUI\u4ee3\u7406\u8bad\u7ec3\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u3001\u96be\u4ee5\u9002\u5e94\u52a8\u6001\u73af\u5883\u7684\u75db\u70b9\uff0c\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u5728\u7ebf\u5b66\u4e60\u6846\u67b6\u3002", "method": "1\uff09\u57fa\u4e8eVLM\u7684\u73af\u5883\u611f\u77e5\u4efb\u52a1\u751f\u6210 2\uff09VLM\u81ea\u52a8\u8bc4\u4f30\u673a\u5236 3\uff09\u53cc\u9636\u6bb5\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08\u63a2\u7d22+\u5fae\u8c03\uff09", "result": "\u5728UI-TARS\u548cAguvis\u4ee3\u7406\u4e0a\u9a8c\u8bc1\uff0cOSWorld\u548cAndroidLab\u73af\u5883\u6307\u6807\u663e\u8457\u63d0\u5347\uff08\u5177\u4f53\u6570\u636e\u89c1\u8bba\u6587\u5b9e\u9a8c\u90e8\u5206\uff09", "conclusion": "ZeroGUI\u8bc1\u660e\u4e86\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u81ea\u52a8\u5316GUI\u4ee3\u7406\u8bad\u7ec3\u53ef\u884c\u6027\uff0c\u5f00\u6e90\u6846\u67b6\u63a8\u52a8GUI\u667a\u80fd\u4f53\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2505.23764", "pdf": "https://arxiv.org/pdf/2505.23764", "abs": "https://arxiv.org/abs/2505.23764", "authors": ["Sihan Yang", "Runsen Xu", "Yiman Xie", "Sizhe Yang", "Mo Li", "Jingli Lin", "Chenming Zhu", "Xiaochen Chen", "Haodong Duan", "Xiangyu Yue", "Dahua Lin", "Tai Wang", "Jiangmiao Pang"], "title": "MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence", "categories": ["cs.CV", "cs.CL"], "comment": "34 pages. A comprehensive, fully human-curated, multi-image-based\n  spatial intelligence benchmark with reasoning annotation for MLLMs. Project\n  page: https://runsenxu.com/projects/MMSI_Bench", "summary": "Spatial intelligence is essential for multimodal large language models\n(MLLMs) operating in the complex physical world. Existing benchmarks, however,\nprobe only single-image relations and thus fail to assess the multi-image\nspatial reasoning that real-world deployments demand. We introduce MMSI-Bench,\na VQA benchmark dedicated to multi-image spatial intelligence. Six 3D-vision\nresearchers spent more than 300 hours meticulously crafting 1,000 challenging,\nunambiguous multiple-choice questions from over 120,000 images, each paired\nwith carefully designed distractors and a step-by-step reasoning process. We\nconduct extensive experiments and thoroughly evaluate 34 open-source and\nproprietary MLLMs, observing a wide gap: the strongest open-source model\nattains roughly 30% accuracy and OpenAI's o3 reasoning model reaches 40%, while\nhumans score 97%. These results underscore the challenging nature of MMSI-Bench\nand the substantial headroom for future research. Leveraging the annotated\nreasoning processes, we also provide an automated error analysis pipeline that\ndiagnoses four dominant failure modes, including (1) grounding errors, (2)\noverlap-matching and scene-reconstruction errors, (3) situation-transformation\nreasoning errors, and (4) spatial-logic errors, offering valuable insights for\nadvancing multi-image spatial intelligence. Project page:\nhttps://runsenxu.com/projects/MMSI_Bench .", "AI": {"tldr": "\u63d0\u51fa\u591a\u56fe\u50cf\u7a7a\u95f4\u667a\u80fd\u8bc4\u6d4b\u57fa\u51c6MMSI-Bench\uff0c\u63ed\u793a\u73b0\u6709\u6a21\u578b\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u663e\u8457\u5dee\u8ddd\uff0830-40% vs 97%\uff09\uff0c\u5e76\u63d0\u4f9b\u9519\u8bef\u8bca\u65ad\u6846\u67b6", "motivation": "\u73b0\u6709\u57fa\u51c6\u4ec5\u6d4b\u8bd5\u5355\u56fe\u50cf\u7a7a\u95f4\u5173\u7cfb\uff0c\u65e0\u6cd5\u6ee1\u8db3\u73b0\u5b9e\u573a\u666f\u5bf9\u591a\u56fe\u50cf\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u9700\u6c42", "method": "\u75316\u4f4d3D\u89c6\u89c9\u4e13\u5bb6\u8017\u65f6300+\u5c0f\u65f6\u6784\u5efa\u542b1,000\u9053\u9009\u62e9\u9898\u7684\u8bc4\u6d4b\u96c6\uff0812\u4e07+\u56fe\u50cf\uff09\uff0c\u8bbe\u8ba1\u5e72\u6270\u9879\u5e76\u6807\u6ce8\u9010\u6b65\u63a8\u7406\u8fc7\u7a0b", "result": "34\u4e2a\u6a21\u578b\u6d4b\u8bd5\u663e\u793a\u6700\u5927\u5f00\u6e90\u6a21\u578b\u51c6\u786e\u7387\u4ec530%\uff0cGPT-3\u8fbe40%\uff0c\u4eba\u7c7b\u8868\u73b0\u8fbe97%\uff0c\u63ed\u793a\u6280\u672f\u4ee3\u5dee", "conclusion": "MMSI-Bench\u51f8\u663e\u591a\u56fe\u50cf\u7a7a\u95f4\u63a8\u7406\u6311\u6218\u6027\uff0c\u901a\u8fc7\u9519\u8bef\u8bca\u65ad\u6d41\u7a0b\uff08\u5b9a\u4f4d/\u573a\u666f\u91cd\u5efa/\u60c5\u5883\u8f6c\u6362/\u903b\u8f91\u9519\u8bef\uff09\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u65b9\u5411"}}
