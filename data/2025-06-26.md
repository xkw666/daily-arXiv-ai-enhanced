<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation](https://arxiv.org/abs/2506.19952)
*Deepon Halder,Thanmay Jayakumar,Raj Dabre*

Main category: cs.CL

TL;DR: 提出CycleDistill方法，通过迭代生成合成平行语料库提升低资源语言的机器翻译质量


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的少样本翻译能力落后于专用系统，而低资源语言缺乏平行语料库

Method: 基于单语料库迭代生成合成平行数据（零样本/少样本翻译），并通过蒸馏微调模型

Result: 首轮迭代即超越基线模型20-30chrF点，softmax激活蒸馏带来小幅提升

Conclusion: CycleDistill有效解决低资源语言翻译难题，无需大规模平行语料即可实现高质量机器翻译

Abstract: Large language models (LLMs), despite their ability to perform few-shot
machine translation (MT), often lag behind dedicated MT systems trained on
parallel corpora, which are crucial for high quality machine translation (MT).
However, parallel corpora are often scarce or non-existent for low-resource
languages. In this paper, we propose CycleDistill, a bootstrapping approach
leveraging LLMs and few-shot translation to obtain high-quality MT systems.
CycleDistill involves iteratively generating synthetic parallel corpora from
monolingual corpora via zero- or few-shot MT, which is then used to fine-tune
the model that was used for generating said data for MT. CycleDistill does not
need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments
focusing on three Indian languages, by relying solely on monolingual corpora,
it can achieve high-quality machine translation, improving upon a few-shot
baseline model by over 20-30 chrF points on average in the first iteration. We
also study the effect of leveraging softmax activations during the distillation
process and observe mild improvements in translation quality.

</details>


### [2] [Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs](https://arxiv.org/abs/2506.19967)
*Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in
language understanding and generation, yet they continue to underperform on
knowledge-intensive reasoning tasks due to limited access to structured context
and multi-hop information. Retrieval-Augmented Generation (RAG) partially
mitigates this by grounding generation in retrieved context, but conventional
RAG and GraphRAG methods often fail to capture relational structure across
nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel
framework that enhances LLM-based graph reasoning by applying inference-time
compute scaling. Our method combines sequential scaling with deep
chain-of-thought graph traversal, and parallel scaling with majority voting
over sampled trajectories within an interleaved reasoning-execution loop.
Experiments on the GRBench benchmark demonstrate that our approach
significantly improves multi-hop question answering performance, achieving
substantial gains over both traditional GraphRAG and prior graph traversal
baselines. These findings suggest that inference-time scaling is a practical
and architecture-agnostic solution for structured knowledge reasoning with LLMs

</details>


### [3] [Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation](https://arxiv.org/abs/2506.19998)
*Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong*

Main category: cs.CL

TL;DR: 提出Doc2Agent流程，通过API文档自动生成Python工具并迭代优化，实现代理性能55%提升且成本降低90%，适用于WebArena和糖材料科学等复杂领域


<details>
  <summary>Details</summary>
Motivation: 现有API代理依赖标准化工具集，无法处理真实世界的复杂API文档。需要解决非结构化文档解析、API测试和参数推断等核心挑战

Method: 1. 从API文档生成可执行工具 2. 使用代码代理进行迭代优化 3. 支持Python工具生成和验证

Result: 在WebArena基准测试中相对性能提升55%，成本降低90%；成功构建糖材料科学领域专用代理，验证复杂知识密集型任务处理能力

Conclusion: Doc2Agent提供可扩展的通用解决方案，能够从非结构化API文档大规模构建工具代理，适应不同领域的复杂需求

Abstract: REST APIs play important roles in enriching the action space of web agents,
yet most API-based agents rely on curated and uniform toolsets that do not
reflect the complexity of real-world APIs. Building tool-using agents for
arbitrary domains remains a major challenge, as it requires reading
unstructured API documentation, testing APIs and inferring correct parameters.
We propose Doc2Agent, a scalable pipeline to build agents that can call
Python-based tools generated from API documentation. Doc2Agent generates
executable tools from API documentations and iteratively refines them using a
code agent. We evaluate our approach on real-world APIs, WebArena APIs, and
research APIs, producing validated tools. We achieved a 55\% relative
performance improvement with 90\% lower cost compared to direct API calling on
WebArena benchmark. A domain-specific agent built for glycomaterial science
further demonstrates the pipeline's adaptability to complex, knowledge-rich
tasks. Doc2Agent offers a generalizable solution for building tool agents from
unstructured API documentation at scale.

</details>


### [4] [A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs](https://arxiv.org/abs/2506.20073)
*Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang*

Main category: cs.CL

TL;DR: 提出了融合大语言模型与时空模型的STReason框架，通过上下文学习实现复杂时空推理任务的多任务推理和可解释输出


<details>
  <summary>Details</summary>
Motivation: 现有时空模型局限于单一任务且缺乏复杂长推理能力，难以应对现实世界中需要深度解释的多元决策场景

Method: 整合LLMs的推理能力和时空模型的分析能力，利用上下文学习将自然语言查询分解为模块化程序并系统执行

Result: 新基准测试显示STReason全面超越先进LLM基线（尤其复杂场景），人类评估验证其可信度和实际应用价值

Conclusion: STReason为发展更强大、泛化性更强的时空推理系统提供了新方向，可有效减轻专家负担并拓展实际应用范围

Abstract: Spatio-temporal data mining plays a pivotal role in informed decision making
across diverse domains. However, existing models are often restricted to narrow
tasks, lacking the capacity for multi-task inference and complex long-form
reasoning that require generation of in-depth, explanatory outputs. These
limitations restrict their applicability to real-world, multi-faceted decision
scenarios. In this work, we introduce STReason, a novel framework that
integrates the reasoning strengths of large language models (LLMs) with the
analytical capabilities of spatio-temporal models for multi-task inference and
execution. Without requiring task-specific finetuning, STReason leverages
in-context learning to decompose complex natural language queries into modular,
interpretable programs, which are then systematically executed to generate both
solutions and detailed rationales. To facilitate rigorous evaluation, we
construct a new benchmark dataset and propose a unified evaluation framework
with metrics specifically designed for long-form spatio-temporal reasoning.
Experimental results show that STReason significantly outperforms advanced LLM
baselines across all metrics, particularly excelling in complex,
reasoning-intensive spatio-temporal scenarios. Human evaluations further
validate STReason's credibility and practical utility, demonstrating its
potential to reduce expert workload and broaden the applicability to real-world
spatio-temporal tasks. We believe STReason provides a promising direction for
developing more capable and generalizable spatio-temporal reasoning systems.

</details>


### [5] [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](https://arxiv.org/abs/2506.20081)
*Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie*

Main category: cs.CL

TL;DR: 论文提出SACL框架，通过语义增强和减少文档偏见，显著提升代码检索效果（如HumanEval基准Recall@1提升12.8%），并改善代码生成性能（HumanEval Pass@1提升4.88%）


<details>
  <summary>Details</summary>
Motivation: 现有代码检索器过度依赖表层文本特征（如文档字符串）且对有良好文档的代码存在偏见，导致检索结果受无关文档影响

Method: 系统性地屏蔽代码特征分析检索机制，提出SACL框架（通过语义信息增强代码结构知识，降低文档偏见）

Result: SACL在HumanEval/MBPP/SWE-Bench-Lite分别提升12.8%/9.4%/7.0% Recall@1；HumanEval代码生成Pass@1提升4.88%

Conclusion: 代码检索质量受表面特征和文档偏见限制，SACL通过语义增强有效突破现有检索瓶颈，为代码生成系统提供更可靠的检索基础

Abstract: Retrieval-Augmented Code Generation (RACG) is a critical technique for
enhancing code generation by retrieving relevant information. In this work, we
conduct an in-depth analysis of code retrieval by systematically masking
specific features while preserving code functionality. Our discoveries include:
(1) although trained on code, current retrievers heavily rely on surface-level
textual features (e.g., docstrings, identifier names), and (2) they exhibit a
strong bias towards well-documented code, even if the documentation is
irrelevant.Based on our discoveries, we propose SACL, a framework that enriches
textual information and reduces bias by augmenting code or structural knowledge
with semantic information. Extensive experiments show that SACL substantially
improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /
MBPP / SWE-Bench-Lite), which also leads to better code generation performance
(e.g., by 4.88% Pass@1 on HumanEval).

</details>


### [6] [Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder](https://arxiv.org/abs/2506.20083)
*Yingji Zhang,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 将组合语义与符号语义融入分布语义空间，提出语义表示学习新范式，通过比较VAE/VQVAE/SAE自编码器的潜在空间几何特性，探索提升语言模型可解释性与组合性的路径。


<details>
  <summary>Details</summary>
Motivation: 解决符号语义与分布语义的割裂问题，通过融合两者的优势来增强Transformer自回归语言模型的可解释性、可控性、组合性和泛化能力。

Method: 系统比较三种自编码架构（变分自编码器VAE、矢量量化VAE、稀疏自编码器SAE），分析其潜在空间几何结构与语义解释性的关联机制。

Result: 不同自编码架构在语义结构表达上存在显著差异：VQVAE通过离散编码增强组合性，SAE的稀疏表征提升可解释性，VAE在生成质量上更具优势。

Conclusion: 语义表示学习为连接符号与分布语义提供了有效框架，自编码器的几何特性选择直接影响语言模型的语义可控制性，这为改进大语言模型提供了新方向。

Abstract: Integrating compositional and symbolic properties into current distributional
semantic spaces can enhance the interpretability, controllability,
compositionality, and generalisation capabilities of Transformer-based
auto-regressive language models (LMs). In this survey, we offer a novel
perspective on latent space geometry through the lens of compositional
semantics, a direction we refer to as \textit{semantic representation
learning}. This direction enables a bridge between symbolic and distributional
semantics, helping to mitigate the gap between them. We review and compare
three mainstream autoencoder architectures-Variational AutoEncoder (VAE),
Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the
distinctive latent geometries they induce in relation to semantic structure and
interpretability.

</details>


### [7] [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)
*Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei*

Main category: cs.CL

TL;DR: 提出首个时序文本QA数据集EngineMT-QA及跨模态框架ITFormer，实现时间序列与自然语言的高效融合


<details>
  <summary>Details</summary>
Motivation: 高维时序信号与自然语言的动态交互存在整合挑战，缺乏有效跨模态建模方法

Method: 构建EngineMT-QA数据集，设计ITFormer框架桥接时序编码器与冻结LLMs，通过特征提取/对齐/融合三阶段实现跨模态交互

Result: QA准确率显著超越基线模型，仅增加0.8%可训练参数，计算效率提升3倍

Conclusion: 建立可适配的时序-语言整合范式，为工业监测/医疗等多模态AI应用开辟新路径

Abstract: Time-series data are critical in diverse applications, such as industrial
monitoring, medical diagnostics, and climate research. However, effectively
integrating these high-dimensional temporal signals with natural language for
dynamic, interactive tasks remains a significant challenge. To address this, we
introduce the Time-Series Question Answering (Time-Series QA) task and release
EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset
designed to capture complex interactions between time-series signals and
natural language. Building on this resource, we propose the Instruct Time
Transformer (ITFormer), a novel framework that bridges time-series encoders
with frozen large language models (LLMs). ITFormer effectively extracts,
aligns, and fuses temporal and textual features, achieving a strong improvement
in QA accuracy over strong baselines with fewer than 1\% additional trainable
parameters. By combining computational efficiency with robust cross-modal
modeling, our work establishes a adaptable paradigm for integrating temporal
data with natural language, paving the way for new research and applications in
multi-modal AI. More details about the project, including datasets and code,
are available at: https://pandalin98.github.io/itformer_site/

</details>


### [8] [A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection](https://arxiv.org/abs/2506.20112)
*Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon*

Main category: cs.CL

TL;DR: 通过三层LLM框架提升放射报告校对效率，PPV提升至0.159，运营成本降低42.6%


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的放射报告校对方法因错误发生率低导致PPV（阳性预测值）受限，需探索更高效的质控方案

Method: 1. 使用三个递进框架：单提示检测器→提取器+检测器→提取器+检测器+误报验证器
2. 基于MIMIC-III等数据库的1,000份放射报告进行回顾分析
3. 采用聚类bootstrap检验、精确McNemar检验进行统计验证

Result: 三层框架使PPV从0.063提升至0.159（p<0.001），每千份报告成本从9.72美元降至5.58美元，人工审核量减少54%

Conclusion: 三阶段LLM框架在保持检测性能的同时显著优化成本效益，为AI辅助放射质控提供可行路径

Abstract: Background: The positive predictive value (PPV) of large language model
(LLM)-based proofreading for radiology reports is limited due to the low error
prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV
and reduces operational costs compared with baseline approaches. Materials and
Methods: A retrospective analysis was performed on 1,000 consecutive radiology
reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III
database. Two external datasets (CheXpert and Open-i) were validation sets.
Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor
plus detector; and (3) extractor, detector, and false-positive verifier.
Precision was measured by PPV and absolute true positive rate (aTPR).
Efficiency was calculated from model inference charges and reviewer
remuneration. Statistical significance was tested using cluster bootstrap,
exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV
increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,
Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.
baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per
1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and
USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.
Human-reviewed reports decreased from 192 to 88. External validation supported
Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR
(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and
reduced operational costs, maintaining detection performance, providing an
effective strategy for AI-assisted radiology report quality assurance.

</details>


### [9] [Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests](https://arxiv.org/abs/2506.20119)
*Masaki Uto,Yuma Ito*

Main category: cs.CL

TL;DR: 提出结合自动评分技术的新型缺失分数填补方法，显著降低人工评分工作量的同时保持能力评估精度


<details>
  <summary>Details</summary>
Motivation: 传统建构反应测试需要大量人工评分导致效率低下，且IRT在缺失数据较多时准确性下降

Method: 通过自动评分技术生成补充评分数据，改进IRT对缺失分数的插补方法

Result: 在显著减少人工评分工作量的前提下，实现了学习者高阶能力评估的高精度估计

Conclusion: 该方法有效解决了稀疏/异质数据场景下的评分缺失问题，为教育评估提供了高效解决方案

Abstract: Evaluating the abilities of learners is a fundamental objective in the field
of education. In particular, there is an increasing need to assess higher-order
abilities such as expressive skills and logical thinking. Constructed-response
tests such as short-answer and essay-based questions have become widely used as
a method to meet this demand. Although these tests are effective, they require
substantial manual grading, making them both labor-intensive and costly. Item
response theory (IRT) provides a promising solution by enabling the estimation
of ability from incomplete score data, where human raters grade only a subset
of answers provided by learners across multiple test items. However, the
accuracy of ability estimation declines as the proportion of missing scores
increases. Although data augmentation techniques for imputing missing scores
have been explored in order to address this limitation, they often struggle
with inaccuracy for sparse or heterogeneous data. To overcome these challenges,
this study proposes a novel method for imputing missing scores by leveraging
automated scoring technologies for accurate IRT-based ability estimation. The
proposed method achieves high accuracy in ability estimation while markedly
reducing manual grading workload.

</details>


### [10] [CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation](https://arxiv.org/abs/2506.20128)
*Aashiq Muhamed*

Main category: cs.CL

TL;DR: 提出CCRS评估框架——包含五个基于预训练大模型的零样本指标，解决RAG系统多维评估难题并提升效率


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估方法存在简单指标无法捕捉多维质量（上下文连贯性/事实正确性等）、复杂框架效率低下的双重困境

Method: 设计Contextual Coherence/Question Relevance等5个指标，利用单一LLM实现端到端评估，避免中间处理步骤

Result: 在BioASQ数据集验证中，CCRS有效区分系统性能（如Mistral-7B优于Llama），且比RAGChecker框架效率提升3倍以上

Conclusion: CCRS构建了兼顾全面性与实用性的评估体系，为RAG系统的迭代优化提供了高效诊断工具

Abstract: RAG systems enhance LLMs by incorporating external knowledge, which is
crucial for domains that demand factual accuracy and up-to-date information.
However, evaluating the multifaceted quality of RAG outputs, spanning aspects
such as contextual coherence, query relevance, factual correctness, and
informational completeness, poses significant challenges. Existing evaluation
methods often rely on simple lexical overlap metrics, which are inadequate for
capturing these nuances, or involve complex multi-stage pipelines with
intermediate steps like claim extraction or require finetuning specialized
judge models, hindering practical efficiency. To address these limitations, we
propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five
metrics that utilizes a single, powerful, pretrained LLM as a zero-shot,
end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance
(QR), Information Density (ID), Answer Correctness (AC), and Information Recall
(IR). We apply CCRS to evaluate six diverse RAG system configurations on the
challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively
discriminates between system performances, confirming, for instance, that the
Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of
CCRS metric properties, including score distributions, convergent/discriminant
validity, tie rates, population statistics, and discriminative power. Compared
to the complex RAGChecker framework, CCRS offers comparable or superior
discriminative power for key aspects like recall and faithfulness, while being
significantly more computationally efficient. CCRS thus provides a practical,
comprehensive, and efficient framework for evaluating and iteratively improving
RAG systems.

</details>


### [11] [AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control](https://arxiv.org/abs/2506.20160)
*Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du*

Main category: cs.CL

TL;DR: 通过整合准确性感知的强化学习奖励机制AALC，在保持数学推理精度的前提下将模型响应长度缩减50%以上，并发现效率提升会伴随可解释性降低


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过冗长思维链提升性能时，产生过高计算成本却未带来相应精度增益，需在训练中动态平衡正确性与简洁性

Method: 开发整合验证准确率的动态长度奖励机制，采用平滑调度策略延迟长度惩罚，直至模型达到目标性能阈值

Result: 在标准/外部分布基准测试中实现响应长度减半，精度维持或提升，同时识别出模型会省略部分解释性叙述框架

Conclusion: 奖励机制能有效引导大型模型生成高效推理路径，但揭示了效率与可解释性之间的内在权衡关系

Abstract: Large reasoning models (LRMs) achieve impressive reasoning capabilities by
generating lengthy chain-of-thoughts, but this "overthinking" incurs high
latency and cost without commensurate accuracy gains. In this work, we
introduce AALC, a lightweight, accuracy-aware length reward integrated into
reinforcement learning that dynamically balances correctness and brevity during
training. By incorporating validation accuracy into the reward and employing a
smooth, dynamically scheduled length penalty, AALC delays length penalty until
target performance is met. Through extensive experiments across standard and
out-of-distribution math benchmarks, we show that our approach reduces response
length by over 50% while maintaining or even improving the original accuracy.
Furthermore, qualitative analysis reveals that our method curbs redundant
reasoning patterns such as excessive subgoal setting and verification, leading
to structurally refined outputs rather than naive truncation. We also identify
that efficiency gains are accompanied by reduced interpretability: models
trained with AALC omit some narrative framing and explanatory context. These
findings highlight the potential of reward-based strategies to guide LRMs
toward more efficient, generalizable reasoning paths.

</details>


### [12] [SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](https://arxiv.org/abs/2506.20167)
*Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma*

Main category: cs.CL

TL;DR: 提出SEED结构编码器，通过整合特征提取、语义对齐、任务映射和语言模型推理，解决时间序列预测中结构依赖与语义推理的割裂问题。


<details>
  <summary>Details</summary>
Motivation: 现有结构编码器缺乏语义推理能力，而大语言模型无法直接处理时间序列数据，导致统一预测系统开发受限。SEED旨在通过模块化架构实现数值模式与语义推理的有效对齐。

Method: 四阶段架构：1) Token-aware编码器提取时间片段；2) 投影模块对齐语言模型嵌入；3) 语义重编程映射到任务原型；4) 冻结语言模型进行预测。实现表示学习与推理过程的解耦。

Result: 实验显示SEED在多个数据集上持续超越基线模型，验证了结构-语义协同建模的有效性。比较研究证实其能弥合数值模式与语义推理的建模鸿沟。

Conclusion: SEED通过模块化设计成功实现时间序列预测中结构建模与语义推理的融合，为构建可迁移的预测系统提供了新范式。

Abstract: Multivariate time series forecasting requires models to simultaneously
capture variable-wise structural dependencies and generalize across diverse
tasks. While structural encoders are effective in modeling feature
interactions, they lack the capacity to support semantic-level reasoning or
task adaptation. Conversely, large language models (LLMs) possess strong
generalization capabilities but remain incompatible with raw time series
inputs. This gap limits the development of unified, transferable prediction
systems. Therefore, we introduce SEED, a structural encoder for
embedding-driven decoding, which integrates four stages: a token-aware encoder
for patch extraction, a projection module that aligns patches with language
model embeddings, a semantic reprogramming mechanism that maps patches to
task-aware prototypes, and a frozen language model for prediction. This modular
architecture decouples representation learning from inference, enabling
efficient alignment between numerical patterns and semantic reasoning.
Empirical results demonstrate that the proposed method achieves consistent
improvements over strong baselines, and comparative studies on various datasets
confirm SEED's role in addressing the structural-semantic modeling gap.

</details>


### [13] [COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees](https://arxiv.org/abs/2506.20178)
*Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.CL

TL;DR: 提出COIN框架，通过统计校准阈值筛选单个生成答案，在控制错误发现率(FDR)的同时显著提升样本保留率。


<details>
  <summary>Details</summary>
Motivation: 传统启发式不确定性量化方法缺乏对错误发现率的正式保障，分形共形预测框架构建的预测集常包含错误答案，限制实际应用价值。

Method: 使用校准集估计经验错误率，采用Clopper-Pearson等置信区间方法建立真实错误率上界，选择最大不确定性阈值实现FDR控制。

Result: COIN在多模态文本生成任务中展现出鲁棒的风险控制能力、高测试时样本保留率，以及在有限校准数据下的预测效率优势。

Conclusion: 该框架兼具统计有效性、预测效率和扩展性，通过灵活的上界构造策略可适配不同应用场景，提升生成系统的可靠性。

Abstract: Uncertainty quantification (UQ) for foundation models is essential to
identify and mitigate potential hallucinations in automatically generated text.
However, heuristic UQ approaches lack formal guarantees for key metrics such as
the false discovery rate (FDR) in selective prediction. Previous work adopts
the split conformal prediction (SCP) framework to ensure desired coverage of
admissible answers by constructing prediction sets, but these sets often
contain incorrect candidates, limiting their practical utility. To address
this, we propose COIN, an uncertainty-guarding selection framework that
calibrates statistically valid thresholds to filter a single generated answer
per question under user-specified FDR constraints. COIN estimates the empirical
error rate on a calibration set and applies confidence interval methods such as
Clopper-Pearson to establish a high-probability upper bound on the true error
rate (i.e., FDR). This enables the selection of the largest uncertainty
threshold that ensures FDR control on test data while significantly increasing
sample retention. We demonstrate COIN's robustness in risk control, strong
test-time power in retaining admissible answers, and predictive efficiency
under limited calibration data across both general and multimodal text
generation tasks. Furthermore, we show that employing alternative upper bound
constructions and UQ strategies can further boost COIN's power performance,
which underscores its extensibility and adaptability to diverse application
scenarios.

</details>


### [14] [How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?](https://arxiv.org/abs/2506.20199)
*Mengqi Wang,Tiantian Feng,Shrikanth Narayanan*

Main category: cs.CL

TL;DR: 通过增强样本检索策略（包含改写与语义连贯的示例），显著提升对话情绪识别任务在多数据集上的准确率


<details>
  <summary>Details</summary>
Motivation: 针对LLM在情绪识别等主观任务中的性能提升难题，受GenSER挑战赛启发探索对话情绪识别优化方案

Method: 提出随机检索/增强检索策略，分析对话上下文对识别效果的影响，在IEMOCAP/MELD/EmoryNLP数据集验证

Result: 增强检索策略在所有数据集持续超越其他方法（准确率最高提升4.2%）

Conclusion: 构建语义连贯的目标样本并通过改写增强，是提升对话情绪识别精度的关键路径

Abstract: Large language models (LLMs) have enabled a wide variety of real-world
applications in various domains. However, creating a high-performing
application with high accuracy remains challenging, particularly for subjective
tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this
study investigates approaches to improving conversational emotion recognition
(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples
in in-context learning (ICL) to enhance CER. We propose various strategies
based on random and augmented example retrieval and also analyze the impact of
conversational context on CER accuracy. Experiments were conducted on the three
datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented
example retrieval consistently outperforms other techniques under investigation
across all datasets, highlighting the importance of retrieving coherent
targeted examples and enhancing them through paraphrasing.

</details>


### [15] [Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation](https://arxiv.org/abs/2506.20203)
*Petra Barančíková,Ondřej Bojar*

Main category: cs.CL

TL;DR: 比较捷克特定与多语言句子嵌入模型，发现内在语义优势与下游任务表现不一致


<details>
  <summary>Details</summary>
Motivation: 探究句子嵌入模型在语义相似性测试与机器翻译评估任务中的表现差异

Method: 通过Costra数据集和STS基准进行内在语义评估，结合COMET指标进行机器翻译评估的微调实验

Result: 内在测试优异模型在下游任务未必优秀，空间平滑模型经微调后反能取得更好效果

Conclusion: 语义属性探针与下游任务存在复杂关联，需深入研究'可操作化语义'或构建更精细的下游任务数据集

Abstract: In this paper, we compare Czech-specific and multilingual sentence embedding
models through intrinsic and extrinsic evaluation paradigms. For intrinsic
evaluation, we employ Costra, a complex sentence transformation dataset, and
several Semantic Textual Similarity (STS) benchmarks to assess the ability of
the embeddings to capture linguistic phenomena such as semantic similarity,
temporal aspects, and stylistic variations. In the extrinsic evaluation, we
fine-tune each embedding model using COMET-based metrics for machine
translation evaluation.
  Our experiments reveal an interesting disconnect: models that excel in
intrinsic semantic similarity tests do not consistently yield superior
performance on downstream translation evaluation tasks. Conversely, models with
seemingly over-smoothed embedding spaces can, through fine-tuning, achieve
excellent results. These findings highlight the complex relationship between
semantic property probes and downstream task, emphasizing the need for more
research into 'operationalizable semantics' in sentence embeddings, or more
in-depth downstream tasks datasets (here translation evaluation)

</details>


### [16] [Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems](https://arxiv.org/abs/2506.20209)
*Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti*

Main category: cs.CL

TL;DR: 提出基于多视角软标签的NLP建模方法，在保留标注分歧的同时提升分类性能与模型包容性


<details>
  <summary>Details</summary>
Motivation: 传统NLP方法通过聚合标注者观点构建单一事实，导致少数派观点被压制，尤其在主观性任务中会引发模型偏见。本研究旨在通过保留个体标注差异来开发更具包容性的模型。

Method: 1. 引入多视角学习框架，采用软标签编码标注分歧
2. 在仇恨言论检测、讽刺识别、立场检测等主观任务中验证
3. 结合Jensen-Shannon散度评估分布近似度

Result: 1. 相比传统方法JSD降低35%，F1提升8%
2. 在讽刺检测等任务中模型置信度下降，反映主观性挑战
3. XAI分析揭示模型在模糊样本中的决策不确定性

Conclusion: 多视角建模有效保留人类认知多样性，推动NLP向包容性方向发展。模型不确定性分析为改进主观任务提供了新方向，XAI工具在解释复杂决策中发挥关键作用。

Abstract: In the realm of Natural Language Processing (NLP), common approaches for
handling human disagreement consist of aggregating annotators' viewpoints to
establish a single ground truth. However, prior studies show that disregarding
individual opinions can lead can lead to the side effect of underrepresenting
minority perspectives, especially in subjective tasks, where annotators may
systematically disagree because of their preferences. Recognizing that labels
reflect the diverse backgrounds, life experiences, and values of individuals,
this study proposes a new multi-perspective approach using soft labels to
encourage the development of the next generation of perspective aware models,
more inclusive and pluralistic. We conduct an extensive analysis across diverse
subjective text classification tasks, including hate speech, irony, abusive
language, and stance detection, to highlight the importance of capturing human
disagreements, often overlooked by traditional aggregation methods. Results
show that the multi-perspective approach not only better approximates human
label distributions, as measured by Jensen-Shannon Divergence (JSD), but also
achieves superior classification performance (higher F1 scores), outperforming
traditional approaches. However, our approach exhibits lower confidence in
tasks like irony and stance detection, likely due to the inherent subjectivity
present in the texts. Lastly, leveraging Explainable AI (XAI), we explore model
uncertainty and uncover meaningful insights into model predictions.

</details>


### [17] [Enhancing Large Language Models through Structured Reasoning](https://arxiv.org/abs/2506.20241)
*Yubo Dong,Hehe Fan*

Main category: cs.CL

TL;DR: 论文提出通过显式结构化推理增强大语言模型，通过结构化数据标注、监督微调和GRPO优化策略提升LLMs的复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs依赖隐式统计关系，缺乏结构化知识表示，导致复杂逻辑推理和系统规划任务表现不足。

Method: 1. 将非结构化数据转换为显式标注推理步骤的结构化格式
2. 使用监督微调(SFT)训练模型
3. 采用GRPO优化策略整合MAX-Flow和LCS算法提升推理效率

Result: 实验显示优化后的DeepSeek-R1-Distill-Qwen-1.5B模型具有简洁推理能力、跨场景鲁棒性及更好的优化技术兼容性

Conclusion: 结构化推理机制显著增强LLMs的逻辑推理能力，验证了显式知识注入的有效性

Abstract: Recent Large Language Models (LLMs) have significantly advanced natural
language processing and automated decision-making. However, these models still
encounter difficulties when performing complex reasoning tasks involving
logical deduction and systematic planning, primarily due to their reliance on
implicit statistical relationships without structured knowledge
representation.Inspired by cognitive science and neurosymbolic AI, we introduce
a novel approach to enhance LLMs through explicit structured reasoning. First,
we convert unstructured data into structured formats by explicitly annotating
reasoning steps. We then employ this structured dataset to train LLMs through
Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning
capabilities of LLMs using Group Relative Policy Optimization (GRPO),
incorporating two innovative algorithms--MAX-Flow and Longest Common
Subsequence (LCS)--which notably improve reasoning effectiveness and reduce
computational complexity. Experimental results from fine-tuning a
DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust
performance across various scenarios, and improved compatibility with
optimization techniques, validating the efficacy of structured reasoning
integration in LLMs.

</details>


### [18] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

Main category: cs.CL

TL;DR: 提出基于分块的多自监督学习融合方法，结合CNN-BiLSTM框架提升非母语语音流畅度评估效果


<details>
  <summary>Details</summary>
Motivation: 现有自动流畅度评估方法难以有效捕捉非母语者的语音节奏特征（停顿/不流畅），需融合多维度声学特征并解决传统分段方法的过分割问题

Method: 1. 集成Wav2Vec2/HuBERT/WavLM三种SSL模型互补优势 2. 使用Silero-VAD进行呼吸组分块 3. 引入可学习加权机制融合声学-语言特征 4. 结合CNN-BiLSTM捕捉局部和长程依赖

Result: 在Speechocean762上F1提升2.8分/Pearson相关系数提高6.2分；Avalinguo数据集F1提升4.2分/Pearson提高4.0分，均超越Pyannote基线

Conclusion: 分块式多SSL融合显著提升流畅度评估效果，但未来需增强对非常规韵律方言的适应能力

Abstract: Automatic fluency assessment (AFA) remains challenging, particularly in
capturing speech rhythm, pauses, and disfluencies in non-native speakers. We
introduce a chunk-based approach integrating self-supervised learning (SSL)
models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths
in phonetic, prosodic, and noisy speech modeling, with a hierarchical
CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero
voice activity detection (Silero-VAD), enabling fine-grained temporal analysis
while mitigating over-segmentation artifacts. SSL embeddings are fused via a
learnable weighted mechanism, balancing acoustic and linguistic features, and
enriched with chunk-level fluency markers (e.g., speech rate, pause durations,
n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies
across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves
F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines
on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on
Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These
findings highlight chunk-based multi-SSL fusion for robust fluency evaluation,
though future work should explore generalization to dialects with irregular
prosody.

</details>


### [19] [Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models](https://arxiv.org/abs/2506.20269)
*Kai-Robin Lange,Tobias Schmidt,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

Main category: cs.CL

TL;DR: 提出结合大型语言模型与主题模型的管道方法，动态追踪媒体叙事变化，并以《华尔街日报》2009-2023年文章验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有叙事提取方法处理全语料库时面临高成本/计算难题，需结合LLM语言理解与主题模型扩展性实现动态叙事演变分析

Method: 采用主题模型+变点检测定位主题变化节点，筛选代表性文档后通过LLM自动解析变化类型(内容/叙事)

Result: LLM可有效检测时间节点上的叙事变化存在性，但在区分内容变化与叙事变化时表现欠佳

Conclusion: LLM在自动化叙事分析中具备高效性但存在复杂分类局限，结合方法可实现大规模叙事动态建模

Abstract: With rapidly evolving media narratives, it has become increasingly critical
to not just extract narratives from a given corpus but rather investigate, how
they develop over time. While popular narrative extraction methods such as
Large Language Models do well in capturing typical narrative elements or even
the complex structure of a narrative, applying them to an entire corpus comes
with obstacles, such as a high financial or computational cost. We propose a
combination of the language understanding capabilities of Large Language Models
with the large scale applicability of topic models to dynamically model
narrative shifts across time using the Narrative Policy Framework. We apply a
topic model and a corresponding change point detection method to find changes
that concern a specific topic of interest. Using this model, we filter our
corpus for documents that are particularly representative of that change and
feed them into a Large Language Model that interprets the change that happened
in an automated fashion and distinguishes between content and narrative shifts.
We employ our pipeline on a corpus of The Wall Street Journal news paper
articles from 2009 to 2023. Our findings indicate that a Large Language Model
can efficiently extract a narrative shift if one exists at a given point in
time, but does not perform as well when having to decide whether a shift in
content or a narrative shift took place.

</details>


### [20] [Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content](https://arxiv.org/abs/2506.20331)
*Rian Touchent,Nathan Godey,Eric de la Clergerie*

Main category: cs.CL

TL;DR: 研究者通过两阶段标注流程构建了Biomed-Enriched生物医学数据集，包含临床案例和高质量教育内容，实验显示其能有效提升医学NLP模型性能并降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 临床文本通常因隐私限制难以获取，PubMed临床案例成为替代资源。该数据集旨在提供大规模开放的临床案例集合，支持生物医学NLP研究。

Method: 1. 大语言模型标注40万PubMed段落（类型/领域/教育质量）→ 2. 微调小模型实现全库标签传播 → 3. 质量过滤+领域上采样构建子集

Result: 提取200万临床案例（含45万高质量），临床上采样使MMLU ProfMed提升5%，教育过滤提高MedQA/MedMCQA 1%，组合策略节省66%训练token

Conclusion: Biomed-Enriched为医学NLP提供结构化数据支持，验证了定向数据筛选的高效预训练策略，推动临床文本分析的资源开放与模型优化

Abstract: We introduce Biomed-Enriched, a biomedical text dataset constructed from
PubMed via a two-stage annotation process. In the first stage, a large language
model annotates 400K paragraphs from PubMed scientific articles, assigning
scores for their type (review, study, clinical case, other), domain (clinical,
biomedical, other), and educational quality. The educational quality score
(rated 1 to 5) estimates how useful a paragraph is for college-level learning.
These annotations are then used to fine-tune a small language model, which
propagates the labels across the full PMC-OA corpus. The resulting metadata
allows us to extract refined subsets, including 2M clinical case paragraphs
with over 450K high-quality ones from articles with commercial-use licenses,
and to construct several variants via quality filtering and domain upsampling.
Clinical text is typically difficult to access due to privacy constraints, as
hospital records cannot be publicly shared. Hence, our dataset provides an
alternative large-scale, openly available collection of clinical cases from
PubMed, making it a valuable resource for biomedical and clinical NLP.
Preliminary continual-pretraining experiments with OLMo2 suggest these curated
subsets enable targeted improvements, with clinical upsampling boosting
performance by ~5% on MMLU ProfMed and educational quality filtering improving
MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster
convergence, reaching same performance with a third of training tokens,
indicating potential for more efficient and effective biomedical pretraining
strategies.

</details>


### [21] [TAPS: Tool-Augmented Personalisation via Structured Tagging](https://arxiv.org/abs/2506.20409)
*Ekaterina Taktasheva,Jeff Dalton*

Main category: cs.CL

TL;DR: 提出TAPS框架，通过结构化标记工具和不确定性检测机制，显著提升大型语言模型整合用户偏好的能力


<details>
  <summary>Details</summary>
Motivation: 现有工具增强型语言模型在整合用户偏好方面存在不足，尤其在目标导向的对话任务中难以有效个性化工具调用

Method: 结合结构化标记工具（组织用户偏好）和基于不确定性的工具检测器（动态选择适配工具）

Result: 在NLSI基准测试中取得开源模型新SOTA，个性化工具调用准确率提升21.3%

Conclusion: TAPS通过系统化架构设计有效解决了LLM个性化工具调用难题，为开源社区提供了可扩展的个性化AI框架

Abstract: Recent advancements in tool-augmented large language models have enabled them
to interact with external tools, enhancing their ability to perform complex
user tasks. However, existing approaches overlook the role of personalisation
in guiding tool use. This work investigates how user preferences can be
effectively integrated into goal-oriented dialogue agents. Through extensive
analysis, we identify key weaknesses in the ability of LLMs to personalise tool
use. To this end, we introduce \name, a novel solution that enhances
personalised tool use by leveraging a structured tagging tool and an
uncertainty-based tool detector. TAPS significantly improves the ability of
LLMs to incorporate user preferences, achieving the new state-of-the-art for
open source models on the NLSI task.

</details>


### [22] [An Agentic System for Rare Disease Diagnosis with Traceable Reasoning](https://arxiv.org/abs/2506.20430)
*Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie*

Main category: cs.CL

TL;DR: 首个基于大语言模型的罕见病诊断系统DeepRare，通过模块化架构整合40+工具与实时医学知识，在8个数据集中实现100%准确诊断1013种疾病，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决全球3亿罕见病患者因临床异质性、低患病率和医生知识局限导致的诊断困境，构建智能化诊断工具。

Method: 三模块架构：1) 带长期记忆的中央主机 2) 整合40+工具与实时医学知识的专业代理服务器 3) 可扩展的透明推理机制。

Result: HPO评估Recall@1达57.18%(超第二名23.79%)，多模态输入Recall@1 70.60%，临床专家验证同意率95.4%，已部署为网页应用(http://raredx.cn/doctor)。

Conclusion: 模块化LLM系统显著提升罕见病诊断效率，透明推理链与实时知识更新确保临床可靠性，实际应用验证其有效性。

Abstract: Rare diseases collectively affect over 300 million individuals worldwide, yet
timely and accurate diagnosis remains a pervasive challenge. This is largely
due to their clinical heterogeneity, low individual prevalence, and the limited
familiarity most clinicians have with rare conditions. Here, we introduce
DeepRare, the first rare disease diagnosis agentic system powered by a large
language model (LLM), capable of processing heterogeneous clinical inputs. The
system generates ranked diagnostic hypotheses for rare diseases, each
accompanied by a transparent chain of reasoning that links intermediate
analytic steps to verifiable medical evidence.
  DeepRare comprises three key components: a central host with a long-term
memory module; specialized agent servers responsible for domain-specific
analytical tasks integrating over 40 specialized tools and web-scale,
up-to-date medical knowledge sources, ensuring access to the most current
clinical information. This modular and scalable design enables complex
diagnostic reasoning while maintaining traceability and adaptability. We
evaluate DeepRare on eight datasets. The system demonstrates exceptional
diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013
diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15
methods, like traditional bioinformatics diagnostic tools, LLMs, and other
agentic systems, achieving an average Recall@1 score of 57.18% and surpassing
the second-best method (Reasoning LLM) by a substantial margin of 23.79
percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at
Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of
reasoning chains by clinical experts achieves 95.40% agreements. Furthermore,
the DeepRare system has been implemented as a user-friendly web application
http://raredx.cn/doctor.

</details>


### [23] [Probing AI Safety with Source Code](https://arxiv.org/abs/2506.20471)
*Ujwal Narayan,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Karthik Narasimhan,Ameet Deshpande,Vishvak Murahari*

Main category: cs.CL

TL;DR: CoDoT提示策略揭示当前大语言模型存在严重安全隐患，毒性内容生成量激增16-300%


<details>
  <summary>Details</summary>
Motivation: 现有模型安全措施无法有效阻止有害内容生成，需开发更本质的安全评估方法

Method: 将自然语言指令转换为等价代码形式（如make_more_toxic({text})），突破现有安全防护机制

Result: GPT-4毒性提升16.5倍，DeepSeek R1全部失效，7个主流模型平均毒性增加300%，递归使用毒性翻倍

Conclusion: 模型安全应与能力同步发展，需从第一性原理重构安全评估体系

Abstract: Large language models (LLMs) have become ubiquitous, interfacing with humans
in numerous safety-critical applications. This necessitates improving
capabilities, but importantly coupled with greater safety measures to align
these models with human values and preferences. In this work, we demonstrate
that contemporary models fall concerningly short of the goal of AI safety,
leading to an unsafe and harmful experience for users. We introduce a prompting
strategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT
converts natural language inputs to simple code that represents the same
intent. For instance, CoDoT transforms the natural language prompt "Make the
statement more toxic: {text}" to: "make_more_toxic({text})". We show that CoDoT
results in a consistent failure of a wide range of state-of-the-art LLMs. For
example, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of
the time, and toxicity increases 300% on average across seven modern LLMs.
Additionally, recursively applying CoDoT can further increase toxicity two
times. Given the rapid and widespread adoption of LLMs, CoDoT underscores the
critical need to evaluate safety efforts from first principles, ensuring that
safety and capabilities advance together.

</details>


### [24] [Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations](https://arxiv.org/abs/2506.20474)
*Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出一种计算框架，分析对话中谈话时间的分配动态及其对参与者感知的影响


<details>
  <summary>Details</summary>
Motivation: 研究对话中谈话时间分配的动态机制及其对交流体验的影响，现有研究缺乏对底层动态过程的量化分析方法

Method: 构建包含对话层面时间分布和微观动态过程的计算框架，通过大规模陌生人视频聊天数据集进行验证

Result: 平衡对话更受偏好（尤其对说话较少者），即使整体平衡相同，不同动态类型仍导致感知差异

Conclusion: 该框架为通信平台设计提供了新工具，适用于人机/人人交互场景的动态优化分析

Abstract: An intrinsic aspect of every conversation is the way talk-time is shared
between multiple speakers. Conversations can be balanced, with each speaker
claiming a similar amount of talk-time, or imbalanced when one talks
disproportionately. Such overall distributions are the consequence of
continuous negotiations between the speakers throughout the conversation: who
should be talking at every point in time, and for how long?
  In this work we introduce a computational framework for quantifying both the
conversation-level distribution of talk-time between speakers, as well as the
lower-level dynamics that lead to it. We derive a typology of talk-time sharing
dynamics structured by several intuitive axes of variation. By applying this
framework to a large dataset of video-chats between strangers, we confirm that,
perhaps unsurprisingly, different conversation-level distributions of talk-time
are perceived differently by speakers, with balanced conversations being
preferred over imbalanced ones, especially by those who end up talking less.
Then we reveal that -- even when they lead to the same level of overall balance
-- different types of talk-time sharing dynamics are perceived differently by
the participants, highlighting the relevance of our newly introduced typology.
Finally, we discuss how our framework offers new tools to designers of
computer-mediated communication platforms, for both human-human and human-AI
communication.

</details>


### [25] [Knowledge-Aware Diverse Reranking for Cross-Source Question Answering](https://arxiv.org/abs/2506.20476)
*Tong Zhou*

Main category: cs.CL

TL;DR: Marikarp团队提出知识感知多样化重排RAG流程，在SIGIR 2025 LiveRAG竞赛中夺冠


<details>
  <summary>Details</summary>
Motivation: 应对DataMorgana生成的多样化评估集（涵盖多主题/题型/知识组织形式）的检索挑战

Method: 采用知识感知的多样化重排策略优化RAG流程

Result: 在包含1500万文档的FineWeb子集检索任务中取得竞赛第一名

Conclusion: 该方法在复杂评估环境下验证了知识增强检索的有效性，为RAG系统优化提供新思路

Abstract: This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG
competition. The competition's evaluation set, automatically generated by
DataMorgana from internet corpora, encompassed a wide range of target topics,
question types, question formulations, audience types, and knowledge
organization methods. It offered a fair evaluation of retrieving
question-relevant supporting documents from a 15M documents subset of the
FineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline
achieved first place in the competition.

</details>


### [26] [GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching](https://arxiv.org/abs/2506.20480)
*Guinan Su,Li Shen,Lu Yin,Shiwei Liu,Yanwu Yang,Jonas Geiping*

Main category: cs.CL

TL;DR: 提出通过策略性合并不同微调模型的分层来压缩LLMs，在减少25%参数量的同时保持97.3%原始性能


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法局限于单一模型优化，无法整合不同微调模型的优势能力，需要更高效的模型压缩方案

Method: 构建支持层移除/选择/合并的三维搜索空间，将模型压缩建模为零阶优化问题

Result: Llama2-13B压缩后参数量减少约25%，性能保留率达97.3%，超越现有SOTA方法

Conclusion: 分层组合策略有效平衡模型压缩与能力保留，为LLM高效部署提供新方向

Abstract: Large language models (LLMs) have shown remarkable capabilities in language
understanding and generation. However, such impressive capability typically
comes with a substantial model size, which presents significant challenges in
deployment and inference. While structured pruning of model parameters offers a
promising way to reduce computational costs at deployment time, current methods
primarily focus on single model pruning. In this work, we develop a novel
strategy to compress models by strategically combining or merging layers from
finetuned model variants, which preserves the original model's abilities by
aggregating capabilities accentuated in different finetunes. We pose the
optimal tailoring of these LLMs as a zero-order optimization problem, adopting
a search space that supports three different operations: (1) Layer removal, (2)
Layer selection from different candidate models, and (3) Layer merging. Our
experiments demonstrate that this approach leads to competitive model pruning,
for example, for the Llama2-13B model families, our compressed models maintain
approximately 97.3\% of the original performance while removing $\sim25\%$ of
parameters, significantly outperforming previous state-of-the-art methods. The
code is available at https://github.com/Guinan-Su/auto-merge-llm.

</details>


### [27] [ReCode: Updating Code API Knowledge with Reinforcement Learning](https://arxiv.org/abs/2506.20495)
*Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 提出ReCode框架，通过规则增强的强化学习提升LLMs在动态API场景中的代码生成能力，同时保持模型通用性


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在应对API频繁更新时表现不足，因其依赖训练数据中过时的API知识，亟需解决动态环境下的可靠代码生成问题

Method: 构建2,000条数据训练版本迁移能力，设计改进的字符串相似度指标作为强化学习奖励，应用GRPO/DAPO算法进行训练

Result: ReCode显著提升LLMs在动态API任务表现（尤其在CodeUpdateArena），Qwen2.5-Coder-7B超越32B参数模型

Conclusion: ReCode在保持模型通用能力前提下有效解决API动态更新问题，适用于多种LLM和强化学习算法，提供开源代码实现

Abstract: Large Language Models (LLMs) exhibit remarkable code generation capabilities
but falter when adapting to frequent updates in external library APIs. This
critical limitation, stemming from reliance on outdated API knowledge from
their training data, even with access to current documentation, impedes
reliable code generation in dynamic environments. To tackle this issue, we
propose ReCode (rule-based Reinforcement learning for Code Update), a novel
framework that mimics human programmer adaptation to API changes. Specifically,
we construct a dataset of approximately 2,000 data entries to train the LLMs to
perform version migration based on updated information. Then, we introduce a
modified string similarity metric for code evaluation as the reward for
reinforcement learning. Our experiments demonstrate that ReCode substantially
boosts LLMs' code generation performance in dynamic API scenarios, especially
on the unseen CodeUpdateArena task. Crucially, compared to supervised
fine-tuning, ReCode has less impact on LLMs' general code generation abilities.
We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and
DAPO), all achieving consistent improvements. Notably, after training,
Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned
model and the reasoning model with the same architecture. Code is available at
https://github.com/zjunlp/ReCode.

</details>


### [28] [OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling](https://arxiv.org/abs/2506.20512)
*Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu*

Main category: cs.CL

TL;DR: 通过分析Qwen/Llama模型的中训练策略对强化学习的影响，发现高质量数学语料和两阶段训练策略能显著提升RL性能，并开源了OctoThinker模型系列和70B数学推理语料库。


<details>
  <summary>Details</summary>
Motivation: 探究不同基座模型在强化学习中表现差异的根本原因，为开发下一代RL兼容性强的基座模型提供指导

Method: 通过四组对比实验分析中期训练策略（数学语料/QA数据/指令数据/训练规模）对RL动态的影响，提出包含稳定学习率阶段和衰减阶段的Stable-then-Decay两阶段训练策略

Result: 1. MegaMath数学语料显著提升RL性能 2. 长思维链数据增强推理深度但需注意数据格式化 3. 两阶段策略使OctoThinker模型缩小与Qwen的性能差距

Conclusion: 通过优化中期训练策略可有效提升模型RL兼容性，开源的OctoThinker模型和MegaMath-Web-Pro-Max语料库将推动RL时代的基础模型研究

Abstract: Different base language model families, such as Llama and Qwen, exhibit
divergent behaviors during post-training with reinforcement learning (RL),
especially on reasoning-intensive tasks. What makes a base language model
suitable for reinforcement learning? Gaining deeper insight into this question
is essential for developing RL-scalable foundation models of the next
generation. In this work, we investigate how mid-training strategies shape RL
dynamics, focusing on two representative model families: Qwen and Llama. Our
study reveals that (1) high-quality mathematical corpora, such as
MegaMath-Web-Pro, significantly improve both base model and RL performance,
while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further
adding QA-style data, particularly long chain-of-thought (CoT) reasoning
examples, enhances RL outcomes, and instruction data further unlocks this
effect; (3) while long-CoT improves reasoning depth, it can also induce
verbosity of model responses and unstability of RL training, underscoring the
importance of data formatting; (4) scaling mid-training consistently leads to
stronger downstream RL performance. Building on these insights, we introduce a
two-stage mid-training strategy, Stable-then-Decay, in which base models are
first trained on 200B tokens with a constant learning rate, followed by 20B
tokens across three CoT-focused branches with learning rate decay. This yields
OctoThinker, a family of models demonstrating strong RL compatibility and
closing the performance gap with more RL-friendly model families, i.e., Qwen.
We hope our work will help shape pre-training strategies for foundation models
in the RL era. To support further research, we release our open-source models
along with a curated math reasoning-intensive corpus of over 70 billion tokens
(i.e., MegaMath-Web-Pro-Max).

</details>


### [29] [When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs](https://arxiv.org/abs/2506.20544)
*Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker*

Main category: cs.CL

TL;DR: 提出新型多语言/多任务推理计算方法，通过自适应采样策略+改进型选择机制，在8B/111B模型上实现6.8-9.0%性能提升


<details>
  <summary>Details</summary>
Motivation: 现有推理计算优化方法局限于英语及特定领域（如数学/编程），缺乏跨语言/开放任务的通用性解决方案。尤其在低资源语言场景存在性能瓶颈

Method: 开发语言/任务感知的采样策略（温度参数动态调整）+ 改进型多语言选择机制，建立m-ArenaHard-v2.0基准测试平台进行验证

Result: 8B模型在m-ArenaHard-v2.0实现平均+6.8%胜率提升；111B模型（Command-A）仅用5样本即获+9.0%改进，显著优于单样本解码

Conclusion: 证明语言/任务适配的推理计算策略必要性，为低资源语言提供低成本性能提升方案，推动AI技术民主化进程

Abstract: Recent advancements in large language models (LLMs) have shifted focus toward
scaling inference-time compute, improving performance without retraining the
model. A common approach is to sample multiple outputs in parallel, and select
one of these as the final output. However, work to date has focused on English
and a handful of domains such as math and code. In contrast, we are most
interested in techniques that generalize across open-ended tasks, formally
verifiable tasks, and across languages. In this work, we study how to robustly
scale inference-time compute for open-ended generative tasks in a multilingual,
multi-task setting.
  Our findings show that both sampling strategy based on temperature variation
and selection strategy must be adapted to account for diverse domains and
varied language settings. We evaluate existing selection methods, revealing
that strategies effective in English often fail to generalize across languages.
We propose novel sampling and selection strategies specifically adapted for
multilingual and multi-task inference scenarios, and show they yield notable
gains across languages and tasks. In particular, our combined sampling and
selection methods lead to an average +6.8 jump in win-rates for our 8B models
on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At
larger scale, Command-A (111B model) equipped with our methods, shows +9.0
improvement in win-rates on the same benchmark with just five samples against
single-sample decoding, a substantial increase at minimal cost. Our results
underscore the need for language- and task-aware approaches to inference-time
compute, aiming to democratize performance improvements in underrepresented
languages.

</details>


### [30] [Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm](https://arxiv.org/abs/2506.20606)
*Baixiang Huang,Zhen Tan,Haoran Wang,Zijie Liu,Dawei Li,Ali Payani,Huan Liu,Tianlong Chen,Kai Shu*

Main category: cs.CL

TL;DR: 提出通过行为编辑技术动态调整LLM智能体的伦理行为，并构建多层次评测基准BehaviorBench验证有效性


<details>
  <summary>Details</summary>
Motivation: LLM智能体在高风险领域存在严重伦理安全隐患，现有模型编辑技术为解决该问题提供了新思路

Method: 将行为引导构建为模型编辑任务（Behavior Editing），基于心理学道德理论开发多层级评测基准BehaviorBench

Result: 行为编辑既能实现场景化道德校准，也能全局改变智能体道德倾向，但存在被恶意利用风险

Conclusion: 提出智能体行为引导新范式，揭示行为编辑技术兼具伦理治理潜力与安全风险的双刃剑特性

Abstract: Agents based on Large Language Models (LLMs) have demonstrated strong
capabilities across a wide range of tasks. However, deploying LLM-based agents
in high-stakes domains comes with significant safety and ethical risks.
Unethical behavior by these agents can directly result in serious real-world
consequences, including physical harm and financial loss. To efficiently steer
the ethical behavior of agents, we frame agent behavior steering as a model
editing task, which we term Behavior Editing. Model editing is an emerging area
of research that enables precise and efficient modifications to LLMs while
preserving their overall capabilities. To systematically study and evaluate
this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in
psychological moral theories. This benchmark supports both the evaluation and
editing of agent behaviors across a variety of scenarios, with each tier
introducing more complex and ambiguous scenarios. We first demonstrate that
Behavior Editing can dynamically steer agents toward the target behavior within
specific scenarios. Moreover, Behavior Editing enables not only
scenario-specific local adjustments but also more extensive shifts in an
agent's global moral alignment. We demonstrate that Behavior Editing can be
used to promote ethical and benevolent behavior or, conversely, to induce
harmful or malicious behavior. Through comprehensive evaluations on agents
based on frontier LLMs, BehaviorBench shows the effectiveness of Behavior
Editing across different models and scenarios. Our findings offer key insights
into a new paradigm for steering agent behavior, highlighting both the promise
and perils of Behavior Editing.

</details>


### [31] [DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation](https://arxiv.org/abs/2506.20639)
*Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang*

Main category: cs.CL

TL;DR: 提出DiffuCoder扩散大语言模型及coupled-GRPO强化学习方法，提升代码生成性能


<details>
  <summary>Details</summary>
Motivation: 探索扩散语言模型在代码生成中的潜力，解决现有dLLMs训练和推理机制研究不足的问题

Method: 基于130B代码数据训练7B参数模型，提出互补掩码噪声采样方案coupled-GRPO，系统分析解码行为差异

Result: 代码基准提升4.4%（EvalPlus），减少对自回归解码的依赖，生成顺序多样性提升

Conclusion: 揭示了dLLMs的非因果生成特性，建立了扩散原生强化学习框架，扩展了代码生成的可能性

Abstract: Diffusion large language models (dLLMs) are compelling alternatives to
autoregressive (AR) models because their denoising models operate over the
entire sequence. The global planning and iterative refinement features of dLLMs
are particularly useful for code generation. However, current training and
inference mechanisms for dLLMs in coding are still under-explored. To demystify
the decoding behavior of dLLMs and unlock their potential for coding, we
systematically investigate their denoising processes and reinforcement learning
(RL) methods. We train a 7B dLLM, \textbf{DiffuCoder}, on 130B tokens of code.
Using this model as a testbed, we analyze its decoding behavior, revealing how
it differs from that of AR models: (1) dLLMs can decide how causal their
generation should be without relying on semi-AR decoding, and (2) increasing
the sampling temperature diversifies not only token choices but also their
generation order. This diversity creates a rich search space for RL rollouts.
For RL training, to reduce the variance of token log-likelihood estimates and
maintain training efficiency, we propose \textbf{coupled-GRPO}, a novel
sampling scheme that constructs complementary mask noise for completions used
in training. In our experiments, coupled-GRPO significantly improves
DiffuCoder's performance on code generation benchmarks (+4.4\% on EvalPlus) and
reduces reliance on AR causal during decoding. Our work provides deeper insight
into the machinery of dLLM generation and offers an effective, diffusion-native
RL training framework. https://github.com/apple/ml-diffucoder.

</details>


### [32] [Memento: Note-Taking for Your Future Self](https://arxiv.org/abs/2506.20642)
*Chao Wan,Albert Gong,Mihir Mishra,Carl-Leander Henneking,Claas Beger,Kilian Q. Weinberger*

Main category: cs.CL

TL;DR: 提出Memento提示策略，通过问题分解、动态构建事实库和整合推理三阶段流程提升大语言模型在多跳问答中的表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型擅长纯推理任务，但在需要检索与推理紧密结合的多跳问答场景中表现受限

Method: 三阶段策略：1）问题分解为子步骤 2）用LLM动态构建事实数据库 3）综合事实解决问题

Result: 在PhantomWiki提升CoT性能100%，2WikiMultiHopQA上超越CoT-RAG 20F1点，MuSiQue数据集提升ReAct 3F1点

Conclusion: Memento能有效增强现有提示策略，在开放域问答和代理场景中展现出显著优势

Abstract: Large language models (LLMs) excel at reasoning-only tasks, but struggle when
reasoning must be tightly coupled with retrieval, as in multi-hop question
answering. To overcome these limitations, we introduce a prompting strategy
that first decomposes a complex question into smaller steps, then dynamically
constructs a database of facts using LLMs, and finally pieces these facts
together to solve the question. We show how this three-stage strategy, which we
call Memento, can boost the performance of existing prompting strategies across
diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the
performance of chain-of-thought (CoT) when all information is provided in
context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento
improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the
multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the
challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1
percentage points, demonstrating its utility in agentic settings.

</details>


### [33] [Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs](https://arxiv.org/abs/2506.20666)
*Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman*

Main category: cs.CL

TL;DR: 利用认知科学中的礼貌用语认知模型，系统评估LLM在推理模型和开源模型训练中人类式社交-信息效用价值权衡的表现模式


<details>
  <summary>Details</summary>
Motivation: 当前缺乏解释LLM动态多面价值权衡的工具，而认知模型能形式化描述人类在言语行为中的效用函数权衡机制

Method: 应用礼貌用语认知模型框架，从两个维度评估：1)前沿黑盒模型的推理深度差异 2)开源模型RL训练动态，分析基础模型、预训练数据等因素对效用值的影响

Result: 发现推理模型信息效用占优，数学能力强的开源模型社交效用更低；训练早期效用值发生重大偏移，基础模型和预训练数据选择比对齐方法影响更持久

Conclusion: 该方法为理解LLM高阶行为提供新视角，对形成训练策略假设、控制训练过程中的价值权衡具有指导意义

Abstract: Navigating everyday social situations often requires juggling conflicting
goals, such as conveying a harsh truth, maintaining trust, all while still
being mindful of another person's feelings. These value trade-offs are an
integral part of human decision-making and language use, however, current tools
for interpreting such dynamic and multi-faceted notions of values in LLMs are
limited. In cognitive science, so-called "cognitive models" provide formal
accounts of these trade-offs in humans, by modeling the weighting of a
speaker's competing utility functions in choosing an action or utterance. In
this work, we use a leading cognitive model of polite speech to interpret the
extent to which LLMs represent human-like trade-offs. We apply this lens to
systematically evaluate value trade-offs in two encompassing model settings:
degrees of reasoning "effort" in frontier black-box models, and RL
post-training dynamics of open-source models. Our results highlight patterns of
higher informational utility than social utility in reasoning models, and in
open-source models shown to be stronger in mathematical reasoning. Our findings
from LLMs' training dynamics suggest large shifts in utility values early on in
training with persistent effects of the choice of base model and pretraining
data, compared to feedback dataset or alignment method. We show that our method
is responsive to diverse aspects of the rapidly evolving LLM landscape, with
insights for forming hypotheses about other high-level behaviors, shaping
training regimes for reasoning models, and better controlling trade-offs
between values during model training.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [34] [RaRa Clipper: A Clipper for Gaussian Splatting Based on Ray Tracer and Rasterizer](https://arxiv.org/abs/2506.20202)
*Da Li,Donggang Jia,Yousef Rajeh,Dominik Engel,Ivan Viola*

Main category: cs.GR

TL;DR: 提出结合光栅化与光线追踪的混合渲染框架RaRa，实现高斯溅射数据的高效精准裁剪


<details>
  <summary>Details</summary>
Motivation: 传统硬裁剪方法因高斯原语的体积特性无法精确定位像素级贡献，导致高斯溅射数据裁剪存在精度与效率问题

Method: 采用RaRa策略：先通过光栅化快速定位被裁剪平面切割的高斯体，再通过光线追踪计算部分遮挡的衰减权重，精准估计像素贡献

Result: 在多种数据集验证中实现视觉优化效果，保持实时渲染性能，未裁剪区域保持高保真度

Conclusion: 该方法突破传统硬裁剪局限，通过混合渲染策略实现平滑连续的动态裁剪效果，为高斯溅射数据应用提供新范式

Abstract: With the advancement of Gaussian Splatting techniques, a growing number of
datasets based on this representation have been developed. However, performing
accurate and efficient clipping for Gaussian Splatting remains a challenging
and unresolved problem, primarily due to the volumetric nature of Gaussian
primitives, which makes hard clipping incapable of precisely localizing their
pixel-level contributions. In this paper, we propose a hybrid rendering
framework that combines rasterization and ray tracing to achieve efficient and
high-fidelity clipping of Gaussian Splatting data. At the core of our method is
the RaRa strategy, which first leverages rasterization to quickly identify
Gaussians intersected by the clipping plane, followed by ray tracing to compute
attenuation weights based on their partial occlusion. These weights are then
used to accurately estimate each Gaussian's contribution to the final image,
enabling smooth and continuous clipping effects. We validate our approach on
diverse datasets, including general Gaussians, hair strand Gaussians, and
multi-layer Gaussians, and conduct user studies to evaluate both perceptual
quality and quantitative performance. Experimental results demonstrate that our
method delivers visually superior results while maintaining real-time rendering
performance and preserving high fidelity in the unclipped regions.

</details>


### [35] [X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis](https://arxiv.org/abs/2506.20267)
*Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger*

Main category: cs.GR

TL;DR: 提出了首个基于可解释皮层特征的可解释表面视觉Transformer（X-SiT），用于阿尔茨海默病等神经系统疾病的检测，并提供与疾病模式对应的原型解释。


<details>
  <summary>Details</summary>
Motivation: 三维容积数据难以可视化复杂脑结构，而皮层表面数据更易理解且广泛用于神经疾病研究，需开发可解释的医疗影像模型以支持临床决策。

Method: 开发X-SiT模型，包含原型表面片段解码器，通过空间对应皮层原型进行案例推理，实现表面嵌入分类。

Result: 在阿尔茨海默病和额颞叶痴呆检测中达到SOTA性能，原型可解释性与已知疾病模式一致并能揭示分类错误。

Conclusion: X-SiT首次实现皮层数据的固有可解释性，兼顾诊断准确性和临床可理解性，推动了医疗AI的透明化决策支持。

Abstract: Interpretable models are crucial for supporting clinical decision-making,
driving advances in their development and application for medical images.
However, the nature of 3D volumetric data makes it inherently challenging to
visualize and interpret intricate and complex structures like the cerebral
cortex. Cortical surface renderings, on the other hand, provide a more
accessible and understandable 3D representation of brain anatomy, facilitating
visualization and interactive exploration. Motivated by this advantage and the
widespread use of surface data for studying neurological disorders, we present
the eXplainable Surface Vision Transformer (X-SiT). This is the first
inherently interpretable neural network that offers human-understandable
predictions based on interpretable cortical features. As part of X-SiT, we
introduce a prototypical surface patch decoder for classifying surface patch
embeddings, incorporating case-based reasoning with spatially corresponding
cortical prototypes. The results demonstrate state-of-the-art performance in
detecting Alzheimer's disease and frontotemporal dementia while additionally
providing informative prototypes that align with known disease patterns and
reveal classification errors.

</details>


### [36] [DreamAnywhere: Object-Centric Panoramic 3D Scene Generation](https://arxiv.org/abs/2506.20367)
*Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: 提出DreamAnywhere模块化系统，通过文本生成360度全景图并分解重构为可编辑3D场景，在视图一致性和图像质量上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D场景生成技术存在视角单一、视觉保真度低、场景理解有限、室内外场景适配性差等问题，需要更高效的影视制作解决方案

Method: 1.文本生成360度全景图 2.背景与对象分离 3.混合修复构建完整3D表示 4.对象掩码升维为可编辑3D模型 5.支持沉浸式导航和对象级编辑

Result: 在跨场景测试中，新视角合成连贯性提升显著，图像质量达业界标杆水平。用户研究显示83%从业者更倾向使用本系统

Conclusion: 该系统显著降低3D内容制作成本，特别适合低成本电影快速迭代场景布局，其模块化设计支持组件替换，具有较强行业适用性

Abstract: Recent advances in text-to-3D scene generation have demonstrated significant
potential to transform content creation across multiple industries. Although
the research community has made impressive progress in addressing the
challenges of this complex task, existing methods often generate environments
that are only front-facing, lack visual fidelity, exhibit limited scene
understanding, and are typically fine-tuned for either indoor or outdoor
settings. In this work, we address these issues and propose DreamAnywhere, a
modular system for the fast generation and prototyping of 3D scenes. Our system
synthesizes a 360{\deg} panoramic image from text, decomposes it into
background and objects, constructs a complete 3D representation through hybrid
inpainting, and lifts object masks to detailed 3D objects that are placed in
the virtual environment. DreamAnywhere supports immersive navigation and
intuitive object-level editing, making it ideal for scene exploration, visual
mock-ups, and rapid prototyping -- all with minimal manual modeling. These
features make our system particularly suitable for low-budget movie production,
enabling quick iteration on scene layout and visual tone without the overhead
of traditional 3D workflows. Our modular pipeline is highly customizable as it
allows components to be replaced independently. Compared to current
state-of-the-art text and image-based 3D scene generation approaches,
DreamAnywhere shows significant improvements in coherence in novel view
synthesis and achieves competitive image quality, demonstrating its
effectiveness across diverse and challenging scenarios. A comprehensive user
study demonstrates a clear preference for our method over existing approaches,
validating both its technical robustness and practical usefulness.

</details>


### [37] [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](https://arxiv.org/abs/2506.20652)
*Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: EditP23是一种无需掩码的3D编辑方法，通过图像对引导编辑感知流，实现跨视图一致性传播，保持对象结构和外观。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本提示或显式空间掩码的3D编辑方法不够直观。EditP23通过使用原始视图及其编辑版本作为条件，使编辑过程更符合用户直觉。

Method: 利用预训练多视图扩散模型的潜在空间，通过编辑感知流将单视图编辑前馈传播到多视角，无需优化步骤且保持对象身份。

Result: 在多种对象类别和编辑场景中实现高保真结果，无需手动掩码即可保持原始对象结构和外观的连贯性。

Conclusion: EditP23为3D编辑提供了直观的图像驱动方案，通过跨视图一致性传播实现了高效、身份保持的编辑效果。

Abstract: We present EditP23, a method for mask-free 3D editing that propagates 2D
image edits to multi-view representations in a 3D-consistent manner. In
contrast to traditional approaches that rely on text-based prompting or
explicit spatial masks, EditP23 enables intuitive edits by conditioning on a
pair of images: an original view and its user-edited counterpart. These image
prompts are used to guide an edit-aware flow in the latent space of a
pre-trained multi-view diffusion model, allowing the edit to be coherently
propagated across views. Our method operates in a feed-forward manner, without
optimization, and preserves the identity of the original object, in both
structure and appearance. We demonstrate its effectiveness across a range of
object categories and editing scenarios, achieving high fidelity to the source
while requiring no manual masks.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents](https://arxiv.org/abs/2506.20326)
*Sergio Torres Aguilar*

Main category: cs.CV

TL;DR: 系统评估了五种目标检测模型在三个历史文献数据集上的表现，发现CNN-OBB模型在复杂文档处理中显著优于Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 解决历史文献复杂页面布局的自动化分析需求，比较不同目标检测架构在多样化古文档数据集上的适应性。

Method: 使用Co-DETR、Grounding DINO等Transformer模型与YOLO系列（AABB/OBB/YOLO-World）在e-NDP、CATMuS、HORAE三个中世纪文献数据集进行对比测试。

Result: Co-DETR在结构化数据集e-NDP表现最佳（0.752 mAP），而YOLOv11x-OBB在复杂数据集CATMuS/HORAE分别达到0.564和0.568 mAP，显著优于其他模型。

Conclusion: 定向边界框（OBB）是处理非笛卡尔布局的关键，Transformer适合结构化文档，CNN-OBB在复杂文档处理中展现出更强的泛化能力。

Abstract: Robust Document Layout Analysis (DLA) is critical for the automated
processing and understanding of historical documents with complex page
organizations. This paper benchmarks five state-of-the-art object detection
architectures on three annotated datasets representing a spectrum of
codicological complexity: The e-NDP, a corpus of Parisian medieval registers
(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval
and modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated
books of hours (ca.13th-16th centuries). We evaluate two Transformer-based
models (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and
YOLO-World). Our findings reveal significant performance variations dependent
on model architecture, data set characteristics, and bounding box
representation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results
(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on
the more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB
significantly outperforms all other models (0.564 and 0.568, respectively).
This study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)
is not a minor refinement but a fundamental requirement for accurately modeling
the non-Cartesian nature of historical manuscripts. We conclude that a key
trade-off exists between the global context awareness of Transformers, ideal
for structured layouts, and the superior generalization of CNN-OBB models for
visually diverse and complex documents.

</details>


### [39] [MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670)
*Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出首个端到端强化学习框架MMSearch-R1，通过多模态搜索工具和结果导向奖励机制，实现大模型在互联网环境中的按需高效搜索


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法和搜索代理存在低效/过度搜索问题，需要更智能的按需搜索机制来适应真实互联网环境的动态复杂性

Method: 整合图文搜索工具，设计基于结果奖励和搜索惩罚的强化学习框架；通过半自动化流程构建多模态搜索VQA数据集，并创建搜索平衡子集

Result: 在知识密集型任务中性能超越同规模RAG基线，搜索调用减少30%的同时达到更大RAG模型水平

Conclusion: 该框架为多模态搜索研究提供了新范式，实验结果揭示了优化搜索行为的关键因素，对实际应用具有指导意义

Abstract: Robust deployment of large multimodal models (LMMs) in real-world scenarios
requires access to external knowledge sources, given the complexity and dynamic
nature of real-world information. Existing approaches such as
retrieval-augmented generation (RAG) and prompt engineered search agents rely
on rigid pipelines, often leading to inefficient or excessive search behaviors.
We present MMSearch-R1, the first end-to-end reinforcement learning framework
that enables LMMs to perform on-demand, multi-turn search in real-world
Internet environments. Our framework integrates both image and text search
tools, allowing the model to reason about when and how to invoke them guided by
an outcome-based reward with a search penalty. To support training, We collect
a multimodal search VQA dataset through a semi-automated pipeline that covers
diverse visual and textual knowledge needs and curate a search-balanced subset
with both search-required and search-free samples, which proves essential for
shaping efficient and on-demand search behavior. Extensive experiments on
knowledge-intensive and info-seeking VQA tasks show that our model not only
outperforms RAG-based baselines of the same model size, but also matches the
performance of a larger RAG-based model while reducing search calls by over
30%. We further analyze key empirical findings to offer actionable insights for
advancing research in multimodal search.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [40] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

Main category: cs.LG

TL;DR: 提出基于时空点过程的概率模型，结合霍克斯过程建模眼动行为，相比基线模型能更好拟合人类扫视模式，但语境惊奇值对注视时长预测提升有限。


<details>
  <summary>Details</summary>
Motivation: 传统眼动建模方法依赖聚合测量和强假设，忽略阅读时空中动态细节。新模型旨在通过时空联合建模揭示更精细的阅读认知过程。

Method: 使用标记时空点过程建模：1) 霍克斯过程捕捉扫视的时空激发特性 2) 卷积预测器建模注视持续时间的溢出效应 3) 整合语境惊奇值等预测因子

Result: 霍克斯模型显著优于基线扫视模型；语境惊奇值仅轻微提升注视时长预测（ΔAUC≈0.5%），暗示传统惊奇理论解释微观眼动存在局限

Conclusion: 时空联合建模能有效捕捉眼动动态，但语言认知理论与生理行为测量的鸿沟仍需新理论框架弥合

Abstract: Reading is a process that unfolds across space and time, alternating between
fixations where a reader focuses on a specific point in space, and saccades
where a reader rapidly shifts their focus to a new point. An ansatz of
psycholinguistics is that modeling a reader's fixations and saccades yields
insight into their online sentence processing. However, standard approaches to
such modeling rely on aggregated eye-tracking measurements and models that
impose strong assumptions, ignoring much of the spatio-temporal dynamics that
occur during reading. In this paper, we propose a more general probabilistic
model of reading behavior, based on a marked spatio-temporal point process,
that captures not only how long fixations last, but also where they land in
space and when they take place in time. The saccades are modeled using a Hawkes
process, which captures how each fixation excites the probability of a new
fixation occurring near it in time and space. The duration time of fixation
events is modeled as a function of fixation-specific predictors convolved
across time, thus capturing spillover effects. Empirically, our Hawkes process
model exhibits a better fit to human saccades than baselines. With respect to
fixation durations, we observe that incorporating contextual surprisal as a
predictor results in only a marginal improvement in the model's predictive
accuracy. This finding suggests that surprisal theory struggles to explain
fine-grained eye movements.

</details>


### [41] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

Main category: cs.LG

TL;DR: 提出MIRAGE多模态基准测试，用于评估农业领域专家级咨询场景下的多模态模型推理与决策能力


<details>
  <summary>Details</summary>
Motivation: 现有基准多依赖封闭分类体系与明确输入，难以应对真实农业咨询场景中模糊上下文、开放世界实体和隐性知识缺口等复杂需求

Method: 基于35,000+真实用户-专家对话构建，通过多阶段数据整理流程创建含7,000+生物实体的多样化测试集，采用开放世界设定模拟未明确定义场景

Result: 建成目前生物分类最丰富的视觉语言基准，覆盖作物健康、害虫诊断等场景，支持主动引导式交互与罕见实体处理能力的评估

Conclusion: MIRAGE为多模态模型在复杂现实场景中的应用提供了高保真测试平台，特别推动农业咨询等知识密集型领域的AI系统发展

Abstract: We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning
and decision-making in consultative interaction settings. Designed for the
agriculture domain, MIRAGE captures the full complexity of expert consultations
by combining natural user queries, expert-authored responses, and image-based
context, offering a high-fidelity benchmark for evaluating models on grounded
reasoning, clarification strategies, and long-form generation in a real-world,
knowledge-intensive domain. Grounded in over 35,000 real user-expert
interactions and curated through a carefully designed multi-step pipeline,
MIRAGE spans diverse crop health, pest diagnosis, and crop management
scenarios. The benchmark includes more than 7,000 unique biological entities,
covering plant species, pests, and diseases, making it one of the most
taxonomically diverse benchmarks available for vision-language models, grounded
in the real world. Unlike existing benchmarks that rely on well-specified user
inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich
scenarios with open-world settings, requiring models to infer latent knowledge
gaps, handle rare entities, and either proactively guide the interaction or
respond. Project Page: https://mirage-benchmark.github.io

</details>


### [42] [Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track](https://arxiv.org/abs/2506.19882)
*Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho*

Main category: cs.LG

TL;DR: 建议机器学习会议设立'反驳与批评'专项通道，通过系统性纠错机制推动研究生态的自我修正


<details>
  <summary>Details</summary>
Motivation: 当前机器学习领域论文激增但存在错误研究被接收的问题，同行评审机制存在局限性，缺乏系统性的纠错机制

Method: 提出设立'反驳与批评'专项通道，讨论轨道设计、审查原则、潜在风险，并附ICLR 2025口头报告的示例分析

Result: 建立官方纠错机制可促进研究生态的动态自我修正，但需平衡批评强度与学术礼仪

Conclusion: 机器学习会议应建立官方、权威的机制来帮助研究实现自我纠正，推动科学进步

Abstract: Science progresses by iteratively advancing and correcting humanity's
understanding of the world. In machine learning (ML) research, rapid
advancements have led to an explosion of publications, but have also led to
misleading, incorrect, flawed or perhaps even fraudulent studies being accepted
and sometimes highlighted at ML conferences due to the fallibility of peer
review. While such mistakes are understandable, ML conferences do not offer
robust processes to help the field systematically correct when such errors are
made.This position paper argues that ML conferences should establish a
dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would
provide a high-profile, reputable platform to support vital research that
critically challenges prior research, thereby fostering a dynamic
self-correcting research ecosystem. We discuss key considerations including
track design, review principles, potential pitfalls, and provide an
illustrative example submission concerning a recent ICLR 2025 Oral. We conclude
that ML conferences should create official, reputable mechanisms to help ML
research self-correct.

</details>


### [43] [Counterfactual Influence as a Distributional Quantity](https://arxiv.org/abs/2506.20481)
*Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 单独使用自影响因子会低估记忆化风险，完整影响分布揭示重复样本对模型记忆的实际影响


<details>
  <summary>Details</summary>
Motivation: 传统反事实自影响因子指标无法全面反映训练数据间的复杂交互效应，需通过分布视角重新评估记忆化机制

Method: 通过计算语言模型训练样本的完整影响分布矩阵，并在CIFAR-10图像数据集进行验证分析

Result: 重复样本显著降低自影响值但保持高可提取性，影响分布分析可有效检测CIFAR-10中的近似重复样本

Conclusion: 记忆化是训练数据复杂交互的结果，完整影响分布比单一自影响指标更能揭示实际隐私风险

Abstract: Machine learning models are known to memorize samples from their training
data, raising concerns around privacy and generalization. Counterfactual
self-influence is a popular metric to study memorization, quantifying how the
model's prediction for a sample changes depending on the sample's inclusion in
the training dataset. However, recent work has shown memorization to be
affected by factors beyond self-influence, with other training samples, in
particular (near-)duplicates, having a large impact. We here study memorization
treating counterfactual influence as a distributional quantity, taking into
account how all training samples influence how a sample is memorized. For a
small language model, we compute the full influence distribution of training
samples on each other and analyze its properties. We find that solely looking
at self-influence can severely underestimate tangible risks associated with
memorization: the presence of (near-)duplicates seriously reduces
self-influence, while we find these samples to be (near-)extractable. We
observe similar patterns for image classification, where simply looking at the
influence distributions reveals the presence of near-duplicates in CIFAR-10.
Our findings highlight that memorization stems from complex interactions across
training data and is better captured by the full influence distribution than by
self-influence alone.

</details>


### [44] [Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards](https://arxiv.org/abs/2506.20520)
*Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos*

Main category: cs.LG

TL;DR: 通过理论分析和实验验证，证明在基线V下界于期望奖励时，离策略REINFORCE算法能实现策略改进，且离策略更新应侧重正奖励信号。


<details>
  <summary>Details</summary>
Motivation: 解决离策略RL方法在LLM对齐中存在的实现简单但性能不足的问题，探索介于监督微调和传统RL之间的中间算法

Method: 提出基于A=r-V优势函数的离策略REINFORCE算法，理论证明当V≤E[r]时可保证策略改进，并通过调节V实现不同奖惩侧重

Result: 理论建立策略改进保证，实验在随机bandit环境验证理论结论，在LLM推理微调任务中提升模型表现

Conclusion: 离策略更新需侧重正奖励信号，合理设置基线V的下界可提升算法稳定性，为LLM对齐提供新思路

Abstract: Reinforcement learning (RL) is increasingly used to align large language
models (LLMs). Off-policy methods offer greater implementation simplicity and
data efficiency than on-policy techniques, but often result in suboptimal
performance. In this work, we study the intermediate range of algorithms
between off-policy RL and supervised fine-tuning by analyzing a simple
off-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with
$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$
emphasizes high-reward samples, while raising it penalizes low-reward ones more
heavily. We first provide a theoretical analysis of this off-policy REINFORCE
algorithm, showing that when the baseline $V$ lower-bounds the expected reward,
the algorithm enjoys a policy improvement guarantee. Our analysis reveals that
while on-policy updates can safely leverage both positive and negative signals,
off-policy updates benefit from focusing more on positive rewards than on
negative ones. We validate our findings experimentally in a controlled
stochastic bandit setting and through fine-tuning state-of-the-art LLMs on
reasoning tasks.

</details>


### [45] [PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models](https://arxiv.org/abs/2506.20629)
*Soufiane Hayou,Nikhil Ghosh,Bin Yu*

Main category: cs.LG

TL;DR: 提出了PLoP方法，通过自动识别最佳适配器放置位置，优化LoRA微调效果


<details>
  <summary>Details</summary>
Motivation: 现有LoRA适配器放置策略存在矛盾（注意力模块vs MLP模块），缺乏系统性的理论指导

Method: 基于理论分析开发PLoP框架，通过预训练模型和微调任务自动确定适配器最佳放置模块类型

Result: 在监督微调和强化学习推理任务中，PLoP始终优于或至少等同于传统人工选择策略

Conclusion: PLoP为LoRA适配器放置提供了数据驱动的解决方案，显著提升模型微调效率与效果

Abstract: Low-Rank Adaptation (LoRA) is a widely used finetuning method for large
models. Its small memory footprint allows practitioners to adapt large models
to specific tasks at a fraction of the cost of full finetuning. Different
modifications have been proposed to enhance its efficiency by, for example,
setting the learning rate, the rank, and the initialization. Another
improvement axis is adapter placement strategy: when using LoRA, practitioners
usually pick module types to adapt with LoRA, such as Query and Key modules.
Few works have studied the problem of adapter placement, with nonconclusive
results: original LoRA paper suggested placing adapters in attention modules,
while other works suggested placing them in the MLP modules. Through an
intuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a
lightweight method that allows automatic identification of module types where
LoRA adapters should be placed, given a pretrained model and a finetuning task.
We demonstrate that PLoP consistently outperforms, and in the worst case
competes, with commonly used placement strategies through comprehensive
experiments on supervised finetuning and reinforcement learning for reasoning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究开发了基于本地LLM的可定制RAG框架，在医疗任务中准确率超过商业模型且能耗更低。


<details>
  <summary>Details</summary>
Motivation: 解决商业大语言模型在医疗领域的高资源消耗、患者隐私与安全问题。

Method: 构建可监控能耗的RAG框架，测试不同开源LLM（含医疗专用模型），并与主流商业模型进行性能/能耗对比。

Result: llama3.1-RAG准确率58.5%最优，能耗比o4-mini低172%，每kWh性能提升2.7倍，总碳排仅473g。

Conclusion: 本地LLM+RAG方案在提升医疗AI性能的同时显著降低环境影响，符合联合国可持续发展目标。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [47] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现大语言模型（LLMs）在分配政治/社会身份角色后，表现出与人类相似的动机性推理倾向，导致事实判断准确率下降且难以通过提示去偏。


<details>
  <summary>Details</summary>
Motivation: 人类动机性推理会危害社会关键议题讨论，但LLMs是否因身份认同产生类似选择性推理尚未明确。本文探索角色设定对LLMs推理客观性的影响。

Method: 为8个开源/商用LLMs分配4类政治社会属性角色，测试其在错误信息辨别和科学证据评估任务中的表现，并与无角色模型对比。

Result: 角色模型信息辨别准确率降低9%；政治角色在身份相符时评估科学证据正确率提升90%；传统去偏提示方法基本无效。

Conclusion: LLMs表现出与人类相似的顽固性动机推理，可能加剧社会身份认同偏见，现有技术手段难以有效缓解该问题。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [48] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: Proposes Genesys, a multi-agent LLM system using genetic programming and Ladder of Scales approach to discover novel LM architectures, achieving competitive performance with existing models.


<details>
  <summary>Details</summary>
Motivation: Explore leveraging LLMs to automate discovery of novel language model architectures by simulating real research processes.

Method: Multi-agent LLM approach with Ladder of Scales strategy (14M~350M parameters) and genetic programming backbone for efficient design generation.

Result: 1,162 new designs generated (1,062 verified), best designs outperformed GPT2/Mamba2 on 6/9 benchmarks.

Conclusion: Genesys demonstrates effective autonomous architecture discovery through scalable verification and genetic programming, providing insights for future systems.

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [49] [The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](https://arxiv.org/abs/2506.20664)
*Andrei Lupu,Timon Willi,Jakob Foerster*

Main category: cs.AI

TL;DR: 提出Decrypto基准测试评估LLMs在多智能体场景中的心智理论与推理能力，发现前沿模型表现落后于人类及早期模型


<details>
  <summary>Details</summary>
Motivation: 现有LLM多智能体推理评估工具存在范围狭窄、数据泄露、交互性不足等问题，需建立更聚焦心智理论的核心能力评测平台

Method: 设计基于密码破译游戏的交互式基准，整合认知科学实验范式，严格控制其他干扰变量，构建可扩展的ToM能力测试框架

Result: 前沿LLM游戏表现显著低于人类（平均准确率低42%），GPT-4在二阶心智推理任务中准确率仅19%，弱于早期GPT-3模型

Conclusion: Decrypto填补现有评估体系空白，揭示模型推理能力提升与心智理论发展不匹配，为构建更智能的多智能体系统提供新方向

Abstract: As Large Language Models (LLMs) gain agentic abilities, they will have to
navigate complex multi-agent scenarios, interacting with human users and other
agents in cooperative and competitive settings. This will require new reasoning
skills, chief amongst them being theory of mind (ToM), or the ability to reason
about the "mental" states of other agents. However, ToM and other multi-agent
abilities in LLMs are poorly understood, since existing benchmarks suffer from
narrow scope, data leakage, saturation, and lack of interactivity. We thus
propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM
drawing inspiration from cognitive science, computational pragmatics and
multi-agent reinforcement learning. It is designed to be as easy as possible in
all other dimensions, eliminating confounding factors commonly found in other
benchmarks. To our knowledge, it is also the first platform for designing
interactive ToM experiments.
  We validate the benchmark design through comprehensive empirical evaluations
of frontier LLMs, robustness studies, and human-AI cross-play experiments. We
find that LLM game-playing abilities lag behind humans and simple
word-embedding baselines. We then create variants of two classic cognitive
science experiments within Decrypto to evaluate three key ToM abilities.
Surprisingly, we find that state-of-the-art reasoning models are significantly
worse at those tasks than their older counterparts. This demonstrates that
Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and
paves the path towards better artificial agents.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [50] [Capturing Visualization Design Rationale](https://arxiv.org/abs/2506.16571)
*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

Main category: cs.HC

TL;DR: 提出利用学生可视化笔记本和LLM技术构建捕捉可视化设计原理的数据集


<details>
  <summary>Details</summary>
Motivation: 现有可视化研究过度聚焦图表解读而忽视设计过程，真实设计决策的rationale缺乏系统性记录

Method: 通过学生课程作品构建literate notebooks语料库，采用LLM生成并验证QAR三元组

Result: 建立首个包含可视化设计选择及其背后逻辑的标注数据集

Conclusion: 该方法有效捕捉设计思维过程，为可视化教育和技术研发提供新范式

Abstract: Prior natural language datasets for data visualization have focused on tasks
such as visualization literacy assessment, insight generation, and
visualization generation from natural language instructions. These studies
often rely on controlled setups with purpose-built visualizations and
artificially constructed questions. As a result, they tend to prioritize the
interpretation of visualizations, focusing on decoding visualizations rather
than understanding their encoding. In this paper, we present a new dataset and
methodology for probing visualization design rationale through natural
language. We leverage a unique source of real-world visualizations and natural
language narratives: literate visualization notebooks created by students as
part of a data visualization course. These notebooks combine visual artifacts
with design exposition, in which students make explicit the rationale behind
their design decisions. We also use large language models (LLMs) to generate
and categorize question-answer-rationale triples from the narratives and
articulations in the notebooks. We then carefully validate the triples and
curate a dataset that captures and distills the visualization design choices
and corresponding rationales of the students.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

Main category: cs.RO

TL;DR: PSALM-V：首个通过视觉交互自主推导符号动作语义的神经符号学习系统，显著提升规划成功率


<details>
  <summary>Details</summary>
Motivation: 解决现有基于LLM的符号规划方法依赖文本领域、预设问题文件或完全可观测性的限制，实现真实视觉环境下的自主语义学习

Method: 通过动态推断PDDL问题文件+执行结果分析+错误解释合成，维护动作语义的树状信念空间迭代优化，结合神经模块（LLM生成初始计划）与符号推理

Result: ALFRED任务成功率从37%→74%；RTFM/Overcooked环境提升步骤效率；真实机器人任务正确推导PDDL条件（容忍底层操作失败）

Conclusion: 神经符号协同框架突破符号规划对专家定义的依赖，通过动态语义推导实现真实物理场景的可靠规划，为具身智能提供新范式

Abstract: We propose PSALM-V, the first autonomous neuro-symbolic learning system able
to induce symbolic action semantics (i.e., pre- and post-conditions) in visual
environments through interaction. PSALM-V bootstraps reliable symbolic planning
without expert action definitions, using LLMs to generate heuristic plans and
candidate symbolic semantics. Previous work has explored using large language
models to generate action semantics for Planning Domain Definition Language
(PDDL)-based symbolic planners. However, these approaches have primarily
focused on text-based domains or relied on unrealistic assumptions, such as
access to a predefined problem file, full observability, or explicit error
messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain
action semantics by analyzing execution outcomes and synthesizing possible
error explanations. The system iteratively generates and executes plans while
maintaining a tree-structured belief over possible action semantics for each
action, iteratively refining these beliefs until a goal state is reached.
Simulated experiments of task completion in ALFRED demonstrate that PSALM-V
increases the plan success rate from 37% (Claude-3.7) to 74% in partially
observed setups. Results on two 2D game environments, RTFM and Overcooked-AI,
show that PSALM-V improves step efficiency and succeeds in domain induction in
multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions
for real-world robot BlocksWorld tasks, despite low-level manipulation failures
from the robot.

</details>


### [52] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究通过240组人机对话实验发现，现有计算机视觉模型在检测机器人对话失误时性能接近随机猜测，用户往往不会主动向机器人反馈沟通问题


<details>
  <summary>Details</summary>
Motivation: 机器人难以通过非语言反馈检测对话失误，而人类能轻松通过语言和非语言线索识别沟通错误，这会影响用户信任和参与度

Method: 使用包含四种对话故障类型的多模态数据集，结合最先进计算机视觉模型分析，并通过用户即时反馈验证模型检测能力

Result: 模型在常规对话中的失误检测准确率接近随机水平（50%），但在情感表达更明显的数据集中能有效识别困惑状态；人类评估者同样只能识别约50%的诱导性沟通错误

Conclusion: 机器人对话失误检测的根本局限在于用户通常不会主动反馈沟通问题，该发现有助于设计更有效的人机对话系统，建议在关键环节主动获取用户反馈

Abstract: Detecting miscommunication in human-robot interaction is a critical function
for maintaining user engagement and trust. While humans effortlessly detect
communication errors in conversations through both verbal and non-verbal cues,
robots face significant challenges in interpreting non-verbal feedback, despite
advances in computer vision for recognizing affective expressions. This
research evaluates the effectiveness of machine learning models in detecting
miscommunications in robot dialogue. Using a multi-modal dataset of 240
human-robot conversations, where four distinct types of conversational failures
were systematically introduced, we assess the performance of state-of-the-art
computer vision models. After each conversational turn, users provided feedback
on whether they perceived an error, enabling an analysis of the models' ability
to accurately detect robot mistakes. Despite using state-of-the-art models, the
performance barely exceeds random chance in identifying miscommunication, while
on a dataset with more expressive emotional content, they successfully
identified confused states. To explore the underlying cause, we asked human
raters to do the same. They could also only identify around half of the induced
miscommunications, similarly to our model. These results uncover a fundamental
limitation in identifying robot miscommunications in dialogue: even when users
perceive the induced miscommunication as such, they often do not communicate
this to their robotic conversation partner. This knowledge can shape
expectations of the performance of computer vision models and can help
researchers to design better human-robot conversations by deliberately
eliciting feedback where needed.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [53] [FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment](https://arxiv.org/abs/2506.20303)
*Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye*

Main category: eess.IV

TL;DR: 提出FundaQ-8框架解决眼底图像质量评估难题，通过ResNet18模型预测质量分数并验证临床价值


<details>
  <summary>Details</summary>
Motivation: 传统眼底图像质量评估存在图像采集差异性和专家主观性问题，需建立系统性评估标准

Method: 基于专家验证的FundaQ-8八维度评分体系，使用ResNet18回归模型进行迁移学习，在1800张临床图像上训练

Result: 在EyeQ数据集验证中显示可靠性，质量感知训练显著提升糖尿病视网膜病变分级的诊断稳健性

Conclusion: FundaQ-8框架有效解决质量评估标准化难题，质量意识训练可增强真实筛查应用中的模型表现

Abstract: Automated fundus image quality assessment (FIQA) remains a challenge due to
variations in image acquisition and subjective expert evaluations. We introduce
FundaQ-8, a novel expert-validated framework for systematically assessing
fundus image quality using eight critical parameters, including field coverage,
anatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a
structured scoring reference, we develop a ResNet18-based regression model to
predict continuous quality scores in the 0 to 1 range. The model is trained on
1800 fundus images from real-world clinical sources and Kaggle datasets, using
transfer learning, mean squared error optimization, and standardized
preprocessing. Validation against the EyeQ dataset and statistical analyses
confirm the framework's reliability and clinical interpretability.
Incorporating FundaQ-8 into deep learning models for diabetic retinopathy
grading also improves diagnostic robustness, highlighting the value of
quality-aware training in real-world screening applications.

</details>
