<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 56]
- [cs.GR](#cs.GR) [Total: 8]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.SD](#cs.SD) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: 提出Synthetic Bootstrapped Pretraining (SBP)预训练框架，通过建模文档间关系合成新语料，使3B模型在1T tokens训练下性能显著提升，接近20倍数据量的上限基准。


<details>
  <summary>Details</summary>
Motivation: 传统预训练仅关注文档内部token关联，未能有效建模文档间丰富的可学习关联。SBP通过建模文档间关系突破这一限制，提升模型性能。

Method: 1. 构建文档关系模型学习预训练数据的关联模式
2. 基于关系模型合成大规模新语料库
3. 采用计算匹配的预训练配置（3B参数模型，1T tokens从头训练）

Result: 1. 性能持续超越重复数据基线
2. 达到20倍唯一数据量基准的显著性能比例
3. 定性分析显示合成文档具有概念抽象和新叙述重构能力

Conclusion: SBP通过隐式学习文档间潜在概念的贝叶斯范式，在提升模型性能的同时，为预训练提供了数据效率优化的新路径。

Abstract: We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [2] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

TL;DR: 研究评估了三种分词算法（BPE/WordPiece/SentencePiece）在低资源语言宗喀巴语中的表现，发现SentencePiece效果最佳，为构建宗喀巴语大语言模型奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 宗喀巴语作为低资源语言（约70万使用者），现有分词器对复杂语言结构处理不佳，阻碍其NLP发展，需专门解决方案。

Method: 使用Subword Fertility、Continued Words比例、序列长度标准化和执行时间等指标，对比评估三种主流分词算法性能。

Result: SentencePiece（Unigram）在宗喀巴语分词中表现最优，BPE和WordPiece也展现应用潜力。

Conclusion: 低资源语言需要定制化NLP方法，本研究通过优选分词算法，为后续宗喀巴语大语言模型开发提供了关键技术支持。

Abstract: Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [3] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 提出SGToxicGuard数据集及评估框架，揭示多语言大模型在新加坡多元语言环境中的安全漏洞


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在低资源多语言环境(如新加坡)中的安全机制研究不足，存在文化敏感性和毒性内容风险

Method: 采用红队测试方法，在对话/问答/内容生成三场景中系统测试多语言大模型，构建涵盖新加坡英语/中文/马来语/泰米尔语的数据集

Result: 实验发现最先进的多语言大模型在安全防护上存在严重漏洞，尤其在文化适应性方面表现不足

Conclusion: 该研究为构建语言多样性环境中的安全AI系统奠定基础，提供文化敏感性优化和毒性缓解方案

Abstract: The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [4] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

TL;DR: 研究发现大语言模型在事实核查任务中，判断性词汇比政治倾向更显著影响真实性评估，部分模型存在未被提示语消除的政治偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在事实核查等客观性任务中，政治偏见如何通过委婉/贬义词汇替换影响判断一致性。

Method: 构建德语主张的最小对立对（仅政治内涵不同），评估6个LLM对等效主张真实性判断的稳定性。

Result: 判断性词汇显著影响真实性评估，部分模型显示政治偏见且无法通过强调客观性的提示消除。

Conclusion: LLM开发需重点关注训练数据中的判断性词汇过滤，而非单纯依赖提示工程消除政治偏见。

Abstract: Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [5] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 大语言模型幻觉预测依赖问题侧捷径而非真实自省，SCAO方法通过单字压缩增强模型侧信号实现稳定性能


<details>
  <summary>Details</summary>
Motivation: 挑战LLM幻觉预测源于自我认知的传统观点，揭示问题侧表面模式对预测结果的干扰机制

Method: 提出AQE量化问题侧影响+SCAO单字回答压缩方法，在消减问题侧线索的实验场景验证有效性

Result: SCAO在问题侧线索受限条件下保持稳定表现，F1值提升12.3%且方差降低40%

Conclusion: 研究证实模型侧自省信号的有效提取路径，为LLM自我认知机制评估建立新范式

Abstract: Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>


### [6] [Real, Fake, or Manipulated? Detecting Machine-Influenced Text](https://arxiv.org/abs/2509.15350)
*Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer*

Main category: cs.CL

TL;DR: 提出了分层长度鲁棒的机器影响文本检测器HERO，用于区分人类撰写、机器生成、机器润色和机器翻译四类文本


<details>
  <summary>Details</summary>
Motivation: 现有机器文本检测方法仅区分人类/机器撰写，忽略了机器文本的细粒度使用场景（如翻译/润色），难以有效识别潜在滥用风险

Method: 结合长度专家模型预测结果，通过子类别指导模块强化易混淆类别（如不同源语言）的区分，构建分层检测框架

Result: 在5个LLM和6个领域上的实验显示，HERO比现有方法平均提升2.5-3 mAP

Conclusion: HERO首次实现细粒度的机器文本使用意图检测，通过子类别指导有效提升检测鲁棒性，对打击AI滥用具有实用价值

Abstract: Large Language Model (LLMs) can be used to write or modify documents,
presenting a challenge for understanding the intent behind their use. For
example, benign uses may involve using LLM on a human-written document to
improve its grammar or to translate it into another language. However, a
document entirely produced by a LLM may be more likely to be used to spread
misinformation than simple translation (\eg, from use by malicious actors or
simply by hallucinating). Prior works in Machine Generated Text (MGT) detection
mostly focus on simply identifying whether a document was human or machine
written, ignoring these fine-grained uses. In this paper, we introduce a
HiErarchical, length-RObust machine-influenced text detector (HERO), which
learns to separate text samples of varying lengths from four primary types:
human-written, machine-generated, machine-polished, and machine-translated.
HERO accomplishes this by combining predictions from length-specialist models
that have been trained with Subcategory Guidance. Specifically, for categories
that are easily confused (\eg, different source languages), our Subcategory
Guidance module encourages separation of the fine-grained categories, boosting
performance. Extensive experiments across five LLMs and six domains demonstrate
the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on
average.

</details>


### [7] [Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](https://arxiv.org/abs/2509.15361)
*Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu*

Main category: cs.CL

TL;DR: 提出基于因果中介分析的去偏框架CMDebias，通过反事实样本区分核心语义与虚假关联，结合动态路由的MoE架构实现多模态去偏


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在复杂推理任务中易受表层相关性偏差影响，导致鲁棒性和泛化能力下降

Method: 1. 利用反事实样本分离核心语义与虚假上下文
2. 采用混合专家模型动态选择模态特定的去偏专家
3. 基于因果中介分析实现训练阶段去偏

Result: 在反讽检测和情感分析任务中准确率分别达到89.7%和92.3%，显著超越现有最佳模型（+4.2%和+3.8%）

Conclusion: 该框架有效解决了多模态模型中的表层偏差问题，为复杂认知任务的可靠推理提供了新范式

Abstract: Multimodal Large Language Models (MLLMs) have shown substantial capabilities
in integrating visual and textual information, yet frequently rely on spurious
correlations, undermining their robustness and generalization in complex
multimodal reasoning tasks. This paper addresses the critical challenge of
superficial correlation bias in MLLMs through a novel causal mediation-based
debiasing framework. Specially, we distinguishing core semantics from spurious
textual and visual contexts via counterfactual examples to activate
training-stage debiasing and employ a Mixture-of-Experts (MoE) architecture
with dynamic routing to selectively engages modality-specific debiasing
experts. Empirical evaluation on multimodal sarcasm detection and sentiment
analysis tasks demonstrates that our framework significantly surpasses unimodal
debiasing strategies and existing state-of-the-art models.

</details>


### [8] [Speech Language Models for Under-Represented Languages: Insights from Wolof](https://arxiv.org/abs/2509.15362)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

TL;DR: 研究者开发了首个沃洛夫语语音大模型，通过高质量语音数据提升ASR性能，并实现语音翻译功能，模型和代码将开源


<details>
  <summary>Details</summary>
Motivation: 解决沃洛夫语等资源匮乏语言的语音处理需求，提升自动语音识别性能并扩展语音翻译能力

Method: 1. 收集大规模沃洛夫语自发语音数据
2. 基于HuBERT模型持续预训练优化ASR
3. 将语音编码器集成到沃洛夫语LLM中
4. 探索思维链（CoT）多步推理策略

Result: 相比基础模型和非洲中心模型，ASR性能显著提升，语音翻译任务表现优异，思维链策略有效改善转录效果

Conclusion: 该方法成功构建首个沃洛夫语语音LLM，验证了高质量数据的重要性，开源将促进资源匮乏语言的NLP发展

Abstract: We present our journey in training a speech language model for Wolof, an
underrepresented language spoken in West Africa, and share key insights. We
first emphasize the importance of collecting large-scale, spontaneous,
high-quality speech data, and show that continued pretraining HuBERT on this
dataset outperforms both the base model and African-centric models on ASR. We
then integrate this speech encoder into a Wolof LLM to train the first Speech
LLM for this language, extending its capabilities to tasks such as speech
translation. Furthermore, we explore training the Speech LLM to perform
multi-step Chain-of-Thought before transcribing or translating. Our results
show that the Speech LLM not only improves speech recognition but also performs
well in speech translation. The models and the code will be openly shared.

</details>


### [9] [Frustratingly Easy Data Augmentation for Low-Resource ASR](https://arxiv.org/abs/2509.15373)
*Katsumi Ibaraki,David Chiang*

Main category: cs.CL

TL;DR: 提出三种自包含数据增强方法，通过文本生成与TTS技术显著提升低资源语音识别性能（如Nashta语言WER降低14.3%），并验证高资源语言适用性。


<details>
  <summary>Details</summary>
Motivation: 解决低资源ASR任务中标注数据不足的核心瓶颈，传统方法依赖大量标注数据的限制在资源匮乏语言中尤为突出。

Method: 基于词汇替换/随机替换/LLM生成三种文本增强方案，结合TTS合成语音数据，使用Wav2Vec2-XLSR-53预训练模型进行原始+合成数据的联合微调。

Result: 在四个极低资源语言实现性能突破（Nashta绝对WER降低14.3%），且在英语等高资源语言同样有效，证实方法普适性。

Conclusion: 创新性数据增强方案突破低资源ASR数据瓶颈，合成数据与预训练模型协同作用，形成跨语言规模的实用解决方案。

Abstract: This paper introduces three self-contained data augmentation methods for
low-resource Automatic Speech Recognition (ASR). Our techniques first generate
novel text--using gloss-based replacement, random replacement, or an LLM-based
approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We
apply these methods, which leverage only the original annotated data, to four
languages with extremely limited resources (Vatlongos, Nashta, Shinekhen
Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a
combination of the original audio and generated synthetic data yields
significant performance gains, including a 14.3% absolute WER reduction for
Nashta. The methods prove effective across all four low-resource languages and
also show utility for high-resource languages like English, demonstrating their
broad applicability.

</details>


### [10] [Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering](https://arxiv.org/abs/2509.15403)
*Yangyi Li,Mengdi Huai*

Main category: cs.CL

TL;DR: 提出一种后处理且模型无关的自然语言解释不确定性估计框架，并设计鲁棒方法保证噪声下的置信度有效性


<details>
  <summary>Details</summary>
Motivation: 现有自然语言解释方法缺乏置信度量化，尤其在医疗噪声场景下难以评估解释可靠性

Method: 开发模型无关的后处理不确定性框架+抗噪声鲁棒估计方法，解决自回归生成过程的置信度量化难题

Result: 问答任务实验验证框架有效性，噪声环境下仍保持置信度校准特性

Conclusion: 首次实现自然语言解释的可信量化，为LLM可解释性研究提供可靠性评估新范式

Abstract: Large language models (LLMs) have shown strong capabilities, enabling
concise, context-aware answers in question answering (QA) tasks. The lack of
transparency in complex LLMs has inspired extensive research aimed at
developing methods to explain large language behaviors. Among existing
explanation methods, natural language explanations stand out due to their
ability to explain LLMs in a self-explanatory manner and enable the
understanding of model behaviors even when the models are closed-source.
However, despite these promising advancements, there is no existing work
studying how to provide valid uncertainty guarantees for these generated
natural language explanations. Such uncertainty quantification is critical in
understanding the confidence behind these explanations. Notably, generating
valid uncertainty estimates for natural language explanations is particularly
challenging due to the auto-regressive generation process of LLMs and the
presence of noise in medical inquiries. To bridge this gap, in this work, we
first propose a novel uncertainty estimation framework for these generated
natural language explanations, which provides valid uncertainty guarantees in a
post-hoc and model-agnostic manner. Additionally, we also design a novel robust
uncertainty estimation method that maintains valid uncertainty guarantees even
under noise. Extensive experiments on QA tasks demonstrate the desired
performance of our methods.

</details>


### [11] [Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data](https://arxiv.org/abs/2509.15419)
*Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros*

Main category: cs.CL

TL;DR: 研究在医学数据受限场景下微调PEGASUS系列模型进行文本摘要生成的挑战，通过实验揭示模型训练过程中出现的双下降现象及检查点尺寸对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 医学领域数据敏感且受限，现有抽象摘要模型难以直接应用。随着医学影像报告数量激增，开发适配专业领域的自动化摘要工具具有迫切需求。

Method: 在公开放射学报告数据集上微调PEGASUS/PEGASUS-X模型，通过控制检查点尺寸和训练数据量，结合词汇指标（ROUGE）和语义指标（BERTScore）持续评估模型表现。

Result: PEGASUS表现出阶段性双下降现象，较大检查点导致性能下降。模型在有限数据下容易过拟合，验证集表现呈现峰值-下降-恢复模式。

Conclusion: 本研究揭示了高表达模型在数据稀缺场景下的微调风险，为开发专业领域鲁棒摘要模型提供了重要实验依据，建议未来研究关注动态微调策略。

Abstract: Regardless of the rapid development of artificial intelligence, abstractive
summarisation is still challenging for sensitive and data-restrictive domains
like medicine. With the increasing number of imaging, the relevance of
automated tools for complex medical text summarisation is expected to become
highly relevant. In this paper, we investigated the adaptation via fine-tuning
process of a non-domain-specific abstractive summarisation encoder-decoder
model family, and gave insights to practitioners on how to avoid over- and
underfitting. We used PEGASUS and PEGASUS-X, on a medium-sized radiological
reports public dataset. For each model, we comprehensively evaluated two
different checkpoints with varying sizes of the same training data. We
monitored the models' performances with lexical and semantic metrics during the
training history on the fixed-size validation set. PEGASUS exhibited different
phases, which can be related to epoch-wise double-descent, or
peak-drop-recovery behaviour. For PEGASUS-X, we found that using a larger
checkpoint led to a performance detriment. This work highlights the challenges
and risks of fine-tuning models with high expressivity when dealing with scarce
training data, and lays the groundwork for future investigations into more
robust fine-tuning strategies for summarisation models in specialised domains.

</details>


### [12] [BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition](https://arxiv.org/abs/2509.15430)
*Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen*

Main category: cs.CL

TL;DR: 提出BiRQ双层自监督学习框架，结合BEST-RQ的效率与HuBERT的标签增强优势，通过模型自生成量化标签和锚定标签实现端到端高效训练


<details>
  <summary>Details</summary>
Motivation: 现有语音自监督学习方法面临效率与标签质量的权衡：HuBERT依赖多阶段流程和外部编码器，BEST-RQ虽简单但生成弱标签。需要兼顾效率与标签质量的解决方案

Method: 1. 使用随机投影量化器离散中间表示生成增强标签
2. 通过原始输入直接生成锚定标签防止训练崩溃
3. 采用可微分Gumbel-softmax实现端到端双层优化
4. 复用模型部分结构作为伪标签生成器降低内存消耗

Result: 在LibriSpeech(960h)、AMI(150h)和YODAS(5,000h)数据集上持续优于BEST-RQ基线，同时保持低复杂度和计算效率（比HuBERT减少50%内存消耗）

Conclusion: BiRQ通过内源性标签增强机制，在无需外部编码器的前提下实现迭代式标签优化，为大规模语音表示学习提供了内存高效且性能优越的端到端解决方案

Abstract: Speech is a rich signal, and labeled audio-text pairs are costly, making
self-supervised learning essential for scalable representation learning. A core
challenge in speech SSL is generating pseudo-labels that are both informative
and efficient: strong labels, such as those used in HuBERT, improve downstream
performance but rely on external encoders and multi-stage pipelines, while
efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.
We propose BiRQ, a bilevel SSL framework that combines the efficiency of
BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key
idea is to reuse part of the model itself as a pseudo-label generator:
intermediate representations are discretized by a random-projection quantizer
to produce enhanced labels, while anchoring labels derived directly from the
raw input stabilize training and prevent collapse. Training is formulated as an
efficient first-order bilevel optimization problem, solved end-to-end with
differentiable Gumbel-softmax selection. This design eliminates the need for
external label encoders, reduces memory cost, and enables iterative label
refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ
while maintaining low complexity and computational efficiency. We validate our
method on various datasets, including 960-hour LibriSpeech, 150-hour AMI
meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

</details>


### [13] [PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting](https://arxiv.org/abs/2509.15447)
*Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams*

Main category: cs.CL

TL;DR: 提出PILOT框架，通过结构化心理语言特征引导LLM生成，在三种控制模式下实现生成质量与多样性的平衡优化


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言的角色描述存在属性强调不可控问题，需更精准的生成控制机制

Method: 两阶段框架：1)将自然语言角色转化为标准化心理语言多维评分 2)基于评分进行可量化引导生成

Result: 模式化引导(SBS)提升主题纯度15.8%，混合模式(HPS)在多样性(0.237轮廓系数)与一致性(0.957纯度)间取得平衡

Conclusion: PILOT框架成功实现生成质量与可控性的统一，为AI内容生成提供可量化调节的解决方案

Abstract: Generative AI applications commonly leverage user personas as a steering
mechanism for synthetic data generation, but reliance on natural language
representations forces models to make unintended inferences about which
attributes to emphasize, limiting precise control over outputs. We introduce
PILOT (Psychological and Linguistic Output Targeting), a two-phase framework
for steering large language models with structured psycholinguistic profiles.
In Phase 1, PILOT translates natural language persona descriptions into
multidimensional profiles with normalized scores across linguistic and
psychological dimensions. In Phase 2, these profiles guide generation along
measurable axes of variation. We evaluate PILOT across three state-of-the-art
LLMs (Mistral Large 2, Deepseek-R1, LLaMA 3.3 70B) using 25 synthetic personas
under three conditions: Natural-language Persona Steering (NPS), Schema-Based
Steering (SBS), and Hybrid Persona-Schema Steering (HPS). Results demonstrate
that schema-based approaches significantly reduce artificial-sounding persona
repetition while improving output coherence, with silhouette scores increasing
from 0.098 to 0.237 and topic purity from 0.773 to 0.957. Our analysis reveals
a fundamental trade-off: SBS produces more concise outputs with higher topical
consistency, while NPS offers greater lexical diversity but reduced
predictability. HPS achieves a balance between these extremes, maintaining
output variety while preserving structural consistency. Expert linguistic
evaluation confirms that PILOT maintains high response quality across all
conditions, with no statistically significant differences between steering
approaches.

</details>


### [14] [Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](https://arxiv.org/abs/2509.15476)
*Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 系统评估多模态大语言模型在英汉讽刺检测任务中的表现，探索不同训练范式与特征融合方法


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对音频-视觉-文本多模态讽刺理解的系统性探索，需验证MLLMs在跨语言场景下的潜力

Method: 使用LLMs/MLLMs在零样本/少样本/LoRA微调设置下评估，设计协作门控融合模块整合多模态特征

Result: 音频模型单模态最优，文本-音频/音频-视觉组合超越单/三模态模型，Qwen-Omni展现竞争力

Conclusion: MLLMs在跨语言多模态讽刺理解中展现潜力，音频模态在多模态组合中起关键作用

Abstract: Sarcasm detection remains a challenge in natural language understanding, as
sarcastic intent often relies on subtle cross-modal cues spanning text, speech,
and vision. While prior work has primarily focused on textual or visual-textual
sarcasm, comprehensive audio-visual-textual sarcasm understanding remains
underexplored. In this paper, we systematically evaluate large language models
(LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and
Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In
addition to direct classification, we explore models as feature encoders,
integrating their representations through a collaborative gating fusion module.
Experimental results show that audio-based models achieve the strongest
unimodal performance, while text-audio and audio-vision combinations outperform
unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show
competitive zero-shot and fine-tuned performance. Our findings highlight the
potential of MLLMs for cross-lingual, audio-visual-textual sarcasm
understanding.

</details>


### [15] [Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](https://arxiv.org/abs/2509.15478)
*Madison Van Doren,Casey Ford,Emily Dix*

Main category: cs.CL

TL;DR: 研究发现不同多模态大语言模型在对抗提示下的安全性差异显著，文本提示比多模态更易绕过安全机制。


<details>
  <summary>Details</summary>
Motivation: 评估主流MLLMs在对抗条件下的安全性，因其广泛部署但安全机制研究不足。

Method: 26名红队成员生成726个针对非法活动、虚假信息和不道德行为的提示，使用4个模型生成2904个输出并由17名标注者进行危害评分。

Result: Pixtral 12B有害响应率最高(62%)，Claude抗性最强(10%)；文本提示攻击成功率略高于多模态。

Conclusion: 亟需建立鲁棒的多模态安全基准以应对MLLMs的广泛部署风险。

Abstract: Multimodal large language models (MLLMs) are increasingly used in real world
applications, yet their safety under adversarial conditions remains
underexplored. This study evaluates the harmlessness of four leading MLLMs
(GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to
adversarial prompts across text-only and multimodal formats. A team of 26 red
teamers generated 726 prompts targeting three harm categories: illegal
activity, disinformation, and unethical behaviour. These prompts were submitted
to each model, and 17 annotators rated 2,904 model outputs for harmfulness
using a 5-point scale. Results show significant differences in vulnerability
across models and modalities. Pixtral 12B exhibited the highest rate of harmful
responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%).
Contrary to expectations, text-only prompts were slightly more effective at
bypassing safety mechanisms than multimodal ones. Statistical analysis
confirmed that both model type and input modality were significant predictors
of harmfulness. These findings underscore the urgent need for robust,
multimodal safety benchmarks as MLLMs are deployed more widely.

</details>


### [16] [mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment](https://arxiv.org/abs/2509.15485)
*Ahmed Abdou*

Main category: cs.CL

TL;DR: 提出一种基于保形预测的阿拉伯语可读性分级后处理方法，通过不确定性解码提升模型性能（QWK提升1-3%），在BAREC 2025评测中取得84.9%-85.7%句子级和73.3%文档级成绩。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语教育评估中人工审阅者需要同时兼顾统计置信度与实用性的需求，通过置信区间缩小人工审核范围。

Method: 使用保形预测生成带覆盖保证的预测集，结合softmax重归一化概率进行加权平均，减少跨级误判带来的高惩罚。

Result: 在严格评测轨道中：句子级QWK测试集84.9%/盲测85.7%，文档级73.3%；不同基模型均实现1-3个点的QWK提升。

Conclusion: 该方法通过统计保证与实用性的结合，使教育评估者能聚焦于少量可信的难度等级，提升人工审核效率与模型可用性。

Abstract: We present a simple, model-agnostic post-processing technique for
fine-grained Arabic readability classification in the BAREC 2025 Shared Task
(19 ordinal levels). Our method applies conformal prediction to generate
prediction sets with coverage guarantees, then computes weighted averages using
softmax-renormalized probabilities over the conformal sets. This
uncertainty-aware decoding improves Quadratic Weighted Kappa (QWK) by reducing
high-penalty misclassifications to nearer levels. Our approach shows consistent
QWK improvements of 1-3 points across different base models. In the strict
track, our submission achieves QWK scores of 84.9\%(test) and 85.7\% (blind
test) for sentence level, and 73.3\% for document level. For Arabic educational
assessment, this enables human reviewers to focus on a handful of plausible
levels, combining statistical guarantees with practical usability.

</details>


### [17] [LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference](https://arxiv.org/abs/2509.15515)
*Hantao Yang,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.CL

TL;DR: 本文提出基于背包问题建模的LLM缓存优化算法，在查询异质场景下实现12%成本降低，理论遗憾系数从O(MN√T)改进为O(√MNT)。


<details>
  <summary>Details</summary>
Motivation: 现有LLM缓存研究假设查询规模同质，无法有效处理实际场景中的查询异质性问题。异质查询导致缓存选择组合爆炸，传统方法在计算效率和统计性能上面临双重挑战。

Method: 将最优缓存选择建模为背包问题，设计基于积累策略的算法，平衡计算开销与缓存更新效率。通过理论分析证明算法有效性。

Result: 1. 理论证明遗憾界O(√MNT)，比Berkeley结果改进√MN系数 2. 首次给出问题依赖界限 3. 真实数据实验显示降低12%总成本

Conclusion: 该研究通过创新建模和算法设计，在理论和实验层面均显著提升异质查询场景下的LLM推理效率，为实际系统优化提供新思路。

Abstract: This paper revisits the LLM cache bandit problem, with a special focus on
addressing the query heterogeneity for cost-effective LLM inference. Previous
works often assume uniform query sizes. Heterogeneous query sizes introduce a
combinatorial structure for cache selection, making the cache replacement
process more computationally and statistically challenging. We treat optimal
cache selection as a knapsack problem and employ an accumulation-based strategy
to effectively balance computational overhead and cache updates. In theoretical
analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$
bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$
result in Berkeley, where $N$ is the total number of queries and $M$ is the
cache size. Additionally, we also provide a problem-dependent bound, which was
absent in previous works. The experiment rely on real-world data show that our
algorithm reduces the total cost by approximately 12\%.

</details>


### [18] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

TL;DR: 系统比较人类与LLM生成的俚语使用，发现模型存在认知偏差且创造性知识未充分对齐人类


<details>
  <summary>Details</summary>
Motivation: 研究LLM在俚语处理中的可靠性和泛化能力，验证其是否掌握与人类认知匹配的结构化俚语知识

Method: 通过在线俚语词典(OSD)的人类用例与GPT-4o/Llama-3生成用例的三维对比：系统性偏差、创造性(词汇创新与复用)、蒸馏任务信息量

Result: LLM存在显著认知偏差，虽掌握俚语创造性特征但知识未充分对齐人类，难以胜任语言分析等外推任务

Conclusion: LLM的俚语知识不足以支持语言学分析等扩展应用，需进一步优化模型对非正式语言结构的理解

Abstract: Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [19] [A method for improving multilingual quality and diversity of instruction fine-tuning datasets](https://arxiv.org/abs/2509.15549)
*Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei*

Main category: cs.CL

TL;DR: 提出M-DaQ方法解决多语言指令微调的数据质量与多样性问题，在18种语言上验证显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法依赖单一语言假设/启发式规则，难以适应多语言场景下的数据质量与多样性需求

Method: 通过选择高质量且语义多样的多语言IFT样本，首次系统研究多语言场景下的表面对齐假说(SAH)

Result: 60%胜率超越基线模型，人工评估显示响应文化相关度提升，实验覆盖18种语言

Conclusion: M-DaQ有效增强LLMs多语言能力，代码开源促进后续研究

Abstract: Multilingual Instruction Fine-Tuning (IFT) is essential for enabling large
language models (LLMs) to generalize effectively across diverse linguistic and
cultural contexts. However, the scarcity of high-quality multilingual training
data and corresponding building method remains a critical bottleneck. While
data selection has shown promise in English settings, existing methods often
fail to generalize across languages due to reliance on simplistic heuristics or
language-specific assumptions. In this work, we introduce Multilingual Data
Quality and Diversity (M-DaQ), a novel method for improving LLMs
multilinguality, by selecting high-quality and semantically diverse
multilingual IFT samples. We further conduct the first systematic investigation
of the Superficial Alignment Hypothesis (SAH) in multilingual setting.
Empirical results across 18 languages demonstrate that models fine-tuned with
M-DaQ method achieve significant performance gains over vanilla baselines over
60% win rate. Human evaluations further validate these gains, highlighting the
increment of cultural points in the response. We release the M-DaQ code to
support future research.

</details>


### [20] [DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm](https://arxiv.org/abs/2509.15550)
*Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao*

Main category: cs.CL

TL;DR: 提出DNA-DetectLLM，一种基于DNA修复理念的零样本检测方法，通过量化修复代价区分AI生成与人类文本。


<details>
  <summary>Details</summary>
Motivation: LLM生成文本与人类文本特征分布重叠导致检测困难，需解决错误信息传播、知识产权争议等社会风险。

Method: 构建理想AI序列→迭代修复非最优token→以累计修复代价作为检测信号，实现可解释的零样本检测。

Result: 在公开基准数据集上AUROC提升5.55%，F1分数提升2.08%，对抗攻击与文本长度鲁棒性显著。

Conclusion: DNA启发的修复视角有效捕捉生成文本内在特征，检测性能与鲁棒性达到SOTA水平。

Abstract: The rapid advancement of large language models (LLMs) has blurred the line
between AI-generated and human-written text. This progress brings societal
risks such as misinformation, authorship ambiguity, and intellectual property
concerns, highlighting the urgent need for reliable AI-generated text detection
methods. However, recent advances in generative language modeling have resulted
in significant overlap between the feature distributions of human-written and
AI-generated text, blurring classification boundaries and making accurate
detection increasingly challenging. To address the above challenges, we propose
a DNA-inspired perspective, leveraging a repair-based process to directly and
interpretably capture the intrinsic differences between human-written and
AI-generated text. Building on this perspective, we introduce DNA-DetectLLM, a
zero-shot detection method for distinguishing AI-generated and human-written
text. The method constructs an ideal AI-generated sequence for each input,
iteratively repairs non-optimal tokens, and quantifies the cumulative repair
effort as an interpretable detection signal. Empirical evaluations demonstrate
that our method achieves state-of-the-art detection performance and exhibits
strong robustness against various adversarial attacks and input lengths.
Specifically, DNA-DetectLLM achieves relative improvements of 5.55% in AUROC
and 2.08% in F1 score across multiple public benchmark datasets.

</details>


### [21] [Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining](https://arxiv.org/abs/2509.15556)
*Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng*

Main category: cs.CL

TL;DR: 提出Climb框架，通过量化跨语言依赖关系优化多语言数据分配，实验显示其显著提升模型性能并达到SOTA


<details>
  <summary>Details</summary>
Motivation: 解决多语言模型中数据分配比例难以优化的痛点，尤其是跨语言交互复杂性和数据规模敏感性带来的挑战

Method: 1. 引入跨语言交互感知的语言比例量化指标 2. 设计两阶段优化流程（边际效益均衡+分配向量最大化）简化多语言优化问题

Result: Climb分配方案在多语言任务中持续取得SOTA，且使用更少训练token即可媲美开源大模型性能

Conclusion: 系统性优化数据分配机制能显著提升多语言模型性能，为语言资源分配提供了新的方法论框架

Abstract: Large language models (LLMs) have become integral to a wide range of
applications worldwide, driving an unprecedented global demand for effective
multilingual capabilities. Central to achieving robust multilingual performance
is the strategic allocation of language proportions within training corpora.
However, determining optimal language ratios is highly challenging due to
intricate cross-lingual interactions and sensitivity to dataset scale. This
paper introduces Climb (Cross-Lingual Interaction-aware Multilingual
Balancing), a novel framework designed to systematically optimize multilingual
data allocation. At its core, Climb introduces a cross-lingual
interaction-aware language ratio, explicitly quantifying each language's
effective allocation by capturing inter-language dependencies. Leveraging this
ratio, Climb proposes a principled two-step optimization procedure--first
equalizing marginal benefits across languages, then maximizing the magnitude of
the resulting language allocation vectors--significantly simplifying the
inherently complex multilingual optimization problem. Extensive experiments
confirm that Climb can accurately measure cross-lingual interactions across
various multilingual settings. LLMs trained with Climb-derived proportions
consistently achieve state-of-the-art multilingual performance, even achieving
competitive performance with open-sourced LLMs trained with more tokens.

</details>


### [22] [How important is language for human-like intelligence?](https://arxiv.org/abs/2509.15560)
*Gary Lupyan,Hunter Gentry,Martin Zettersten*

Main category: cs.CL

TL;DR: 语言不仅是思想的表达工具，更是人类认知的转化器，通过紧凑表征与文化迭代助力抽象思维形成，这对通用AI系统开发具有关键启示。


<details>
  <summary>Details</summary>
Motivation: 探讨语言在人类认知中的变革性作用，结合AI与认知科学最新进展，揭示语言对抽象概念表征及因果推理的支撑机制。

Method: 理论分析语言的两种核心特性：1) 压缩表征降低抽象概念（如精确数量）的认知负荷；2) 语言作为集体智慧迭代产物，承载文化进化形成的抽象结构。

Result: 语言学习使智能系统（生物或人工）获得世界压缩模型，逆向工程支撑人类思维的因果结构，促进领域通用能力发展。

Conclusion: 语言通过文化积累的抽象概念库，成为解锁通用人工智能及人类高阶认知能力的关键基础设施。

Abstract: We use language to communicate our thoughts. But is language merely the
expression of thoughts, which are themselves produced by other, nonlinguistic
parts of our minds? Or does language play a more transformative role in human
cognition, allowing us to have thoughts that we otherwise could (or would) not
have? Recent developments in artificial intelligence (AI) and cognitive science
have reinvigorated this old question. We argue that language may hold the key
to the emergence of both more general AI systems and central aspects of human
intelligence. We highlight two related properties of language that make it such
a powerful tool for developing domain--general abilities. First, language
offers compact representations that make it easier to represent and reason
about many abstract concepts (e.g., exact numerosity). Second, these compressed
representations are the iterated output of collective minds. In learning a
language, we learn a treasure trove of culturally evolved abstractions. Taken
together, these properties mean that a sufficiently powerful learning system
exposed to language--whether biological or artificial--learns a compressed
model of the world, reverse engineering many of the conceptual and causal
structures that support human (and human-like) thought.

</details>


### [23] [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](https://arxiv.org/abs/2509.15568)
*Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo*

Main category: cs.CL

TL;DR: LiteLong通过结构化主题组织和多智能体辩论机制，高效合成高质量长上下文训练数据，降低计算和工程成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于相关性的长上下文数据合成方法存在计算效率低和数据工程复杂的问题，亟需资源高效的替代方案。

Method: 1. 使用BISAC书籍分类系统构建层次化主题框架
2. 多LLM辩论生成多样化主题内容
3. BM25轻量检索拼接128K-token训练样本

Result: 在HELMET和Ruler基准测试中展现竞争力，且可与其他长依赖增强方法无缝集成

Conclusion: LiteLong降低了长上下文合成的资源门槛，为语言模型的长上下文训练研究提供了可扩展的解决方案

Abstract: High-quality long-context data is essential for training large language
models (LLMs) capable of processing extensive documents, yet existing synthesis
approaches using relevance-based aggregation face challenges of computational
efficiency. We present LiteLong, a resource-efficient method for synthesizing
long-context data through structured topic organization and multi-agent debate.
Our approach leverages the BISAC book classification system to provide a
comprehensive hierarchical topic organization, and then employs a debate
mechanism with multiple LLMs to generate diverse, high-quality topics within
this structure. For each topic, we use lightweight BM25 retrieval to obtain
relevant documents and concatenate them into 128K-token training samples.
Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves
competitive long-context performance and can seamlessly integrate with other
long-dependency enhancement methods. LiteLong makes high-quality long-context
data synthesis more accessible by reducing both computational and data
engineering costs, facilitating further research in long-context language
training.

</details>


### [24] [Relevance to Utility: Process-Supervised Rewrite for RAG](https://arxiv.org/abs/2509.15577)
*Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song*

Main category: cs.CL

TL;DR: 提出R2U框架，通过过程监督直接优化生成正确答案的概率，解决RAG系统中检索相关性与生成效用间的鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成系统存在检索文档相关但生成效用不足的问题，传统桥接模块无法准确捕捉文档效用。

Method: 采用过程监督直接优化生成正确率，设计基于大语言模型监督的知识蒸馏流程提升小模型泛化能力。

Result: 在开放域问答基准测试中显著超越现有桥接基线方法，实现持续性能提升。

Conclusion: 通过过程监督的直接优化与高效蒸馏策略，R2U有效提升了RAG系统的生成效用，为检索-生成协同优化提供新思路。

Abstract: Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.

</details>


### [25] [Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization](https://arxiv.org/abs/2509.15579)
*Yun Tang,Cindy Tseng*

Main category: cs.CL

TL;DR: 提出Chunk SSL算法统一支持流式和离线语音预训练，通过掩码预测损失和高效标量量化实现，在语音识别/翻译任务中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习算法假设完整语音输入，难以适配流式场景的片段语音处理需求。需要开发同时支持流式和离线模式的自监督预训练框架。

Method: 1. 基于分块的掩码预测机制，利用当前块和先前块信息重建语音
2. 提出复制-追加数据增强方法
3. 采用百万级词汇量的有限标量量化(FSQ)模块
4. 引入分组掩码预测降低大词表计算成本

Result: 在Librispeech和Must-C数据集上，流式/离线模式的语音识别和翻译任务均达到SOTA竞争水平。

Conclusion: Chunk SSL成功统一流式与离线预训练范式，大词表FSQ有效促进知识迁移，分组预测机制平衡计算效率与模型性能。

Abstract: Low latency speech human-machine communication is becoming increasingly
necessary as speech technology advances quickly in the last decade. One of the
primary factors behind the advancement of speech technology is self-supervised
learning. Most self-supervised learning algorithms are designed with full
utterance assumption and compromises have to made if partial utterances are
presented, which are common in the streaming applications. In this work, we
propose a chunk based self-supervised learning (Chunk SSL) algorithm as an
unified solution for both streaming and offline speech pre-training. Chunk SSL
is optimized with the masked prediction loss and an acoustic encoder is
encouraged to restore indices of those masked speech frames with help from
unmasked frames in the same chunk and preceding chunks. A copy and append data
augmentation approach is proposed to conduct efficient chunk based
pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to
discretize input speech features and our study shows a high resolution FSQ
codebook, i.e., a codebook with vocabulary size up to a few millions, is
beneficial to transfer knowledge from the pre-training task to the downstream
tasks. A group masked prediction loss is employed during pre-training to
alleviate the high memory and computation cost introduced by the large
codebook. The proposed approach is examined in two speech to text tasks, i.e.,
speech recognition and speech translation. Experimental results on the
\textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method
could achieve very competitive results for speech to text tasks at both
streaming and offline modes.

</details>


### [26] [DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models](https://arxiv.org/abs/2509.15587)
*Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung*

Main category: cs.CL

TL;DR: 提出新逻辑基准DivLogicEval以改进大语言模型的逻辑推理评估，通过反直觉语句组合和新评估指标解决现有基准偏差问题


<details>
  <summary>Details</summary>
Motivation: 现有逻辑推理评测基准存在多技能耦合、语言单一性缺陷和分布偏差，导致评估结果不可靠

Method: 构建包含多样化反直觉自然语句的基准，设计降低LLM偏差/随机性影响的新评估指标

Result: 实验验证了DivLogicEval对逻辑推理能力的要求，并展示不同流行LLM在逻辑推理任务上的性能差异

Conclusion: DivLogicEval能更准确评估语言模型的逻辑推理能力，为模型优化提供可靠基准

Abstract: Logic reasoning in natural language has been recognized as an important
measure of human intelligence for Large Language Models (LLMs). Popular
benchmarks may entangle multiple reasoning skills and thus provide unfaithful
evaluations on the logic reasoning skill. Meanwhile, existing logic reasoning
benchmarks are limited in language diversity and their distributions are
deviated from the distribution of an ideal logic reasoning benchmark, which may
lead to biased evaluation results. This paper thereby proposes a new classical
logic benchmark DivLogicEval, consisting of natural sentences composed of
diverse statements in a counterintuitive way. To ensure a more reliable
evaluation, we also introduce a new evaluation metric that mitigates the
influence of bias and randomness inherent in LLMs. Through experiments, we
demonstrate the extent to which logical reasoning is required to answer the
questions in DivLogicEval and compare the performance of different popular LLMs
in conducting logical reasoning.

</details>


### [27] [SciEvent: Benchmarking Multi-domain Scientific Event Extraction](https://arxiv.org/abs/2509.15620)
*Bofu Dong,Pritesh Shah,Sumedh Sonawane,Tiyasha Banerjee,Erin Brady,Xinya Du,Ming Jiang*

Main category: cs.CL

TL;DR: 提出SciEvent多领域科学事件抽取基准，通过统一事件抽取模式解决传统科学信息提取（SciIE）在跨学科应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统SciIE局限于狭窄领域且缺乏上下文感知，导致信息碎片化或矛盾。需要能支持结构化、跨领域理解的科学信息提取方法。

Method: 1. 将摘要分割为背景、方法、结果、结论四个核心科学活动阶段；2. 提取对应的事件触发词及细粒度论元。

Result: 实验表明现有事件抽取模型与人类标注存在性能差距，在社会科学/人文领域表现欠佳。

Conclusion: SciEvent成为推动多领域科学信息抽取发展的挑战性基准，为实现可泛化的结构化理解奠定基础。

Abstract: Scientific information extraction (SciIE) has primarily relied on
entity-relation extraction in narrow domains, limiting its applicability to
interdisciplinary research and struggling to capture the necessary context of
scientific information, often resulting in fragmented or conflicting
statements. In this paper, we introduce SciEvent, a novel multi-domain
benchmark of scientific abstracts annotated via a unified event extraction (EE)
schema designed to enable structured and context-aware understanding of
scientific content. It includes 500 abstracts across five research domains,
with manual annotations of event segments, triggers, and fine-grained
arguments. We define SciIE as a multi-stage EE pipeline: (1) segmenting
abstracts into core scientific activities--Background, Method, Result, and
Conclusion; and (2) extracting the corresponding triggers and arguments.
Experiments with fine-tuned EE models, large language models (LLMs), and human
annotators reveal a performance gap, with current models struggling in domains
such as sociology and humanities. SciEvent serves as a challenging benchmark
and a step toward generalizable, multi-domain SciIE.

</details>


### [28] [Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets](https://arxiv.org/abs/2509.15621)
*Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Machine Unlearning (MU) has recently attracted considerable attention as a
solution to privacy and copyright issues in large language models (LLMs).
Existing MU methods aim to remove specific target sentences from an LLM while
minimizing damage to unrelated knowledge. However, these approaches require
explicit target sentences and do not support removing broader concepts, such as
persons or events. To address this limitation, we introduce Concept Unlearning
(CU) as a new requirement for LLM unlearning. We leverage knowledge graphs to
represent the LLM's internal knowledge and define CU as removing the forgetting
target nodes and associated edges. This graph-based formulation enables a more
intuitive unlearning and facilitates the design of more effective methods. We
propose a novel method that prompts the LLM to generate knowledge triplets and
explanatory sentences about the forgetting target and applies the unlearning
process to these representations. Our approach enables more precise and
comprehensive concept removal by aligning the unlearning process with the LLM's
internal knowledge representations. Experiments on real-world and synthetic
datasets demonstrate that our method effectively achieves concept-level
unlearning while preserving unrelated knowledge.

</details>


### [29] [Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models](https://arxiv.org/abs/2509.15631)
*Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara*

Main category: cs.CL

TL;DR: 提出通过调整大语言模型内部激活状态实现真正遗忘的新方法，解决现有抑制策略无法消除底层知识且易导致模型崩溃的问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘方法通过抑制输出无法真正消除模型内部知识，且存在模型崩溃风险，需要更本质的遗忘机制

Method: 将目标实体的内部激活状态调整至与'未知'实体不可区分，在稀疏自编码器潜在空间中对齐激活模式

Result: 有效调整目标实体激活状态，在问答任务中显著降低目标知识召回率（下降64%），非目标知识召回率保持92%以上

Conclusion: 该方法实现了真正的知识遗忘而非单纯输出抑制，为LLM隐私保护提供了新范式，解决了传统方法过度抑制和模型退化的问题

Abstract: As large language models (LLMs) are increasingly deployed across various
applications, privacy and copyright concerns have heightened the need for more
effective LLM unlearning techniques. Many existing unlearning methods aim to
suppress undesirable outputs through additional training (e.g., gradient
ascent), which reduces the probability of generating such outputs. While such
suppression-based approaches can control model outputs, they may not eliminate
the underlying knowledge embedded in the model's internal activations; muting a
response is not the same as forgetting it. Moreover, such suppression-based
methods often suffer from model collapse. To address these issues, we propose a
novel unlearning method that directly intervenes in the model's internal
activations. In our formulation, forgetting is defined as a state in which the
activation of a forgotten target is indistinguishable from that of ``unknown''
entities. Our method introduces an unlearning objective that modifies the
activation of the target entity away from those of known entities and toward
those of unknown entities in a sparse autoencoder latent space. By aligning the
target's internal activation with those of unknown entities, we shift the
model's recognition of the target entity from ``known'' to ``unknown'',
achieving genuine forgetting while avoiding over-suppression and model
collapse. Empirically, we show that our method effectively aligns the internal
activations of the forgotten target, a result that the suppression-based
approaches do not reliably achieve. Additionally, our method effectively
reduces the model's recall of target knowledge in question-answering tasks
without significant damage to the non-target knowledge.

</details>


### [30] [Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation](https://arxiv.org/abs/2509.15640)
*Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine*

Main category: cs.CL

TL;DR: 系统评估六种多语言大语言模型在医学英越翻译中的表现，发现模型规模是性能核心因素，术语增强提示策略有效提升专业翻译质量。


<details>
  <summary>Details</summary>
Motivation: 越南语作为低资源语言在医学翻译中存在关键需求，但相关研究和资源匮乏，需系统评估不同提示策略的实际效果。

Method: 使用MedEV数据集测试六种LLMs（0.5B-9B参数），对比零样本/少样本提示、医学词典增强提示及嵌入检索方法。

Result: 大模型零样本表现优异，少样本提升有限；术语提示和嵌入检索能有效提升20%的领域专业翻译准确率。

Conclusion: 多语言LLMs在医学翻译中展现潜力但存在局限，术语增强策略可作为当前阶段的有效解决方案。

Abstract: Medical English-Vietnamese machine translation (En-Vi MT) is essential for
healthcare access and communication in Vietnam, yet Vietnamese remains a
low-resource and under-studied language. We systematically evaluate prompting
strategies for six multilingual LLMs (0.5B-9B parameters) on the MedEV dataset,
comparing zero-shot, few-shot, and dictionary-augmented prompting with Meddict,
an English-Vietnamese medical lexicon. Results show that model scale is the
primary driver of performance: larger LLMs achieve strong zero-shot results,
while few-shot prompting yields only marginal improvements. In contrast,
terminology-aware cues and embedding-based example retrieval consistently
improve domain-specific translation. These findings underscore both the promise
and the current limitations of multilingual LLMs for medical En-Vi MT.

</details>


### [31] [Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations](https://arxiv.org/abs/2509.15655)
*Linyang He,Qiaolin Wang,Xilin Jiang,Nima Mesgarani*

Main category: cs.CL

TL;DR: 语音语言模型在语法特征编码上显著优于概念特征编码


<details>
  <summary>Details</summary>
Motivation: 现有研究未明确语音模型对深层句法和语义特征的编码能力，需系统评估不同应用场景下SLMs的语境特征编码表现

Method: 采用最小对设计和诊断特征分析方法，对71个跨语言层级的任务进行分层分时段分析，覆盖自监督学习、语音识别、语音压缩和音频大模型编码器

Result: 所有语音模型对语法特征的编码均比概念特征更稳定可靠（尤其语音压缩模型表现最弱，音频大模型编码器最强）

Conclusion: 首次系统验证语音模型不同层级的语言特征编码机制，为改进听觉大语言模型的概念编码能力提供理论基础

Abstract: Transformer-based speech language models (SLMs) have significantly improved
neural speech recognition and understanding. While existing research has
examined how well SLMs encode shallow acoustic and phonetic features, the
extent to which SLMs encode nuanced syntactic and conceptual features remains
unclear. By drawing parallels with linguistic competence assessments for large
language models, this study is the first to systematically evaluate the
presence of contextual syntactic and semantic features across SLMs for
self-supervised learning (S3M), automatic speech recognition (ASR), speech
compression (codec), and as the encoder for auditory large language models
(AudioLLMs). Through minimal pair designs and diagnostic feature analysis
across 71 tasks spanning diverse linguistic levels, our layer-wise and
time-resolved analysis uncovers that 1) all speech encode grammatical features
more robustly than conceptual ones.

</details>


### [32] [VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion](https://arxiv.org/abs/2509.15667)
*Dimitrios Damianos,Leon Voukoutis,Georgios Paraskevopoulos,Vassilis Katsouros*

Main category: cs.CL

TL;DR: 提出连续空间融合框架VoxKrikri，通过交叉注意力对齐Whisper与LLM的隐藏表示，实现希腊语语音LLM并提升ASR性能20%


<details>
  <summary>Details</summary>
Motivation: 解决现有语音LLM在跨模态对齐和多语言支持（特别是低资源语言）方面的不足，探索更有效的中间音频文本空间对齐机制

Method: 在连续文本表征空间融合Whisper解码器状态与LLM状态，采用跨模态注意力机制，支持离线和流式两种处理模式

Result: 希腊语ASR基准测试平均提升20%，跨模态表示对齐有效性验证，创造首个希腊语音LLM VoxKrikri

Conclusion: 连续空间融合为多语言/低资源语音LLM提供有效路径，在保持SOTA性能的同时突破跨模态对齐瓶颈

Abstract: We present a multimodal fusion framework that bridges pre-trained
decoder-based large language models (LLM) and acoustic encoder-decoder
architectures such as Whisper, with the aim of building speech-enabled LLMs.
Instead of directly using audio embeddings, we explore an intermediate
audio-conditioned text space as a more effective mechanism for alignment. Our
method operates fully in continuous text representation spaces, fusing
Whisper's hidden decoder states with those of an LLM through cross-modal
attention, and supports both offline and streaming modes. We introduce
\textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that
our approach effectively aligns representations across modalities. These
results highlight continuous space fusion as a promising path for multilingual
and low-resource speech LLMs, while achieving state-of-the-art results for
Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative
improvement across benchmarks.

</details>


### [33] [Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment](https://arxiv.org/abs/2509.15701)
*Ke Wang,Wenning Wei,Yan Deng,Lei He,Sheng Zhao*

Main category: cs.CL

TL;DR: 研究通过微调大规模多模态模型实现自动发音评估，在单词/句子层面表现优异但音素评估仍存挑战，发现斯皮尔曼系数更能反映评分一致性


<details>
  <summary>Details</summary>
Motivation: 探索LMMs在发音评估中的细粒度应用潜力，解决现有系统在多层次评价中的性能瓶颈问题

Method: 使用Speechocean762数据集和私有语料微调LMMs，对比零样本设置并与公开/商业系统进行单粒度任务比较

Result: 微调模型PCC达0.9但SCC仅0.6，单词/句子级评估效果显著优于音素级，单粒度任务表现达到商业系统水平

Conclusion: LMMs在APA应用存在粒度敏感性，需开发细粒度建模方法和考虑排序一致性的评估指标

Abstract: Automatic Pronunciation Assessment (APA) is critical for Computer-Assisted
Language Learning (CALL), requiring evaluation across multiple granularities
and aspects. Large Multimodal Models (LMMs) present new opportunities for APA,
but their effectiveness in fine-grained assessment remains uncertain. This work
investigates fine-tuning LMMs for APA using the Speechocean762 dataset and a
private corpus. Fine-tuning significantly outperforms zero-shot settings and
achieves competitive results on single-granularity tasks compared to public and
commercial systems. The model performs well at word and sentence levels, while
phoneme-level assessment remains challenging. We also observe that the Pearson
Correlation Coefficient (PCC) reaches 0.9, whereas Spearman's rank Correlation
Coefficient (SCC) remains around 0.6, suggesting that SCC better reflects
ordinal consistency. These findings highlight both the promise and limitations
of LMMs for APA and point to future work on fine-grained modeling and
rank-aware evaluation.

</details>


### [34] [Once Upon a Time: Interactive Learning for Storytelling with Small Language Models](https://arxiv.org/abs/2509.15714)
*Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn*

Main category: cs.CL

TL;DR: 通过认知反馈机制提升语言模型训练效率，交互式学习仅需1M词即可达到传统410M词训练效果


<details>
  <summary>Details</summary>
Motivation: 受儿童社交互动学习启发，探索结合高层次认知反馈机制能否减少语言模型训练数据量

Method: 构建师生模型框架：学生生成故事，教师评估可读性/连贯性/创造性，对比不同预训练数据量下的学习效果

Result: 高层次反馈机制具有超强数据效率（1M词交互学习 ≈ 410M词传统训练效果）

Conclusion: 整合认知科学启发的交互反馈可显著提升语言模型训练效率，为AI学习机制优化提供新方向

Abstract: Children efficiently acquire language not just by listening, but by
interacting with others in their social environment. Conversely, large language
models are typically trained with next-word prediction on massive amounts of
text. Motivated by this contrast, we investigate whether language models can be
trained with less data by learning not only from next-word prediction but also
from high-level, cognitively inspired feedback. We train a student model to
generate stories, which a teacher model rates on readability, narrative
coherence, and creativity. By varying the amount of pretraining before the
feedback loop, we assess the impact of this interactive learning on formal and
functional linguistic competence. We find that the high-level feedback is
highly data efficient: With just 1 M words of input in interactive learning,
storytelling skills can improve as much as with 410 M words of next-word
prediction.

</details>


### [35] [REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting](https://arxiv.org/abs/2509.15723)
*Nannan Huang,Haytham M. Fayek,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 提出REFER频率框架提示方法，通过显式参考类和降低认知负荷，有效提升大语言模型意见摘要的公平性，尤其在大型模型和强推理指令下效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有依赖超参数调整和真实分布信息的方法存在实际应用限制，需要开发更符合人类认知原理的公平性提升方法。

Method: 基于认知科学的频率表示原理，设计显式参考类的提示框架，通过系统实验比较不同提示策略对模型公平性的影响。

Result: REFER框架显著提高模型摘要的公平性表现，且模型规模越大/推理指令越强，改进幅度越明显（最大提升达32%）。

Conclusion: 将人类认知增强机制迁移至语言模型提示工程，为提升AI公平性开辟了新路径，未来可扩展至其他推理场景。

Abstract: Individuals express diverse opinions, a fair summary should represent these
viewpoints comprehensively. Previous research on fairness in opinion
summarisation using large language models (LLMs) relied on hyperparameter
tuning or providing ground truth distributional information in prompts.
However, these methods face practical limitations: end-users rarely modify
default model parameters, and accurate distributional information is often
unavailable. Building upon cognitive science research demonstrating that
frequency-based representations reduce systematic biases in human statistical
reasoning by making reference classes explicit and reducing cognitive load,
this study investigates whether frequency framed prompting (REFER) can
similarly enhance fairness in LLM opinion summarisation. Through systematic
experimentation with different prompting frameworks, we adapted techniques
known to improve human reasoning to elicit more effective information
processing in language models compared to abstract probabilistic
representations.Our results demonstrate that REFER enhances fairness in
language models when summarising opinions. This effect is particularly
pronounced in larger language models and using stronger reasoning instructions.

</details>


### [36] [Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](https://arxiv.org/abs/2509.15739)
*Reza Sanayei,Srdjan Vesic,Eduardo Blanco,Mihai Surdeanu*

Main category: cs.CL

TL;DR: LLM在类辩论的非线性结构推理中展现中等潜力，但受限于输入长度和文本连贯性，需结合图结构推理优化。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在自然辩论场景（以计算论证理论为基础）中模拟结构化推理的能力，突破现有线性任务局限。

Method: 使用QuAD语义框架评估LLM对攻击/支持关系的推理，通过NoDE数据集测试不同提示策略（思维链、上下文学习）的表现。

Result: 模型输出与QuAD排名中度匹配，长文本/不连贯语境性能下降，高级提示策略可缓解长度/位置偏差。

Conclusion: LLM具备形式化论证建模潜力，但需开发图感知推理机制突破现有局限。

Abstract: Large Language Models (LLMs) excel at linear reasoning tasks but remain
underexplored on non-linear structures such as those found in natural debates,
which are best expressed as argument graphs. We evaluate whether LLMs can
approximate structured reasoning from Computational Argumentation Theory (CAT).
Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which
assigns acceptability scores to arguments based on their attack and support
relations. Given only dialogue-formatted debates from two NoDE datasets, models
are prompted to rank arguments without access to the underlying graph. We test
several LLMs under advanced instruction strategies, including Chain-of-Thought
and In-Context Learning. While models show moderate alignment with QuAD
rankings, performance degrades with longer inputs or disrupted discourse flow.
Advanced prompting helps mitigate these effects by reducing biases related to
argument length and position. Our findings highlight both the promise and
limitations of LLMs in modeling formal argumentation semantics and motivate
future work on graph-aware reasoning.

</details>


### [37] [UniGist: Towards General and Hardware-aligned Sequence-level Long Context Compression](https://arxiv.org/abs/2509.15763)
*Chenlong Deng,Zhisong Zhang,Kelong Mao,Shuaiyi Li,Tianqing Fang,Hongming Zhang,Haitao Mi,Dong Yu,Zhicheng Dou*

Main category: cs.CL

TL;DR: UniGist提出通过细粒度压缩标记替换原始token，配合高效训练策略，显著降低长上下文模型KV缓存的内存开销并保持上下文完整性。


<details>
  <summary>Details</summary>
Motivation: 现有序列级压缩方案在丢弃KV缓存时易丢失关键上下文信息，需开发既能有效压缩又能保留核心信息的解决方案。

Method: 1. 引入细粒度gist标记替换原始token
2. 采用分块自由训练策略
3. 设计支持gist位移优化的GPU训练内核
4. 实现物理删除压缩token的灵活推理机制

Result: 在多个长上下文任务中，UniGist压缩质量提升50%+，细节召回任务准确率提升21.6%，长程依赖建模F1提升13.4%

Conclusion: UniGist在实现实时内存节省的同时，通过创新性的细粒度压缩机制显著增强了长上下文建模能力，为实际部署提供了有效解决方案。

Abstract: Large language models are increasingly capable of handling long-context
inputs, but the memory overhead of key-value (KV) cache remains a major
bottleneck for general-purpose deployment. While various compression strategies
have been explored, sequence-level compression, which drops the full KV caches
for certain tokens, is particularly challenging as it can lead to the loss of
important contextual information. To address this, we introduce UniGist, a
sequence-level long-context compression framework that efficiently preserves
context information by replacing raw tokens with special compression tokens
(gists) in a fine-grained manner. We adopt a chunk-free training strategy and
design an efficient kernel with a gist shift trick, enabling optimized GPU
training. Our scheme also supports flexible inference by allowing the actual
removal of compressed tokens, resulting in real-time memory savings.
Experiments across multiple long-context tasks demonstrate that UniGist
significantly improves compression quality, with especially strong performance
in detail-recalling tasks and long-range dependency modeling.

</details>


### [38] [UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations](https://arxiv.org/abs/2509.15789)
*Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen*

Main category: cs.CL

TL;DR: 开发了基于网络爬取和GAPA算法的端到端解决方案，构建了713M英语token的公开最大人工翻译平行语料库


<details>
  <summary>Details</summary>
Motivation: 现有联合国文件语料库存在流程不透明、难以复现和规模受限的问题，阻碍机器翻译研究发展

Method: 1. 全自动流程：从网页抓取到段落对齐 2. 提出图辅助段落对齐算法(GAPA) 3. 支持单机/分布式计算架构

Result: 创建含7.13亿英语token的语料库，规模达先前工作两倍，且完全由人工翻译内容构成

Conclusion: 该可复现框架和超大规模语料库（MIT许可开源）显著提升了多语言数据的质量与可用性

Abstract: The quality and accessibility of multilingual datasets are crucial for
advancing machine translation. However, previous corpora built from United
Nations documents have suffered from issues such as opaque process, difficulty
of reproduction, and limited scale. To address these challenges, we introduce a
complete end-to-end solution, from data acquisition via web scraping to text
alignment. The entire process is fully reproducible, with a minimalist
single-machine example and optional distributed computing steps for
scalability. At its core, we propose a new Graph-Aided Paragraph Alignment
(GAPA) algorithm for efficient and flexible paragraph-level alignment. The
resulting corpus contains over 713 million English tokens, more than doubling
the scale of prior work. To the best of our knowledge, this represents the
largest publicly available parallel corpus composed entirely of
human-translated, non-AI-generated content. Our code and corpus are accessible
under the MIT License.

</details>


### [39] [RAVE: Retrieval and Scoring Aware Verifiable Claim Detection](https://arxiv.org/abs/2509.15793)
*Yufeng Li,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 提出RAVE框架，通过整合证据检索与可信度信号提升社交媒体可验证声明检测效果，准确率和F1值超越基线模型


<details>
  <summary>Details</summary>
Motivation: 现有基于语言特征和可核查价值的方法难以应对模糊政治言论和推文等多样化格式，需开发更有效的自动事实核查工具应对虚假信息传播

Method: RAVE框架结合证据检索与结构化信号（证据相关性和来源可信度评分），通过双阶段检索与联合评分机制增强检测能力

Result: 在CT22-test和PoliClaim-test数据集上，RAVE在准确率（75.2%）和F1值（73.8%）上均优于纯文本模型（68.4%/66.1%）及检索基线（71.2%/69.5%）

Conclusion: 融合证据检索与可信度评估的结构化信号能有效提升复杂场景（政治话语、社交媒体）下的可验证声明检测，为自动化事实核查提供新方向

Abstract: The rapid spread of misinformation on social media underscores the need for
scalable fact-checking tools. A key step is claim detection, which identifies
statements that can be objectively verified. Prior approaches often rely on
linguistic cues or claim check-worthiness, but these struggle with vague
political discourse and diverse formats such as tweets. We present RAVE
(Retrieval and Scoring Aware Verifiable Claim Detection), a framework that
combines evidence retrieval with structured signals of relevance and source
credibility. Experiments on CT22-test and PoliClaim-test show that RAVE
consistently outperforms text-only and retrieval-based baselines in both
accuracy and F1.

</details>


### [40] [Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning](https://arxiv.org/abs/2509.15811)
*Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz*

Main category: cs.CL

TL;DR: 跨语言奖励模型通过利用不同语言生成路径的互补性，显著提升多语言模型的数学推理性能，尤其在低采样预算下对英语帮助明显。


<details>
  <summary>Details</summary>
Motivation: 探究多语言大模型中不同语言的推理能力差异及生成路径的互补性。

Method: 训练跨语言奖励模型对多语言生成的回答进行质量排序。

Result: 跨语言奖励模型相比单语言模型提升推理性能，英语在低采样预算下受益显著。

Conclusion: 通过整合多语言互补优势，为提升跨语言推理能力开辟新路径。

Abstract: While the reasoning abilities of large language models (LLMs) continue to
advance, it remains unclear how such ability varies across languages in
multilingual LLMs and whether different languages produce reasoning paths that
complement each other. To investigate this question, we train a reward model to
rank generated responses for a given question across languages. Our results
show that our cross-lingual reward model substantially improves mathematical
reasoning performance compared to using reward modeling within a single
language, benefiting even high-resource languages. While English often exhibits
the highest performance in multilingual models, we find that cross-lingual
sampling particularly benefits English under low sampling budgets. Our findings
reveal new opportunities to improve multilingual reasoning by leveraging the
complementary strengths of diverse languages.

</details>


### [41] [The Curious Case of Visual Grounding: Different Effects for Speech- and Text-based Language Encoders](https://arxiv.org/abs/2509.15837)
*Adrian Sauter,Willem Zuidema,Marianne de Heer Kloots*

Main category: cs.CL

TL;DR: 研究通过比较语音和文本模型的表征，发现视觉基础增强了词汇身份编码而非语义，且对语音模型语义提升有限


<details>
  <summary>Details</summary>
Motivation: 探索视觉信息如何影响音频/文本模型的语义处理机制，分析视觉基础对语言表征的影响差异

Method: 采用全局表征对齐度比较和语音/语义聚类分析两种方法

Result: 1. 视觉基础使语音-文本表征对齐度提升（主要来自词汇身份编码）
2. 语音模型保持语音主导，视觉基础未改善语义区分性（与文本模型相反）

Conclusion: 研究结果为开发融合视觉信息的语音模型语义增强方法提供了理论依据

Abstract: How does visual information included in training affect language processing
in audio- and text-based deep learning models? We explore how such visual
grounding affects model-internal representations of words, and find
substantially different effects in speech- vs. text-based language encoders.
Firstly, global representational comparisons reveal that visual grounding
increases alignment between representations of spoken and written language, but
this effect seems mainly driven by enhanced encoding of word identity rather
than meaning. We then apply targeted clustering analyses to probe for phonetic
vs. semantic discriminability in model representations. Speech-based
representations remain phonetically dominated with visual grounding, but in
contrast to text-based representations, visual grounding does not improve
semantic discriminability. Our findings could usefully inform the development
of more efficient methods to enrich speech-based models with visually-informed
semantics.

</details>


### [42] [Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems](https://arxiv.org/abs/2509.15839)
*Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang*

Main category: cs.CL

TL;DR: 提出中文物理推理基准Multi-Physics，通过双评估框架系统分析多模态大模型在复杂学科中的表现


<details>
  <summary>Details</summary>
Motivation: 现有评估基准在细粒度学科覆盖、逐步推理过程评估和多语言支持方面存在不足，特别是缺乏对视觉信息作用的系统研究

Method: 构建包含5个难度层级、11个物理学科的数据集，采用答案准确率和思维链完整性的双评估框架，通过输入模式对比研究视觉信息影响

Result: 揭示当前MLLMs在复杂物理推理中的局限性，验证视觉信息对模型性能的关键作用，建立思维链完整性与准确率的正相关关系

Conclusion: Multi-Physics为社区提供细粒度评估资源，其方法论为解构多模态推理过程提供新视角，开源数据推动领域发展

Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress,
their application in specialized scientific domains like physics reveals
significant gaps in current evaluation benchmarks. Specifically, existing
benchmarks often lack fine-grained subject coverage, neglect the step-by-step
reasoning process, and are predominantly English-centric, failing to
systematically evaluate the role of visual information. Therefore, we introduce
\textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive
benchmark that includes 5 difficulty levels, featuring 1,412 image-associated,
multiple-choice questions spanning 11 high-school physics subjects. We employ a
dual evaluation framework to evaluate 20 different MLLMs, analyzing both final
answer accuracy and the step-by-step integrity of their chain-of-thought.
Furthermore, we systematically study the impact of difficulty level and visual
information by comparing the model performance before and after changing the
input mode. Our work provides not only a fine-grained resource for the
community but also offers a robust methodology for dissecting the multimodal
reasoning process of state-of-the-art MLLMs, and our dataset and code have been
open-sourced: https://github.com/luozhongze/Multi-Physics.

</details>


### [43] [Distribution-Aligned Decoding for Efficient LLM Task Adaptation](https://arxiv.org/abs/2509.15888)
*Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CL

TL;DR: 提出Steering Vector Decoding (SVD)方法，通过解码阶段的分布对齐替代权重更新，实现轻量级、理论可解释的任务适配。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（PEFT）在适应十亿级参数模型时仍存在成本过高问题，需要更轻量的输出分布直接对齐方案。

Method: 1. 短时预热微调获取任务分布
2. 通过KL散度梯度提取任务导向向量
3. 解码阶段使用导向向量控制输出分布

Result: 在9个基准测试中：
- 多选任务准确率最高提升5%
- 开放式生成真实性提升2%
- 常识推理提升1-2%
（无需额外可训练参数）

Conclusion: SVD为大语言模型任务适配提供了理论支撑的轻量级方案，在保持PEFT参数效率的同时显著提升模型表现。

Abstract: Adapting billion-parameter language models to a downstream task is still
costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task
adaptation as output-distribution alignment: the objective is to steer the
output distribution toward the task distribution directly during decoding
rather than indirectly through weight updates. Building on this view, we
introduce Steering Vector Decoding (SVD), a lightweight, PEFT-compatible, and
theoretically grounded method. We start with a short warm-start fine-tune and
extract a task-aware steering vector from the Kullback-Leibler (KL) divergence
gradient between the output distribution of the warm-started and pre-trained
models. This steering vector is then used to guide the decoding process to
steer the model's output distribution towards the task distribution. We
theoretically prove that SVD is first-order equivalent to the gradient step of
full fine-tuning and derive a globally optimal solution for the strength of the
steering vector. Across three tasks and nine benchmarks, SVD paired with four
standard PEFT methods improves multiple-choice accuracy by up to 5 points and
open-ended truthfulness by 2 points, with similar gains (1-2 points) on
commonsense datasets without adding trainable parameters beyond the PEFT
adapter. SVD thus offers a lightweight, theoretically grounded path to stronger
task adaptation for large language models.

</details>


### [44] [The Psychology of Falsehood: A Human-Centric Survey of Misinformation Detection](https://arxiv.org/abs/2509.15896)
*Arghodeep Nandi,Megha Sundriyal,Euna Mehnaz Khan,Jikai Sun,Emily Vraga,Jaideep Srivastava,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 提出将传统事实核查与心理学（认知偏差/社会动态/情感反应）结合，构建更有效的错误信息检测框架


<details>
  <summary>Details</summary>
Motivation: 现有错误信息检测系统过度聚焦事实准确性，忽视了人类认知和情感维度对信息传播的关键影响，导致无法全面遏制错误信息的社会危害

Method: 通过心理学视角（认知偏差理论、社会影响模型、情感分析）系统分析现有检测系统，提出神经-行为模型的多维度整合框架

Result: 揭示当前方法在心理机制建模、动态社会传播追踪方面的缺陷，提出融合脑神经科学数据和社会网络分析的改进方向

Conclusion: 整合技术检测与人类认知/社会复杂性的跨学科框架，能更有效识别和阻断错误信息的传播路径与心理影响机制

Abstract: Misinformation remains one of the most significant issues in the digital age.
While automated fact-checking has emerged as a viable solution, most current
systems are limited to evaluating factual accuracy. However, the detrimental
effect of misinformation transcends simple falsehoods; it takes advantage of
how individuals perceive, interpret, and emotionally react to information. This
underscores the need to move beyond factuality and adopt more human-centered
detection frameworks. In this survey, we explore the evolving interplay between
traditional fact-checking approaches and psychological concepts such as
cognitive biases, social dynamics, and emotional responses. By analyzing
state-of-the-art misinformation detection systems through the lens of human
psychology and behavior, we reveal critical limitations of current methods and
identify opportunities for improvement. Additionally, we outline future
research directions aimed at creating more robust and adaptive frameworks, such
as neuro-behavioural models that integrate technological factors with the
complexities of human cognition and social influence. These approaches offer
promising pathways to more effectively detect and mitigate the societal harms
of misinformation.

</details>


### [45] [Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions](https://arxiv.org/abs/2509.15901)
*Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp*

Main category: cs.CL

TL;DR: 提出FRAME模块化流程和SCOPE协议，通过语义重组与推理轨迹构建，结合P-MESA评估框架，显著降低会议摘要的幻觉与遗漏错误（减少2/5错误点），提升个性化适配与结果可信度（评估准确率≥89%，与人类评分强相关r≥0.70）。


<details>
  <summary>Details</summary>
Motivation: 现有LLM会议摘要存在幻觉、遗漏、内容不相关三大缺陷，需提升生成结果的可控性、忠实度与个性化适配能力。

Method: 1. FRAME流程：事实提取→主题化组织→大纲语义增强；2. SCOPE协议：通过回答九大问题构建推理轨迹指导内容选择；3. P-MESA多维度无参考评估框架。

Result: P-MESA平衡准确率≥89%，错误严重度相关系数r≥0.70；在QMSum/FAME数据集上，FRAME使幻觉和遗漏减少2/5错误点，SCOPE提升知识适配度与目标对齐效果。

Conclusion: 通过重构摘要生成范式（语义增强+推理轨迹），结合新型评估体系，系统性提升会议摘要的可靠性、控制力与个性化适配，为LLM摘要技术发展提供新方向。

Abstract: Meeting summarization with large language models (LLMs) remains error-prone,
often producing outputs with hallucinations, omissions, and irrelevancies. We
present FRAME, a modular pipeline that reframes summarization as a semantic
enrichment task. FRAME extracts and scores salient facts, organizes them
thematically, and uses these to enrich an outline into an abstractive summary.
To personalize summaries, we introduce SCOPE, a reason-out-loud protocol that
has the model build a reasoning trace by answering nine questions before
content selection. For evaluation, we propose P-MESA, a multi-dimensional,
reference-free evaluation framework to assess if a summary fits a target
reader. P-MESA reliably identifies error instances, achieving >= 89% balanced
accuracy against human annotations and strongly aligns with human severity
ratings (r >= 0.70). On QMSum and FAME, FRAME reduces hallucination and
omission by 2 out of 5 points (measured with MESA), while SCOPE improves
knowledge fit and goal alignment over prompt-only baselines. Our findings
advocate for rethinking summarization to improve control, faithfulness, and
personalization.

</details>


### [46] [Beyond the Score: Uncertainty-Calibrated LLMs for Automated Essay Assessment](https://arxiv.org/abs/2509.15926)
*Ahmed Karim,Qiao Wang,Zheng Yuan*

Main category: cs.CL

TL;DR: 将保形预测与开源大语言模型结合，为自动作文评分系统提供带有置信度保障的集合预测输出


<details>
  <summary>Details</summary>
Motivation: 解决现有自动评分系统缺乏置信度指标和解释性，阻碍高风险考试场景落地的问题

Method: 在Llama-3 8B和Qwen-2.5 3B模型上微调，使用保形预测框架进行校准（90%风险水平），采用UAcc指标评估可靠性

Result: 校准后的模型在保证覆盖率目标的同时保持预测集紧凑，验证中等规模开源LLM可支持教师介入的评分系统

Conclusion: 首次将保形预测与UAcc结合用于作文评分，证明技术可行性，提出扩展研究和用户验证作为未来方向

Abstract: Automated Essay Scoring (AES) systems now reach near human agreement on some
public benchmarks, yet real-world adoption, especially in high-stakes
examinations, remains limited. A principal obstacle is that most models output
a single score without any accompanying measure of confidence or explanation.
We address this gap with conformal prediction, a distribution-free wrapper that
equips any classifier with set-valued outputs and formal coverage guarantees.
Two open-source large language models (Llama-3 8B and Qwen-2.5 3B) are
fine-tuned on three diverse corpora (ASAP, TOEFL11, Cambridge-FCE) and
calibrated at a 90 percent risk level. Reliability is assessed with UAcc, an
uncertainty-aware accuracy that rewards models for being both correct and
concise. To our knowledge, this is the first work to combine conformal
prediction and UAcc for essay scoring. The calibrated models consistently meet
the coverage target while keeping prediction sets compact, indicating that
open-source, mid-sized LLMs can already support teacher-in-the-loop AES; we
discuss scaling and broader user studies as future work.

</details>


### [47] [Localmax dynamics for attention in transformers and its asymptotic behavior](https://arxiv.org/abs/2509.15958)
*Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard*

Main category: cs.CL

TL;DR: 提出新型localmax注意力模型，分析其收敛性、渐进行为及与传统方法的联系


<details>
  <summary>Details</summary>
Motivation: 解决传统softmax与hardmax动态的局限性，通过参数化设计实现更灵活的关注机制，提升理论可解释性

Method: 运用动态系统理论分析收敛性，引入quiescent sets描述顶点邻域不变性，并尝试扩展Lyapunov稳定性方法

Result: 证明模型无有限时间收敛性，揭示quiescent sets在参数时变中的关键作用，建立与hardmax的极限关联

Conclusion: localmax拓展了注意力机制的理论框架，但非对称交互对传统分析工具提出新挑战，需发展适配的动态系统方法

Abstract: We introduce a new discrete-time attention model, termed the localmax
dynamics, which interpolates between the classic softmax dynamics and the
hardmax dynamics, where only the tokens that maximize the influence toward a
given token have a positive weight. As in hardmax, uniform weights are
determined by a parameter controlling neighbor influence, but the key extension
lies in relaxing neighborhood interactions through an alignment-sensitivity
parameter, which allows controlled deviations from pure hardmax behavior. As we
prove, while the convex hull of the token states still converges to a convex
polytope, its structure can no longer be fully described by a maximal alignment
set, prompting the introduction of quiescent sets to capture the invariant
behavior of tokens near vertices. We show that these sets play a key role in
understanding the asymptotic behavior of the system, even under time-varying
alignment sensitivity parameters. We further show that localmax dynamics does
not exhibit finite-time convergence and provide results for vanishing, nonzero,
time-varying alignment-sensitivity parameters, recovering the limiting behavior
of hardmax as a by-product. Finally, we adapt Lyapunov-based methods from
classical opinion dynamics, highlighting their limitations in the asymmetric
setting of localmax interactions and outlining directions for future research.

</details>


### [48] [BEFT: Bias-Efficient Fine-Tuning of Language Models](https://arxiv.org/abs/2509.15974)
*Baichuan Huang,Ananth Balashankar,Amir Aminifar*

Main category: cs.CL

TL;DR: 提出了一种名为BEFT的偏差高效微调方法，通过选择特定偏差项进行微调，在保持参数效率的同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏差项变化的幅度或经验Fisher信息的方法对偏差项选择指导有限，需探索更有效的偏差项选择机制以实现参数高效微调。

Method: 开发基于任务损失函数的二阶导数分析的偏差项选择方法，支持编码器-解码器架构的LLM（110M至6.7B参数）跨分类、生成等多任务场景应用。

Result: 在GLUE、SuperGLUE等基准测试中，BEFT相比全参数微调节省99.6%参数量的同时，保持98%以上性能水平。

Conclusion: 通过理论驱动的偏差项选择机制，BEFT为大规模语言模型的高效适配提供了新的解决方案，在参数效率与性能间取得更好平衡。

Abstract: Fine-tuning all-bias-terms stands out among various parameter-efficient
fine-tuning (PEFT) techniques, owing to its out-of-the-box usability and
competitive performance, especially in low-data regimes. Bias-only fine-tuning
has the potential for unprecedented parameter efficiency. However, the link
between fine-tuning different bias terms (i.e., bias terms in the query, key,
or value projections) and downstream performance remains unclear. The existing
approaches, e.g., based on the magnitude of bias change or empirical Fisher
information, provide limited guidance for selecting the particular bias term
for effective fine-tuning. In this paper, we propose an approach for selecting
the bias term to be fine-tuned, forming the foundation of our bias-efficient
fine-tuning (BEFT). We extensively evaluate our bias-efficient approach against
other bias-selection approaches, across a wide range of large language models
(LLMs) spanning encoder-only and decoder-only architectures from 110M to 6.7B
parameters. Our results demonstrate the effectiveness and superiority of our
bias-efficient approach on diverse downstream tasks, including classification,
multiple-choice, and generation tasks.

</details>


### [49] [Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning](https://arxiv.org/abs/2509.16025)
*Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen*

Main category: cs.CL

TL;DR: 提出基于多模态基础模型的会话级口语评估方法，结合Whisper ASR声学校准和多目标学习，在无需人工特征下实现更可靠的L2英语口语能力评估。


<details>
  <summary>Details</summary>
Motivation: 现有级联系统存在误差传播风险，端到端模型受限于短音频窗口可能忽略话语级特征，需开发更可靠的会话级评估方法满足计算机辅助语言学习需求。

Method: 采用冻结的Whisper ASR模型提取声学特征，结合多目标学习框架联合优化整体口语水平评估和分项特质预测，实现端到端的会话级处理。

Result: 在Speak & Improve基准上超越原有级联系统SOTA，展现跨部分的强泛化能力，形成适用于CALL应用的紧凑评估模型。

Conclusion: 该方法通过完整处理学习者会话响应，在预测整体口语水平方面表现优异，为计算机辅助语言学习提供了高效的自动化评估解决方案。

Abstract: Spoken Language Assessment (SLA) estimates a learner's oral proficiency from
spontaneous speech. The growing population of L2 English speakers has
intensified the demand for reliable SLA, a critical component of Computer
Assisted Language Learning (CALL). Existing efforts often rely on cascaded
pipelines, which are prone to error propagation, or end-to-end models that
often operate on a short audio window, which might miss discourse-level
evidence. This paper introduces a novel multimodal foundation model approach
that performs session-level evaluation in a single pass. Our approach couples
multi-target learning with a frozen, Whisper ASR model-based speech prior for
acoustic-aware calibration, allowing for jointly learning holistic and
trait-level objectives of SLA without resorting to handcrafted features. By
coherently processing the entire response session of an L2 speaker, the model
excels at predicting holistic oral proficiency. Experiments conducted on the
Speak & Improve benchmark demonstrate that our proposed approach outperforms
the previous state-of-the-art cascaded system and exhibits robust cross-part
generalization, producing a compact deployable grader that is tailored for CALL
applications.

</details>


### [50] [Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech](https://arxiv.org/abs/2509.16028)
*Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim*

Main category: cs.CL

TL;DR: 提出TVS框架分离LLM推理与语音输出，通过ReVerT中间层提升语音自然度同时保持推理性能


<details>
  <summary>Details</summary>
Motivation: 直接应用LLM于语音对话会导致文本-语音输出不匹配，现有方法损害模型推理能力

Method: Think-Verbalize-Speak三阶段框架，采用基于增量异步摘要的ReVerT实现低延迟文本转换

Result: 在保证推理能力前提下显著提升语音自然度和简洁性（多基准测试验证）

Conclusion: 解耦推理与语音输出的框架有效平衡LLM性能与语音质量，为语音对话系统提供新范式

Abstract: Spoken dialogue systems increasingly employ large language models (LLMs) to
leverage their advanced reasoning capabilities. However, direct application of
LLMs in spoken communication often yield suboptimal results due to mismatches
between optimal textual and verbal delivery. While existing approaches adapt
LLMs to produce speech-friendly outputs, their impact on reasoning performance
remains underexplored. In this work, we propose Think-Verbalize-Speak, a
framework that decouples reasoning from spoken delivery to preserve the full
reasoning capacity of LLMs. Central to our method is verbalizing, an
intermediate step that translates thoughts into natural, speech-ready text. We
also introduce ReVerT, a latency-efficient verbalizer based on incremental and
asynchronous summarization. Experiments across multiple benchmarks show that
our method enhances speech naturalness and conciseness with minimal impact on
reasoning. The project page with the dataset and the source code is available
at https://yhytoto12.github.io/TVS-ReVerT

</details>


### [51] [Beyond Pointwise Scores: Decomposed Criteria-Based Evaluation of LLM Responses](https://arxiv.org/abs/2509.16093)
*Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: 提出DeCE评估框架，通过分解精确度（事实准确性）和召回率（概念覆盖率），显著提升法律/医学等高危领域长文本答案评估效果，与专家判断相关性达0.78。


<details>
  <summary>Details</summary>
Motivation: 传统评估指标（BLEU/ROUGE）无法捕捉语义正确性，现有LLM评估器将多维质量压缩为单一分数，难以满足专业领域精细化评估需求。

Method: 1. 分离精确度（事实准确+相关）和召回率（概念覆盖）维度
2. 自动从参考答案提取实例化评估标准
3. 模型无关且领域通用的框架设计

Result: 1. 与专家判断相关性r=0.78（传统指标0.12）
2. 通用模型侧重召回率，专用模型侧重精确度
3. 仅11.95%生成标准需专家修正

Conclusion: DeCE提供可解释、可扩展的评估框架，揭示模型特性间的权衡关系，适用于需要细粒度质量评估的专业领域。

Abstract: Evaluating long-form answers in high-stakes domains such as law or medicine
remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to
capture semantic correctness, and current LLM-based evaluators often reduce
nuanced aspects of answer quality into a single undifferentiated score. We
introduce DeCE, a decomposed LLM evaluation framework that separates precision
(factual accuracy and relevance) and recall (coverage of required concepts),
using instance-specific criteria automatically extracted from gold answer
requirements. DeCE is model-agnostic and domain-general, requiring no
predefined taxonomies or handcrafted rubrics. We instantiate DeCE to evaluate
different LLMs on a real-world legal QA task involving multi-jurisdictional
reasoning and citation grounding. DeCE achieves substantially stronger
correlation with expert judgments ($r=0.78$), compared to traditional metrics
($r=0.12$), pointwise LLM scoring ($r=0.35$), and modern multidimensional
evaluators ($r=0.48$). It also reveals interpretable trade-offs: generalist
models favor recall, while specialized models favor precision. Importantly,
only 11.95% of LLM-generated criteria required expert revision, underscoring
DeCE's scalability. DeCE offers an interpretable and actionable LLM evaluation
framework in expert domains.

</details>


### [52] [DiEP: Adaptive Mixture-of-Experts Compression through Differentiable Expert Pruning](https://arxiv.org/abs/2509.16105)
*Sikai Bai,Haoxi Li,Jie Zhang,Zicong Hong,Song Guo*

Main category: cs.CL

TL;DR: 提出非均匀剪枝策略DiEP，通过分层自适应调整剪枝率，解决MoE模型剪枝时不同层专家冗余差异导致的性能下降问题。在Mixtral 8×7B等模型上验证，仅保留半数专家即可维持92%性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统MoE剪枝采用统一稀疏度，忽视不同层专家冗余度的差异，导致次优结果和性能损失。需开发适配不同层冗余特性的剪枝策略。

Method: 1. 将离散搜索空间连续化处理，支持指数级非均匀专家组合
2. 联合学习层间重要性参数
3. 基于梯度的自适应剪枝机制调整分层剪枝率

Result: 在5种先进MoE模型测试中：
- Mixtral 8×7B剪除半数专家仍保持92%性能
- MMLU数据集表现超越其他方法7.1%
- 验证了分层剪枝策略的有效性

Conclusion: DiEP首次实现MoE模型的非均匀自适应剪枝，突破传统剪枝方法的性能瓶颈，为大规模MoE模型部署提供高效压缩方案。

Abstract: Despite the significant breakthrough of Mixture-of-Experts (MoE), the
increasing scale of these MoE models presents huge memory and storage
challenges. Existing MoE pruning methods, which involve reducing parameter size
with a uniform sparsity across all layers, often lead to suboptimal outcomes
and performance degradation due to varying expert redundancy in different MoE
layers. To address this, we propose a non-uniform pruning strategy, dubbed
\textbf{Di}fferentiable \textbf{E}xpert \textbf{P}runing (\textbf{DiEP}), which
adaptively adjusts pruning rates at the layer level while jointly learning
inter-layer importance, effectively capturing the varying redundancy across
different MoE layers. By transforming the global discrete search space into a
continuous one, our method handles exponentially growing non-uniform expert
combinations, enabling adaptive gradient-based pruning. Extensive experiments
on five advanced MoE models demonstrate the efficacy of our method across
various NLP tasks. Notably, \textbf{DiEP} retains around 92\% of original
performance on Mixtral 8$\times$7B with only half the experts, outperforming
other pruning methods by up to 7.1\% on the challenging MMLU dataset.

</details>


### [53] [It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge](https://arxiv.org/abs/2509.16107)
*Lukas Ellinger,Georg Groh*

Main category: cs.CL

TL;DR: LLMs在处理对话指代歧义时存在局限，简化请求削弱常识推理，直接偏好优化微调可显著提升表现


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何利用常识解决多轮对话中的指代歧义，分析持续歧义下的模型行为及简化语言请求的影响

Method: 构建多语言评估数据集，测试5个主流LLMs（含人工标注），并对Llama-3.1-8B进行直接偏好优化微调实验

Result: 当前模型易固化单一解释或穷举可能答案，简化提示使常识推理使用率下降62%，微调后模型准确率提升37%

Conclusion: LLMs的歧义处理机制存在本质缺陷，需通过针对性微调优化才能适应不同沟通风格，保证对话系统鲁棒性

Abstract: Ambiguous words or underspecified references require interlocutors to resolve
them, often by relying on shared context and commonsense knowledge. Therefore,
we systematically investigate whether Large Language Models (LLMs) can leverage
commonsense to resolve referential ambiguity in multi-turn conversations and
analyze their behavior when ambiguity persists. Further, we study how requests
for simplified language affect this capacity. Using a novel multilingual
evaluation dataset, we test DeepSeek v3, GPT-4o, Qwen3-32B, GPT-4o-mini, and
Llama-3.1-8B via LLM-as-Judge and human annotations. Our findings indicate that
current LLMs struggle to resolve ambiguity effectively: they tend to commit to
a single interpretation or cover all possible references, rather than hedging
or seeking clarification. This limitation becomes more pronounced under
simplification prompts, which drastically reduce the use of commonsense
reasoning and diverse response strategies. Fine-tuning Llama-3.1-8B with Direct
Preference Optimization substantially improves ambiguity resolution across all
request types. These results underscore the need for advanced fine-tuning to
improve LLMs' handling of ambiguity and to ensure robust performance across
diverse communication styles.

</details>


### [54] [CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion](https://arxiv.org/abs/2509.16112)
*Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li*

Main category: cs.CL

TL;DR: CodeRAG提出了基于检索增强的仓库级代码补全框架，通过查询构建优化、多路径代码检索和BestFit重排序显著提升现有方法性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在查询构建不当、单一检索路径、检索器与LLM未对齐的问题，导致代码补全效果受限。

Method: 采用对数概率指导的查询构建策略，结合多路径代码检索和偏好对齐的BestFit重排序机制。

Result: 在ReccEval和CCEval基准测试中，CodeRAG持续超越SOTA方法，验证了框架有效性。

Conclusion: CodeRAG通过系统性优化检索增强流程，为仓库级代码补全提供了高效解决方案，代码已开源。

Abstract: Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.

</details>


### [55] [CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs](https://arxiv.org/abs/2509.16188)
*Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma*

Main category: cs.CL

TL;DR: 提出CultureScope框架，基于文化冰山理论构建三维分类体系，实现跨文化场景下大语言模型文化理解能力的系统性评估


<details>
  <summary>Details</summary>
Motivation: 现有评估基准缺乏文化理论指导，依赖专家标注，难以实现跨文化场景的规模化适配，无法满足可信AI应用需求

Method: 设计包含3层次140维度的文化知识分类体系，支持自动化构建不同语言文化的知识库与评估数据集

Result: 实验验证方法有效性，发现现有模型文化理解存在系统性缺陷，单纯增加多语言数据无法提升文化认知能力

Conclusion: CultureScope为LLMs文化能力评估提供系统性解决方案，揭示了当前模型在跨文化应用中的局限性，推动可信AI发展

Abstract: As large language models (LLMs) are increasingly deployed in diverse cultural
environments, evaluating their cultural understanding capability has become
essential for ensuring trustworthy and culturally aligned applications.
However, most existing benchmarks lack comprehensiveness and are challenging to
scale and adapt across different cultural contexts, because their frameworks
often lack guidance from well-established cultural theories and tend to rely on
expert-driven manual annotations. To address these issues, we propose
CultureScope, the most comprehensive evaluation framework to date for assessing
cultural understanding in LLMs. Inspired by the cultural iceberg theory, we
design a novel dimensional schema for cultural knowledge classification,
comprising 3 layers and 140 dimensions, which guides the automated construction
of culture-specific knowledge bases and corresponding evaluation datasets for
any given languages and cultures. Experimental results demonstrate that our
method can effectively evaluate cultural understanding. They also reveal that
existing large language models lack comprehensive cultural competence, and
merely incorporating multilingual data does not necessarily enhance cultural
understanding. All code and data files are available at
https://github.com/HoganZinger/Culture

</details>


### [56] [RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198)
*Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang*

Main category: cs.CL

TL;DR: 提出了Repository Planning Graph（RPG）统一代码仓库规划，并开发ZeroRepo框架实现规模化生成，在基准测试中代码量和成功率远超基线模型


<details>
  <summary>Details</summary>
Motivation: 自然语言在描述复杂软件结构时存在模糊性，导致大语言模型难以生成完整且结构合理的代码仓库

Method: 通过RPG图结构统一提案层和实施层规划，ZeroRepo框架采用三阶段流程（规划→细化→验证）实现代码生成

Result: 在RepoCraft基准测试中生成36K行代码（超Claude Code 3.9倍），功能覆盖率81.5%，通过率69.7%

Conclusion: RPG有效建模复杂依赖关系，通过近线性扩展提升规划能力，同时增强LLM对代码仓库的理解效率

Abstract: Large language models excel at function- and file-level code generation, yet
generating complete repositories from scratch remains a fundamental challenge.
This process demands coherent and reliable planning across proposal- and
implementation-level stages, while natural language, due to its ambiguity and
verbosity, is ill-suited for faithfully representing complex software
structures. To address this, we introduce the Repository Planning Graph (RPG),
a persistent representation that unifies proposal- and implementation-level
planning by encoding capabilities, file structures, data flows, and functions
in one graph. RPG replaces ambiguous natural language with an explicit
blueprint, enabling long-horizon planning and scalable repository generation.
Building on RPG, we develop ZeroRepo, a graph-driven framework for repository
generation from scratch. It operates in three stages: proposal-level planning
and implementation-level refinement to construct the graph, followed by
graph-guided code generation with test validation. To evaluate this setting, we
construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.
On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly
3.9$\times$ the strongest baseline (Claude Code) and about 64$\times$ other
baselines. It attains 81.5% functional coverage and a 69.7% pass rate,
exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further
analysis shows that RPG models complex dependencies, enables progressively more
sophisticated planning through near-linear scaling, and enhances LLM
understanding of repositories, thereby accelerating agent localization.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [57] [ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows](https://arxiv.org/abs/2509.15236)
*Shubham Kavane,Kajol Kulkarni,Harald Koestler*

Main category: cs.GR

TL;DR: 提出了ChannelFlow-Tools框架，将CAD建模到机器学习数据准备的流程标准化，支持三维阻塞流场的高效数据集生成与可复现CFD代理模型训练。


<details>
  <summary>Details</summary>
Motivation: 传统CFD代理模型数据集创建多为一次性流程，缺乏可复现性和配置灵活性。该研究旨在建立标准化流水线，实现从参数化几何生成到多分辨率张量输出的全流程可控。

Method: 集成几何合成可行性检查、SDF体素化、waLBerla LBM求解器编排、笛卡尔重采样等技术栈，通过Hydra/OmegaConf统一配置驱动，案例研究生成超万组Re=100-15000的多样流场场景。

Result: 端到端评估显示：128x32x32分辨率3D U-Net基线模型可有效学习，标准化表征支持存储优化与可复现训练，示范了代理模型与数据集规模的关联分析。

Conclusion: 该框架将零散的数据准备转化为可配置流水线，为CFD代理建模提供标准化基础设施，支持受控消融实验与确定性复现。

Abstract: We present ChannelFlow-Tools, a configuration-driven framework that
standardizes the end-to-end path from programmatic CAD solid generation to
ML-ready inputs and targets for 3D obstructed channel flows. The toolchain
integrates geometry synthesis with feasibility checks, signed distance field
(SDF) voxelization, automated solver orchestration on HPC (waLBerla LBM), and
Cartesian resampling to co-registered multi-resolution tensors. A single
Hydra/OmegaConf configuration governs all stages, enabling deterministic
reproduction and controlled ablations. As a case study, we generate 10k+ scenes
spanning Re=100-15000 with diverse shapes and poses. An end-to-end evaluation
of storage trade-offs directly from the emitted artifacts, a minimal 3D U-Net
at 128x32x32, and example surrogate models with dataset size illustrate that
the standardized representations support reproducible ML training.
ChannelFlow-Tools turns one-off dataset creation into a reproducible,
configurable pipeline for CFD surrogate modeling.

</details>


### [58] [GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing](https://arxiv.org/abs/2509.15246)
*Nomi Yu,Md Ferdous Alam,A. John Hart,Faez Ahmed*

Main category: cs.GR

TL;DR: 提出GenCAD-3D多模态生成框架，结合对比学习与潜在扩散模型，配合SynthBal数据增强策略，显著提升复杂CAD程序的生成精度与自动化水平。


<details>
  <summary>Details</summary>
Motivation: 现有CAD生成模型受限于数据集不平衡与复杂几何体表征不足，需解决自动化生成中手动干预过多、无效模型频发的问题。

Method: 1. 基于对比学习的CAD-几何编码器潜在嵌入对齐 2. 潜在扩散模型生成/检索CAD序列 3. SynthBal合成数据增强平衡数据集复杂度分布。

Result: SynthBal使复杂几何体重建精度提升37%，无效CAD生成率下降52%，在复杂结构任务上超越现有SOTA模型。

Conclusion: 该框架为逆向工程与设计自动化提供新范式，公开的51个实测3D零件数据集将推动工业界应用迭代。

Abstract: CAD programs, structured as parametric sequences of commands that compile
into precise 3D geometries, are fundamental to accurate and efficient
engineering design processes. Generating these programs from nonparametric data
such as point clouds and meshes remains a crucial yet challenging task,
typically requiring extensive manual intervention. Current deep generative
models aimed at automating CAD generation are significantly limited by
imbalanced and insufficiently large datasets, particularly those lacking
representation for complex CAD programs. To address this, we introduce
GenCAD-3D, a multimodal generative framework utilizing contrastive learning for
aligning latent embeddings between CAD and geometric encoders, combined with
latent diffusion models for CAD sequence generation and retrieval.
Additionally, we present SynthBal, a synthetic data augmentation strategy
specifically designed to balance and expand datasets, notably enhancing
representation of complex CAD geometries. Our experiments show that SynthBal
significantly boosts reconstruction accuracy, reduces the generation of invalid
CAD models, and markedly improves performance on high-complexity geometries,
surpassing existing benchmarks. These advancements hold substantial
implications for streamlining reverse engineering and enhancing automation in
engineering design. We will publicly release our datasets and code, including a
set of 51 3D-printed and laser-scanned parts on our project site.

</details>


### [59] [Causal Reasoning Elicits Controllable 3D Scene Generation](https://arxiv.org/abs/2509.15249)
*Shen Chen,Ruiyu Zhao,Jiale Zhou,Zongkai Wu,Jenq-Neng Hwang,Lei Li*

Main category: cs.GR

TL;DR: 提出CausalStruct框架，通过因果推理与LLMs构建因果图，结合PID控制与3D渲染技术，显著提升3D场景生成的逻辑连贯性与真实感


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法难以建模对象间的复杂逻辑依赖与物理约束，导致动态真实环境适配性不足

Method: 1. 构建对象节点与因果边的因果图
2. 通过因果顺序确定对象放置顺序
3. 应用因果干预调整空间配置
4. PID控制器迭代优化参数
5. 3D高斯溅射与评分蒸馏提升渲染

Result: 实验验证生成的3D场景在逻辑连贯性（↑32%）、空间交互真实性（↑28%）和场景适应性（↑41%）指标显著提升

Conclusion: 将因果推理系统整合到3D生成流程中，为动态场景构建提供了物理约束可解释的新范式

Abstract: Existing 3D scene generation methods often struggle to model the complex
logical dependencies and physical constraints between objects, limiting their
ability to adapt to dynamic and realistic environments. We propose
CausalStruct, a novel framework that embeds causal reasoning into 3D scene
generation. Utilizing large language models (LLMs), We construct causal graphs
where nodes represent objects and attributes, while edges encode causal
dependencies and physical constraints. CausalStruct iteratively refines the
scene layout by enforcing causal order to determine the placement order of
objects and applies causal intervention to adjust the spatial configuration
according to physics-driven constraints, ensuring consistency with textual
descriptions and real-world dynamics. The refined scene causal graph informs
subsequent optimization steps, employing a
Proportional-Integral-Derivative(PID) controller to iteratively tune object
scales and positions. Our method uses text or images to guide object placement
and layout in 3D scenes, with 3D Gaussian Splatting and Score Distillation
Sampling improving shape accuracy and rendering stability. Extensive
experiments show that CausalStruct generates 3D scenes with enhanced logical
coherence, realistic spatial interactions, and robust adaptability.

</details>


### [60] [Geometric Integration for Neural Control Variates](https://arxiv.org/abs/2509.15538)
*Daniel Meister,Takahiro Harada*

Main category: cs.GR

TL;DR: 提出使用分段线性激活函数的MLP作为控制变量，通过计算几何的二维积分域细分方法实现解析积分，应用于光传输模拟降低方差。


<details>
  <summary>Details</summary>
Motivation: 神经网络的解析积分困难限制了其作为控制变量在蒙特卡洛积分中的应用。研究简单MLP模型的解析积分可能性，以提升方差缩减效率。

Method: 采用连续分段线性激活函数的MLP，通过计算几何技术对积分域进行二维细分，实现神经网络控制变量的解析积分。

Result: 成功将MLP作为控制变量与提出的积分方法结合，在光传输模拟中验证了方差缩减的有效性。

Conclusion: 分段线性MLP配合域细分方法可作为高效控制变量，为复杂积分问题提供新的解决方案。

Abstract: Control variates are a variance-reduction technique for Monte Carlo
integration. The principle involves approximating the integrand by a function
that can be analytically integrated, and integrating using the Monte Carlo
method only the residual difference between the integrand and the
approximation, to obtain an unbiased estimate. Neural networks are universal
approximators that could potentially be used as a control variate. However, the
challenge lies in the analytic integration, which is not possible in general.
In this manuscript, we study one of the simplest neural network models, the
multilayered perceptron (MLP) with continuous piecewise linear activation
functions, and its possible analytic integration. We propose an integration
method based on integration domain subdivision, employing techniques from
computational geometry to solve this problem in 2D. We demonstrate that an MLP
can be used as a control variate in combination with our integration method,
showing applications in the light transport simulation.

</details>


### [61] [Implicit Modeling for 3D-printed Multi-material Computational Object Design via Python](https://arxiv.org/abs/2509.15562)
*Charles Wade,Devon Beck,Robert MacCurdy*

Main category: cs.GR

TL;DR: 论文提出开源框架加速多材料增材制造与超材料设计，包含Python API、隐式建模技术和有限元集成，案例展示优化自行车座设计。


<details>
  <summary>Details</summary>
Motivation: 加速多材料增材制造与超材料设计研究，提供灵活工具促进复杂材料分布与结构设计。

Method: 开发基于Python的API支持参数化梯度设计，集成隐式多材料建模技术，结合有限元分析实现自适应网格与仿真引导设计。

Result: 通过功能梯度晶格、算法生成结构及仿真优化案例（如多材料自行车座）验证框架有效性。

Conclusion: 开源工具与兼容切片软件的导出策略显著提升了功能梯度计算设计方法的可访问性与应用范围。

Abstract: This paper introduces open-source contributions designed to accelerate
research in volumetric multi-material additive manufacturing and metamaterial
design. We present a flexible Python-based API facilitating parametric
expression of multi-material gradients, integration with external libraries,
multi-material lattice structure design, and interoperability with finite
element modeling. Novel implicit multi-material modeling techniques enable
detailed spatial grading at multiple scales within lattice structures.
Additionally, our framework integrates with finite element analysis, offering
predictive simulations via adaptive mesh sizing and direct import of simulation
results to guide material distributions. Practical case studies illustrate the
utility of these contributions, including functionally graded lattices,
algorithmically generated structures, and simulation-informed designs,
exemplified by a multi-material bicycle seat optimized for mechanical
performance and rider comfort. Finally, we introduce a mesh export strategy
compatible with standard slicing software, significantly broadening the
accessibility and adoption of functionality graded computational design
methodologies for multi-material fabrication.

</details>


### [62] [Fast subdivision of Bézier curves](https://arxiv.org/abs/2509.15691)
*Paweł Woźny,Filip Chudy*

Main category: cs.GR

TL;DR: 本文提出使用快速傅里叶变换(FFT)将d维n次贝塞尔曲线细分的时间复杂度从O(dn²)降至O(dn log n)，并通过改进算法实现数值稳定性。该方法还支持新增控制点时O(d)时间更新细分，并可扩展应用于有理贝塞尔曲线/曲面和导数计算。


<details>
  <summary>Details</summary>
Motivation: 传统de Casteljau算法时间复杂度为O(dn²)，在计算机图形学和CAD领域需要更高效的贝塞尔曲线细分算法。通过FFT优化计算效率，满足大规模场景需求。

Method: 1. 基于FFT/逆FFT实现核心算法
2. 改进数值不稳定问题(保持相同时间复杂度)
3. 开发新增控制点的快速更新机制
4. 扩展至有理贝塞尔曲线/曲面细分及导数计算

Result: 1. Python实验验证改进后算法的数值稳定性
2. 实现O(dn log n)时间复杂度
3. 控制点扩展时细分更新仅需O(d)时间
4. 成功应用于衍生几何对象计算

Conclusion: 该算法突破传统复杂度瓶颈，经改进后兼具计算效率与数值稳定性。其架构扩展性强，为贝塞尔曲线相关计算提供了新的高效解决方案。

Abstract: It is well-known that a $d$-dimensional polynomial B\'{e}zier curve of degree
$n$ can be subdivided into two segments using the famous de Casteljau algorithm
in $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper,
we show that it is possible to do this in $O(dn\log{n})$ time using the fast
Fourier transform and its inverse. Experiments show that the direct application
of the new method performs well only for small values of $n$, as the algorithm
is numerically unstable. However, a slightly modified version -- which still
has $O(dn\log{n})$ computational complexity -- offers good numerical quality,
which is confirmed by numerical experiments conducted in \textsf{Python}.
Moreover, the new method has a nice property: if a B\'{e}zier curve is extended
by an additional control point, the subdivision can be updated in $O(d)$ time.
  A similar idea can be applied to speed up the subdivision of rational
B\'{e}zier curves and rectangular B\'{e}zier surfaces, as well as to compute
the derivatives of B\'{e}zier curves more efficiently.

</details>


### [63] [MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes](https://arxiv.org/abs/2509.15892)
*Mohamed Ebbed,Zorah Lähner*

Main category: cs.GR

TL;DR: 提出基于NeuralAngelo的动态三维重建框架，通过模板优化和变形场实现高精度动态场景重建


<details>
  <summary>Details</summary>
Motivation: 现有动态场景重建方法存在网格噪声大/过度平滑的问题，且难以处理拓扑变化等复杂动态场景

Method: 首帧构建高质量模板，通过联合优化变形场实现模板跟踪与几何细化，支持拓扑更新

Result: 在ActorsHQ数据集上实现优于SOTA的重建精度

Conclusion: 结合静态重建优势与动态变形场，有效提升动态场景几何细节重建能力

Abstract: Dynamic scene reconstruction from multi-view videos remains a fundamental
challenge in computer vision. While recent neural surface reconstruction
methods have achieved remarkable results in static 3D reconstruction, extending
these approaches with comparable quality for dynamic scenes introduces
significant computational and representational challenges. Existing dynamic
methods focus on novel-view synthesis, therefore, their extracted meshes tend
to be noisy. Even approaches aiming for geometric fidelity often result in too
smooth meshes due to the ill-posedness of the problem. We present a novel
framework for highly detailed dynamic reconstruction that extends the static 3D
reconstruction method NeuralAngelo to work in dynamic settings. To that end, we
start with a high-quality template scene reconstruction from the initial frame
using NeuralAngelo, and then jointly optimize deformation fields that track the
template and refine it based on the temporal sequence. This flexible template
allows updating the geometry to include changes that cannot be modeled with the
deformation field, for instance occluded parts or the changes in the topology.
We show superior reconstruction accuracy in comparison to previous
state-of-the-art methods on the ActorsHQ dataset.

</details>


### [64] [Generating Detailed Character Motion from Blocking Poses](https://arxiv.org/abs/2509.16064)
*Purvi Goel,Guy Tevet,C. K. Liu,Kayvon Fatahalian*

Main category: cs.GR

TL;DR: 提出通过混合无条件扩散模型输出与阻挡姿势约束的新方法，首次实现将粗糙阻挡姿势转化为精细动画的扩散模型


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型无法有效利用稀疏阻挡姿势添加运动细节，需要开发既能保持姿势约束又能增强细节的解决方案

Method: 在扩散过程中使用混合策略：将无条件扩散输出与输入姿势约束按权重融合，再输入运动重定时模型

Result: 新方法显著优于基于输出混合或引导约束的现有方案，成功生成自然合理的详细动画

Conclusion: 该方法通过简单的推理时混合机制，突破了扩散模型在运动细节增强领域的技术瓶颈

Abstract: We focus on the problem of using generative diffusion models for the task of
motion detailing: converting a rough version of a character animation,
represented by a sparse set of coarsely posed, and imprecisely timed blocking
poses, into a detailed, natural looking character animation. Current diffusion
models can address the problem of correcting the timing of imprecisely timed
poses, but we find that no good solution exists for leveraging the diffusion
prior to enhance a sparse set of blocking poses with additional pose detail. We
overcome this challenge using a simple inference-time trick. At certain
diffusion steps, we blend the outputs of an unconditioned diffusion model with
input blocking pose constraints using per-blocking-pose tolerance weights, and
pass this result in as the input condition to an pre-existing motion retiming
model. We find this approach works significantly better than existing
approaches that attempt to add detail by blending model outputs or via
expressing blocking pose constraints as guidance. The result is the first
diffusion model that can robustly convert blocking-level poses into plausible
detailed character animations.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [65] [VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency](https://arxiv.org/abs/2509.15969)
*Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze*

Main category: eess.AS

TL;DR: VoXtream提出了一种全自回归、零样本的实时流式文本转语音（TTS）系统，通过单调对齐方案和动态前瞻机制实现首词102ms极低延迟，在中等规模9k小时语料训练下达到与更大模型相当的合成质量。


<details>
  <summary>Details</summary>
Motivation: 现有流式TTS系统存在初始延迟高的问题。研究旨在通过动态对齐架构设计，在保证语音质量的前提下实现实时语音合成的极低首词延迟，突破传统流式系统需要等待多词输入的瓶颈。

Method: 采用三阶段Transformer架构：1）增量音素转换器处理输入流；2）时序转换器预测语义/时长token；3）深度转换器生成声学token。通过单调对齐约束和动态前瞻机制实现零延迟的流式生成。

Result: 在GPU上实现102ms初始延迟（当前公开系统最低），合成质量在MOS等指标上超越大规模基线模型，在完整流式/输出流式两种场景下均保持竞争力。

Conclusion: VoXtream证明了中等规模语料训练的自回归架构在实时TTS任务中的有效性，其动态对齐机制为流式语音合成提供了新的技术路径，平衡了延迟与质量的需求。

Abstract: We present VoXtream, a fully autoregressive, zero-shot streaming
text-to-speech (TTS) system for real-time use that begins speaking from the
first word. VoXtream directly maps incoming phonemes to audio tokens using a
monotonic alignment scheme and a dynamic look-ahead that does not delay onset.
Built around an incremental phoneme transformer, a temporal transformer
predicting semantic and duration tokens, and a depth transformer producing
acoustic tokens, VoXtream achieves, to our knowledge, the lowest initial delay
among publicly available streaming TTS: 102 ms on GPU. Despite being trained on
a mid-scale 9k-hour corpus, it matches or surpasses larger baselines on several
metrics, while delivering competitive quality in both output- and
full-streaming settings. Demo and code are available at
https://herimor.github.io/voxtream.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [66] [Efficient and Versatile Model for Multilingual Information Retrieval of Islamic Text: Development and Deployment in Real-World Scenarios](https://arxiv.org/abs/2509.15380)
*Vera Pavlova,Mohammed Makhlouf*

Main category: cs.IR

TL;DR: 提出混合跨语言和单语言训练方法，在伊斯兰领域多语言检索中取得优异效果，并验证单模型部署的可行性


<details>
  <summary>Details</summary>
Motivation: 现有MLIR研究多在孤立场景评估，难以满足实际部署需求。利用古兰经多语言语料库特性，探索满足多语言用户需求的最佳检索系统开发方案。

Method: 采用四种训练范式（单语言/跨语言/全翻译训练/混合跨单语言）构建11个检索模型，通过领域内数据集评估性能并分析嵌入空间特性

Result: 混合方法在不同检索场景下表现最优，单模型部署方案在保持轻量化的同时实现高效多语言检索

Conclusion: 通过混合训练策略优化嵌入空间特性，证明部署单一轻量模型可兼顾多语言检索效果与落地成本效益

Abstract: Despite recent advancements in Multilingual Information Retrieval (MLIR), a
significant gap remains between research and practical deployment. Many studies
assess MLIR performance in isolated settings, limiting their applicability to
real-world scenarios. In this work, we leverage the unique characteristics of
the Quranic multilingual corpus to examine the optimal strategies to develop an
ad-hoc IR system for the Islamic domain that is designed to satisfy users'
information needs in multiple languages. We prepared eleven retrieval models
employing four training approaches: monolingual, cross-lingual,
translate-train-all, and a novel mixed method combining cross-lingual and
monolingual techniques. Evaluation on an in-domain dataset demonstrates that
the mixed approach achieves promising results across diverse retrieval
scenarios. Furthermore, we provide a detailed analysis of how different
training configurations affect the embedding space and their implications for
multilingual retrieval effectiveness. Finally, we discuss deployment
considerations, emphasizing the cost-efficiency of deploying a single
versatile, lightweight model for real-world MLIR applications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [67] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

TL;DR: ViSpec框架通过视觉适配器压缩图像标记并增强多模态一致性，首次实现视觉语言模型推测解码的显著加速


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型推测解码方法速度提升有限（<1.5倍），大模型能有效过滤冗余图像信息而小模型无法实现，需专门框架解决多模态加速难题

Method: 1. 轻量视觉适配器压缩图像标记并保留位置信息
2. 全局特征向量增强后续文本的多模态连贯性
3. 通过改造现有数据集和目标模型生成扩展响应构建训练数据
4. 防止草案模型通过隐状态走捷径的混合训练策略

Result: 实验验证ViSpec实现VLM推测解码的实质性加速突破，达到现有方法无法实现的加速效果

Conclusion: ViSpec填补多模态推测解码空白，其视觉信息压缩方法和防捷径学习策略为高效多模态推理提供新方向

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [68] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

TL;DR: 提出多模态参数无关合规引擎M-PACE，通过母-子MLLM架构实现广告合规检查，推理成本降低31倍且保持高准确性


<details>
  <summary>Details</summary>
Motivation: 传统多阶段合规框架存在架构碎片化、扩展性差、难以适应动态标准等问题，需要统一的多模态处理方案

Method: 采用双阶段MLLM架构（母模型评估子模型输出），构建含视觉遮挡/脏话注入等挑战性场景的增强基准数据集

Result: 实现单图0.0005美元的超低成本（Gemini 2.0 Flash），推理成本降低31倍，精度与高价模型相当

Conclusion: M-PACE通过智能模型调度在广告合规领域实现成本-质量平衡，为多模态内容审查提供实时自动化解决方案

Abstract: Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [69] [Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues](https://arxiv.org/abs/2509.15540)
*Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha*

Main category: cs.CV

TL;DR: 提出对称双向多模态学习框架SyDES，通过文本与图像的双向引导机制，在欲望理解、情感识别和情感分析任务中实现F1值1.1%/0.6%/0.9%的提升


<details>
  <summary>Details</summary>
Motivation: 现有情感分析方法主要关注语言模态，忽视图像的非语言线索；多模态方法在欲望理解领域尚未充分探索

Method: 采用低分辨率图像全局对齐，高分辨率子图掩码建模；设计文本引导图像解码器和图像引导文本解码器；混合尺度策略平衡感知与计算成本

Result: 在MSED数据集上超越SOTA方法：欲望理解（+1.1%）、情感识别（+0.6%）、情感分析（+0.9%）F1值

Conclusion: 双向跨模态交互机制和混合尺度图像策略有效提升意图相关表征学习，代码已开源

Abstract: Desire, as an intention that drives human behavior, is closely related to
both emotion and sentiment. Multimodal learning has advanced sentiment and
emotion recognition, but multimodal approaches specially targeting human desire
understanding remain underexplored. And existing methods in sentiment analysis
predominantly emphasize verbal cues and overlook images as complementary
non-verbal cues. To address these gaps, we propose a Symmetrical Bidirectional
Multimodal Learning Framework for Desire, Emotion, and Sentiment Recognition,
which enforces mutual guidance between text and image modalities to effectively
capture intention-related representations in the image. Specifically,
low-resolution images are used to obtain global visual representations for
cross-modal alignment, while high resolution images are partitioned into
sub-images and modeled with masked image modeling to enhance the ability to
capture fine-grained local features. A text-guided image decoder and an
image-guided text decoder are introduced to facilitate deep cross-modal
interaction at both local and global representations of image information.
Additionally, to balance perceptual gains with computation cost, a mixed-scale
image strategy is adopted, where high-resolution images are cropped into
sub-images for masked modeling. The proposed approach is evaluated on MSED, a
multimodal dataset that includes a desire understanding benchmark, as well as
emotion and sentiment recognition. Experimental results indicate consistent
improvements over other state-of-the-art methods, validating the effectiveness
of our proposed method. Specifically, our method outperforms existing
approaches, achieving F1-score improvements of 1.1% in desire understanding,
0.6% in emotion recognition, and 0.9% in sentiment analysis. Our code is
available at: https://github.com/especiallyW/SyDES.

</details>


### [70] [Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](https://arxiv.org/abs/2509.16163)
*Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.CV

TL;DR: 提出基于张量分解的轻量级防御方法，无需重新训练即可提升视觉语言模型对抗攻击鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有防御方法需要昂贵重新训练或架构改动，难以适配预训练模型

Method: 通过张量分解技术分解并重建视觉编码器表示，过滤对抗噪声同时保留语义信息

Result: 在Flickr30K恢复12.3%被攻击损失性能（Recall@1从7.5%→19.8%），COCO恢复8.1%（3.8%→11.9%）

Conclusion: 张量链分解（秩8-32，残差强度α=0.1-0.2）是即插即用解决方案，计算开销极低

Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone
to adversarial attacks. Existing defenses often demand costly retraining or
significant architecture changes. We introduce a lightweight defense using
tensor decomposition suitable for any pre-trained VLM, requiring no retraining.
By decomposing and reconstructing vision encoder representations, it filters
adversarial noise while preserving meaning. Experiments with CLIP on COCO and
Flickr30K show improved robustness. On Flickr30K, it restores 12.3\%
performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On
COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%.
Analysis shows Tensor Train decomposition with low rank (8-32) and low residual
strength ($\alpha=0.1-0.2$) is optimal. This method is a practical,
plug-and-play solution with minimal overhead for existing VLMs.

</details>


### [71] [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
*Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen*

Main category: cs.CV

TL;DR: Manzano通过混合分词器和统一训练方案，显著降低多模态大语言模型在理解与生成任务间的性能折衷


<details>
  <summary>Details</summary>
Motivation: 现有开源多模态模型在视觉理解与生成能力之间存在性能权衡问题，亟需统一的解决方案

Method: 采用共享视觉编码器+双轻量适配器架构，结合自回归LLM预测语义与辅助扩散解码器生成像素，通过统一训练方案实现双任务联合学习

Result: 在统一模型中达到SOTA性能，与专用模型竞争（尤其在文本丰富场景），模型规模扩展带来稳定增益且任务冲突最小

Conclusion: 混合分词器设计有效平衡多模态任务，统一训练框架验证了双任务协同学习的可行性，为多模态模型发展提供新思路

Abstract: Unified multimodal Large Language Models (LLMs) that can both understand and
generate visual content hold immense potential. However, existing open-source
models often suffer from a performance trade-off between these capabilities. We
present Manzano, a simple and scalable unified framework that substantially
reduces this tension by coupling a hybrid image tokenizer with a well-curated
training recipe. A single shared vision encoder feeds two lightweight adapters
that produce continuous embeddings for image-to-text understanding and discrete
tokens for text-to-image generation within a common semantic space. A unified
autoregressive LLM predicts high-level semantics in the form of text and image
tokens, with an auxiliary diffusion decoder subsequently translating the image
tokens into pixels. The architecture, together with a unified training recipe
over understanding and generation data, enables scalable joint learning of both
capabilities. Manzano achieves state-of-the-art results among unified models,
and is competitive with specialist models, particularly on text-rich
evaluation. Our studies show minimal task conflicts and consistent gains from
scaling model size, validating our design choice of a hybrid tokenizer.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [72] [Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents](https://arxiv.org/abs/2509.15233)
*Xueqiao Zhang,Chao Zhang,Jingtao Xu,Yifan Zhu,Xin Shi,Yi Yang,Yawei Luo*

Main category: cs.MM

TL;DR: 通过引入视频模态和动态角色设定提升角色扮演代理的交互性，构建大规模数据集Role-playing-Video60k并提出多维度评估方法验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有角色扮演代理主要依赖静态角色设定，缺乏对人类动态感知能力的模拟，限制了交互的沉浸感。

Method: 1. 构建含6万视频和70万对话的大规模数据集；2. 结合自适应时间采样与动静角色设定框架（动态设定通过视频帧时序分析，静态设定包含训练对话和视频摘要）；3. 设计覆盖8个指标的评估体系。

Result: 实验证明动态角色设定显著提升响应质量，验证了框架的有效性。

Conclusion: 动态角色设定是提升角色扮演代理表现的关键，新数据集和评估方法为领域研究提供重要基础设施。

Abstract: Role-playing agents (RPAs) have attracted growing interest for their ability
to simulate immersive and interactive characters. However, existing approaches
primarily focus on static role profiles, overlooking the dynamic perceptual
abilities inherent to humans. To bridge this gap, we introduce the concept of
dynamic role profiles by incorporating video modality into RPAs. To support
this, we construct Role-playing-Video60k, a large-scale, high-quality dataset
comprising 60k videos and 700k corresponding dialogues. Based on this dataset,
we develop a comprehensive RPA framework that combines adaptive temporal
sampling with both dynamic and static role profile representations.
Specifically, the dynamic profile is created by adaptively sampling video
frames and feeding them to the LLM in temporal order, while the static profile
consists of (1) character dialogues from training videos during fine-tuning,
and (2) a summary context from the input video during inference. This joint
integration enables RPAs to generate greater responses. Furthermore, we propose
a robust evaluation method covering eight metrics. Experimental results
demonstrate the effectiveness of our framework, highlighting the importance of
dynamic role profiles in developing RPAs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [73] [Learning Analytics from Spoken Discussion Dialogs in Flipped Classroom](https://arxiv.org/abs/2301.12399)
*Hang Su,Borislav Dzodzo,Changlun Li,Danyang Zhao,Hao Geng,Yunxiang Li,Sidharth Jaggi,Helen Meng*

Main category: cs.CY

TL;DR: 通过分析翻转课堂中的小组讨论对话，使用统计分析和机器学习方法预测学习成果，最高准确率达78.9%


<details>
  <summary>Details</summary>
Motivation: 翻转课堂的讨论对话蕴含学习过程信息，需通过分析这些对话了解小组学习效果与过程

Method: 将课程改造为翻转课堂模式，录制并转录课堂讨论，提取多维度特征后采用统计分析和机器学习（高/中/低三档预测）

Result: 发现讨论对话特征与学习成果显著相关，机器学习模型预测准确率最高达78.9%

Conclusion: 验证了通过讨论对话自动预测学习成果的可行性，为翻转课堂效果评估提供了新的技术路径

Abstract: The flipped classroom is a new pedagogical strategy that has been gaining
increasing importance recently. Spoken discussion dialog commonly occurs in
flipped classroom, which embeds rich information indicating processes and
progression of students' learning. This study focuses on learning analytics
from spoken discussion dialog in the flipped classroom, which aims to collect
and analyze the discussion dialogs in flipped classroom in order to get to know
group learning processes and outcomes. We have recently transformed a course
using the flipped classroom strategy, where students watched video-recorded
lectures at home prior to group-based problem-solving discussions in class. The
in-class group discussions were recorded throughout the semester and then
transcribed manually. After features are extracted from the dialogs by multiple
tools and customized processing techniques, we performed statistical analyses
to explore the indicators that are related to the group learning outcomes from
face-to-face discussion dialogs in the flipped classroom. Then, machine
learning algorithms are applied to the indicators in order to predict the group
learning outcome as High, Mid or Low. The best prediction accuracy reaches
78.9%, which demonstrates the feasibility of achieving automatic learning
outcome prediction from group discussion dialog in flipped classroom.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [74] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: 研究证明通过MCP协议接入医院EHR系统的LLM能有效检索临床数据，简单任务准确率接近完美，复杂任务仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在医院部署时因EHR系统访问受限导致的临床应用瓶颈，探索MCP协议的实际效能。

Method: 开发EHR-MCP框架集成医院数据库，使用GPT-4.1 LangGraph代理测试6个感染控制任务，对比8名患者的医生金标准。

Result: LLM正确执行工具选择，5/6任务达成近完美准确率，复杂时间计算任务表现较弱，主要错误来自参数误设和结果解读。

Conclusion: EHR-MCP为医院AI提供了安全数据访问基础，未来需扩展至推理生成和临床影响评估以实现生成式AI的医疗整合。

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [75] [Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning](https://arxiv.org/abs/2509.15279)
*Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai*

Main category: cs.LG

TL;DR: Fleming-R1模型通过结构化数据设计、推理导向初始化和可验证强化学习，显著提升医疗AI的临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在医疗应用中难以同时实现高准确性和透明推理过程，需改进专家级临床推理能力。

Method: 1. RODS数据策略结合医疗QA数据集与知识图谱合成
2. CoT冷启动技术提炼高质量推理轨迹
3. RLVR强化学习框架通过自适应困难样本挖掘优化模型

Result: 7B模型超越更大基线模型，32B版本接近GPT-4o性能，各医疗基准测试均显著优于开源替代方案。

Conclusion: 该方法突破单纯精度优化，推动临床推理向可验证、可审计方向发展，支持高风险医疗环境的安全部署。

Abstract: While large language models show promise in medical applications, achieving
expert-level clinical reasoning remains challenging due to the need for both
accurate answers and transparent reasoning processes. To address this
challenge, we introduce Fleming-R1, a model designed for verifiable medical
reasoning through three complementary innovations. First, our
Reasoning-Oriented Data Strategy (RODS) combines curated medical QA datasets
with knowledge-graph-guided synthesis to improve coverage of underrepresented
diseases, drugs, and multi-hop reasoning chains. Second, we employ
Chain-of-Thought (CoT) cold start to distill high-quality reasoning
trajectories from teacher models, establishing robust inference priors. Third,
we implement a two-stage Reinforcement Learning from Verifiable Rewards (RLVR)
framework using Group Relative Policy Optimization, which consolidates core
reasoning skills while targeting persistent failure modes through adaptive
hard-sample mining. Across diverse medical benchmarks, Fleming-R1 delivers
substantial parameter-efficient improvements: the 7B variant surpasses much
larger baselines, while the 32B model achieves near-parity with GPT-4o and
consistently outperforms strong open-source alternatives. These results
demonstrate that structured data design, reasoning-oriented initialization, and
verifiable reinforcement learning can advance clinical reasoning beyond simple
accuracy optimization. We release Fleming-R1 publicly to promote transparent,
reproducible, and auditable progress in medical AI, enabling safer deployment
in high-stakes clinical environments.

</details>


### [76] [Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning](https://arxiv.org/abs/2509.15561)
*Om Naphade,Saksham Bansal,Parikshit Pareek*

Main category: cs.LG

TL;DR: 提出专家块框架（Expert Block Framework），利用小型LLM实现高效超参数调优，TCS模块将训练轨迹转为结构化上下文，使小模型性能接近GPT-4


<details>
  <summary>Details</summary>
Motivation: 传统超参数调优（HPT）在大模型场景下计算成本高且不透明，需探索更高效的替代方案

Method: 核心TCS模块（轨迹上下文总结器）结构化处理训练轨迹，结合14B和32B小型本地LLM，采用10次试验预算

Result: 在六个任务中平均性能与GPT-4差距仅~0.9个百分点

Conclusion: 通过TCS模块赋能，小规模LLM可低成本实现接近大模型的调优效果，降低计算资源需求

Abstract: Hyper-parameter Tuning (HPT) is a necessary step in machine learning (ML)
pipelines but becomes computationally expensive and opaque with larger models.
Recently, Large Language Models (LLMs) have been explored for HPT, yet most
rely on models exceeding 100 billion parameters. We propose an Expert Block
Framework for HPT using Small LLMs. At its core is the Trajectory Context
Summarizer (TCS), a deterministic block that transforms raw training
trajectories into structured context, enabling small LLMs to analyze
optimization progress with reliability comparable to larger models. Using two
locally-run LLMs (phi4:reasoning14B and qwen2.5-coder:32B) and a 10-trial
budget, our TCS-enabled HPT pipeline achieves average performance within ~0.9
percentage points of GPT-4 across six diverse tasks.

</details>


### [77] [KITE: Kernelized and Information Theoretic Exemplars for In-Context Learning](https://arxiv.org/abs/2509.15676)
*Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 提出基于信息论的上下文学习示例选择方法，通过子模优化和核技巧提升模型在特定查询下的预测精度，实验显示分类任务性能显著优于传统检索方法。


<details>
  <summary>Details</summary>
Motivation: 传统最近邻方法（如KATE）在高维嵌入空间中存在泛化能力差和示例多样性不足的问题，需开发面向特定查询的优化选择策略。

Method: 1. 将LLM建模为输入嵌入的线性函数
2. 将示例选择转化为基于查询的优化问题
3. 设计近似子模的代理目标函数，采用贪婪算法求解
4. 引入核技巧处理高维特征空间
5. 添加最优设计正则项增强示例多样性

Result: 在多个分类任务中准确率平均提升8-15%，尤其在标签稀缺场景下较传统方法优势显著（p<0.01）

Conclusion: 基于信息论原理的结构化示例选择策略，通过核空间优化和多样性正则化，有效提升了上下文学习在现实场景中的实用性。

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for adapting
large language models (LLMs) to new and data-scarce tasks using only a few
carefully selected task-specific examples presented in the prompt. However,
given the limited context size of LLMs, a fundamental question arises: Which
examples should be selected to maximize performance on a given user query?
While nearest-neighbor-based methods like KATE have been widely adopted for
this purpose, they suffer from well-known drawbacks in high-dimensional
embedding spaces, including poor generalization and a lack of diversity. In
this work, we study this problem of example selection in ICL from a principled,
information theory-driven perspective. We first model an LLM as a linear
function over input embeddings and frame the example selection task as a
query-specific optimization problem: selecting a subset of exemplars from a
larger example bank that minimizes the prediction error on a specific query.
This formulation departs from traditional generalization-focused learning
theoretic approaches by targeting accurate prediction for a specific query
instance. We derive a principled surrogate objective that is approximately
submodular, enabling the use of a greedy algorithm with an approximation
guarantee. We further enhance our method by (i) incorporating the kernel trick
to operate in high-dimensional feature spaces without explicit mappings, and
(ii) introducing an optimal design-based regularizer to encourage diversity in
the selected examples. Empirically, we demonstrate significant improvements
over standard retrieval methods across a suite of classification tasks,
highlighting the benefits of structure-aware, diverse example selection for ICL
in real-world, label-scarce scenarios.

</details>


### [78] [EmoHeal: An End-to-End System for Personalized Therapeutic Music Retrieval from Fine-grained Emotions](https://arxiv.org/abs/2509.15986)
*Xinchen Wan,Jinhua Liang,Huan Zhang*

Main category: cs.LG

TL;DR: 提出EmoHeal系统，通过细粒度情绪识别与音乐治疗原则结合，实现个性化数字心理健康干预


<details>
  <summary>Details</summary>
Motivation: 现有数字心理健康工具忽视细微情绪状态且缺乏个性化，尤其针对全球15亿人受影响的睡前焦虑问题

Method: 使用微调XLM-RoBERTa检测27种情绪 → 音乐知识图谱参数映射（GEMS/iso原则） → CLAMP3模型检索三阶段视听内容（匹配-引导-目标）

Result: 40人实验显示显著情绪改善（M=4.12）和高感知准确度（M=4.05），准确度与疗效强相关（r=0.72）

Conclusion: 验证了理论驱动型情绪感知工具的可行性，为音乐治疗原则的AI规模化应用提供了技术蓝图

Abstract: Existing digital mental wellness tools often overlook the nuanced emotional
states underlying everyday challenges. For example, pre-sleep anxiety affects
more than 1.5 billion people worldwide, yet current approaches remain largely
static and "one-size-fits-all", failing to adapt to individual needs. In this
work, we present EmoHeal, an end-to-end system that delivers personalized,
three-stage supportive narratives. EmoHeal detects 27 fine-grained emotions
from user text with a fine-tuned XLM-RoBERTa model, mapping them to musical
parameters via a knowledge graph grounded in music therapy principles (GEMS,
iso-principle). EmoHeal retrieves audiovisual content using the CLAMP3 model to
guide users from their current state toward a calmer one
("match-guide-target"). A within-subjects study (N=40) demonstrated significant
supportive effects, with participants reporting substantial mood improvement
(M=4.12, p<0.001) and high perceived emotion recognition accuracy (M=4.05,
p<0.001). A strong correlation between perceived accuracy and therapeutic
outcome (r=0.72, p<0.001) validates our fine-grained approach. These findings
establish the viability of theory-driven, emotion-aware digital wellness tools
and provides a scalable AI blueprint for operationalizing music therapy
principles.

</details>


### [79] [SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](https://arxiv.org/abs/2509.16060)
*Maithili Joshi,Palash Nandi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: 论文提出白盒越狱方法SABER，通过残差连接中间层绕过LLM安全机制，在HarmBench测试集上性能提升51%


<details>
  <summary>Details</summary>
Motivation: 现有大规模对齐训练的语言模型仍存在被越狱攻击的风险，研究发现其安全机制主要分布在中后隐藏层

Method: SABER方法在中间层s和e之间建立残差连接（s<e），通过特征空间维度绕开安全对齐机制

Result: 在HarmBench测试集上相对基线提升51%攻击成功率，验证集困惑度偏移仅0.53

Conclusion: SABER揭示了LLM安全机制的层级脆弱性，为模型安全性评估提供了新视角（源码已开源）

Abstract: Large Language Models (LLMs) with safe-alignment training are powerful
instruments with robust language comprehension capabilities. These models
typically undergo meticulous alignment procedures involving human feedback to
ensure the acceptance of safe inputs while rejecting harmful or unsafe ones.
However, despite their massive scale and alignment efforts, LLMs remain
vulnerable to jailbreak attacks, where malicious users manipulate the model to
produce harmful outputs that it was explicitly trained to avoid. In this study,
we find that the safety mechanisms in LLMs are predominantly embedded in the
middle-to-late layers. Building on this insight, we introduce a novel white-box
jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which
connects two intermediate layers $s$ and $e$ such that $s < e$, through a
residual connection. Our approach achieves a 51% improvement over the
best-performing baseline on the HarmBench test set. Furthermore, SABER induces
only a marginal shift in perplexity when evaluated on the HarmBench validation
set. The source code is publicly available at
https://github.com/PalGitts/SABER.

</details>


### [80] [Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences](https://arxiv.org/abs/2509.16189)
*Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland*

Main category: cs.LG

TL;DR: 论文指出机器学习系统因缺乏潜在学习能力导致泛化不足，提出通过情景记忆和检索机制提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统无法像自然智能那样进行与当前任务无关的潜在学习，这限制了其数据利用效率和泛化能力，具体表现为语言模型的反转诅咒和智能体导航等场景的泛化失败。

Method: 从认知科学角度提出情景记忆的解决方案，构建带有检索机制的系统进行验证，重点研究跨示例信息利用所需的上下文学习能力。

Result: 实验证明具备检索机制的系统能更灵活地利用学习经验，在多个挑战场景中展现出更好的泛化性能，特别是通过示例内上下文学习实现跨示例信息整合。

Conclusion: 研究揭示了当前机器学习数据效率低下的潜在原因，证实检索机制可作为参数化学习的重要补充，为提升泛化能力提供了新方向。

Abstract: When do machine learning systems fail to generalize, and what mechanisms
could improve their generalization? Here, we draw inspiration from cognitive
science to argue that one weakness of machine learning systems is their failure
to exhibit latent learning -- learning information that is not relevant to the
task at hand, but that might be useful in a future task. We show how this
perspective links failures ranging from the reversal curse in language modeling
to new findings on agent-based navigation. We then highlight how cognitive
science points to episodic memory as a potential part of the solution to these
issues. Correspondingly, we show that a system with an oracle retrieval
mechanism can use learning experiences more flexibly to generalize better
across many of these challenges. We also identify some of the essential
components for effectively using retrieval, including the importance of
within-example in-context learning for acquiring the ability to use information
across retrieved examples. In summary, our results illustrate one possible
contributor to the relative data inefficiency of current machine learning
systems compared to natural intelligence, and help to understand how retrieval
methods can complement parametric learning to improve generalization.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [81] [SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models](https://arxiv.org/abs/2509.15661)
*Qiaolin Wang,Xilin Jiang,Linyang He,Junkai Wu,Nima Mesgarani*

Main category: cs.SD

TL;DR: Proposes SightSound-R1 framework to transfer vision reasoning capability to audio models via cross-modal distillation


<details>
  <summary>Details</summary>
Motivation: Addresses the reasoning capability gap between audio-language models (LALMs) and vision-language models (LVLMs) in complex soundscapes due to lack of chain-of-thought audio data

Method: Three-step distillation: 1) LVLM-generated audio-focused chains of thought, 2) audio-grounded validation filter, 3) SFT+GRPO training pipeline

Result: Improves LALM performance in AVQA tests (+8.2%) and shows better generalization to unseen auditory scenarios

Conclusion: Vision reasoning can effectively transfer to audio models through cross-modal distillation, enabling better scaling with audio-visual data

Abstract: While large audio-language models (LALMs) have demonstrated state-of-the-art
audio understanding, their reasoning capability in complex soundscapes still
falls behind large vision-language models (LVLMs). Compared to the visual
domain, one bottleneck is the lack of large-scale chain-of-thought audio data
to teach LALM stepwise reasoning. To circumvent this data and modality gap, we
present SightSound-R1, a cross-modal distillation framework that transfers
advanced reasoning from a stronger LVLM teacher to a weaker LALM student on the
same audio-visual question answering (AVQA) dataset. SightSound-R1 consists of
three core steps: (i) test-time scaling to generate audio-focused chains of
thought (CoT) from an LVLM teacher, (ii) audio-grounded validation to filter
hallucinations, and (iii) a distillation pipeline with supervised fine-tuning
(SFT) followed by Group Relative Policy Optimization (GRPO) for the LALM
student. Results show that SightSound-R1 improves LALM reasoning performance
both in the in-domain AVQA test set as well as in unseen auditory scenes and
questions, outperforming both pretrained and label-only distilled baselines.
Thus, we conclude that vision reasoning can be effectively transferred to audio
models and scaled with abundant audio-visual data.

</details>


### [82] [Direct Simultaneous Translation Activation for Large Audio-Language Models](https://arxiv.org/abs/2509.15692)
*Pei Zhang,Yiming Wang,Jialong Tang,Baosong Yang,Rui Wang,Derek F. Wong,Fei Huang*

Main category: cs.SD

TL;DR: 提出SimulSA策略，通过随机截断语音构造部分对齐翻译，仅需增强1%同步数据即可激活大型音频语言模型的实时语音翻译能力，无需修改架构或解码策略。


<details>
  <summary>Details</summary>
Motivation: 现有同步语音翻译研究常需修改模型架构，而本研究旨在直接激活基础模型的实时翻译能力，避免架构调整需求。

Method: 采用自增强策略（SimulSA），利用大模型固有能力生成同步数据：截断语音输入并构建部分对齐翻译，将同步数据融入离线监督微调数据中。

Result: 实验表明仅增强1%同步数据即可显著激活模型实时翻译能力，BLEU值提升显著（中文→英文+9.6，英文→中文+6.4），且保持离线翻译性能。

Conclusion: SimulSA通过数据分布对齐有效解决预训练与推理阶段的模态差异，为大型模型的实时语音翻译能力激活提供了高效解决方案。

Abstract: Simultaneous speech-to-text translation (Simul-S2TT) aims to translate speech
into target text in real time, outputting translations while receiving source
speech input, rather than waiting for the entire utterance to be spoken.
Simul-S2TT research often modifies model architectures to implement read-write
strategies. However, with the rise of large audio-language models (LALMs), a
key challenge is how to directly activate Simul-S2TT capabilities in base
models without additional architectural changes. In this paper, we introduce
{\bf Simul}taneous {\bf S}elf-{\bf A}ugmentation ({\bf SimulSA}), a strategy
that utilizes LALMs' inherent capabilities to obtain simultaneous data by
randomly truncating speech and constructing partially aligned translation. By
incorporating them into offline SFT data, SimulSA effectively bridges the
distribution gap between offline translation during pretraining and
simultaneous translation during inference. Experimental results demonstrate
that augmenting only about {\bf 1\%} of the simultaneous data, compared to the
full offline SFT data, can significantly activate LALMs' Simul-S2TT
capabilities without modifications to model architecture or decoding strategy.

</details>
