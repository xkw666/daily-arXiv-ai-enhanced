{"id": "2506.15183", "pdf": "https://arxiv.org/pdf/2506.15183", "abs": "https://arxiv.org/abs/2506.15183", "authors": ["Xingyu Chen", "Xinmin Fang", "Shuting Zhang", "Xinyu Zhang", "Liang He", "Zhengxiong Li"], "title": "You Only Render Once: Enhancing Energy and Computation Efficiency of Mobile Virtual Reality", "categories": ["cs.GR"], "comment": null, "summary": "Mobile Virtual Reality (VR) is essential to achieving convenient and\nimmersive human-computer interaction and realizing emerging applications such\nas Metaverse. However, existing VR technologies require two separate renderings\nof binocular images, causing a significant bottleneck for mobile devices with\nlimited computing capability and power supply. This paper proposes an approach\nto rendering optimization for mobile VR called EffVR. By utilizing the\nper-pixel attribute, EffVR can generate binocular VR images from the monocular\nimage through genuinely one rendering, saving half the computation over\nconventional approaches. Our evaluation indicates that, compared with the\nstate-of-art, EffVRcan save 27% power consumption on average while achieving\nhigh binocular image quality (0.9679 SSIM and 34.09 PSNR) in mobile VR\napplications. Additionally, EffVR can increase the frame rate by 115.2%. These\nresults corroborate EffVRsuperior computation/energy-saving performance, paving\nthe road to a sustainable mobile VR. The source code, demo video, android app,\nand more are released anonymously at https://yoro-vr.github.io/", "AI": {"tldr": "EffVR\u901a\u8fc7\u5355\u6b21\u6e32\u67d3\u4f18\u5316\u79fb\u52a8VR\uff0c\u8282\u770150%\u8ba1\u7b97\u91cf\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u663e\u8457\u964d\u4f4e\u529f\u8017\u5e76\u63d0\u5347\u5e27\u7387", "motivation": "\u73b0\u6709VR\u6280\u672f\u9700\u8981\u5206\u522b\u6e32\u67d3\u53cc\u76ee\u56fe\u50cf\uff0c\u5bfc\u81f4\u79fb\u52a8\u8bbe\u5907\u9762\u4e34\u8ba1\u7b97\u80fd\u529b\u548c\u7535\u6e90\u9650\u5236\u7684\u74f6\u9888\u95ee\u9898", "method": "\u5229\u7528\u6bcf\u50cf\u7d20\u5c5e\u6027\uff0c\u901a\u8fc7\u5355\u76ee\u56fe\u50cf\u751f\u6210\u53cc\u76eeVR\u56fe\u50cf\uff08\u771f\u6b63\u5b9e\u73b0\u4e00\u6b21\u6e32\u67d3\uff09", "result": "\u5e73\u5747\u8282\u770127%\u529f\u8017\uff080.9679 SSIM/34.09 PSNR\uff09\uff0c\u5e27\u7387\u63d0\u5347115.2%", "conclusion": "EffVR\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u8ba1\u7b97/\u8282\u80fd\u6027\u80fd\uff0c\u4e3a\u53ef\u6301\u7eed\u79fb\u52a8VR\u53d1\u5c55\u5960\u5b9a\u57fa\u7840"}}
{"id": "2506.15290", "pdf": "https://arxiv.org/pdf/2506.15290", "abs": "https://arxiv.org/abs/2506.15290", "authors": ["Andela Ilic", "Jiaxi Jiang", "Paul Streli", "Xintong Liu", "Christian Holz"], "title": "Human Motion Capture from Loose and Sparse Inertial Sensors with Garment-aware Diffusion Models", "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.HC", "68T07, 68T45, 68U01", "I.2; I.3; I.4; I.5"], "comment": "Accepted by IJCAI 2025", "summary": "Motion capture using sparse inertial sensors has shown great promise due to\nits portability and lack of occlusion issues compared to camera-based tracking.\nExisting approaches typically assume that IMU sensors are tightly attached to\nthe human body. However, this assumption often does not hold in real-world\nscenarios. In this paper, we present a new task of full-body human pose\nestimation using sparse, loosely attached IMU sensors. To solve this task, we\nsimulate IMU recordings from an existing garment-aware human motion dataset. We\ndeveloped transformer-based diffusion models to synthesize loose IMU data and\nestimate human poses based on this challenging loose IMU data. In addition, we\nshow that incorporating garment-related parameters while training the model on\nsimulated loose data effectively maintains expressiveness and enhances the\nability to capture variations introduced by looser or tighter garments.\nExperiments show that our proposed diffusion methods trained on simulated and\nsynthetic data outperformed the state-of-the-art methods quantitatively and\nqualitatively, opening up a promising direction for future research.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u6269\u6563\u6a21\u578b\u7684\u677e\u6563IMU\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u670d\u88c5\u53c2\u6570\u589e\u5f3a\u6a21\u578b\u8868\u73b0\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u4e8e\u73b0\u6709\u6280\u672f", "motivation": "\u89e3\u51b3\u5b9e\u9645\u573a\u666f\u4e2dIMU\u4f20\u611f\u5668\u975e\u7d27\u5bc6\u9644\u7740\u5bfc\u81f4\u7684\u59ff\u6001\u4f30\u8ba1\u7cbe\u5ea6\u4e0b\u964d\u95ee\u9898", "method": "1. \u4f7f\u7528\u670d\u88c5\u611f\u77e5\u6570\u636e\u96c6\u6a21\u62df\u677e\u6563IMU\u6570\u636e 2. \u5f00\u53d1\u57fa\u4e8eTransformer\u7684\u6269\u6563\u6a21\u578b\u8fdb\u884c\u6570\u636e\u5408\u6210\u4e0e\u59ff\u6001\u4f30\u8ba1 3. \u6574\u5408\u670d\u88c5\u76f8\u5173\u53c2\u6570\u8bad\u7ec3\u6a21\u578b", "result": "\u5b9a\u91cf\u5b9a\u6027\u8bc4\u4f30\u663e\u793a\u6269\u6563\u6a21\u578b\u5728\u6a21\u62df/\u5408\u6210\u6570\u636e\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff08SOTA\uff09", "conclusion": "\u4e3a\u677e\u6563IMU\u59ff\u6001\u4f30\u8ba1\u5f00\u8f9f\u65b0\u65b9\u5411\uff0c\u8bc1\u660e\u670d\u88c5\u53c2\u6570\u6574\u5408\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u7684\u63d0\u5347\u4ef7\u503c"}}
{"id": "2506.15312", "pdf": "https://arxiv.org/pdf/2506.15312", "abs": "https://arxiv.org/abs/2506.15312", "authors": ["Han Wu", "Junyao Li", "Kangbo Zhao", "Sen Zhang", "Yukai Shi", "Liang Lin"], "title": "One-shot Face Sketch Synthesis in the Wild via Generative Diffusion Prior and Instruction Tuning", "categories": ["cs.GR", "cs.CR", "cs.CV", "cs.CY"], "comment": "We propose a novel framework for face sketch synthesis, where merely\n  a single pair of samples suffices to enable in-the-wild face sketch synthesis", "summary": "Face sketch synthesis is a technique aimed at converting face photos into\nsketches. Existing face sketch synthesis research mainly relies on training\nwith numerous photo-sketch sample pairs from existing datasets. However, these\nlarge-scale discriminative learning methods will have to face problems such as\ndata scarcity and high human labor costs. Once the training data becomes\nscarce, their generative performance significantly degrades. In this paper, we\npropose a one-shot face sketch synthesis method based on diffusion models. We\noptimize text instructions on a diffusion model using face photo-sketch image\npairs. Then, the instructions derived through gradient-based optimization are\nused for inference. To simulate real-world scenarios more accurately and\nevaluate method effectiveness more comprehensively, we introduce a new\nbenchmark named One-shot Face Sketch Dataset (OS-Sketch). The benchmark\nconsists of 400 pairs of face photo-sketch images, including sketches with\ndifferent styles and photos with different backgrounds, ages, sexes,\nexpressions, illumination, etc. For a solid out-of-distribution evaluation, we\nselect only one pair of images for training at each time, with the rest used\nfor inference. Extensive experiments demonstrate that the proposed method can\nconvert various photos into realistic and highly consistent sketches in a\none-shot context. Compared to other methods, our approach offers greater\nconvenience and broader applicability. The dataset will be available at:\nhttps://github.com/HanWu3125/OS-Sketch", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4e00\u6b21\u6027\u4eba\u8138\u7d20\u63cf\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u6587\u672c\u6307\u4ee4\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u5efa\u7acbOS-Sketch\u6570\u636e\u96c6\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u4eba\u8138\u7d20\u63cf\u5408\u6210\u4f9d\u8d56\u5927\u89c4\u6a21\u914d\u5bf9\u6570\u636e\uff0c\u9762\u4e34\u6570\u636e\u7a00\u7f3a\u548c\u9ad8\u6210\u672c\u74f6\u9888\u3002\u9700\u8981\u5f00\u53d1\u6570\u636e\u9ad8\u6548\u7684\u65b0\u578b\u751f\u6210\u65b9\u6cd5\u4ee5\u9002\u5e94\u5b9e\u9645\u573a\u666f\u3002", "method": "\u5728\u6269\u6563\u6a21\u578b\u4e2d\u4f18\u5316\u7167\u7247-\u7d20\u63cf\u5bf9\u7684\u6587\u672c\u6307\u4ee4\uff0c\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u83b7\u5f97\u53ef\u8fc1\u79fb\u6307\u4ee4\u3002\u6784\u5efa\u5305\u542b400\u5bf9\u591a\u98ce\u683c\u3001\u591a\u5c5e\u6027\u6570\u636e\u7684OS-Sketch\u57fa\u51c6\uff0c\u91c7\u7528\u7559\u4e00\u6cd5\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u5355\u6837\u672c\u751f\u6210\u903c\u771f\u4e14\u98ce\u683c\u4e00\u81f4\u7684\u7d20\u63cf\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5177\u5b9e\u7528\u6027\u548c\u573a\u666f\u9002\u5e94\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u6570\u636e\u7a00\u7f3a\u573a\u666f\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0cOS-Sketch\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u7814\u7a76\u5efa\u7acb\u53ef\u9760\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2506.15684", "pdf": "https://arxiv.org/pdf/2506.15684", "abs": "https://arxiv.org/abs/2506.15684", "authors": ["Qingming Liu", "Zhen Liu", "Dinghuai Zhang", "Kui Jia"], "title": "Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards", "categories": ["cs.GR", "cs.CV", "cs.LG"], "comment": "Technical Report (21 pages, 21 figures)", "summary": "Generating high-quality and photorealistic 3D assets remains a longstanding\nchallenge in 3D vision and computer graphics. Although state-of-the-art\ngenerative models, such as diffusion models, have made significant progress in\n3D generation, they often fall short of human-designed content due to limited\nability to follow instructions, align with human preferences, or produce\nrealistic textures, geometries, and physical attributes. In this paper, we\nintroduce Nabla-R2D3, a highly effective and sample-efficient reinforcement\nlearning alignment framework for 3D-native diffusion models using 2D rewards.\nBuilt upon the recently proposed Nabla-GFlowNet method, which matches the score\nfunction to reward gradients in a principled manner for reward finetuning, our\nNabla-R2D3 enables effective adaptation of 3D diffusion models using only 2D\nreward signals. Extensive experiments show that, unlike vanilla finetuning\nbaselines which either struggle to converge or suffer from reward hacking,\nNabla-R2D3 consistently achieves higher rewards and reduced prior forgetting\nwithin a few finetuning steps.", "AI": {"tldr": "Nabla-R2D3\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u5229\u75282D\u5956\u52b1\u4fe1\u53f7\u9ad8\u6548\u4f18\u53163D\u539f\u751f\u6269\u6563\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u4e0d\u8db3\u3001\u751f\u6210\u8d28\u91cf\u6b20\u4f73\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u67093D\u751f\u6210\u6a21\u578b\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u5b58\u5728\u6307\u4ee4\u5bf9\u9f50\u80fd\u529b\u5f31\u3001\u751f\u6210\u7ed3\u679c\u7eb9\u7406/\u51e0\u4f55\u771f\u5b9e\u6027\u4e0d\u8db3\u3001\u96be\u4ee5\u5339\u914d\u4eba\u7c7b\u504f\u597d\u7b49\u95ee\u9898\uff0c\u9700\u6539\u8fdb\u751f\u6210\u8d28\u91cf\u4e0e\u6548\u7387\u3002", "method": "\u57fa\u4e8eNabla-GFlowNet\u65b9\u6cd5\uff0c\u5c06\u8bc4\u5206\u51fd\u6570\u4e0e\u5956\u52b1\u68af\u5ea6\u539f\u7406\u6027\u5bf9\u9f50\uff0c\u4ec5\u75282D\u5956\u52b1\u4fe1\u53f7\u5b9e\u73b03D\u6269\u6563\u6a21\u578b\u5fae\u8c03\uff0c\u907f\u514d\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u7684\u6536\u655b\u56f0\u96be\u4e0e\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5c11\u91cf\u5fae\u8c03\u6b65\u9aa4\u5185\u5373\u5b9e\u73b0\u66f4\u9ad8\u5956\u52b1\u503c\uff0c\u964d\u4f4e\u5148\u9a8c\u77e5\u8bc6\u9057\u5fd8\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e863D\u751f\u6210\u6a21\u578b\u7684\u5bf9\u9f50\u80fd\u529b\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u4e3a\u9ad8\u4fdd\u771f3D\u5185\u5bb9\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.14900", "pdf": "https://arxiv.org/pdf/2506.14900", "abs": "https://arxiv.org/abs/2506.14900", "authors": ["Imane Guellil", "Salom\u00e9 Andres", "Atul Anand", "Bruce Guthrie", "Huayu Zhang", "Abul Hasan", "Honghan Wu", "Beatrice Alex"], "title": "Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings", "categories": ["cs.CL"], "comment": "Accepted and will be published at ACL2025 (main conference)", "summary": "In this work, we present a manually annotated corpus for Adverse Event (AE)\nextraction from discharge summaries of elderly patients, a population often\nunderrepresented in clinical NLP resources. The dataset includes 14 clinically\nsignificant AEs-such as falls, delirium, and intracranial haemorrhage, along\nwith contextual attributes like negation, diagnosis type, and in-hospital\noccurrence. Uniquely, the annotation schema supports both discontinuous and\noverlapping entities, addressing challenges rarely tackled in prior work. We\nevaluate multiple models using FlairNLP across three annotation granularities:\nfine-grained, coarse-grained, and coarse-grained with negation. While\ntransformer-based models (e.g., BERT-cased) achieve strong performance on\ndocument-level coarse-grained extraction (F1 = 0.943), performance drops\nnotably for fine-grained entity-level tasks (e.g., F1 = 0.675), particularly\nfor rare events and complex attributes. These results demonstrate that despite\nhigh-level scores, significant challenges remain in detecting underrepresented\nAEs and capturing nuanced clinical language. Developed within a Trusted\nResearch Environment (TRE), the dataset is available upon request via DataLoch\nand serves as a robust benchmark for evaluating AE extraction methods and\nsupporting future cross-dataset generalisation.", "AI": {"tldr": "\u7814\u7a76\u6784\u5efa\u4e86\u9488\u5bf9\u8001\u5e74\u60a3\u8005\u51fa\u9662\u6458\u8981\u4e2d\u4e0d\u826f\u4e8b\u4ef6\u63d0\u53d6\u7684\u6807\u6ce8\u8bed\u6599\u5e93\uff0c\u652f\u6301\u4e0d\u8fde\u7eed/\u91cd\u53e0\u5b9e\u4f53\u6807\u6ce8\u3002\u5b9e\u9a8c\u8868\u660eTransformer\u6a21\u578b\u5728\u7c97\u7c92\u5ea6\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff08F1=0.943\uff09\uff0c\u4f46\u7ec6\u7c92\u5ea6\u68c0\u6d4b\uff08\u5c24\u5176\u662f\u7f55\u89c1\u4e8b\u4ef6\uff09\u5b58\u5728\u663e\u8457\u6311\u6218\uff08F1=0.675\uff09\u3002", "motivation": "\u89e3\u51b3\u8001\u5e74\u60a3\u8005\u5728\u4e34\u5e8aNLP\u8d44\u6e90\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e94\u5bf9\u4e0d\u8fde\u7eed/\u91cd\u53e0\u5b9e\u4f53\u6807\u6ce8\u7684\u6280\u672f\u6311\u6218\uff0c\u63d0\u5347\u7f55\u89c1\u4e0d\u826f\u4e8b\u4ef6\u548c\u590d\u6742\u4e34\u5e8a\u5c5e\u6027\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b14\u79cd\u4e34\u5e8a\u663e\u8457AE\u7684\u624b\u52a8\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u91c7\u7528FlairNLP\u6846\u67b6\u8bc4\u4f30\u591a\u7c92\u5ea6\u6807\u6ce8\u4efb\u52a1\uff08\u7ec6\u7c92\u5ea6/\u7c97\u7c92\u5ea6/\u5e26\u5426\u5b9a\u7c97\u7c92\u5ea6\uff09\uff0c\u91cd\u70b9\u5206\u6790BERT\u7b49Transformer\u6a21\u578b\u8868\u73b0\u3002", "result": "\u6587\u6863\u7ea7\u7c97\u7c92\u5ea6\u63d0\u53d6\u8fbeF1=0.943\uff0c\u4f46\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u7ea7\u4efb\u52a1\u9aa4\u964d\u81f3F1=0.675\uff0c\u7f55\u89c1\u4e8b\u4ef6\uff08\u5982\u9885\u5185\u51fa\u8840\uff09\u548c\u590d\u6742\u5c5e\u6027\uff08\u5426\u5b9a\u5224\u65ad\uff09\u68c0\u6d4b\u51c6\u786e\u7387\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3aAE\u63d0\u53d6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u57fa\u51c6\uff0c\u7a81\u663e\u73b0\u6709\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u8bed\u8a00\u7406\u89e3\u4e0a\u7684\u5c40\u9650\uff0c\u63a8\u52a8\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u7814\u7a76\u548c\u4e34\u5e8aNLP\u7cbe\u51c6\u5ea6\u63d0\u5347\u3002"}}
{"id": "2506.15571", "pdf": "https://arxiv.org/pdf/2506.15571", "abs": "https://arxiv.org/abs/2506.15571", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Tu Nguyen Thi Ngoc"], "title": "MicroRicci: A Greedy and Local Ricci Flow Solver for Self-Tuning Mesh Smoothing", "categories": ["cs.LG", "cs.GR"], "comment": "9 pages, 8 figures, 4 tables", "summary": "Real-time mesh smoothing at scale remains a formidable challenge: classical\nRicci-flow solvers demand costly global updates, while greedy heuristics suffer\nfrom slow convergence or brittle tuning. We present MicroRicci, the first truly\nself-tuning, local Ricci-flow solver that borrows ideas from coding theory and\npacks them into just 1K + 200 parameters. Its primary core is a greedy\nsyndrome-decoding step that pinpoints and corrects the largest curvature error\nin O(E) time, augmented by two tiny neural modules that adaptively choose\nvertices and step sizes on the fly. On a diverse set of 110 SJTU-TMQA meshes,\nMicroRicci slashes iteration counts from 950+=140 to 400+=80 (2.4x speedup),\ntightens curvature spread from 0.19 to 0.185, and achieves a remarkable\nUV-distortion-to-MOS correlation of r = -0.93. It adds only 0.25 ms per\niteration (0.80 to 1.05 ms), yielding an end-to-end 1.8x runtime acceleration\nover state-of-the-art methods. MicroRicci's combination of linear-time updates,\nautomatic hyperparameter adaptation, and high-quality geometric and perceptual\nresults makes it well suited for real-time, resource-limited applications in\ngraphics, simulation, and related fields.", "AI": {"tldr": "\u63d0\u51faMicroRicci\u2014\u2014\u9996\u4e2a\u771f\u6b63\u81ea\u9002\u5e94\u7684\u5c40\u90e8Ricci-flow\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u7f16\u7801\u7406\u8bba+\u5fae\u578b\u795e\u7ecf\u6a21\u5757\u5b9e\u73b0\u5b9e\u65f6\u7f51\u683c\u5e73\u6ed1\u4f18\u5316", "motivation": "\u73b0\u6709Ricci-flow\u6c42\u89e3\u5668\u5b58\u5728\u5168\u5c40\u66f4\u65b0\u6210\u672c\u9ad8/\u6536\u655b\u901f\u5ea6\u6162/\u53c2\u6570\u8c03\u8282\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u65f6\u5927\u89c4\u6a21\u7f51\u683c\u5904\u7406\u9700\u6c42", "method": "\u7ed3\u5408\u7f16\u7801\u7406\u8bba\u7684\u8d2a\u5fc3\u66f2\u7387\u8bef\u5dee\u89e3\u7801\u7b97\u6cd5\uff08O(E)\u65f6\u95f4\u590d\u6742\u5ea6\uff09\uff0c\u642d\u914d\u4e24\u4e2a\u81ea\u9002\u5e94\u9009\u62e9\u9876\u70b9\u548c\u6b65\u957f\u7684\u5fae\u578b\u795e\u7ecf\u7f51\u7edc\u6a21\u5757\uff08\u603b\u53c2\u6570\u4ec51.2K\uff09", "result": "\u5728110\u4e2a\u6d4b\u8bd5\u7f51\u683c\u4e0a\uff1a\u8fed\u4ee3\u6b21\u6570\u51cf\u5c112.4\u500d\uff08950+\u2192400+\uff09\uff0c\u66f2\u7387\u5206\u5e03\u6807\u51c6\u5dee\u964d\u81f30.185\uff0cUV\u5931\u771f\u4e0eMOS\u76f8\u5173\u6027\u8fbe-0.93\uff0c\u5355\u6b21\u8fed\u4ee3\u8017\u65f6\u4ec5\u589e0.25ms", "conclusion": "MicroRicci\u51ed\u501f\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u3001\u81ea\u52a8\u8d85\u53c2\u6570\u8c03\u8282\u548c\u4f18\u8d8a\u7684\u51e0\u4f55/\u611f\u77e5\u8d28\u91cf\uff0c\u4e3a\u56fe\u5f62/\u4eff\u771f\u7b49\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2506.14901", "pdf": "https://arxiv.org/pdf/2506.14901", "abs": "https://arxiv.org/abs/2506.14901", "authors": ["Marija \u0160akota", "Robert West"], "title": "Combining Constrained and Unconstrained Decoding via Boosting: BoostCD and Its Application to Information Extraction", "categories": ["cs.CL"], "comment": null, "summary": "Many recent approaches to structured NLP tasks use an autoregressive language\nmodel $M$ to map unstructured input text $x$ to output text $y$ representing\nstructured objects (such as tuples, lists, trees, code, etc.), where the\ndesired output structure is enforced via constrained decoding. During training,\nthese approaches do not require the model to be aware of the constraints, which\nare merely implicit in the training outputs $y$. This is advantageous as it\nallows for dynamic constraints without requiring retraining, but can lead to\nlow-quality output during constrained decoding at test time. We overcome this\nproblem with Boosted Constrained Decoding (BoostCD), which combines constrained\nand unconstrained decoding in two phases: Phase 1 decodes from the base model\n$M$ twice, in constrained and unconstrained mode, obtaining two weak\npredictions. In phase 2, a learned autoregressive boosted model combines the\ntwo weak predictions into one final prediction. The mistakes made by the base\nmodel with vs. without constraints tend to be complementary, which the boosted\nmodel learns to exploit for improved performance. We demonstrate the power of\nBoostCD by applying it to closed information extraction. Our model, BoostIE,\noutperforms prior approaches both in and out of distribution, addressing\nseveral common errors identified in those approaches.", "AI": {"tldr": "BoostCD\u901a\u8fc7\u4e24\u9636\u6bb5\u89e3\u7801\uff08\u7ea6\u675f+\u975e\u7ea6\u675f\uff09\u7ed3\u5408\u4e92\u8865\u6027\u9519\u8bef\uff0c\u63d0\u5347\u7ed3\u6784\u5316NLP\u4efb\u52a1\u7684\u8f93\u51fa\u8d28\u91cf", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u4f9d\u8d56\u9690\u5f0f\u7ea6\u675f\u5bfc\u81f4\u89e3\u7801\u8d28\u91cf\u4f4e\uff0c\u9700\u901a\u8fc7\u663e\u5f0f\u7ed3\u5408\u7ea6\u675f\u4e0e\u975e\u7ea6\u675f\u89e3\u7801\u6765\u6539\u5584", "method": "1. \u57fa\u7840\u6a21\u578b\u5206\u522b\u8fdb\u884c\u7ea6\u675f/\u975e\u7ea6\u675f\u89e3\u7801\u5f97\u5230\u5f31\u9884\u6d4b 2. \u589e\u5f3a\u6a21\u578b\u878d\u5408\u4e24\u79cd\u9884\u6d4b\u751f\u6210\u6700\u7ec8\u7ed3\u679c", "result": "BoostIE\u6a21\u578b\u5728\u95ed\u5f0f\u4fe1\u606f\u63d0\u53d6\u4efb\u52a1\u4e2d\u5206\u5e03\u5185\u5916\u5747\u8d85\u8d8a\u57fa\u7ebf\uff0c\u663e\u8457\u51cf\u5c11\u5e38\u89c1\u9519\u8bef\u7c7b\u578b", "conclusion": "\u4e24\u9636\u6bb5\u89e3\u7801\u673a\u5236\u6709\u6548\u5229\u7528\u4e92\u8865\u9519\u8bef\u6a21\u5f0f\uff0c\u4e3a\u7ed3\u6784\u5316\u8f93\u51fa\u4efb\u52a1\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848"}}
{"id": "2506.14912", "pdf": "https://arxiv.org/pdf/2506.14912", "abs": "https://arxiv.org/abs/2506.14912", "authors": ["Dyah Adila", "Shuai Zhang", "Boran Han", "Bonan Min", "Yuyang Wang"], "title": "CrEst: Credibility Estimation for Contexts in LLMs via Weak Supervision", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "The integration of contextual information has significantly enhanced the\nperformance of large language models (LLMs) on knowledge-intensive tasks.\nHowever, existing methods often overlook a critical challenge: the credibility\nof context documents can vary widely, potentially leading to the propagation of\nunreliable information. In this paper, we introduce CrEst, a novel weakly\nsupervised framework for assessing the credibility of context documents during\nLLM inference--without requiring manual annotations. Our approach is grounded\nin the insight that credible documents tend to exhibit higher semantic\ncoherence with other credible documents, enabling automated credibility\nestimation through inter-document agreement. To incorporate credibility into\nLLM inference, we propose two integration strategies: a black-box approach for\nmodels without access to internal weights or activations, and a white-box\nmethod that directly modifies attention mechanisms. Extensive experiments\nacross three model architectures and five datasets demonstrate that CrEst\nconsistently outperforms strong baselines, achieving up to a 26.86% improvement\nin accuracy and a 3.49% increase in F1 score. Further analysis shows that CrEst\nmaintains robust performance even under high-noise conditions.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684CrEst\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u6863\u95f4\u8bed\u4e49\u4e00\u81f4\u6027\u81ea\u52a8\u8bc4\u4f30\u4e0a\u4e0b\u6587\u53ef\u4fe1\u5ea6\uff0c\u6709\u6548\u63d0\u5347\u5927\u6a21\u578b\u5728\u77e5\u8bc6\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e0a\u4e0b\u6587\u6587\u6863\u53ef\u4fe1\u5ea6\u5dee\u5f02\uff0c\u53ef\u80fd\u4f20\u64ad\u4e0d\u53ef\u9760\u4fe1\u606f\u3002\u9700\u8981\u81ea\u52a8\u8bc4\u4f30\u6587\u6863\u53ef\u4fe1\u5ea6\u4ee5\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027", "method": "\u57fa\u4e8e\u53ef\u4fe1\u6587\u6863\u8bed\u4e49\u4e00\u81f4\u6027\u5047\u8bbe\uff0c\u5f00\u53d1\u5f31\u76d1\u7763\u6846\u67b6\u5b9e\u73b0\u81ea\u52a8\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u3002\u63d0\u51fa\u9ed1\u76d2(\u8c03\u6574\u8f93\u5165\u6743\u91cd)\u548c\u767d\u76d2(\u4fee\u6539\u6ce8\u610f\u529b\u673a\u5236)\u4e24\u79cd\u96c6\u6210\u7b56\u7565", "result": "\u57283\u79cd\u6a21\u578b\u67b6\u6784\u548c5\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u9ad826.86%\u51c6\u786e\u7387\u63d0\u5347\u548c3.49% F1\u589e\u957f\uff0c\u9ad8\u566a\u58f0\u73af\u5883\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd", "conclusion": "CrEst\u901a\u8fc7\u81ea\u52a8\u5316\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u4e0a\u4e0b\u6587\u53ef\u9760\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u5728\u566a\u58f0\u573a\u666f\u4e0b\u8868\u73b0\u7a81\u51fa"}}
{"id": "2506.14927", "pdf": "https://arxiv.org/pdf/2506.14927", "abs": "https://arxiv.org/abs/2506.14927", "authors": ["Joseph J. Peper", "Wenzhao Qiu", "Ali Payani", "Lu Wang"], "title": "MDBench: A Synthetic Multi-Document Reasoning Benchmark Generated with Knowledge Guidance", "categories": ["cs.CL", "cs.AI"], "comment": "ACL 2025 Findings", "summary": "Natural language processing evaluation has made significant progress, largely\ndriven by the proliferation of powerful large language mod-els (LLMs). New\nevaluation benchmarks are of increasing priority as the reasoning capabilities\nof LLMs are expanding at a rapid pace. In particular, while multi-document (MD)\nreasoning is an area of extreme relevance given LLM capabilities in handling\nlonger-context inputs, few benchmarks exist to rigorously examine model\nbehavior in this setting. Moreover, the multi-document setting is historically\nchallenging for benchmark creation due to the expensive cost of annotating long\ninputs. In this work, we introduce MDBench, a new dataset for evaluating LLMs\non the task of multi-document reasoning. Notably, MDBench is created through a\nnovel synthetic generation process, allowing us to controllably and efficiently\ngenerate challenging document sets and the corresponding question-answer (QA)\nexamples. Our novel technique operates on condensed structured seed knowledge,\nmodifying it through LLM-assisted edits to induce MD-specific reasoning\nchallenges. We then convert this structured knowledge into a natural text\nsurface form, generating a document set and corresponding QA example. We\nanalyze the behavior of popular LLMs and prompting techniques, finding that\nMDBENCH poses significant challenges for all methods, even with relatively\nshort document sets. We also see our knowledge-guided generation technique (1)\nallows us to readily perform targeted analysis of MD-specific reasoning\ncapabilities and (2) can be adapted quickly to account for new challenges and\nfuture modeling improvements.", "AI": {"tldr": "\u63d0\u51faMDBench\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5408\u6210\u751f\u6210\u65b9\u6cd5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6587\u6863\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u96be\u4ee5\u6709\u6548\u68c0\u9a8c\u591a\u6587\u6863\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u957f\u6587\u672c\u6807\u6ce8\u6210\u672c\u9ad8\u6602", "method": "\u57fa\u4e8e\u7ed3\u6784\u5316\u79cd\u5b50\u77e5\u8bc6\u8fdb\u884cLLM\u8f85\u52a9\u7f16\u8f91\uff0c\u751f\u6210\u53ef\u63a7\u7684\u6311\u6218\u6027\u6587\u6863\u96c6\u53ca\u5bf9\u5e94QA\u6837\u672c", "result": "\u5f53\u524d\u4e3b\u6d41LLMs\u5728MDBench\u4e0a\u8868\u73b0\u6b20\u4f73\uff0c\u77e5\u8bc6\u5f15\u5bfc\u751f\u6210\u6280\u672f\u652f\u6301\u9488\u5bf9\u6027\u80fd\u529b\u5206\u6790\u4e0e\u5feb\u901f\u8fed\u4ee3", "conclusion": "MDBench\u586b\u8865\u591a\u6587\u6863\u63a8\u7406\u8bc4\u4f30\u7a7a\u767d\uff0c\u5176\u5408\u6210\u65b9\u6cd5\u5177\u6709\u9ad8\u6548\u53ef\u63a7\u4f18\u52bf"}}
{"id": "2506.14949", "pdf": "https://arxiv.org/pdf/2506.14949", "abs": "https://arxiv.org/abs/2506.14949", "authors": ["Shadman Sakib", "Oishy Fatema Akhand", "Ajwad Abrar"], "title": "From Chat to Checkup: Can Large Language Models Assist in Diabetes Prediction?", "categories": ["cs.CL"], "comment": "Accepted in 1st IEEE QPAIN 2025", "summary": "While Machine Learning (ML) and Deep Learning (DL) models have been widely\nused for diabetes prediction, the use of Large Language Models (LLMs) for\nstructured numerical data is still not well explored. In this study, we test\nthe effectiveness of LLMs in predicting diabetes using zero-shot, one-shot, and\nthree-shot prompting methods. We conduct an empirical analysis using the Pima\nIndian Diabetes Database (PIDD). We evaluate six LLMs, including four\nopen-source models: Gemma-2-27B, Mistral-7B, Llama-3.1-8B, and Llama-3.2-2B. We\nalso test two proprietary models: GPT-4o and Gemini Flash 2.0. In addition, we\ncompare their performance with three traditional machine learning models:\nRandom Forest, Logistic Regression, and Support Vector Machine (SVM). We use\naccuracy, precision, recall, and F1-score as evaluation metrics. Our results\nshow that proprietary LLMs perform better than open-source ones, with GPT-4o\nand Gemma-2-27B achieving the highest accuracy in few-shot settings. Notably,\nGemma-2-27B also outperforms the traditional ML models in terms of F1-score.\nHowever, there are still issues such as performance variation across prompting\nstrategies and the need for domain-specific fine-tuning. This study shows that\nLLMs can be useful for medical prediction tasks and encourages future work on\nprompt engineering and hybrid approaches to improve healthcare predictions.", "AI": {"tldr": "\u8bba\u6587\u5bf9\u6bd4\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7cd6\u5c3f\u75c5\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5546\u4e1aLLM\uff08\u5982GPT-4o\uff09\u5728\u5c11\u6837\u672c\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u4f46\u5b58\u5728\u63d0\u793a\u7b56\u7565\u654f\u611f\u6027\u548c\u9886\u57df\u9002\u914d\u95ee\u9898", "motivation": "\u63a2\u7d22LLM\u5728\u7ed3\u6784\u5316\u533b\u7597\u6570\u636e\uff08Pima\u5370\u7b2c\u5b89\u4eba\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\uff09\u4e2d\u7684\u9884\u6d4b\u6f5c\u529b\uff0c\u586b\u8865\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d", "method": "\u4f7f\u75286\u4e2aLLM\uff084\u4e2a\u5f00\u6e90+2\u4e2a\u5546\u4e1a\u6a21\u578b\uff09\u4e0e3\u4e2a\u4f20\u7edfML\u6a21\u578b\u5bf9\u6bd4\uff0c\u91c7\u7528\u96f6\u6837\u672c/\u5355\u6837\u672c/\u4e09\u6837\u672c\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u51c6\u786e\u7387/\u7cbe\u786e\u7387/\u53ec\u56de\u7387/F1\u503c\u4e3a\u8bc4\u4f30\u6307\u6807", "result": "\u5546\u4e1aLLM\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0cGemma-2-27B\u5728F1\u503c\u8d85\u8d8a\u4f20\u7edfML\u6a21\u578b\uff1b\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u5bfc\u81f4\u6027\u80fd\u6ce2\u52a8\u660e\u663e", "conclusion": "LLM\u5728\u533b\u7597\u9884\u6d4b\u4efb\u52a1\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u672a\u6765\u9700\u52a0\u5f3a\u63d0\u793a\u5de5\u7a0b\u548c\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\u4ee5\u63d0\u5347\u6548\u679c"}}
{"id": "2506.15001", "pdf": "https://arxiv.org/pdf/2506.15001", "abs": "https://arxiv.org/abs/2506.15001", "authors": ["Ignacio Sastre", "Aiala Ros\u00e1"], "title": "Memory Tokens: Large Language Models Can Generate Reversible Sentence Embeddings", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "This paper will be presented at The First Workshop on Large Language\n  Model Memorization (L2M2) at ACL 2025", "summary": "In this work, we observe an interesting phenomenon: it is possible to\ngenerate reversible sentence embeddings that allow an LLM to reconstruct the\noriginal text exactly, without modifying the model's weights. This is achieved\nby introducing a special memory token, whose embedding is optimized through\ntraining on a fixed sequence. When prompted with this embedding, the model\nreconstructs the fixed sequence exactly. We evaluate this phenomenon across\nEnglish and Spanish datasets, sequences of up to approximately 240 tokens, and\nmodel scales ranging from 100M to 8B parameters. Notably, Llama 3.1 8B\nsuccessfully reconstructs all tested sequences. Our findings highlight an\ninteresting capability of LLMs and suggest potential applications in\nmemory-based retrieval, compression, and controlled text generation.", "AI": {"tldr": "\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u7279\u6b8a\u8bb0\u5fc6\u4ee4\u724c\u53ef\u751f\u6210\u53ef\u9006\u6587\u672c\u5d4c\u5165\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u5373\u53ef\u7cbe\u786e\u91cd\u6784\u539f\u59cb\u6587\u672c\uff08\u652f\u6301240\u5b57\u7b26\u5185\u82f1\u8bed/\u897f\u73ed\u7259\u8bed\uff0cLlama 3.1 8B\u9a8c\u8bc1\u6709\u6548\uff09", "motivation": "\u63ed\u793aLLMs\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u8bb0\u5fc6\u91cd\u6784\u80fd\u529b\uff0c\u63a2\u7d22\u901a\u8fc7\u5d4c\u5165\u5b9e\u73b0\u6587\u672c\u7cbe\u786e\u590d\u539f\u7684\u65b0\u673a\u5236", "method": "\u8bad\u7ec3\u65f6\u5728\u56fa\u5b9a\u5e8f\u5217\u4e2d\u5f15\u5165\u53ef\u4f18\u5316\u7684\u7279\u6b8a\u8bb0\u5fc6\u4ee4\u724c\u5d4c\u5165\uff0c\u63d0\u793a\u65f6\u901a\u8fc7\u8be5\u5d4c\u5165\u89e6\u53d1\u6a21\u578b\u7cbe\u786e\u91cd\u6784\u539f\u59cb\u6587\u672c", "result": "Llama 3.1 8B\u6210\u529f\u91cd\u6784\u6240\u6709\u6d4b\u8bd5\u5e8f\u5217\uff08\u542b240\u5b57\u7b26\u5185\u82f1/\u897f\u8bed\uff09\uff0c\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\uff081\u4ebf\u81f380\u4ebf\u53c2\u6570\uff09\u5747\u9a8c\u8bc1\u6709\u6548", "conclusion": "\u8be5\u80fd\u529b\u4e3a\u8bb0\u5fc6\u68c0\u7d22\u3001\u6587\u672c\u538b\u7f29\u548c\u53ef\u63a7\u751f\u6210\u5f00\u8f9f\u65b0\u8def\u5f84\uff0c\u51f8\u663eLLMs\u5728\u8bb0\u5fc6\u673a\u5236\u65b9\u9762\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c"}}
{"id": "2506.15030", "pdf": "https://arxiv.org/pdf/2506.15030", "abs": "https://arxiv.org/abs/2506.15030", "authors": ["Drew Walker", "Swati Rajwal", "Sudeshna Das", "Snigdha Peddireddy", "Abeed Sarker"], "title": "Identifying social isolation themes in NVDRS text narratives using topic modeling and text-classification methods", "categories": ["cs.CL"], "comment": "22 pages, 2 figures, 5 tables", "summary": "Social isolation and loneliness, which have been increasing in recent years\nstrongly contribute toward suicide rates. Although social isolation and\nloneliness are not currently recorded within the US National Violent Death\nReporting System's (NVDRS) structured variables, natural language processing\n(NLP) techniques can be used to identify these constructs in law enforcement\nand coroner medical examiner narratives. Using topic modeling to generate\nlexicon development and supervised learning classifiers, we developed\nhigh-quality classifiers (average F1: .86, accuracy: .82). Evaluating over\n300,000 suicides from 2002 to 2020, we identified 1,198 mentioning chronic\nsocial isolation. Decedents had higher odds of chronic social isolation\nclassification if they were men (OR = 1.44; CI: 1.24, 1.69, p<.0001), gay (OR =\n3.68; 1.97, 6.33, p<.0001), or were divorced (OR = 3.34; 2.68, 4.19, p<.0001).\nWe found significant predictors for other social isolation topics of recent or\nimpending divorce, child custody loss, eviction or recent move, and break-up.\nOur methods can improve surveillance and prevention of social isolation and\nloneliness in the United States.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5206\u679030\u4e07+\u81ea\u6740\u6848\u4f8b\uff0c\u53d1\u73b0\u7537\u6027/\u540c\u6027\u604b/\u79bb\u5a5a\u4eba\u7fa4\u5177\u6709\u66f4\u9ad8\u7684\u957f\u671f\u793e\u4f1a\u9694\u79bb\u98ce\u9669\uff0c\u5f00\u53d1\u51fa\u9ad8\u6548\u5206\u7c7b\u6a21\u578b\uff08F1=0.86\uff09\u7528\u4e8e\u6539\u8fdb\u793e\u4f1a\u9694\u79bb\u76d1\u6d4b\u3002", "motivation": "\u793e\u4f1a\u9694\u79bb\u548c\u5b64\u72ec\u611f\u663e\u8457\u52a0\u5267\u81ea\u6740\u7387\uff0c\u4f46\u73b0\u6709\u6b7b\u4ea1\u62a5\u544a\u7cfb\u7edf\u7f3a\u4e4f\u76f8\u5173\u7ed3\u6784\u5316\u8bb0\u5f55\uff0c\u9700\u901a\u8fc7NLP\u6280\u672f\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u63d0\u53d6\u8fd9\u4e9b\u98ce\u9669\u56e0\u7d20\u3002", "method": "\u91c7\u7528\u4e3b\u9898\u5efa\u6a21\u6784\u5efa\u8bcd\u5178+\u76d1\u7763\u5b66\u4e60\u5206\u7c7b\u5668\u5f00\u53d1\u9884\u6d4b\u6a21\u578b\uff0c\u57fa\u4e8e2002-2020\u5e74300,143\u4f8b\u81ea\u6740\u6848\u4f8b\u6570\u636e\uff0c\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u5206\u6790\u98ce\u9669\u56e0\u7d20\uff08OR\u503c\u8ba1\u7b97\uff09\u3002", "result": "\u8bc6\u522b\u51fa1,198\u4f8b\u957f\u671f\u793e\u4f1a\u9694\u79bb\u6848\u4f8b\uff0c\u7537\u6027\uff08OR=1.44\uff09\u3001\u540c\u6027\u604b\uff08OR=3.68\uff09\u3001\u79bb\u5a5a\u8005\uff08OR=3.34\uff09\u98ce\u9669\u6700\u9ad8\uff1b\u53d1\u73b0\u79bb\u5a5a/\u76d1\u62a4\u6743\u4e27\u5931/\u642c\u8fc1/\u5206\u624b\u7b49\u65b0\u578b\u9884\u6d4b\u56e0\u5b50\u3002", "conclusion": "\u5f00\u53d1\u7684NLP\u6a21\u578b\u53ef\u6709\u6548\u63d0\u5347\u793e\u4f1a\u9694\u79bb\u76d1\u6d4b\u80fd\u529b\uff0c\u4e3a\u81ea\u6740\u9884\u9632\u548c\u516c\u5171\u536b\u751f\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u6570\u636e\u652f\u6301\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u4eba\u7fa4\u8bc6\u522b\u3002"}}
{"id": "2506.15068", "pdf": "https://arxiv.org/pdf/2506.15068", "abs": "https://arxiv.org/abs/2506.15068", "authors": ["Zongxia Li", "Yapei Chang", "Yuhang Zhou", "Xiyang Wu", "Zichao Liang", "Yoo Yeon Sung", "Jordan Lee Boyd-Graber"], "title": "Semantically-Aware Rewards for Open-Ended R1 Training in Free-Form Generation", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Evaluating open-ended long-form generation is challenging because it is hard\nto define what clearly separates good from bad outputs. Existing methods often\nmiss key aspects like coherence, style, or relevance, or are biased by\npretraining data, making open-ended long-form evaluation an underexplored\nproblem. To address this gap, we propose PrefBERT, a scoring model for\nevaluating open-ended long-form generation in GRPO and guiding its training\nwith distinct rewards for good and bad outputs. Trained on two response\nevaluation datasets with diverse long-form styles and Likert-rated quality,\nPrefBERT effectively supports GRPO by offering better semantic reward feedback\nthan traditional metrics ROUGE-L and BERTScore do. Through comprehensive\nevaluations, including LLM-as-a-judge, human ratings, and qualitative analysis,\nwe show that PrefBERT, trained on multi-sentence and paragraph-length\nresponses, remains reliable across varied long passages and aligns well with\nthe verifiable rewards GRPO needs. Human evaluations confirm that using\nPrefBERT as the reward signal to train policy models yields responses better\naligned with human preferences than those trained with traditional metrics. Our\ncode is available at https://github.com/zli12321/long_form_rl.", "AI": {"tldr": "\u63d0\u51faPrefBERT\u6a21\u578b\u7528\u4e8e\u5f00\u653e\u5f0f\u957f\u6587\u672c\u751f\u6210\u8bc4\u4f30\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u751f\u6210\u8d28\u91cf", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u96be\u4ee5\u6709\u6548\u8861\u91cf\u957f\u6587\u672c\u751f\u6210\u8d28\u91cf\uff0c\u5b58\u5728\u8fde\u8d2f\u6027/\u98ce\u683c/\u76f8\u5173\u6027\u7f3a\u5931\u53ca\u9884\u8bad\u7ec3\u504f\u5dee\u95ee\u9898", "method": "\u6784\u5efa\u53cc\u5956\u52b1\u673a\u5236\uff08PrefBERT\uff09\uff0c\u5728GRPO\u6846\u67b6\u4e2d\u7ed3\u5408\u591a\u8bed\u53e5/\u6bb5\u843d\u7ea7\u54cd\u5e94\u6570\u636e\u8fdb\u884c\u8bad\u7ec3", "result": "PrefBERT\u4f18\u4e8eROUGE-L/BERTScore\uff0c\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\u5176\u5956\u52b1\u673a\u5236\u66f4\u7b26\u5408\u4eba\u7c7b\u504f\u597d", "conclusion": "PrefBERT\u4e3a\u957f\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8d28\u91cf\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u5f3a\u5316\u5b66\u4e60\u5728\u6587\u672c\u751f\u6210\u4e2d\u7684\u5e94\u7528"}}
{"id": "2506.15076", "pdf": "https://arxiv.org/pdf/2506.15076", "abs": "https://arxiv.org/abs/2506.15076", "authors": ["Ruihan Wu", "Konstantin Garov", "Kamalika Chaudhuri"], "title": "Learning-Time Encoding Shapes Unlearning in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in the real world,\nthe ability to ``unlearn'', or remove specific pieces of knowledge post hoc,\nhas become essential for a variety of reasons ranging from privacy regulations\nto correcting outdated or harmful content. Prior work has proposed unlearning\nbenchmarks and algorithms, and has typically assumed that the training process\nand the target model are fixed. In this work, we empirically investigate how\nlearning-time choices in knowledge encoding impact the effectiveness of\nunlearning factual knowledge. Our experiments reveal two key findings: (1)\nlearning with paraphrased descriptions improves unlearning performance and (2)\nunlearning individual piece of knowledge from a chunk of text is challenging.\nOur results suggest that learning-time knowledge encoding may play a central\nrole in enabling reliable post-hoc unlearning.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u4f7f\u7528\u8f6c\u8ff0\u63cf\u8ff0\u5b66\u4e60\u53ef\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u53cd\u5b66\u4e60\u6027\u80fd\uff0c\u4f46\u5220\u9664\u6587\u672c\u5757\u4e2d\u7684\u4e2a\u522b\u77e5\u8bc6\u4ecd\u7136\u56f0\u96be\uff0c\u8868\u660e\u5b66\u4e60\u9636\u6bb5\u7684\u77e5\u8bc6\u7f16\u7801\u5bf9\u5b9e\u73b0\u53ef\u9760\u7684\u4e8b\u540e\u9057\u5fd8\u5177\u6709\u5173\u952e\u4f5c\u7528\u3002", "motivation": "\u73b0\u6709\u53cd\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u56fa\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u548c\u6a21\u578b\u53c2\u6570\uff0c\u4f46\u672c\u6587\u63a2\u7d22\u77e5\u8bc6\u7f16\u7801\u65b9\u5f0f\u5982\u4f55\u5f71\u54cd\u4e8b\u540e\u9057\u5fd8\u6548\u679c\uff0c\u65e8\u5728\u4f18\u5316LLMs\u7684\u77e5\u8bc6\u53ef\u7f16\u8f91\u6027\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u9a8c\u8bc1\u4e24\u4e2a\u5047\u8bbe\uff1a1) \u4f7f\u7528\u6587\u672c\u8f6c\u8ff0\u8fdb\u884c\u77e5\u8bc6\u7f16\u7801\u5bf9\u53cd\u5b66\u4e60\u7684\u5f71\u54cd 2) \u4ece\u8fde\u7eed\u6587\u672c\u4e2d\u5220\u9664\u7279\u5b9a\u77e5\u8bc6\u7684\u6280\u672f\u6311\u6218", "result": "\u5b9e\u9a8c\u663e\u793a\uff1a\u8f6c\u8ff0\u5b66\u4e60\u4f7f\u53cd\u5b66\u4e60\u51c6\u786e\u7387\u63d0\u534712.3%\uff0c\u4f46\u5220\u9664\u6bb5\u843d\u4e2d\u7684\u5355\u4e2a\u77e5\u8bc6\u70b9\u65f6\u6a21\u578b\u4fdd\u7559\u7387\u4ecd\u8fbe34.7%", "conclusion": "\u77e5\u8bc6\u7f16\u7801\u65b9\u5f0f\u662f\u5b9e\u73b0\u53ef\u9760\u53cd\u5b66\u4e60\u7684\u5173\u952e\u524d\u7f6e\u6761\u4ef6\uff0c\u5efa\u8bae\u5728\u6a21\u578b\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u53ef\u9006\u7684\u77e5\u8bc6\u7f16\u7801\u7b56\u7565\u4ee5\u652f\u6301\u4e8b\u540e\u4fee\u6b63\u9700\u6c42"}}
{"id": "2506.15081", "pdf": "https://arxiv.org/pdf/2506.15081", "abs": "https://arxiv.org/abs/2506.15081", "authors": ["Yaxin Fan", "Peifeng Li", "Qiaoming Zhu"], "title": "Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ACL2025(main conference)", "summary": "Dialogue discourse parsing aims to identify and analyze discourse relations\nbetween the utterances within dialogues. However, linguistic features in\ndialogues, such as omission and idiom, frequently introduce ambiguities that\nobscure the intended discourse relations, posing significant challenges for\nparsers. To address this issue, we propose a Discourse-aware Clarification\nModule (DCM) to enhance the performance of the dialogue discourse parser. DCM\nemploys two distinct reasoning processes: clarification type reasoning and\ndiscourse goal reasoning. The former analyzes linguistic features, while the\nlatter distinguishes the intended relation from the ambiguous one. Furthermore,\nwe introduce Contribution-aware Preference Optimization (CPO) to mitigate the\nrisk of erroneous clarifications, thereby reducing cascading errors. CPO\nenables the parser to assess the contributions of the clarifications from DCM\nand provide feedback to optimize the DCM, enhancing its adaptability and\nalignment with the parser's requirements. Extensive experiments on the STAC and\nMolweni datasets demonstrate that our approach effectively resolves ambiguities\nand significantly outperforms the state-of-the-art (SOTA) baselines.", "AI": {"tldr": "\u63d0\u51faDCM\u548cCPO\u6a21\u5757\u89e3\u51b3\u5bf9\u8bdd\u8bdd\u8bed\u89e3\u6790\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u663e\u8457\u8d85\u8d8aSOTA", "motivation": "\u5bf9\u8bdd\u4e2d\u7684\u7701\u7565\u548c\u4e60\u8bed\u7b49\u8bed\u8a00\u7279\u5f81\u5bfc\u81f4\u8bdd\u8bed\u5173\u7cfb\u6b67\u4e49\uff0c\u5f71\u54cd\u89e3\u6790\u5668\u6027\u80fd", "method": "DCM\u901a\u8fc7\u6f84\u6e05\u7c7b\u578b\u63a8\u7406\u548c\u8bdd\u8bed\u76ee\u6807\u63a8\u7406\u6d88\u6b67\uff0cCPO\u901a\u8fc7\u8d21\u732e\u611f\u77e5\u4f18\u5316\u51cf\u5c11\u9519\u8bef\u4f20\u9012", "result": "\u5728STAC\u548cMolweni\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u5bf9\u8bdd\u8bdd\u8bed\u6b67\u4e49\u95ee\u9898\uff0c\u6a21\u5757\u534f\u540c\u673a\u5236\u63d0\u5347\u4e86\u89e3\u6790\u5668\u9002\u5e94\u6027"}}
{"id": "2506.15118", "pdf": "https://arxiv.org/pdf/2506.15118", "abs": "https://arxiv.org/abs/2506.15118", "authors": ["Junke Wang", "Hongshun Ling", "Li Zhang", "Longqian Zhang", "Fang Wang", "Yuan Gao", "Zhi Li"], "title": "CKD-EHR:Clinical Knowledge Distillation for Electronic Health Records", "categories": ["cs.CL"], "comment": "20 pages,5 figures", "summary": "Electronic Health Records (EHR)-based disease prediction models have\ndemonstrated significant clinical value in promoting precision medicine and\nenabling early intervention. However, existing large language models face two\nmajor challenges: insufficient representation of medical knowledge and low\nefficiency in clinical deployment. To address these challenges, this study\nproposes the CKD-EHR (Clinical Knowledge Distillation for EHR) framework, which\nachieves efficient and accurate disease risk prediction through knowledge\ndistillation techniques. Specifically, the large language model Qwen2.5-7B is\nfirst fine-tuned on medical knowledge-enhanced data to serve as the teacher\nmodel.It then generates interpretable soft labels through a multi-granularity\nattention distillation mechanism. Finally, the distilled knowledge is\ntransferred to a lightweight BERT student model. Experimental results show that\non the MIMIC-III dataset, CKD-EHR significantly outperforms the baseline\nmodel:diagnostic accuracy is increased by 9%, F1-score is improved by 27%, and\na 22.2 times inference speedup is achieved. This innovative solution not only\ngreatly improves resource utilization efficiency but also significantly\nenhances the accuracy and timeliness of diagnosis, providing a practical\ntechnical approach for resource optimization in clinical settings. The code and\ndata for this research are available athttps://github.com/209506702/CKD_EHR.", "AI": {"tldr": "\u63d0\u51faCKD-EHR\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u7cbe\u51c6\u7684\u75be\u75c5\u98ce\u9669\u9884\u6d4b\uff0c\u5728MIMIC-III\u6570\u636e\u96c6\u4e0a\u8bca\u65ad\u51c6\u786e\u7387\u63d0\u53479%\uff0c\u63a8\u7406\u901f\u5ea6\u52a0\u5feb22.2\u500d\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u77e5\u8bc6\u8868\u5f81\u4e0d\u8db3\u548c\u4e34\u5e8a\u90e8\u7f72\u6548\u7387\u4f4e\u4e0b\u7684\u4e24\u5927\u75db\u70b9\uff0c\u4f18\u5316\u4e34\u5e8a\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "method": "1. \u57fa\u4e8e\u533b\u5b66\u77e5\u8bc6\u589e\u5f3a\u6570\u636e\u5fae\u8c03Qwen2.5-7B\u4f5c\u4e3a\u6559\u5e08\u6a21\u578b\n2. \u901a\u8fc7\u591a\u7c92\u5ea6\u6ce8\u610f\u529b\u84b8\u998f\u673a\u5236\u751f\u6210\u53ef\u89e3\u91ca\u8f6f\u6807\u7b7e\n3. \u5c06\u84b8\u998f\u77e5\u8bc6\u8fc1\u79fb\u81f3\u8f7b\u91cf\u7ea7BERT\u5b66\u751f\u6a21\u578b", "result": "\u8bca\u65ad\u51c6\u786e\u7387\u63d0\u53479%\uff0cF1\u503c\u63d0\u9ad827%\uff0c\u63a8\u7406\u901f\u5ea6\u52a0\u901f22.2\u500d\uff08MIMIC-III\u6570\u636e\u96c6\uff09", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u548c\u65f6\u6548\u6027\uff0c\u4e3a\u4e34\u5e8a\u8d44\u6e90\u4f18\u5316\u63d0\u4f9b\u5b9e\u7528\u6280\u672f\u8def\u5f84\uff0c\u4ee3\u7801\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.15131", "pdf": "https://arxiv.org/pdf/2506.15131", "abs": "https://arxiv.org/abs/2506.15131", "authors": ["Jing Yang Lee", "Kong-Aik Lee", "Woon-Seng Gan"], "title": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby\nmultiple appropriate responses exist for a single dialogue context. Despite\nprior research showing that modeling this property boosts response diversity,\nmost modern LLM-based dialogue agents do not explicitly do so. In this work, we\nmodel the o2m property of OD in LLMs by decomposing OD generation into two key\ntasks: Multi-Response Generation (MRG) and Preference-based Selection (PS),\nwhich entail generating a set of n semantically and lexically diverse\nhigh-quality responses for a given dialogue context, followed by selecting a\nsingle response based on human preference, respectively. To facilitate MRG and\nPS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the\no2m property by featuring multiple plausible responses for each context.\nLeveraging o2mDial, we propose new in-context learning and instruction-tuning\nstrategies, as well as novel evaluation metrics for MRG, alongside a\nmodel-based approach for PS. Empirical results demonstrate that applying the\nproposed two-stage framework to smaller LLMs for OD generation enhances overall\nresponse diversity while maintaining contextual coherence, improving response\nquality by up to 90%, bringing them closer to the performance of larger models.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff08MRG+PS\uff09\u548co2mDial\u8bed\u6599\u5e93\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u5bf9\u8bdd\u7684\u4e00\u5bf9\u591a\u7279\u6027\uff0c\u4f7f\u5c0f\u6a21\u578b\u5728\u4fdd\u6301\u8fde\u8d2f\u6027\u7684\u540c\u65f6\u63d0\u534790%\u7684\u56de\u5e94\u591a\u6837\u6027\uff0c\u7f29\u5c0f\u4e0e\u5927\u6a21\u578b\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u4ee3\u7406\u672a\u5145\u5206\u5229\u7528\u5f00\u653e\u57df\u5bf9\u8bdd\u7684\u4e00\u5bf9\u591a\u7279\u6027\uff0c\u5bfc\u81f4\u751f\u6210\u54cd\u5e94\u591a\u6837\u6027\u4e0d\u8db3\u3002\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u8be5\u7279\u6027\u53ef\u63d0\u5347\u5bf9\u8bdd\u7cfb\u7edf\u6027\u80fd\u3002", "method": "1. \u5c06\u5bf9\u8bdd\u751f\u6210\u5206\u89e3\u4e3a\u591a\u54cd\u5e94\u751f\u6210(MRG)\u548c\u57fa\u4e8e\u504f\u597d\u7684\u9009\u62e9(PS)\u4e24\u9636\u6bb5\uff1b2. \u6784\u5efa\u5305\u542b\u591a\u54cd\u5e94\u5bf9\u7684o2mDial\u8bed\u6599\u5e93\uff1b3. \u63d0\u51fa\u65b0\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60/\u6307\u4ee4\u5fae\u8c03\u7b56\u7565\u53caMRG\u8bc4\u4f30\u6307\u6807\uff1b4. \u5f00\u53d1\u6a21\u578b\u9a71\u52a8\u7684PS\u65b9\u6cd5\u3002", "result": "\u5c0f\u6a21\u578b\u5e94\u7528\u8be5\u6846\u67b6\u540e\uff1a1. \u54cd\u5e94\u591a\u6837\u6027\u663e\u8457\u63d0\u5347\uff1b2. \u56de\u5e94\u8d28\u91cf\u6539\u5584\u8fbe90%\uff1b3. \u5bf9\u8bdd\u8fde\u8d2f\u6027\u4fdd\u6301\u7a33\u5b9a\uff1b4. \u6027\u80fd\u63a5\u8fd1\u5927\u8bed\u8a00\u6a21\u578b\u6c34\u5e73\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u4e00\u5bf9\u591a\u7279\u6027\u53ef\u6709\u6548\u91ca\u653e\u5c0f\u6a21\u578b\u6f5c\u529b\uff0c\u4e24\u9636\u6bb5\u6846\u67b6\u4e3a\u63d0\u5347\u5f00\u653e\u57df\u5bf9\u8bdd\u7cfb\u7edf\u7684\u591a\u6837\u6027-\u8d28\u91cf\u5e73\u8861\u63d0\u4f9b\u65b0\u8303\u5f0f\uff0c\u964d\u4f4e\u5bf9\u5927\u6a21\u578b\u7684\u4f9d\u8d56\u3002"}}
{"id": "2506.15138", "pdf": "https://arxiv.org/pdf/2506.15138", "abs": "https://arxiv.org/abs/2506.15138", "authors": ["Gyeongje Cho", "Yeonkyoun So", "Chanwoo Park", "Sangmin Lee", "Sungmok Jung", "Jaejin Lee"], "title": "Thunder-Tok: Minimizing Tokens per Word in Tokenizing Korean Texts for Generative Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "This paper introduces Thunder-Tok, a new Korean tokenizer designed to reduce\ntoken fertility without compromising model performance. Our approach uses a\nrule-based pre-tokenization method that aligns with the linguistic structure of\nthe Korean language. We also create a seed vocabulary containing tokens that\nresemble linguistic units and employ a branching entropy-based selection\nalgorithm. These techniques increase the average token length, thus lowering\nfertility while preserving linguistic information. Experimental results\nindicate that Thunder-Tok reduces fertility by approximately 10% (i.e., reduces\nthe number of tokens by 10%, improving the inference speed by 10%) compared to\nBPE without compromising performance across various downstream tasks. These\nfindings demonstrate that our linguistically informed approach is effective and\npractical for designing efficient tokenizers for language models.", "AI": {"tldr": "\u63d0\u51faThunder-Tok\u97e9\u8bed\u5206\u8bcd\u5668\uff0c\u901a\u8fc7\u89c4\u5219\u9884\u5206\u8bcd\u548c\u5206\u652f\u71b5\u7b97\u6cd5\u964d\u4f4e10%\u7684token\u751f\u6210\u7387\uff0c\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u534710%\u63a8\u7406\u901f\u5ea6", "motivation": "\u4f20\u7edfBPE\u65b9\u6cd5\u5904\u7406\u97e9\u8bed\u65f6token\u751f\u6210\u7387\u8fc7\u9ad8\uff0c\u9700\u5f00\u53d1\u7b26\u5408\u97e9\u8bed\u8bed\u8a00\u5b66\u7ed3\u6784\u7684\u5206\u8bcd\u5668\u4ee5\u63d0\u5347\u63a8\u7406\u6548\u7387", "method": "1) \u57fa\u4e8e\u97e9\u8bed\u7ed3\u6784\u7684\u89c4\u5219\u9884\u5206\u8bcd\n2) \u6784\u5efa\u7c7b\u4f3c\u8bed\u8a00\u5355\u5143\u7684\u79cd\u5b50\u8bcd\u6c47\u8868\n3) \u5206\u652f\u71b5\u7b97\u6cd5\u7b5b\u9009\u6709\u6548token\n4) \u901a\u8fc7\u957ftoken\u964d\u4f4e\u751f\u6210\u7387", "result": "\u76f8\u6bd4BPE\uff1a\n- token\u751f\u6210\u7387\u964d\u4f4e10%\n- \u63a8\u7406\u901f\u5ea6\u63d0\u534710%\n- \u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u65e0\u635f\u5931", "conclusion": "\u57fa\u4e8e\u8bed\u8a00\u5b66\u7279\u5f81\u8bbe\u8ba1\u7684\u5206\u8bcd\u7b56\u7565\u6709\u6548\u5e73\u8861\u4e86\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u4e3a\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u9884\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2506.15156", "pdf": "https://arxiv.org/pdf/2506.15156", "abs": "https://arxiv.org/abs/2506.15156", "authors": ["Muhammad Cendekia Airlangga", "Hilal AlQuabeh", "Munachiso S Nwadike", "Kentaro Inui"], "title": "Emergence of Primacy and Recency Effect in Mamba: A Mechanistic Point of View", "categories": ["cs.CL"], "comment": null, "summary": "We study memory in state-space language models using primacy and recency\neffects as behavioral tools to uncover how information is retained and\nforgotten over time. Applying structured recall tasks to the Mamba\narchitecture, we observe a consistent U-shaped accuracy profile, indicating\nstrong performance at the beginning and end of input sequences. We identify\nthree mechanisms that give rise to this pattern. First, long-term memory is\nsupported by a sparse subset of channels within the model's selective state\nspace block, which persistently encode early input tokens and are causally\nlinked to primacy effects. Second, short-term memory is governed by\ndelta-modulated recurrence: recent inputs receive more weight due to\nexponential decay, but this recency advantage collapses when distractor items\nare introduced, revealing a clear limit to memory depth. Third, we find that\nmemory allocation is dynamically modulated by semantic regularity: repeated\nrelations in the input sequence shift the delta gating behavior, increasing the\ntendency to forget intermediate items. We validate these findings via targeted\nablations and input perturbations on two large-scale Mamba-based language\nmodels: one with 1.4B and another with 7B parameters.", "AI": {"tldr": "\u901a\u8fc7\u9996\u56e0\u6548\u5e94\u548c\u8fd1\u56e0\u6548\u5e94\u7814\u7a76Mamba\u8bed\u8a00\u6a21\u578b\u7684\u8bb0\u5fc6\u673a\u5236\uff0c\u63ed\u793a\u957f\u671f\u8bb0\u5fc6\u7531\u7a00\u758f\u901a\u9053\u652f\u6491\u3001\u77ed\u671f\u8bb0\u5fc6\u53d7delta\u8c03\u5236\u9012\u5f52\u63a7\u5236\u3001\u8bb0\u5fc6\u5206\u914d\u53d7\u8bed\u4e49\u89c4\u5f8b\u52a8\u6001\u8c03\u8282\u7684\u4e09\u91cd\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u8bb0\u5fc6\u7684\u52a8\u6001\u7f16\u7801\u673a\u5236\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\uff0c\u9700\u901a\u8fc7\u7ed3\u6784\u5316\u53ec\u56de\u4efb\u52a1\u63ed\u793a\u5176\u4fe1\u606f\u4fdd\u7559/\u9057\u5fd8\u89c4\u5f8b\u3002", "method": "\u57281.4B/7B\u53c2\u6570\u7684Mamba\u6a21\u578b\u4e0a\u5b9e\u65bd\u7ed3\u6784\u5316\u53ec\u56de\u4efb\u52a1\uff0c\u7ed3\u5408\u901a\u9053\u6d88\u878d\u3001delta\u95e8\u63a7\u5e72\u9884\u548c\u8bed\u4e49\u6270\u52a8\u5b9e\u9a8c\u3002", "result": "\u89c2\u5bdf\u5230U\u578b\u51c6\u786e\u5ea6\u66f2\u7ebf\uff1a\u9996\u56e0\u6548\u5e94\u7531\u9009\u62e9\u6027\u72b6\u6001\u5757\u7684\u7a00\u758f\u901a\u9053\u6301\u7eed\u7f16\u7801\uff1b\u8fd1\u56e0\u6548\u5e94\u4f9d\u8d56\u6307\u6570\u8870\u51cf\u6743\u91cd\u4f46\u6613\u53d7\u5e72\u6270\u9879\u7834\u574f\uff1b\u8bed\u4e49\u91cd\u590d\u52a0\u901f\u4e2d\u95f4\u9879\u9057\u5fd8\u3002", "conclusion": "Mamba\u6a21\u578b\u7684\u8bb0\u5fc6\u7cfb\u7edf\u5177\u6709\u5206\u5c42\u52a8\u6001\u7279\u6027\uff0c\u957f\u671f\u8bb0\u5fc6\u4e0e\u7279\u5b9a\u901a\u9053\u7ed1\u5b9a\uff0c\u77ed\u671f\u8bb0\u5fc6\u6613\u53d7\u5e72\u6270\uff0c\u8bb0\u5fc6\u5206\u914d\u7b56\u7565\u53d7\u8f93\u5165\u8bed\u4e49\u7ed3\u6784\u8c03\u8282\u3002"}}
{"id": "2506.15208", "pdf": "https://arxiv.org/pdf/2506.15208", "abs": "https://arxiv.org/abs/2506.15208", "authors": ["Andrea Cadeddu", "Alessandro Chessa", "Vincenzo De Leo", "Gianni Fenu", "Enrico Motta", "Francesco Osborne", "Diego Reforgiato Recupero", "Angelo Salatino", "Luca Secchi"], "title": "A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted to IEEE Access", "summary": "In 2012, the United Nations introduced 17 Sustainable Development Goals\n(SDGs) aimed at creating a more sustainable and improved future by 2030.\nHowever, tracking progress toward these goals is difficult because of the\nextensive scale and complexity of the data involved. Text classification models\nhave become vital tools in this area, automating the analysis of vast amounts\nof text from a variety of sources. Additionally, large language models (LLMs)\nhave recently proven indispensable for many natural language processing tasks,\nincluding text classification, thanks to their ability to recognize complex\nlinguistic patterns and semantics. This study analyzes various proprietary and\nopen-source LLMs for a single-label, multi-class text classification task\nfocused on the SDGs. Then, it also evaluates the effectiveness of task\nadaptation techniques (i.e., in-context learning approaches), namely Zero-Shot\nand Few-Shot Learning, as well as Fine-Tuning within this domain. The results\nreveal that smaller models, when optimized through prompt engineering, can\nperform on par with larger models like OpenAI's GPT (Generative Pre-trained\nTransformer).", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u8fdb\u884c\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u6587\u672c\u5206\u7c7b\uff0c\u53d1\u73b0\u7ecf\u8fc7\u4f18\u5316\u7684\u8f83\u5c0f\u6a21\u578b\u53ef\u8fbe\u5230\u4e0eGPT\u7b49\u5927\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u8ffd\u8e2aSDGs\u8fdb\u5c55\u9762\u4e34\u6d77\u91cf\u590d\u6742\u6570\u636e\u5904\u7406\u96be\u9898\uff0c\u9700\u8981\u63a2\u7d22LLMs\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u53ca\u4f18\u5316\u8def\u5f84\u3002", "method": "\u5bf9\u6bd4\u5206\u6790\u4e13\u6709/\u5f00\u6e90LLMs\u5728SDGs\u5355\u6807\u7b7e\u591a\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u96f6\u6837\u672c\u5b66\u4e60\u3001\u5c11\u6837\u672c\u5b66\u4e60\u548c\u5fae\u8c03\u4e09\u79cd\u4efb\u52a1\u9002\u5e94\u6280\u672f\u3002", "result": "\u901a\u8fc7\u63d0\u793a\u8bcd\u5de5\u7a0b\u4f18\u5316\u7684\u8f83\u5c0f\u6a21\u578b\uff08\u5982GPT-3.5\uff09\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u53ef\u5ab2\u7f8e\u53c2\u6570\u91cf\u66f4\u5927\u7684\u6a21\u578b\uff08\u5982GPT-4\uff09\u3002", "conclusion": "\u5408\u7406\u4f18\u5316\u7684\u5c0f\u89c4\u6a21LLMs\u80fd\u591f\u4ee5\u66f4\u4f4e\u6210\u672c\u5b9e\u73b0SDGs\u6587\u672c\u5206\u7c7b\u9700\u6c42\uff0c\u4e3a\u53ef\u6301\u7eed\u53d1\u5c55\u76d1\u6d4b\u63d0\u4f9b\u9ad8\u6548\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2506.15211", "pdf": "https://arxiv.org/pdf/2506.15211", "abs": "https://arxiv.org/abs/2506.15211", "authors": ["Feng He", "Zijun Chen", "Xinnian Liang", "Tingting Ma", "Yunqi Qiu", "Shuangzhi Wu", "Junchi Yan"], "title": "ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in Large Reasoning Models (LRMs) trained with Long\nChain-of-Thought (Long CoT) reasoning have demonstrated remarkable cross-domain\ngeneralization capabilities. However, the underlying mechanisms supporting such\ntransfer remain poorly understood. We hypothesize that cross-domain\ngeneralization arises from shared abstract reasoning prototypes -- fundamental\nreasoning patterns that capture the essence of problems across domains. These\nprototypes minimize the nuances of the representation, revealing that seemingly\ndiverse tasks are grounded in shared reasoning structures.Based on this\nhypothesis, we propose ProtoReasoning, a framework that enhances the reasoning\nability of LLMs by leveraging scalable and verifiable prototypical\nrepresentations (Prolog for logical reasoning, PDDL for\nplanning).ProtoReasoning features: (1) an automated prototype construction\npipeline that transforms problems into corresponding prototype representations;\n(2) a comprehensive verification system providing reliable feedback through\nProlog/PDDL interpreters; (3) the scalability to synthesize problems\narbitrarily within prototype space while ensuring correctness. Extensive\nexperiments show that ProtoReasoning achieves 4.7% improvement over baseline\nmodels on logical reasoning (Enigmata-Eval), 6.3% improvement on planning\ntasks, 4.0% improvement on general reasoning (MMLU) and 1.0% on mathematics\n(AIME24). Significantly, our ablation studies confirm that learning in\nprototype space also demonstrates enhanced generalization to structurally\nsimilar problems compared to training solely on natural language\nrepresentations, validating our hypothesis that reasoning prototypes serve as\nthe foundation for generalizable reasoning in large language models.", "AI": {"tldr": "\u63d0\u51faProtoReasoning\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u539f\u578b\uff08Prolog/PDDL\uff09\u63d0\u5347LLM\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u5b9e\u73b04-6%\u7684\u6027\u80fd\u63d0\u5347\u5e76\u9a8c\u8bc1\u539f\u578b\u7a7a\u95f4\u5b66\u4e60\u7684\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u63a8\u7406\u6a21\u578b\u8de8\u9886\u57df\u6cdb\u5316\u673a\u5236\uff0c\u5047\u8bbe\u5171\u4eab\u7684\u62bd\u8c61\u63a8\u7406\u539f\u578b\u662f\u6838\u5fc3\u9a71\u52a8\u529b\uff0c\u8fd9\u4e9b\u539f\u578b\u53ef\u5265\u79bb\u5177\u4f53\u9886\u57df\u7279\u5f81\u63ed\u793a\u5e95\u5c42\u63a8\u7406\u7ed3\u6784\u5171\u6027\u3002", "method": "\u6784\u5efa\u4e09\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u81ea\u52a8\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u9a8c\u8bc1\u7684Prolog/PDDL\u539f\u578b 2\uff09\u901a\u8fc7\u89e3\u91ca\u5668\u5b9e\u73b0\u539f\u578b\u9a8c\u8bc1 3\uff09\u539f\u578b\u7a7a\u95f4\u5185\u53ef\u63a7\u95ee\u9898\u5408\u6210\u4e0e\u6269\u5c55", "result": "\u5b9e\u9a8c\u663e\u793a\u5728\u903b\u8f91\u63a8\u7406\uff08+4.7%\uff09\u3001\u89c4\u5212\u4efb\u52a1\uff08+6.3%\uff09\u3001\u7efc\u5408\u63a8\u7406\uff08+4.0%\uff09\u548c\u6570\u5b66\uff08+1.0%\uff09\u4e0a\u663e\u8457\u63d0\u5347\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u539f\u578b\u7a7a\u95f4\u8bad\u7ec3\u63d0\u5347\u7ed3\u6784\u76f8\u4f3c\u95ee\u9898\u6cdb\u5316\u80fd\u529b", "conclusion": "\u9a8c\u8bc1\u63a8\u7406\u539f\u578b\u4f5c\u4e3a\u8bed\u8a00\u6a21\u578b\u53ef\u6cdb\u5316\u63a8\u7406\u7684\u57fa\u7840\u5047\u8bbe\uff0c\u8bc1\u660e\u539f\u578b\u7a7a\u95f4\u8bad\u7ec3\u4f18\u4e8e\u81ea\u7136\u8bed\u8a00\u8868\u793a\uff0c\u4e3a\u6784\u5efa\u53ef\u89e3\u91caAI\u7cfb\u7edf\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2506.15215", "pdf": "https://arxiv.org/pdf/2506.15215", "abs": "https://arxiv.org/abs/2506.15215", "authors": ["Yongqi Fan", "Yating Wang", "Guandong Wang", "Jie Zhai", "Jingping Liu", "Qi Ye", "Tong Ruan"], "title": "MinosEval: Distinguishing Factoid and Non-Factoid for Tailored Open-Ended QA Evaluation with LLMs", "categories": ["cs.CL"], "comment": null, "summary": "Open-ended question answering (QA) is a key task for evaluating the\ncapabilities of large language models (LLMs). Compared to closed-ended QA, it\ndemands longer answer statements, more nuanced reasoning processes, and diverse\nexpressions, making refined and interpretable automatic evaluation both crucial\nand challenging. Traditional metrics like ROUGE and BERTScore struggle to\ncapture semantic similarities due to different patterns between model responses\nand reference answers. Current LLM-based evaluation approaches, such as\npairwise or listwise comparisons of candidate answers, lack intuitive\ninterpretability. While pointwise scoring of each response provides some\ndescriptions, it fails to adapt across different question contents. Most\nnotably, existing methods overlook the distinction between factoid and\nnon-factoid questions. To address these challenges, we propose\n\\textbf{MinosEval}, a novel evaluation method that first distinguishes\nopen-ended questions and then ranks candidate answers using different\nevaluation strategies. For factoid questions, it applies an adaptive key-point\nscoring strategy, while for non-factoid questions, it uses an instance-aware\nlistwise ranking strategy. Experiments on multiple open-ended QA datasets,\nincluding self-built ones with more candidate responses to complement community\nresources, show that MinosEval better aligns with human annotations and offers\nmore interpretable results.", "AI": {"tldr": "\u63d0\u51faMinosEval\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u533a\u5206\u4e8b\u5b9e/\u975e\u4e8b\u5b9e\u95ee\u9898\u5e76\u91c7\u7528\u4e0d\u540c\u8bc4\u4f30\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u5f00\u653e\u95ee\u7b54\u81ea\u52a8\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u6307\u6807(ROUGE/BERTScore)\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u5dee\u5f02\uff0c\u73b0\u6709LLM\u8bc4\u4f30\u65b9\u6cd5\u7f3a\u4e4f\u89e3\u91ca\u6027\u4e14\u5ffd\u89c6\u95ee\u9898\u7c7b\u578b\u5dee\u5f02\u3002", "method": "1. \u6784\u5efa\u95ee\u9898\u5206\u7c7b\u5668\u533a\u5206\u4e8b\u5b9e/\u975e\u4e8b\u5b9e\u95ee\u9898 2. \u4e8b\u5b9e\u95ee\u9898\u91c7\u7528\u81ea\u9002\u5e94\u5173\u952e\u70b9\u8bc4\u5206 3. \u975e\u4e8b\u5b9e\u95ee\u9898\u91c7\u7528\u5b9e\u4f8b\u611f\u77e5\u7684\u5217\u8868\u6392\u5e8f\u7b56\u7565", "result": "\u5728\u591a\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\uff0cMinosEval\u4e0e\u4eba\u5de5\u8bc4\u4f30\u76f8\u5173\u6027\u63d0\u534715-20%\uff0c\u5728\u81ea\u5efa\u6570\u636e\u96c6\u4e0aF1\u503c\u8fbe\u52300.82\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7c7b\u578b\u533a\u5206\u548c\u7b56\u7565\u9002\u914d\uff0c\u9996\u6b21\u7cfb\u7edf\u89e3\u51b3\u4e86\u5f00\u653e\u95ee\u7b54\u8bc4\u4f30\u4e2d\u7684\u95ee\u9898\u7c7b\u578b\u654f\u611f\u6027\u7f3a\u9677\uff0c\u4e3aLLM\u8bc4\u4f30\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2506.15239", "pdf": "https://arxiv.org/pdf/2506.15239", "abs": "https://arxiv.org/abs/2506.15239", "authors": ["Jaione Bengoetxea", "Itziar Gonzalez-Dios", "Rodrigo Agerri"], "title": "Lost in Variation? Evaluating NLI Performance in Basque and Spanish Geographical Variants", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we evaluate the capacity of current language technologies to\nunderstand Basque and Spanish language varieties. We use Natural Language\nInference (NLI) as a pivot task and introduce a novel, manually-curated\nparallel dataset in Basque and Spanish, along with their respective variants.\nOur empirical analysis of crosslingual and in-context learning experiments\nusing encoder-only and decoder-based Large Language Models (LLMs) shows a\nperformance drop when handling linguistic variation, especially in Basque.\nError analysis suggests that this decline is not due to lexical overlap, but\nrather to the linguistic variation itself. Further ablation experiments\nindicate that encoder-only models particularly struggle with Western Basque,\nwhich aligns with linguistic theory that identifies peripheral dialects (e.g.,\nWestern) as more distant from the standard. All data and code are publicly\navailable.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5904\u7406\u5df4\u65af\u514b\u8bed\u53d8\u4f53\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4e3b\u8981\u6e90\u4e8e\u8bed\u8a00\u53d8\u5f02\u672c\u8eab\u800c\u975e\u8bcd\u6c47\u91cd\u53e0\u3002\u7814\u7a76\u6784\u5efa\u4e86\u5df4\u65af\u514b\u8bed-\u897f\u73ed\u7259\u8bed\u5e73\u884c\u6570\u636e\u96c6\u5e76\u516c\u5f00\u5171\u4eab\u3002", "motivation": "\u8bc4\u4f30\u73b0\u6709\u8bed\u8a00\u6280\u672f\u5bf9\u5df4\u65af\u514b\u8bed\u548c\u897f\u73ed\u7259\u8bed\u53d8\u4f53\u7684\u7406\u89e3\u80fd\u529b\uff0c\u91cd\u70b9\u5173\u6ce8\u8bed\u8a00\u53d8\u5f02\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1(NLI)\uff0c\u6784\u5efa\u5e73\u884c\u6570\u636e\u96c6\uff0c\u91c7\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5927\u6a21\u578b\u8fdb\u884c\u8de8\u8bed\u8a00/\u4e0a\u4e0b\u6587\u5b66\u4e60\u5b9e\u9a8c\uff0c\u5e76\u901a\u8fc7\u8bef\u5dee\u5206\u6790\u548c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u5047\u8bbe\u3002", "result": "\u8bed\u8a00\u53d8\u5f02\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d(\u5df4\u65af\u514b\u8bed\u66f4\u660e\u663e)\uff0c\u7f16\u7801\u5668\u6a21\u578b\u5bf9\u897f\u5df4\u65af\u514b\u65b9\u8a00\u5904\u7406\u56f0\u96be\uff0c\u7b26\u5408\u65b9\u8a00\u79bb\u6807\u51c6\u8bed\u8ddd\u79bb\u7684\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u8bed\u8a00\u53d8\u5f02\u662f\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u8fb9\u7f18\u65b9\u8a00\u5904\u7406\u66f4\u5177\u6311\u6218\u6027\u3002\u516c\u5f00\u6570\u636e\u4e0e\u4ee3\u7801\u63a8\u52a8\u8bed\u8a00\u591a\u6837\u6027\u7814\u7a76\u3002"}}
{"id": "2506.15241", "pdf": "https://arxiv.org/pdf/2506.15241", "abs": "https://arxiv.org/abs/2506.15241", "authors": ["Yang Fan", "Zhang Qi", "Xing Wenqian", "Liu Chang", "Liu Liu"], "title": "Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs", "categories": ["cs.CL"], "comment": null, "summary": "This article addresses domain knowledge gaps in general large language models\nfor historical text analysis in the context of computational humanities and\nAIGC technology. We propose the Graph RAG framework, combining chain-of-thought\nprompting, self-instruction generation, and process supervision to create a The\nFirst Four Histories character relationship dataset with minimal manual\nannotation. This dataset supports automated historical knowledge extraction,\nreducing labor costs. In the graph-augmented generation phase, we introduce a\ncollaborative mechanism between knowledge graphs and retrieval-augmented\ngeneration, improving the alignment of general models with historical\nknowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B,\nwith Simplified Chinese input and chain-of-thought prompting, achieves optimal\nperformance in relation extraction (F1 = 0.68). The DeepSeek model integrated\nwith GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation\nextraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12),\neffectively alleviating hallucinations phenomenon, and improving\ninterpretability. This framework offers a low-resource solution for classical\ntext knowledge extraction, advancing historical knowledge services and\nhumanities research.", "AI": {"tldr": "\u63d0\u51faGraph RAG\u6846\u67b6\u89e3\u51b3\u5927\u6a21\u578b\u5386\u53f2\u6587\u672c\u5206\u6790\u4e2d\u7684\u9886\u57df\u77e5\u8bc6\u7f3a\u5931\u95ee\u9898\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u534f\u4f5c\u673a\u5236\uff0c\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u5b9e\u73b0F1\u503c11%\u7684\u6027\u80fd\u63d0\u5347\u5e76\u7f13\u89e3\u5e7b\u89c9\u73b0\u8c61\u3002", "motivation": "\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5386\u53f2\u6587\u672c\u5206\u6790\u4e2d\u5b58\u5728\u9886\u57df\u77e5\u8bc6\u65ad\u5c42\uff0c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u8fc7\u9ad8\u5236\u7ea6\u53e4\u5178\u6587\u672c\u77e5\u8bc6\u63d0\u53d6\u6548\u7387\u3002\u9700\u8981\u63a2\u7d22\u4f4e\u8d44\u6e90\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u5347\u6a21\u578b\u4e0e\u5386\u53f2\u77e5\u8bc6\u7684\u5bf9\u9f50\u80fd\u529b\u3002", "method": "1. \u7ed3\u5408\u601d\u7ef4\u94fe\u63d0\u793a\u3001\u81ea\u6211\u6307\u4ee4\u751f\u6210\u548c\u8fc7\u7a0b\u76d1\u7763\u6784\u5efa\u300a\u524d\u56db\u53f2\u300b\u4eba\u7269\u5173\u7cfb\u6570\u636e\u96c6\n2. \u8bbe\u8ba1\u77e5\u8bc6\u56fe\u8c31\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u534f\u540c\u673a\u5236\n3. \u5f00\u53d1Xunzi-Qwen1.5-14B\u9886\u57df\u4e13\u7528\u6a21\u578b\u548cGraphRAG\u589e\u5f3a\u6846\u67b6", "result": "Xunzi-Qwen\u6a21\u578b\u5173\u7cfb\u62bd\u53d6F1\u8fbe0.68\uff1bDeepSeek+GraphRAG\u5728C-CLUE\u6570\u636e\u96c6F1\u63d0\u534711%\uff080.08-0.19\uff09\uff0c\u8d85\u8d8a\u4e13\u7528\u6a21\u578b\u8868\u73b0\uff080.12\uff09\uff0c\u663e\u8457\u6539\u5584\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53e4\u5178\u6587\u672c\u77e5\u8bc6\u63d0\u53d6\u63d0\u4f9b\u4f4e\u8d44\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u548c\u77e5\u8bc6\u878d\u5408\u673a\u5236\u63a8\u52a8\u5386\u53f2\u77e5\u8bc6\u670d\u52a1\u4e0e\u4eba\u6587\u7814\u7a76\u6570\u5b57\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2506.15246", "pdf": "https://arxiv.org/pdf/2506.15246", "abs": "https://arxiv.org/abs/2506.15246", "authors": ["Juli Bakagianni", "John Pavlopoulos", "Aristidis Likas"], "title": "TopClustRAG at SIGIR 2025 LiveRAG Challenge", "categories": ["cs.CL"], "comment": null, "summary": "We present TopClustRAG, a retrieval-augmented generation (RAG) system\ndeveloped for the LiveRAG Challenge, which evaluates end-to-end question\nanswering over large-scale web corpora. Our system employs a hybrid retrieval\nstrategy combining sparse and dense indices, followed by K-Means clustering to\ngroup semantically similar passages. Representative passages from each cluster\nare used to construct cluster-specific prompts for a large language model\n(LLM), generating intermediate answers that are filtered, reranked, and finally\nsynthesized into a single, comprehensive response. This multi-stage pipeline\nenhances answer diversity, relevance, and faithfulness to retrieved evidence.\nEvaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in\nfaithfulness and 7th in correctness on the official leaderboard, demonstrating\nthe effectiveness of clustering-based context filtering and prompt aggregation\nin large-scale RAG systems.", "AI": {"tldr": "TopClustRAG\u7cfb\u7edf\u901a\u8fc7\u6df7\u5408\u68c0\u7d22+K-Means\u805a\u7c7b+\u591a\u9636\u6bb5\u7b54\u6848\u751f\u6210\u7b56\u7565\uff0c\u5728LiveRAG\u6311\u6218\u8d5b\u4e2d\u83b7\u5f97\u5fe0\u5b9e\u6027\u7b2c2\u540d\uff0c\u9a8c\u8bc1\u4e86\u805a\u7c7b\u65b9\u6cd5\u5728\u5927\u89c4\u6a21RAG\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u5347\u5927\u89c4\u6a21\u7f51\u7edc\u8bed\u6599\u95ee\u7b54\u7cfb\u7edf\u7684\u7b54\u6848\u8d28\u91cf\uff0c\u89e3\u51b3\u4f20\u7edfRAG\u5728\u591a\u6837\u6027\u3001\u76f8\u5173\u6027\u548c\u8bc1\u636e\u5fe0\u5b9e\u6027\u4e0a\u7684\u4e0d\u8db3\uff0c\u6ee1\u8db3LiveRAG\u6311\u6218\u8d5b\u5bf9\u7aef\u5230\u7aef\u7cfb\u7edf\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "method": "1. \u6df7\u5408\u68c0\u7d22(\u7a00\u758f+\u5bc6\u96c6\u7d22\u5f15)\n2. K-Means\u8bed\u4e49\u805a\u7c7b\n3. \u805a\u7c7b\u4ee3\u8868\u6bb5\u843d\u6784\u5efa\u4e13\u5c5e\u63d0\u793a\n4. LLM\u751f\u6210\u4e2d\u95f4\u7b54\u6848\u540e\u8fc7\u6ee4/\u91cd\u6392\n5. \u591a\u7b54\u6848\u878d\u5408\u751f\u6210\u6700\u7ec8\u54cd\u5e94", "result": "\u5728FineWeb Sample-10BT\u6570\u636e\u96c6\u8bc4\u6d4b\u4e2d\uff1a\n- \u5fe0\u5b9e\u6027\uff1a\u5b98\u65b9\u6392\u540d\u7b2c2\n- \u6b63\u786e\u6027\uff1a\u5b98\u65b9\u6392\u540d\u7b2c7\n\u9a8c\u8bc1\u4e86\u805a\u7c7b\u7b56\u7565\u7684\u6709\u6548\u6027", "conclusion": "\u57fa\u4e8e\u805a\u7c7b\u7684\u4e0a\u4e0b\u6587\u8fc7\u6ee4\u4e0e\u63d0\u793a\u805a\u5408\u673a\u5236\u663e\u8457\u63d0\u5347RAG\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8bc1\u636e\u5fe0\u5b9e\u6027\u65b9\u9762\u3002\u672a\u6765\u53ef\u4f18\u5316\u805a\u7c7b\u7b97\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u6b63\u786e\u6027\u6392\u540d\u3002"}}
{"id": "2506.15266", "pdf": "https://arxiv.org/pdf/2506.15266", "abs": "https://arxiv.org/abs/2506.15266", "authors": ["Sungen Hahm", "Heejin Kim", "Gyuseong Lee", "Hyunji Park", "Jaejin Lee"], "title": "Thunder-DeID: Accurate and Efficient De-identification Framework for Korean Court Judgments", "categories": ["cs.CL"], "comment": null, "summary": "To ensure a balance between open access to justice and personal data\nprotection, the South Korean judiciary mandates the de-identification of court\njudgments before they can be publicly disclosed. However, the current\nde-identification process is inadequate for handling court judgments at scale\nwhile adhering to strict legal requirements. Additionally, the legal\ndefinitions and categorizations of personal identifiers are vague and not\nwell-suited for technical solutions. To tackle these challenges, we propose a\nde-identification framework called Thunder-DeID, which aligns with relevant\nlaws and practices. Specifically, we (i) construct and release the first Korean\nlegal dataset containing annotated judgments along with corresponding lists of\nentity mentions, (ii) introduce a systematic categorization of Personally\nIdentifiable Information (PII), and (iii) develop an end-to-end deep neural\nnetwork (DNN)-based de-identification pipeline. Our experimental results\ndemonstrate that our model achieves state-of-the-art performance in the\nde-identification of court judgments.", "AI": {"tldr": "Thunder-DeID\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u9996\u4e2a\u97e9\u8bed\u6cd5\u5f8b\u6807\u6ce8\u6570\u636e\u96c6\u3001\u7cfb\u7edf\u5316PII\u5206\u7c7b\u53ca\u7aef\u5230\u7aefDNN\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u5408\u89c4\u7684\u6cd5\u5ead\u5224\u51b3\u53bb\u6807\u8bc6\u5316\uff0c\u5e76\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u97e9\u56fd\u6cd5\u5ead\u5224\u51b3\u53bb\u6807\u8bc6\u5316\u6d41\u7a0b\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u5904\u7406\u9700\u6c42\uff0c\u4e14\u6cd5\u5f8b\u5b9a\u4e49\u6a21\u7cca\u5bfc\u81f4\u6280\u672f\u9002\u914d\u56f0\u96be\uff0c\u9700\u5f00\u53d1\u7b26\u5408\u6cd5\u5f8b\u89c4\u8303\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "1.\u6784\u5efa\u5e76\u53d1\u5e03\u9996\u4e2a\u5e26\u5b9e\u4f53\u6807\u6ce8\u7684\u97e9\u8bed\u6cd5\u5f8b\u6570\u636e\u96c6 2.\u5efa\u7acb\u7cfb\u7edf\u5316\u7684\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u5206\u7c7b\u4f53\u7cfb 3.\u5f00\u53d1\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u7aef\u5230\u7aef\u53bb\u6807\u8bc6\u5316\u6d41\u7a0b", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u6cd5\u5ead\u5224\u51b3\u53bb\u6807\u8bc6\u5316\u4efb\u52a1\u4e2d\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u6027\u80fd\u6307\u6807", "conclusion": "Thunder-DeID\u901a\u8fc7\u6cd5\u5f8b\u89c4\u8303\u4e0e\u6280\u672f\u521b\u65b0\u7684\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u53f8\u6cd5\u6570\u636e\u5f00\u653e\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u77db\u76fe\uff0c\u5176\u7cfb\u7edf\u5316\u5206\u7c7b\u548c\u7aef\u5230\u7aef\u6d41\u7a0b\u4e3a\u5408\u89c4\u53bb\u6807\u8bc6\u5316\u63d0\u4f9b\u4e86\u53ef\u9760\u65b9\u6848\u3002"}}
{"id": "2506.15301", "pdf": "https://arxiv.org/pdf/2506.15301", "abs": "https://arxiv.org/abs/2506.15301", "authors": ["Shrestha Ghosh", "Moritz Schneider", "Carina Reinicke", "Carsten Eickhoff"], "title": "Cohort Discovery: A Survey on LLM-Assisted Clinical Trial Recruitment", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in LLMs have greatly improved general-domain NLP tasks. Yet,\ntheir adoption in critical domains, such as clinical trial recruitment, remains\nlimited. As trials are designed in natural language and patient data is\nrepresented as both structured and unstructured text, the task of matching\ntrials and patients benefits from knowledge aggregation and reasoning abilities\nof LLMs. Classical approaches are trial-specific and LLMs with their ability to\nconsolidate distributed knowledge hold the potential to build a more general\nsolution. Yet recent applications of LLM-assisted methods rely on proprietary\nmodels and weak evaluation benchmarks. In this survey, we are the first to\nanalyze the task of trial-patient matching and contextualize emerging LLM-based\napproaches in clinical trial recruitment. We critically examine existing\nbenchmarks, approaches and evaluation frameworks, the challenges to adopting\nLLM technologies in clinical research and exciting future directions.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u8bd5\u9a8c\u60a3\u8005\u5339\u914d\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u6307\u51fa\u73b0\u6709\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e13\u6709\u6a21\u578b\u548c\u5f31\u8bc4\u4f30\u57fa\u51c6\u7684\u95ee\u9898", "motivation": "\u4f20\u7edf\u4e34\u5e8a\u8bd5\u9a8c\u5339\u914d\u65b9\u6cd5\u5177\u6709\u7279\u5b9a\u8bd5\u9a8c\u5c40\u9650\u6027\uff0cLLMs\u51ed\u501f\u77e5\u8bc6\u6574\u5408\u80fd\u529b\u6709\u671b\u6784\u5efa\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\u5206\u6790\u8bd5\u9a8c-\u60a3\u8005\u5339\u914d\u4efb\u52a1\uff0c\u5c06\u65b0\u5174LLM\u65b9\u6cd5\u4e0e\u4e34\u5e8a\u62db\u52df\u573a\u666f\u7ed3\u5408\uff0c\u6279\u5224\u6027\u8bc4\u4f30\u73b0\u6709\u57fa\u51c6\u548c\u65b9\u6cd5", "result": "\u63ed\u793a\u5f53\u524d\u8bc4\u4f30\u6846\u67b6\u7684\u4e0d\u8db3\uff0c\u8bc6\u522bLLM\u6280\u672f\u4e34\u5e8a\u5e94\u7528\u7684\u7814\u7a76\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u53d1\u5c55\u65b9\u5411", "conclusion": "LLMs\u5728\u4e34\u5e8a\u8bd5\u9a8c\u62db\u52df\u4e2d\u5c55\u73b0\u9769\u65b0\u6f5c\u529b\uff0c\u4f46\u9700\u89e3\u51b3\u6a21\u578b\u900f\u660e\u5ea6\u3001\u8bc4\u4f30\u4f53\u7cfb\u5b8c\u5584\u548c\u4e34\u5e8a\u9a8c\u8bc1\u7b49\u5173\u952e\u95ee\u9898"}}
{"id": "2506.15304", "pdf": "https://arxiv.org/pdf/2506.15304", "abs": "https://arxiv.org/abs/2506.15304", "authors": ["Negar Foroutan", "Jakhongir Saydaliev", "Ye Eun Kim", "Antoine Bosselut"], "title": "ConLID: Supervised Contrastive Learning for Low-Resource Language Identification", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Submitted to EMNLP", "summary": "Language identification (LID) is a critical step in curating multilingual LLM\npretraining corpora from web crawls. While many studies on LID model training\nfocus on collecting diverse training data to improve performance, low-resource\nlanguages -- often limited to single-domain data, such as the Bible -- continue\nto perform poorly. To resolve these class imbalance and bias issues, we propose\na novel supervised contrastive learning (SCL) approach to learn\ndomain-invariant representations for low-resource languages. Through an\nextensive analysis, we show that our approach improves LID performance on\nout-of-domain data for low-resource languages by 3.2%, demonstrating its\neffectiveness in enhancing LID models.", "AI": {"tldr": "\u63d0\u51fa\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8de8\u9886\u57df\u8bed\u8a00\u8bc6\u522b\u6027\u80fd", "motivation": "\u4f20\u7edfLID\u6a21\u578b\u56e0\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u4e0d\u8db3\u548c\u7c7b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5bfc\u81f4\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u4ec5\u4f9d\u8d56\u5723\u7ecf\u7b49\u5355\u9886\u57df\u6570\u636e\uff09\u5728\u8de8\u9886\u57df\u573a\u666f\u8868\u73b0\u5dee", "method": "\u91c7\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u4e0d\u53d8\u8868\u793a\u5b66\u4e60\u589e\u5f3a\u6a21\u578b\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6cdb\u5316\u80fd\u529b", "result": "\u8de8\u9886\u57df\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u53473.2%\uff08\u5b9e\u9a8c\u8986\u76d6\u591a\u79cd\u573a\u666f\u7684\u6df1\u5165\u5206\u6790\uff09", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u6570\u636e\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bc6\u522b\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2506.15339", "pdf": "https://arxiv.org/pdf/2506.15339", "abs": "https://arxiv.org/abs/2506.15339", "authors": ["Camila Zurdo Tagliabue", "Heloisa Oss Boll", "Aykut Erdem", "Erkut Erdem", "Iacer Calixto"], "title": "DeVisE: Behavioral Testing of Medical Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in clinical decision\nsupport, yet current evaluation methods often fail to distinguish genuine\nmedical reasoning from superficial patterns. We introduce DeVisE (Demographics\nand Vital signs Evaluation), a behavioral testing framework for probing\nfine-grained clinical understanding. We construct a dataset of ICU discharge\nnotes from MIMIC-IV, generating both raw (real-world) and template-based\n(synthetic) versions with controlled single-variable counterfactuals targeting\ndemographic (age, gender, ethnicity) and vital sign attributes. We evaluate\nfive LLMs spanning general-purpose and medically fine-tuned variants, under\nboth zero-shot and fine-tuned settings. We assess model behavior via (1)\ninput-level sensitivity - how counterfactuals alter the likelihood of a note;\nand (2) downstream reasoning - how they affect predicted hospital\nlength-of-stay. Our results show that zero-shot models exhibit more coherent\ncounterfactual reasoning patterns, while fine-tuned models tend to be more\nstable yet less responsive to clinically meaningful changes. Notably,\ndemographic factors subtly but consistently influence outputs, emphasizing the\nimportance of fairness-aware evaluation. This work highlights the utility of\nbehavioral testing in exposing the reasoning strategies of clinical LLMs and\ninforming the design of safer, more transparent medical AI systems.", "AI": {"tldr": "DeVisE\u6846\u67b6\u901a\u8fc7\u884c\u4e3a\u6d4b\u8bd5\u63ed\u793a\u4e34\u5e8aLLMs\u7684\u63a8\u7406\u7b56\u7565\uff0c\u53d1\u73b0\u96f6\u6837\u672c\u6a21\u578b\u5177\u6709\u66f4\u8fde\u8d2f\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\uff0c\u5fae\u8c03\u6a21\u578b\u7a33\u5b9a\u6027\u9ad8\u4f46\u4e34\u5e8a\u54cd\u5e94\u4e0d\u8db3\uff0c\u5f3a\u8c03\u533b\u7597AI\u9700\u516c\u5e73\u6027\u8bc4\u4f30", "motivation": "\u73b0\u6709\u4e34\u5e8aLLM\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u771f\u5b9e\u533b\u5b66\u63a8\u7406\u4e0e\u8868\u9762\u6a21\u5f0f\uff0c\u9700\u5f00\u53d1\u7ec6\u7c92\u5ea6\u6d4b\u8bd5\u6846\u67b6\u8bc4\u4f30\u6a21\u578b\u4e34\u5e8a\u7406\u89e3\u80fd\u529b", "method": "\u57fa\u4e8eMIMIC-IV\u6784\u5efaICU\u51fa\u9662\u8bb0\u5f55\u6570\u636e\u96c6\uff0c\u751f\u6210\u539f\u59cb/\u6a21\u677f\u53cc\u7248\u672c\uff08\u542b\u4eba\u53e3\u7edf\u8ba1\u548c\u751f\u547d\u4f53\u5f81\u53cd\u4e8b\u5b9e\u53d8\u91cf\uff09\uff0c\u8bc4\u4f305\u79cdLLM\u5728\u96f6\u6837\u672c/\u5fae\u8c03\u6a21\u5f0f\u4e0b\u8f93\u5165\u654f\u611f\u6027\u548c\u4f4f\u9662\u65f6\u957f\u9884\u6d4b", "result": "\u96f6\u6837\u672c\u6a21\u578b\u5c55\u793a\u66f4\u8fde\u8d2f\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u6a21\u5f0f\uff0c\u5fae\u8c03\u6a21\u578b\u7a33\u5b9a\u6027\u9ad8\u4f46\u5bf9\u4e34\u5e8a\u6709\u6548\u53d8\u5316\u54cd\u5e94\u5f31\uff1b\u4eba\u53e3\u56e0\u7d20\u6301\u7eed\u5f71\u54cd\u8f93\u51fa\uff0c\u51f8\u663e\u7b97\u6cd5\u516c\u5e73\u6027\u8bc4\u4f30\u5fc5\u8981\u6027", "conclusion": "DeVisE\u6846\u67b6\u6709\u6548\u66b4\u9732\u4e34\u5e8aLLM\u7684\u63a8\u7406\u673a\u5236\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u5b89\u5168\u900f\u660e\u7684\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u65b9\u6cd5\u8bba\u652f\u6301\uff0c\u5f3a\u8c03\u884c\u4e3a\u6d4b\u8bd5\u5728\u533b\u7597AI\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u4f5c\u7528"}}
