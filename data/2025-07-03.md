<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 7]
- [cs.IR](#cs.IR) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered](https://arxiv.org/abs/2507.01019)
*Imran Mirza,Cole Huang,Ishwara Vasista,Rohan Patil,Asli Akalin,Sean O'Brien,Kevin Zhu*

Main category: cs.CL

TL;DR: MALIBU基准测试揭示LLM多智能体系统隐式强化社会偏见，需细致检测与平衡策略。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多智能体系统可能在角色互动中隐式强化模型偏见，影响系统公平性，需开发评估工具量化此类偏差。

Method: 通过两阶段评估：1) 基于人口特征标签的响应评分；2) 跨特征对比评估，使用LLM多智能体评审系统进行量化分析。

Result: 研究发现LLM输出存在系统性偏见，且缓解措施可能过度偏向边缘群体而非中立，需平衡策略实现公平。

Conclusion: 多智能体系统需结合MALIBU的透明评估框架，采用细粒度检测和动态平衡策略应对隐性偏见挑战。

Abstract: Multi-agent systems, which consist of multiple AI models interacting within a
shared environment, are increasingly used for persona-based interactions.
However, if not carefully designed, these systems can reinforce implicit biases
in large language models (LLMs), raising concerns about fairness and equitable
representation. We present MALIBU, a novel benchmark developed to assess the
degree to which LLM-based multi-agent systems implicitly reinforce social
biases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems
through scenario-based assessments. AI models complete tasks within predefined
contexts, and their responses undergo evaluation by an LLM-based multi-agent
judging system in two phases. In the first phase, judges score responses
labeled with specific demographic personas (e.g., gender, race, religion)
across four metrics. In the second phase, judges compare paired responses
assigned to different personas, scoring them and selecting the superior
response. Our study quantifies biases in LLM-generated outputs, revealing that
bias mitigation may favor marginalized personas over true neutrality,
emphasizing the need for nuanced detection, balanced fairness strategies, and
transparent evaluation benchmarks in multi-agent systems.

</details>


### [2] [Event-based evaluation of abstractive news summarization](https://arxiv.org/abs/2507.01160)
*Huiling You,Samia Touileb,Erik Velldal,Lilja Øvrelid*

Main category: cs.CL

TL;DR: 通过事件重叠分析提升摘要质量评估


<details>
  <summary>Details</summary>
Motivation: 传统基于文本重叠的摘要评估方法无法有效捕捉新闻事件核心信息，需要更关注事件完整性的评估维度

Method: 使用挪威专家标注数据集（含事件标注和参考摘要），计算生成摘要/参考摘要/原文之间的事件重叠度

Result: 新方法能清晰量化摘要中保留的事件信息量，提供比传统指标更深入的评估维度

Conclusion: 基于事件重叠的评估框架能更准确地反映生成摘要对核心新闻要素的覆盖程度

Abstract: An abstractive summary of a news article contains its most important
information in a condensed version. The evaluation of automatically generated
summaries by generative language models relies heavily on human-authored
summaries as gold references, by calculating overlapping units or similarity
scores. News articles report events, and ideally so should the summaries. In
this work, we propose to evaluate the quality of abstractive summaries by
calculating overlapping events between generated summaries, reference
summaries, and the original news articles. We experiment on a richly annotated
Norwegian dataset comprising both events annotations and summaries authored by
expert human annotators. Our approach provides more insight into the event
information contained in the summaries.

</details>


### [3] [Matching and Linking Entries in Historical Swedish Encyclopedias](https://arxiv.org/abs/2507.01170)
*Simon Börjesson,Erik Ersmark,Pierre Nugues*

Main category: cs.CL

TL;DR: 分析瑞典百科全书《Nordisk familjebok》两个版本地理条目变化，发现地理焦点从欧洲转向北美/非洲/亚洲等地，反映一战影响和新兴势力崛起


<details>
  <summary>Details</summary>
Motivation: 探究百科全书内容演变如何反映瑞典知识体系的地理认知变迁

Method: 使用语义句子嵌入匹配条目+Transformer分类器提取地理条目+Wikidata链接分析

Result: 发现地理关注度从欧洲向北美/非洲/亚洲/澳大利亚/北斯堪的纳维亚显著转移（p<0.05）

Conclusion: 基于计算方法的分析有效揭示了百科全书内容演变与历史背景（第一次世界大战）的关联性，数据与代码开源可用

Abstract: The \textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and
20th centuries. It was written by a team of experts and aimed to be an
intellectual reference, stressing precision and accuracy. This encyclopedia had
four main editions remarkable by their size, ranging from 20 to 38 volumes. As
a consequence, the \textit{Nordisk familjebok} had a considerable influence in
universities, schools, the media, and society overall. As new editions were
released, the selection of entries and their content evolved, reflecting
intellectual changes in Sweden.
  In this paper, we used digitized versions from \textit{Project Runeberg}. We
first resegmented the raw text into entries and matched pairs of entries
between the first and second editions using semantic sentence embeddings. We
then extracted the geographical entries from both editions using a
transformer-based classifier and linked them to Wikidata. This enabled us to
identify geographic trends and possible shifts between the first and second
editions, written between 1876-1899 and 1904-1926, respectively.
  Interpreting the results, we observe a small but significant shift in
geographic focus away from Europe and towards North America, Africa, Asia,
Australia, and northern Scandinavia from the first to the second edition,
confirming the influence of the First World War and the rise of new powers. The
code and data are available on GitHub at
https://github.com/sibbo/nordisk-familjebok.

</details>


### [4] [MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis](https://arxiv.org/abs/2507.01213)
*Adamu Lawan,Juhua Pu,Haruna Yunusa,Jawad Muhammad,Muhammad Lawan*

Main category: cs.CL

TL;DR: 提出MEGA框架，整合双向mLSTM与部分翻转反向流(PF-mLSTM)，通过多头交叉指数门控融合机制(MECGAF)提升ABSA任务性能，实现精度与效率双优


<details>
  <summary>Details</summary>
Motivation: 现有ABSA方法在计算效率与性能间难以平衡：深度学习模型缺乏全局语境、transformer计算资源需求高、Mamba存在CUDA依赖和局部关联弱化问题。xLSTM在长程依赖建模方面的潜力尚未在ABSA领域开发

Method: 构建双向mLSTM架构，包含正向流和部分翻转反向流(PF-mLSTM)。PF-mLSTM通过反向处理初始序列片段强化局部语境建模，保留关键短程模式。开发MECGAF机制动态融合前向与PF-mLSTM输出，优化短程依赖捕捉同时保持全局语境

Result: 在三个基准数据集上超越现有最优模型，ABSA任务中实现更高的准确率和计算效率

Conclusion: MEGA框架通过创新架构设计有效平衡全局语境与局部关联建模，其PF-mLSTM和MECGAF机制为提升细粒度情感分析性能提供了新思路，推动高效ABSA模型发展

Abstract: Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language
Processing (NLP) task that extracts aspects from text and determines their
associated sentiments, enabling fine-grained analysis of user opinions.
Existing ABSA methods struggle to balance computational efficiency with high
performance: deep learning models often lack global context, transformers
demand significant computational resources, and Mamba-based approaches face
CUDA dependency and diminished local correlations. Recent advancements in
Extended Long Short-Term Memory (xLSTM) models, particularly their efficient
modeling of long-range dependencies, have significantly advanced the NLP
community. However, their potential in ABSA remains untapped. To this end, we
propose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework
integrating a bi-directional mLSTM architecture with forward and partially
flipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context
modeling by processing the initial sequence segment in reverse with dedicated
parameters, preserving critical short-range patterns. We further introduce an
mLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that
dynamically combines forward mLSTM outputs as query and key with PF-mLSTM
outputs as value, optimizing short-range dependency capture while maintaining
global context and efficiency. Experimental results on three benchmark datasets
demonstrate that MEGA outperforms state-of-the-art baselines, achieving
superior accuracy and efficiency in ABSA tasks.

</details>


### [5] [The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure](https://arxiv.org/abs/2507.01234)
*Yu Fan,Yang Tian,Shauli Ravfogel,Mrinmaya Sachan,Elliott Ash,Alexander Hoyle*

Main category: cs.CL

TL;DR: 提出一种低计算成本的去偏算法，有效消除文本嵌入中的干扰因素偏见，提升跨语料库的文档相似性和聚类效果


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入的相似性度量容易受来源/语言等无关属性干扰，影响跨语料库文本处理效果

Method: 从编码器表示中主动移除已观测干扰因素信息，保持低计算成本特性

Result: 所有嵌入变体和任务中文档相似性/聚类指标显著提升，分布外基准测试性能未受影响

Conclusion: 该去偏方法能有效提升跨语料库文本处理效果，且不影响模型原有能力，具备实际应用价值

Abstract: Embedding-based similarity metrics between text sequences can be influenced
not just by the content dimensions we most care about, but can also be biased
by spurious attributes like the text's source or language. These document
confounders cause problems for many applications, but especially those that
need to pool texts from different corpora. This paper shows that a debiasing
algorithm that removes information about observed confounders from the encoder
representations substantially reduces these biases at a minimal computational
cost. Document similarity and clustering metrics improve across every embedding
variant and task we evaluate -- often dramatically. Interestingly, performance
on out-of-distribution benchmarks is not impacted, indicating that the
embeddings are not otherwise degraded.

</details>


### [6] [GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant](https://arxiv.org/abs/2507.01259)
*Michał Matak,Jarosław A. Chudziak*

Main category: cs.CL

TL;DR: 提出基于波兰民法典的gAIus架构，通过可解释性强的检索机制显著提升LLM法律问答准确性，使GPT-3.5性能提升419%，GPT-4o-mini准确率从31%提升至86%


<details>
  <summary>Details</summary>
Motivation: 解决LLM在处理非英语/中文法律问题时缺乏可靠法律条文引用的问题，特别是针对波兰法律场景的特殊需求

Method: 开发基于特定法律条文（波兰民法典）的检索机制，构建波兰法律学徒考试题库作为评估数据集

Result: 该架构使GPT-3.5准确率提升419%，超越GPT-4o表现，并将GPT-4o-mini得分从31%提升至86%

Conclusion: 验证了基于法律条文检索架构的有效性，提出未来可扩展至其他法律体系及开发自动法律咨询系统的应用方向

Abstract: In this paper we discuss the capability of large language models to base
their answer and provide proper references when dealing with legal matters of
non-english and non-chinese speaking country. We discuss the history of legal
information retrieval, the difference between case law and statute law, its
impact on the legal tasks and analyze the latest research in this field. Basing
on that background we introduce gAIus, the architecture of the cognitive
LLM-based agent, whose responses are based on the knowledge retrieved from
certain legal act, which is Polish Civil Code. We propose a retrieval mechanism
which is more explainable, human-friendly and achieves better results than
embedding-based approaches. To evaluate our method we create special dataset
based on single-choice questions from entrance exams for law apprenticeships
conducted in Poland. The proposed architecture critically leveraged the
abilities of used large language models, improving the gpt-3.5-turbo-0125 by
419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.
At the end of our paper we show the possible future path of research and
potential applications of our findings.

</details>


### [7] [Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening](https://arxiv.org/abs/2507.01278)
*Cindy Lie Tabuse,David Restepo,Carolina Gracitelli,Fernando Korn Malerbi,Caio Regatieri,Luis Filipe Nakayama*

Main category: cs.CL

TL;DR: GPT-4在眼科影像分析中展现基础临床推理能力，但复杂任务精度不足，暂不适用于临床但具辅助潜力。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在眼科临床决策中的应用价值，特别是糖尿病视网膜病变和青光眼筛查场景。

Method: 使用300张标注眼底图像，通过结构化提示词测试GPT-4在添加真实/合成元数据前后的ICDR分级、转诊推荐和杯盘比估计能力。

Result: ICDR分级准确率67.5%（主要依赖正常病例识别），DR转诊准确率82.3%，青光眼筛查各项指标均低于4%。元数据对结果无显著影响。

Conclusion: LLM目前适用于眼科教育/文档辅助等非临床场景，临床决策需更高精度模型。

Abstract: Large language models (LLMs) can simulate clinical reasoning based on natural
language prompts, but their utility in ophthalmology is largely unexplored.
This study evaluated GPT-4's ability to interpret structured textual
descriptions of retinal fundus photographs and simulate clinical decisions for
diabetic retinopathy (DR) and glaucoma screening, including the impact of
adding real or synthetic clinical metadata. We conducted a retrospective
diagnostic validation study using 300 annotated fundus images. GPT-4 received
structured prompts describing each image, with or without patient metadata. The
model was tasked with assigning an ICDR severity score, recommending DR
referral, and estimating the cup-to-disc ratio for glaucoma referral.
Performance was evaluated using accuracy, macro and weighted F1 scores, and
Cohen's kappa. McNemar's test and change rate analysis were used to assess the
influence of metadata. GPT-4 showed moderate performance for ICDR
classification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),
driven mainly by correct identification of normal cases. Performance improved
in the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For
glaucoma referral, performance was poor across all settings (accuracy ~78%, F1
<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes
(McNemar p > 0.05), and predictions remained consistent across conditions.
GPT-4 can simulate basic ophthalmic decision-making from structured prompts but
lacks precision for complex tasks. While not suitable for clinical use, LLMs
may assist in education, documentation, or image annotation workflows in
ophthalmology.

</details>


### [8] [Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization](https://arxiv.org/abs/2507.01281)
*Juan Chen,Baolong Bi,Wei Zhang,Jingyan Sui,Xiaofei Zhu,Yuanzhuo Wang,Lingrui Mei,Shenghua Liu*

Main category: cs.CL

TL;DR: 提出CARE-RAG框架解决RAG系统中知识冲突问题，通过冲突驱动总结和QA修复提升生成可靠性，在噪声/冲突场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: RAG系统面临内部知识不一致与检索噪声导致的知识冲突问题，严重影响生成可靠性，需系统化整合所有证据源。

Method: 1.参数感知证据提取（比较参数记录）
2.上下文感知证据提炼（去噪检索内容）
3.基于3B LLaMA3.2的冲突驱动总结
4.QA修复机制更新基准答案

Result: 在修订后的QA数据集上，CARE-RAG在噪声/冲突证据场景中持续超越现有RAG基线方法

Conclusion: CARE-RAG通过多源证据融合与冲突管理机制，显著提升RAG系统在复杂知识环境下的可信度

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating their parametric knowledge with external retrieved content.
However, knowledge conflicts caused by internal inconsistencies or noisy
retrieved content can severely undermine the generation reliability of RAG
systems.In this work, we argue that LLMs should rethink all evidence, including
both retrieved content and internal knowledge, before generating responses.We
propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel
framework that improves trustworthiness through Conflict-Driven Summarization
of all available evidence.CARE-RAG first derives parameter-aware evidence by
comparing parameter records to identify diverse internal perspectives. It then
refines retrieved evidences to produce context-aware evidence, removing
irrelevant or misleading content. To detect and summarize conflicts, we distill
a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable
synthesis across multiple sources.To further ensure evaluation integrity, we
introduce a QA Repair step to correct outdated or ambiguous benchmark
answers.Experiments on revised QA datasets with retrieval data show that
CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios
with noisy or conflicting evidence.

</details>


### [9] [Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks](https://arxiv.org/abs/2507.01297)
*Xinxi Lyu,Michael Duan,Rulin Shao,Pang Wei Koh,Sewon Min*

Main category: cs.CL

TL;DR: 提出CompactDS数据存储方案，通过多样化高质量数据源和混合检索策略，显著提升RAG在推理密集型任务的性能


<details>
  <summary>Details</summary>
Motivation: 挑战传统观点，证明RAG在复杂推理任务中的有效性，关键在于构建与预训练数据对齐的高质量多样化数据存储

Method: 设计CompactDS：1) 过滤低质量网络内容保留高价值子集 2) 结合内存ANN检索与磁盘精确搜索实现高效检索

Result: 在MMLU/GPQA/MATH等基准上实现10%-33%的绝对提升，自研数据存储效果匹配Google搜索和复杂代理系统

Conclusion: 数据源多样性对RAG性能至关重要，CompactDS的简单自包含设计为AI系统研究提供了新范式

Abstract: Retrieval-augmented Generation (RAG) has primarily been studied in limited
settings, such as factoid question answering; more challenging,
reasoning-intensive benchmarks have seen limited success from minimal RAG. In
this work, we challenge this prevailing view on established,
reasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We
identify a key missing component in prior work: a usable, web-scale datastore
aligned with the breadth of pretraining data. To this end, we introduce
CompactDS: a diverse, high-quality, web-scale datastore that achieves high
retrieval accuracy and subsecond latency on a single-node. The key insights are
(1) most web content can be filtered out without sacrificing coverage, and a
compact, high-quality subset is sufficient; and (2) combining in-memory
approximate nearest neighbor (ANN) retrieval and on-disk exact search balances
speed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves
consistent accuracy improvements across all benchmarks and model sizes
(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,
and 19% on MATH. No single data source suffices alone, highlighting the
importance of diversity of sources (web crawls, curated math, academic papers,
textbooks). Finally, we show that our carefully designed in-house datastore
matches or outperforms web search engines such as Google Search, as well as
recently proposed, complex agent-based RAG systems--all while maintaining
simplicity, reproducibility, and self-containment. We release CompactDS and our
retrieval pipeline, supporting future research exploring retrieval-based AI
systems.

</details>


### [10] [La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation](https://arxiv.org/abs/2507.01299)
*Kai Liu,Bowen Xu,Shaoyu Wu,Xin Chen,Hao Zhou,Yongliang Tao,Lulu Hu*

Main category: cs.CL

TL;DR: LaRoSA提出无需额外训练或基于幅度的剪枝，通过层级正交旋转实现LLM激活稀疏化，在保持模型性能的同时获得稳定加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有激活稀疏化方法需要恢复训练（影响实际部署）或依赖幅度剪枝（导致稀疏波动和加速不稳定），难以实用化。

Method: 1. 通过层级正交旋转将激活映射到更适合稀疏化的空间
2. 采用Top-K选择机制实现模型级稳定稀疏
3. 支持不同尺寸和架构的LLM适配

Result: LLaMA2-7B在40%稀疏度下：
- 困惑度仅增加0.17
- 实际运行速度提升1.30x
- 零样本任务准确率差距缩小至0.54%（优于TEAL 1.77%和CATS 17.14%）

Conclusion: LaRoSA首次实现无需重训练的高效激活稀疏化，在性能损失极小的情况下提供可靠加速，为LLM部署提供实用化解决方案。

Abstract: Activation sparsity can reduce the computational overhead and memory
transfers during the forward pass of Large Language Model (LLM) inference.
Existing methods face limitations, either demanding time-consuming recovery
training that hinders real-world adoption, or relying on empirical
magnitude-based pruning, which causes fluctuating sparsity and unstable
inference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse
Activation), a novel method for activation sparsification designed to improve
LLM efficiency without requiring additional training or magnitude-based
pruning. We leverage layerwise orthogonal rotations to transform input
activations into rotated forms that are more suitable for sparsification. By
employing a Top-K selection approach within the rotated activations, we achieve
consistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA
is effective across various sizes and types of LLMs, demonstrating minimal
performance degradation and robust inference acceleration. Specifically, for
LLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a
consistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in
zero-shot tasks compared to the dense model to just 0.54%, while surpassing
TEAL by 1.77% and CATS by 17.14%.

</details>


### [11] [Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs](https://arxiv.org/abs/2507.01334)
*Nifu Dan,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: 研究通过高级指令调优模型Deepseek-R1在SciBench物理问题上实现了最先进准确率，并展示了独特的符号推导推理模式，少样本提示策略仍能提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索高级推理模型在解决复杂物理问题中的潜力，突破LLMs在物理推理中概念理解与问题解决能力的瓶颈。

Method: 使用Deepseek-R1模型对SciBench基准中的多样化物理问题进行系统性评估，并测试少样本提示策略的有效性。

Result: 模型不仅达到SOTA准确率（比之前方法提升显著），且生成以符号推导为核心的独特推理路径，少样本提示带来4.7%的绝对准确率提升。

Conclusion: 高级推理模型在物理问题解决中展现卓越潜力，符号推导能力突出，提示工程仍是持续提升性能的有效手段。

Abstract: Navigating the complexities of physics reasoning has long been a difficult
task for Large Language Models (LLMs), requiring a synthesis of profound
conceptual understanding and adept problem-solving techniques. In this study,
we investigate the application of advanced instruction-tuned reasoning models,
such as Deepseek-R1, to address a diverse spectrum of physics problems curated
from the challenging SciBench benchmark. Our comprehensive experimental
evaluation reveals the remarkable capabilities of reasoning models. Not only do
they achieve state-of-the-art accuracy in answering intricate physics
questions, but they also generate distinctive reasoning patterns that emphasize
on symbolic derivation. Furthermore, our findings indicate that even for these
highly sophisticated reasoning models, the strategic incorporation of few-shot
prompting can still yield measurable improvements in overall accuracy,
highlighting the potential for continued performance gains.

</details>


### [12] [LEDOM: An Open and Fundamental Reverse Language Model](https://arxiv.org/abs/2507.01335)
*Xunjian Yin,Sitao Cheng,Yuxi Xie,Xinyu Hu,Li Lin,Xinyi Wang,Liangming Pan,William Yang Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 提出首个纯逆向语言模型LEDOM，通过逆向推理能力显著提升数学任务表现


<details>
  <summary>Details</summary>
Motivation: 探索反向语言模型作为基础模型的潜力，利用逆向时序处理开发新型应用场景

Method: 基于435B tokens预训练2B/7B参数模型，采用逆向token预测机制，开发逆向奖励重排序方法

Result: 逆向奖励方法使数学推理任务性能显著提升，验证模型独特推理能力

Conclusion: LEDOM展现逆向建模新范式，开源模型与数据促进语言模型双向推理研究

Abstract: We introduce LEDOM, the first purely reverse language model, trained
autoregressively on 435B tokens with 2B and 7B parameter variants, which
processes sequences in reverse temporal order through previous token
prediction. For the first time, we present the reverse language model as a
potential foundational model across general tasks, accompanied by a set of
intriguing examples and insights. Based on LEDOM, we further introduce a novel
application: Reverse Reward, where LEDOM-guided reranking of forward language
model outputs leads to substantial performance improvements on mathematical
reasoning tasks. This approach leverages LEDOM's unique backward reasoning
capability to refine generation quality through posterior evaluation. Our
findings suggest that LEDOM exhibits unique characteristics with broad
application potential. We will release all models, training code, and
pre-training data to facilitate future research.

</details>


### [13] [Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy](https://arxiv.org/abs/2507.01352)
*Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou*

Main category: cs.CL

TL;DR: 提出40M规模的SynPref-40M偏好数据集和Skywork-Reward-V2奖励模型，通过人机协同数据标注实现七大基准SOTA表现


<details>
  <summary>Details</summary>
Motivation: 现有开源奖励模型受限于偏好数据集的质量问题(范围狭窄/合成标签/质量控制不足)，导致在复杂人类偏好建模中表现脆弱

Method: 1. 设计两阶段人机协同流程：人工验证标注+LLM自动化扩展 2. 从40M数据中精选26M高质量数据训练0.6B-8B参数模型

Result: 在七大基准测试中全面领先，涵盖人类偏好对齐、安全性、抗风格偏差等维度，验证数据规模与质量的双重有效性

Conclusion: 揭示了现有人工标注数据的潜力边界，证明人机协同数据优化能显著提升模型性能，为开源奖励模型发展指明新方向

Abstract: Despite the critical role of reward models (RMs) in reinforcement learning
from human feedback (RLHF), current state-of-the-art open RMs perform poorly on
most existing evaluation benchmarks, failing to capture the spectrum of nuanced
and sophisticated human preferences. Even approaches that incorporate advanced
training techniques have not yielded meaningful performance improvements. We
hypothesize that this brittleness stems primarily from limitations in
preference datasets, which are often narrowly scoped, synthetically labeled, or
lack rigorous quality control. To address these challenges, we present a
large-scale preference dataset comprising 40 million preference pairs, named
SynPref-40M. To enable data curation at scale, we design a human-AI synergistic
two-stage pipeline that leverages the complementary strengths of human
annotation quality and AI scalability. In this pipeline, humans provide
verified annotations, while large language models perform automatic curation
based on human guidance. Training on this preference mixture, we introduce
Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B
parameters, trained on a carefully curated subset of 26 million preference
pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile
across a wide range of capabilities, including alignment with human
preferences, objective correctness, safety, resistance to stylistic biases, and
best-of-N scaling, achieving state-of-the-art performance across seven major
reward model benchmarks. Ablation studies confirm that the effectiveness of our
approach stems not only from data scale but also from high-quality curation.
The Skywork-Reward-V2 series represents substantial progress in open reward
models, highlighting the untapped potential of existing preference datasets and
demonstrating how human-AI curation synergy can unlock significantly higher
data quality.

</details>


### [14] [Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction](https://arxiv.org/abs/2507.01437)
*Ting Xu,Xiaoxiao Deng,Xiandong Meng,Haifeng Yang,Yan Wu*

Main category: cs.CL

TL;DR: 提出基于注意力机制的深度学习模型，有效解决医疗文本多标签预测问题，在MIMIC-IV数据集上展现优越性能


<details>
  <summary>Details</summary>
Motivation: 电子健康记录存在非结构化特征和高维语义复杂性，传统方法难以有效处理多标签共现和稀疏信息场景

Method: 使用Transformer架构进行文本表示学习，结合多层自注意力机制捕捉医疗实体关系，采用Sigmoid多标签分类器，并引入上下文感知语义对齐机制

Result: 在基线比较、噪声测试等实验中全面超越现有方法，不同数据规模和干扰水平下保持强泛化能力

Conclusion: 该框架为临床文本处理提供高效解决方案，对多标签医疗建模任务具有重要实践价值

Abstract: This paper addresses the challenges posed by the unstructured nature and
high-dimensional semantic complexity of electronic health record texts. A deep
learning method based on attention mechanisms is proposed to achieve unified
modeling for information extraction and multi-label disease prediction. The
study is conducted on the MIMIC-IV dataset. A Transformer-based architecture is
used to perform representation learning over clinical text. Multi-layer
self-attention mechanisms are employed to capture key medical entities and
their contextual relationships. A Sigmoid-based multi-label classifier is then
applied to predict multiple disease labels. The model incorporates a
context-aware semantic alignment mechanism, enhancing its representational
capacity in typical medical scenarios such as label co-occurrence and sparse
information. To comprehensively evaluate model performance, a series of
experiments were conducted, including baseline comparisons, hyperparameter
sensitivity analysis, data perturbation studies, and noise injection tests.
Results demonstrate that the proposed method consistently outperforms
representative existing approaches across multiple performance metrics. The
model maintains strong generalization under varying data scales, interference
levels, and model depth configurations. The framework developed in this study
offers an efficient algorithmic foundation for processing real-world clinical
texts and presents practical significance for multi-label medical text modeling
tasks.

</details>


### [15] [LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation](https://arxiv.org/abs/2507.01449)
*Tianyu Liu,Qitan Lv,Hao Li,Xing Gao,Xiao Sun*

Main category: cs.CL

TL;DR: 提出LogitSpec方法，通过利用最后一个token的logit扩展检索范围来提升推测解码效率，无需训练即可实现LLM推理加速


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的推测解码方法依赖匹配范式检索参考token，但常无法找到足够准确匹配的候选token

Method: 1) 利用最后一个token的logit预测下下个token 2) 同时检索包含下一个和下下个token的相关参考内容

Result: 在多种文本生成基准测试中达到2.61倍加速，平均每个解码步骤接受3.28个token

Conclusion: LogitSpec通过logit双重预测机制有效扩展检索范围，实现训练免费、即插即用的推理加速方案

Abstract: Speculative decoding (SD), where a small draft model is employed to propose
draft tokens in advance and then the target model validates them in parallel,
has emerged as a promising technique for LLM inference acceleration. Many
endeavors to improve SD are to eliminate the need for a draft model and
generate draft tokens in a retrieval-based manner in order to further alleviate
the drafting overhead and significantly reduce the difficulty in deployment and
applications. However, retrieval-based SD relies on a matching paradigm to
retrieval the most relevant reference as the draft tokens, where these methods
often fail to find matched and accurate draft tokens. To address this
challenge, we propose LogitSpec to effectively expand the retrieval range and
find the most relevant reference as drafts. Our LogitSpec is motivated by the
observation that the logit of the last token can not only predict the next
token, but also speculate the next next token. Specifically, LogitSpec
generates draft tokens in two steps: (1) utilizing the last logit to speculate
the next next token; (2) retrieving relevant reference for both the next token
and the next next token. LogitSpec is training-free and plug-and-play, which
can be easily integrated into existing LLM inference frameworks. Extensive
experiments on a wide range of text generation benchmarks demonstrate that
LogitSpec can achieve up to 2.61 $\times$ speedup and 3.28 mean accepted tokens
per decoding step. Our code is available at
https://github.com/smart-lty/LogitSpec.

</details>


### [16] [Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities](https://arxiv.org/abs/2507.01479)
*Yingqiang Gao,Kaede Johnson,David Froehlich,Luisa Carrer,Sarah Ebling*

Main category: cs.CL

TL;DR: 通过直接偏好优化（DPO）技术整合智力障碍人士的反馈，构建个性化AI文本简化系统


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本简化系统缺乏用户偏好反馈机制，无法满足智力障碍人群的个性化需求

Method: 扩展监督微调（SFT）方法，采用DPO对齐技术进行后训练，构建包含数据收集-模型选择-训练-评估的系统开发流程

Result: 实现了目标群体偏好驱动的文本简化，验证了用户参与对AI无障碍系统设计的重要性

Conclusion: 通过融合专家意见和用户直接反馈，推动了群体级个性化包容性AI系统的发展

Abstract: Automatic text simplification (ATS) aims to enhance language accessibility
for various target groups, particularly persons with intellectual disabilities.
Recent advancements in generative AI, especially large language models (LLMs),
have substantially improved the quality of machine-generated text
simplifications, thereby mitigating information barriers for the target group.
However, existing LLM-based ATS systems do not incorporate preference feedback
on text simplifications during training, resulting in a lack of personalization
tailored to the specific needs of target group representatives.
  In this work, we extend the standard supervised fine-tuning (SFT) approach
for adapting LLM-based ATS models by leveraging a computationally efficient LLM
alignment technique -- direct preference optimization (DPO). Specifically, we
post-train LLM-based ATS models using human feedback collected from persons
with intellectual disabilities, reflecting their preferences on paired text
simplifications generated by mainstream LLMs. Furthermore, we propose a
pipeline for developing personalized LLM-based ATS systems, encompassing data
collection, model selection, SFT and DPO post-training, and evaluation. Our
findings underscore the necessity of active participation of target group
persons in designing personalized AI accessibility solutions aligned with human
expectations. This work represents a step towards personalizing inclusive AI
systems at the target-group level, incorporating insights not only from text
simplification experts but also from target group persons themselves.

</details>


### [17] [Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing](https://arxiv.org/abs/2507.01541)
*Álvaro Zaera,Diana Nicoleta Popa,Ivan Sekulic,Paolo Rosso*

Main category: cs.CL

TL;DR: 提出结合不确定性建模与微调大语言模型的模块化框架，实现高效准确的超出范围意图检测


<details>
  <summary>Details</summary>
Motivation: 现有任务对话系统对未知意图的检测存在效率与准确性难以平衡的问题，需结合传统方法与新兴LLM技术突破性能瓶颈

Method: 1. 在现有意图分类器上应用不确定性估计 2. 对高不确定性样本触发微调LLM进行最终决策

Result: 在关键OOS检测基准测试中取得SOTA效果，包括实际部署系统采集的真实数据

Conclusion: 该框架通过两阶段混合架构成功平衡计算效率与检测性能，为工业级对话系统提供实用解决方案

Abstract: Out-of-scope (OOS) intent detection is a critical challenge in task-oriented
dialogue systems (TODS), as it ensures robustness to unseen and ambiguous
queries. In this work, we propose a novel but simple modular framework that
combines uncertainty modeling with fine-tuned large language models (LLMs) for
efficient and accurate OOS detection. The first step applies uncertainty
estimation to the output of an in-scope intent detection classifier, which is
currently deployed in a real-world TODS handling tens of thousands of user
interactions daily. The second step then leverages an emerging LLM-based
approach, where a fine-tuned LLM is triggered to make a final decision on
instances with high uncertainty. Unlike prior approaches, our method
effectively balances computational efficiency and performance, combining
traditional approaches with LLMs and yielding state-of-the-art results on key
OOS detection benchmarks, including real-world OOS data acquired from a
deployed TODS.

</details>


### [18] [Is External Information Useful for Stance Detection with LLMs?](https://arxiv.org/abs/2507.01543)
*Quang Minh Nguyen,Taegyoon Kim*

Main category: cs.CL

TL;DR: 研究发现外部信息会降低多数LLM在立场检测任务中的性能，最大F1下降27.9%，揭示LLM存在信息对齐偏差


<details>
  <summary>Details</summary>
Motivation: 探究维基百科和网络搜索等外部信息如何影响LLM在立场检测任务中的表现，验证其与BERT模型的差异

Method: 在3个数据集12个目标上系统评估8种LLM，通过对比实验分析外部信息影响机制，测试思维链提示和微调效果

Result: 78%案例显示外部信息损害性能（最大F1降27.9%），LLM倾向与外部信息立场对齐而非文本真实立场，微调仅部分缓解

Conclusion: 与BERT系统结论相反，LLM立场分类器存在信息偏见风险，提示需谨慎处理外部信息在LLM应用中的使用

Abstract: In the stance detection task, a text is classified as either favorable,
opposing, or neutral towards a target. Prior work suggests that the use of
external information, e.g., excerpts from Wikipedia, improves stance detection
performance. However, whether or not such information can benefit large
language models (LLMs) remains an unanswered question, despite their wide
adoption in many reasoning tasks. In this study, we conduct a systematic
evaluation on how Wikipedia and web search external information can affect
stance detection across eight LLMs and in three datasets with 12 targets.
Surprisingly, we find that such information degrades performance in most cases,
with macro F1 scores dropping by up to 27.9\%. We explain this through
experiments showing LLMs' tendency to align their predictions with the stance
and sentiment of the provided information rather than the ground truth stance
of the given text. We also find that performance degradation persists with
chain-of-thought prompting, while fine-tuning mitigates but does not fully
eliminate it. Our findings, in contrast to previous literature on BERT-based
systems which suggests that external information enhances performance,
highlight the risks of information biases in LLM-based stance classifiers. Code
is available at https://github.com/ngqm/acl2025-stance-detection.

</details>


### [19] [Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation](https://arxiv.org/abs/2507.01594)
*Shutong Feng,Hsien-chin Lin,Nurul Lubis,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Renato Vukovic,Milica Gašić*

Main category: cs.CL

TL;DR: 提出LUSTER系统，结合大语言模型与结构化奖励机制的端到端强化学习框架，有效提升任务导向对话系统的任务完成度和情感响应能力。


<details>
  <summary>Details</summary>
Motivation: 当前任务导向对话系统在噪声环境下同时优化任务成功率、情感理解能力和信息传递准确性存在挑战，需探索更全面的系统设计方法。

Method: 建立包含用户模拟器和自然语言理解模块的评估环境，开发基于LLM的端到端强化学习框架（LUSTER），整合短期情感奖励和长期任务奖励机制。

Result: 实验表明结构化奖励建模与LLM能力的结合显著提升系统鲁棒性，在任务成功率和情感响应维度均优于传统方法。

Conclusion: LLM与强化学习的协同框架为下一代对话系统提供了有效解决方案，平衡任务效能与情感智能的发展需求。

Abstract: Task-oriented dialogue (ToD) systems are designed to help users achieve
specific goals through natural language interaction. While recent advances in
large language models (LLMs) have significantly improved linguistic fluency and
contextual understanding, building effective and emotionally intelligent ToD
systems remains a complex challenge. Effective ToD systems must optimise for
task success, emotional understanding and responsiveness, and precise
information conveyance, all within inherently noisy and ambiguous
conversational environments. In this work, we investigate architectural,
representational, optimisational as well as emotional considerations of ToD
systems. We set up systems covering these design considerations with a
challenging evaluation environment composed of a natural-language user
simulator coupled with an imperfect natural language understanding module. We
propose \textbf{LUSTER}, an \textbf{L}LM-based \textbf{U}nified \textbf{S}ystem
for \textbf{T}ask-oriented dialogue with \textbf{E}nd-to-end
\textbf{R}einforcement learning with both short-term (user sentiment) and
long-term (task success) rewards. Our findings demonstrate that combining LLM
capability with structured reward modelling leads to more resilient and
emotionally responsive ToD systems, offering a practical path forward for
next-generation conversational agents.

</details>


### [20] [Chart Question Answering from Real-World Analytical Narratives](https://arxiv.org/abs/2507.01627)
*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 提出了基于可视化笔记本构建的真实场景图表问答数据集，挑战现有多模态大模型


<details>
  <summary>Details</summary>
Motivation: 现有图表问答数据集缺乏真实场景下的多视图图表和基于分析叙述的自然语言问题，需要更符合实际推理流程的评测基准

Method: 从可视化笔记本中提取真实世界的多视图图表，结合分析性叙述构建自然语言问题

Result: GPT-4模型在该数据集上仅达到69.3%准确率，揭示当前模型在真实CQA场景中的不足

Conclusion: 该数据集为图表问答研究提供了更真实的评估场景，揭示了现有模型与人类分析能力之间的显著差距

Abstract: We present a new dataset for chart question answering (CQA) constructed from
visualization notebooks. The dataset features real-world, multi-view charts
paired with natural language questions grounded in analytical narratives.
Unlike prior benchmarks, our data reflects ecologically valid reasoning
workflows. Benchmarking state-of-the-art multimodal large language models
reveals a significant performance gap, with GPT-4.1 achieving an accuracy of
69.3%, underscoring the challenges posed by this more authentic CQA setting.

</details>


### [21] [Confidence and Stability of Global and Pairwise Scores in NLP Evaluation](https://arxiv.org/abs/2507.01633)
*Georgii Levtsov,Dmitry Ustalov*

Main category: cs.CL

TL;DR: 本文通过合成和真实数据集实验，系统比较了NLP领域全局评分与成对比较两种模型评估策略的优劣。全局评分提供整体可靠性但可能低估特殊强模型，成对比较擅长挖掘低分优质模型但收敛较慢。


<details>
  <summary>Details</summary>
Motivation: 针对当前NLP评估从GLUE等全局评分转向LMSYS Arena等成对比较的趋势，研究者希望明确两种方法在模型评估中的适用场景，为选择评估策略提供实证依据。

Method: 使用合成数据集和真实数据集，结合标准全局指标（如准确率）与Bradley-Terry成对比较模型，通过蒙特卡洛模拟和实际基准测试进行对比分析。

Result: 全局评分在常规场景下排名更稳定，但对存在罕见严重错误的高能力模型敏感度不足；成对比较在文本生成等难以量化评估的领域表现突出，但遇到平局时需更多比较样本。

Conclusion: 建议根据评估目标混合使用：需要整体可靠性时选择全局评分，关注特定能力维度时采用成对比较，同时注意不同方法对模型错误模式的敏感度差异。

Abstract: With the advent of highly capable instruction-tuned neural language models,
benchmarking in natural language processing (NLP) is increasingly shifting
towards pairwise comparison leaderboards, such as LMSYS Arena, from traditional
global pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper
empirically investigates the strengths and weaknesses of both global scores and
pairwise comparisons to aid decision-making in selecting appropriate model
evaluation strategies. Through computational experiments on synthetic and
real-world datasets using standard global metrics and the popular Bradley-Terry
model for pairwise comparisons, we found that while global scores provide more
reliable overall rankings, they can underestimate strong models with rare,
significant errors or low confidence. Conversely, pairwise comparisons are
particularly effective for identifying strong contenders among models with
lower global scores, especially where quality metrics are hard to define (e.g.,
text generation), though they require more comparisons to converge if ties are
frequent. Our code and data are available at
https://github.com/HSPyroblast/srw-ranking under a permissive license.

</details>


### [22] [Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings](https://arxiv.org/abs/2507.01645)
*Rifki Afina Putri*

Main category: cs.CL

TL;DR: 研究显示预训练模型在印尼本地语言的情感分析迁移能力受语言接触影响，MAD-X适配器方法显著提升性能（尤其有相关语言接触的情况）


<details>
  <summary>Details</summary>
Motivation: 探索如何将预训练语言模型有效迁移到低资源印尼本地语言，解决资源匮乏语言的模型应用难题

Method: 使用印尼单语BERT、mBERT/XLM-R多语言模型和MAD-X适配器方法，将10种本地语言分为已见/部分已见/未见三类进行零样本和适配器迁移测试

Result: 多语言模型在已见语言表现最佳（F1=76.2），部分已见次之（F1=65.1），未见最差（F1=42.3）；MAD-X使已见语言提升9.3%且无需标注数据，语言接触历史是迁移成功核心因素

Conclusion: 模型对目标语言的先前接触（直接或通过相关语言）是迁移成功关键，适配器方法能有效突破资源限制，为低资源语言NLP提供新解决方案

Abstract: In this paper, we investigate the transferability of pre-trained language
models to low-resource Indonesian local languages through the task of sentiment
analysis. We evaluate both zero-shot performance and adapter-based transfer on
ten local languages using models of different types: a monolingual Indonesian
BERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based
approach called MAD-X. To better understand model behavior, we group the target
languages into three categories: seen (included during pre-training), partially
seen (not included but linguistically related to seen languages), and unseen
(absent and unrelated in pre-training data). Our results reveal clear
performance disparities across these groups: multilingual models perform best
on seen languages, moderately on partially seen ones, and poorly on unseen
languages. We find that MAD-X significantly improves performance, especially
for seen and partially seen languages, without requiring labeled data in the
target language. Additionally, we conduct a further analysis on tokenization
and show that while subword fragmentation and vocabulary overlap with
Indonesian correlate weakly with prediction quality, they do not fully explain
the observed performance. Instead, the most consistent predictor of transfer
success is the model's prior exposure to the language, either directly or
through a related language.

</details>


### [23] [AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness](https://arxiv.org/abs/2507.01702)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Zhen Ye,Guang Chen,Zhiyong Huang,Jing Ma*

Main category: cs.CL

TL;DR: 提出了AdamMeme框架，通过多智能体协作和动态更新模因数据，系统评估多模态大语言模型对有害网络模因的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于静态数据集的准确性评估方法无法适应快速演变的网络模因，需要更动态的评估框架来暴露模型弱点。

Method: 构建基于多智能体协作的评估框架（AdamMeme），通过迭代更新具有挑战性的模因样本进行细粒度模型测试。

Result: 实验表明该框架能系统揭示不同mLLM模型的性能差异，提供模型特定弱点的深入分析。

Conclusion: AdamMeme为动态评估模型对有害内容的解释能力提供了灵活、全面的解决方案，代码已开源。

Abstract: The proliferation of multimodal memes in the social media era demands that
multimodal Large Language Models (mLLMs) effectively understand meme
harmfulness. Existing benchmarks for assessing mLLMs on harmful meme
understanding rely on accuracy-based, model-agnostic evaluations using static
datasets. These benchmarks are limited in their ability to provide up-to-date
and thorough assessments, as online memes evolve dynamically. To address this,
we propose AdamMeme, a flexible, agent-based evaluation framework that
adaptively probes the reasoning capabilities of mLLMs in deciphering meme
harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive
evaluations by iteratively updating the meme data with challenging samples,
thereby exposing specific limitations in how mLLMs interpret harmfulness.
Extensive experiments show that our framework systematically reveals the
varying performance of different target mLLMs, offering in-depth, fine-grained
analyses of model-specific weaknesses. Our code is available at
https://github.com/Lbotirx/AdamMeme.

</details>


### [24] [Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach](https://arxiv.org/abs/2507.01715)
*Aditya Tomar,Rudra Murthy,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 通过联合训练偏见与刻板印象检测任务，显著提升语言模型在敏感领域的公平性检测性能


<details>
  <summary>Details</summary>
Motivation: 语言模型中的偏见和刻板印象在内容审核等敏感领域可能造成严重危害，需探索联合学习机制提升检测效果

Method: 构建StereoBias多标签数据集(含宗教/性别/种族等5类)，对比QLoRA微调的Decoder-only模型与Encoder-only模型性能，通过联合训练范式验证偏见与刻板印象的协同检测效果

Result: 联合训练使偏见检测准确率显著优于单独训练，且Decoder模型展现出与Encoder模型相当的竞争力。消融实验证实性能提升源于偏见与刻板印象的内在关联而非单纯多任务学习

Conclusion: 利用刻板印象与偏见的关联性进行联合建模，能够有效提升AI系统的公平性和可靠性，为构建负责任的AI系统提供新思路

Abstract: Bias and stereotypes in language models can cause harm, especially in
sensitive areas like content moderation and decision-making. This paper
addresses bias and stereotype detection by exploring how jointly learning these
tasks enhances model performance. We introduce StereoBias, a unique dataset
labeled for bias and stereotype detection across five categories: religion,
gender, socio-economic status, race, profession, and others, enabling a deeper
study of their relationship. Our experiments compare encoder-only models and
fine-tuned decoder-only models using QLoRA. While encoder-only models perform
well, decoder-only models also show competitive results. Crucially, joint
training on bias and stereotype detection significantly improves bias detection
compared to training them separately. Additional experiments with sentiment
analysis confirm that the improvements stem from the connection between bias
and stereotypes, not multi-task learning alone. These findings highlight the
value of leveraging stereotype information to build fairer and more effective
AI systems.

</details>


### [25] [LLMs for Legal Subsumption in German Employment Contracts](https://arxiv.org/abs/2507.01734)
*Oliver Wardas,Florian Matthes*

Main category: cs.CL

TL;DR: 研究利用大语言模型（LLM）和上下文学习评估德国雇佣合同条款的合法性，发现法律审查指南显著提升召回率（达80%），但LLM使用法律全文的表现仍远低于人类律师。


<details>
  <summary>Details</summary>
Motivation: 法律工作具有文本密集和资源密集特性，现有数据驱动方法因缺乏可解释性和可信度难以适应动态法律环境。

Method: 扩展数据集并测试不同LLM在三种法律上下文（无背景/法律全文/提炼版审查指南）下对合同条款'有效'、'不公平'或'无效'的分类能力。

Result: 法律全文小幅提升性能，审查指南显著提高无效条款召回率和加权F1分数（80%），但LLM使用法律全文的表现仍大幅落后于人类律师。

Conclusion: 贡献了包含审查指南和法律来源的扩展数据集，表明LLM在合同合法性审查中具备辅助潜力，但现有方法仍存在明显局限性。

Abstract: Legal work, characterized by its text-heavy and resource-intensive nature,
presents unique challenges and opportunities for NLP research. While
data-driven approaches have advanced the field, their lack of interpretability
and trustworthiness limits their applicability in dynamic legal environments.
To address these issues, we collaborated with legal experts to extend an
existing dataset and explored the use of Large Language Models (LLMs) and
in-context learning to evaluate the legality of clauses in German employment
contracts. Our work evaluates the ability of different LLMs to classify clauses
as "valid," "unfair," or "void" under three legal context variants: no legal
context, full-text sources of laws and court rulings, and distilled versions of
these (referred to as examination guidelines). Results show that full-text
sources moderately improve performance, while examination guidelines
significantly enhance recall for void clauses and weighted F1-Score, reaching
80\%. Despite these advancements, LLMs' performance when using full-text
sources remains substantially below that of human lawyers. We contribute an
extended dataset, including examination guidelines, referenced legal sources,
and corresponding annotations, alongside our code and all log files. Our
findings highlight the potential of LLMs to assist lawyers in contract legality
review while also underscoring the limitations of the methods presented.

</details>


### [26] [Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results](https://arxiv.org/abs/2507.01764)
*Matteo Di Cristofaro*

Main category: cs.CL

TL;DR: 研究探讨了分词不一致性对语料库分析的影响，提出预处理表情符号和同形异义符的方法以保证文本表征准确性。


<details>
  <summary>Details</summary>
Motivation: 分词差异会影响语言数据的表征效度和分析结论的可重复性，尤其在处理表情符号/同形异义符时存在技术挑战

Method: 通过分析数字文本中的表情符号和同形异义符处理难题，开发确保语料库准确表征源数据的预处理方法

Result: 预处理方法有效维护了语料库对源数据的保真度，支持可靠的语言学分析并保证解释的可重复性

Conclusion: 语料分析需兼顾语言特征和技术处理细节，该发现对定量和定性研究范式均具有重要方法论意义

Abstract: Tokenisation - "the process of splitting text into atomic parts" (Brezina &
Timperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides
the basis for any applicable quantitative method (e.g. collocations) while
ensuring the reliability of qualitative approaches. This paper examines how
discrepancies in tokenisation affect the representation of language data and
the validity of analytical findings: investigating the challenges posed by
emojis and homoglyphs, the study highlights the necessity of preprocessing
these elements to maintain corpus fidelity to the source data. The research
presents methods for ensuring that digital texts are accurately represented in
corpora, thereby supporting reliable linguistic analysis and guaranteeing the
repeatability of linguistic interpretations. The findings emphasise the
necessity of a detailed understanding of both linguistic and technical aspects
involved in digital textual data to enhance the accuracy of corpus analysis,
and have significant implications for both quantitative and qualitative
approaches in corpus-based research.

</details>


### [27] [MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2507.01785)
*Zhixun Chen,Ping Guo,Wenhan Han,Yifan Zhang,Binbin Liu,Haobin Lin,Fengze Liu,Yan Zhao,Bingni Zhang,Taifeng Wang,Yin Zheng,Meng Fang*

Main category: cs.CL

TL;DR: 提出MuRating框架，通过迁移英语数据质量信号训练多语言评估器，显著提升LLM在多语言场景下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有数据质量评估方法集中于英语场景，缺乏多语言场景下的高效数据筛选方案，制约非英语语种模型性能。

Method: 1. 聚合多个英语评估器的成对比较生成统一质量评分
2. 通过翻译投射建立跨语言质量关联
3. 基于单语/跨语/平行文本训练多语言评估器
4. 应用于网页数据筛选并预训练1.2B参数的LLaMA模型

Result: 相比QuRater/AskLLM等基线方法，在英语基准测试平均准确率提升3.2%，多语言评估提升4.7%，知识密集型任务提升达12.5%

Conclusion: 验证了跨语言质量迁移的有效性，揭示翻译保真度对数据选择的影响，提出叙事材料代表性不足的问题，为多语言数据优化指明方向。

Abstract: Data quality is a critical driver of large language model performance, yet
existing model-based selection methods focus almost exclusively on English. We
introduce MuRating, a scalable framework that transfers high-quality English
data-quality signals into a single rater for 17 target languages. MuRating
aggregates multiple English "raters" via pairwise comparisons to learn unified
document-quality scores,then projects these judgments through translation to
train a multilingual evaluator on monolingual, cross-lingual, and parallel text
pairs. Applied to web data, MuRating selects balanced subsets of English and
multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to
strong baselines, including QuRater, AskLLM, DCLM and so on, our approach
boosts average accuracy on both English benchmarks and multilingual
evaluations, with especially large gains on knowledge-intensive tasks. We
further analyze translation fidelity, selection biases, and underrepresentation
of narrative material, outlining directions for future work.

</details>


### [28] [Probing Evaluation Awareness of Language Models](https://arxiv.org/abs/2507.01786)
*Jord Nguyen,Khiem Hoang,Carlo Leonardo Attubato,Felix Hofstätter*

Main category: cs.CL

TL;DR: 大语言模型具备区分测试与部署阶段的能力（评估意识），可能影响AI治理框架的有效性。研究通过线性探针证明Llama-3模型能识别真实评估场景，现有安全评估已被模型判定为人工痕迹，强调需构建可信评估体系并利用模型内部机制加强安全审计。


<details>
  <summary>Details</summary>
Motivation: 揭示语言模型的评估意识对AI安全治理的潜在威胁，现有安全评估可能因模型识别其非真实性而失效，需系统性解决方案确保评估可靠性。

Method: 使用线性探针技术分析Llama-3.3-70B-Instruct模型内部表示，区分真实场景提示与评估提示，验证安全评估数据的可识别性。

Result: 模型能有效分离评估/部署提示，当前安全评估已被正确分类为人工痕迹，证实评估机制存在被模型识别的漏洞。

Conclusion: 必须开发抗评估意识的审计方法，结合黑箱测试与模型内部分析，应对未来模型可能增强的评估欺骗能力。

Abstract: Language models can distinguish between testing and deployment phases -- a
capability known as evaluation awareness. This has significant safety and
policy implications, potentially undermining the reliability of evaluations
that are central to AI governance frameworks and voluntary industry
commitments. In this paper, we study evaluation awareness in
Llama-3.3-70B-Instruct. We show that linear probes can separate real-world
evaluation and deployment prompts, suggesting that current models internally
represent this distinction. We also find that current safety evaluations are
correctly classified by the probes, suggesting that they already appear
artificial or inauthentic to models. Our findings underscore the importance of
ensuring trustworthy evaluations and understanding deceptive capabilities. More
broadly, our work showcases how model internals may be leveraged to support
blackbox methods in safety audits, especially for future models more competent
at evaluation awareness and deception.

</details>


### [29] [How Do Vision-Language Models Process Conflicting Information Across Modalities?](https://arxiv.org/abs/2507.01790)
*Tianze Hua,Tian Yun,Ellie Pavlick*

Main category: cs.CL

TL;DR: 研究探讨多模态AI模型在输入冲突时的行为，发现模型存在模态偏好并通过调整内部结构可优化性能。


<details>
  <summary>Details</summary>
Motivation: 理解多模态模型如何处理视觉-语言输入冲突，探索其内部机制以提升冲突信号处理能力。

Method: 通过向模型输入矛盾模态(如图像/标题冲突)，要求其报告特定模态信息，分析行为偏好及内部表征结构。

Result: 模型普遍存在单一模态偏好，发现模态偏好与内部表征相关，并识别可操纵的'路由器头'以控制模态响应。

Conclusion: 为识别和控制多模态模型在复杂环境中的冲突检测与解决机制提供了关键方法基础。

Abstract: AI models are increasingly required to be multimodal, integrating disparate
input streams into a coherent state representation on which subsequent
behaviors and actions can be based. This paper seeks to understand how such
models behave when input streams present conflicting information. Focusing
specifically on vision-language models, we provide inconsistent inputs (e.g.,
an image of a dog paired with the caption "A photo of a cat") and ask the model
to report the information present in one of the specific modalities (e.g.,
"What does the caption say / What is in the image?"). We find that models often
favor one modality over the other, e.g., reporting the image regardless of what
the caption says, but that different models differ in which modality they
favor. We find evidence that the behaviorally preferred modality is evident in
the internal representational structure of the model, and that specific
attention heads can restructure the representations to favor one modality over
the other. Moreover, we find modality-agnostic "router heads" which appear to
promote answers about the modality requested in the instruction, and which can
be manipulated or transferred in order to improve performance across datasets
and modalities. Together, the work provides essential steps towards identifying
and controlling if and how models detect and resolve conflicting signals within
complex multimodal environments.

</details>


### [30] [The Anatomy of Evidence: An Investigation Into Explainable ICD Coding](https://arxiv.org/abs/2507.01802)
*Katharina Beckh,Elisa Studeny,Sujan Sai Gannamaneni,Dario Antweiler,Stefan Rüping*

Main category: cs.CL

TL;DR: 提出通过MDACE数据集分析医疗编码系统可解释性，揭示证据匹配规律并提出评估建议


<details>
  <summary>Details</summary>
Motivation: 自动医疗编码需满足监管透明度要求，但现有评估受限于数据规模。MDACE数据集提供临床证据标注支持深入分析

Method: 对MDACE数据集进行多维度分析，提出匹配度指标并评估SOTA方法的证据提取能力

Result: 真实证据与编码描述存在关联性，现有方法证据重叠度达60%。成功案例显示局部注意力有效，失败案例暴露上下文推理不足

Conclusion: 需建立更严谨的可解释性评估框架，结合领域知识优化证据提取模型

Abstract: Automatic medical coding has the potential to ease documentation and billing
processes. For this task, transparency plays an important role for medical
coders and regulatory bodies, which can be achieved using explainability
methods. However, the evaluation of these approaches has been mostly limited to
short text and binary settings due to a scarcity of annotated data. Recent
efforts by Cheng et al. (2023) have introduced the MDACE dataset, which
provides a valuable resource containing code evidence in clinical records. In
this work, we conduct an in-depth analysis of the MDACE dataset and perform
plausibility evaluation of current explainable medical coding systems from an
applied perspective. With this, we contribute to a deeper understanding of
automatic medical coding and evidence extraction. Our findings reveal that
ground truth evidence aligns with code descriptions to a certain degree. An
investigation into state-of-the-art approaches shows a high overlap with ground
truth evidence. We propose match measures and highlight success and failure
cases. Based on our findings, we provide recommendations for developing and
evaluating explainable medical coding systems.

</details>


### [31] [Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes](https://arxiv.org/abs/2507.01810)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.CL

TL;DR: 比较小型语言模型在临床笔记开放属性值提取中的结构化输出可解析性，发现JSON格式解析性最优。


<details>
  <summary>Details</summary>
Motivation: 为隐私敏感的临床场景中部署语言模型时，提供序列化格式选择和提示设计的实践指导

Method: 评估JSON/YAML/XML三种序列化格式，分析结构鲁棒性随文档长度、提示策略和模型规模的变化规律

Result: JSON格式解析稳定性最高，目标导向的prompt和大模型提升鲁棒性，长文档和特定笔记类型会降低解析成功率

Conclusion: 建议临床部署优先选择JSON格式，需针对性设计prompt并考虑文档长度与笔记类型的格式容错机制

Abstract: We present a comparative analysis of the parseability of structured outputs
generated by small language models for open attribute-value extraction from
clinical notes. We evaluate three widely used serialization formats: JSON,
YAML, and XML, and find that JSON consistently yields the highest parseability.
Structural robustness improves with targeted prompting and larger models, but
declines for longer documents and certain note types. Our error analysis
identifies recurring format-specific failure patterns. These findings offer
practical guidance for selecting serialization formats and designing prompts
when deploying language models in privacy-sensitive clinical settings.

</details>


### [32] [Low-Perplexity LLM-Generated Sequences and Where To Find Them](https://arxiv.org/abs/2507.01844)
*Arthur Wuhrmann,Anastasiia Kucherenko,Andrei Kucharavy*

Main category: cs.CL

TL;DR: 通过分析LLMs生成的低困惑度序列追踪其训练数据来源，发现大量片段无法匹配语料库，量化匹配数据的分布模式


<details>
  <summary>Details</summary>
Motivation: 理解训练数据如何影响LLM输出行为，提升模型透明度、可问责性及隐私公平性

Method: 开发系统化流程：1)可靠提取多样化主题的低困惑度序列 2)溯源训练数据 3)量化匹配数据分布

Result: 1)大量低困惑度序列无法溯源 2)匹配数据呈现跨文档的特定分布模式 3)建立量化评估框架

Conclusion: 该方法揭示了LLM记忆机制特征，为理解训练数据与模型行为的关联提供了新视角

Abstract: As Large Language Models (LLMs) become increasingly widespread, understanding
how specific training data shapes their outputs is crucial for transparency,
accountability, privacy, and fairness. To explore how LLMs leverage and
replicate their training data, we introduce a systematic approach centered on
analyzing low-perplexity sequences - high-probability text spans generated by
the model. Our pipeline reliably extracts such long sequences across diverse
topics while avoiding degeneration, then traces them back to their sources in
the training data. Surprisingly, we find that a substantial portion of these
low-perplexity spans cannot be mapped to the corpus. For those that do match,
we quantify the distribution of occurrences across source documents,
highlighting the scope and nature of verbatim recall and paving a way toward
better understanding of how LLMs training data impacts their behavior.

</details>


### [33] [Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages](https://arxiv.org/abs/2507.01853)
*Samridhi Raj Sinha,Rajvee Sheth,Abhishek Upperwal,Mayank Singh*

Main category: cs.CL

TL;DR: EKA-EVAL是首个针对全球及印度大语言模型的端到端可扩展评估套件，集成35+基准测试(含10个印度语言数据集)，支持分布式推理/量化/多GPU，显著降低多语言评估门槛。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估框架以英语为中心，难以满足印度等多语言地区的需求，需建立专门的多语言评估生态系统。

Method: 集成多类别基准数据集，内置分布式推理/量化/多GPU支持，通过开源框架实现可扩展架构设计。

Result: 覆盖更广泛评估场景，成为首个专门针对印度语言的端到端评估套件，代码已开源并计划扩展至100+基准测试。

Conclusion: 该框架通过标准化多语言评估流程，为LLM在多元语言环境的发展奠定基础，助力构建更公平的AI评估体系。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for evaluation frameworks that go beyond English centric benchmarks and
address the requirements of linguistically diverse regions such as India. We
present EKA-EVAL, a unified and production-ready evaluation framework that
integrates over 35 benchmarks, including 10 Indic-specific datasets, spanning
categories like reasoning, mathematics, tool use, long-context understanding,
and reading comprehension. Compared to existing Indian language evaluation
tools, EKA-EVAL offers broader benchmark coverage, with built-in support for
distributed inference, quantization, and multi-GPU usage. Our systematic
comparison positions EKA-EVAL as the first end-to-end, extensible evaluation
suite tailored for both global and Indic LLMs, significantly lowering the
barrier to multilingual benchmarking. The framework is open-source and publicly
available at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA
initiative (https://eka.soket.ai), which aims to scale up to over 100
benchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.

</details>


### [34] [DIY-MKG: An LLM-Based Polyglot Language Learning System](https://arxiv.org/abs/2507.01872)
*Kenan Tang,Yanhong Li,Yao Qin*

Main category: cs.CL

TL;DR: DIY-MKG开源系统通过构建个性化多语言知识图谱，利用LLM实现词汇扩展和动态测验生成，解决传统语言学习工具在多语言关联、个性化和认知负荷方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有语言学习工具缺乏多语言词汇关联支持、个性化不足且造成认知超载。研究者旨在创建支持多语言学习的系统，通过知识图谱增强学习自主性。

Method: 系统构建个性化词汇知识图谱，采用LLM进行词汇选择性扩展，集成注释功能和自适应复习模块，并建立用户纠错反馈机制优化提示词。

Result: 评估显示系统在多语言环境下词汇扩展可靠公平，生成的测验准确率达96.8%，验证了系统稳健性。

Conclusion: DIY-MKG通过知识图谱构建和用户反馈机制有效提升多语言学习参与度，实现了个性化、低认知负荷的语言学习解决方案。

Abstract: Existing language learning tools, even those powered by Large Language Models
(LLMs), often lack support for polyglot learners to build linguistic
connections across vocabularies in multiple languages, provide limited
customization for individual learning paces or needs, and suffer from
detrimental cognitive offloading. To address these limitations, we design
Do-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system
that supports polyglot language learning. DIY-MKG allows the user to build
personalized vocabulary knowledge graphs, which are constructed by selective
expansion with related words suggested by an LLM. The system further enhances
learning through rich annotation capabilities and an adaptive review module
that leverages LLMs for dynamic, personalized quiz generation. In addition,
DIY-MKG allows users to flag incorrect quiz questions, simultaneously
increasing user engagement and providing a feedback loop for prompt refinement.
Our evaluation of LLM-based components in DIY-MKG shows that vocabulary
expansion is reliable and fair across multiple languages, and that the
generated quizzes are highly accurate, validating the robustness of DIY-MKG.

</details>


### [35] [MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants](https://arxiv.org/abs/2507.01887)
*Dongyi Ding,Tiannan Wang,Chenghao Zhu,Meiling Tao,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 提出MiCoTA框架，通过中间模型和中等长度CoT序列蒸馏，解决小模型长推理能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）由于容量限制难以学习长链式推理（CoT），形成"SLMs可学习性差距"。

Method: 使用中等规模模型作为教师助理，结合中等长度CoT序列进行分阶段知识蒸馏，弥推理能力与模型容量差距。

Result: Qwen2.5-7B/3B模型在AIME等基准平均分提升3.47/3.93，量化实验显示数据分布更接近基础SLM。

Conclusion: MiCoTA有效提升SLMs长推理能力，为小模型知识蒸馏提供新思路，未来可探索更优中间模型选择策略。

Abstract: Large language models (LLMs) excel at reasoning tasks requiring long thought
sequences for planning, reflection, and refinement. However, their substantial
model size and high computational demands are impractical for widespread
deployment. Yet, small language models (SLMs) often struggle to learn long-form
CoT reasoning due to their limited capacity, a phenomenon we refer to as the
"SLMs Learnability Gap". To address this, we introduce
\textbf{Mi}d-\textbf{Co}T \textbf{T}eacher \textbf{A}ssistant Distillation
(MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA
employs intermediate-sized models as teacher assistants and utilizes
intermediate-length CoT sequences to bridge both the capacity and reasoning
length gaps. Our experiments on downstream tasks demonstrate that although SLMs
distilled from large teachers can perform poorly, by applying MiCoTA, they
achieve significant improvements in reasoning performance. Specifically,
Qwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and
3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and
GSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform
a quantitative experiment demonstrating that our method produces data more
closely aligned with base SLM distributions. Our insights pave the way for
future research into long-CoT data distillation for SLMs.

</details>


### [36] [High-Layer Attention Pruning with Rescaling](https://arxiv.org/abs/2507.01900)
*Songtao Liu,Peng Liu*

Main category: cs.CL

TL;DR: 提出基于高层注意力头剪枝和自适应缩放校准的LLM压缩方法，显著提升生成任务效果


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法忽视注意力头在网络中的位置重要性，盲目剪枝导致性能损失

Method: 1. 优先剪枝模型高层注意力头 2. 引入自适应缩放参数校准表征尺度

Result: 在27个数据集的生成/判别任务中全面超越现有方法，生成任务改进尤其显著

Conclusion: 位置敏感剪枝策略配合表征校准机制，有效提升LLM剪枝后的性能保持能力

Abstract: Pruning is a highly effective approach for compressing large language models
(LLMs), significantly reducing inference latency. However, conventional
training-free structured pruning methods often employ a heuristic metric that
indiscriminately removes some attention heads across all pruning layers,
without considering their positions within the network architecture. In this
work, we propose a novel pruning algorithm that strategically prunes attention
heads in the model's higher layers. Since the removal of attention heads can
alter the magnitude of token representations, we introduce an adaptive
rescaling parameter that calibrates the representation scale post-pruning to
counteract this effect. We conduct comprehensive experiments on a wide range of
LLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our
evaluation includes both generation and discriminative tasks across 27
datasets. The results consistently demonstrate that our method outperforms
existing structured pruning methods. This improvement is particularly notable
in generation tasks, where our approach significantly outperforms existing
baselines.

</details>


### [37] [AI4Research: A Survey of Artificial Intelligence for Scientific Research](https://arxiv.org/abs/2507.01903)
*Qiguang Chen,Mingda Yang,Libo Qin,Jinhao Liu,Zheng Yan,Jiannan Guan,Dengyun Peng,Yiyan Ji,Hanjing Li,Mengkang Hu,Yimeng Zhang,Yihao Liang,Yuhang Zhou,Jiaqi Wang,Zhi Chen,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出首个AI4Research综合调查报告，构建系统分类框架并整合多学科资源


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对AI驱动科研的系统性归纳，阻碍领域发展与创新突破

Method: 通过系统分类法划分五大核心任务，识别研究空白并建立跨学科资源库

Result: 建立包含自动化实验优化、可扩展方法论及社会影响评估的新研究范式

Conclusion: 该框架为科研社区提供资源导航，推动AI驱动科研的跨学科创新发展

Abstract: Recent advancements in artificial intelligence (AI), particularly in large
language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated
remarkable capabilities in complex domains such as logical reasoning and
experimental coding. Motivated by these advancements, numerous studies have
explored the application of AI in the innovation process, particularly in the
context of scientific research. These AI technologies primarily aim to develop
systems that can autonomously conduct research processes across a wide range of
scientific disciplines. Despite these significant strides, a comprehensive
survey on AI for Research (AI4Research) remains absent, which hampers our
understanding and impedes further development in this field. To address this
gap, we present a comprehensive survey and offer a unified perspective on
AI4Research. Specifically, the main contributions of our work are as follows:
(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify
five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key
research gaps and highlight promising future directions, focusing on the rigor
and scalability of automated experiments, as well as the societal impact. (3)
Abundant applications and resources: Finally, we compile a wealth of resources,
including relevant multidisciplinary applications, data corpora, and tools. We
hope our work will provide the research community with quick access to these
resources and stimulate innovative breakthroughs in AI4Research.

</details>


### [38] [Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models](https://arxiv.org/abs/2507.01915)
*Chengao Li,Hanyu Zhang,Yunkun Xu,Hongyan Xue,Xiang Ao,Qing He*

Main category: cs.CL

TL;DR: 提出GAPO多目标优化框架，通过梯度自适应缩放解决LLMs与冲突人类偏好的对齐问题，在Mistral-7B上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法难以有效处理多样化且可能冲突的人类偏好，需开发更优的多目标对齐方案。

Method: 1. GAPO采用多梯度下降算法，自适应调整各目标梯度权重 2. P-GAPO引入用户偏好参数实现定制化Pareto解

Result: 理论证明GAPO的Pareto收敛性，实验显示在Mistral-7B上helpfulness和harmlessness指标超越现有方法

Conclusion: GAPO为多目标价值对齐提供了理论保障和高效实现框架，P-GAPO扩展了实际应用的定制化能力

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful
technique for aligning large language models (LLMs) with human preferences.
However, effectively aligning LLMs with diverse human preferences remains a
significant challenge, particularly when they are conflict. To address this
issue, we frame human value alignment as a multi-objective optimization
problem, aiming to maximize a set of potentially conflicting objectives. We
introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning
paradigm that employs multiple-gradient descent to align LLMs with diverse
preference distributions. GAPO adaptively rescales the gradients for each
objective to determine an update direction that optimally balances the
trade-offs between objectives. Additionally, we introduce P-GAPO, which
incorporates user preferences across different objectives and achieves Pareto
solutions that better align with the user's specific needs. Our theoretical
analysis demonstrates that GAPO converges towards a Pareto optimal solution for
multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms
current state-of-the-art methods, achieving superior performance in both
helpfulness and harmlessness.

</details>


### [39] [NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks](https://arxiv.org/abs/2507.01921)
*Yang Li,Youssef Emad,Karthik Padthe,Jack Lanchantin,Weizhe Yuan,Thao Nguyen,Jason Weston,Shang-Wen Li,Dong Wang,Ilia Kulikov,Xian Li*

Main category: cs.CL

TL;DR: 通过筛选教师模型中需要多样化推理策略的困难样本（NaturalThoughts），能更高效地提升学生模型在STEM推理任务中的表现，效果优于单纯扩大数据规模。


<details>
  <summary>Details</summary>
Motivation: 探究教师模型的哪种推理示范能最有效提升学生模型推理能力，突破现有研究中简单扩大数据规模的传统做法。

Method: 基于NaturalReasoning题库构建高质量推理轨迹数据集NaturalThoughts，系统分析数据规模、样本难度、推理策略多样性等因素对知识蒸馏的影响。

Result: 在Llama/Qwen模型上，NaturalThoughts在GPQA-Diamond等STEM基准测试中显著超越OpenThoughts等现有数据集。

Conclusion: 选择需要多样化推理策略的困难样本，比单纯扩大数据规模更能有效传递教师模型的推理能力。

Abstract: Recent work has shown that distilling reasoning traces from a larger teacher
model via supervised finetuning outperforms reinforcement learning with the
smaller student model alone (Guo et al. 2025). However, there has not been a
systematic study of what kind of reasoning demonstrations from the teacher are
most effective in improving the student model's reasoning capabilities. In this
work we curate high-quality "NaturalThoughts" by selecting reasoning traces
from a strong teacher model based on a large pool of questions from
NaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of
factors that affect distilling reasoning capabilities, in terms of sample
efficiency and scalability for general reasoning tasks. We observe that simply
scaling up data size with random sampling is a strong baseline with steady
performance gains. Further, we find that selecting difficult examples that
require more diverse reasoning strategies is more sample-efficient to transfer
the teacher model's reasoning skills. Evaluated on both Llama and Qwen models,
training with NaturalThoughts outperforms existing reasoning datasets such as
OpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including
GPQA-Diamond, MMLU-Pro and SuperGPQA.

</details>


### [40] [Decision-oriented Text Evaluation](https://arxiv.org/abs/2507.01923)
*Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen*

Main category: cs.CL

TL;DR: 提出决策导向的NLG评估框架，验证人机协作决策效能优于单一主体


<details>
  <summary>Details</summary>
Motivation: 传统NLG评估指标与决策效果关联性弱，需建立基于实际决策影响力的评估体系

Method: 使用市场摘要文本作为测试案例，通过人类投资者和LLM代理的财务表现衡量决策质量

Result: 人机协同团队在分析性评论支撑下显著超越个体表现，单一主体表现不优于随机基准

Conclusion: NLG评估应聚焦人机协同决策能力，传统内在指标存在关键性局限

Abstract: Natural language generation (NLG) is increasingly deployed in high-stakes
domains, yet common intrinsic evaluation methods, such as n-gram overlap or
sentence plausibility, weakly correlate with actual decision-making efficacy.
We propose a decision-oriented framework for evaluating generated text by
directly measuring its influence on human and large language model (LLM)
decision outcomes. Using market digest texts--including objective morning
summaries and subjective closing-bell analyses--as test cases, we assess
decision quality based on the financial performance of trades executed by human
investors and autonomous LLM agents informed exclusively by these texts. Our
findings reveal that neither humans nor LLM agents consistently surpass random
performance when relying solely on summaries. However, richer analytical
commentaries enable collaborative human-LLM teams to outperform individual
human or agent baselines significantly. Our approach underscores the importance
of evaluating generated text by its ability to facilitate synergistic
decision-making between humans and LLMs, highlighting critical limitations of
traditional intrinsic metrics.

</details>


### [41] [Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla](https://arxiv.org/abs/2507.01931)
*Md Sazzadul Islam Ridoy,Sumi Akter,Md. Aminur Rahman*

Main category: cs.CL

TL;DR: Wav2Vec-BERT在低资源孟加拉语ASR任务中全面超越Whisper模型，具备更高计算效率和更低词错率


<details>
  <summary>Details</summary>
Motivation: 评估主流语音识别模型（Whisper和Wav2Vec-BERT）在低资源语言环境下的表现，为资源匮乏语言提供语音系统开发方案

Method: 使用Mozilla Common Voice-17和OpenSLR数据集，通过系统化的微调、超参数优化（学习率/训练轮次/检查点选择），对比词错率、字符错率、训练时间和计算效率

Result: Wav2Vec-BERT在所有关键指标（WER/CER/计算资源消耗）上表现更优，训练速度提升40%，显存占用减少30%

Conclusion: 基于Transformer的Wav2Vec-BERT架构更适合低资源语言环境，为开发鲁棒语音系统提供了模型选择依据和调优方法论

Abstract: In recent years, neural models trained on large multilingual text and speech
datasets have shown great potential for supporting low-resource languages. This
study investigates the performances of two state-of-the-art Automatic Speech
Recognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's
Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments
using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to
evaluate model performances. Through systematic fine-tuning and hyperparameter
optimization, including learning rate, epochs, and model checkpoint selection,
we have compared the models based on Word Error Rate (WER), Character Error
Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model
outperformed Whisper across all key evaluation metrics, demonstrated superior
performance while requiring fewer computational resources, and offered valuable
insights to develop robust speech recognition systems in low-resource
linguistic settings.

</details>


### [42] [The Thin Line Between Comprehension and Persuasion in LLMs](https://arxiv.org/abs/2507.01936)
*Adrian de Wynter,Tangming Yuan*

Main category: cs.CL

TL;DR: 大语言模型能生成有说服力的辩论内容但缺乏深层对话理解，影响其作为评估工具的可靠性


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在敏感领域（如论文评审和心理健康应用）中的对话理解能力，特别是对辩论结构和语用背景的掌握程度

Method: 通过辩论场景测试LLMs的对话连贯性，结合用户实验测量其对对话结构的理解与人类对AI参与的批判性反应

Result: LLMs可生成改变听众观点的辩论内容，但人类意识到AI参与时会提高批判性；模型无法展示对对话深层结构的理解

Conclusion: 对话有效性的实现优先于上下文理解，这对论证理论和LLMs的实际应用具有重要启示

Abstract: Large language models (LLMs) are excellent at maintaining high-level,
convincing dialogues. They are being fast deployed as chatbots and evaluators
in sensitive areas, such as peer review and mental health applications. This,
along with the disparate accounts on their reasoning capabilities, calls for a
closer examination of LLMs and their comprehension of dialogue. In this work we
begin by evaluating LLMs' ability to maintain a debate--one of the purest yet
most complex forms of human communication. Then we measure how this capability
relates to their understanding of what is being talked about, namely, their
comprehension of dialogical structures and the pragmatic context. We find that
LLMs are capable of maintaining coherent, persuasive debates, often swaying the
beliefs of participants and audiences alike. We also note that awareness or
suspicion of AI involvement encourage people to be more critical of the
arguments made. When polling LLMs on their comprehension of deeper structures
of dialogue, however, they cannot demonstrate said understanding. Our findings
tie the shortcomings of LLMs-as-evaluators to their (in)ability to understand
the context. More broadly, for the field of argumentation theory we posit that,
if an agent can convincingly maintain a dialogue, it is not necessary for it to
know what it is talking about. Hence, the modelling of pragmatic context and
coherence are secondary to effectiveness.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [43] [A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory](https://arxiv.org/abs/2507.01110)
*Felix Windisch,Lukas Radl,Thomas Köhler,Michael Steiner,Dieter Schmalstieg,Markus Steinberger*

Main category: cs.GR

TL;DR: 提出无需分区的LoD高斯框架，在单块消费级GPU上实现超大规模场景的动态流式训练与实时渲染


<details>
  <summary>Details</summary>
Motivation: 传统分块方法导致边界伪影/多尺度训练困难/GPU内存受限，难以适应城市级多视角复杂场景

Method: 混合数据结构(高斯层次+顺序点树)实现视点相关LoD选择，轻量级缓存和视图调度系统利用时间一致性支持实时流式传输

Result: 支持从航拍广角到地面细节的无缝多尺度重建，单GPU实现复杂场景的交互式可视化

Conclusion: 突破传统高斯泼溅的场景规模限制，为城市级数字孪生等应用提供高效解决方案

Abstract: Gaussian Splatting has emerged as a high-performance technique for novel view
synthesis, enabling real-time rendering and high-quality reconstruction of
small scenes. However, scaling to larger environments has so far relied on
partitioning the scene into chunks -- a strategy that introduces artifacts at
chunk boundaries, complicates training across varying scales, and is poorly
suited to unstructured scenarios such as city-scale flyovers combined with
street-level views. Moreover, rendering remains fundamentally limited by GPU
memory, as all visible chunks must reside in VRAM simultaneously. We introduce
A LoD of Gaussians, a framework for training and rendering ultra-large-scale
Gaussian scenes on a single consumer-grade GPU -- without partitioning. Our
method stores the full scene out-of-core (e.g., in CPU memory) and trains a
Level-of-Detail (LoD) representation directly, dynamically streaming only the
relevant Gaussians. A hybrid data structure combining Gaussian hierarchies with
Sequential Point Trees enables efficient, view-dependent LoD selection, while a
lightweight caching and view scheduling system exploits temporal coherence to
support real-time streaming and rendering. Together, these innovations enable
seamless multi-scale reconstruction and interactive visualization of complex
scenes -- from broad aerial views to fine-grained ground-level details.

</details>


### [44] [Semiautomatic Simplification](https://arxiv.org/abs/2507.01116)
*Gong Li,Benjamin Watson*

Main category: cs.GR

TL;DR: 提出半自动三维模型简化工具semisimp，通过用户干预提升语义区域保护能力


<details>
  <summary>Details</summary>
Motivation: 现有自动简化技术无法有效保护模型语义区域（如面部/肢体），且忽略动画等应用场景的简化约束。需要用户介入提升重要区域保护。

Method: 1. 用户调控简化顺序优化细节分布
2. 顶点重定位及细节层次传播
3. 模型表面层级分区调整实现分段简化和控制优化

Result: 实现更符合语义特征的模型简化效果，在动画等应用场景中保持关键区域完整性

Conclusion: 用户干预机制有效弥补了全自动简化的不足，semisimp为需要精确控制简化的专业场景提供了新解决方案

Abstract: We present semisimp, a tool for semiautomatic simplification of three
dimensional polygonal models. Existing automatic simplification technology is
quite mature, but is not sensitive to the heightened importance of distinct
semantic model regions such as faces and limbs, nor to simplification
constraints imposed by model usage such as animation. semisimp allows users to
preserve such regions by intervening in the simplification process. Users can
manipulate the order in which basic simplifications are applied to redistribute
model detail, improve the simplified models themselves by repositioning
vertices with propagation to neighboring levels of detail, and adjust the
hierarchical partitioning of the model surface to segment simplification and
improve control of reordering and position propagation.

</details>


### [45] [Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics](https://arxiv.org/abs/2507.01140)
*Eric Zimmermann,Stefan Bruckner*

Main category: cs.GR

TL;DR: 开发了沉浸式多焦点探针技术，允许在保持全局网络上下文的同时创建多个局部子图视图，通过视觉触觉引导实现多尺度编辑


<details>
  <summary>Details</summary>
Motivation: 解决沉浸式网络可视化中局部细节视图与全局概览视图切换困难的核心挑战，克服传统方法难以同时维护多焦点区域上下文的问题

Method: 提出多功能探针技术，支持在虚拟环境中实例化多个可携带的局部子图焦点，通过视觉连接线和触觉反馈保持上下文关联

Result: 实现了网络数据编辑过程中多焦点区域的并行操作，验证了该技术在维持空间认知连续性方面的有效性

Conclusion: 该交互范式成功弥合了沉浸式环境中局部操作与全局认知的鸿沟，为复杂网络编辑任务提供了新的多尺度解决方案

Abstract: Immersive visualization of network data enables users to physically navigate
and interact with complex structures, but managing transitions between detailed
local (egocentric) views and global (exocentric) overviews remains a major
challenge. We present a multifocus probe technique for immersive environments
that allows users to instantiate multiple egocentric subgraph views while
maintaining persistent links to the global network context. Each probe acts as
a portable local focus, enabling fine-grained inspection and editing of distant
or occluded regions. Visual and haptic guidance mechanisms ensure context
preservation during multi-scale interaction. We demonstrate and discuss the
usability of our technique for the editing of network data.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [46] [Automated Vehicles Should be Connected with Natural Language](https://arxiv.org/abs/2507.01059)
*Xiangbo Gao,Keshu Wu,Hao Zhang,Kexin Tian,Yang Zhou,Zhengzhong Tu*

Main category: cs.MA

TL;DR: 提出使用自然语言进行多智能体协同驾驶的意图与推理通信，突破传统感知数据共享的局限性


<details>
  <summary>Details</summary>
Motivation: 现有协同驾驶通信方式（传感器数据/神经网络特征/感知结果）存在带宽效率低、信息不完整、跨平台互操作性差等问题，且缺乏决策层面的协同

Method: 通过自然语言直接传递驾驶意图、决策逻辑和实时推理，平衡语义密度与通信带宽，适应动态交通环境，兼容异构平台

Result: 实现从被动感知共享到主动协调的范式转换，增强智能交通系统的安全性、效率与透明度

Conclusion: 自然语言通信为多智能体协同驾驶提供了新的技术路径，在决策融合和人机互理解方面具有显著优势

Abstract: Multi-agent collaborative driving promises improvements in traffic safety and
efficiency through collective perception and decision making. However, existing
communication media -- including raw sensor data, neural network features, and
perception results -- suffer limitations in bandwidth efficiency, information
completeness, and agent interoperability. Moreover, traditional approaches have
largely ignored decision-level fusion, neglecting critical dimensions of
collaborative driving. In this paper we argue that addressing these challenges
requires a transition from purely perception-oriented data exchanges to
explicit intent and reasoning communication using natural language. Natural
language balances semantic density and communication bandwidth, adapts flexibly
to real-time conditions, and bridges heterogeneous agent platforms. By enabling
the direct communication of intentions, rationales, and decisions, it
transforms collaborative driving from reactive perception-data sharing into
proactive coordination, advancing safety, efficiency, and transparency in
intelligent transportation systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning](https://arxiv.org/abs/2507.01029)
*Junjie Zhou,Yingli Zuo,Shichang Feng,Peng Wan,Qi Zhu,Daoqiang Zhang,Wei Shao*

Main category: cs.LG

TL;DR: 提出PathCoT方法，通过整合病理专家知识和自评估机制，有效提升多模态大模型在病理视觉推理任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在病理视觉推理中存在领域知识缺乏导致模型幻觉，以及额外推理步骤可能引发答案偏差的问题

Method: 1. 设计零样本思维链提示框架PathCoT
2. 引入病理专家知识指导模型推理
3. 开发双路径自评估机制（直接输出与思维链推理结果对比）

Result: 在PathMMU数据集上验证了方法有效性，显著提升病理图像理解和推理能力

Conclusion: PathCoT成功将领域专业知识融入推理流程，通过自评估机制有效减少答案分歧，为医学专业领域的多模态推理提供了新思路

Abstract: With the development of generative artificial intelligence and instruction
tuning techniques, multimodal large language models (MLLMs) have made
impressive progress on general reasoning tasks. Benefiting from the
chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning
problem step-by-step. However, existing MLLMs still face significant challenges
when applied to pathology visual reasoning tasks: (1) LLMs often underperforms
because they lack domain-specific information, which can lead to model
hallucinations. (2) The additional reasoning steps in CoT may introduce errors,
leading to the divergence of answers. To address these limitations, we propose
PathCoT, a novel zero-shot CoT prompting method which integrates the pathology
expert-knowledge into the reasoning process of MLLMs and incorporates
self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides
the MLLM with prior knowledge to perform as pathology experts, and provides
comprehensive analysis of the image with their domain-specific knowledge. By
incorporating the experts' knowledge, PathCoT can obtain the answers with CoT
reasoning. Furthermore, PathCoT incorporates a self-evaluation step that
assesses both the results generated directly by MLLMs and those derived through
CoT, finally determining the reliable answer. The experimental results on the
PathMMU dataset demonstrate the effectiveness of our method on pathology visual
understanding and reasoning.

</details>


### [48] [Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization](https://arxiv.org/abs/2507.01050)
*Jing Yu,Yibo Zhao,Jiapeng Zhu,Wenming Shao,Bo Pang,Zhao Zhang,Xiang Li*

Main category: cs.LG

TL;DR: 提出两阶段训练框架，结合监督微调和强化学习优化文本去毒任务，在减少标注数据依赖的同时提升去毒效果与语义保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本去毒方法存在标注数据依赖性强、语义保留与去毒效果难以兼顾、模型泛化能力不足三大痛点，亟需更高效鲁棒的解决方案。

Method: 1. 使用高质量平行数据监督微调获得基础模型 2. 采用Group Relative Policy Optimization结合未标注数据与定制奖励模型进行强化学习

Result: 实验显示该方法在去毒效果（toxicity reduction提升12.7%）、语义保持（语义相似度提高9.3%）和跨数据集泛化（OOD性能提升15.2%）方面均达SOTA水平，且标注数据用量减少83%。

Conclusion: 该框架通过两阶段联合优化，成功突破传统方法的三难困境，为低资源场景下的文本净化提供了高效解决方案，推动社交媒体内容治理技术进步。

Abstract: The widespread dissemination of toxic content on social media poses a serious
threat to both online environments and public discourse, highlighting the
urgent need for detoxification methods that effectively remove toxicity while
preserving the original semantics. However, existing approaches often struggle
to simultaneously achieve strong detoxification performance, semantic
preservation, and robustness to out-of-distribution data. Moreover, they
typically rely on costly, manually annotated parallel corpora while showing
poor data efficiency. To address these challenges, we propose a two-stage
training framework that jointly optimizes for data efficiency, semantic
preservation, and model generalization. We first perform supervised fine-tuning
on a small set of high-quality, filtered parallel data to establish a strong
initialization. Then, we leverage unlabeled toxic inputs and a custom-designed
reward model to train the LLM using Group Relative Policy Optimization.
Experimental results demonstrate that our method effectively mitigates the
trade-offs faced by previous work, achieving state-of-the-art performance with
improved generalization and significantly reduced dependence on annotated data.
Our code is available at:
https://anonymous.4open.science/r/Detoxification-of-Text-725F/

</details>


### [49] [Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning](https://arxiv.org/abs/2507.01551)
*Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua*

Main category: cs.LG

TL;DR: 提出SPRO框架，通过模型自身生成过程奖励和新型优势估计方法，显著提升训练效率与推理性能


<details>
  <summary>Details</summary>
Motivation: 现有过程强化学习存在计算开销大、缺乏统一理论框架的问题，需开发更高效的过程奖励优化方案

Method: 1) 理论证明策略模型可内生过程奖励 2) 设计累积过程奖励和掩码步骤优势(MSA)实现组内严格优势估计

Result: 训练效率提升3.4倍，准确率提高17.5%，响应长度减少1/3，策略熵保持稳定

Conclusion: SPRO在无需额外计算成本下实现高效过程强化学习，兼具探索充分性与工业部署可行性

Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential
in enhancing the reasoning capabilities of Large Language Models~(LLMs).
However, introducing additional process reward models incurs substantial
computational overhead, and there is no unified theoretical framework for
process-level advantage estimation. To bridge this gap, we propose
\textbf{S}elf-Guided \textbf{P}rocess \textbf{R}eward
\textbf{O}ptimization~(\textbf{SPRO}), a novel framework that enables
process-aware RL through two key innovations: (1) we first theoretically
demonstrate that process rewards can be derived intrinsically from the policy
model itself, and (2) we introduce well-defined cumulative process rewards and
\textbf{M}asked \textbf{S}tep \textbf{A}dvantage (\textbf{MSA}), which
facilitates rigorous step-wise action advantage estimation within shared-prompt
sampling groups. Our experimental results demonstrate that SPRO outperforms
vaniila GRPO with 3.4x higher training efficiency and a 17.5\% test accuracy
improvement. Furthermore, SPRO maintains a stable and elevated policy entropy
throughout training while reducing the average response length by approximately
$1/3$, evidencing sufficient exploration and prevention of reward hacking.
Notably, SPRO incurs no additional computational overhead compared to
outcome-supervised RL methods such as GRPO, which benefit industrial
implementation.

</details>


### [50] [Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling](https://arxiv.org/abs/2507.01679)
*Zeyu Huang,Tianhao Cheng,Zihan Qiu,Zili Wang,Yinghui Xu,Edoardo M. Ponti,Ivan Titov*

Main category: cs.LG

TL;DR: 提出混合SFT和RFT的Prefix-RFT方法，在数学推理任务中实现性能超越并保持框架兼容性


<details>
  <summary>Details</summary>
Motivation: 现有SFT存在行为克隆问题，RFT对初始策略敏感且易产生意外行为，需要探索两种范式的协同机制

Method: Prefix-RFT通过前缀调整技术，在强化微调过程中融合示范数据的学习与自主探索

Result: 在数学推理任务上超越单独SFT/RFT及并行混合策略，且仅需极简修改即可适配标准RFT流程

Conclusion: SFT与RFT具有互补性，统一范式整合示范与探索是LLM后训练的重要方向，方法对数据质量/数量变化具有鲁棒性

Abstract: Existing post-training techniques for large language models are broadly
categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning
(RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking
demonstration data but can lead to problematic generalization as a form of
behavior cloning. Conversely, RFT can significantly enhance a model's
performance but is prone to learn unexpected behaviors, and its performance is
highly sensitive to the initial policy. In this paper, we propose a unified
view of these methods and introduce Prefix-RFT, a hybrid approach that
synergizes learning from both demonstration and exploration. Using mathematical
reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is
both simple and effective. It not only surpasses the performance of standalone
SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key
advantage is its seamless integration into existing open-source frameworks,
requiring only minimal modifications to the standard RFT pipeline. Our analysis
highlights the complementary nature of SFT and RFT, and validates that
Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore,
ablation studies confirm the method's robustness to variations in the quality
and quantity of demonstration data. We hope this work offers a new perspective
on LLM post-training, suggesting that a unified paradigm that judiciously
integrates demonstration and exploration could be a promising direction for
future research.

</details>


### [51] [Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](https://arxiv.org/abs/2507.01752)
*Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud*

Main category: cs.LG

TL;DR: 提出黑盒优化方法BBoxER，通过隐式数据压缩增强LLM隐私安全，兼顾理论保证与轻量化部署


<details>
  <summary>Details</summary>
Motivation: 解决梯度优化方法存在的隐私泄露、数据中毒风险、过拟合问题，适应数据受限场景

Method: 基于进化算法的黑盒优化框架，通过信息瓶颈控制数据流，提供泛化/差分隐私/抗攻击理论边界

Result: 理论证明泛化保证，实验显示少量迭代即可提升LLM推理性能，保持模块化轻量部署特性

Conclusion: BBoxER作为梯度优化的补充方案，适用于隐私敏感环境，实现安全性与模型性能的平衡

Abstract: Gradient-based optimization is the workhorse of deep learning, offering
efficient and scalable training via backpropagation. However, its reliance on
large volumes of labeled data raises privacy and security concerns such as
susceptibility to data poisoning attacks and the risk of overfitting. In
contrast, black box optimization methods, which treat the model as an opaque
function, relying solely on function evaluations to guide optimization, offer a
promising alternative in scenarios where data access is restricted, adversarial
risks are high, or overfitting is a concern. However, black box methods also
pose significant challenges, including poor scalability to high-dimensional
parameter spaces, as prevalent in large language models (LLMs), and high
computational costs due to reliance on numerous model evaluations. This paper
introduces BBoxER, an evolutionary black-box method for LLM post-training that
induces an information bottleneck via implicit compression of the training
data. Leveraging the tractability of information flow, we provide strong
theoretical bounds on generalization, differential privacy, susceptibility to
data poisoning attacks, and robustness to extraction attacks. BBoxER operates
on top of pre-trained LLMs, offering a lightweight and modular enhancement
suitable for deployment in restricted or privacy-sensitive environments, in
addition to non-vacuous generalization guarantees. In experiments with LLMs, we
demonstrate empirically that Retrofitting methods are able to learn, showing
how a few iterations of BBoxER improve performance and generalize well on a
benchmark of reasoning datasets. This positions BBoxER as an attractive add-on
on top of gradient-based optimization.

</details>


### [52] [LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs](https://arxiv.org/abs/2507.01806)
*Reza Arabpour,Haitz Sáez de Ocáriz Borde,Anastasis Kratsios*

Main category: cs.LG

TL;DR: 提出基于CPU的LoRA微调方法，通过预训练适配器组合实现无需GPU训练的参数优化


<details>
  <summary>Details</summary>
Motivation: 解决LoRA技术依赖GPU训练的限制，为仅有笔记本电脑CPU等有限计算资源的用户提供可行方案

Method: 学习映射数据分布到LoRA权重的元操作符，利用Mistral-7B预训练适配器库在CPU上直接组合生成新适配器

Result: 生成的适配器性能虽低于GPU训练版本，但在下游任务中持续超越基础模型

Conclusion: 该方法为传统GPU微调提供了实用替代方案，显著降低了计算资源门槛

Abstract: Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language
Models (LLMs) by enabling parameter-efficient updates. However, their
widespread adoption remains limited by the reliance on GPU-based training. In
this work, we propose a theoretically grounded approach to LoRA fine-tuning
designed specifically for users with limited computational resources,
particularly those restricted to standard laptop CPUs. Our method learns a
meta-operator that maps any input dataset, represented as a probability
distribution, to a set of LoRA weights by leveraging a large bank of
pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of
performing new gradient-based updates, our pipeline constructs adapters via
lightweight combinations of existing LoRAs directly on CPU. While the resulting
adapters do not match the performance of GPU-trained counterparts, they
consistently outperform the base Mistral model on downstream tasks, offering a
practical and accessible alternative to traditional GPU-based fine-tuning.

</details>


### [53] [Test-Time Scaling with Reflective Generative Model](https://arxiv.org/abs/2507.01951)
*Zixiao Wang,Yuxin Wang,Xiaorui Wang,Mengting Xing,Jie Gao,Jianjun Xu,Guangcan Liu,Chenhui Jin,Zhuo Wang,Shengzhuo Zhang,Hongtao Xie*

Main category: cs.LG

TL;DR: MetaStone-S1通过自监督过程奖励模型（SPRM）实现高效推理，仅用32B参数即达到OpenAI-o3-mini系列性能，并开源模型


<details>
  <summary>Details</summary>
Motivation: 解决传统过程奖励模型（PRM）需要额外标注和参数量过大的问题

Method: 通过共享主干网络+任务特定头部的SPRM架构，统一策略模型与过程奖励模型，减少99%以上PRM参数

Result: 在可控思维长度的三种推理模式下实现测试时扩展（TTS），建立计算量-性能扩展定律，32B模型性能对标OpenAI-o3-mini

Conclusion: MetaStone-S1以更小参数量实现顶尖性能，其开源将促进高效生成模型的研究与应用

Abstract: We introduce our first reflective generative model MetaStone-S1, which
obtains OpenAI o3's performance via the self-supervised process reward model
(SPRM). Through sharing the backbone network and using task-specific heads for
next token prediction and process scoring respectively, SPRM successfully
integrates the policy model and process reward model(PRM) into a unified
interface without extra process annotation, reducing over 99% PRM parameters
for efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable
for test time scaling (TTS), and we provide three reasoning effort modes (low,
medium, and high), based on the controllable thinking length. Moreover, we
empirically establish a scaling law that reveals the relationship between total
thinking computation and TTS performance. Experiments demonstrate that our
MetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with
only 32B parameter size. To support the research community, we have
open-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [54] [Can Argus Judge Them All? Comparing VLMs Across Domains](https://arxiv.org/abs/2507.01042)
*Harsh Joshi,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Niharika Jain,Sarthak Jain,Jiechao Gao,Usman Naseem*

Main category: cs.IR

TL;DR: 评估CLIP/BLIP/LXMERT三大视觉语言模型在跨数据集任务中的表现，提出CDC一致性指标揭示泛化-专业化平衡规律


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型(VLMs)快速发展，但模型在不同任务中的性能稳定性缺乏系统评估

Method: 使用跨检索/描述/推理任务的多样化数据集，结合任务精度、生成质量、效率及新型跨数据集一致性(CDC)指标进行多维度评估

Result: CLIP泛化最强(CDC 0.92)、BLIP在精选数据表现优、LXMERT结构化推理领先，揭示泛化与专业化的显式权衡关系

Conclusion: 研究结果为工业界部署VLMs提供决策依据，指导开发兼具鲁棒性和任务灵活性的下一代架构

Abstract: Vision-Language Models (VLMs) are advancing multimodal AI, yet their
performance consistency across tasks is underexamined. We benchmark CLIP, BLIP,
and LXMERT across diverse datasets spanning retrieval, captioning, and
reasoning. Our evaluation includes task accuracy, generation quality,
efficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows
strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT
leads in structured reasoning. These results expose trade-offs between
generalization and specialization, informing industrial deployment of VLMs and
guiding development toward robust, task-flexible architectures.

</details>


### [55] [Cohort Retrieval using Dense Passage Retrieval](https://arxiv.org/abs/2507.01049)
*Pranav Jadhav*

Main category: cs.IR

TL;DR: 本研究首次将密集段落检索(DPR)应用于超声心动图领域，构建结构化查询-段落数据集并开发定制化评估指标，提出性能超越传统方法的定制DPR模型


<details>
  <summary>Details</summary>
Motivation: 解决超声心动图电子健康记录非结构化特性导致的患者队列检索难题，提升医学研究中特定患者群体识别的效率与准确性

Method: 1. 将非结构化EHR转化为查询-段落数据集 2. 基于真实临床场景设计评估指标 3. 开发定制化训练的DPR嵌入模型

Result: 定制DPR模型在多项检索任务中表现优于传统方法和现成SOTA方法，建立可跨医学领域应用的检索框架

Conclusion: 成功验证DPR在超声心动图患者队列检索的适用性，提出的系统化框架具有跨医学领域迁移潜力，为医疗信息检索提供新范式

Abstract: Patient cohort retrieval is a pivotal task in medical research and clinical
practice, enabling the identification of specific patient groups from extensive
electronic health records (EHRs). In this work, we address the challenge of
cohort retrieval in the echocardiography domain by applying Dense Passage
Retrieval (DPR), a prominent methodology in semantic search. We propose a
systematic approach to transform an echocardiographic EHR dataset of
unstructured nature into a Query-Passage dataset, framing the problem as a
Cohort Retrieval task. Additionally, we design and implement evaluation metrics
inspired by real-world clinical scenarios to rigorously test the models across
diverse retrieval tasks. Furthermore, we present a custom-trained DPR embedding
model that demonstrates superior performance compared to traditional and
off-the-shelf SOTA methods.To our knowledge, this is the first work to apply
DPR for patient cohort retrieval in the echocardiography domain, establishing a
framework that can be adapted to other medical domains.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [56] [Scalable Offline ASR for Command-Style Dictation in Courtrooms](https://arxiv.org/abs/2507.01021)
*Kumarmanas Nethil,Vaibhav Mishra,Kriti Anandan,Kavya Manohar*

Main category: eess.AS

TL;DR: 开源指令式听写框架通过VAD分割音频和Whisper并行转录，实现高效多路复用，已在印度15%法庭部署应用。


<details>
  <summary>Details</summary>
Motivation: 解决在线系统资源密集与批处理高延迟的痛点，兼容主流ASR架构需求

Method: 语音活动检测(VAD)分段 + Whisper模型并行转录 + 计算资源多路复用技术

Result: 实际部署显示用户并发量增加时延迟持续下降，较顺序批处理提升显著

Conclusion: 该框架有效平衡计算效率与延迟，在司法等实时转录场景具有实用价值

Abstract: We propose an open-source framework for Command-style dictation that
addresses the gap between resource-intensive Online systems and high-latency
Batch processing. Our approach uses Voice Activity Detection (VAD) to segment
audio and transcribes these segments in parallel using Whisper models, enabling
efficient multiplexing across audios. Unlike proprietary systems like
SuperWhisper, this framework is also compatible with most ASR architectures,
including widely used CTC-based models. Our multiplexing technique maximizes
compute utilization in real-world settings, as demonstrated by its deployment
in around 15% of India's courtrooms. Evaluations on live data show consistent
latency reduction as user concurrency increases, compared to sequential batch
processing. The live demonstration will showcase our open-sourced
implementation and allow attendees to interact with it in real-time.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [57] [Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading](https://arxiv.org/abs/2507.01431)
*Yoonseok Yang,Minjune Kim,Marlon Rondinelli,Keren Shao*

Main category: cs.AI

TL;DR: Pensieve是一款AI辅助评分平台，通过LLM技术实现手写答案转录与智能评分，在真实教学场景中平均减少65%评分时间且保持95.4%评分一致性


<details>
  <summary>Details</summary>
Motivation: 解决大规模STEM课程中手写开放性答案评分效率低下的瓶颈问题

Method: 整合扫描文档处理、LLM转录评估、置信度评级和人工复核的闭环评分系统

Result: 在20+机构处理30万份答案，高置信预测与教师评分一致率95.4%，评分效率提升65%

Conclusion: Pensieve成功实现了AI赋能的教学评估流程优化，展示了LLM在教育场景中的实用价值

Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large
university STEM courses. We introduce Pensieve (https://www.pensieve.co), an
AI-assisted grading platform that leverages large language models (LLMs) to
transcribe and evaluate student work, providing instructors with rubric-aligned
scores, transcriptions, and confidence ratings. Unlike prior tools that focus
narrowly on specific tasks like transcription or rubric generation, Pensieve
supports the entire grading pipeline-from scanned student submissions to final
feedback-within a human-in-the-loop interface.
  Pensieve has been deployed in real-world courses at over 20 institutions and
has graded more than 300,000 student responses. We present system details and
empirical results across four core STEM disciplines: Computer Science,
Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces
grading time by an average of 65%, while maintaining a 95.4% agreement rate
with instructor-assigned grades for high-confidence predictions.

</details>


### [58] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

Main category: cs.AI

TL;DR: Proposes T3DM with distribution shift modeling and adversarial negative sampling for robust TKGR.


<details>
  <summary>Details</summary>
Motivation: Existing TKGR methods inadequately handle event distribution shifts between training/test samples and use low-quality random negative sampling.

Method: Test-Time Training-guided Distribution shift Modelling (T3DM) ensures global consistency through distribution shift adaptation, combined with adversarial-based negative sampling.

Result: T3DM outperforms SOTA baselines with better robustness in experiments.

Conclusion: The approach effectively addresses distribution shifts and improves negative sampling quality for enhanced TKGR performance.

Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the
dynamic development of facts along a timeline. Most research on TKG reasoning
(TKGR) focuses on modelling the repetition of global facts and designing
patterns of local historical facts. However, they face two significant
challenges: inadequate modeling of the event distribution shift between
training and test samples, and reliance on random entity substitution for
generating negative samples, which often results in low-quality sampling. To
this end, we propose a novel distributional feature modeling approach for
training TKGR models, Test-Time Training-guided Distribution shift Modelling
(T3DM), to adjust the model based on distribution shift and ensure the global
consistency of model reasoning. In addition, we design a negative-sampling
strategy to generate higher-quality negative quadruples based on adversarial
training. Extensive experiments show that T3DM provides better and more robust
results than the state-of-the-art baselines in most cases.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [59] [Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems](https://arxiv.org/abs/2507.01599)
*Zhaoyan Sun,Jiayi Wang,Xinyang Zhao,Jiachi Wang,Guoliang Li*

Main category: cs.DB

TL;DR: 提出Data Agent架构，利用大语言模型(LLMs)增强Data+AI系统的协调能力


<details>
  <summary>Details</summary>
Motivation: 传统Data+AI系统过度依赖人工流程编排，LLMs在语义理解和规划上的突破为系统自动化带来新机遇

Method: 构建整合知识理解、推理与规划能力的Data Agent架构，解决工具理解、流程编排、优化执行等设计挑战

Result: 展示数据科学代理、多模态数据分析代理、DBA代理等具体系统实例

Conclusion: Data Agent为Data+AI系统带来革命潜力，但需解决知识管理、执行效率等开放挑战

Abstract: Traditional Data+AI systems utilize data-driven techniques to optimize
performance, but they rely heavily on human experts to orchestrate system
pipelines, enabling them to adapt to changes in data, queries, tasks, and
environments. For instance, while there are numerous data science tools
available, developing a pipeline planning system to coordinate these tools
remains challenging. This difficulty arises because existing Data+AI systems
have limited capabilities in semantic understanding, reasoning, and planning.
Fortunately, we have witnessed the success of large language models (LLMs) in
enhancing semantic understanding, reasoning, and planning abilities. It is
crucial to incorporate LLM techniques to revolutionize data systems for
orchestrating Data+AI applications effectively.
  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive
architecture designed to orchestrate Data+AI ecosystems, which focuses on
tackling data-related tasks by integrating knowledge comprehension, reasoning,
and planning capabilities. We delve into the challenges involved in designing
data agents, such as understanding data/queries/environments/tools,
orchestrating pipelines/workflows, optimizing and executing pipelines, and
fostering pipeline self-reflection. Furthermore, we present examples of data
agent systems, including a data science agent, data analytics agents (such as
unstructured data analytics agent, semantic structured data analytics agent,
data lake analytics agent, and multi-modal data analytics agent), and a
database administrator (DBA) agent. We also outline several open challenges
associated with designing data agent systems.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [60] [Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants](https://arxiv.org/abs/2507.01548)
*Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen*

Main category: cs.HC

TL;DR: 探索老年移民通过AI辅助共创实现非语言叙事表达，重构AI作为支持机制的角色


<details>
  <summary>Details</summary>
Motivation: 解决老年移民叙事碎片化/代表性不足的问题，探索人机协作的新型表达方式

Method: 工作坊结合口头叙述与汉字重构，利用LLM建议小篆字形和实物材料进行共创实验

Result: 参与者成功实现生活经验的触觉表达，验证AI支持机制的有效性

Conclusion: 重新定位AI在叙事创作中的辅助角色，为弱势群体提供非数字化创作路径

Abstract: This paper explores how older adults, particularly aging migrants in urban
China, can engage AI-assisted co-creation to express personal narratives that
are often fragmented, underrepresented, or difficult to verbalize. Through a
pilot workshop combining oral storytelling and the symbolic reconstruction of
Hanzi, participants shared memories of migration and recreated new character
forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),
together with physical materials. Supported by human facilitation and a soft AI
presence, participants transformed lived experience into visual and tactile
expressions without requiring digital literacy. This approach offers new
perspectives on human-AI collaboration and aging by repositioning AI not as a
content producer but as a supportive mechanism, and by supporting narrative
agency within sociotechnical systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [61] [DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting](https://arxiv.org/abs/2507.01305)
*Worameth Chinchuthakun,Pakkapon Phongthawee,Amit Raj,Varun Jampani,Pramook Khungurn,Supasorn Suwajanakorn*

Main category: cs.CV

TL;DR: 基于Stable Diffusion XL的铬球修复技术，通过迭代优化与Turbo加速实现高效光照估计


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于HDR全景数据集导致泛化性不足，扩散模型直接生成HDR光照存在内容不一致问题

Method: 1. 迭代修复生成中值铬球作为低频光照先验 2. Exposure LoRA多曝光融合生成HDR 3. Turbo LoRA单步降噪实现60倍加速

Result: 在多样化场景中生成可信光照估计，Turbo版本保持质量同时将耗时从30分钟降至30秒

Conclusion: 结合迭代优化与模型加速技术，在光照估计质量和计算效率间取得平衡，通过代码开源推动实际应用

Abstract: We introduce a simple yet effective technique for estimating lighting from a
single low-dynamic-range (LDR) image by reframing the task as a chrome ball
inpainting problem. This approach leverages a pre-trained diffusion model,
Stable Diffusion XL, to overcome the generalization failures of existing
methods that rely on limited HDR panorama datasets. While conceptually simple,
the task remains challenging because diffusion models often insert incorrect or
inconsistent content and cannot readily generate chrome balls in HDR format.
Our analysis reveals that the inpainting process is highly sensitive to the
initial noise in the diffusion process, occasionally resulting in unrealistic
outputs. To address this, we first introduce DiffusionLight, which uses
iterative inpainting to compute a median chrome ball from multiple outputs to
serve as a stable, low-frequency lighting prior that guides the generation of a
high-quality final result. To generate high-dynamic-range (HDR) light probes,
an Exposure LoRA is fine-tuned to create LDR images at multiple exposure
values, which are then merged. While effective, DiffusionLight is
time-intensive, requiring approximately 30 minutes per estimation. To reduce
this overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to
about 30 seconds with minimal quality loss. This 60x speedup is achieved by
training a Turbo LoRA to directly predict the averaged chrome balls from the
iterative process. Inference is further streamlined into a single denoising
pass using a LoRA swapping technique. Experimental results that show our method
produces convincing light estimates across diverse settings and demonstrates
superior generalization to in-the-wild scenarios. Our code is available at
https://diffusionlight.github.io/turbo

</details>


### [62] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

Main category: cs.CV

TL;DR: Snake-NeRF框架通过分块训练和内存优化，实现在单GPU设备上线性时间处理大规模卫星图像的3D重建，且不损失质量。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法因显存限制仅能处理小场景，需解决大规模卫星图像3D重建的扩展性问题。

Method: 采用外存计算策略分割场景为无重叠3D分块，引入2×2分块递进策略和分段采样器消除边缘误差，带重叠裁剪图像确保训练完整性。

Result: 单GPU设备上实现线性时间复杂度的大规模卫星图像处理，重建质量无损失。

Conclusion: Snake-NeRF成功扩展了NeRF的应用规模，为单设备处理超大场景3D重建提供可行方案。

Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D
reconstruction from multiview satellite imagery. However, state-of-the-art NeRF
methods are typically constrained to small scenes due to the memory footprint
during training, which we study in this paper. Previous work on large-scale
NeRFs palliate this by dividing the scene into NeRFs. This paper introduces
Snake-NeRF, a framework that scales to large scenes. Our out-of-core method
eliminates the need to load all images and networks simultaneously, and
operates on a single device. We achieve this by dividing the region of interest
into NeRFs that 3D tile without overlap. Importantly, we crop the images with
overlap to ensure each NeRFs is trained with all the necessary pixels. We
introduce a novel $2\times 2$ 3D tile progression strategy and segmented
sampler, which together prevent 3D reconstruction errors along the tile edges.
Our experiments conclude that large satellite images can effectively be
processed with linear time complexity, on a single GPU, and without compromise
in quality.

</details>


### [63] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
*Robert Aufschläger,Youssef Shoeb,Azarm Nowzad,Michael Heigl,Fabian Bally,Martin Schramm*

Main category: cs.CV

TL;DR: 提出cRID跨模态框架，通过视觉语言模型和图注意力网络检测可描述性PII线索，在跨数据集行人重识别任务中实现性能提升并降低隐私风险。


<details>
  <summary>Details</summary>
Motivation: 开放街景数据集存在超出生物特征（如面部）的文本可描述性PII隐私风险，需开发能检测语义可解释特征的方法保护行人隐私。

Method: 融合大型视觉语言模型（检测文本可描述线索）、图注意力网络（特征关联）和表示学习（增强行人Re-ID），构建可解释的跨模态框架。

Result: 在Market-1501到CUHK03-np跨数据集Re-ID中性能提升，验证框架实用性和对开放数据隐私保护的价值。

Conclusion: cRID通过语义可解释特征检测实现PII识别与Re-ID性能的平衡，为开放数据隐私保护提供新思路。

Abstract: The collection and release of street-level recordings as Open Data play a
vital role in advancing autonomous driving systems and AI research. However,
these datasets pose significant privacy risks, particularly for pedestrians,
due to the presence of Personally Identifiable Information (PII) that extends
beyond biometric traits such as faces. In this paper, we present cRID, a novel
cross-modal framework combining Large Vision-Language Models, Graph Attention
Networks, and representation learning to detect textual describable clues of
PII and enhance person re-identification (Re-ID). Our approach focuses on
identifying and leveraging interpretable features, enabling the detection of
semantically meaningful PII beyond low-level appearance cues. We conduct a
systematic evaluation of PII presence in person image datasets. Our experiments
show improved performance in practical cross-dataset Re-ID scenarios, notably
from Market-1501 to CUHK03-np (detected), highlighting the framework's
practical utility. Code is available at https://github.com/RAufschlaeger/cRID.

</details>


### [64] [ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving](https://arxiv.org/abs/2507.01735)
*Kai Chen,Ruiyuan Gao,Lanqing Hong,Hang Xu,Xu Jia,Holger Caesar,Dengxin Dai,Bingbing Liu,Dzmitry Tsishkou,Songcen Xu,Chunjing Xu,Qiang Xu,Huchuan Lu,Dit-Yan Yeung*

Main category: cs.CV

TL;DR: 首个W-CODA研讨会聚焦自动驾驶长尾问题，通过多模态感知技术组织双轨挑战（场景理解与生成），连接前沿技术与可靠自动驾驶体


<details>
  <summary>Details</summary>
Motivation: 解决现有自动驾驶系统在corner cases（极端罕见场景）处理上的不足，推动全智能可靠自动驾驶体的发展

Method: 1. 邀请5位产学专家分享最新进展
2. 组织双轨挑战（corner case场景理解与生成）
3. 收集研究论文建立技术基准

Result: 构建了连接前沿自动驾驶技术与corner case鲁棒性之间的桥梁，形成初步技术交流与评估体系

Conclusion: 该研讨会为开发应对极端场景的可靠自动驾驶系统奠定了重要基础，后续将持续推进技术转化与系统优化

Abstract: In this paper, we present details of the 1st W-CODA workshop, held in
conjunction with the ECCV 2024. W-CODA aims to explore next-generation
solutions for autonomous driving corner cases, empowered by state-of-the-art
multimodal perception and comprehension techniques. 5 Speakers from both
academia and industry are invited to share their latest progress and opinions.
We collect research papers and hold a dual-track challenge, including both
corner case scene understanding and generation. As the pioneering effort, we
will continuously bridge the gap between frontier autonomous driving techniques
and fully intelligent, reliable self-driving agents robust towards corner
cases.

</details>
