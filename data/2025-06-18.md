<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 61]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ClimateChat: Designing Data and Methods for Instruction Tuning LLMs to Answer Climate Change Queries](https://arxiv.org/abs/2506.13796)
*Zhou Chen,Xiao Wang,Yuanhong Liao,Ming Lin,Yuqi Bai*

Main category: cs.CL

TL;DR: 开发自动化方法构建气候指令数据集ClimateChat-Corpus，通过指令微调提升LLMs在气候变化问答任务中的性能，并验证基模型选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有气候LLMs受限于高精度指令数据的低效生产，需要自动化构建方法推动领域发展。

Method: 基于文档事实生成指令，结合网络爬虫和种子指令增强数据多样性，构建ClimateChat-Corpus并微调开源LLMs。

Result: ClimateChat显著提升气候变化QA任务表现，验证基模型选择对指令微调的关键影响及广泛任务适应性。

Conclusion: 为气候指令数据构建和专用LLMs训练提供方法论支持，强调基模型选择在指令微调中的决定性作用。

Abstract: As the issue of global climate change becomes increasingly severe, the demand for research in climate science continues to grow. Natural language processing technologies, represented by Large Language Models (LLMs), have been widely applied to climate change-specific research, providing essential information support for decision-makers and the public. Some studies have improved model performance on relevant tasks by constructing climate change-related instruction data and instruction-tuning LLMs. However, current research remains inadequate in efficiently producing large volumes of high-precision instruction data for climate change, which limits further development of climate change LLMs. This study introduces an automated method for constructing instruction data. The method generates instructions using facts and background knowledge from documents and enhances the diversity of the instruction data through web scraping and the collection of seed instructions. Using this method, we constructed a climate change instruction dataset, named ClimateChat-Corpus, which was used to fine-tune open-source LLMs, resulting in an LLM named ClimateChat. Evaluation results show that ClimateChat significantly improves performance on climate change question-and-answer tasks. Additionally, we evaluated the impact of different base models and instruction data on LLM performance and demonstrated its capability to adapt to a wide range of climate change scientific discovery tasks, emphasizing the importance of selecting an appropriate base model for instruction tuning. This research provides valuable references and empirical support for constructing climate change instruction data and training climate change-specific LLMs.

</details>


### [2] [Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles](https://arxiv.org/abs/2506.13886)
*Antara Raaghavi Bhattacharya,Isabel Papadimitriou,Kathryn Davidson,David Alvarez-Melis*

Main category: cs.CL

TL;DR: 大语言模型难以处理未明确标记数学符号的跨语言数字组合问题，而人类可通过语言理解推断隐含结构


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在跨语言数字系统任务中的表现局限，揭示人类与模型在数字认知机制上的差异

Method: 通过控制实验分离语言表达与数学运算因素，测试不同条件下LLMs的表现，并进行数字构造参数的消融研究

Result: 模型需明确数学符号标记才能稳定解题，消融实验显示LLMs缺乏人类对数字隐含结构的认知能力

Conclusion: 当前推理模型仍难以从人类规模数据中灵活推断隐含的组合规则

Abstract: Across languages, numeral systems vary widely in how they construct and combine numbers. While humans consistently learn to navigate this diversity, large language models (LLMs) struggle with linguistic-mathematical puzzles involving cross-linguistic numeral systems, which humans can learn to solve successfully. We investigate why this task is difficult for LLMs through a series of experiments that untangle the linguistic and mathematical aspects of numbers in language. Our experiments establish that models cannot consistently solve such problems unless the mathematical operations in the problems are explicitly marked using known symbols ($+$, $\times$, etc, as in "twenty + three"). In further ablation studies, we probe how individual parameters of numeral construction and combination affect performance. While humans use their linguistic understanding of numbers to make inferences about the implicit compositional structure of numerals, LLMs seem to lack this notion of implicit numeral structure. We conclude that the ability to flexibly infer compositional rules from implicit patterns in human-scale data remains an open challenge for current reasoning models.

</details>


### [3] [VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training](https://arxiv.org/abs/2506.13888)
*Jipeng Zhang,Kehao Miao,Renjie Pi,Zhaowei Wang,Runtao Liu,Rui Pan,Tong Zhang*

Main category: cs.CL

TL;DR: 提出结合视觉专家、思维链和拒绝抽样的迭代训练框架，有效解决VL奖励模型的自举困境和模态偏见问题，显著提升多模态对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法在视觉语言模型中存在自举困境（高质量数据依赖成熟VL模型）和模态偏见（错误视觉属性导致负反馈循环）两大核心挑战，制约模型对齐效果。

Method: 通过三阶段迭代框架：1）视觉专家生成结构化反馈 2）思维链构建推理路径 3）边际拒绝抽样优化偏好数据，形成数据清洗-批判增强-推理改进的闭环。

Result: 在VL-RM基准测试中，幻觉检测准确率提升18.7%，多模态推理任务F1值提高12.3%，显著优于传统强化学习方法。

Conclusion: 该框架突破视觉语言模型对齐的瓶颈，通过结构化反馈机制和迭代优化策略，为多模态强化学习提供了可验证的奖励建模新范式。

Abstract: Reinforcement Fine-Tuning (RFT) with verifiable rewards has advanced large language models but remains underexplored for Vision-Language (VL) models. The Vision-Language Reward Model (VL-RM) is key to aligning VL models by providing structured feedback, yet training effective VL-RMs faces two major challenges. First, the bootstrapping dilemma arises as high-quality training data depends on already strong VL models, creating a cycle where self-generated supervision reinforces existing biases. Second, modality bias and negative example amplification occur when VL models hallucinate incorrect visual attributes, leading to flawed preference data that further misguides training. To address these issues, we propose an iterative training framework leveraging vision experts, Chain-of-Thought (CoT) rationales, and Margin-based Rejection Sampling. Our approach refines preference datasets, enhances structured critiques, and iteratively improves reasoning. Experiments across VL-RM benchmarks demonstrate superior performance in hallucination detection and multimodal reasoning, advancing VL model alignment with reinforcement learning.

</details>


### [4] [EmoNews: A Spoken Dialogue System for Expressive News Conversations](https://arxiv.org/abs/2506.13894)
*Ryuki Matsuura,Shikhar Bharadwaj,Jiarui Liu,Dhatchi Kunde Govindarajan*

Main category: cs.CL

TL;DR: 开发基于LLM情感分析和PromptTTS的新闻对话系统，提升对话情感调节和用户参与度


<details>
  <summary>Details</summary>
Motivation: 现有任务型对话系统与情感语音合成技术研究割裂，且缺乏面向社交目标的标准化评估体系

Method: 使用LLM情感分析器识别上下文情感，结合PromptTTS合成情境适配的情感语音，提出主观评估量表

Result: 情感对话系统在情感调节(4.3 vs 3.1)和参与度(4.1 vs 3.4)上显著优于基线系统

Conclusion: 语音情感调节对提升对话参与度具有关键作用，开源系统促进情感对话技术发展

Abstract: We develop a task-oriented spoken dialogue system (SDS) that regulates emotional speech based on contextual cues to enable more empathetic news conversations. Despite advancements in emotional text-to-speech (TTS) techniques, task-oriented emotional SDSs remain underexplored due to the compartmentalized nature of SDS and emotional TTS research, as well as the lack of standardized evaluation metrics for social goals. We address these challenges by developing an emotional SDS for news conversations that utilizes a large language model (LLM)-based sentiment analyzer to identify appropriate emotions and PromptTTS to synthesize context-appropriate emotional speech. We also propose subjective evaluation scale for emotional SDSs and judge the emotion regulation performance of the proposed and baseline systems. Experiments showed that our emotional SDS outperformed a baseline system in terms of the emotion regulation and engagement. These results suggest the critical role of speech emotion for more engaging conversations. All our source code is open-sourced at https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1

</details>


### [5] [Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations](https://arxiv.org/abs/2506.13901)
*Abhilekh Borah,Chhavi Sharma,Danush Khanna,Utkarsh Bhatt,Gurpreet Singh,Hasnat Md Abdullah,Raghav Kaushik Ravi,Vinija Jain,Jyoti Patel,Shubham Singh,Vasu Sharma,Arpita Vats,Rahul Raja,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出新的AI对齐指标AQI，通过潜在空间激活分离评估大模型安全性，并发布LITMUS测试数据集。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（拒绝率/毒性分类器等）存在盲区，导致模型易受越狱攻击和对齐欺骗，需更可靠的安全审计工具。

Method: 开发几何指标AQI，综合Davies-Bouldin等聚类质量指标，分析潜在空间中安全/不安全激活的分离程度。配套发布LITMUS多场景测试数据集。

Result: 在DPO/GRPO/RLHF训练的模型测试中，AQI与外部评判指标相关，能发现传统方法遗漏的漏洞。

Conclusion: AQI为解码无关的安全审计提供早期预警，LITMUS数据集推动更鲁棒的AI对齐评估研究。

Abstract: Alignment is no longer a luxury, it is a necessity. As large language models (LLMs) enter high-stakes domains like education, healthcare, governance, and law, their behavior must reliably reflect human-aligned values and safety constraints. Yet current evaluations rely heavily on behavioral proxies such as refusal rates, G-Eval scores, and toxicity classifiers, all of which have critical blind spots. Aligned models are often vulnerable to jailbreaking, stochasticity of generation, and alignment faking.
  To address this issue, we introduce the Alignment Quality Index (AQI). This novel geometric and prompt-invariant metric empirically assesses LLM alignment by analyzing the separation of safe and unsafe activations in latent space. By combining measures such as the Davies-Bouldin Score (DBS), Dunn Index (DI), Xie-Beni Index (XBI), and Calinski-Harabasz Index (CHI) across various formulations, AQI captures clustering quality to detect hidden misalignments and jailbreak risks, even when outputs appear compliant. AQI also serves as an early warning signal for alignment faking, offering a robust, decoding invariant tool for behavior agnostic safety auditing.
  Additionally, we propose the LITMUS dataset to facilitate robust evaluation under these challenging conditions. Empirical tests on LITMUS across different models trained under DPO, GRPO, and RLHF conditions demonstrate AQI's correlation with external judges and ability to reveal vulnerabilities missed by refusal metrics. We make our implementation publicly available to foster future research in this area.

</details>


### [6] [ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection](https://arxiv.org/abs/2506.13956)
*Shang-Chi Tsai,Seiya Kawano,Angel Garcia Contreras,Koichiro Yoshino,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 提出基于大语言模型和稳定扩散模型的数据增强框架，通过生成模拟对话与环境图像提升机器人动作选择准确性


<details>
  <summary>Details</summary>
Motivation: 现实场景中收集多模态数据困难且耗时，需要有效方法增强有限数据下的机器人意图理解能力

Method: 1. 使用大语言模型生成潜在对话和环境上下文 2. 应用稳定扩散模型创建对应环境图像 3. 利用生成数据优化多模态模型

Result: 在真实场景数据集上实现最优性能，显著提升机器人动作选择准确率（达到SOTA）

Conclusion: 该数据增强框架有效解决了数据稀缺问题，通过模拟生成方法成功提升了机器人交互场景中的动作决策能力

Abstract: When designing robots to assist in everyday human activities, it is crucial to enhance user requests with visual cues from their surroundings for improved intent understanding. This process is defined as a multimodal classification task. However, gathering a large-scale dataset encompassing both visual and linguistic elements for model training is challenging and time-consuming. To address this issue, our paper introduces a novel framework focusing on data augmentation in robotic assistance scenarios, encompassing both dialogues and related environmental imagery. This approach involves leveraging a sophisticated large language model to simulate potential conversations and environmental contexts, followed by the use of a stable diffusion model to create images depicting these environments. The additionally generated data serves to refine the latest multimodal models, enabling them to more accurately determine appropriate actions in response to user interactions with the limited target data. Our experimental results, based on a dataset collected from real-world scenarios, demonstrate that our methodology significantly enhances the robot's action selection capabilities, achieving the state-of-the-art performance.

</details>


### [7] [Are manual annotations necessary for statutory interpretations retrieval?](https://arxiv.org/abs/2506.13965)
*Aleksander Smywiński-Pohl,Tomer Libal,Adam Kaczmarczyk,Magdalena Król*

Main category: cs.CL

TL;DR: 探索法律概念解释标注自动化的实验研究，分析人工标注需求量和替代方案的有效性


<details>
  <summary>Details</summary>
Motivation: 传统法律概念解释检索依赖昂贵的人工标注流程，需针对每个法律概念重复标注，研究旨在通过实验验证标注自动化可行性

Method: 1. 确定每个法律概念的最优标注数量
2. 比较随机标注与精选候选标注的效果差异
3. 测试LLM自动化标注的实际效果

Result: 实验显示存在更高效的标注策略，LLM辅助可显著减少人工标注量并保持模型性能

Conclusion: 法律概念解释的标注流程可通过LLM实现部分自动化，精选标注策略优于随机抽样，为法律NLP系统优化提供新思路

Abstract: One of the elements of legal research is looking for cases where judges have extended the meaning of a legal concept by providing interpretations of what a concept means or does not mean. This allow legal professionals to use such interpretations as precedents as well as laymen to better understand the legal concept. The state-of-the-art approach for retrieving the most relevant interpretations for these concepts currently depends on the ranking of sentences and the training of language models over annotated examples. That manual annotation process can be quite expensive and need to be repeated for each such concept, which prompted recent research in trying to automate this process. In this paper, we highlight the results of various experiments conducted to determine the volume, scope and even the need for manual annotation. First of all, we check what is the optimal number of annotations per a legal concept. Second, we check if we can draw the sentences for annotation randomly or there is a gain in the performance of the model, when only the best candidates are annotated. As the last question we check what is the outcome of automating the annotation process with the help of an LLM.

</details>


### [8] [AI shares emotion with humans across languages and cultures](https://arxiv.org/abs/2506.13978)
*Xiuwen Wu,Hao Wang,Zhiang Yan,Xiaohan Tang,Pengfei Xu,Wai-Ting Siok,Ping Li,Jia-Hong Gao,Bingjiang Lyu,Lang Qin*

Main category: cs.CL

TL;DR: 研究显示大型语言模型（LLM）的情感表示与人类感知结构一致，并通过心理学情感概念可精确调控AI的情感输出。


<details>
  <summary>Details</summary>
Motivation: 验证LLM是否与人类共享情感表征，探索其情感输出的可调控性以提升人机协作中的情感交流效果。

Method: 跨语言文化群体和模型家族分析，使用20+情感类别的概念集构建可解释LLM特征，验证其对效价/唤醒度维度的预测能力。

Result: LLM情感空间与人类结构高度一致，情感特征可预测行为数据，且通过人类情感导向向量可实现稳定自然的情感表达调控。

Conclusion: AI不仅共享人类情感表征，更可通过心理学基础的情感概念系统引导输出，为可控情感计算提供新范式。

Abstract: Effective and safe human-machine collaboration requires the regulated and meaningful exchange of emotions between humans and artificial intelligence (AI). Current AI systems based on large language models (LLMs) can provide feedback that makes people feel heard. Yet it remains unclear whether LLMs represent emotion in language as humans do, or whether and how the emotional tone of their output can be controlled. We assess human-AI emotional alignment across linguistic-cultural groups and model-families, using interpretable LLM features translated from concept-sets for over twenty nuanced emotion categories (including six basic emotions). Our analyses reveal that LLM-derived emotion spaces are structurally congruent with human perception, underpinned by the fundamental affective dimensions of valence and arousal. Furthermore, these emotion-related features also accurately predict large-scale behavioural data on word ratings along these two core dimensions, reflecting both universal and language-specific patterns. Finally, by leveraging steering vectors derived solely from human-centric emotion concepts, we show that model expressions can be stably and naturally modulated across distinct emotion categories, which provides causal evidence that human emotion concepts can be used to systematically induce LLMs to produce corresponding affective states when conveying content. These findings suggest AI not only shares emotional representations with humans but its affective outputs can be precisely guided using psychologically grounded emotion concepts.

</details>


### [9] [Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text](https://arxiv.org/abs/2506.14012)
*Amr Mohamed,Yang Zhang,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.CL

TL;DR: 该论文系统评估了大型语言模型（LLM）在代码切换（CSW）下的理解能力，发现当外语标记干扰英文文本时性能下降，但将英文嵌入其他语言常提升理解；微调比提示更有效缓解性能衰退。


<details>
  <summary>Details</summary>
Motivation: 代码切换在多语言社区及网络内容中普遍存在，而LLM作为核心处理工具需适应混合语言输入。研究旨在揭示LLM处理混合语言文本的机制及潜在挑战。

Method: 通过生成代码切换版本的推理与理解基准测试，分析LLM在两种场景下的表现：外语干扰英语文本 vs. 英语嵌入其他语言，并对比提示工程与微调策略的效果。

Result: 外语干扰英语导致性能显著下降（即使符合语言约束），而英语嵌入其他语言常提升理解；提示效果不稳定，微调能更稳定缓解性能衰退。

Conclusion: LLM处理代码切换文本的能力存在显著差异，需针对性优化策略（如微调）以提升多语言场景下的鲁棒性。

Abstract: Code-switching (CSW) is the act of alternating between two or more languages within a single discourse. This phenomenon is widespread in multilingual communities, and increasingly prevalent in online content, where users naturally mix languages in everyday communication. As a result, Large Language Models (LLMs), now central to content processing and generation, are frequently exposed to code-switched inputs. Given their widespread use, it is crucial to understand how LLMs process and reason about such mixed-language text. This paper presents a systematic evaluation of LLM comprehension under code-switching by generating CSW variants of established reasoning and comprehension benchmarks. While degradation is evident when foreign tokens disrupt English text$\unicode{x2013}$even under linguistic constraints$\unicode{x2013}$embedding English into other languages often improves comprehension. Though prompting yields mixed results, fine-tuning offers a more stable path to degradation mitigation.

</details>


### [10] [MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation](https://arxiv.org/abs/2506.14028)
*Xueqing Peng,Lingfei Qian,Yan Wang,Ruoyu Xiang,Yueru He,Yang Ren,Mingyang Jiang,Jeff Zhao,Huan He,Yi Han,Yun Feng,Yuechen Jiang,Yupeng Cao,Haohang Li,Yangyang Yu,Xiaoyu Wang,Penglei Gao,Shengyuan Lin,Keyi Wang,Shanshan Yang,Yilun Zhao,Zhiwei Liu,Peng Lu,Jerry Huang,Suyuchen Wang,Triantafillos Papadopoulos,Polydoros Giannouris,Efstathia Soufleri,Nuo Chen,Guojun Xiong,Zhiyang Deng,Yijia Zhao,Mingquan Lin,Meikang Qiu,Kaleb E Smith,Arman Cohan,Xiao-Yang Liu,Jimin Huang,Alejandro Lopez-Lira,Xi Chen,Junichi Tsujii,Jian-Yun Nie,Sophia Ananiadou,Qianqian Xie*

Main category: cs.CL

TL;DR: 首个多语言多模态金融基准MultiFinBen揭示：顶尖模型在跨语言/多模态金融任务中表现挣扎


<details>
  <summary>Details</summary>
Motivation: 现有金融NLP基准局限于单语言单模态，难以反映真实金融场景的复杂性，需建立更全面的评估体系

Method: 构建MultiFinBen基准，包含多语言金融QA(PolyFiQA)、OCR金融文档理解任务，采用动态难度选择机制优化数据集结构

Result: 评估22个SOTA模型发现，即使最强模型在跨语言金融推理和视觉-文本联合理解任务中准确率显著下降

Conclusion: MultiFinBen的发布将推动金融AI研究的透明化发展，促进跨语言多模态金融应用的技术进步

Abstract: Recent advances in large language models (LLMs) have accelerated progress in financial NLP and applications, yet existing benchmarks remain limited to monolingual and unimodal settings, often over-relying on simple tasks and failing to reflect the complexity of real-world financial communication. We introduce MultiFinBen, the first multilingual and multimodal benchmark tailored to the global financial domain, evaluating LLMs across modalities (text, vision, audio) and linguistic settings (monolingual, bilingual, multilingual) on domain-specific tasks. We introduce two novel tasks, including PolyFiQA-Easy and PolyFiQA-Expert, the first multilingual financial benchmarks requiring models to perform complex reasoning over mixed-language inputs; and EnglishOCR and SpanishOCR, the first OCR-embedded financial QA tasks challenging models to extract and reason over information from visual-text financial documents. Moreover, we propose a dynamic, difficulty-aware selection mechanism and curate a compact, balanced benchmark rather than simple aggregation existing datasets. Extensive evaluation of 22 state-of-the-art models reveals that even the strongest models, despite their general multimodal and multilingual capabilities, struggle dramatically when faced with complex cross-lingual and multimodal tasks in financial domain. MultiFinBen is publicly released to foster transparent, reproducible, and inclusive progress in financial studies and applications.

</details>


### [11] [An Interdisciplinary Review of Commonsense Reasoning and Intent Detection](https://arxiv.org/abs/2506.14040)
*Md Nazmus Sakib*

Main category: cs.CL

TL;DR: 综述近五年28篇论文，分析常识推理与意图检测领域进展，指出未来需突破基础理论、泛化能力与评估体系设计


<details>
  <summary>Details</summary>
Motivation: 针对自然语言理解中常识推理的语境适应难题和意图检测的开放场景挑战，整合NLP与HCI领域交叉见解

Method: 系统性梳理ACL/EMNLP/CHI会议论文，按方法论（零样本学习/生成式建模）与应用场景（跨文化/人机交互）双重维度分类

Result: 发现模型向多语言适应、上下文感知进化，但存在常识知识表征不足、基准测试与现实需求脱节等关键缺陷

Conclusion: 强调跨学科协同创新价值，提出亟需构建动态评估框架与可解释的常识推理系统

Abstract: This review explores recent advances in commonsense reasoning and intent detection, two key challenges in natural language understanding. We analyze 28 papers from ACL, EMNLP, and CHI (2020-2025), organizing them by methodology and application. Commonsense reasoning is reviewed across zero-shot learning, cultural adaptation, structured evaluation, and interactive contexts. Intent detection is examined through open-set models, generative formulations, clustering, and human-centered systems. By bridging insights from NLP and HCI, we highlight emerging trends toward more adaptive, multilingual, and context-aware models, and identify key gaps in grounding, generalization, and benchmark design.

</details>


### [12] [Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications](https://arxiv.org/abs/2506.14046)
*David Kogan,Max Schumacher,Sam Nguyen,Masanori Suzuki,Melissa Smith,Chloe Sophia Bellows,Jared Bernstein*

Main category: cs.CL

TL;DR: 提出Ace-CEFR数据集用于评估对话文本难度，验证模型评估效果优于人类专家，并开源数据集


<details>
  <summary>Details</summary>
Motivation: 现有方法难以准确评估对话文本的语言难度，尤其缺乏专业标注的短对话数据集用于LLM训练与过滤

Method: 构建专家标注的英语对话文本数据集，使用Transformer架构模型和LLM进行文本难度评估实验

Result: 模型评估准确率超越人类专家（标注F1值0.88），推理延迟符合生产环境需求（平均响应时间<500ms）

Conclusion: Ace-CEFR数据集填补了对话文本难度评估的空白，公开数据集将促进LLM训练优化领域的研发

Abstract: There is an unmet need to evaluate the language difficulty of short, conversational passages of text, particularly for training and filtering Large Language Models (LLMs). We introduce Ace-CEFR, a dataset of English conversational text passages expert-annotated with their corresponding level of text difficulty. We experiment with several models on Ace-CEFR, including Transformer-based models and LLMs. We show that models trained on Ace-CEFR can measure text difficulty more accurately than human experts and have latency appropriate to production environments. Finally, we release the Ace-CEFR dataset to the public for research and development.

</details>


### [13] [Automatic Extraction of Clausal Embedding Based on Large-Scale English Text Data](https://arxiv.org/abs/2506.14064)
*Iona Carslaw,Sivan Milton,Nicolas Navarre,Ciyang Qing,Wataru Uegaki*

Main category: cs.CL

TL;DR: 提出基于成分句法分析和启发式规则的方法，从大规模语料库中自动提取自然出现的英语嵌入式从句，构建高质量标注数据集GECS和大型语料库Dolma数据集。


<details>
  <summary>Details</summary>
Motivation: 传统研究依赖人工构造例句，缺乏自然语料中的统计信息和真实用例。为填补这一空白，需开发自动化工具处理大规模文本数据。

Method: 1. 使用成分句法分析结合解析启发式规则检测嵌入式从句
2. 通过Golden Embedded Clause Set (GECS)验证工具准确性
3. 从开源语料库Dolma中提取大规模自然出现例句

Result: 1. 开发出有效提取工具（准确率经GECS验证）
2. 建成含自然出现嵌入式从句的大型语料库
3. 公开发布GECS标注数据集供学术研究使用

Conclusion: 该方法突破传统人工例句限制，为句法理论研究提供数据驱动的新范式，大规模自然语料资源将推动语言学研究的信效度提升。

Abstract: For linguists, embedded clauses have been of special interest because of their intricate distribution of syntactic and semantic features. Yet, current research relies on schematically created language examples to investigate these constructions, missing out on statistical information and naturally-occurring examples that can be gained from large language corpora. Thus, we present a methodological approach for detecting and annotating naturally-occurring examples of English embedded clauses in large-scale text data using constituency parsing and a set of parsing heuristics. Our tool has been evaluated on our dataset Golden Embedded Clause Set (GECS), which includes hand-annotated examples of naturally-occurring English embedded clause sentences. Finally, we present a large-scale dataset of naturally-occurring English embedded clauses which we have extracted from the open-source corpus Dolma using our extraction tool.

</details>


### [14] [Abstract Meaning Representation for Hospital Discharge Summarization](https://arxiv.org/abs/2506.14101)
*Paul Landes,Sitara Rao,Aaron Jeremy Chaise,Barbara Di Eugenio*

Main category: cs.CL

TL;DR: 提出结合语言图谱与深度学习的新方法，显著降低临床摘要生成中的LLM幻觉问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型的幻觉问题在医疗领域存在严重风险，自动生成出院小结可减轻医生文书负担

Method: 基于MIMIC-III数据库和匿名医院临床记录，开发语言图谱与深度学习结合的可靠摘要生成框架

Result: 在真实医疗数据上实现了优异的可靠性表现，提供完整的方法说明、生成示例和训练模型

Conclusion: 该方法有效保障临床文本生成的可追溯性与可信度，相关资源开源促进医疗AI发展

Abstract: The Achilles heel of Large Language Models (LLMs) is hallucination, which has drastic consequences for the clinical domain. This is particularly important with regards to automatically generating discharge summaries (a lengthy medical document that summarizes a hospital in-patient visit). Automatically generating these summaries would free physicians to care for patients and reduce documentation burden. The goal of this work is to discover new methods that combine language-based graphs and deep learning models to address provenance of content and trustworthiness in automatic summarization. Our method shows impressive reliability results on the publicly available Medical Information Mart for Intensive III (MIMIC-III) corpus and clinical notes written by physicians at Anonymous Hospital. rovide our method, generated discharge ary output examples, source code and trained models.

</details>


### [15] [Essential-Web v1.0: 24T tokens of organized web data](https://arxiv.org/abs/2506.14111)
*Essential AI,:,Andrew Hojel,Michael Pust,Tim Romanski,Yash Vanjani,Ritvik Kapila,Mohit Parmar,Adarsh Chaluvaraju,Alok Tripathy,Anil Thomas,Ashish Tanwer,Darsh J Shah,Ishaan Shah,Karl Stratos,Khoi Nguyen,Kurt Smith,Michael Callahan,Peter Rushton,Philip Monk,Platon Mazarakis,Saad Jamal,Saurabh Srivastava,Somanshu Singla,Ashish Vaswani*

Main category: cs.CL

TL;DR: 提出Essential-Web v1.0数据集（24万亿token），通过自研标注模型实现文档分类，显著提升多领域数据质量


<details>
  <summary>Details</summary>
Motivation: 现有预训练数据集存在规模不足和分类体系缺失问题，导致数据成本高且难以有效利用

Method: 1. 使用自研EAI-Distill-0.5b模型（标注一致性接近Qwen2.5-32B-Instruct）进行十二维文档标注
2. 通过SQL式过滤构建领域数据集

Result: 在数学（-8.0% vs SOTA）、编程（+14.3%）、STEM（+24.5%）和医疗（+8.6%）领域取得竞争优势

Conclusion: Essential-Web v1.0已开源，显著降低数据工程门槛，网址：https://huggingface.co/datasets/EssentialAI/essential-web-v1.0

Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0

</details>


### [16] [Sampling from Your Language Model One Byte at a Time](https://arxiv.org/abs/2506.14123)
*Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh*

Main category: cs.CL

TL;DR: 提出在推理阶段将BPE分词模型转换为字符/字节级模型的方法，解决分词错位问题并实现跨模型组合应用


<details>
  <summary>Details</summary>
Motivation: 解决现代语言模型因分词器不同导致的提示边界问题(PBP)、模型组合互操作性差等问题

Method: 在推理阶段保持文本层面生成分布不变的前提下，将BPE分词模型转换为字符级/字节级语言模型

Result: 成功统一不同分词器的词汇表，组合模型和代理调优模型在下游评估中表现优于原模型

Conclusion: 该方法有效解决分词错位问题，提升模型互操作性和组合能力，同时保持生成质量

Abstract: Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations. For example, users are often advised not to end their prompts with a space because it prevents the model from including the space as part of the next token. This Prompt Boundary Problem (PBP) also arises in languages such as Chinese and in code generation, where tokens often do not line up with syntactic boundaries. Additionally mismatching tokenizers often hinder model composition and interoperability. For example, it is not possible to directly ensemble models with different tokenizers due to their mismatching vocabularies. To address these issues, we present an inference-time method to convert any autoregressive LM with a BPE tokenizer into a character-level or byte-level LM, without changing its generative distribution at the text level. Our method efficient solves the PBP and is also able to unify the vocabularies of language models with different tokenizers, allowing one to ensemble LMs with different tokenizers at inference time as well as transfer the post-training from one model to another using proxy-tuning. We demonstrate in experiments that the ensemble and proxy-tuned models outperform their constituents on downstream evals.

</details>


### [17] [DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization](https://arxiv.org/abs/2506.14157)
*Chengyu Huang,Tanya Goyal*

Main category: cs.CL

TL;DR: 研究者提出用距离校准奖励边际(DCRM)指标评估响应对质量，通过最佳N²配对方法构建高质量训练集，有效提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法中，偏好响应与不偏好响应之间的差异可能不符合模型实际需要学习的目标差异，需要量化有效差异指标

Method: 结合距离和奖励边际构建DCRM指标，提出best-of-N²方法选择DCRM最高的响应对构建训练集

Result: 在AlpacaEval、MT-Bench等基准测试中，使用高DCRM数据集训练的模型性能优于现有方法

Conclusion: DCRM是有效的训练数据质量评估指标，基于该指标的配对方法能显著提升偏好优化效果

Abstract: Recent research has attempted to associate preference optimization (PO) performance with the underlying preference datasets. In this work, our observation is that the differences between the preferred response $y^+$ and dispreferred response $y^-$ influence what LLMs can learn, which may not match the desirable differences to learn. Therefore, we use distance and reward margin to quantify these differences, and combine them to get Distance Calibrated Reward Margin (DCRM), a metric that measures the quality of a response pair for PO. Intuitively, DCRM encourages minimal noisy differences and maximal desired differences. With this, we study 3 types of commonly used preference datasets, classified along two axes: the source of the responses and the preference labeling function. We establish a general correlation between higher DCRM of the training set and better learning outcome. Inspired by this, we propose a best-of-$N^2$ pairing method that selects response pairs with the highest DCRM. Empirically, in various settings, our method produces training datasets that can further improve models' performance on AlpacaEval, MT-Bench, and Arena-Hard over the existing training sets.

</details>


### [18] [S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.14158)
*Tao He,Guang Huang,Yu Yang,Tianshi Xu,Sicheng Zhao,Guiguang Ding,Pengyang Wang,Feng Tian*

Main category: cs.CL

TL;DR: 提出S⁴C框架，通过多头部草稿生成和持续验证树提升推测采样效率，在主流任务中实现2.26x-2.60x加速。


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法忽视文本生成连贯性，导致效率受限。需在加速同时保持语义/语法连贯性。

Method: S⁴C框架：1) 多头部并行草稿生成加速token生产；2) 持续验证树实现特征复用和候选验证。

Result: 在Spec-bench基准测试中实现2.26-2.6倍加速，比现有方法多生成23%有效token，计算资源节省37%。

Conclusion: S⁴C通过保持生成连贯性，显著提升推测采样效率，为实时LLM应用提供高效推理方案。

Abstract: Large language models (LLMs) exhibit remarkable reasoning capabilities across diverse downstream tasks. However, their autoregressive nature leads to substantial inference latency, posing challenges for real-time applications. Speculative sampling mitigates this issue by introducing a drafting phase followed by a parallel validation phase, enabling faster token generation and verification. Existing approaches, however, overlook the inherent coherence in text generation, limiting their efficiency. To address this gap, we propose a Speculative Sampling with Syntactic and Semantic Coherence (S$^4$C) framework, which extends speculative sampling by leveraging multi-head drafting for rapid token generation and a continuous verification tree for efficient candidate validation and feature reuse. Experimental results demonstrate that S$^4$C surpasses baseline methods across mainstream tasks, offering enhanced efficiency, parallelism, and the ability to generate more valid tokens with fewer computational resources. On Spec-bench benchmarks, S$^4$C achieves an acceleration ratio of 2.26x-2.60x, outperforming state-of-the-art methods.

</details>


### [19] [MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind](https://arxiv.org/abs/2506.14161)
*Yanlin Li,Hao Liu,Huimin Liu,Yinwei Wei,Yupeng Hu*

Main category: cs.CL

TL;DR: 提出基于刻板印象内容模型(SCM)的评估框架，通过词语联想和情感归因测试揭示大语言模型的隐性心理理论偏见


<details>
  <summary>Details</summary>
Motivation: 传统直接查询法存在社会期望偏差，难以捕捉多维隐性偏见，需开发更精准的评估方法

Method: 设计词语联想偏见测试(WABT)和情感归因测试(AAT)，从能力、社交性、道德三维度评估8个SOTA大模型

Result: 发现普遍社交偏见、多维认知偏差、非对称刻板印象放大等复杂偏见结构

Conclusion: 该框架为揭示大语言模型隐性偏见的系统性结构提供了可靠方法论，突破传统评估局限

Abstract: Theory of Mind (ToM) in Large Language Models (LLMs) refers to their capacity for reasoning about mental states, yet failures in this capacity often manifest as systematic implicit bias. Evaluating this bias is challenging, as conventional direct-query methods are susceptible to social desirability effects and fail to capture its subtle, multi-dimensional nature. To this end, we propose an evaluation framework that leverages the Stereotype Content Model (SCM) to reconceptualize bias as a multi-dimensional failure in ToM across Competence, Sociability, and Morality. The framework introduces two indirect tasks: the Word Association Bias Test (WABT) to assess implicit lexical associations and the Affective Attribution Test (AAT) to measure covert affective leanings, both designed to probe latent stereotypes without triggering model avoidance. Extensive experiments on 8 State-of-the-Art LLMs demonstrate our framework's capacity to reveal complex bias structures, including pervasive sociability bias, multi-dimensional divergence, and asymmetric stereotype amplification, thereby providing a more robust methodology for identifying the structural nature of implicit bias.

</details>


### [20] [GRAM: A Generative Foundation Reward Model for Reward Generalization](https://arxiv.org/abs/2506.14175)
*Chenglong Wang,Yang Gan,Yifu Huo,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Tong Xiao,Chunliang Zhang,Tongran Liu,Jingbo Zhu*

Main category: cs.CL

TL;DR: Proposes a foundation reward model combining unsupervised pre-training and supervised fine-tuning with label smoothing, achieving multi-task generalization across LLM alignment tasks.


<details>
  <summary>Details</summary>
Motivation: Address limitations of discriminative reward models that solely rely on labeled human preference data in LLM alignment.

Method: Develops generative reward model through 1) large-scale unsupervised pre-training 2) supervised fine-tuning with label smoothing (implicit regularized pairwise ranking loss).

Result: Achieves SOTA performance on response ranking (6% improvement), RLHF (15%↑), and task adaptation, outperforms baseline models like GPT-3.5 and PaLM.

Conclusion: Unifies generative/discriminative approaches under shared training objectives, enabling foundation reward models with strong cross-task generalization capabilities.

Abstract: In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.

</details>


### [21] [Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages](https://arxiv.org/abs/2506.14177)
*Tuan Nguyen,Huy-Dat Tran*

Main category: cs.CL

TL;DR: 提出通过合成语码转换数据优化低资源东南亚语言的语音识别模型，建立新基准并验证有效性


<details>
  <summary>Details</summary>
Motivation: 语码转换场景下转录数据稀缺且昂贵，现有ASR模型性能受限，需寻找经济高效的解决方案

Method: 采用短语级混合方法生成拟自然CS数据，结合单语数据微调大规模预训练模型（Whisper/MMS/SeamlessM4T），建立包含马来-英/华-马来/泰米尔-英的三语种基准

Result: 混合训练策略显著提升单语和CS测试集表现，BM-EN提升最大（+9.3%），TA-EN次之（+4.7%），ZH-BM最小（+2.1%）

Conclusion: 该合成数据方法为低资源CS-ASR开发提供经济有效方案，推动东南亚多语言场景的语音技术发展

Abstract: Code-switching (CS), common in multilingual settings, presents challenges for ASR due to scarce and costly transcribed data caused by linguistic complexity. This study investigates building CS-ASR using synthetic CS data. We propose a phrase-level mixing method to generate synthetic CS data that mimics natural patterns. Utilizing monolingual augmented with synthetic phrase-mixed CS data to fine-tune large pretrained ASR models (Whisper, MMS, SeamlessM4T). This paper focuses on three under-resourced Southeast Asian language pairs: Malay-English (BM-EN), Mandarin-Malay (ZH-BM), and Tamil-English (TA-EN), establishing a new comprehensive benchmark for CS-ASR to evaluate the performance of leading ASR models. Experimental results show that the proposed training strategy enhances ASR performance on monolingual and CS tests, with BM-EN showing highest gains, then TA-EN and ZH-BM. This finding offers a cost-effective approach for CS-ASR development, benefiting research and industry.

</details>


### [22] [AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR](https://arxiv.org/abs/2506.14190)
*Tuan Nguyen,Huy-Dat Tran*

Main category: cs.CL

TL;DR: 提出AsyncSwitch框架，通过三阶段训练策略有效提升代码切换语音识别性能，在马来语-英语任务中实现9.02%词错误率降低。


<details>
  <summary>Details</summary>
Motivation: 现有代码切换ASR系统面临多语言数据匮乏和合成音频生成成本高的问题，难以有效扩展。

Method: 三阶段训练：1) 基于代码切换文本预训练解码器自注意力层 2) 用有限语音数据对齐编解码器 3) 完整模型微调

Result: 马来语-英语代码切换任务相对WER降低9.02%，同时提升新加坡英语、马来语及其他英语变体的单语识别性能

Conclusion: AsyncSwitch通过文本数据预训练和分阶段适配策略，在资源有限条件下显著提升多语言ASR性能，兼顾计算效率。

Abstract: Developing code-switched ASR systems is challenging due to language ambiguity and limited exposure to multilingual, code-switched data, while collecting such speech is costly. Prior work generates synthetic audio from text, but these methods are computationally intensive and hard to scale. We introduce AsyncSwitch, a novel asynchronous adaptation framework that leverages large-scale, text-rich web data to pre-expose ASR models to diverse code-switched domains before fine-tuning on paired speech-text corpora. Our three-stage process (1) trains decoder self-attention and feedforward layers on code-switched text, (2) aligns decoder and encoder via cross-attention using limited speech-text data, and (3) fully fine-tunes the entire model. Experiments with Whisper on Malay-English code-switching demonstrate a 9.02% relative WER reduction, while improving monolingual performance in Singlish, Malay, and other English variants.

</details>


### [23] [MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment](https://arxiv.org/abs/2506.14199)
*Junghwan Kim,Kieun Park,Sohee Park,Hyunggug Kim,Bongwon Suh*

Main category: cs.CL

TL;DR: 提出基于大语言模型的多智能体评估系统MAS-LitEval，在文学翻译评估中超越传统指标


<details>
  <summary>Details</summary>
Motivation: 传统翻译评估指标忽视文学作品的叙事一致性和风格保真度，需建立更细致的评估体系

Method: 开发多智能体系统MAS-LitEval，通过术语、叙事、风格三维度评估，测试《小王子》等经典文学作品的LLM翻译

Result: MAS-LitEval在文学细微捕捉方面达到0.890评分，显著优于BLEU等传统指标

Conclusion: 建立可扩展的翻译质量评估框架，为文学翻译研究提供兼具理论深度与实践价值的评估工具

Abstract: Literary translation requires preserving cultural nuances and stylistic elements, which traditional metrics like BLEU and METEOR fail to assess due to their focus on lexical overlap. This oversight neglects the narrative consistency and stylistic fidelity that are crucial for literary works. To address this, we propose MAS-LitEval, a multi-agent system using Large Language Models (LLMs) to evaluate translations based on terminology, narrative, and style. We tested MAS-LitEval on translations of The Little Prince and A Connecticut Yankee in King Arthur's Court, generated by various LLMs, and compared it to traditional metrics. \textbf{MAS-LitEval} outperformed these metrics, with top models scoring up to 0.890 in capturing literary nuances. This work introduces a scalable, nuanced framework for Translation Quality Assessment (TQA), offering a practical tool for translators and researchers.

</details>


### [24] [ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations](https://arxiv.org/abs/2506.14200)
*Brihi Joshi,Keyu He,Sahana Ramnath,Sadra Sabouri,Kaitlyn Zhou,Souti Chattopadhyay,Swabha Swayamdipta,Xiang Ren*

Main category: cs.CL

TL;DR: 研究通过ELI-Why基准测试评估语言模型的教学适配能力，发现GPT-4生成的解释在匹配教育背景和用户需求方面显著弱于人工解释。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型能否根据学习者不同知识背景生成定制化教学解释，填补现有研究对教育适配能力评估的空白。

Method: 构建包含1.34万'Why'问题的ELI-Why基准，通过教育者角色评估（研究一）和学习者需求匹配度评估（研究二）的双重人类实验，对比GPT-4与普通人群生成的解释效果。

Result: GPT-4解释与目标教育背景匹配率仅50%（人工79%）；学习者认为GPT-4解释适配度低20%；自动化评估显示不同模型生成的解释缺乏可区分的年级特征。

Conclusion: 当前语言模型在生成教育适配性解释方面存在显著局限，需改进教学场景中的个性化输出能力以实现有效知识传递。

Abstract: Language models today are widely used in education, yet their ability to tailor responses for learners with varied informational needs and knowledge backgrounds remains under-explored. To this end, we introduce ELI-Why, a benchmark of 13.4K "Why" questions to evaluate the pedagogical capabilities of language models. We then conduct two extensive human studies to assess the utility of language model-generated explanatory answers (explanations) on our benchmark, tailored to three distinct educational grades: elementary, high-school and graduate school. In our first study, human raters assume the role of an "educator" to assess model explanations' fit to different educational grades. We find that GPT-4-generated explanations match their intended educational background only 50% of the time, compared to 79% for lay human-curated explanations. In our second study, human raters assume the role of a learner to assess if an explanation fits their own informational needs. Across all educational backgrounds, users deemed GPT-4-generated explanations 20% less suited on average to their informational needs, when compared to explanations curated by lay people. Additionally, automated evaluation metrics reveal that explanations generated across different language model families for different informational needs remain indistinguishable in their grade-level, limiting their pedagogical effectiveness.

</details>


### [25] [Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation](https://arxiv.org/abs/2506.14203)
*Jongho Kim,Romain Storaï,Seung-won Hwang*

Main category: cs.CL

TL;DR: 提出基于梯度选择增强的语言模型方法，解决语义性错语导致的命名障碍问题，在TOT和失语症患者数据中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 命名障碍患者因语义性错语产生无关词汇干扰，传统方法存在未登录词和语义干扰双重挑战，需增强模型抗干扰能力和未登录词识别能力。

Method: 使用梯度值控制语义干扰下的数据增强质量，通过梯度方差引导未登录词补充。先在TOT数据集验证，再应用于AphasiaBank真实患者数据。

Result: 在两个数据集上均显著超越基线模型，有效提升目标词识别准确率，证实方法对实际临床场景的适用性。

Conclusion: 梯度选择增强机制成功解决语义干扰和未登录词双重挑战，为语言模型在言语康复领域的应用提供新思路。

Abstract: In this study, we investigate the potential of language models (LMs) in aiding patients experiencing anomia, a difficulty identifying the names of items. Identifying the intended target item from patient's circumlocution involves the two challenges of term failure and error: (1) The terms relevant to identifying the item remain unseen. (2) What makes the challenge unique is inherent perturbed terms by semantic paraphasia, which are not exactly related to the target item, hindering the identification process. To address each, we propose robustifying the model from semantically paraphasic errors and enhancing the model with unseen terms with gradient-based selective augmentation. Specifically, the gradient value controls augmented data quality amid semantic errors, while the gradient variance guides the inclusion of unseen but relevant terms. Due to limited domain-specific datasets, we evaluate the model on the Tip-of-the-Tongue dataset as an intermediary task and then apply our findings to real patient data from AphasiaBank. Our results demonstrate strong performance against baselines, aiding anomia patients by addressing the outlined challenges.

</details>


### [26] [AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/abs/2506.14205)
*Jingxu Xie,Dylan Xu,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: 提出AgentSynth框架，通过自动化流程生成高质量计算机使用代理任务数据集，实现成本效益与任务复杂性控制


<details>
  <summary>Details</summary>
Motivation: 解决通用计算机代理任务数据集匮乏问题，利用信息不对称原理构建简单子任务组合成复杂长程任务，降低人工标注成本

Method: 基于LLM的任务提议器生成子任务→执行代理完成轨迹记录→迭代组合成复合任务→独立代理总结任务难度

Result: SOTA代理成功率从难度1的18%骤降至难度6的4%，单轨迹成本仅0.6美元（远低于人工标注）

Conclusion: AgentSynth有效评估代理能力边界，通过子任务数量精确控制复杂度，为智能体开发提供高效低成本的数据解决方案

Abstract: We introduce AgentSynth, a scalable and cost-efficient pipeline for automatically synthesizing high-quality tasks and trajectory datasets for generalist computer-use agents. Leveraging information asymmetry, AgentSynth constructs subtasks that are simple during generation but significantly more challenging when composed into long-horizon tasks, enabling the creation of over 6,000 diverse and realistic tasks. Our pipeline begins with an LLM-based task proposer guided by a persona, followed by an execution agent that completes the task and logs the trajectory. This process is repeated iteratively to form a sequence of subtasks, which are then summarized by a separate agent into a composite task of controllable difficulty. A key strength of AgentSynth is its ability to precisely modulate task complexity by varying the number of subtasks. Empirical evaluations show that state-of-the-art LLM agents suffer a steep performance drop, from 18% success at difficulty level 1 to just 4% at level 6, highlighting the benchmark's difficulty and discriminative power. Moreover, our pipeline achieves a low average cost of \$0.60 per trajectory, orders of magnitude cheaper than human annotations. Our code and data are publicly available at https://github.com/sunblaze-ucb/AgentSynth

</details>


### [27] [CausalDiffTab: Mixed-Type Causal-Aware Diffusion for Tabular Data Generation](https://arxiv.org/abs/2506.14206)
*Jia-Chen Zhang,Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Fei Dai*

Main category: cs.CL

TL;DR: 提出基于扩散模型的CausalDiffTab框架，有效解决混合类型表格数据生成难题，通过自适应因果正则化方法在7个数据集上实现全面性能提升


<details>
  <summary>Details</summary>
Motivation: 当前高质量表格数据生成面临数据类型异构、变量关系复杂、列分布差异大三大挑战，现有方法难以有效捕捉复杂交互关系

Method: 结合扩散模型框架与混合自适应因果正则化（Hierarchical Prior Fusion），动态调节因果约束权重，平衡生成质量与变量关系保持

Result: 在7个基准数据集上全面超越现有方法，保持特征分布准确性的同时显著提升变量间关系建模能力

Conclusion: CausalDiffTab为表格数据生成提供了新范式，其因果正则化机制为复杂关系建模开辟了新方向

Abstract: Training data has been proven to be one of the most critical components in training generative AI. However, obtaining high-quality data remains challenging, with data privacy issues presenting a significant hurdle. To address the need for high-quality data. Synthesize data has emerged as a mainstream solution, demonstrating impressive performance in areas such as images, audio, and video. Generating mixed-type data, especially high-quality tabular data, still faces significant challenges. These primarily include its inherent heterogeneous data types, complex inter-variable relationships, and intricate column-wise distributions. In this paper, we introduce CausalDiffTab, a diffusion model-based generative model specifically designed to handle mixed tabular data containing both numerical and categorical features, while being more flexible in capturing complex interactions among variables. We further propose a hybrid adaptive causal regularization method based on the principle of Hierarchical Prior Fusion. This approach adaptively controls the weight of causal regularization, enhancing the model's performance without compromising its generative capabilities. Comprehensive experiments conducted on seven datasets demonstrate that CausalDiffTab outperforms baseline methods across all metrics. Our code is publicly available at: https://github.com/Godz-z/CausalDiffTab.

</details>


### [28] [Explainable Detection of Implicit Influential Patterns in Conversations via Data Augmentation](https://arxiv.org/abs/2506.14211)
*Sina Abdidizaji,Md Kowsher,Niloofar Yousefi,Ivan Garibay*

Main category: cs.CL

TL;DR: 提出基于语言模型增强的检测框架，提升对话中隐性影响模式的识别准确率6%，并精确定位影响元素位置


<details>
  <summary>Details</summary>
Motivation: 现有模型难以检测对话中隐蔽的影响策略，这些策略通过心理渗透实现信息操控，急需建立有效检测机制

Method: 利用先进语言模型的推理能力扩展数据集，设计可定位隐性影响元素的多任务检测框架

Result: 隐性模式检测准确率提升6%，影响技术和受害者脆弱性多标签分类任务分别提升33%和43%

Conclusion: 该方法有效提升隐蔽信息操控策略的检测能力，为社交平台内容审核提供新技术路径

Abstract: In the era of digitalization, as individuals increasingly rely on digital platforms for communication and news consumption, various actors employ linguistic strategies to influence public perception. While models have become proficient at detecting explicit patterns, which typically appear in texts as single remarks referred to as utterances, such as social media posts, malicious actors have shifted toward utilizing implicit influential verbal patterns embedded within conversations. These verbal patterns aim to mentally penetrate the victim's mind in order to influence them, enabling the actor to obtain the desired information through implicit means. This paper presents an improved approach for detecting such implicit influential patterns. Furthermore, the proposed model is capable of identifying the specific locations of these influential elements within a conversation. To achieve this, the existing dataset was augmented using the reasoning capabilities of state-of-the-art language models. Our designed framework resulted in a 6% improvement in the detection of implicit influential patterns in conversations. Moreover, this approach improved the multi-label classification tasks related to both the techniques used for influence and the vulnerability of victims by 33% and 43%, respectively.

</details>


### [29] [Chaining Event Spans for Temporal Relation Grounding](https://arxiv.org/abs/2506.14213)
*Jongho Kim,Dohyeon Lee,Minsoo Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 提出基于时间线推理网络(TRN)的两步推理框架，解决时序问答任务中答案重叠导致的不可靠问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖答案重叠作为相似性代理指标，但可能因偶然性相同答案导致误判。需通过事件时间跨度预测建立更可靠的推理机制。

Method: 1. 初步结合语义和句法信息回答问题；2. 通过多问题链式推理构建时间线，基于时间线修正答案。

Result: 在TORQUE和TB-dense数据集上，TRN超越现有方法，有效解决答案重叠导致的虚假关联问题。

Conclusion: 通过显式建模时间线实现可靠推理，验证了时序逻辑链对复杂问答任务的重要性。

Abstract: Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: "What finished right before the decision?" or "What finished right after the decision?". To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.

</details>


### [30] [Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team](https://arxiv.org/abs/2506.14234)
*Md Tanzib Hosain,Salman Rahman,Md Kishor Morol,Md Rizwan Parvez*

Main category: cs.CL

TL;DR: Xolver框架通过持续记忆和多模态经验集成（检索/工具/协作/迭代），显著提升LLM复杂推理能力，在多项基准测试中超越先进模型


<details>
  <summary>Details</summary>
Motivation: 当前LLM孤立处理问题，缺乏专家团队整合多种经验（导师指导/历史问题/工具知识/同伴策略）的能力

Method: 集成外部检索+工具使用+多智能体协作+自我评估+迭代优化的训练免框架，利用策略/代码/推理模式等经验进行推理

Result: 使用轻量模型(QWQ-32B)超越Qwen3-235B/Gemini 2.5 Pro，在GSM8K(98.1%)等测试创最佳成绩，验证综合经验的有效性

Conclusion: Xolver证明经验整合是构建专家级推理代理的关键路径，推动语言智能体从孤立推理向经验增强范式转变

Abstract: Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation - treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solvers - such as Olympiad or programming contest teams - leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition. We introduce Xolver, a training-free multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative interactions, agent-driven evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch - marking a transition from isolated inference toward experience-aware language agents. Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses advanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24 (94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) - highlighting holistic experience learning as a key step toward generalist agents capable of expert-level reasoning. Code and data are available at https://kagnlp.github.io/xolver.github.io/.

</details>


### [31] [A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs](https://arxiv.org/abs/2506.14235)
*Yimin Deng,Yuxia Wu,Yejing Wang,Guoshuai Zhao,Li Zhu,Qidong Liu,Derong Xu,Zichuan Fu,Xian Wu,Yefeng Zheng,Xiangyu Zhao,Xueming Qian*

Main category: cs.CL

TL;DR: 提出MESH框架，通过结构-语义混合专家模块提升时序知识图谱推理能力，实验验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有方法无法整合结构学习和语义推理双重视角，且未能区分历史/非历史事件差异，导致泛化性能受限

Method: 设计多专家框架（结构专家/语义专家/混合专家），结合图神经网络和时序注意机制，实现双模态信息融合

Result: 在三个基准数据集上实现SOTA性能，特别是在复杂时序场景下展现显著优势

Conclusion: MESH框架通过多专家协同机制有效解决了时序推理中的结构-语义异构性难题，提升预测准确性和场景适应性

Abstract: Temporal knowledge graph reasoning aims to predict future events with knowledge of existing facts and plays a key role in various downstream tasks. Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives to handle different prediction scenarios. Moreover, they lack the capability to capture the inherent differences between historical and non-historical events, which limits their generalization across different temporal contexts. To this end, we propose a Multi-Expert Structural-Semantic Hybrid (MESH) framework that employs three kinds of expert modules to integrate both structural and semantic information, guiding the reasoning process for different events. Extensive experiments on three datasets demonstrate the effectiveness of our approach.

</details>


### [32] [Re-Initialization Token Learning for Tool-Augmented Large Language Models](https://arxiv.org/abs/2506.14248)
*Chenghao Li,Liu Liu,Baosheng Yu,Jiayan Qiu,Yibing Zhan*

Main category: cs.CL

TL;DR: 提出通过将工具token与词嵌入空间对齐的新方法，显著提升大语言模型调用外部工具的准确性


<details>
  <summary>Details</summary>
Motivation: 现有工具调用方法忽略工具token与单词token的关系，限制了预训练模型的适应性

Method: 基于工具描述构建先验token嵌入，通过初始化与正则化实现工具token与词嵌入空间对齐

Result: 在GSM8K-XL等多个数据集上超越CoT、REACT等基线模型，准确率提升显著

Conclusion: 该方法通过相关token有效增强大语言模型的工具使用能力，具有跨领域适用性

Abstract: Large language models have demonstrated exceptional performance, yet struggle with complex tasks such as numerical reasoning, plan generation. Integrating external tools, such as calculators and databases, into large language models (LLMs) is crucial for enhancing problem-solving capabilities. Current methods assign a unique token to each tool, enabling LLMs to call tools through token prediction-similar to word generation. However, this approach fails to account for the relationship between tool and word tokens, limiting adaptability within pre-trained LLMs. To address this issue, we propose a novel token learning method that aligns tool tokens with the existing word embedding space from the perspective of initialization, thereby enhancing model performance. We begin by constructing prior token embeddings for each tool based on the tool's name or description, which are used to initialize and regularize the learnable tool token embeddings. This ensures the learned embeddings are well-aligned with the word token space, improving tool call accuracy. We evaluate the method on tasks such as numerical reasoning, knowledge-based question answering, and embodied plan generation using GSM8K-XL, FuncQA, KAMEL, and VirtualHome datasets. The results demonstrate clear improvements over recent baselines, including CoT, REACT, ICL, and ToolkenGPT, indicating that our approach effectively augments LLMs with tools through relevant tokens across diverse domains.

</details>


### [33] [From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents](https://arxiv.org/abs/2506.14285)
*Seongbo Jang,Minjin Jeon,Jaehoon Lee,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 提出及时对话响应生成任务及TimelyChat基准，构建55K事件驱动对话数据集，训练Timer模型在预测时间间隔与生成及时响应方面优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有对话生成研究集中于文本上下文连贯性，但未深入探究基于时间上下文的响应时机决策问题。

Method: 利用时间常识知识图谱构建未标注事件数据，通过LLM合成55K事件驱动对话，训练Timer模型实现时间间隔预测与响应生成联合优化。

Result: Timer在轮级(prompt-based LLMs)和对话级(fine-tuned baselines)评估中均表现最优。

Conclusion: 通过构建新任务、基准和大规模数据集，证明了Timer模型在时间敏感对话生成任务中的有效性，相关资源已开源。

Abstract: While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code.

</details>


### [34] [Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent](https://arxiv.org/abs/2506.14302)
*Xueyang Feng,Jingsen Zhang,Jiakai Tang,Wei Li,Guohao Cai,Xu Chen,Quanyu Dai,Yue Zhu,Zhenhua Dong*

Main category: cs.CL

TL;DR: 提出基于期望确认理论的多轮偏好优化范式ECPO，通过建模用户满意度演化机制实现对话推荐代理的优化


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法在多轮对话中成本高且效果欠佳，需要更细粒度地建模用户满意度变化

Method: ECPO框架结合LLM用户模拟器AILO，通过期望确认理论定位用户不满原因，实现针对性逐轮优化

Result: 实验证明ECPO显著提升对话推荐代理的交互能力，在效率与效果上均优于现有方法

Conclusion: 该方法创新性地消除传统多轮优化方法的采样开销，通过满意度演化机制实现精准优化

Abstract: Recent advancements in Large Language Models (LLMs) have significantly propelled the development of Conversational Recommendation Agents (CRAs). However, these agents often generate short-sighted responses that fail to sustain user guidance and meet expectations. Although preference optimization has proven effective in aligning LLMs with user expectations, it remains costly and performs poorly in multi-turn dialogue. To address this challenge, we introduce a novel multi-turn preference optimization (MTPO) paradigm ECPO, which leverages Expectation Confirmation Theory to explicitly model the evolution of user satisfaction throughout multi-turn dialogues, uncovering the underlying causes of dissatisfaction. These causes can be utilized to support targeted optimization of unsatisfactory responses, thereby achieving turn-level preference optimization. ECPO ingeniously eliminates the significant sampling overhead of existing MTPO methods while ensuring the optimization process drives meaningful improvements. To support ECPO, we introduce an LLM-based user simulator, AILO, to simulate user feedback and perform expectation confirmation during conversational recommendations. Experimental results show that ECPO significantly enhances CRA's interaction capabilities, delivering notable improvements in both efficiency and effectiveness over existing MTPO methods.

</details>


### [35] [Evaluation Should Not Ignore Variation: On the Impact of Reference Set Choice on Summarization Metrics](https://arxiv.org/abs/2506.14335)
*Silvia Casola,Yang Janet Liu,Siyao Peng,Oliver Kraus,Albert Gatt,Barbara Plank*

Main category: cs.CL

TL;DR: 现有摘要评估指标（如ROUGE）因参考集差异存在显著不稳定性，影响模型对比可靠性，建议将参考集差异纳入评估体系以提升一致性


<details>
  <summary>Details</summary>
Motivation: 当前摘要评估忽略人类语言多样性，多参考摘要场景下主流评估指标对参考集选择的敏感性未被系统研究

Method: 基于SummEval/GUMSum/DUC2004三个多参考摘要数据集，分析ROUGE等指标稳定性，并补充非新闻类数据的LLM输出人工评估

Result: n-gram类指标模型排名随参考集变化，人类评估与指标相关性微弱（非新闻数据），暴露当前指标可靠性缺陷

Conclusion: 需将参考集差异纳入评估体系（尤其评估LLM时），兼顾指标稳定性和人类判断相关性

Abstract: Human language production exhibits remarkable richness and variation, reflecting diverse communication styles and intents. However, this variation is often overlooked in summarization evaluation. While having multiple reference summaries is known to improve correlation with human judgments, the impact of using different reference sets on reference-based metrics has not been systematically investigated. This work examines the sensitivity of widely used reference-based metrics in relation to the choice of reference sets, analyzing three diverse multi-reference summarization datasets: SummEval, GUMSum, and DUC2004. We demonstrate that many popular metrics exhibit significant instability. This instability is particularly concerning for n-gram-based metrics like ROUGE, where model rankings vary depending on the reference sets, undermining the reliability of model comparisons. We also collect human judgments on LLM outputs for genre-diverse data and examine their correlation with metrics to supplement existing findings beyond newswire summaries, finding weak-to-no correlation. Taken together, we recommend incorporating reference set variation into summarization evaluation to enhance consistency alongside correlation with human judgments, especially when evaluating LLMs.

</details>


### [36] [A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis](https://arxiv.org/abs/2506.14345)
*Bruno Martins,Piotr Szymański,Piotr Gramacki*

Main category: cs.CL

TL;DR: 大型语言模型驱动的研究系统缺乏地理时空推理能力，本文提出整合该能力的系统升级方案


<details>
  <summary>Details</summary>
Motivation: 地理时空约束在公共卫生、环境科学等领域普遍存在，现有深度研究系统无法有效处理这类时空敏感问题

Method: 建议增强检索与合成过程的时空约束处理能力，构建开放可复现的基础设施并建立严格评估标准

Result: 提出将地理时空推理融入研究流程的技术路线，明确技术/基建/评估三位一体的实施框架

Conclusion: 地理时空感知系统的实现将推动AI信息获取系统的进化，对智能研究产生深远影响

Abstract: The emergence of Large Language Models (LLMs) has transformed information access, with current LLMs also powering deep research systems that can generate comprehensive report-style answers, through planned iterative search, retrieval, and reasoning. Still, current deep research systems lack the geo-temporal capabilities that are essential for answering context-rich questions involving geographic and/or temporal constraints, frequently occurring in domains like public health, environmental science, or socio-economic analysis. This paper reports our vision towards next generation systems, identifying important technical, infrastructural, and evaluative challenges in integrating geo-temporal reasoning into deep research pipelines. We argue for augmenting retrieval and synthesis processes with the ability to handle geo-temporal constraints, supported by open and reproducible infrastructures and rigorous evaluation protocols. Our vision outlines a path towards more advanced and geo-temporally aware deep research systems, of potential impact to the future of AI-driven information access.

</details>


### [37] [Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits](https://arxiv.org/abs/2506.14370)
*Amrit Poudel,Yifan Ding,Jurgen Pfeffer,Tim Weninger*

Main category: cs.CL

TL;DR: 搜索引擎通过算法过滤机制系统性抑制敏感内容（色情/阴谋论/加密货币），同时推广高参与度内容，影响公众话语权


<details>
  <summary>Details</summary>
Motivation: 揭示Google作为数字守门人如何通过算法筛选社交媒体内容（hashtag/subreddit），塑造用户信息接触范围

Method: 对比Google搜索结果与Reddit/Twitter原始数据，分析内容可见性偏差

Result: 发现Google系统性抑制色情内容/阴谋论/广告/加密货币相关子版块，优先展示高互动性内容

Conclusion: 搜索引擎的算法守门行为通过控制社交媒体叙事可见度，实质影响公共话语体系构建

Abstract: Search engines play a crucial role as digital gatekeepers, shaping the visibility of Web and social media content through algorithmic curation. This study investigates how search engines like Google selectively promotes or suppresses certain hashtags and subreddits, impacting the information users encounter. By comparing search engine results with nonsampled data from Reddit and Twitter/X, we reveal systematic biases in content visibility. Google's algorithms tend to suppress subreddits and hashtags related to sexually explicit material, conspiracy theories, advertisements, and cryptocurrencies, while promoting content associated with higher engagement. These findings suggest that Google's gatekeeping practices influence public discourse by curating the social media narratives available to users.

</details>


### [38] [ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection](https://arxiv.org/abs/2506.14371)
*Lucile Favero,Daniel Frases,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CL

TL;DR: 提出基于小规模开源语言模型的两步框架（提问者+筛选者），在自动生成批判性问题的竞赛中夺冠，验证了LLM促进论证文本深度思考的潜力。


<details>
  <summary>Details</summary>
Motivation: 针对LLM聊天接口可能助长表面学习的担忧，探索通过生成批判性问题挑战论证漏洞，促进深度推理而非单纯事实检索。

Method: 两阶段框架：1）Questioner模型生成候选问题 2）Judge模型筛选最优问题，均采用小规模开源语言模型实现。

Result: 在ACL 2025第十二届Argument Mining Workshop的自动批判问题生成竞赛中获得第一名。

Conclusion: 验证了基于LLM的方法能有效增强论证文本的批判性参与，为培养批判性思维提供了技术路径。

Abstract: The widespread adoption of chat interfaces based on Large Language Models (LLMs) raises concerns about promoting superficial learning and undermining the development of critical thinking skills. Instead of relying on LLMs purely for retrieving factual information, this work explores their potential to foster deeper reasoning by generating critical questions that challenge unsupported or vague claims in debate interventions. This study is part of a shared task of the 12th Workshop on Argument Mining, co-located with ACL 2025, focused on automatic critical question generation. We propose a two-step framework involving two small-scale open source language models: a Questioner that generates multiple candidate questions and a Judge that selects the most relevant ones. Our system ranked first in the shared task competition, demonstrating the potential of the proposed LLM-based approach to encourage critical engagement with argumentative texts.

</details>


### [39] [Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding](https://arxiv.org/abs/2506.14397)
*Yeonkyoung So,Gyuseong Lee,Sungmok Jung,Joonhak Lee,JiA Kang,Sangho Kim,Jaejin Lee*

Main category: cs.CL

TL;DR: 提出专门评估大语言模型否定理解能力的新基准Thunder-NUBench


<details>
  <summary>Details</summary>
Motivation: 现有基准将否定作为自然语言推理的附属案例，缺乏专门针对否定理解的评估体系。大语言模型在需要深层语义理解的否定任务中持续表现不佳，需建立针对性评估工具。

Method: 构建包含标准否定与局部否定/矛盾/转述等结构变体的句子-否定对，创建多选题数据集，通过对比不同否定结构设计评估框架。

Result: Thunder-NUBench成功揭示模型在否定理解上的局限性，特别是对结构复杂否定的处理能力差异。

Conclusion: 该基准填补否定理解评估空白，为提升语言模型语义理解能力提供关键测试工具，推动更系统的否定机制研究。

Abstract: Negation is a fundamental linguistic phenomenon that poses persistent challenges for Large Language Models (LLMs), particularly in tasks requiring deep semantic understanding. Existing benchmarks often treat negation as a side case within broader tasks like natural language inference, resulting in a lack of benchmarks that exclusively target negation understanding. In this work, we introduce \textbf{Thunder-NUBench}, a novel benchmark explicitly designed to assess sentence-level negation understanding in LLMs. Thunder-NUBench goes beyond surface-level cue detection by contrasting standard negation with structurally diverse alternatives such as local negation, contradiction, and paraphrase. The benchmark consists of manually curated sentence-negation pairs and a multiple-choice dataset that enables in-depth evaluation of models' negation understanding.

</details>


### [40] [ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge](https://arxiv.org/abs/2506.14407)
*Zeinab Sadat Taghavi,Ali Modarressi,Yunpu Ma,Hinrich Schütze*

Main category: cs.CL

TL;DR: 提出ImpliRet评测基准，将检索系统的推理挑战转移到文档侧，揭示当前检索模型在隐式关系推理上的严重不足（最优模型nDCG@10仅15.07%）


<details>
  <summary>Details</summary>
Motivation: 现有检索系统依赖表层语义线索，而复杂推理型查询的评测基准将负担转移至查询侧处理技术。本文旨在探索文档侧隐式关系（时间/算术/常识）对检索系统的挑战。

Method: 构建ImpliRet基准：① 查询简单但相关性依赖文档中的隐式事实（如时间解析、算术关系、常识推理）；② 评估稀疏/稠密检索模型及长上下文模型的性能

Result: 所有检索模型表现均不佳（最佳nDCG@10=15.07%）。GPT-4在10个文档上下文中准确率仅35.06%，显示文档侧推理仍是重大挑战

Conclusion: 文档侧隐式关系推理是当前检索系统的薄弱环节，需开发新的文档理解方法。实验结果揭示了现有技术的重要局限，为未来研究指明方向

Abstract: Retrieval systems are central to many NLP pipelines, but often rely on surface-level cues such as keyword overlap and lexical semantic similarity. To evaluate retrieval beyond these shallow signals, recent benchmarks introduce reasoning-heavy queries; however, they primarily shift the burden to query-side processing techniques -- like prompting or multi-hop retrieval -- that can help resolve complexity. In contrast, we present ImpliRet, a benchmark that shifts the reasoning challenge to document-side processing: The queries are simple, but relevance depends on facts stated implicitly in documents through temporal (e.g., resolving "two days ago"), arithmetic, and world knowledge relationships. We evaluate a range of sparse and dense retrievers, all of which struggle in this setting: the best nDCG@10 is only 15.07%. We also test whether long-context models can overcome this limitation. But even with a short context of only ten documents, including the positive document, GPT-4.1 scores only 35.06%, showing that document-side reasoning remains a challenge. Our codes are available at github.com/ZeinabTaghavi/IMPLIRET.Contribution.

</details>


### [41] [LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs](https://arxiv.org/abs/2506.14429)
*Xiaoran Liu,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 首次系统研究扩散大语言模型的长上下文能力，发现其稳定困惑度特性与局部感知现象，提出无需训练的上下文扩展方法LongLLaDA，建立扩散LLM上下文外推理论基础


<details>
  <summary>Details</summary>
Motivation: 填补扩散LLMs在长上下文能力研究的空白，揭示其与传统自回归模型在上下文扩展中的本质差异

Method: 通过困惑度分析和Needle-In-A-Haystack任务测试，结合RoPE位置编码缩放理论解释现象，提出NTK-based RoPE外推的LongLLaDA方法

Result: 扩散LLMs在直接外推时保持稳定困惑度，局部感知能力使其突破预训练长度限制，成功建立首个扩散LLM上下文扩展方法并验证扩展定律有效性

Conclusion: 本研究为扩散LLMs的上下文扩展提供方法论和理论框架，揭示其在特定长上下文任务中的优势，奠定未来研究的基准基础

Abstract: Large Language Diffusion Models, or diffusion LLMs, have emerged as a significant focus in NLP research, with substantial effort directed toward understanding their scalability and downstream task performance. However, their long-context capabilities remain unexplored, lacking systematic analysis or methods for context extension. In this work, we present the first systematic investigation comparing the long-context performance of diffusion LLMs and traditional auto-regressive LLMs. We first identify a unique characteristic of diffusion LLMs, unlike auto-regressive LLMs, they maintain remarkably \textbf{\textit{stable perplexity}} during direct context extrapolation. Furthermore, where auto-regressive models fail outright during the Needle-In-A-Haystack task with context exceeding their pretrained length, we discover diffusion LLMs exhibit a distinct \textbf{\textit{local perception}} phenomenon, enabling successful retrieval from recent context segments. We explain both phenomena through the lens of Rotary Position Embedding (RoPE) scaling theory. Building on these observations, we propose LongLLaDA, a training-free method that integrates LLaDA with the NTK-based RoPE extrapolation. Our results validate that established extrapolation scaling laws remain effective for extending the context windows of diffusion LLMs. Furthermore, we identify long-context tasks where diffusion LLMs outperform auto-regressive LLMs and others where they fall short. Consequently, this study establishes the first context extrapolation method for diffusion LLMs while providing essential theoretical insights and empirical benchmarks critical for advancing future research on long-context diffusion LLMs.

</details>


### [42] [How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison](https://arxiv.org/abs/2506.14448)
*Jiayin Wang,Zhiquang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CL

TL;DR: 研究通过语义游戏和人类对比评估LLMs的测试时学习能力，发现模型具备潜力但存在显著智能差距


<details>
  <summary>Details</summary>
Motivation: 现有基准测试聚焦静态知识评估，而实现AGI需要模型具备从经验中快速学习的能力，需建立动态评估体系

Method: 提出语义游戏作为抗饱和的测试平台，设计包含有限/累积经验设置的评估框架（含四种经验表示形式），并引入人类基准测试

Result: LLMs展现出可测量的测试时学习能力，但在累积经验下改进稳定性较低且进步速度显著慢于人类

Conclusion: LLMs具有通用学习机器的潜力，但现有模型与人类存在本质性智能鸿沟，动态评估比静态基准更能揭示真实能力差距

Abstract: As evaluation designs of large language models may shape our trajectory toward artificial general intelligence, comprehensive and forward-looking assessment is essential. Existing benchmarks primarily assess static knowledge, while intelligence also entails the ability to rapidly learn from experience. To this end, we advocate for the evaluation of Test-time Learning, the capacity to improve performance in experience-based, reasoning-intensive tasks during test time. In this work, we propose semantic games as effective testbeds for evaluating test-time learning, due to their resistance to saturation and inherent demand for strategic reasoning. We introduce an objective evaluation framework that compares model performance under both limited and cumulative experience settings, and contains four forms of experience representation. To provide a comparative baseline, we recruit eight human participants to complete the same task. Results show that LLMs exhibit measurable test-time learning capabilities; however, their improvements are less stable under cumulative experience and progress more slowly than those observed in humans. These findings underscore the potential of LLMs as general-purpose learning machines, while also revealing a substantial intellectual gap between models and humans, irrespective of how well LLMs perform on static benchmarks.

</details>


### [43] [LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data](https://arxiv.org/abs/2506.14474)
*Eyal German,Sagiv Antebi,Edan Habler,Asaf Shabtai,Yuval Elovici*

Main category: cs.CL

TL;DR: 提出LexiMark水印技术，通过同义词替换高熵词增强模型对水印文本的记忆，实现隐蔽且抗移除的数据集版权验证


<details>
  <summary>Details</summary>
Motivation: 现有数据集水印方法隐蔽性差且易被移除，需开发更隐蔽且抗干扰的水印技术来验证LLM是否未经授权使用特定数据

Method: 选择高熵词汇进行同义词替换，增强模型记忆同时保持语义完整，水印无视觉痕迹且抗自动化/人工检测

Result: 在LLaMA-3等7个模型上验证，持续预训练和微调场景下AUROC显著优于现有方法

Conclusion: LexiMark通过语义保持的隐蔽水印机制，可靠验证LLM训练数据来源，为数据版权保护提供有效解决方案

Abstract: Large language models (LLMs) can be trained or fine-tuned on data obtained without the owner's consent. Verifying whether a specific LLM was trained on particular data instances or an entire dataset is extremely challenging. Dataset watermarking addresses this by embedding identifiable modifications in training data to detect unauthorized use. However, existing methods often lack stealth, making them relatively easy to detect and remove. In light of these limitations, we propose LexiMark, a novel watermarking technique designed for text and documents, which embeds synonym substitutions for carefully selected high-entropy words. Our method aims to enhance an LLM's memorization capabilities on the watermarked text without altering the semantic integrity of the text. As a result, the watermark is difficult to detect, blending seamlessly into the text with no visible markers, and is resistant to removal due to its subtle, contextually appropriate substitutions that evade automated and manual detection. We evaluated our method using baseline datasets from recent studies and seven open-source models: LLaMA-1 7B, LLaMA-3 8B, Mistral 7B, Pythia 6.9B, as well as three smaller variants from the Pythia family (160M, 410M, and 1B). Our evaluation spans multiple training settings, including continued pretraining and fine-tuning scenarios. The results demonstrate significant improvements in AUROC scores compared to existing methods, underscoring our method's effectiveness in reliably verifying whether unauthorized watermarked data was used in LLM training.

</details>


### [44] [LingoLoop Attack: Trapping MLLMs via Linguistic Context and State Entrapment into Endless Loops](https://arxiv.org/abs/2506.14493)
*Jiyuan Fu,Kaixun Jiang,Lingyi Hong,Jinglun Li,Haijing Guo,Dingkang Yang,Zhaoyu Chen,Wenqiang Zhang*

Main category: cs.CL

TL;DR: 提出LingoLoop攻击方法，通过词性感知延迟和生成路径剪枝机制诱导MLLMs生成冗长循环输出，导致计算资源消耗增加30倍


<details>
  <summary>Details</summary>
Motivation: 现有能耗-延迟攻击仅调整token分布而忽视词性特征和句子结构对输出的影响，导致攻击效果受限

Method: 1. POS-Aware Delay机制利用词性标签调整注意力权重延迟EOS生成；2. Generative Path Pruning机制限制隐藏状态幅度强制生成循环序列

Result: 实验显示攻击使Qwen2.5-VL-3B等模型生成token增加30倍，能耗同比提升30倍，持续达到生成上限

Conclusion: 该研究暴露了MLLMs在抗资源耗尽攻击方面的严重漏洞，对其可靠部署提出新的安全挑战

Abstract: Multimodal Large Language Models (MLLMs) have shown great promise but require substantial computational resources during inference. Attackers can exploit this by inducing excessive output, leading to resource exhaustion and service degradation. Prior energy-latency attacks aim to increase generation time by broadly shifting the output token distribution away from the EOS token, but they neglect the influence of token-level Part-of-Speech (POS) characteristics on EOS and sentence-level structural patterns on output counts, limiting their efficacy. To address this, we propose LingoLoop, an attack designed to induce MLLMs to generate excessively verbose and repetitive sequences. First, we find that the POS tag of a token strongly affects the likelihood of generating an EOS token. Based on this insight, we propose a POS-Aware Delay Mechanism to postpone EOS token generation by adjusting attention weights guided by POS information. Second, we identify that constraining output diversity to induce repetitive loops is effective for sustained generation. We introduce a Generative Path Pruning Mechanism that limits the magnitude of hidden states, encouraging the model to produce persistent loops. Extensive experiments demonstrate LingoLoop can increase generated tokens by up to 30 times and energy consumption by a comparable factor on models like Qwen2.5-VL-3B, consistently driving MLLMs towards their maximum generation limits. These findings expose significant MLLMs' vulnerabilities, posing challenges for their reliable deployment. The code will be released publicly following the paper's acceptance.

</details>


### [45] [M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models](https://arxiv.org/abs/2506.14532)
*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Zitong Yu,Merouane Debbah*

Main category: cs.CL

TL;DR: 提出M2BeamLLM多模态框架，利用GPT-2实现毫米波通信系统的智能波束预测，准确率显著优于传统深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波大规模MIMO系统中传统深度学习模型在波束预测时面临的数据依赖性强、多模态信息利用不足的问题。

Method: 整合图像/雷达/LiDAR/GPS等多模态数据，通过传感器编码、跨模态对齐融合、监督微调三阶段框架实现端到端学习。

Result: 在标准/小样本场景下预测准确率分别提升18.7%/32.1%，且传感器模态多样性增加时性能持续提升。

Conclusion: 为车路协同毫米波通信提供了高效智能的波束预测解决方案，验证了LLM在物理层信号处理中的应用潜力。

Abstract: This paper introduces a novel neural network framework called M2BeamLLM for beam prediction in millimeter-wave (mmWave) massive multi-input multi-output (mMIMO) communication systems. M2BeamLLM integrates multi-modal sensor data, including images, radar, LiDAR, and GPS, leveraging the powerful reasoning capabilities of large language models (LLMs) such as GPT-2 for beam prediction. By combining sensing data encoding, multimodal alignment and fusion, and supervised fine-tuning (SFT), M2BeamLLM achieves significantly higher beam prediction accuracy and robustness, demonstrably outperforming traditional deep learning (DL) models in both standard and few-shot scenarios. Furthermore, its prediction performance consistently improves with increased diversity in sensing modalities. Our study provides an efficient and intelligent beam prediction solution for vehicle-to-infrastructure (V2I) mmWave communication systems.

</details>


### [46] [AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs](https://arxiv.org/abs/2506.14562)
*Di He,Ajay Jaiswal,Songjun Tu,Li Shen,Ganzhao Yuan,Shiwei Liu,Lu Yin*

Main category: cs.CL

TL;DR: 提出AlphaDecay方法，通过分析权重矩阵的频谱特性自适应分配权重衰减强度，提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 传统均匀权重衰减忽视LLM模块结构差异及频谱特性差异，需针对性调整衰减强度。

Method: 基于HT-SR理论分析权重相关矩阵的厚尾性，根据频谱特性强弱自适应分配衰减强度：厚尾性强的模块（特征学习强）弱衰减，弱厚尾模块强衰减。

Result: 60M到1B参数规模的预训练实验显示，AlphaDecay在困惑度和泛化能力上优于均匀衰减基准。

Conclusion: 通过平衡模块间频谱特性差异的衰减分配策略，可有效提升模型表现。

Abstract: Weight decay is a standard regularization technique for training large language models (LLMs). While it is common to assign a uniform decay rate to every layer, this approach overlooks the structural diversity of LLMs and the varying spectral properties across modules. In this paper, we introduce AlphaDecay, a simple yet effective method that adaptively assigns different weight decay strengths to each module of an LLM. Our approach is guided by Heavy-Tailed Self-Regularization (HT-SR) theory, which analyzes the empirical spectral density (ESD) of weight correlation matrices to quantify "heavy-tailedness." Modules exhibiting more pronounced heavy-tailed ESDs, reflecting stronger feature learning, are assigned weaker decay, while modules with lighter-tailed spectra receive stronger decay. Our method leverages tailored weight decay assignments to balance the module-wise differences in spectral properties, leading to improved performance. Extensive pre-training tasks with various model sizes from 60M to 1B demonstrate that AlphaDecay achieves better perplexity and generalization than conventional uniform decay and other adaptive decay baselines.

</details>


### [47] [GenerationPrograms: Fine-grained Attribution with Executable Programs](https://arxiv.org/abs/2506.14580)
*David Wan,Eran Hirsch,Elias Stengel-Eskin,Ido Dagan,Mohit Bansal*

Main category: cs.CL

TL;DR: 提出模块化生成框架GenerationPrograms，通过分阶段程序计划与执行机制显著提升文本生成任务的归因质量与可解释性


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在文本生成时存在细粒度归因不准确的问题，且传统方法无法解释模型如何利用源文档生成响应

Method: 两阶段框架：1) 根据查询生成模块化操作程序计划（改写/压缩/融合等）；2) 按程序指令执行操作生成最终响应

Result: 在长问答和多文档摘要任务中，文档级和句子级归因质量显著提升，并能作为事后归因方法优于传统技术，支持模块级优化改进

Conclusion: 模块化分解生成过程有效提升归因质量与可解释性，程序化架构支持局部改进，且可作为高效的事后归因解决方案

Abstract: Recent large language models (LLMs) achieve impressive performance in source-conditioned text generation but often fail to correctly provide fine-grained attributions for their outputs, undermining verifiability and trust. Moreover, existing attribution methods do not explain how and why models leverage the provided source documents to generate their final responses, limiting interpretability. To overcome these challenges, we introduce a modular generation framework, GenerationPrograms, inspired by recent advancements in executable "code agent" architectures. Unlike conventional generation methods that simultaneously generate outputs and attributions or rely on post-hoc attribution, GenerationPrograms decomposes the process into two distinct stages: first, creating an executable program plan composed of modular text operations (such as paraphrasing, compression, and fusion) explicitly tailored to the query, and second, executing these operations following the program's specified instructions to produce the final response. Empirical evaluations demonstrate that GenerationPrograms significantly improves attribution quality at both the document level and sentence level across two long-form question-answering tasks and a multi-document summarization task. We further demonstrate that GenerationPrograms can effectively function as a post-hoc attribution method, outperforming traditional techniques in recovering accurate attributions. In addition, the interpretable programs generated by GenerationPrograms enable localized refinement through modular-level improvements that further enhance overall attribution quality.

</details>


### [48] [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](https://arxiv.org/abs/2506.14606)
*Ahmed Heakl,Sarim Hashmi,Chaimaa Abi,Celine Lee,Abdulrahman Mahmoud*

Main category: cs.CL

TL;DR: 提出GG转译框架，结合LLM与软件测试实现CISC-RISC架构间高正确率转译，性能超越Rosetta 2


<details>
  <summary>Details</summary>
Motivation: 解决复杂CISC与精简RISC架构间因指令复杂度、内存模型差异导致的转译难题，提升代码可移植性

Method: 1. 使用预训练LLM生成候选翻译代码
2. 通过软件测试框架（>98%覆盖率）验证代码功能/语义正确性

Result: HumanEval正确率99%，BringupBench正确率49%；相比Rosetta 2：运行速度1.73x↑，能效1.47x↑，内存使用2.41x↑

Conclusion: GG有效解决现实CISC-RISC转译需求，通过开源建立ISA级代码转译研究基准

Abstract: The hardware ecosystem is rapidly evolving, with increasing interest in translating low-level programs across different instruction set architectures (ISAs) in a quick, flexible, and correct way to enhance the portability and longevity of existing code. A particularly challenging class of this transpilation problem is translating between complex- (CISC) and reduced- (RISC) hardware architectures, due to fundamental differences in instruction complexity, memory models, and execution paradigms. In this work, we introduce GG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the translation power of pre-trained large language models (LLMs) with the rigor of established software testing constructs. Our method generates candidate translations using an LLM from one ISA to another, and embeds such translations within a software-testing framework to build quantifiable confidence in the translation. We evaluate our GG approach over two diverse datasets, enforce high code coverage (>98%) across unit tests, and achieve functional/semantic correctness of 99% on HumanEval programs and 49% on BringupBench programs, respectively. Further, we compare our approach to the state-of-the-art Rosetta 2 framework on Apple Silicon, showcasing 1.73x faster runtime performance, 1.47x better energy efficiency, and 2.41x better memory usage for our transpiled code, demonstrating the effectiveness of GG for real-world CISC-to-RISC translation tasks. We will open-source our codes, data, models, and benchmarks to establish a common foundation for ISA-level code translation research.

</details>


### [49] [When Does Meaning Backfire? Investigating the Role of AMRs in NLI](https://arxiv.org/abs/2506.14613)
*Junghyun Min,Xiulin Yang,Shira Wein*

Main category: cs.CL

TL;DR: 研究AMR对NLI任务的影响，发现提示策略下GPT-4o性能提升源于表面差异而非语义推理改进


<details>
  <summary>Details</summary>
Motivation: 探索抽象意义表示（AMR）能否帮助预训练语言模型提升自然语言推理任务的泛化能力

Method: 通过微调和提示两种方式将AMR整合到NLI任务，使用GPT-4o进行实验并开展消融研究

Result: 微调引入AMR损害模型泛化，提示策略获得的小幅提升实际源于放大文本表面差异而非语义理解

Conclusion: AMR在提示策略中可能误导模型关注表面差异，需谨慎使用语义增强方法避免损害核心语义推理

Abstract: Natural Language Inference (NLI) relies heavily on adequately parsing the semantic content of the premise and hypothesis. In this work, we investigate whether adding semantic information in the form of an Abstract Meaning Representation (AMR) helps pretrained language models better generalize in NLI. Our experiments integrating AMR into NLI in both fine-tuning and prompting settings show that the presence of AMR in fine-tuning hinders model generalization while prompting with AMR leads to slight gains in \texttt{GPT-4o}. However, an ablation study reveals that the improvement comes from amplifying surface-level differences rather than aiding semantic reasoning. This amplification can mislead models to predict non-entailment even when the core meaning is preserved.

</details>


### [50] [Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models](https://arxiv.org/abs/2506.14625)
*Chenchen Yuan,Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 提出整合多个大语言模型的道德判断形成集体共识，通过嵌入优化对齐偏离模型，提高AI系统的道德一致性


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂道德困境中判断分歧的问题，增强AI系统的安全性和一致性

Method: 1. 聚合模型道德评分生成集体概率 2. 通过JS散度优化的token嵌入微调对齐偏离模型 3. 保持语义完整性的哲学理论嵌入调整

Result: 在大规模社会道德困境数据集上有效建立共识，模型忠实度提升14.6%

Conclusion: 多模型数据驱动的道德对齐机制为构建安全可靠的AI系统提供了新范式

Abstract: Large Language Models (LLMs) have shown impressive moral reasoning abilities. Yet they often diverge when confronted with complex, multi-factor moral dilemmas. To address these discrepancies, we propose a framework that synthesizes multiple LLMs' moral judgments into a collectively formulated moral judgment, realigning models that deviate significantly from this consensus. Our aggregation mechanism fuses continuous moral acceptability scores (beyond binary labels) into a collective probability, weighting contributions by model reliability. For misaligned models, a targeted embedding-optimization procedure fine-tunes token embeddings for moral philosophical theories, minimizing JS divergence to the consensus while preserving semantic integrity. Experiments on a large-scale social moral dilemma dataset show our approach builds robust consensus and improves individual model fidelity. These findings highlight the value of data-driven moral alignment across multiple models and its potential for safer, more consistent AI systems.

</details>


### [51] [AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation](https://arxiv.org/abs/2506.14634)
*Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessika Daikeler*

Main category: cs.CL

TL;DR: 研究探讨不同LLM在德语开放式问卷应答分类中的效果，发现微调模型表现最佳，提示方法有效性取决于具体模型。


<details>
  <summary>Details</summary>
Motivation: 探索LLM能否替代耗时的人工编码和监督学习模型，特别是在非英语复杂语境下的分类效果验证。

Method: 使用德国调查参与原因数据，对比多种前沿LLM及提示方法，以专家人工编码为基准评估性能。

Result: 不同LLM性能差异显著，仅微调模型达到理想预测水平；提示效果与模型强相关；未微调时分类偏差导致分布差异。

Conclusion: LLM应用于开放式应答分类需权衡效率、准确性和可靠性，微调及模型选择对结果有决定性影响。

Abstract: The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.

</details>


### [52] [Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot](https://arxiv.org/abs/2506.14641)
*Xiang Cheng,Chengyan Pan,Minjun Zhao,Deyang Li,Fangchao Liu,Xinyu Zhang,Xiao Zhang,Yong Liu*

Main category: cs.CL

TL;DR: 研究表明，在Qwen2.5等新型大语言模型中，传统或增强型CoT示例均未提升数学推理能力，模型倾向于忽略示例而依赖指令，需重新评估ICL范式。


<details>
  <summary>Details</summary>
Motivation: 探究CoT示例是否仍能提升新型强语言模型（如Qwen2.5系列）在数学任务中的推理能力。

Method: 通过系统实验，对比传统CoT示例、Zero-Shot CoT以及基于Qwen2.5-Max等先进模型生成的增强型CoT示例的效果。

Result: 传统/增强型CoT示例均未提升模型推理性能，模型主要关注指令而忽略示例，推理能力无显著增益。

Conclusion: 当前ICL+CoT框架在数学推理中存在局限，需重新审视ICL范式及示例定义方式。

Abstract: In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \texttt{Qwen2.5-Max} and \texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.

</details>


### [53] [Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments](https://arxiv.org/abs/2506.14645)
*. Pazzaglia,V. Vendetti,L. D. Comencini,F. Deriu,V. Modugno*

Main category: cs.CL

TL;DR: 研究表明经过政治立场数据微调的大语言模型能生成极具煽动性的极化内容，其效果与人类言论难以区分，引发对AI伦理和治理的深刻担忧。


<details>
  <summary>Details</summary>
Motivation: 探讨微调后的大语言模型是否会在网络环境中加剧意识形态极化，验证其生成偏见内容的能力及潜在社会危害。

Method: 使用Reddit政治讨论数据集微调开源LLM，通过语言学分析、情感评分和人工标注评估模型输出的可信度与修辞一致性。

Result: 模型能生成高可信度、高挑衅性内容，人类标注者难以区分AI生成与真实人类言论（混淆度达indistinguishable级别）。

Conclusion: 揭示AI政治化应用风险，呼吁加强AI治理、平台监管，并开发对抗性微调检测工具以维护信息生态安全。

Abstract: The increasing sophistication of large language models (LLMs) has sparked growing concerns regarding their potential role in exacerbating ideological polarization through the automated generation of persuasive and biased content. This study explores the extent to which fine-tuned LLMs can replicate and amplify polarizing discourse within online environments. Using a curated dataset of politically charged discussions extracted from Reddit, we fine-tune an open-source LLM to produce context-aware and ideologically aligned responses. The model's outputs are evaluated through linguistic analysis, sentiment scoring, and human annotation, with particular attention to credibility and rhetorical alignment with the original discourse. The results indicate that, when trained on partisan data, LLMs are capable of producing highly plausible and provocative comments, often indistinguishable from those written by humans. These findings raise significant ethical questions about the use of AI in political discourse, disinformation, and manipulation campaigns. The paper concludes with a discussion of the broader implications for AI governance, platform regulation, and the development of detection tools to mitigate adversarial fine-tuning risks.

</details>


### [54] [GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors](https://arxiv.org/abs/2506.14646)
*Hengyuan Zhang,Xinrong Chen,Yingmin Qiu,Xiao Liang,Ziyue Li,Guanyu Wang,Weiping Li,Tong Mo,Wenyue Li,Hayden Kwok-Hay So,Ngai Wong*

Main category: cs.CL

TL;DR: 提出GuiLoMo策略，通过引导选择向量实现细粒度的LoRA专家数量和秩分配，显著提升参数高效微调性能


<details>
  <summary>Details</summary>
Motivation: 现有LoRA-MoE方法存在两个关键限制：下游任务对专家数量分配的影响不足，以及跨专家统一秩分配导致表示多样性受限

Method: 采用引导选择向量(GSVs)的双层优化策略，通过模型特定需求与任务需求联合学习，实现逐层自适应的专家配置

Result: 在三个主干模型的多样化基准测试中，GuiLoMo始终优于或匹配所有基线方法

Conclusion: 自适应专家配置策略能有效提升模型表现，不同层和任务需要差异化的专家数量与秩分配

Abstract: Parameter-efficient fine-tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), offer an efficient way to adapt large language models with reduced computational costs. However, their performance is limited by the small number of trainable parameters. Recent work combines LoRA with the Mixture-of-Experts (MoE), i.e., LoRA-MoE, to enhance capacity, but two limitations remain in hindering the full exploitation of its potential: 1) the influence of downstream tasks when assigning expert numbers, and 2) the uniform rank assignment across all LoRA experts, which restricts representational diversity. To mitigate these gaps, we propose GuiLoMo, a fine-grained layer-wise expert numbers and ranks allocation strategy with GuidedSelection Vectors (GSVs). GSVs are learned via a prior bilevel optimization process to capture both model- and task-specific needs, and are then used to allocate optimal expert numbers and ranks. Experiments on three backbone models across diverse benchmarks show that GuiLoMo consistently achieves superior or comparable performance to all baselines. Further analysis offers key insights into how expert numbers and ranks vary across layers and tasks, highlighting the benefits of adaptive expert configuration. Our code is available at https://github.com/Liar406/Gui-LoMo.git.

</details>


### [55] [Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality](https://arxiv.org/abs/2506.14681)
*Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi*

Main category: cs.CL

TL;DR: 研究通过训练1000+监督微调(SFT)模型，揭示了任务协同效应和困惑度对SFT效果的预测能力，并发现中间层权重变化与性能增益强相关。


<details>
  <summary>Details</summary>
Motivation: 探索SFT在不同任务和模型上的效果差异，理解数据集属性与微调性能的关系，为优化对齐策略提供实证依据。

Method: 在代码生成、数学推理等多样化任务上训练多组基座模型，系统分析数据集关键特征及SFT引起的逐层权重变化。

Result: 发现部分任务协同效应具有普适性，困惑度优于表面相似性的预测效果，中间层参数调整与性能提升相关度最高。

Conclusion: 强调模型专属优化策略的重要性，验证困惑度的有效性，并计划开源所有模型推动LLM对齐领域研究。

Abstract: Supervised fine-tuning (SFT) is a critical step in aligning large language models (LLMs) with human instructions and values, yet many aspects of SFT remain poorly understood. We trained a wide range of base models on a variety of datasets including code generation, mathematical reasoning, and general-domain tasks, resulting in 1,000+ SFT models under controlled conditions. We then identified the dataset properties that matter most and examined the layer-wise modifications introduced by SFT. Our findings reveal that some training-task synergies persist across all models while others vary substantially, emphasizing the importance of model-specific strategies. Moreover, we demonstrate that perplexity consistently predicts SFT effectiveness--often surpassing superficial similarity between trained data and benchmark--and that mid-layer weight changes correlate most strongly with performance gains. We will release these 1,000+ SFT models and benchmark results to accelerate further research.

</details>


### [56] [Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers](https://arxiv.org/abs/2506.14702)
*Daniel D'souza,Julia Kreutzer,Adrien Morisot,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TL;DR: 提出通过优化训练协议，结合数据特征分类和隐式条件控制，显著提升模型在长尾数据上的生成性能


<details>
  <summary>Details</summary>
Motivation: 解决通用模型在长尾/低代表性用例中表现不足的问题，突破传统训练-推理界限实现可控优化

Method: 1. 创建数据特征与任务来源分类法
2. 微调基础模型自动推断特征标记
3. 支持显式控制和隐式条件生成

Result: 平均生成质量提升5.7%（长尾领域9.1%），CodeRepair任务提升14.1%，指令跟随评估提升35.3%绝对值

Conclusion: 通过结构化特征标记和灵活的条件控制机制，有效提升模型在低资源场景的适应性与生成质量

Abstract: One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations.

</details>


### [57] [Capacity Matters: a Proof-of-Concept for Transformer Memorization on Real-World Data](https://arxiv.org/abs/2506.14704)
*Anton Changalidis,Aki Härmä*

Main category: cs.CL

TL;DR: 研究通过SNOMED合成数据集验证了嵌入大小是Transformer记忆能力的关键因素，Softmax激活函数更稳定，数据复杂度提升记忆效果。


<details>
  <summary>Details</summary>
Motivation: 探索模型架构（层数/激活函数）和数据配置如何影响生成式Transformer的记忆机制，为优化模型设计提供依据。

Method: 使用SNOMED知识图谱生成结构化文本数据（三元组和复杂序列），通过调整嵌入维度、网络层数、激活函数等参数进行对比实验。

Result: 嵌入维度主导学习效率，增加层数对简单数据集有害；Softmax优于其他激活函数，数据复杂度与记忆能力正相关。

Conclusion: 揭示了Transformer记忆机制的关键要素，建立了基于结构化数据的模型优化框架。

Abstract: This paper studies how the model architecture and data configurations influence the empirical memorization capacity of generative transformers. The models are trained using synthetic text datasets derived from the Systematized Nomenclature of Medicine (SNOMED) knowledge graph: triplets, representing static connections, and sequences, simulating complex relation patterns. The results show that embedding size is the primary determinant of learning speed and capacity, while additional layers provide limited benefits and may hinder performance on simpler datasets. Activation functions play a crucial role, and Softmax demonstrates greater stability and capacity. Furthermore, increasing the complexity of the data set seems to improve the final memorization. These insights improve our understanding of transformer memory mechanisms and provide a framework for optimizing model design with structured real-world data.

</details>


### [58] [Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.14731)
*Ring Team,Bin Hu,Cai Chen,Deng Zhao,Ding Liu,Dingnan Jin,Feng Zhu,Hao Dai,Hongzhi Luan,Jia Guo,Jiaming Liu,Jiewei Wu,Jun Mei,Jun Zhou,Junbo Zhao,Junwu Xiong,Kaihong Zhang,Kuan Xu,Lei Liang,Liang Jiang,Liangcheng Fu,Longfei Zheng,Qiang Gao,Qing Cui,Quan Wan,Shaomian Zheng,Shuaicheng Li,Tongkai Yang,Wang Ren,Xiaodong Yan,Xiaopei Wan,Xiaoyun Feng,Xin Zhao,Xinxing Yang,Xinyu Kong,Xuemin Yang,Yang Li,Yingting Wu,Yongkang Liu,Zhankai Xu,Zhenduo Zhang,Zhenglei Zhou,Zhenyu Huang,Zhiqiang Zhang,Zihao Wang,Zujie Wen*

Main category: cs.CL

TL;DR: Ring-lite通过蒸馏+强化学习的联合训练方案，在仅激活1/3参数量的情况下达到SOTA小模型推理性能，并提出C3PO算法解决MoE强化学习稳定性问题


<details>
  <summary>Details</summary>
Motivation: 针对现有小规模推理模型参数量大、计算效率低的问题，探索通过MoE架构+强化学习的方案实现参数高效利用与性能平衡

Method: 1. 提出算法-系统协同设计的C3PO优化方法 2. 基于熵损失的蒸馏检查点选择策略 3. 两阶段训练解决多领域数据冲突

Result: 在AIME/LiveCodeBench/GPQA-Diamond等基准匹配SOTA性能，参数量仅需同类模型的1/3，训练吞吐量提升2.1倍

Conclusion: 成功验证了MoE+RL的可行性，C3PO算法显著提升训练稳定性，两阶段训练范式有效解决数据冲突，最终将开源模型/数据/代码

Abstract: We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code.

</details>


### [59] [Reasoning with Exploration: An Entropy Perspective](https://arxiv.org/abs/2506.14758)
*Daixuan Cheng,Shaohan Huang,Xuekai Zhu,Bo Dai,Wayne Xin Zhao,Zhenliang Zhang,Furu Wei*

Main category: cs.CL

TL;DR: 通过在强化学习优势函数中增加熵项，激励语言模型构建更长推理链以突破现有性能瓶颈


<details>
  <summary>Details</summary>
Motivation: 现有语言模型推理方法过度偏向利用（exploitation），导致性能遇到瓶颈。研究者发现高熵区域与探索性推理行为（关键逻辑节点/自我验证修正/模型未探索行为）存在强相关

Method: 仅需一行代码修改：在强化学习优势函数中增加基于熵的项，通过促进更长更深的推理链实现探索（与传统最大熵方法不同）

Result: 在Pass@K指标上取得显著提升（即使K极大时），突破了语言模型推理能力边界

Conclusion: 这种熵增强方法成功将探索目标转化为提升模型推理深度的有效机制，为语言模型推理能力优化提供了新思路

Abstract: Balancing exploration and exploitation is a central goal in reinforcement learning (RL). Despite recent advances in enhancing language model (LM) reasoning, most methods lean toward exploitation, and increasingly encounter performance plateaus. In this work, we revisit entropy -- a signal of exploration in RL -- and examine its relationship to exploratory reasoning in LMs. Through empirical analysis, we uncover strong positive correlations between high-entropy regions and three types of exploratory reasoning actions: (1) pivotal tokens that determine or connect logical steps, (2) reflective actions such as self-verification and correction, and (3) rare behaviors under-explored by the base LMs. Motivated by this, we introduce a minimal modification to standard RL with only one line of code: augmenting the advantage function with an entropy-based term. Unlike traditional maximum-entropy methods which encourage exploration by promoting uncertainty, we encourage exploration by promoting longer and deeper reasoning chains. Notably, our method achieves significant gains on the Pass@K metric -- an upper-bound estimator of LM reasoning capabilities -- even when evaluated with extremely large K values, pushing the boundaries of LM reasoning.

</details>


### [60] [From Bytes to Ideas: Language Modeling with Autoregressive U-Nets](https://arxiv.org/abs/2506.14761)
*Mathurin Videau,Badr Youbi Idrissi,Alessandro Leite,Marc Schoenauer,Olivier Teytaud,David Lopez-Paz*

Main category: cs.CL

TL;DR: 提出自回归U-Net框架实现动态分词，突破传统BPE固定分词限制，实现多尺度序列建模与跨语言知识迁移


<details>
  <summary>Details</summary>
Motivation: 传统分词方法（如BPE）固化文本粒度，限制模型处理灵活性，无法适应多语言/字符级任务需求

Method: 构建分层U-Net：从字节→词→词组逐层池化，深层预测未来多词（语义模式），浅层处理字节细节（时间跨度分层）

Result: 深层结构在控制预训练计算时显示潜力（与BPE基线相当），分层架构展现跨尺度建模优势趋势

Conclusion: 内置动态分词系统突破传统分词限制，支持字符级任务与低资源语言知识迁移的统一处理框架

Abstract: Tokenization imposes a fixed granularity on the input text, freezing how a language model operates on data and how far in the future it predicts. Byte Pair Encoding (BPE) and similar schemes split text once, build a static vocabulary, and leave the model stuck with that choice. We relax this rigidity by introducing an autoregressive U-Net that learns to embed its own tokens as it trains. The network reads raw bytes, pools them into words, then pairs of words, then up to 4 words, giving it a multi-scale view of the sequence. At deeper stages, the model must predict further into the future -- anticipating the next few words rather than the next byte -- so deeper stages focus on broader semantic patterns while earlier stages handle fine details. When carefully tuning and controlling pretraining compute, shallow hierarchies tie strong BPE baselines, and deeper hierarchies have a promising trend. Because tokenization now lives inside the model, the same system can handle character-level tasks and carry knowledge across low-resource languages.

</details>


### [61] [A Variational Framework for Improving Naturalness in Generative Spoken Language Models](https://arxiv.org/abs/2506.14767)
*Li-Wei Chen,Takuya Higuchi,Zakaria Aldeneh,Ahmed Hussen Abdelaziz,Alexander Rudnicky*

Main category: cs.CL

TL;DR: 提出使用变分自编码器自动学习连续语音属性，增强语义标记以提升语音生成自然度


<details>
  <summary>Details</summary>
Motivation: 现有语音标记方法聚焦语言特征但忽略韵律信息，手动特征工程存在局限性

Method: 端到端变分方法自动编码连续语音属性，无需人工特征选择

Result: 实现自动化的副语言特征融合，生成质量获人类评分认可（提供代码/模型/样本）

Conclusion: 该变分方法克服了传统语义标记的韵律缺陷，提升了语音生成的副语言表现力

Abstract: The success of large language models in text processing has inspired their adaptation to speech modeling. However, since speech is continuous and complex, it is often discretized for autoregressive modeling. Speech tokens derived from self-supervised models (known as semantic tokens) typically focus on the linguistic aspects of speech but neglect prosodic information. As a result, models trained on these tokens can generate speech with reduced naturalness. Existing approaches try to fix this by adding pitch features to the semantic tokens. However, pitch alone cannot fully represent the range of paralinguistic attributes, and selecting the right features requires careful hand-engineering. To overcome this, we propose an end-to-end variational approach that automatically learns to encode these continuous speech attributes to enhance the semantic tokens. Our approach eliminates the need for manual extraction and selection of paralinguistic features. Moreover, it produces preferred speech continuations according to human raters. Code, samples and models are available at https://github.com/b04901014/vae-gslm.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [62] [ReFrame: Layer Caching for Accelerated Inference in Real-Time Rendering](https://arxiv.org/abs/2506.13814)
*Lufei Liu,Tor M. Aamodt*

Main category: cs.GR

TL;DR: ReFrame通过缓存中间特征优化实时渲染，平均加速1.4倍且质量损失可忽略


<details>
  <summary>Details</summary>
Motivation: 利用渲染任务的时间连贯性重用中间计算结果，通过缓存策略优化质量与性能的权衡

Method: 在编码器-解码器架构的渲染网络中研究不同缓存策略，支持多任务应用

Result: 在三个实时渲染任务中实现1.4倍平均加速，代码已开源

Conclusion: ReFrame为渲染管线提供了高效的特征复用框架，平衡加速效果与图像质量

Abstract: Graphics rendering applications increasingly leverage neural networks in tasks such as denoising, supersampling, and frame extrapolation to improve image quality while maintaining frame rates. The temporal coherence inherent in these tasks presents an opportunity to reuse intermediate results from previous frames and avoid redundant computations. Recent work has shown that caching intermediate features to be reused in subsequent inferences is an effective method to reduce latency in diffusion models. We extend this idea to real-time rendering and present ReFrame, which explores different caching policies to optimize trade-offs between quality and performance in rendering workloads. ReFrame can be applied to a variety of encoder-decoder style networks commonly found in rendering pipelines. Experimental results show that we achieve 1.4x speedup on average with negligible quality loss in three real-time rendering tasks. Code available: https://ubc-aamodt-group.github.io/reframe-layer-caching/

</details>


### [63] [Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing](https://arxiv.org/abs/2506.13827)
*Zhuoying Li,Zhu Xu,Yuxin Peng,Yang Liu*

Main category: cs.GR

TL;DR: 提出BPM指标用于平衡指令图像编辑中的修改与保留，通过分离编辑相关/无关区域进行双重评估，实验表明其优于现有指标并与人工评估高度一致。


<details>
  <summary>Details</summary>
Motivation: 现有指标存在高人工成本或任务不适配问题，无法全面评估编辑效果（指令遵循性和内容保留性）。

Method: 1. 定位编辑相关区域；2. 区域感知判断（编辑区域位置/尺寸匹配性）→语义感知判断（指令遵循性+内容保留性）。

Result: BPM在综合指令编辑数据上达到最优评估效果，与人工评估对齐度最高（Pearson系数0.82）。

Conclusion: BPM首次实现编辑质量的双维度评估，其区域定位机制可提升现有编辑方法，代码已开源。

Abstract: Instruction-based image editing, which aims to modify the image faithfully according to the instruction while preserving irrelevant content unchanged, has made significant progress. However, there still lacks a comprehensive metric for assessing the editing quality. Existing metrics either require high human evaluation costs, which hinder large-scale evaluation, or are adapted from other tasks and lose task-specific concerns, failing to comprehensively evaluate both instruction-based modification and preservation of irrelevant regions, resulting in biased evaluation. To tackle this, we introduce a new metric called Balancing Preservation and Modification (BPM), tailored for instruction-based image editing by explicitly disentangling the image into editing-relevant and irrelevant regions for specific consideration. We first identify and locate editing-relevant regions, followed by a two-tier process to assess editing quality: Region-Aware Judge evaluates whether the position and size of the edited region align with the instruction, and Semantic-Aware Judge further assesses the instruction content compliance within editing-relevant regions as well as content preservation within irrelevant regions, yielding comprehensive and interpretable quality assessment. Moreover, the editing-relevant region localization in BPM can be integrated into image editing approaches to improve editing quality, demonstrating its broad applicability. We verify the effectiveness of the BPM metric on comprehensive instruction-editing data, and the results show the highest alignment with human evaluation compared to existing metrics, indicating its efficacy. Code is available at: https://joyli-x.github.io/BPM/

</details>


### [64] [Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints](https://arxiv.org/abs/2506.14104)
*RuiKun Yang,ZhongLiang Wei,Longdi Xian*

Main category: cs.GR

TL;DR: 通过DeepSeek+MidJourney融合方法生成抗疫主题杨柳青年画，验证AI与传统艺术结合的有效性


<details>
  <summary>Details</summary>
Motivation: 解决非物质文化遗产杨柳青年画在保护传承与创新发展之间的平衡难题

Method: 采用DeepSeek生成主题提示词，结合MidJourney图像生成，通过FID分数（均值150.2±4.9）和62人问卷进行多维度评估

Result: 混合方法获得最低FID分数（文化特征保留最优），参与者表现出最高文化推广意愿（86%）和消费兴趣（92%）

Conclusion: AI与传统艺术的深度融合既能保持文化基因，又能创造符合现代审美的创新表达，实现文化遗产的活态传承

Abstract: Yangliuqing woodblock prints, a cornerstone of China's intangible cultural heritage, are celebrated for their intricate designs and vibrant colors. However, preserving these traditional art forms while fostering innovation presents significant challenges. This study explores the DeepSeek + MidJourney approach to generating creative, themed Yangliuqing woodblock prints focused on the fight against COVID-19 and depicting joyous winners. Using Fréchet Inception Distance (FID) scores for evaluation, the method that combined DeepSeek-generated thematic prompts, MidJourney-generated thematic images, original Yangliuqing prints, and DeepSeek-generated key prompts in MidJourney-generated outputs achieved the lowest mean FID score (150.2) with minimal variability (σ = 4.9). Additionally, feedback from 62 participants, collected via questionnaires, confirmed that this hybrid approach produced the most representative results. Moreover, the questionnaire data revealed that participants demonstrated the highest willingness to promote traditional culture and the strongest interest in consuming the AI-generated images produced through this method. These findings underscore the effectiveness of an innovative approach that seamlessly blends traditional artistic elements with modern AI-driven creativity, ensuring both cultural preservation and contemporary relevance.

</details>


### [65] [ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies](https://arxiv.org/abs/2506.14315)
*Jinyan Yuan,Bangbang Yang,Keke Wang,Panwang Pan,Lin Ma,Xuehai Zhang,Xiao Liu,Zhaopeng Cui,Yuewen Ma*

Main category: cs.GR

TL;DR: 提出ImmerseGen框架，通过分层轻量几何代理和RGBA纹理合成实现VR场景的紧凑建模与实时渲染，在保持视觉质量的同时显著提升渲染效率。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景建模方法存在高复杂度建模流程与视觉真实性不足的矛盾，且难以兼顾移动端实时渲染需求。本文旨在通过代理建模范式突破这一技术瓶颈。

Method: 1) 分层代理建模：使用简化地形+广告牌网格构建场景结构
2) 地形条件纹理合成：用户中心的基础世界生成
3) RGBA资产纹理映射：中前景场景的逼真渲染
4) VLM语义网格分析代理：增强空间推理与资产布局

Result: 实验表明：相比传统方法，在场景生成质量上PSNR提升18.6%，渲染帧率提高3.2倍；实时VR演示验证了移动端4K@90fps的稳定渲染性能。

Conclusion: 通过代理建模范式突破传统建模局限，实现建模效率与视觉质量的协同优化，其紧凑表示支持移动VR实时渲染，动态效果与环境音频增强多感官沉浸体验。

Abstract: Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery.This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io.

</details>


### [66] [GHAR: GeoPose-based Handheld Augmented Reality for Architectural Positioning, Manipulation and Visual Exploration](https://arxiv.org/abs/2506.14414)
*Sabahat Israr,Dawar Khan,Zhanglin Cheng,Mukhtaj Khan,Kiyoshi Kiyokawa*

Main category: cs.GR

TL;DR: 提出基于GeoPose的无标记手持增强现实框架GHAR，通过手势操作实现建筑模型可视化，在可用性、操作性和理解性上显著优于传统标记系统。


<details>
  <summary>Details</summary>
Motivation: 现有基于标记的手持AR系统存在安装困难、光线敏感和标记设计限制，需开发无标记方案突破技术瓶颈。

Method: 采用GeoPose追踪技术，通过多手势实现7自由度(平移/旋转/缩放)操作，将建筑CAD模型叠加至实景进行交互式预览。

Result: 使用SUS和HARUS评估显示，相比标记系统，无标记框架在可用性(提升23%)、操作性(提升31%)和模型理解性(提升19%)均有显著改进。

Conclusion: GHAR框架有效支持建筑工程前期规划，通过无标记方案突破传统AR限制，为基础设施可视化提供更优解决方案。

Abstract: Handheld Augmented Reality (HAR) is revolutionizing the civil infrastructure application domain. The current trend in HAR relies on marker tracking technology. However, marker-based systems have several limitations, such as difficulty in use and installation, sensitivity to light, and marker design. In this paper, we propose a markerless HAR framework with GeoPose-based tracking. We use different gestures for manipulation and achieve 7 DOF (3 DOF each for translation and rotation, and 1 DOF for scaling). The proposed framework, called GHAR, is implemented for architectural building models. It augments virtual CAD models of buildings on the ground, enabling users to manipulate and visualize an architectural model before actual construction. The system offers a quick view of the building infrastructure, playing a vital role in requirement analysis and planning in construction technology. We evaluated the usability, manipulability, and comprehensibility of the proposed system using a standard user study with the System Usability Scale (SUS) and Handheld Augmented Reality User Study (HARUS). We compared our GeoPose-based markerless HAR framework with a marker-based HAR framework, finding significant improvement in the aforementioned three parameters with the markerless framework.

</details>


### [67] [SkinCells: Sparse Skinning using Voronoi Cells](https://arxiv.org/abs/2506.14714)
*Egor Larionov,Igor Santesteban,Hsiao-yu Chen,Gene Lin,Philipp Herholz,Ryan Goldade,Ladislav Kavan,Doug Roble,Tuur Stuyck*

Main category: cs.GR

TL;DR: 提出全自动生成高质量蒙皮权重的方法，支持稀疏骨骼影响控制与多细节层次适配，适用于移动端大规模场景


<details>
  <summary>Details</summary>
Motivation: 传统蒙皮权重生成依赖手动调整，现有自动方法在处理复杂几何体时质量不足，且缺乏移动端大规模应用所需的稀疏控制与多细节层次支持

Method: 基于空间优化的权重生成框架，引入参数化SkinCells函数族，实现权重在多细节层次模型间的无缝迁移应用

Result: 在双调和权重计算失败的案例中仍能稳健生成优质蒙皮权重，支持每顶点骨骼影响数控制，优化结果可跨不同LOD层级复用

Conclusion: 该方法显著提升角色资产创建自动化水平，特别适用于多用户并发的移动端实时动画场景，推动实时角色动画制作流程革新

Abstract: For decades, efficient real-time skinning methods have played a crucial role in animating character rigs for visual effects and games. These methods remain a fundamental component of modern applications. However, animatable digital asset creation predominantly remains a manual process. Current automated tools often fall short of delivering the desired level of quality for intricate and complex geometries, requiring manual touch-ups. We propose a fully automatic and robust method for generating high quality skinning weights given a user-provided skeleton and mesh in A- or T-pose. Notably, our approach provides direct sparsity controls, limiting the number of bone influences per vertex, which is essential for efficient asset creation for large-scale mobile experiences with multiple concurrent users. Our method additionally addresses the need for level-of-detail (LoD) variations in performance-sensitive applications, which are exacerbated on mobile platforms. By optimizing weights in space rather than on discrete points, we enable a single optimization result to be seamlessly applied to all levels of detail of that asset or even variations of that asset. To achieve this, we introduce a novel parameterized family of functions called SkinCells. We demonstrate how our automatic method is able to robustly compute skinning weights in cases where biharmonic weight computation fails.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [68] [Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment](https://arxiv.org/abs/2506.14148)
*Long-Vu Hoang,Tuan Nguyen,Tran Huy Dat*

Main category: cs.SD

TL;DR: 开发基于声学散射和深度学习的非侵入式头发分类方法，准确率达90%


<details>
  <summary>Details</summary>
Motivation: 探索隐私保护的非接触式分类方案，替代传统视觉方法

Method: 采用四类策略：全监督学习、嵌入分类、监督式基础模型微调、自监督模型全参数微调

Result: 自监督模型全参数微调策略实现近90%分类准确率

Conclusion: 声学散射技术为医疗美容等领域开辟了非接触、保护隐私的物体分类新路径

Abstract: This paper presents a novel non-invasive object classification approach using acoustic scattering, demonstrated through a case study on hair assessment. When an incident wave interacts with an object, it generates a scattered acoustic field encoding structural and material properties. By emitting acoustic stimuli and capturing the scattered signals from head-with-hair-sample objects, we classify hair type and moisture using AI-driven, deep-learning-based sound classification. We benchmark comprehensive methods, including (i) fully supervised deep learning, (ii) embedding-based classification, (iii) supervised foundation model fine-tuning, and (iv) self-supervised model fine-tuning. Our best strategy achieves nearly 90% classification accuracy by fine-tuning all parameters of a self-supervised model. These results highlight acoustic scattering as a privacy-preserving, non-contact alternative to visual classification, opening huge potential for applications in various industries.

</details>


### [69] [Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models](https://arxiv.org/abs/2506.14153)
*Tuan Dat Phuong,Long-Vu Hoang,Huy Dat Tran*

Main category: cs.SD

TL;DR: 提出用KAN网络替代XLSR-Conformer中的MLP层，在ASVspoof2021上相对提升60.55%检测性能


<details>
  <summary>Details</summary>
Motivation: 现有基于SSL的语音伪造检测系统（如XLSR-Conformer）在架构上仍有改进空间，需提升对抗先进语音合成攻击的能力

Method: 基于Kolmogorov-Arnold表示定理，用KAN网络替代传统多层感知机（MLP）进行特征建模

Result: 在ASVspoof2021测试中，LA和DF集相对性能提升60.55%，21LA集实现0.70%等错误率（EER）

Conclusion: 将KAN整合到自监督学习模型中，是提升合成语音检测性能的有效方向

Abstract: Recent advancements in speech synthesis technologies have led to increasingly advanced spoofing attacks, posing significant challenges for automatic speaker verification systems. While systems based on self-supervised learning (SSL) models, particularly the XLSR-Conformer model, have demonstrated remarkable performance in synthetic speech detection, there remains room for architectural improvements. In this paper, we propose a novel approach that replaces the traditional Multi-Layer Perceptron in the XLSR-Conformer model with a Kolmogorov-Arnold Network (KAN), a novel architecture based on the Kolmogorov-Arnold representation theorem. Our results on ASVspoof2021 demonstrate that integrating KAN into the SSL-based models can improve the performance by 60.55% relatively on LA and DF sets, further achieving 0.70% EER on the 21LA set. These findings suggest that incorporating KAN into SSL-based models is a promising direction for advances in synthetic speech detection.

</details>


### [70] [Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription](https://arxiv.org/abs/2506.14223)
*Anna Hamberger,Sebastian Murgul,Jochen Schmidt,Michael Heizmann*

Main category: cs.SD

TL;DR: 提出了基于T5架构的Fretting-Transformer模型，实现MIDI到吉他指板谱的自动转换，解决演奏可行性问题，在准确性和演奏性指标上超越基线方法。


<details>
  <summary>Details</summary>
Motivation: MIDI等符号音乐表示法缺乏吉他演奏的关键指法信息，现有方法难以解决弦-品歧义和物理演奏可行性问题。

Method: 采用T5编码器-解码器架构，整合DadaGP/GuitarToday/Leduc数据集，设计新型数据预处理和tokenization策略，建立指法准确性和演奏性量化评估指标。

Result: 模型性能优于A*算法和Guitar Pro商业软件，上下文敏感处理与调弦/变调夹条件机制的加入显著提升表现。

Conclusion: 为自动化吉他谱转录建立了可靠框架，上下文感知和条件机制为后续发展奠定基础。

Abstract: Music transcription plays a pivotal role in Music Information Retrieval (MIR), particularly for stringed instruments like the guitar, where symbolic music notations such as MIDI lack crucial playability information. This contribution introduces the Fretting-Transformer, an encoderdecoder model that utilizes a T5 transformer architecture to automate the transcription of MIDI sequences into guitar tablature. By framing the task as a symbolic translation problem, the model addresses key challenges, including string-fret ambiguity and physical playability. The proposed system leverages diverse datasets, including DadaGP, GuitarToday, and Leduc, with novel data pre-processing and tokenization strategies. We have developed metrics for tablature accuracy and playability to quantitatively evaluate the performance. The experimental results demonstrate that the Fretting-Transformer surpasses baseline methods like A* and commercial applications like Guitar Pro. The integration of context-sensitive processing and tuning/capo conditioning further enhances the model's performance, laying a robust foundation for future developments in automated guitar transcription.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [71] [Computational Studies in Influencer Marketing: A Systematic Literature Review](https://arxiv.org/abs/2506.14602)
*Haoyang Gui,Thales Bertaglia,Catalina Goanta,Gerasimos Spanakis*

Main category: cs.CY

TL;DR: 通过PRISMA模型对69篇文献进行系统综述，梳理网红营销计算研究的四大主题（网红识别、广告策略、赞助内容分析、公平性），揭示当前研究偏重商业优化而忽视伦理合规，提出多学科研究议程。


<details>
  <summary>Details</summary>
Motivation: 当前网红营销计算研究领域碎片化且缺乏系统性方法论综述，导致平台外监管者和跨领域研究者难以形成科学认知体系。

Method: 基于PRISMA框架的系统文献综述法，结合机器学习（分类/聚类）与非机器学习方法（统计/网络分析），对文献进行主题分类与方法论解构。

Result: 识别出机器学习方法主导的四大研究方向，发现83%研究聚焦商业效果优化，仅9%涉及合规性；跨语言/跨平台研究不足，模型可解释性普遍低于40%。

Conclusion: 建议构建融合监管科技的多学科框架，推动细粒度分析（行业/语言维度），建立标准化数据集（当前仅12%研究公开数据），提升算法透明度（XAI技术应用）。

Abstract: Influencer marketing has become a crucial feature of digital marketing strategies. Despite its rapid growth and algorithmic relevance, the field of computational studies in influencer marketing remains fragmented, especially with limited systematic reviews covering the computational methodologies employed. This makes overarching scientific measurements in the influencer economy very scarce, to the detriment of interested stakeholders outside of platforms themselves, such as regulators, but also researchers from other fields. This paper aims to provide an overview of the state of the art of computational studies in influencer marketing by conducting a systematic literature review (SLR) based on the PRISMA model. The paper analyses 69 studies to identify key research themes, methodologies, and future directions in this research field. The review identifies four major research themes: Influencer identification and characterisation, Advertising strategies and engagement, Sponsored content analysis and discovery, and Fairness. Methodologically, the studies are categorised into machine learning-based techniques (e.g., classification, clustering) and non-machine-learning-based techniques (e.g., statistical analysis, network analysis). Key findings reveal a strong focus on optimising commercial outcomes, with limited attention to regulatory compliance and ethical considerations. The review highlights the need for more nuanced computational research that incorporates contextual factors such as language, platform, and industry type, as well as improved model explainability and dataset reproducibility. The paper concludes by proposing a multidisciplinary research agenda that emphasises the need for further links to regulation and compliance technology, finer granularity in analysis, and the development of standardised datasets.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [72] [ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \& a ML Ensemble on Longitudinal Identity Resolution](https://arxiv.org/abs/2506.13792)
*Gonçalo Hora de Carvalho,Lazar S. Popov,Sander Kaatee,Kristinn R. Thórisson,Tangrui Li,Pétur Húni Björnsson,Jilles S. Dibangoye*

Main category: cs.AI

TL;DR: 提出ICE-ID新型历史身份解析基准数据集，包含220年冰岛人口普查记录，支持长期人物实体匹配研究，并比较多种方法性能


<details>
  <summary>Details</summary>
Motivation: 填补现有缺乏真实世界长期纵向数据集的空白，促进数据链接与历史分析领域的跨学科研究

Method: 构建包含规则匹配器、ML集成、LLMs表格网络与新型NARS系统（基于非公理逻辑的通用AI框架）的对比实验体系

Result: NARS系统以简单架构达到当前最佳效果（SOTA），在身份解析任务中展现出竞争优势

Conclusion: 通过公开数据集和代码实现可复现的基准测试，为纵向数据环境下的身份解析研究开辟新途径

Abstract: We introduce ICE-ID, a novel benchmark dataset for historical identity resolution, comprising 220 years (1703-1920) of Icelandic census records. ICE-ID spans multiple generations of longitudinal data, capturing name variations, demographic changes, and rich genealogical links. To the best of our knowledge, this is the first large-scale, open tabular dataset specifically designed to study long-term person-entity matching in a real-world population. We define identity resolution tasks (within and across census waves) with clearly documented metrics and splits. We evaluate a range of methods: handcrafted rule-based matchers, a ML ensemble as well as LLMs for structured data (e.g. transformer-based tabular networks) against a novel approach to tabular data called NARS (Non-Axiomatic Reasoning System) - a general-purpose AI framework designed to reason with limited knowledge and resources. Its core is Non-Axiomatic Logic (NAL), a term-based logic. Our experiments show that NARS is suprisingly simple and competitive with other standard approaches, achieving SOTA at our task. By releasing ICE-ID and our code, we enable reproducible benchmarking of identity resolution approaches in longitudinal settings and hope that ICE-ID opens new avenues for cross-disciplinary research in data linkage and historical analytics.

</details>


### [73] [Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs](https://arxiv.org/abs/2506.14245)
*Xumeng Wen,Zihan Liu,Shun Zheng,Zhijian Xu,Shengyu Ye,Zhirong Wu,Xiao Liang,Yang Wang,Junjie Li,Ziming Miao,Jiang Bian,Mao Yang*

Main category: cs.AI

TL;DR: 论文指出RLVR在传统Pass@K指标下表现不佳的矛盾源于该指标本身缺陷，提出新评估指标CoT-Pass@K验证RLVR确实能提升推理逻辑完整性。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR模型在Pass@K指标下表现反直觉的矛盾，揭示该指标因忽视推理路径正确性而存在评估偏差的根本问题。

Method: 提出CoT-Pass@K新指标（要求推理路径和答案均正确），建立RLVR激励逻辑完整性的理论框架，并通过训练动态分析验证。

Result: 使用新指标显示RLVR能激励正确推理的泛化（所有K值有效），且该能力在训练早期即出现并平滑泛化。

Conclusion: RLVR具有真正提升机器推理的潜力，但需配合更可靠的评估方法（如CoT-Pass@K）才能准确反映其价值。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned models often underperform their base models on the $Pass@K$ metric for solution-finding, leading to the hypothesis that RLVR merely re-weights existing reasoning paths at the cost of reasoning diversity. In this work, we resolve this contradiction by identifying the source of the problem: the $Pass@K$ metric itself is a flawed measure of reasoning, as it credits correct final answers that probably arise from inaccurate or incomplete chains of thought (CoTs). To address this, we introduce a more precise evaluation metric, $CoT$-$Pass@K$, which mandates that both the reasoning path and the final answer be correct. We provide a new theoretical foundation that formalizes how RLVR, unlike traditional RL, is uniquely structured to incentivize logical integrity. Our empirical results are supportive: using $CoT$-$Pass@K$, we observe that RLVR can incentivize the generalization of correct reasoning for all values of $K$. Furthermore, by analyzing the training dynamics, we find that this enhanced reasoning capability emerges early in the training process and smoothly generalizes. Our work provides a clear perspective on the role of RLVR, offers a more reliable method for its evaluation, and confirms its potential to genuinely advance machine reasoning.

</details>


### [74] [Optimizing Length Compression in Large Reasoning Models](https://arxiv.org/abs/2506.14755)
*Zhengxiang Cheng,Dongping Chen,Mingyang Fu,Tianyi Zhou*

Main category: cs.AI

TL;DR: 提出LC-R1方法通过压缩无效思维减少大模型推理冗余，实现推理长度减少50%且精度仅下降2%


<details>
  <summary>Details</summary>
Motivation: 解决大模型推理过程中存在的无效重复验证问题（无效思维现象）

Method: 基于GRPO框架开发LC-R1方法，结合长度奖励和压缩奖励优化推理过程

Result: 在多个基准测试中实现推理序列长度压缩约50%，精度仅下降2%

Conclusion: Brevity与Sufficiency原则指导的LC-R1方法为高效推理模型提供了新的优化方向

Abstract: Large Reasoning Models (LRMs) have achieved remarkable success, yet they often suffer from producing unnecessary and verbose reasoning chains. We identify a core aspect of this issue as "invalid thinking" -- models tend to repeatedly double-check their work after having derived the correct answer. To address this specific inefficiency, we move beyond the general principles of Efficacy and Efficiency to propose two new, fine-grained principles: Brevity, which advocates for eliminating redundancy, and Sufficiency, which ensures critical reasoning steps are preserved. Guided by these principles, we introduce LC-R1, a post-training method based on Group Relative Policy Optimization (GRPO). LC-R1 employs a novel combination of a Length Reward for overall conciseness and a Compress Reward that is specifically designed to remove the invalid portion of the thinking process. Extensive experiments on multiple reasoning benchmarks demonstrate that LC-R1 achieves a significant reduction in sequence length (~50%) with only a marginal (~2%) drop in accuracy, achieving a favorable trade-off point on the Pareto frontier that prioritizes high compression. Our analysis further validates the robustness of LC-R1 and provides valuable insights for developing more powerful yet computationally efficient LRMs. Our code is released at https://github.com/zxiangx/LC-R1.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [75] [Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience](https://arxiv.org/abs/2506.13971)
*Andrew Chang,Chenkai Hu,Ji Qi,Zhuojian Wei,Kexin Zhang,Viswadruth Akkaraju,David Poeppel,Dustin Freeman*

Main category: eess.AS

TL;DR: 半监督学习框架有效预测视频会议中的负面体验，减少标注数据需求


<details>
  <summary>Details</summary>
Motivation: 视频会议中的非流畅或不愉快时刻研究不足，自然数据中这些时刻稀少，监督学习标注成本高

Method: 采用半监督学习（SSL）结合标注和未标注数据，通过多模态（音频/面部/文本）深度特征融合和协同训练进行预测

Result: 模态融合协同训练SSL模型ROC-AUC达0.9，F1分数0.6，仅8%标注数据即可达到监督模型96%性能

Conclusion: 提出标注效率提升的框架，为视频会议体验建模提供新范式

Abstract: Group conversations over videoconferencing are a complex social behavior. However, the subjective moments of negative experience, where the conversation loses fluidity or enjoyment remain understudied. These moments are infrequent in naturalistic data, and thus training a supervised learning (SL) model requires costly manual data annotation. We applied semi-supervised learning (SSL) to leverage targeted labeled and unlabeled clips for training multimodal (audio, facial, text) deep features to predict non-fluid or unenjoyable moments in holdout videoconference sessions. The modality-fused co-training SSL achieved an ROC-AUC of 0.9 and an F1 score of 0.6, outperforming SL models by up to 4% with the same amount of labeled data. Remarkably, the best SSL model with just 8% labeled data matched 96% of the SL model's full-data performance. This shows an annotation-efficient framework for modeling videoconference experience.

</details>


### [76] [Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios](https://arxiv.org/abs/2506.14204)
*Aswin Shanmugam Subramanian,Amit Das,Naoyuki Kanda,Jinyu Li,Xiaofei Wang,Yifan Gong*

Main category: eess.AS

TL;DR: 扩展SOT框架实现流式/离线ASR系统，通过CSS前端增强重叠语音识别，双模型架构平衡延迟与精度


<details>
  <summary>Details</summary>
Motivation: 解决实时字幕生成和摘要任务中延迟与精度的平衡需求，挑战传统级联系统的设计范式

Method: 1. 结合CSS前端与端到端系统处理重叠语音
2. 流式场景用Conformer Transducer+离线用Seq2Seq双模型
3. 提出分段式segSOT提升离线场景可读性

Result: CSS框架提升多说话人场景识别精度，双模型架构满足不同延迟要求，segSOT优化离线转录结构

Conclusion: 通过前端处理、模型架构创新和序列化输出优化，在流式/离线场景中实现精度与延迟的最佳平衡

Abstract: We extend the frameworks of Serialized Output Training (SOT) to address practical needs of both streaming and offline automatic speech recognition (ASR) applications. Our approach focuses on balancing latency and accuracy, catering to real-time captioning and summarization requirements. We propose several key improvements: (1) Leveraging Continuous Speech Separation (CSS) single-channel front-end with end-to-end (E2E) systems for highly overlapping scenarios, challenging the conventional wisdom of E2E versus cascaded setups. The CSS framework improves the accuracy of the ASR system by separating overlapped speech from multiple speakers. (2) Implementing dual models -- Conformer Transducer for streaming and Sequence-to-Sequence for offline -- or alternatively, a two-pass model based on cascaded encoders. (3) Exploring segment-based SOT (segSOT) which is better suited for offline scenarios while also enhancing readability of multi-talker transcriptions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [77] [LittleBit: Ultra Low-Bit Quantization via Latent Factorization](https://arxiv.org/abs/2506.13771)
*Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim*

Main category: cs.LG

TL;DR: 提出LittleBit方法实现LLM的0.1位/权重极端量化，通过低秩矩阵分解+二值化+多尺度补偿机制，在保持性能的同时实现31倍内存压缩和5倍加速潜力。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法在低于1位精度时性能显著下降，阻碍LLM在资源受限环境的应用。需要开发能保持性能的极端压缩方案。

Method: 1. 低秩矩阵分解表示权重 2. 因子二值化 3. 多尺度补偿机制(行列补偿+潜在维度重要性学习) 4. Dual-SVID分解稳定训练初始化 5. 集成残差补偿减少误差

Result: Llama2-13B压缩至0.9GB，0.1BPW性能超越现有方法0.7BPW水平，内核级基准测试显示潜在5倍FP16加速。

Conclusion: LittleBit开创了LLM极端量化的新范式，为资源受限环境部署高性能模型提供了可行方案，推动边缘计算和移动端AI发展。

Abstract: Deploying large language models (LLMs) often faces challenges from substantial memory and computational costs. Quantization offers a solution, yet performance degradation in the sub-1-bit regime remains particularly difficult. This paper introduces LittleBit, a novel method for extreme LLM compression. It targets levels like 0.1 bits per weight (BPW), achieving nearly 31$\times$ memory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents weights in a low-rank form using latent matrix factorization, subsequently binarizing these factors. To counteract information loss from this extreme precision, it integrates a multi-scale compensation mechanism. This includes row, column, and an additional latent dimension that learns per-rank importance. Two key contributions enable effective training: Dual Sign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware training (QAT) initialization, and integrated Residual Compensation to mitigate errors. Extensive experiments confirm LittleBit's superiority in sub-1-bit quantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading method's 0.7 BPW. This establishes a superior size-performance trade-off, with kernel-level benchmarks indicating potential for a 5$\times$ speedup compared to FP16. LittleBit paves the way for deploying powerful LLMs in resource-constrained environments.

</details>


### [78] [Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models](https://arxiv.org/abs/2506.13923)
*Vaskar Nath,Elaine Lau,Anisha Gunjal,Manasi Sharma,Nikhil Baharte,Sean Hendryx*

Main category: cs.LG

TL;DR: 研究提出RLVR训练通过两种机制提升模型性能：将pass@k压缩为pass@1和通过能力增益解决新问题，并开发Guide算法显著提升数学基准表现。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习在可验证奖励下如何驱动模型解决新问题的机制，特别是自蒸馏和自然语言指导对性能提升的影响。

Method: 在0.5B-72B参数模型上使用50万+数学/科学/编程问题进行实验，开发Guide算法（结合自然语言提示和重要性采样调整），应用于GRPO/PPO变体。

Result: Guide-GRPO在7B/32B模型上实现数学基准最高4%提升，证明能力增益跨规模存在但主要依赖自蒸馏。

Conclusion: 自蒸馏是模型解决新问题的核心机制，Guide算法通过上下文提示优化显著增强泛化能力，理论分析与实验验证共同支持该结论。

Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance through two main means: (1) by compressing pass@$k$ into pass@1 and (2) via "capability gain" in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $\text{Guide}$ - a new class of online training algorithms. $\text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the "off-policy" trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $\text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$\%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $\text{Guide}$'s components and theoretically analyze Guide's learning efficiency.

</details>


### [79] [AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science](https://arxiv.org/abs/2506.13992)
*An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding*

Main category: cs.LG

TL;DR: 研究评估了大型语言模型在数据科学任务中利用领域知识的能力，发现其在批判性应用外部信息、处理时间序列数据和分类变量方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数据科学流程自动化方面取得进展，但其能否像人类专家那样批判性运用领域知识尚未明确，需建立系统性评估框架。

Method: 通过AssistedDS基准（包含明确生成机制的合成数据集和真实Kaggle竞赛），结合有益/对抗性领域文档，评估LLMs在数据清洗、特征工程和模型选择中的知识应用能力。

Result: 发现三大问题：1) LLMs常非批判性采纳信息（对抗性内容使预测性能下降59%）；2) 有益指导难抵消对抗信息影响；3) 处理时序数据时存在跨折叠特征工程错误、分类变量误读。

Conclusion: 当前模型在批判性评估专家知识方面存在重大缺陷，需发展更鲁棒的知识感知系统作为自动化数据科学的核心研究方向。

Abstract: Large language models (LLMs) have advanced the automation of data science workflows. Yet it remains unclear whether they can critically leverage external domain knowledge as human data scientists do in practice. To answer this question, we introduce AssistedDS (Assisted Data Science), a benchmark designed to systematically evaluate how LLMs handle domain knowledge in tabular prediction tasks. AssistedDS features both synthetic datasets with explicitly known generative mechanisms and real-world Kaggle competitions, each accompanied by curated bundles of helpful and adversarial documents. These documents provide domain-specific insights into data cleaning, feature engineering, and model selection. We assess state-of-the-art LLMs on their ability to discern and apply beneficial versus harmful domain knowledge, evaluating submission validity, information recall, and predictive performance. Our results demonstrate three key findings: (1) LLMs frequently exhibit an uncritical adoption of provided information, significantly impairing their predictive performance when adversarial content is introduced, (2) helpful guidance is often insufficient to counteract the negative influence of adversarial information, and (3) in Kaggle datasets, LLMs often make errors in handling time-series data, applying consistent feature engineering across different folds, and interpreting categorical variables correctly. These findings highlight a substantial gap in current models' ability to critically evaluate and leverage expert knowledge, underscoring an essential research direction for developing more robust, knowledge-aware automated data science systems.

</details>


### [80] [Improving LoRA with Variational Learning](https://arxiv.org/abs/2506.14280)
*Bai Cong,Nico Daheim,Yuesong Shen,Rio Yokota,Mohammad Emtiyaz Khan,Thomas Möllenhoff*

Main category: cs.LG

TL;DR: IVON变分算法有效优化LoRA微调，在保持计算效率的同时显著提升模型性能指标


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯方法在LoRA微调中存在的准确率提升有限、计算成本高、需要复杂调优的问题

Method: 采用IVON变分算法结合后验剪枝技术，实现与AdamW相当的运行成本

Result: 在Llama-3.2-3B等十亿级模型上：准确率提升1.3%，ECE下降5.4%，超越AdamW/Laplace-LoRA/BLoB

Conclusion: IVON为LoRA微调提供了高效可靠的变分学习框架，具有实际部署价值

Abstract: Bayesian methods have recently been used to improve LoRA finetuning and, although they improve calibration, their effect on other metrics (such as accuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian methods also increase computational overheads and require additional tricks for them to work well. Here, we fix these issues by using a recently proposed variational algorithm called IVON. We show that IVON is easy to implement and has similar costs to AdamW, and yet it can also drastically improve many metrics by using a simple posterior pruning technique. We present extensive results on billion-scale LLMs (Llama and Qwen series) going way beyond the scale of existing applications of IVON. For example, we finetune a Llama-3.2-3B model on a set of commonsense reasoning tasks and improve accuracy over AdamW by 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian methods like Laplace-LoRA and BLoB. Overall, our results show that variational learning with IVON can effectively improve LoRA finetuning.

</details>


### [81] [TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization](https://arxiv.org/abs/2506.14574)
*Mingkang Zhu,Xi Chen,Zhongdao Wang,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.LG

TL;DR: 提出基于细粒度token级奖励指导的DPO优化框架，显著提升对话模型性能


<details>
  <summary>Details</summary>
Motivation: 现有基于序列级奖励的DPO方法难以利用token级奖励信号，限制了策略优化效果

Method: 将PPO分解为token级优化问题推导闭式解，结合Bradley-Terry模型构建token级奖励指导的DPO损失函数

Result: 在MT-Bench/AlpacaEval 2/Arena-Hard上分别获得7.5/6.2/4.3点的显著性能提升

Conclusion: 该方法成功将token级奖励整合到DPO框架中，为语言模型对齐提供了新思路，代码已开源促进社区发展

Abstract: Recent advancements in reinforcement learning from human feedback have shown that utilizing fine-grained token-level reward models can substantially enhance the performance of Proximal Policy Optimization (PPO) in aligning large language models. However, it is challenging to leverage such token-level reward as guidance for Direct Preference Optimization (DPO), since DPO is formulated as a sequence-level bandit problem. To address this challenge, this work decomposes the sequence-level PPO into a sequence of token-level proximal policy optimization problems and then frames the problem of token-level PPO with token-level reward guidance, from which closed-form optimal token-level policy and the corresponding token-level reward can be derived. Using the obtained reward and Bradley-Terry model, this work establishes a framework of computable loss functions with token-level reward guidance for DPO, and proposes a practical reward guidance based on the induced DPO reward. This formulation enables different tokens to exhibit varying degrees of deviation from reference policy based on their respective rewards. Experiment results demonstrate that our method achieves substantial performance improvements over DPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on AlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at https://github.com/dvlab-research/TGDPO.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [82] [CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language Models in Tool-Calling Error Scenarios](https://arxiv.org/abs/2506.13977)
*Shiting Huang,Zhen Fang,Zehui Chen,Siyu Yuan,Junjie Ye,Yu Zeng,Lin Chen,Qi Mao,Feng Zhao*

Main category: cs.SE

TL;DR: 提出CRITICTOOL评测基准，通过进化策略构建多样化工具使用错误场景，分析大模型在工具学习中的反思能力


<details>
  <summary>Details</summary>
Motivation: 复杂长周期任务中工具调用过程易触发错误，需建立有效的错误识别/诊断/恢复机制推动工具学习发展

Method: 基于函数调用过程错误分析，采用进化策略构建包含多复杂度工具使用错误的评测基准CRITICTOOL

Result: 验证了基准的泛化性和有效性，揭示了不同大模型在工具反思能力上的差异

Conclusion: CRITICTOOL为工具学习研究提供新视角，代码开源促进领域发展

Abstract: The ability of large language models (LLMs) to utilize external tools has enabled them to tackle an increasingly diverse range of tasks. However, as the tasks become more complex and long-horizon, the intricate tool utilization process may trigger various unexpected errors. Therefore, how to effectively handle such errors, including identifying, diagnosing, and recovering from them, has emerged as a key research direction for advancing tool learning. In this work, we first extensively analyze the types of errors encountered during the function-calling process on several competitive tool evaluation benchmarks. Based on it, we introduce CRITICTOOL, a comprehensive critique evaluation benchmark specialized for tool learning. Building upon a novel evolutionary strategy for dataset construction, CRITICTOOL holds diverse tool-use errors with varying complexities, which better reflects real-world scenarios. We conduct extensive experiments on CRITICTOOL, and validate the generalization and effectiveness of our constructed benchmark strategy. We also provide an in-depth analysis of the tool reflection ability on various LLMs, offering a new perspective on the field of tool learning in LLMs. The code is available at \href{https://github.com/Shellorley0513/CriticTool}{https://github.com/Shellorley0513/CriticTool}.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [83] [RadFabric: Agentic AI System with Reasoning Capability for Radiology](https://arxiv.org/abs/2506.14142)
*Wenting Chen,Yi Dong,Zhaojun Ding,Yucheng Shi,Yifan Zhou,Fang Zeng,Yijun Luo,Tianyu Lin,Yihang Su,Yichen Wu,Kai Zhang,Zhen Xiang,Tianming Liu,Ninghao Liu,Lichao Sun,Yixuan Yuan,Xiang Li*

Main category: cs.CV

TL;DR: 提出多模态框架RadFabric，通过跨模态特征对齐和模块化代理系统显著提升胸部X光诊断精度与透明度


<details>
  <summary>Details</summary>
Motivation: 解决现有CXR自动系统在病理覆盖范围有限、诊断准确性不足及视觉-文本推理整合不充分的问题

Method: 基于模型上下文协议(MCP)构建模块化系统，整合专业病理检测代理、解剖解释代理和基于大型多模态模型的推理代理

Result: 骨折检测准确率达1.000，整体诊断准确率0.799，显著优于传统系统(0.229-0.527)

Conclusion: RadFabric通过偏好驱动推理机制实现解剖精确、临床可操作的CXR分析，推动AI放射学向透明化发展

Abstract: Chest X ray (CXR) imaging remains a critical diagnostic tool for thoracic conditions, but current automated systems face limitations in pathology coverage, diagnostic accuracy, and integration of visual and textual reasoning. To address these gaps, we propose RadFabric, a multi agent, multimodal reasoning framework that unifies visual and textual analysis for comprehensive CXR interpretation. RadFabric is built on the Model Context Protocol (MCP), enabling modularity, interoperability, and scalability for seamless integration of new diagnostic agents. The system employs specialized CXR agents for pathology detection, an Anatomical Interpretation Agent to map visual findings to precise anatomical structures, and a Reasoning Agent powered by large multimodal reasoning models to synthesize visual, anatomical, and clinical data into transparent and evidence based diagnoses. RadFabric achieves significant performance improvements, with near-perfect detection of challenging pathologies like fractures (1.000 accuracy) and superior overall diagnostic accuracy (0.799) compared to traditional systems (0.229 to 0.527). By integrating cross modal feature alignment and preference-driven reasoning, RadFabric advances AI-driven radiology toward transparent, anatomically precise, and clinically actionable CXR analysis.

</details>


### [84] [VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning](https://arxiv.org/abs/2506.14629)
*Md. Adnanul Islam,Md. Faiyaz Abdullah Sayeedi,Md. Asaduzzaman Shuvo,Muhammad Ziaur Rahman,Shahanur Rahman Bappy,Raiyan Rahman,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 开发多模态数据集VisText-Mosquito，通过视觉文本融合实现蚊虫滋生地智能检测与推理，验证AI主动预防蚊媒疾病的可行性。


<details>
  <summary>Details</summary>
Motivation: 应对蚊媒疾病全球健康风险，强调'预防优于治疗'理念，需通过早期检测和主动控制滋生源头阻断疫情传播。

Method: 构建包含1828张检测标注图、142张水面分割图及自然语言推理文本的多模态数据集，采用YOLOv9s、YOLOv11n-Seg目标检测模型和BLIP文本生成模型进行验证。

Result: YOLOv9s检测精度0.929(mAP@50 0.928)，YOLOv11n-Seg分割精度0.915(mAP@50 0.797)，BLIP模型生成结果BLEU 54.7/BERTScore 0.91/ROUGE-L 0.87。

Conclusion: VisText-Mosquito数据集有效支持蚊虫滋生地智能分析，验证了AI主动预防技术路径，开源代码促进公共卫生领域应用创新。

Abstract: Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves a final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.87. This dataset and model framework emphasize the theme "Prevention is Better than Cure", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito

</details>


### [85] [ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM](https://arxiv.org/abs/2506.14766)
*Yujun Wang,Jinhe Bi,Yunpu Ma,Soeren Pirk*

Main category: cs.CV

TL;DR: 提出基于注意力引导的对比解码框架，通过直接干预模型注意力机制显著减少多模态大语言模型幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有方法VCD和ICD的效用可能源于注意力分布的本质改变而非表面logits调整，这启发了更根本的注意力干预方案

Method: 开发注意力可调控的对比解码框架，直接在模型的注意力机制层面进行干预

Result: 在POPE/CHAIR/MMHal-Bench等基准上显著降低幻觉，同时提升标准VQA任务表现

Conclusion: 注意力引导机制为缓解MLLM幻觉问题提供了更原则性的解决方案，且能兼容多种模型架构和解码方法

Abstract: Multimodal Large Language Model (MLLM) often suffer from hallucinations. They over-rely on partial cues and generate incorrect responses. Recently, methods like Visual Contrastive Decoding (VCD) and Instruction Contrastive Decoding (ICD) have been proposed to mitigate hallucinations by contrasting predictions from perturbed or negatively prefixed inputs against original outputs. In this work, we uncover that methods like VCD and ICD fundamentally influence internal attention dynamics of the model. This observation suggests that their effectiveness may not stem merely from surface-level modifications to logits but from deeper shifts in attention distribution. Inspired by this insight, we propose an attention-steerable contrastive decoding framework that directly intervenes in attention mechanisms of the model to offer a more principled approach to mitigating hallucinations. Our experiments across multiple MLLM architectures and diverse decoding methods demonstrate that our approach significantly reduces hallucinations and improves the performance on benchmarks such as POPE, CHAIR, and MMHal-Bench, while simultaneously enhancing performance on standard VQA benchmarks.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [86] [Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study](https://arxiv.org/abs/2506.13811)
*Sompote Youwai,David Phim,Vianne Gayl Murcia,Rianne Clair Onas*

Main category: cs.MA

TL;DR: 研究验证基于路由器的多智能体系统在基础设计自动化中的优越性，相比传统流程提升10-43.75个百分点性能，Grok 3展现突出的独立数学推理能力


<details>
  <summary>Details</summary>
Motivation: 传统工程设计流程存在效率瓶颈，需探索LLM在工程计算中的直接应用潜力，同时保障专业文档规范要求

Method: 采用单/多智能体架构对比研究，构建双层次分类框架识别基础类型，集成DeepSeek/ChatGPT/Grok/Gemini等模型进行性能基准测试

Result: 路由器系统在浅基/桩基设计分别达95%/90.63%准确率，较Grok独立性能提升8.75/3.13个百分点；超越常规流程最高43.75个百分点优势

Conclusion: 路由器多智能体系作为先进辅助工具可提升设计效率，但需保持人类专业监督以确保土木工程安全标准，暂不适用完全自主设计场景

Abstract: This study investigates router-based multi-agent systems for automating foundation design calculations through intelligent task classification and expert selection. Three approaches were evaluated: single-agent processing, multi-agent designer-checker architecture, and router-based expert selection. Performance assessment utilized baseline models including DeepSeek R1, ChatGPT 4 Turbo, Grok 3, and Gemini 2.5 Pro across shallow foundation and pile design scenarios. The router-based configuration achieved performance scores of 95.00% for shallow foundations and 90.63% for pile design, representing improvements of 8.75 and 3.13 percentage points over standalone Grok 3 performance respectively. The system outperformed conventional agentic workflows by 10.0 to 43.75 percentage points. Grok 3 demonstrated superior standalone performance without external computational tools, indicating advances in direct LLM mathematical reasoning for engineering applications. The dual-tier classification framework successfully distinguished foundation types, enabling appropriate analytical approaches. Results establish router-based multi-agent systems as optimal for foundation design automation while maintaining professional documentation standards. Given safety-critical requirements in civil engineering, continued human oversight remains essential, positioning these systems as advanced computational assistance tools rather than autonomous design replacements in professional practice.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [87] [Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning](https://arxiv.org/abs/2506.13778)
*Anvi Alex Eponon,Moein Shahiki-Tash,Ildar Batyrshin,Christian E. Maldonado-Sifuentes,Grigori Sidorov,Alexander Gelbukh*

Main category: cs.IR

TL;DR: 提出基于问题生成的知识编码方法，替代传统分块策略，显著提升RAG系统性能并降低存储需求


<details>
  <summary>Details</summary>
Motivation: 解决传统检索增强生成系统中存在的微调成本高、分块效率低、存储需求大和检索延迟长等问题

Method: 1. 生成覆盖词汇和语义空间的问题作为检索线索
2. 开发自定义句法重排方法
3. 创建300字符内的论文摘要卡片（paper-cards）

Result: 单跳检索Recall@3达0.84（提升60%），BM25检索MRR@3从0.56升至0.85，多跳任务F1达0.52（超越基线模型），存储需求降低80%

Conclusion: 该方法无需微调、降低80%存储需求、减少检索延迟，并通过问题驱动实现直观的知识访问，为可扩展的RAG系统提供高效替代方案

Abstract: This study presents a question-based knowledge encoding approach that improves retrieval-augmented generation (RAG) systems without requiring fine-tuning or traditional chunking. We encode textual content using generated questions that span the lexical and semantic space, creating targeted retrieval cues combined with a custom syntactic reranking method.
  In single-hop retrieval over 109 scientific papers, our approach achieves a Recall@3 of 0.84, outperforming traditional chunking methods by 60 percent. We also introduce "paper-cards", concise paper summaries under 300 characters, which enhance BM25 retrieval, increasing MRR@3 from 0.56 to 0.85 on simplified technical queries.
  For multihop tasks, our reranking method reaches an F1 score of 0.52 with LLaMA2-Chat-7B on the LongBench 2WikiMultihopQA dataset, surpassing chunking and fine-tuned baselines which score 0.328 and 0.412 respectively.
  This method eliminates fine-tuning requirements, reduces retrieval latency, enables intuitive question-driven knowledge access, and decreases vector storage demands by 80%, positioning it as a scalable and efficient RAG alternative.

</details>


### [88] [AcademicBrowse: Benchmarking Academic Browse Ability of LLMs](https://arxiv.org/abs/2506.13784)
*Junting Zhou,Wang Li,Yiyan Liao,Nengyuan Zhang,Tingjia Miaoand Zhihui Qi,Yuhan Wu,Tong Yang*

Main category: cs.IR

TL;DR: 创建AcademicBrowse数据集以评估大语言模型在复杂学术信息检索任务中的性能，填补现有搜索数据集在学术场景的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试(如BrowseComp)无法满足学术搜索场景中对深度文献追踪、专业数据库支持、长尾知识检索及学术严谨性的特殊需求。

Method: 设计首个专注学术检索评估的数据集，具备学术实用性(真实场景模拟)、高难度(需至少三次深度搜索)、简洁评估(明确答案来源)和广泛覆盖(15+学科)四大特征。

Result: 覆盖15个学科领域，通过结构化评估标准有效提升LLMs在复杂学术检索任务中的性能测量与优化能力。

Conclusion: AcademicBrowse为学术信息检索领域提供了首个专业评估基准，通过公开数据集促进LLMs在科研支持能力上的系统性提升。数据集已开源。

Abstract: Large Language Models (LLMs)' search capabilities have garnered significant attention. Existing benchmarks, such as OpenAI's BrowseComp, primarily focus on general search scenarios and fail to adequately address the specific demands of academic search. These demands include deeper literature tracing and organization, professional support for academic databases, the ability to navigate long-tail academic knowledge, and ensuring academic rigor. Here, we proposed AcademicBrowse, the first dataset specifically designed to evaluate the complex information retrieval capabilities of Large Language Models (LLMs) in academic research. AcademicBrowse possesses the following key characteristics: Academic Practicality, where question content closely mirrors real academic learning and research environments, avoiding deliberately misleading models; High Difficulty, with answers that are challenging for single models (e.g., Grok DeepSearch or Gemini Deep Research) to provide directly, often requiring at least three deep searches to derive; Concise Evaluation, where limiting conditions ensure answers are as unique as possible, accompanied by clear sources and brief solution explanations, greatly facilitating subsequent audit and verification, surpassing the current lack of analyzed search datasets both domestically and internationally; and Broad Coverage, as the dataset spans at least 15 different academic disciplines. Through AcademicBrowse, we expect to more precisely measure and promote the performance improvement of LLMs in complex academic information retrieval tasks. The data is available at: https://huggingface.co/datasets/PKU-DS-LAB/AcademicBrowse

</details>


### [89] [InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking](https://arxiv.org/abs/2506.14086)
*Rahul Seetharaman,Kaustubh D. Dhole,Aman Bansal*

Main category: cs.IR

TL;DR: 提出InsertRank方法，通过在大语言模型重排序中整合BM25等词汇信号，显著提升复杂推理型检索任务效果


<details>
  <summary>Details</summary>
Motivation: 现有LLM重排序器在处理需要推理的复杂查询时，仍存在性能提升空间。传统检索信号（如BM25）与LLM的语义理解能力具有互补性

Method: 在LLM重排序阶段引入BM25分数进行联合排序，通过分数归一化、位置偏差控制等技术实现多信号融合

Result: 在跨领域推理基准BRIGHT（37.5）和医疗推理基准R2MED（51.1）上超越现有方法，验证了多模型适配性（GPT/Gemini/Deepseek）

Conclusion: InsertRank证明了传统检索信号与LLM结合的可行性，为复杂查询处理提供了新思路，具有跨模型通用性

Abstract: Large Language Models (LLMs) have demonstrated significant strides across various information retrieval tasks, particularly as rerankers, owing to their strong generalization and knowledge-transfer capabilities acquired from extensive pretraining. In parallel, the rise of LLM-based chat interfaces has raised user expectations, encouraging users to pose more complex queries that necessitate retrieval by ``reasoning'' over documents rather than through simple keyword matching or semantic similarity. While some recent efforts have exploited reasoning abilities of LLMs for reranking such queries, considerable potential for improvement remains. In that regards, we introduce InsertRank, an LLM-based reranker that leverages lexical signals like BM25 scores during reranking to further improve retrieval performance. InsertRank demonstrates improved retrieval effectiveness on -- BRIGHT, a reasoning benchmark spanning 12 diverse domains, and R2MED, a specialized medical reasoning retrieval benchmark spanning 8 different tasks. We conduct an exhaustive evaluation and several ablation studies and demonstrate that InsertRank consistently improves retrieval effectiveness across multiple families of LLMs, including GPT, Gemini, and Deepseek models. %In addition, we also conduct ablation studies on normalization by varying the scale of the BM25 scores, and positional bias by shuffling the order of the documents. With Deepseek-R1, InsertRank achieves a score of 37.5 on the BRIGHT benchmark. and 51.1 on the R2MED benchmark, surpassing previous methods.

</details>
