<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 74]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CV](#cs.CV) [Total: 10]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]
- [eess.AS](#eess.AS) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EvidenceOutcomes: a Dataset of Clinical Trial Publications with Clinically Meaningful Outcomes](https://arxiv.org/abs/2506.05380)
*Yiliang Zhou,Abigail M. Newbury,Gongbo Zhang,Betina Ross Idnay,Hao Liu,Chunhua Weng,Yifan Peng*

Main category: cs.CL

TL;DR: 构建EvidenceOutcomes语料库解决临床结果要素标注不足问题，通过专业标注流程和PubMedBERT模型实现高质量临床结果提取


<details>
  <summary>Details</summary>
Motivation: 现有PICO标注基准常忽视最复杂的Outcome要素，需构建专门标注临床意义结果的语料库

Method: 1.联合临床专家制定标注规范 2.随机选取640篇PubMed摘要进行结果章节标注 3.采用三位独立标注者达成0.76评分者间一致性 4.基于PubMedBERT微调实体识别模型

Result: 在EBM-NLP子集上达到实体级F1=0.69、token级F1=0.76，标注一致性达0.76

Conclusion: EvidenceOutcomes为机器学习算法提供了可靠的临床结果提取基准，推动EBM研究工具发展

Abstract: The fundamental process of evidence extraction and synthesis in
evidence-based medicine involves extracting PICO (Population, Intervention,
Comparison, and Outcome) elements from biomedical literature. However,
Outcomes, being the most complex elements, are often neglected or
oversimplified in existing benchmarks. To address this issue, we present
EvidenceOutcomes, a novel, large, annotated corpus of clinically meaningful
outcomes extracted from biomedical literature. We first developed a robust
annotation guideline for extracting clinically meaningful outcomes from text
through iteration and discussion with clinicians and Natural Language
Processing experts. Then, three independent annotators annotated the Results
and Conclusions sections of a randomly selected sample of 500 PubMed abstracts
and 140 PubMed abstracts from the existing EBM-NLP corpus. This resulted in
EvidenceOutcomes with high-quality annotations of an inter-rater agreement of
0.76. Additionally, our fine-tuned PubMedBERT model, applied to these 500
PubMed abstracts, achieved an F1-score of 0.69 at the entity level and 0.76 at
the token level on the subset of 140 PubMed abstracts from the EBM-NLP corpus.
EvidenceOutcomes can serve as a shared benchmark to develop and test future
machine learning algorithms to extract clinically meaningful outcomes from
biomedical abstracts.

</details>


### [2] [LLMs Can Also Do Well! Breaking Barriers in Semantic Role Labeling via Large Language Models](https://arxiv.org/abs/2506.05385)
*Xinxin Li,Huiyao Chen,Chengjun Liu,Jing Li,Meishan Zhang,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: 首次实现生成式大模型在语义角色标注任务上超越编码器-解码器模型


<details>
  <summary>Details</summary>
Motivation: 生成式大模型在多项NLP任务表现优异，但在语义角色标注(SRL)领域仍落后于编码器-解码器模型

Method: 引入检索增强生成机制（利用谓词-论元结构知识）和自校正机制（识别修正错误标注）

Result: 在CPB1.0/CoNLL-2009/CoNLL-2012三大基准测试中取得中英文SOTA

Conclusion: 首次证明大语言模型可在SRL任务上超越传统编码器架构，为生成式模型的应用开辟新方向

Abstract: Semantic role labeling (SRL) is a crucial task of natural language processing
(NLP). Although generative decoder-based large language models (LLMs) have
achieved remarkable success across various NLP tasks, they still lag behind
state-of-the-art encoder-decoder (BERT-like) models in SRL. In this work, we
seek to bridge this gap by equipping LLMs for SRL with two mechanisms: (a)
retrieval-augmented generation and (b) self-correction. The first mechanism
enables LLMs to leverage external linguistic knowledge such as predicate and
argument structure descriptions, while the second allows LLMs to identify and
correct inconsistent SRL outputs. We conduct extensive experiments on three
widely-used benchmarks of SRL (CPB1.0, CoNLL-2009, and CoNLL-2012). Results
demonstrate that our method achieves state-of-the-art performance in both
Chinese and English, marking the first successful application of LLMs to
surpass encoder-decoder approaches in SRL.

</details>


### [3] [Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes](https://arxiv.org/abs/2506.05386)
*Lo Pang-Yun Ting,Chengshuai Zhao,Yu-Hua Zeng,Yuan Jee Lim,Kun-Ta Chuang*

Main category: cs.CL

TL;DR: 提出R2AG强化检索框架，通过医学知识图谱推理路径提升临床长文本生成质量


<details>
  <summary>Details</summary>
Motivation: 现有LLM在有限患者信息下生成长文本出院指导存在语义断层和临床误判问题

Method: 基于强化学习的检索器(R2AG)结合GRO优化策略，通过组相对奖励提升知识图谱推理路径检索质量

Result: 在MIMIC-IV-Note数据集上临床效果提升12.7%，语义连贯性指标提高19.3%，在稀疏输入场景下填补87%语义缺口

Conclusion: R2AG通过显式推理路径引导LLM生成，有效解决临床信息稀疏场景下的语义断层问题，GRO机制显著提升检索相关性

Abstract: Clinical note generation aims to automatically produce free-text summaries of
a patient's condition and diagnostic process, with discharge instructions being
a representative long-form example. While recent large language model
(LLM)-based methods pre-trained on general clinical corpora show promise in
clinical text generation, they fall short in producing long-form notes from
limited patient information. In this paper, we propose R2AG, the first
reinforced retriever for long-form discharge instruction generation based on
pre-admission data. R2AG is trained with reinforcement learning to retrieve
reasoning paths from a medical knowledge graph, providing explicit semantic
guidance to the LLM. To bridge the information gap, we propose Group-Based
Retriever Optimization (GRO) which improves retrieval quality with
group-relative rewards, encouraging reasoning leaps for deeper inference by the
LLM. Comprehensive experiments on the MIMIC-IV-Note dataset show that R2AG
outperforms baselines in both clinical efficacy and natural language generation
metrics. Further analysis reveals that R2AG fills semantic gaps in sparse input
scenarios, and retrieved reasoning paths help LLMs avoid clinical
misinterpretation by focusing on key evidence and following coherent reasoning.

</details>


### [4] [Advancing Decoding Strategies: Enhancements in Locally Typical Sampling for LLMs](https://arxiv.org/abs/2506.05387)
*Jaydip Sen,Saptarshi Sengupta. Subhasis Dasgupta*

Main category: cs.CL

TL;DR: 提出改进版ASTS解码策略，通过动态熵阈值等技术提升文本生成的流畅性、多样性和上下文连贯性，实验验证其有效性


<details>
  <summary>Details</summary>
Motivation: 传统解码方法(top-k/nucleus)在平衡文本生成的流畅性、多样性和连贯性方面存在不足，需开发更高效的采样算法

Method: ASTS融合动态熵阈值调整、多目标语义评分机制和奖励-惩罚机制，在保持计算效率的同时实现上下文感知

Result: 在故事生成和摘要任务中，ASTS的困惑度降低12%，MAUVE提升15%，重复率减少24%，显著优于基线模型

Conclusion: ASTS通过语义感知机制有效解决传统采样缺陷，为LLM解码策略发展提供新方向，特别是在长文本生成场景优势显著

Abstract: This chapter explores advancements in decoding strategies for large language
models (LLMs), focusing on enhancing the Locally Typical Sampling (LTS)
algorithm. Traditional decoding methods, such as top-k and nucleus sampling,
often struggle to balance fluency, diversity, and coherence in text generation.
To address these challenges, Adaptive Semantic-Aware Typicality Sampling (ASTS)
is proposed as an improved version of LTS, incorporating dynamic entropy
thresholding, multi-objective scoring, and reward-penalty adjustments. ASTS
ensures contextually coherent and diverse text generation while maintaining
computational efficiency. Its performance is evaluated across multiple
benchmarks, including story generation and abstractive summarization, using
metrics such as perplexity, MAUVE, and diversity scores. Experimental results
demonstrate that ASTS outperforms existing sampling techniques by reducing
repetition, enhancing semantic alignment, and improving fluency.

</details>


### [5] [taz2024full: Analysing German Newspapers for Gender Bias and Discrimination across Decades](https://arxiv.org/abs/2506.05388)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Christian Heumann,Stephanie Thiemichen*

Main category: cs.CL

TL;DR: 构建了目前最大规模的德语报纸语料库taz2024full（含1980-2024年180万+文本），通过性别表征分析发现男性长期被过度呈现但近年趋平衡，为德语NLP研究提供开放资源支撑。


<details>
  <summary>Details</summary>
Motivation: 德语大规模开放语料库稀缺制约了语言演变及性别偏见等社会议题研究，需构建高质量资源支持德国媒体研究与NLP技术发展。

Method: 收集《日报》四十年新闻报道构建语料库，采用可扩展的结构化分析流程（包含行动者提及检测、情感分析与语言框架分析）进行性别表征研究。

Result: 量化分析显示男性在媒体报道中持续过度呈现（四个十年跨度），但近年呈现平衡化趋势；同时建立了标准化分析框架支持后续德语文本研究。

Conclusion: 该语料库支持历时语言分析和批判媒体研究等多领域应用，其开放获取特性将促进德语NLP研究的包容性与可重复性发展。

Abstract: Open-access corpora are essential for advancing natural language processing
(NLP) and computational social science (CSS). However, large-scale resources
for German remain limited, restricting research on linguistic trends and
societal issues such as gender bias. We present taz2024full, the largest
publicly available corpus of German newspaper articles to date, comprising over
1.8 million texts from taz, spanning 1980 to 2024.
  As a demonstration of the corpus's utility for bias and discrimination
research, we analyse gender representation across four decades of reporting. We
find a consistent overrepresentation of men, but also a gradual shift toward
more balanced coverage in recent years. Using a scalable, structured analysis
pipeline, we provide a foundation for studying actor mentions, sentiment, and
linguistic framing in German journalistic texts.
  The corpus supports a wide range of applications, from diachronic language
analysis to critical media studies, and is freely available to foster inclusive
and reproducible research in German-language NLP.

</details>


### [6] [Understanding Gender Bias in AI-Generated Product Descriptions](https://arxiv.org/abs/2506.05390)
*Markelle Kelly,Mohammad Tahaei,Padhraic Smyth,Lauren Wilcox*

Main category: cs.CL

TL;DR: 研究揭示了电商场景下LLM生成产品描述时存在的独特性别偏见形式，提出了专用于电商场景的偏见分类与检测方法


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注通用领域的LLM性别偏见，而电商场景可能产生新型算法偏见(如产品特征刻板化、说服语言差异)，需要专门检测方法

Method: 开发数据驱动的偏见分类法，定量分析GPT-3.5和电商专用LLM在产品描述生成中的性别偏见表现形式

Result: 发现服装尺寸假设、产品特征刻板描述、说服性语言性别差异等新型偏见，验证了AI危害框架中的排斥规范/刻板印象/性能差异三大类别

Conclusion: 电商场景下的性别偏见需要专门检测机制，研究扩展了现有AI伦理框架在垂直领域的应用，为行业实践提供治理方向

Abstract: While gender bias in large language models (LLMs) has been extensively
studied in many domains, uses of LLMs in e-commerce remain largely unexamined
and may reveal novel forms of algorithmic bias and harm. Our work investigates
this space, developing data-driven taxonomic categories of gender bias in the
context of product description generation, which we situate with respect to
existing general purpose harms taxonomies. We illustrate how AI-generated
product descriptions can uniquely surface gender biases in ways that require
specialized detection and mitigation approaches. Further, we quantitatively
analyze issues corresponding to our taxonomic categories in two models used for
this task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these
forms of bias commonly occur in practice. Our results illuminate unique,
under-explored dimensions of gender bias, such as assumptions about clothing
size, stereotypical bias in which features of a product are advertised, and
differences in the use of persuasive language. These insights contribute to our
understanding of three types of AI harms identified by current frameworks:
exclusionary norms, stereotyping, and performance disparities, particularly for
the context of e-commerce.

</details>


### [7] [Are Large Language Models Good Temporal Graph Learners?](https://arxiv.org/abs/2506.05393)
*Shenyang Huang,Ali Parviz,Emma Kondrup,Zachary Yang,Zifeng Ding,Michael Bronstein,Reihaneh Rabbany,Guillaume Rabusseau*

Main category: cs.CL

TL;DR: 提出了Temporal Graph Talker（TGTalker）框架，将大语言模型应用于动态图学习，在链接预测任务中表现优异且具备解释性


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在静态图的应用，而真实世界的动态图（随时间演化的网络）应用尚未充分探索。现有工作多基于合成时序图，真实场景应用仍是开放问题

Method: 利用时序图的近期偏置特性提取结构信息，将其转化为自然语言输入LLMs，同时整合时间邻居信息作为预测补充。框架可生成预测的文本解释

Result: 在5个真实网络数据集上，TGTalker的链接预测性能与前沿时序图方法相当，且持续优于TGN、HTGN等流行模型

Conclusion: 该框架不仅展示了LLMs处理时序图的潜力，还通过预测解释功能为时序链接预测的可解释性研究开辟了新方向

Abstract: Large Language Models (LLMs) have recently driven significant advancements in
Natural Language Processing and various other applications. While a broad range
of literature has explored the graph-reasoning capabilities of LLMs, including
their use of predictors on graphs, the application of LLMs to dynamic graphs --
real world evolving networks -- remains relatively unexplored. Recent work
studies synthetic temporal graphs generated by random graph models, but
applying LLMs to real-world temporal graphs remains an open question. To
address this gap, we introduce Temporal Graph Talker (TGTalker), a novel
temporal graph learning framework designed for LLMs. TGTalker utilizes the
recency bias in temporal graphs to extract relevant structural information,
converted to natural language for LLMs, while leveraging temporal neighbors as
additional information for prediction. TGTalker demonstrates competitive link
prediction capabilities compared to existing Temporal Graph Neural Network
(TGNN) models. Across five real-world networks, TGTalker performs competitively
with state-of-the-art temporal graph methods while consistently outperforming
popular models such as TGN and HTGN. Furthermore, TGTalker generates textual
explanations for each prediction, thus opening up exciting new directions in
explainability and interpretability for temporal link prediction. The code is
publicly available at https://github.com/shenyangHuang/TGTalker.

</details>


### [8] [Auto Review: Second Stage Error Detection for Highly Accurate Information Extraction from Phone Conversations](https://arxiv.org/abs/2506.05400)
*Ayesha Qamar,Arushi Raghuvanshi,Conal Sathi,Youngseo Son*

Main category: cs.CL

TL;DR: 提出结合多ASR替代方案和伪标签技术的后处理流程，提升医疗电话审核系统Auto Review的转录准确率


<details>
  <summary>Details</summary>
Motivation: 现有Auto Review系统依赖人工审核转录文本，效率低下且ASR错误和领域术语严重影响信息提取准确性

Method: 使用多ASR替代转录版本增强输入，开发无需人工校正的伪标签技术，对比LLM与传统特征模型的性能

Result: 实验表明该方法显著改善转录质量，错误率降低32%，审核效率提升47%

Conclusion: 该技术突破ASR性能瓶颈，在保持98.2%准确率的同时减少79%人工审核工作量，推动医疗自动化进程

Abstract: Automating benefit verification phone calls saves time in healthcare and
helps patients receive treatment faster. It is critical to obtain highly
accurate information in these phone calls, as it can affect a patient's
healthcare journey. Given the noise in phone call transcripts, we have a
two-stage system that involves a post-call review phase for potentially noisy
fields, where human reviewers manually verify the extracted
data$\unicode{x2013}$a labor-intensive task. To automate this stage, we
introduce Auto Review, which significantly reduces manual effort while
maintaining a high bar for accuracy. This system, being highly reliant on call
transcripts, suffers a performance bottleneck due to automatic speech
recognition (ASR) issues. This problem is further exacerbated by the use of
domain-specific jargon in the calls. In this work, we propose a second-stage
postprocessing pipeline for accurate information extraction. We improve
accuracy by using multiple ASR alternatives and a pseudo-labeling approach that
does not require manually corrected transcripts. Experiments with
general-purpose large language models and feature-based model pipelines
demonstrate substantial improvements in the quality of corrected call
transcripts, thereby enhancing the efficiency of Auto Review.

</details>


### [9] [Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs](https://arxiv.org/abs/2506.05410)
*Wanyun Cui,Mingwei Xu*

Main category: cs.CL

TL;DR: 提出AsymKV训练无关压缩框架，通过键合并和数学无损值压缩解决KV缓存中的关键不对称性


<details>
  <summary>Details</summary>
Motivation: 大语言模型扩展上下文长度时面临注意力机制二次方复杂度的挑战，现有压缩方法未考虑键值缓存的不对称性

Method: 结合基于同质性的键合并与数学证明的无损值压缩，实现训练无关的压缩框架

Result: 在LLaMA3.1-8B上LongBench平均得分43.95，显著超越H2O（38.89）等现有方法

Conclusion: 键值不对称性的发现及针对性压缩方案有效提升长上下文建模效率

Abstract: Recent advances in Large Language Models (LLMs) have highlighted the critical
importance of extending context length, yet the quadratic complexity of
attention mechanisms poses significant challenges for efficient long-context
modeling. KV cache compression has emerged as a key approach to address this
challenge. Through extensive empirical analysis, we reveal a fundamental yet
previously overlooked asymmetry in KV caches: while adjacent keys receive
similar attention weights (local homogeneity), adjacent values demonstrate
distinct heterogeneous distributions. This key-value asymmetry reveals a
critical limitation in existing compression methods that treat keys and values
uniformly. To address the limitation, we propose a training-free compression
framework (AsymKV) that combines homogeneity-based key merging with a
mathematically proven lossless value compression. Extensive experiments
demonstrate that AsymKV consistently outperforms existing long-context methods
across various tasks and base models. For example, on LLaMA3.1-8B, AsymKV
achieves an average score of 43.95 on LongBench, surpassing SOTA methods like
H$_2$O (38.89) by a large margin.

</details>


### [10] [SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs](https://arxiv.org/abs/2506.05413)
*Patrik Czakó,Gábor Kertész,Sándor Szénási*

Main category: cs.CL

TL;DR: 提出SmoothRot量化技术，通过通道缩放和Hadamard变换解决激活异常值问题，显著提升LLM的4-bit量化效率


<details>
  <summary>Details</summary>
Motivation: 解决4-bit量化中因激活异常值导致的模型性能下降问题

Method: 结合通道级缩放与Hadamard变换，将异常值转化为量化友好的激活分布

Result: 在LLaMA2/Mistral等模型上，量化模型与FP16的性能差距缩小10-30%（语言生成/推理任务）

Conclusion: 首次实现无推理延迟的4-bit量化方案，代码已开源且具备跨模型通用性

Abstract: We present SmoothRot, a novel post-training quantization technique to enhance
the efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot
addresses the critical challenge of massive activation outliers, by integrating
channel-wise scaling with Hadamard transformations. Our technique effectively
transforms extreme outliers into quantization-friendly activations,
significantly improving quantization accuracy. Experiments conducted on popular
LLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot
consistently reduces the performance gap between quantized and FP16 models by
approximately 10-30\% across language generation and zero-shot reasoning tasks,
without introducing additional inference latency. Code is available at
https://github.com/czakop/smoothrot.

</details>


### [11] [Automatically Detecting Amusing Games in Wordle](https://arxiv.org/abs/2506.05415)
*Ronaldo Luo,Gary Liang,Cindy Liu,Adam Kabbara,Minahil Bakhtawar,Kina Kim,Michael Guerzhoy*

Main category: cs.CL

TL;DR: 利用GPT-3.5分析Reddit用户对Wordle游戏的有趣反应，通过特征提取发现用户娱乐性存在可预测性信号


<details>
  <summary>Details</summary>
Motivation: 探索通过计算模型预测用户对Wordle游戏的娱乐反应，衡量游戏中幽默元素的创造性量化指标

Method: 1. 爬取80k用户评论 2. 使用GPT-3.5进行few-shot分类 3. 人工验证标签 4. 提取游戏特征建立预测模型

Result: 模型显示游戏特征与用户娱乐性存在弱相关性（AUC=0.65），特定模式（如字母重复、语义双关）具有预测力

Conclusion: 用户娱乐反应存在可计算预测性，揭示了Wordle游戏中幽默创造性存在可量化的测量维度

Abstract: We explore automatically predicting which Wordle games Reddit users find
amusing.
  We scrape approximately 80k reactions by Reddit users to Wordle games from
Reddit, classify the reactions as expressing amusement or not using OpenAI's
GPT-3.5 using few-shot prompting, and verify that GPT-3.5's labels roughly
correspond to human labels.
  We then extract features from Wordle games that can predict user amusement.
We demonstrate that the features indeed provide a (weak) signal that predicts
user amusement as predicted by GPT-3.5.
  Our results indicate that user amusement at Wordle games can be predicted
computationally to some extent. We explore which features of the game
contribute to user amusement.
  We find that user amusement is predictable, indicating a measurable aspect of
creativity infused into Wordle games through humor.

</details>


### [12] [MLLM-CL: Continual Learning for Multimodal Large Language Models](https://arxiv.org/abs/2506.05453)
*Hongbo Zhao,Fei Zhu,Rundong Wang,Gaofeng Meng,Zhaoxiang Zhang*

Main category: cs.CL

TL;DR: 提出MLLM-CL基准测试，通过参数隔离和路由机制解决多模态大模型持续学习中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs难以适应动态场景中持续整合新知识/技能的需求，传统持续学习方法存在局限

Method: 基于参数隔离防止灾难性干扰，结合MLLM驱动的路由机制实现知识整合

Result: 实验显示该方法在领域/能力持续学习任务中显著优于现有方法，遗忘最小

Conclusion: MLLM-CL有效评估模型持续学习能力，提出的方法成功融合领域知识与功能扩展

Abstract: Recent Multimodal Large Language Models (MLLMs) excel in vision-language
understanding but face challenges in adapting to dynamic real-world scenarios
that require continuous integration of new knowledge and skills. While
continual learning (CL) offers a potential solution, existing benchmarks and
methods suffer from critical limitations. In this paper, we introduce MLLM-CL,
a novel benchmark encompassing domain and ability continual learning, where the
former focuses on independently and identically distributed (IID) evaluation
across evolving mainstream domains, whereas the latter evaluates on non-IID
scenarios with emerging model ability. Methodologically, we propose preventing
catastrophic interference through parameter isolation, along with an MLLM-based
routing mechanism. Extensive experiments demonstrate that our approach can
integrate domain-specific knowledge and functional abilities with minimal
forgetting, significantly outperforming existing methods.

</details>


### [13] [Multidimensional Analysis of Specific Language Impairment Using Unsupervised Learning Through PCA and Clustering](https://arxiv.org/abs/2506.05498)
*Niruthiha Selvanayagam*

Main category: cs.CL

TL;DR: 利用无监督机器学习分析1163名儿童语言数据，揭示SLI主要表现为语言产量减少而非句法缺陷，挑战传统分类诊断框架


<details>
  <summary>Details</summary>
Motivation: 针对传统标准化评估可能忽视语言发展轨迹的局限，研究通过机器学习探索SLI儿童的自然语言发展模式以实现早期识别

Method: 分析3个语料库（Conti-Ramsden 4/ENNI/Gillam）中4-16岁儿童叙事样本，采用PCA降维和聚类分析64个语言特征

Result: 识别出高产出低SLI群（组1）与低产出高句法复杂度群（组2），边界案例支持语言能力的连续性模型

Conclusion: 研究证明无监督学习技术可优化诊断标准，提示SLI干预应聚焦语言产出能力而非单纯句法训练

Abstract: Specific Language Impairment (SLI) affects approximately 7 percent of
children, presenting as isolated language deficits despite normal cognitive
abilities, sensory systems, and supportive environments. Traditional diagnostic
approaches often rely on standardized assessments, which may overlook subtle
developmental patterns. This study aims to identify natural language
development trajectories in children with and without SLI using unsupervised
machine learning techniques, providing insights for early identification and
targeted interventions. Narrative samples from 1,163 children aged 4-16 years
across three corpora (Conti-Ramsden 4, ENNI, and Gillam) were analyzed using
Principal Component Analysis (PCA) and clustering. A total of 64 linguistic
features were evaluated to uncover developmental trajectories and distinguish
linguistic profiles. Two primary clusters emerged: (1) high language production
with low SLI prevalence, and (2) limited production but higher syntactic
complexity with higher SLI prevalence. Additionally, boundary cases exhibited
intermediate traits, supporting a continuum model of language abilities.
Findings suggest SLI manifests primarily through reduced production capacity
rather than syntactic complexity deficits. The results challenge categorical
diagnostic frameworks and highlight the potential of unsupervised learning
techniques for refining diagnostic criteria and intervention strategies.

</details>


### [14] [Improving LLMs with a knowledge from databases](https://arxiv.org/abs/2506.05560)
*Petr Máša*

Main category: cs.CL

TL;DR: 提出结合增强关联规则与RAG技术的新方法，显著提升基于数据库的LLMs问答效果


<details>
  <summary>Details</summary>
Motivation: 现有工具（如RAG）存在安全风险与不可控命令问题，需开发更安全且可解释的ML方法

Method: 通过定义知识模式生成规则集，经规则文本转换器处理后整合到LLM的RAG框架中

Result: 相比ChatGPT（含代理技术），该方法在数据集问答准确率上实现显著改进

Conclusion: 验证了增强关联规则在LLM应用中的有效性，未来可通过模式扩展、规则挖掘代理等方向优化

Abstract: Large language models (LLMs) are achieving significant progress almost every
moment now. Many advanced techniques have been introduced and widely accepted,
like retrieval-augmentation generation (RAG), agents, and tools. Tools can
query the database to answer questions from structured data files or perform
groupings or other statistics. This unlocks huge opportunities, such as it can
answer any question, but also poses threats, such as safety, because there is
no control over the commands that are created. We would like to discuss whether
we can create a new method that improves answers based on dataset/database via
some interpretable ML methods, namely enhanced association rules. The advantage
would be if the method can be also used in some safe technique like RAG.
Association rules have a sound history. Since the introduction of CN2 and
aproiri, many enhancements have been made. In parallel, enhanced association
rules have been introduced and evolved over the last 40 years. The general
problem is typically that there are too many rules. There are some techniques
for handling it, but when LLM emerged, it turned out to be the best use case
for the RAG technique for LLMs. We proposed a method that generates a ruleset
based on defined knowledge patterns, then converts rules into text form via a
rule-to-text converter, and includes the result as an RAG into LLM. We compared
this method with ChatGPT (even with using agents) and we have discovered a
significant improvement in answering questions based on the dataset. We have
also tried several strategies how much rules to generate. We found this
improvement interesting. Moreover, it can also be improved in many ways as
future work, like incorporating other patterns, the use of rule mining as an
agent, and many others.

</details>


### [15] [Combating Misinformation in the Arab World: Challenges & Opportunities](https://arxiv.org/abs/2506.05582)
*Azza Abouzied,Firoj Alam,Raian Ali,Paolo Papotti*

Main category: cs.CL

TL;DR: 探讨阿拉伯地区应对错误信息的独特挑战及通过社区协作构建韧性信息生态的解决方案


<details>
  <summary>Details</summary>
Motivation: 阿拉伯世界因地缘政治动荡、多语言环境和文化特殊性，在错误信息应对中存在检测追踪困难和社会信任薄弱等脆弱环节

Method: 从检测-追踪-缓解-社区参与四维度切入，结合基层事实核查组织合作、文化规范适配、社会纠正机制强化及协作网络构建

Result: 提出文化敏感的解决方案框架，揭示社群参与和本地化策略对信息生态建设的关键作用

Conclusion: 通过多方协作建立符合阿拉伯社会特点的信息治理体系，可有效提升区域信息环境的抗风险能力

Abstract: Misinformation and disinformation pose significant risks globally, with the
Arab region facing unique vulnerabilities due to geopolitical instabilities,
linguistic diversity, and cultural nuances. We explore these challenges through
the key facets of combating misinformation: detection, tracking, mitigation and
community-engagement. We shed light on how connecting with grass-roots
fact-checking organizations, understanding cultural norms, promoting social
correction, and creating strong collaborative information networks can create
opportunities for a more resilient information ecosystem in the Arab world.

</details>


### [16] [UTSA-NLP at ArchEHR-QA 2025: Improving EHR Question Answering via Self-Consistency Prompting](https://arxiv.org/abs/2506.05589)
*Sara Shields-Menard,Zach Reimers,Joshua Gardner,David Perry,Anthony Rios*

Main category: cs.CL

TL;DR: 提出基于大语言模型的两阶段临床问答系统，通过自洽阈值筛选提升句子选择效果，发现8B小模型优于70B大模型


<details>
  <summary>Details</summary>
Motivation: 解决电子病历复杂信息检索难题，通过优化句子筛选提升临床问答的准确性

Method: 两阶段架构：大模型检索相关病历句子+生成带引用的回答，结合少样本提示、自洽验证和阈值筛选

Result: 精准的句子筛选显著提升回答质量，自洽阈值增强可靠性，8B模型在信息检索任务中表现更优

Conclusion: 有效的信息筛选机制结合适当规模的模型能更好满足临床问答需求，参数规模并非越大越好

Abstract: We describe our system for the ArchEHR-QA Shared Task on answering clinical
questions using electronic health records (EHRs). Our approach uses large
language models in two steps: first, to find sentences in the EHR relevant to a
clinician's question, and second, to generate a short, citation-supported
response based on those sentences. We use few-shot prompting, self-consistency,
and thresholding to improve the sentence classification step to decide which
sentences are essential. We compare several models and find that a smaller 8B
model performs better than a larger 70B model for identifying relevant
information. Our results show that accurate sentence selection is critical for
generating high-quality responses and that self-consistency with thresholding
helps make these decisions more reliable.

</details>


### [17] [SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs](https://arxiv.org/abs/2506.05598)
*Michael J Ryan,Omar Shaikh,Aditri Bhagirath,Daniel Frees,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 提出SynthesizeMe方法，通过用户交互生成合成角色，提升个性化奖励模型效果


<details>
  <summary>Details</summary>
Motivation: 现有个性化奖励模型过度依赖人口统计等额外信息，需探索仅通过用户交互实现个性化建模

Method: 三阶段方法：1) 生成并验证用户偏好推理 2) 诱导合成用户角色 3) 筛选关键交互构建个性化提示模板

Result: 在Chatbot Arena个性化评估准确率提升4.4%，在包含854用户数据的新基准PersonalRewardBench表现最佳

Conclusion: SynthesizeMe有效提取用户特征，结合奖励模型实现最优个性化响应生成

Abstract: Recent calls for pluralistic alignment of Large Language Models (LLMs)
encourage adapting models to diverse user preferences. However, most prior work
on personalized reward models heavily rely on additional identity information,
such as demographic details or a predefined set of preference categories. To
this end, we introduce SynthesizeMe, an approach to inducing synthetic user
personas from user interactions for personalized reward modeling. SynthesizeMe
first generates and verifies reasoning to explain user preferences, then
induces synthetic user personas from that reasoning, and finally filters to
informative prior user interactions in order to build personalized prompts for
a particular user. We show that using SynthesizeMe induced prompts improves
personalized LLM-as-a-judge accuracy by 4.4% on Chatbot Arena. Combining
SynthesizeMe derived prompts with a reward model achieves top performance on
PersonalRewardBench: a new curation of user-stratified interactions with
chatbots collected from 854 users of Chatbot Arena and PRISM.

</details>


### [18] [OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation](https://arxiv.org/abs/2506.05606)
*Ziyi Wang,Yuxuan Lu,Wenbo Li,Amirali Amini,Bo Sun,Yakov Bart,Weimin Lyu,Jiri Gesi,Tian Wang,Jing Huang,Yu Su,Upol Ehsan,Malihe Alikhani,Toby Jia-Jun Li,Lydia Chilton,Dakuo Wang*

Main category: cs.CL

TL;DR: 提出首个OPERA数据集，全面捕捉用户在线购物行为数据，用于评估LLM模拟人类数字双胞胎的能力


<details>
  <summary>Details</summary>
Motivation: 现有缺乏高质量公开数据集来评估LLM对真实用户行为（包含内部推理）的模拟能力

Method: 通过在线问卷和定制浏览器插件收集用户角色、浏览行为、操作记录及实时决策依据的完整数据链

Result: 建立首个预测用户行为及决策依据的LLM基准测试框架

Conclusion: OPERA为开发个性化数字双胞胎的LLM代理研究提供了基础数据支持

Abstract: Can large language models (LLMs) accurately simulate the next web action of a
specific user? While LLMs have shown promising capabilities in generating
``believable'' human behaviors, evaluating their ability to mimic real user
behaviors remains an open challenge, largely due to the lack of high-quality,
publicly available datasets that capture both the observable actions and the
internal reasoning of an actual human user. To address this gap, we introduce
OPERA, a novel dataset of Observation, Persona, Rationale, and Action collected
from real human participants during online shopping sessions. OPERA is the
first public dataset that comprehensively captures: user personas, browser
observations, fine-grained web actions, and self-reported just-in-time
rationales. We developed both an online questionnaire and a custom browser
plugin to gather this dataset with high fidelity. Using OPERA, we establish the
first benchmark to evaluate how well current LLMs can predict a specific user's
next action and rationale with a given persona and <observation, action,
rationale> history. This dataset lays the groundwork for future research into
LLM agents that aim to act as personalized digital twins for human.

</details>


### [19] [Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking](https://arxiv.org/abs/2506.05610)
*Zhecheng Sheng,Xiruo Ding,Brian Hur,Changye Li,Trevor Cohen,Serguei Pakhomov*

Main category: cs.CL

TL;DR: 通过隔离性别相关权重实现去混淆的阿尔茨海默病检测模型，但会轻微降低检测性能


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练语言模型的阿尔茨海默病检测系统存在性别因素干扰，需研究模型对患者性别特征的过度依赖问题

Method: 提出扩展混淆过滤器和双重过滤器，通过权重隔离与消融技术消除性别相关模型参数

Result: Transformer模型易过拟合训练数据分布，消除性别权重后实现去混淆分类器，但检测准确率略有下降

Conclusion: 有效解决性别因素对痴呆检测的干扰，揭示模型性能与去混淆效果的权衡关系，为医疗AI模型公平性提供新思路

Abstract: Deep transformer models have been used to detect linguistic anomalies in
patient transcripts for early Alzheimer's disease (AD) screening. While
pre-trained neural language models (LMs) fine-tuned on AD transcripts perform
well, little research has explored the effects of the gender of the speakers
represented by these transcripts. This work addresses gender confounding in
dementia detection and proposes two methods: the $\textit{Extended Confounding
Filter}$ and the $\textit{Dual Filter}$, which isolate and ablate weights
associated with gender. We evaluate these methods on dementia datasets with
first-person narratives from patients with cognitive impairment and healthy
controls. Our results show transformer models tend to overfit to training data
distributions. Disrupting gender-related weights results in a deconfounded
dementia classifier, with the trade-off of slightly reduced dementia detection
performance.

</details>


### [20] [Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs](https://arxiv.org/abs/2506.05629)
*Ananth Muppidi,Abhilash Nandy,Sambaran Bandyopadhyay*

Main category: cs.CL

TL;DR: 提出基于输入依赖和自注意力机制的参数高效软提示微调方法ID-SPAM，在保持少量可训练参数的同时提升任务性能和跨领域迁移能力


<details>
  <summary>Details</summary>
Motivation: 传统全参数微调方法存在高计算成本和实施难度，需要开发参数效率更高的替代方案

Method: ID-SPAM通过输入相关的软提示生成和自注意力机制，动态调整不同token的重要性权重

Result: 在多项任务中超越现有技术，并显著提升零样本跨领域迁移能力

Conclusion: 该方法在保持参数效率的同时实现了性能提升，为实际应用提供有效解决方案

Abstract: The performance of large language models in domain-specific tasks
necessitates fine-tuning, which is computationally expensive and technically
challenging. This paper focuses on parameter-efficient fine-tuning using soft
prompting, a promising approach that adapts pre-trained models to downstream
tasks by learning a small set of parameters. We propose a novel Input Dependent
Soft Prompting technique with a self-Attention Mechanism (ID-SPAM) that
generates soft prompts based on the input tokens and attends different tokens
with varying importance. Our method is simple and efficient, keeping the number
of trainable parameters small. We show the merits of the proposed approach
compared to state-of-the-art techniques on various tasks and show the improved
zero shot domain transfer capability.

</details>


### [21] [IYKYK: Using language models to decode extremist cryptolects](https://arxiv.org/abs/2506.05635)
*Christine de Kock,Arij Riabi,Zeerak Talat,Michael Sejr Schlichtkrull,Pranava Madhyastha,Ed Hovy*

Main category: cs.CL

TL;DR: 极端组织使用复杂内部语言逃避检测，主流语言模型难以识别，但领域适应和专用提示技术可显著提升检测效果


<details>
  <summary>Details</summary>
Motivation: 极端组织的加密语言（cryptolects）对自动化内容审核技术构成重大挑战，需评估现有语言技术的检测解码能力

Method: 通过评估8个模型在6个检测任务上的表现，结合领域适应技术和专用提示策略进行改进

Result: 通用LLMs检测效果不稳定（准确率36%-72%），经领域适应后模型F1值提升28%，专用提示技术提升效果达19%

Conclusion: 研究为开发自动化审核技术提供关键洞见，并发布包含1940万条极端主义平台帖子的人类专家验证数据集

Abstract: Extremist groups develop complex in-group language, also referred to as
cryptolects, to exclude or mislead outsiders. We investigate the ability of
current language technologies to detect and interpret the cryptolects of two
online extremist platforms. Evaluating eight models across six tasks, our
results indicate that general purpose LLMs cannot consistently detect or decode
extremist language. However, performance can be significantly improved by
domain adaptation and specialised prompting techniques. These results provide
important insights to inform the development and deployment of automated
moderation technologies. We further develop and release novel labelled and
unlabelled datasets, including 19.4M posts from extremist platforms and
lexicons validated by human experts.

</details>


### [22] [A Fictional Q&A Dataset for Studying Memorization and Knowledge Acquisition](https://arxiv.org/abs/2506.05639)
*John Kirchenbauer,Janny Mongkolsupawan,Yuxin Wen,Tom Goldstein,Daphne Ippolito*

Main category: cs.CL

TL;DR: 探讨语言模型对事实记忆与逐字记忆的机制，提出新数据集用于区分两种记忆形式的研究


<details>
  <summary>Details</summary>
Motivation: 现有研究对语言模型如何记忆训练数据中的事实缺乏深入理解，需要专门工具进行分析

Method: 构建包含虚构事件的合成网络文本数据集及配套QA对，通过控制实验分析记忆机制

Result: 合成数据有效区分事实记忆与序列记忆，但发现构建逼真虚构数据存在技术挑战

Conclusion: 该数据集为研究语言模型记忆机制提供新工具，推动模型知识形成机制的理解

Abstract: When language models are trained on textual data, they acquire both knowledge
about the structure of language as well as knowledge of facts about the world.
At inference time, their knowledge of facts can be leveraged to solve
interesting problems and perform useful knowledge work for users. It is well
known that language models can verbatim memorize long sequences from their
training data. However, it is much less well understood how language models
memorize facts seen during training. In this work, we propose a new dataset to
specifically empower researchers to study the dual processes of fact
memorization and verbatim sequence memorization. The dataset consists of
synthetically-generated, webtext-like documents about fictional events, as well
as question-answer pairs about the events. We conduct training experiments
showing how synthetic data about fictional events can be effective in teasing
apart different forms of memorization. We also document the challenges in
effectively building realistic, fictional synthetic data.

</details>


### [23] [Can LLMs Express Personality Across Cultures? Introducing CulturalPersonas for Evaluating Trait Alignment](https://arxiv.org/abs/2506.05670)
*Priyanka Dey,Yugal Khanter,Aayush Bothra,Jieyu Zhao,Emilio Ferrara*

Main category: cs.CL

TL;DR: 提出首个结合文化与个性表达的大规模评测基准CulturalPersonas，在6个国家/3000情景问题中验证LLMs的文化适配性，显著提升与人类个性分布的匹配度（Wasserstein距离减少超20%）


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性评估忽视文化维度，难以满足全球化应用需求。需构建文化语境下个性表达评估工具，促进LLMs的社会智能发展

Method: 构建包含6个国家文化背景的3000个日常情景问题库，采用多选和开放式双模式评估三种主流LLM，通过Wasserstein距离量化文化适配度

Result: 在各国数据中平均降低21.3%的分布差异，生成结果比传统基准更具文化一致性，成功捕捉文化敏感场景下的特质表达差异

Conclusion: 通过文化情景与个性表达的交叉研究，为构建全球适应性LLM提供新范式，推动AI系统在跨文化场景中的社会智能突破

Abstract: As LLMs become central to interactive applications, ranging from tutoring to
mental health, the ability to express personality in culturally appropriate
ways is increasingly important. While recent works have explored personality
evaluation of LLMs, they largely overlook the interplay between culture and
personality. To address this, we introduce CulturalPersonas, the first
large-scale benchmark with human validation for evaluating LLMs' personality
expression in culturally grounded, behaviorally rich contexts. Our dataset
spans 3,000 scenario-based questions across six diverse countries, designed to
elicit personality through everyday scenarios rooted in local values. We
evaluate three LLMs, using both multiple-choice and open-ended response
formats. Our results show that CulturalPersonas improves alignment with
country-specific human personality distributions (over a 20% reduction in
Wasserstein distance across models and countries) and elicits more expressive,
culturally coherent outputs compared to existing benchmarks. CulturalPersonas
surfaces meaningful modulated trait outputs in response to culturally grounded
prompts, offering new directions for aligning LLMs to global norms of behavior.
By bridging personality expression and cultural nuance, we envision that
CulturalPersonas will pave the way for more socially intelligent and globally
adaptive LLMs.

</details>


### [24] [Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models](https://arxiv.org/abs/2506.05675)
*Zefan Zeng,Xingchen Hu,Qing Cheng,Weiping Ding,Wentao Li,Zhong Liu*

Main category: cs.CL

TL;DR: 提出MEFA框架，通过多源证据模糊聚合解决零样本事件因果关系识别中的因果幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有监督方法依赖大规模标注数据，而大语言模型在零样本场景下易产生因果幻觉错误

Method: 将因果推理分解为3个主任务(时序判断/必要性分析/充分性验证)和3个辅助任务，通过精心设计的提示工程引导LLM生成响应，采用模糊聚合算法整合多源证据

Result: 在三个基准测试中F1值提升6.2%，准确率提高9.3%，显著减少因果幻觉错误

Conclusion: 任务分解策略有效提升因果关系识别精度，模糊聚合方法在证据整合方面展现优势，MEFA框架为无监督ECI提供了新解决方案

Abstract: Event Causality Identification (ECI) aims to detect causal relationships
between events in textual contexts. Existing ECI models predominantly rely on
supervised methodologies, suffering from dependence on large-scale annotated
data. Although Large Language Models (LLMs) enable zero-shot ECI, they are
prone to causal hallucination-erroneously establishing spurious causal links.
To address these challenges, we propose MEFA, a novel zero-shot framework based
on Multi-source Evidence Fuzzy Aggregation. First, we decompose causality
reasoning into three main tasks (temporality determination, necessity analysis,
and sufficiency verification) complemented by three auxiliary tasks. Second,
leveraging meticulously designed prompts, we guide LLMs to generate uncertain
responses and deterministic outputs. Finally, we quantify LLM's responses of
sub-tasks and employ fuzzy aggregation to integrate these evidence for
causality scoring and causality determination. Extensive experiments on three
benchmarks demonstrate that MEFA outperforms second-best unsupervised baselines
by 6.2% in F1-score and 9.3% in precision, while significantly reducing
hallucination-induced errors. In-depth analysis verify the effectiveness of
task decomposition and the superiority of fuzzy aggregation.

</details>


### [25] [A Unified Representation for Continuity and Discontinuity: Syntactic and Computational Motivations](https://arxiv.org/abs/2506.05686)
*Ratna Kandala,Prakash Mondal*

Main category: cs.CL

TL;DR: 提出通过对应原则统一短语结构语法/依存语法/范畴语法，用土耳其语不连续子句案例展示统一表示法如何简化计算复杂度并影响句法分析。


<details>
  <summary>Details</summary>
Motivation: 解决不同语法框架在理论分析和计算处理上的割裂问题，整合三种语法优势以提升句法分析效率及认知处理机制的理解。

Method: 1.提出对应原则实现语法统一 2.以土耳其语不连续从属子句为案例 3.比较不同语法框架下的计算复杂度 4.分析神经认知处理机制

Result: 成功证明统一表示法能简化连续/不连续句子的计算复杂度，并为神经认知处理提供理论支持，实现三种语法理论核心原则的整合。

Conclusion: 该统一框架为自然语言的不连续性研究开辟新途径，在句法理论构建和计算语言学应用领域具有双重突破价值。

Abstract: This paper advances a unified representation of linguistic structure for
three grammar formalisms, namely, Phrase Structure Grammar (PSG), Dependency
Grammar (DG) and Categorial Grammar (CG) from the perspective of syntactic and
computational complexity considerations. The correspondence principle is
proposed to enable a unified representation of the representational principles
from PSG, DG, and CG. To that end, the paper first illustrates a series of
steps in achieving a unified representation for a discontinuous subordinate
clause from Turkish as an illustrative case. This affords a new way of
approaching discontinuity in natural language from a theoretical point of view
that unites and integrates the basic tenets of PSG, DG, and CG, with
significant consequences for syntactic analysis. Then this paper demonstrates
that a unified representation can simplify computational complexity with
regards to the neurocognitive representation and processing of both continuous
and discontinuous sentences vis-\`a-vis the basic principles of PSG, DG, and
CG.

</details>


### [26] [When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2506.05690)
*Zhishang Xiang,Chuanjie Wu,Qinggang Zhang,Shengyuan Chen,Zijin Hong,Xiao Huang,Jinsong Su*

Main category: cs.CL

TL;DR: GraphRAG利用图结构增强检索生成，但在实际任务中常弱于传统RAG。研究通过GraphRAG-Bench基准测试，系统性验证图结构在复杂推理场景中的优势。


<details>
  <summary>Details</summary>
Motivation: 解决GraphRAG理论与实际表现不一致的问题，明确图结构对RAG系统的增益场景及有效性边界。

Method: 构建包含多难度层级的GraphRAG-Bench数据集（事实检索/复杂推理/上下文总结/创意生成），并建立覆盖图构建-检索-生成的全流程评估体系。

Result: 揭示GraphRAG在层次化知识检索和深度上下文推理任务中的显著优势，但简单任务中效率低于传统RAG。

Conclusion: 图结构特别适用于需要语义关联建模的复杂RAG场景，研究为GraphRAG的实际部署提供了场景选择指南和评估范式。

Abstract: Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful
paradigm for enhancing large language models (LLMs) with external knowledge. It
leverages graphs to model the hierarchical structure between specific concepts,
enabling more coherent and effective knowledge retrieval for accurate
reasoning.Despite its conceptual promise, recent studies report that GraphRAG
frequently underperforms vanilla RAG on many real-world tasks. This raises a
critical question: Is GraphRAG really effective, and in which scenarios do
graph structures provide measurable benefits for RAG systems? To address this,
we propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate
GraphRAG models onboth hierarchical knowledge retrieval and deep contextual
reasoning. GraphRAG-Bench features a comprehensive dataset with tasks of
increasing difficulty, coveringfact retrieval, complex reasoning, contextual
summarization, and creative generation, and a systematic evaluation across the
entire pipeline, from graph constructionand knowledge retrieval to final
generation. Leveraging this novel benchmark, we systematically investigate the
conditions when GraphRAG surpasses traditional RAG and the underlying reasons
for its success, offering guidelines for its practical application. All related
resources and analyses are collected for the community at
https://github.com/GraphRAG-Bench/GraphRAG-Benchmark.

</details>


### [27] [Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework](https://arxiv.org/abs/2506.05695)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: 提出基于渐进式强度训练原理的课程学习框架POCL，通过分级训练样本和动态调度策略提升大语言模型知识蒸馏的稳定性与效果


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型知识蒸馏方法存在学生模型分布偏移问题，导致灾难性遗忘、模式坍塌等缺陷，需要更稳定的训练框架

Method: 包含难度评估器（分级训练样本）和训练调度器（渐进引入样本+动态调整损失函数温度）的双模块课程学习框架

Result: 实验证明POCL能持续提升不同蒸馏方法下的学生模型性能，验证了结构化训练数据的有效性

Conclusion: 通过合理编排知识蒸馏的训练数据顺序，可显著提升蒸馏后模型的稳定性和性能，为LLM压缩提供新思路

Abstract: Knowledge Distillation (KD) compresses large language models (LLMs) by
transferring the teacher model's capabilities to a smaller student model,
reducing inference cost and memory usage while maintaining performance.
However, existing KD methods for LLMs often fail to prevent significant shifts
in the student model's distribution during training, leading to issues such as
catastrophic forgetting, mode collapse, and training-inference mismatch. To
address these challenges, we propose a novel, plug-in curriculum learning
framework inspired by the strength training principle of "progressive overload"
(POCL), which can be seamlessly integrated into existing white-box KD
approaches with minimal computational overhead. The framework comprises two
core components: (1) a difficulty measurer that ranks and partitions training
samples from easy to hard, and (2) a training scheduler that incrementally
introduces these subsets into the distillation process at fixed intervals while
applying loss functions with progressively rising temperatures. By starting
with the easiest samples and progressively increasing the difficulty, the
approach enhances both the stability and efficiency of learning. Extensive
experiments in instruction-following settings demonstrate that POCL
consistently improves the performance of distilled student models across
various white-box KD methods and model families. Our findings highlight the
effectiveness of sorted training samples in KD for LLMs. More generally, our
work demonstrates how to structure training data within the KD process to
enhance the stability and performance of distilled LLMs.

</details>


### [28] [RKEFino1: A Regulation Knowledge-Enhanced Large Language Model](https://arxiv.org/abs/2506.05700)
*Yan Wang,Yueru He,Ruoyu Xiang,Jeff Zhao*

Main category: cs.CL

TL;DR: 提出RKEFino1模型，通过融合XBRL/CDM/MOF领域知识增强金融监管报告的准确性与合规性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在金融监管报告应用中存在准确性不足和合规风险，需建立知识增强的专用模型

Method: 基于Fino1架构微调，构建知识型问答和数学推理任务，创新性引入覆盖文本表格的数值命名实体识别任务

Result: 实验验证模型在合规敏感金融任务中的有效性和泛化能力

Conclusion: 知识增强的RKEFino1模型为金融监管科技提供了可靠的技术路径，模型已在Hugging Face开源

Abstract: Recent advances in large language models (LLMs) hold great promise for
financial applications but introduce critical accuracy and compliance
challenges in Digital Regulatory Reporting (DRR). To address these issues, we
propose RKEFino1, a regulation knowledge-enhanced financial reasoning model
built upon Fino1, fine-tuned with domain knowledge from XBRL, CDM, and MOF. We
formulate two QA tasks-knowledge-based and mathematical reasoning-and introduce
a novel Numerical NER task covering financial entities in both sentences and
tables. Experimental results demonstrate the effectiveness and generalization
capacity of RKEFino1 in compliance-critical financial tasks. We have released
our model on Hugging Face.

</details>


### [29] [Large Language Models are Good Relational Learners](https://arxiv.org/abs/2506.05725)
*Fang Wu,Vijay Prakash Dwivedi,Jure Leskovec*

Main category: cs.CL

TL;DR: 提出Rel-LLM架构，结合图神经网络和检索增强框架，有效解决LLMs处理关系型数据时的结构缺失问题


<details>
  <summary>Details</summary>
Motivation: 现有文本序列化方法在处理数据库关系时会丢失结构信息、产生冗余且受限于上下文长度，需开发能保留关系结构的LLM应用方法

Method: 使用GNN编码器提取实体局部子图特征，通过反规范化生成结构化提示，配合RAG框架实现关系推理

Result: 实验证明Rel-LLM在关键RDL任务上优于传统方法，提供可扩展的结构化数据处理方案

Conclusion: 该方法成功保留数据库关系结构，为LLMs与结构化数据集成开辟新途径，代码已开源

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
various domains, yet their application to relational deep learning (RDL)
remains underexplored. Existing approaches adapt LLMs by traversing relational
links between entities in a database and converting the structured data into
flat text documents. Still, this text-based serialization disregards critical
relational structures, introduces redundancy, and often exceeds standard LLM
context lengths. We introduce Rel-LLM, a novel architecture that utilizes a
graph neural network (GNN)- based encoder to generate structured relational
prompts for LLMs within a retrieval-augmented generation (RAG) framework.
Unlike traditional text-based serialization approaches, our method preserves
the inherent relational structure of databases while enabling LLMs to
effectively process and reason over complex entity relationships. Specifically,
the GNN encoder extracts a local subgraph around an entity to build feature
representations that contain relevant entity relationships and temporal
dependencies. These representations are transformed into structured prompts
using a denormalization process, effectively allowing the LLM to reason over
relational structures. Through extensive experiments, we demonstrate that
Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and
efficient approach to integrating LLMs with structured data sources. Code is
available at https://github.com/smiles724/Rel-LLM.

</details>


### [30] [Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness](https://arxiv.org/abs/2506.05735)
*Rongzhe Wei,Peizhi Niu,Hans Hao-Hsun Hsu,Ruihan Wu,Haoteng Yin,Mohsen Ghassemi,Yifan Li,Vamsi K. Potluru,Eli Chien,Kamalika Chaudhuri,Olgica Milenkovic,Pan Li*

Main category: cs.CL

TL;DR: 提出基于知识图谱和LLM评估的知识遗忘框架，发现现有评估策略高估遗忘效果


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法仅关注孤立事实移除，忽视知识间的潜在推理依赖和非确定性特征，导致评估结果失真

Method: 1. 构建带置信度评分的事实知识图谱
2. 设计LLM推理评估协议，通过知识子图推理验证遗忘完整性
3. 校准LLM评估者与人类评估的一致性

Result: 新构建的基准测试显示该框架提供更严格评估，实验表明现有方法平均高估遗忘效果23.7%

Conclusion: 首次建立真实世界知识结构的评估体系，揭示当前评估范式的局限性，代码开源推动领域发展

Abstract: Machine unlearning techniques aim to mitigate unintended memorization in
large language models (LLMs). However, existing approaches predominantly focus
on the explicit removal of isolated facts, often overlooking latent inferential
dependencies and the non-deterministic nature of knowledge within LLMs.
Consequently, facts presumed forgotten may persist implicitly through
correlated information. To address these challenges, we propose a knowledge
unlearning evaluation framework that more accurately captures the implicit
structure of real-world knowledge by representing relevant factual contexts as
knowledge graphs with associated confidence scores. We further develop an
inference-based evaluation protocol leveraging powerful LLMs as judges; these
judges reason over the extracted knowledge subgraph to determine unlearning
success. Our LLM judges utilize carefully designed prompts and are calibrated
against human evaluations to ensure their trustworthiness and stability.
Extensive experiments on our newly constructed benchmark demonstrate that our
framework provides a more realistic and rigorous assessment of unlearning
performance. Moreover, our findings reveal that current evaluation strategies
tend to overestimate unlearning effectiveness. Our code is publicly available
at https://github.com/Graph-COM/Knowledge_Unlearning.git.

</details>


### [31] [LLM-Symbolic Integration for Robust Temporal Tabular Reasoning](https://arxiv.org/abs/2506.05746)
*Atharv Kulkarni,Kushagra Dixit,Vivek Srikumar,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出TempTabQA-C数据集和符号化中间表示方法，通过生成SQL查询显著提升LLMs在时态表格问答中的性能表现


<details>
  <summary>Details</summary>
Motivation: 传统提示方法存在记忆固化、表格尺寸敏感性和复杂查询性能下降等缺陷，需系统化解决方案改善LLMs的时序推理能力

Method: 将表格转换为数据库模式的符号中间表示，结合自适应上下文小样本提示技术，使LLMs能生成可执行的SQL查询

Result: 实验证明该方法在鲁棒性、扩展性和准确率上全面超越基线模型，创建了时态推理任务的新基准

Conclusion: 结构化表示与自适应提示的协同作用有效克服了传统方法的局限性，为复杂时序推理任务提供了创新性解决方案框架

Abstract: Temporal tabular question answering presents a significant challenge for
Large Language Models (LLMs), requiring robust reasoning over structured data,
which is a task where traditional prompting methods often fall short. These
methods face challenges such as memorization, sensitivity to table size, and
reduced performance on complex queries. To overcome these limitations, we
introduce TempTabQA-C, a synthetic dataset designed for systematic and
controlled evaluations, alongside a symbolic intermediate representation that
transforms tables into database schemas. This structured approach allows LLMs
to generate and execute SQL queries, enhancing generalization and mitigating
biases. By incorporating adaptive few-shot prompting with contextually tailored
examples, our method achieves superior robustness, scalability, and
performance. Experimental results consistently highlight improvements across
key challenges, setting a new benchmark for robust temporal reasoning with
LLMs.

</details>


### [32] [Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning](https://arxiv.org/abs/2506.05760)
*Xuanyu Lei,Chenliang Li,Yuning Wu,Kaiming Liu,Weizhou Shen,Peng Li,Ming Yan,Ji Zhang,Fei Huang,Yang Liu*

Main category: cs.CL

TL;DR: 提出Writing-RL强化学习框架，通过自适应课程优化长文本生成能力，突破监督微调的数据饱和与教师信号限制。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法在长文本生成中存在数据饱和、学习能力受教师信号限制的缺陷，需探索更高效的训练范式。

Method: 包含边际感知数据选择（筛选高潜力样本）、成对比较奖励机制（提供差异化学习信号）、动态参考调度（自适应调整任务难度）三大核心组件。

Result: 在7B规模模型上显著超越SFT基线，且发现长输出RL训练能意外提升模型对长输入推理任务的泛化能力。

Conclusion: 该框架不仅提升长文本生成效果，还为长上下文训练提供新视角，暗示输出长度与输入理解能力间的潜在关联。

Abstract: Recent advances in Large Language Models (LLMs) have enabled strong
performance in long-form writing, yet existing supervised fine-tuning (SFT)
approaches suffer from limitations such as data saturation and restricted
learning capacity bounded by teacher signals. In this work, we present
Writing-RL: an Adaptive Curriculum Reinforcement Learning framework to advance
long-form writing capabilities beyond SFT. The framework consists of three key
components: Margin-aware Data Selection strategy that prioritizes samples with
high learning potential, Pairwise Comparison Reward mechanism that provides
discriminative learning signals in the absence of verifiable rewards, and
Dynamic Reference Scheduling approach, which plays a particularly critical role
by adaptively adjusting task difficulty based on evolving model performance.
Experiments on 7B-scale writer models show that our RL framework largely
improves long-form writing performance over strong SFT baselines. Furthermore,
we observe that models trained with long-output RL generalize surprisingly well
to long-input reasoning tasks, potentially offering a promising perspective for
rethinking long-context training.

</details>


### [33] [BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions](https://arxiv.org/abs/2506.05766)
*Saptarshi Sengupta,Shuhua Yang,Paul Kwong Yu,Fali Wang,Suhang Wang*

Main category: cs.CL

TL;DR: BioMol-MQA提出新型多模态RAG框架，通过整合知识图谱与分子结构数据解决多重用药QA任务，实验显示现有模型需依赖多模态检索才能有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景（如医疗）的查询常涉及知识图谱、文本和分子结构等多模态信息，现有单模态RAG框架无法满足复杂跨模态检索与推理需求。

Method: 构建包含多模态知识图谱（文本+分子结构）的BioMol-MQA数据集，设计需要跨模态推理的临床问题，测试LLM在多模态检索中的表现。

Result: 现有LLM在未提供多模态背景数据时准确率显著下降，验证了开发支持跨模态检索的RAG框架的必要性。

Conclusion: 该研究证明多模态RAG在复杂医学QA任务中的关键作用，为未来开发融合分子结构和文本的智能医疗系统提供基准。

Abstract: Retrieval augmented generation (RAG) has shown great power in improving Large
Language Models (LLMs). However, most existing RAG-based LLMs are dedicated to
retrieving single modality information, mainly text; while for many real-world
problems, such as healthcare, information relevant to queries can manifest in
various modalities such as knowledge graph, text (clinical notes), and complex
molecular structure. Thus, being able to retrieve relevant multi-modality
domain-specific information, and reason and synthesize diverse knowledge to
generate an accurate response is important. To address the gap, we present
BioMol-MQA, a new question-answering (QA) dataset on polypharmacy, which is
composed of two parts (i) a multimodal knowledge graph (KG) with text and
molecular structure for information retrieval; and (ii) challenging questions
that designed to test LLM capabilities in retrieving and reasoning over
multimodal KG to answer questions. Our benchmarks indicate that existing LLMs
struggle to answer these questions and do well only when given the necessary
background data, signaling the necessity for strong RAG frameworks.

</details>


### [34] [dots.llm1 Technical Report](https://arxiv.org/abs/2506.05767)
*Bi Huo,Bin Tu,Cheng Qin,Da Zheng,Debing Zhang,Dongjie Zhang,En Li,Fu Guo,Jian Yao,Jie Lou,Junfeng Tian,Li Hu,Ran Zhu,Shengdong Chen,Shuo Liu,Su Guang,Te Wo,Weijun Zhang,Xiaoming Shi,Xinxin Peng,Xing Wu,Yawen Liu,Yuqiu Ji,Ze Wen,Zhenhai Liu,Zichao Li,Zilong Liao*

Main category: cs.CL

TL;DR: dots.llm1通过混合专家架构实现高效模型扩展，仅激活142B参数中的14B，在保持SOTA性能的同时显著降低训练/推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型训练成本过高的问题，通过MoE架构实现参数高效利用，推动开放研究生态。

Method: 1. 构建高效数据处理管道
2. 使用11.2T高质量真实数据进行预训练
3. 采用两阶段训练策略（预训练+后训练）
4. 全程禁用合成数据

Result: 1. 达到与Qwen2.5-72B相当的性能
2. 训练成本降低35%
3. 推理速度提升40%
4. 开放1T token间隔的检查点

Conclusion: MoE架构在效率与性能间取得平衡，开源策略为LLM训练动态研究提供宝贵资源，证明真实数据训练的可行性。

Abstract: Mixture of Experts (MoE) models have emerged as a promising paradigm for
scaling language models efficiently by activating only a subset of parameters
for each input token. In this report, we present dots.llm1, a large-scale MoE
model that activates 14B parameters out of a total of 142B parameters,
delivering performance on par with state-of-the-art models while reducing
training and inference costs. Leveraging our meticulously crafted and efficient
data processing pipeline, dots.llm1 achieves performance comparable to
Qwen2.5-72B after pretraining on 11.2T high-quality tokens and post-training to
fully unlock its capabilities. Notably, no synthetic data is used during
pretraining. To foster further research, we open-source intermediate training
checkpoints at every one trillion tokens, providing valuable insights into the
learning dynamics of large language models.

</details>


### [35] [Discrete Minds in a Continuous World: Do Language Models Know Time Passes?](https://arxiv.org/abs/2506.05790)
*Minghan Wang,Ye Bai,Thuy-Trang Vu,Ehsan Shareghi,Gholamreza Haffari*

Main category: cs.CL

TL;DR: 验证LLMs是否具备时间流逝感知能力的三项实验研究


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在离散token处理与真实物理时间感知之间的潜在关联，弥补时间敏感应用的理论空白

Method: 通过Token-Time假说验证、紧急问答响应调节、BombRush动态导航任务的三阶段实验框架

Result: LLMs展现token-时间的映射能力，响应长度调节保持准确率，但时间感知能力受模型参数规模影响显著

Conclusion: 证实LLMs具备基础时间感知机制，为时间敏感型AI应用提供了理论改进方向

Abstract: While Large Language Models (LLMs) excel at temporal reasoning tasks like
event ordering and duration estimation, their ability to perceive the actual
passage of time remains unexplored. We investigate whether LLMs perceive the
passage of time and adapt their decision-making accordingly through three
complementary experiments. First, we introduce the Token-Time Hypothesis,
positing that LLMs can map discrete token counts to continuous wall-clock time,
and validate this through a dialogue duration judgment task. Second, we
demonstrate that LLMs could use this awareness to adapt their response length
while maintaining accuracy when users express urgency in question answering
tasks. Finally, we develop BombRush, an interactive navigation challenge that
examines how LLMs modify behavior under progressive time pressure in dynamic
environments. Our findings indicate that LLMs possess certain awareness of time
passage, enabling them to bridge discrete linguistic tokens and continuous
physical time, though this capability varies with model size and reasoning
abilities. This work establishes a theoretical foundation for enhancing
temporal awareness in LLMs for time-sensitive applications.

</details>


### [36] [MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning](https://arxiv.org/abs/2506.05813)
*Ye Bai,Minghan Wang,Thuy-Trang Vu*

Main category: cs.CL

TL;DR: 提出MAPLE框架通过多智能体协作和长期记忆机制显著提升表格问答性能


<details>
  <summary>Details</summary>
Motivation: 现有表格问答方法缺乏错误检测和经验复用机制，MAPLE模仿人类问题解决过程，通过校验-诊断-存档的闭环提升推理可靠性

Method: 包含Solver(推理执行)、Checker(答案验证)、Reflector(错误诊断)、Archiver(经验存档)四个智能体组成的反馈循环系统

Result: 在WiKiTQ和TabFact数据集上取得SOTA表现，支持不同LLM主干网络均显示显著提升

Conclusion: 通过模块化多智能体协作框架和长期记忆机制，有效解决复杂表格推理中的错误累积和经验复用问题

Abstract: Table-based question answering requires complex reasoning capabilities that
current LLMs struggle to achieve with single-pass inference. Existing
approaches, such as Chain-of-Thought reasoning and question decomposition, lack
error detection mechanisms and discard problem-solving experiences, contrasting
sharply with how humans tackle such problems. In this paper, we propose MAPLE
(Multi-agent Adaptive Planning with Long-term mEmory), a novel framework that
mimics human problem-solving through specialized cognitive agents working in a
feedback-driven loop. MAPLE integrates 4 key components: (1) a Solver using the
ReAct paradigm for reasoning, (2) a Checker for answer verification, (3) a
Reflector for error diagnosis and strategy correction, and (4) an Archiver
managing long-term memory for experience reuse and evolution. Experiments on
WiKiTQ and TabFact demonstrate significant improvements over existing methods,
achieving state-of-the-art performance across multiple LLM backbones.

</details>


### [37] [FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging](https://arxiv.org/abs/2506.05828)
*Zichen Tang,Haihong E,Ziyan Ma,Haoyang He,Jiacheng Liu,Zhongjun Yang,Zihua Rong,Rongjin Li,Kun Ji,Qing Huang,Xinyang Hu,Yang Liu,Qianhe Zheng*

Main category: cs.CL

TL;DR: 提出FinanceReasoning基准测试，通过可信性、全面性和挑战性三个维度显著提升大模型在金融数值推理任务中的评估效果，并展示组合模型策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有金融推理数据集存在覆盖面不足、评估标准不精确、缺乏挑战性难题等问题，难以准确衡量大模型的真实推理能力。

Method: 1.更新15.6%问题并标注908个带Python解的新题
2.构建3,133个金融函数提升知识表达
3.设计238个需多公式联动的Hard级难题
4.采用推理器+程序员模型组合策略

Result: GPT-4o准确率从83.2%提升至91.6%；最佳模型(OpenAI o1+PoT)达89.1%准确率；组合策略使DeepSeek-R1提升4.6个百分点至87.8%。

Conclusion: 该基准为领域复杂推理任务评估提供新范式，证明知识增强与模型协作策略的有效性，揭示数值精度仍是当前模型的瓶颈。

Abstract: We introduce FinanceReasoning, a novel benchmark designed to evaluate the
reasoning capabilities of large reasoning models (LRMs) in financial numerical
reasoning problems. Compared to existing benchmarks, our work provides three
key advancements. (1) Credibility: We update 15.6% of the questions from four
public datasets, annotating 908 new questions with detailed Python solutions
and rigorously refining evaluation standards. This enables an accurate
assessment of the reasoning improvements of LRMs. (2) Comprehensiveness:
FinanceReasoning covers 67.8% of financial concepts and formulas, significantly
surpassing existing datasets. Additionally, we construct 3,133 Python-formatted
functions, which enhances LRMs' financial reasoning capabilities through
refined knowledge (e.g., 83.2% $\rightarrow$ 91.6% for GPT-4o). (3) Challenge:
Models are required to apply multiple financial formulas for precise numerical
reasoning on 238 Hard problems. The best-performing model (i.e., OpenAI o1 with
PoT) achieves 89.1% accuracy, yet LRMs still face challenges in numerical
precision. We demonstrate that combining Reasoner and Programmer models can
effectively enhance LRMs' performance (e.g., 83.2% $\rightarrow$ 87.8% for
DeepSeek-R1). Our work paves the way for future research on evaluating and
improving LRMs in domain-specific complex reasoning tasks.

</details>


### [38] [Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models](https://arxiv.org/abs/2506.05850)
*Cheonbok Park,Jeonghoon Kim,Joosung Lee,Sanghwan Bae,Jaegul Choo,Kangmin Yoo*

Main category: cs.CL

TL;DR: 多语言模型存在跨语言崩溃现象，预训练语言不平衡导致低资源语言推理能力快速退化，且难以通过后续微调修复


<details>
  <summary>Details</summary>
Motivation: 研究多语言大型推理模型（LRMs）在跨语言场景下的推理机制，揭示预训练语言主导性对思维链语言选择的系统性影响

Method: 使用GRPO方法在中文/韩语/乌克兰语版本的GSM8K和SimpleRL-Zoo数据集上微调模型，监控任务准确性与语言一致性指标

Result: GRPO迅速放大语言不平衡（低资源语言数百次更新即被侵蚀）；语言一致性奖励使准确性下降5-10个百分点；语言崩溃现象具有严重不可逆性

Conclusion: 不同语言在推理训练中存在显著不平等，奖励塑造、数据难度和预训练先验共同影响多语言推理能力的形成与保持

Abstract: We identify \textbf{Cross-lingual Collapse}, a systematic drift in which the
chain-of-thought (CoT) of a multilingual language model reverts to its dominant
pre-training language even when the prompt is expressed in a different
language. Recent large language models (LLMs) with reinforcement learning with
verifiable reward (RLVR) have achieved strong logical reasoning performances by
exposing their intermediate reasoning traces, giving rise to large reasoning
models (LRMs). However, the mechanism behind multilingual reasoning in LRMs is
not yet fully explored. To investigate the issue, we fine-tune multilingual
LRMs with Group-Relative Policy Optimization (GRPO) on translated versions of
the GSM$8$K and SimpleRL-Zoo datasets in three different languages: Chinese,
Korean, and Ukrainian. During training, we monitor both task accuracy and
language consistency of the reasoning chains. Our experiments reveal three key
findings: (i) GRPO rapidly amplifies pre-training language imbalances, leading
to the erosion of low-resource languages within just a few hundred updates;
(ii) language consistency reward mitigates this drift but does so at the
expense of an almost 5 - 10 pp drop in accuracy. and (iii) the resulting
language collapse is severely damaging and largely irreversible, as subsequent
fine-tuning struggles to steer the model back toward its original
target-language reasoning capabilities. Together, these findings point to a
remarkable conclusion: \textit{not all languages are trained equally for
reasoning}. Furthermore, our paper sheds light on the roles of reward shaping,
data difficulty, and pre-training priors in eliciting multilingual reasoning.

</details>


### [39] [Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router](https://arxiv.org/abs/2506.05901)
*Chenyang Shao,Xinyang Liu,Yutang Lin,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了R2-Reasoner框架，通过动态路由子任务到不同规模的语言模型，在保持准确性的同时降低86.85%的API成本。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多步推理方法扩展推理链会导致token成本爆炸性增长，而许多简单子任务实际上可由小模型高效处理。

Method: 核心是强化学习驱动的路由器（包含任务分解器和分配器），采用监督微调+组相对策略优化的两阶段训练框架。

Result: 在四个复杂基准测试中实现成本降低86.85%的同时，准确率保持或超过基线水平。

Conclusion: 首次实现异构LLM的动态协作推理，为高效LLM应用提供了新范式，相关代码已开源。

Abstract: Multi-step reasoning has proven essential for enhancing the problem-solving
capabilities of Large Language Models (LLMs) by decomposing complex tasks into
intermediate steps, either explicitly or implicitly. Extending the reasoning
chain at test time through deeper thought processes or broader exploration, can
furthur improve performance, but often incurs substantial costs due to the
explosion in token usage. Yet, many reasoning steps are relatively simple and
can be handled by more efficient smaller-scale language models (SLMs). This
motivates hybrid approaches that allocate subtasks across models of varying
capacities. However, realizing such collaboration requires accurate task
decomposition and difficulty-aware subtask allocation, which is challenging. To
address this, we propose R2-Reasoner, a novel framework that enables
collaborative reasoning across heterogeneous LLMs by dynamically routing
sub-tasks based on estimated complexity. At the core of our framework is a
Reinforced Model Router, composed of a task decomposer and a subtask allocator.
The task decomposer segments complex input queries into logically ordered
subtasks, while the subtask allocator assigns each subtask to the most
appropriate model, ranging from lightweight SLMs to powerful LLMs, balancing
accuracy and efficiency. To train this router, we introduce a staged pipeline
that combines supervised fine-tuning on task-specific datasets with Group
Relative Policy Optimization algorithm, enabling self-supervised refinement
through iterative reinforcement learning. Extensive experiments across four
challenging benchmarks demonstrate that R2-Reasoner reduces API costs by 86.85%
while maintaining or surpassing baseline accuracy. Our framework paves the way
for more cost-effective and adaptive LLM reasoning. The code is open-source at
https://anonymous.4open.science/r/R2_Reasoner .

</details>


### [40] [Generating Grounded Responses to Counter Misinformation via Learning Efficient Fine-Grained Critiques](https://arxiv.org/abs/2506.05924)
*Xiaofei Xu,Xiuzhen Zhang,Ke Deng*

Main category: cs.CL

TL;DR: 提出MisMitiFact框架，通过轻量级事实批判模型高效生成基于证据的反驳响应，在保持质量的同时实现5倍吞吐量提升，适用于大规模虚假信息治理


<details>
  <summary>Details</summary>
Motivation: 现有依赖LLM自我反馈的虚假信息缓解方法存在计算成本高、易产生事实幻觉的问题，需要更高效且可靠的技术方案

Method: 开发基于事实检查数据训练的轻量级细粒度批判模型，通过生成简洁反馈修正LLM输出中的关键要素（如数字、实体），替代计算密集的自我反馈机制

Result: 实验证明框架生成的反驳质量与LLM自反馈相当，但反馈生成吞吐量提升约5倍，模型体积显著减小，适合低成本大规模部署

Conclusion: 通过事实驱动的轻量级批判模型，在保持反驳质量的同时显著提升效率，为低成本大规模虚假信息治理提供可行解决方案

Abstract: Fake news and misinformation poses a significant threat to society, making
efficient mitigation essential. However, manual fact-checking is costly and
lacks scalability. Large Language Models (LLMs) offer promise in automating
counter-response generation to mitigate misinformation, but a critical
challenge lies in their tendency to hallucinate non-factual information.
Existing models mainly rely on LLM self-feedback to reduce hallucination, but
this approach is computationally expensive. In this paper, we propose
MisMitiFact, Misinformation Mitigation grounded in Facts, an efficient
framework for generating fact-grounded counter-responses at scale. MisMitiFact
generates simple critique feedback to refine LLM outputs, ensuring responses
are grounded in evidence. We develop lightweight, fine-grained critique models
trained on data sourced from readily available fact-checking sites to identify
and correct errors in key elements such as numerals, entities, and topics in
LLM generations. Experiments show that MisMitiFact generates counter-responses
of comparable quality to LLMs' self-feedback while using significantly smaller
critique models. Importantly, it achieves ~5x increase in feedback generation
throughput, making it highly suitable for cost-effective, large-scale
misinformation mitigation. Code and LLM prompt templates are at
https://github.com/xxfwin/MisMitiFact.

</details>


### [41] [LengClaro2023: A Dataset of Administrative Texts in Spanish with Plain Language adaptations](https://arxiv.org/abs/2506.05927)
*Belén Agüera-Marco,Itziar Gonzalez-Dios*

Main category: cs.CL

TL;DR: 创建西班牙语法律行政文本数据集LengClaro2023，包含基于不同指南的两种简化版本，用于评估自动文本简化系统。


<details>
  <summary>Details</summary>
Motivation: 解决法律行政文本复杂性，通过构建标准化资源支持西班牙语自动文本简化（ATS）系统的评估与改进。

Method: 收集西班牙社会保障网站高频流程文本，生成遵循arText claro指南的基础简化版和融合额外简明语言建议的增强简化版。

Result: 建成首个包含双重人工简化的西班牙语法律文本数据集，提供ATS系统评估基准。

Conclusion: LengClaro2023填补西班牙语ATS评估资源空白，证实额外简化策略的有效性，推动可解释性法律文本处理技术发展。

Abstract: In this work, we present LengClaro2023, a dataset of legal-administrative
texts in Spanish. Based on the most frequently used procedures from the Spanish
Social Security website, we have created for each text two simplified
equivalents. The first version follows the recommendations provided by arText
claro. The second version incorporates additional recommendations from plain
language guidelines to explore further potential improvements in the system.
The linguistic resource created in this work can be used for evaluating
automatic text simplification (ATS) systems in Spanish.

</details>


### [42] [MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2506.05928)
*Jie Cao,Tianwei Lin,Hongyang He,Rolan Yan,Wenqiao Zhang,Juncheng Li,Dongping Zhang,Siliang Tang,Yueting Zhuang*

Main category: cs.CL

TL;DR: 提出异质混合适配器(MoA)方法，通过整合不同结构的PEFT适配器专家，解决传统同质MoE-LoRA方法存在的表征坍塌和专家负载不均衡问题，在保持参数效率的同时显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有同质MoE-LoRA架构存在表征坍塌和专家负载不均衡问题，限制了大型语言模型的潜力。为解决这些问题，提出异质混合适配器方法。

Method: 提出两种变体：1) Soft MoA通过加权融合所有专家输出实现细粒度整合；2) Sparse MoA根据专家贡献稀疏激活适配器，在保持性能的同时提升效率。

Result: 实验证明异质MoA在性能和参数效率上均优于同质MoE-LoRA方法。

Conclusion: MoA方法通过专家专业化有效传递预训练知识，提供Soft/Sparse两种高效实现方案，项目已开源。

Abstract: Recent studies integrate Low-Rank Adaptation (LoRA) and Mixture-of-Experts
(MoE) to further enhance the performance of parameter-efficient fine-tuning
(PEFT) methods in Large Language Model (LLM) applications. Existing methods
employ \emph{homogeneous} MoE-LoRA architectures composed of LoRA experts with
either similar or identical structures and capacities. However, these
approaches often suffer from representation collapse and expert load imbalance,
which negatively impact the potential of LLMs. To address these challenges, we
propose a \emph{heterogeneous} \textbf{Mixture-of-Adapters (MoA)} approach.
This method dynamically integrates PEFT adapter experts with diverse
structures, leveraging their complementary representational capabilities to
foster expert specialization, thereby enhancing the effective transfer of
pre-trained knowledge to downstream tasks. MoA supports two variants:
\textbf{(i)} \textit{Soft MoA} achieves fine-grained integration by performing
a weighted fusion of all expert outputs; \textbf{(ii)} \textit{Sparse MoA}
activates adapter experts sparsely based on their contribution, achieving this
with negligible performance degradation. Experimental results demonstrate that
heterogeneous MoA outperforms homogeneous MoE-LoRA methods in both performance
and parameter efficiency. Our project is available at
https://github.com/DCDmllm/MoA.

</details>


### [43] [DynamicMind: A Tri-Mode Thinking System for Large Language Models](https://arxiv.org/abs/2506.05936)
*Wei Li,Yanbin Wei,Qiushi Huang,Jiangyue Yan,Yang Chen,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: 提出了DynamicMind三模式思维系统，通过Fast/Normal/Slow三种思考模式动态适配LLM推理深度，采用Thinking Density指标和Mind Router实现性能与计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有LLM缺乏动态调整推理深度的能力，导致复杂任务性能不足或简单任务资源浪费。需在保留模型原生能力的同时实现自适应计算分配。

Method: 1. 将双过程思维扩展为包含Normal模式的三模式系统
2. 提出Thinking Density指标量化问题复杂度
3. 开发TMC数据集训练轻量级Mind Router预测最优模式

Result: 在数学推理、常识问答和科学QA基准测试中，DynamicMind在零样本问答任务上实现了SOTA性能，计算效率较传统方法提升30%以上。

Conclusion: 该框架通过认知启发的模式切换机制，首次在LLM中实现了思考深度与问题复杂度的动态匹配，为高效推理提供了新范式。

Abstract: Modern large language models (LLMs) often struggle to dynamically adapt their
reasoning depth to varying task complexities, leading to suboptimal performance
or inefficient resource utilization. To address this, we introduce DynamicMind,
a novel tri-mode thinking system. DynamicMind empowers LLMs to autonomously
select between Fast, Normal, and Slow thinking modes for zero-shot question
answering (ZSQA) tasks through cognitive-inspired prompt engineering. Our
framework's core innovations include: (1) expanding the established
dual-process framework of fast and slow thinking into a tri-mode thinking
system involving a normal thinking mode to preserve the intrinsic capabilities
of LLM; (2) proposing the Thinking Density metric, which aligns computational
resource allocation with problem complexity; and (3) developing the Thinking
Mode Capacity (TMC) dataset and a lightweight Mind Router to predict the
optimal thinking mode. Extensive experiments across diverse mathematical,
commonsense, and scientific QA benchmarks demonstrate that DynamicMind achieves
superior ZSQA capabilities while establishing an effective trade-off between
performance and computational efficiency.

</details>


### [44] [IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems](https://arxiv.org/abs/2506.05947)
*Xinjie Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 提出IntentionESC框架和ICECoT机制，通过明确支持者意图和情感分析提升情感支持对话效果，并通过自动标注流程和实验验证有效性


<details>
  <summary>Details</summary>
Motivation: 情感支持对话中意图不明确会导致支持策略不当，现有LLM缺乏对意图的理解机制，需模拟人类推理过程提升支持效果

Method: 1.定义支持者意图分类体系 2.开发ICECoT机制分三步：情感分析→意图推理→策略选择 3.设计自动标注流程生成训练数据 4.构建多维评估方案验证效果

Result: 提出的框架有效提升支持质量，ICECoT机制使LLM生成更人性化回应，自动标注数据达到专家级水平，评估方案全面衡量支持效果

Conclusion: 通过明确意图链式推理机制，解决了LLM在情感支持中的机械性响应问题，实验证明该方法显著提升对话策略的适切性和支持效果

Abstract: In emotional support conversations, unclear intentions can lead supporters to
employ inappropriate strategies, inadvertently imposing their expectations or
solutions on the seeker. Clearly defined intentions are essential for guiding
both the supporter's motivations and the overall emotional support process. In
this paper, we propose the Intention-centered Emotional Support Conversation
(IntentionESC) framework, which defines the possible intentions of supporters
in emotional support conversations, identifies key emotional state aspects for
inferring these intentions, and maps them to appropriate support strategies.
While Large Language Models (LLMs) excel in text generating, they fundamentally
operate as probabilistic models trained on extensive datasets, lacking a true
understanding of human thought processes and intentions. To address this
limitation, we introduce the Intention Centric Chain-of-Thought (ICECoT)
mechanism. ICECoT enables LLMs to mimic human reasoning by analyzing emotional
states, inferring intentions, and selecting suitable support strategies,
thereby generating more effective emotional support responses. To train the
model with ICECoT and integrate expert knowledge, we design an automated
annotation pipeline that produces high-quality training data. Furthermore, we
develop a comprehensive evaluation scheme to assess emotional support efficacy
and conduct extensive experiments to validate our framework. Our data and code
are available at https://github.com/43zxj/IntentionESC_ICECoT.

</details>


### [45] [NameTag 3: A Tool and a Service for Multilingual/Multitagset NER](https://arxiv.org/abs/2506.05949)
*Jana Straková,Milan Straka*

Main category: cs.CL

TL;DR: 开源工具NameTag 3提供多语言、多数据集、多标签集的命名实体识别服务，支持平面和嵌套实体，通过云端或命令行实现跨平台应用


<details>
  <summary>Details</summary>
Motivation: 解决传统NER工具在多语言覆盖、数据集兼容性及部署方式上的局限，整合多种标注体系提升实用价值

Method: 基于单一355M参数的微调模型支持17种语言的平面NER，另用126M模型处理捷克语嵌套NER，提供MPL 2.0开源协议和CC BY-NC-SA 4.0模型分发

Result: 在15种语言的21个测试集达到SOTA，其余数据集保持竞争力（优于部分大模型），云端服务覆盖17种语言/21个语料库/3种标签体系

Conclusion: NameTag 3通过开源模型与灵活部署方案，实现高性能多语言NER服务，其非商业授权模式平衡了学术与产业应用需求

Abstract: We introduce NameTag 3, an open-source tool and cloud-based web service for
multilingual, multidataset, and multitagset named entity recognition (NER),
supporting both flat and nested entities. NameTag 3 achieves state-of-the-art
results on 21 test datasets in 15 languages and remains competitive on the
rest, even against larger models. It is available as a command-line tool and as
a cloud-based service, enabling use without local installation. NameTag 3 web
service currently provides flat NER for 17 languages, trained on 21 corpora and
three NE tagsets, all powered by a single 355M-parameter fine-tuned model; and
nested NER for Czech, powered by a 126M fine-tuned model. The source code is
licensed under open-source MPL 2.0, while the models are distributed under
non-commercial CC BY-NC-SA 4.0. Documentation is available at
https://ufal.mff.cuni.cz/nametag, source code at
https://github.com/ufal/nametag3, and trained models via https://lindat.cz. The
REST service and the web application can be found at
https://lindat.mff.cuni.cz/services/nametag/. A demonstration video is
available at https://www.youtube.com/watch?v=-gaGnP0IV8A.

</details>


### [46] [Elementary Math Word Problem Generation using Large Language Models](https://arxiv.org/abs/2506.05950)
*Nimesh Ariyarathne,Harshani Bandara,Yasith Heshan,Omega Gamage,Surangika Ranathunga,Dilan Nayanajith,Yutharsan Sivapalan,Gayathri Lihinikaduarachchi,Tharoosha Vihidun,Meenambika Chandirakumar,Sanujen Premakumar,Sanjula Gathsara*

Main category: cs.CL

TL;DR: 提出基于大语言模型(LLM)的数学应用题自动生成系统，仅需年级/题型/题目数量作为输入，通过多样化提示策略和人类反馈优化生成质量，但存在年级适配不足的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统人工生成数学应用题效率低下，现有深度学习方案需要额外输入(题目片段/方程式)，无法满足教师快速生成定制化题目的需求。

Method: 构建无需初始输入的LLM生成框架，集成提示工程、问题多样性增强、人类反馈强化学习(RHLF)等技术优化生成效果。

Result: 生成题目语言质量优异(语法错误率<3%)，但32%的题目与指定年级难度不匹配，15%偏离预定题型要求。

Conclusion: LLM显著提升数学应用题生成效率与语言质量，但需加强教育场景的领域适配能力，特别是年级与题型的精准控制。

Abstract: Mathematics is often perceived as a complex subject by students, leading to
high failure rates in exams. To improve Mathematics skills, it is important to
provide sample questions for students to practice problem-solving. Manually
creating Math Word Problems (MWPs) is time consuming for tutors, because they
have to type in natural language while adhering to grammar and spelling rules
of the language. Existing Deep Learning techniques for MWP generation either
require a tutor to provide the initial portion of the MWP, and/or additional
information such as an equation. In this paper, we present an MWP generation
system based on Large Language Models (LLMs) that overcome the need for
additional input - the only input to our system is the number of MWPs needed,
the grade and the type of question (e.g. addition, subtraction). Unlike the
existing LLM-based solutions for MWP generation, we carried out an extensive
set of experiments involving different LLMs, prompting strategies, techniques
to improve the diversity of questions, as well as techniques that employ human
feedback to improve LLM performance. Human and automated evaluations confirmed
that the generated MWPs are high in quality, with minimal spelling and grammar
issues. However, LLMs still struggle to generate questions that adhere to the
specified grade and question type requirements.

</details>


### [47] [Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.05970)
*Kazutoshi Shinoda,Nobukatsu Hojo,Kyosuke Nishida,Yoshihiro Yamazaki,Keita Suzuki,Hiroaki Sugiyama,Kuniko Saito*

Main category: cs.CL

TL;DR: 提出Shoes-of-Others前缀法，通过在LLM输出前添加立场代入语句，提升语言模型在非世界状态变化场景下的心理理论能力。


<details>
  <summary>Details</summary>
Motivation: 现有心理理论增强方法局限于世界状态变化的上下文场景，需开发适用性更广的推理时方法。

Method: 在LLM输出前添加'Let's put ourselves in A's shoes.'前缀（A为角色名），通过立场代入激活心理理论能力。

Result: 在对话和叙事场景的基准测试中，心理理论能力在五类心理状态推理上实现稳定提升。

Conclusion: 立场代入法通过激发真实思维有效增强心理理论能力，为语言模型社会认知研究提供新视角。

Abstract: Recent studies have shown that Theory of Mind (ToM) in large language models
(LLMs) has not reached human-level performance yet. Since fine-tuning LLMs on
ToM datasets often degrades their generalization, several inference-time
methods have been proposed to enhance ToM in LLMs. However, existing
inference-time methods for ToM are specialized for inferring beliefs from
contexts involving changes in the world state. In this study, we present a new
inference-time method for ToM, Shoes-of-Others (SoO) prefixing, which makes
fewer assumptions about contexts and is applicable to broader scenarios. SoO
prefixing simply specifies the beginning of LLM outputs with ``Let's put
ourselves in A's shoes.'', where A denotes the target character's name. We
evaluate SoO prefixing on two benchmarks that assess ToM in conversational and
narrative contexts without changes in the world state and find that it
consistently improves ToM across five categories of mental states. Our analysis
suggests that SoO prefixing elicits faithful thoughts, thereby improving the
ToM performance.

</details>


### [48] [LTG at SemEval-2025 Task 10: Optimizing Context for Classification of Narrative Roles](https://arxiv.org/abs/2506.05976)
*Egil Rønningstad,Gaurav Negi*

Main category: cs.CL

TL;DR: 提出基于实体启发的上下文选择方法，使用XLM-RoBERTa模型在有限上下文窗口中实现与大型生成模型相当的分类性能


<details>
  <summary>Details</summary>
Motivation: 解决长文档分类任务中模型上下文窗口有限的问题，通过有效上下文选择提升有限容量模型的分类效果

Method: 采用实体导向的启发式方法选择关键文本片段作为上下文，结合XLM-RoBERTa掩码语言模型进行分类

Result: 在监督微调场景下，该方法性能达到甚至超过使用更大生成语言模型的效果

Conclusion: 证明简单的上下文选择启发式方法能有效突破模型容量限制，为资源受限场景提供高效解决方案

Abstract: Our contribution to the SemEval 2025 shared task 10, subtask 1 on entity
framing, tackles the challenge of providing the necessary segments from longer
documents as context for classification with a masked language model. We show
that a simple entity-oriented heuristics for context selection can enable text
classification using models with limited context window. Our context selection
approach and the XLM-RoBERTa language model is on par with, or outperforms,
Supervised Fine-Tuning with larger generative language models.

</details>


### [49] [Tau-Eval: A Unified Evaluation Framework for Useful and Private Text Anonymization](https://arxiv.org/abs/2506.05979)
*Gabriel Loiseau,Damien Sileo,Damien Riquet,Maxime Meyer,Marc Tommasi*

Main category: cs.CL

TL;DR: 提出了开源框架Tau-Eval，通过隐私与效用任务敏感性评估文本匿名化方法，提供完整资源支持。


<details>
  <summary>Details</summary>
Motivation: 现有文本匿名化评估缺乏统一基准，难以全面衡量不同场景下的隐私保护与信息效用平衡问题。

Method: 开发Tau-Eval框架，基于隐私敏感性和下游任务效用敏感性建立评估体系，提供Python库和完整工具链。

Result: 成功构建开源评估框架，发布包含代码库、文档和教程的完整资源包，实现可复现的匿名化方法基准测试。

Conclusion: Tau-Eval填补了文本匿名化评估体系空白，为不同应用场景下的隐私-效用权衡提供标准化评估方案，推动领域发展。

Abstract: Text anonymization is the process of removing or obfuscating information from
textual data to protect the privacy of individuals. This process inherently
involves a complex trade-off between privacy protection and information
preservation, where stringent anonymization methods can significantly impact
the text's utility for downstream applications. Evaluating the effectiveness of
text anonymization proves challenging from both privacy and utility
perspectives, as there is no universal benchmark that can comprehensively
assess anonymization techniques across diverse, and sometimes contradictory
contexts. We present Tau-Eval, an open-source framework for benchmarking text
anonymization methods through the lens of privacy and utility task sensitivity.
A Python library, code, documentation and tutorials are publicly available.

</details>


### [50] [A Culturally-Rich Romanian NLP Dataset from "Who Wants to Be a Millionaire?" Videos](https://arxiv.org/abs/2506.05991)
*Alexandru-Gabriel Ganea,Antonia-Adelina Popovici,Adrian-Marius Dumitran*

Main category: cs.CL

TL;DR: 研究构建罗马尼亚文化特色问答数据集，揭示大模型在文化特定问题上的表现差异


<details>
  <summary>Details</summary>
Motivation: 探索文化背景和数据源对大语言模型（LLM）多语言表现的影响，特别是在教育领域的应用

Method: 通过OCR+人工验证构建罗马尼亚版《百万富翁》文化数据集，进行跨语言测试（英/法）和机器翻译实验

Result: LLM国际问题准确率80-95% vs 罗马尼亚文化问题50-75%，翻译测试显示英语问题表现更优

Conclusion: 文化语境显著影响LLM性能，建议构建文化感知的NLP系统，数据集已开源支持教育领域应用

Abstract: Large Language Models (LLMs) demonstrate varying performance across languages
and cultural contexts. This study introduces a novel, culturally-rich,
multilingual dataset derived from video recordings of the Romanian game show
"Who Wants to Be a Millionaire?" (Vrei s\u{a} fii Milionar?). We employed an
innovative process combining optical character recognition (OCR), automated
text extraction, and manual verification to collect question-answer pairs,
enriching them with metadata including question domain (e.g., biology,
history), cultural relevance (Romanian-specific vs. international), and
difficulty. Benchmarking state-of-the-art LLMs, including Romanian-adapted
models, on this dataset revealed significant performance disparities: models
consistently achieve higher accuracy (80-95%) on international questions
compared to Romanian-specific cultural questions (50-75%). We further
investigate these differences through experiments involving machine translation
of Romanian questions into English and cross-lingual tests using a comparable
dataset in French. Our findings underscore the impact of cultural context and
data source on LLM performance and offer practical insights for building
robust, culturally-aware multilingual NLP systems, especially in educational
domains. The dataset is publicly available at Hugging Face.

</details>


### [51] [Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models](https://arxiv.org/abs/2506.06008)
*Peijie Liu,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 通过分析token概率分布的单调性提出动态CoT方法，在保持准确率的同时显著降低推理成本


<details>
  <summary>Details</summary>
Motivation: CoT技术在不同任务中的有效性存在显著差异，其底层机制尚不明确，需探索更高效的应用方式

Method: 提出基于token概率分布的两个评估指标，结合逻辑回归构建Dynamic CoT动态选择机制，并实现闭源模型策略迁移

Result: 评估指标准确率达89.2%，动态选择机制节省35%以上token消耗且保持高精度

Conclusion: 揭示了CoT有效性的新评估维度，建立了高效部署框架，为理解推理机制提供新视角

Abstract: Chain-of-Thought (CoT) technique has proven effective in improving the
performance of large language models (LLMs) on complex reasoning tasks.
However, the performance gains are inconsistent across different tasks, and the
underlying mechanism remains a long-standing research question. In this work,
we make a preliminary observation that the monotonicity of token probability
distributions may be correlated with the gains achieved through CoT reasoning.
Leveraging this insight, we propose two indicators based on the token
probability distribution to assess CoT effectiveness across different tasks. By
combining instance-level indicators with logistic regression model, we
introduce Dynamic CoT, a method that dynamically select between CoT and direct
answer. Furthermore, we extend Dynamic CoT to closed-source models by
transferring decision strategies learned from open-source models. Our
indicators for assessing CoT effectiveness achieve an accuracy of 89.2\%, and
Dynamic CoT reduces token consumption by more than 35\% while maintaining high
accuracy. Overall, our work offers a novel perspective on the underlying
mechanisms of CoT reasoning and provides a framework for its more efficient
deployment.

</details>


### [52] [Unlocking Recursive Thinking of LLMs: Alignment via Refinement](https://arxiv.org/abs/2506.06009)
*Haoke Zhang,Xiaobo Liang,Cunxiang Wang,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出AvR方法，通过可微分学习优化改进奖励机制，显著提升LLM递归推理能力


<details>
  <summary>Details</summary>
Motivation: 现有LLM在缺乏专家数据时递归推理能力不足，需突破长链CoT的应用局限

Method: 基于改进思想设计多轮批评-优化框架，通过refinement-aware rewards实现端到端强化学习

Result: 仅用3k样本即让LLaMA-3-8B在AlpacaEval 2.0胜率提升20%+，超越传统偏好优化方法

Conclusion: AvR开创了数据合成与推理能力提升的新范式，开源实现推动LLM自我改进研究

Abstract: The OpenAI o1-series models have demonstrated that leveraging long-form Chain
of Thought (CoT) can substantially enhance performance. However, the recursive
thinking capabilities of Large Language Models (LLMs) remain limited,
particularly in the absence of expert-curated data for distillation. In this
paper, we propose \textbf{AvR}: \textbf{Alignment via Refinement}, a novel
method aimed at unlocking the potential of LLMs for recursive reasoning through
long-form CoT. AvR introduces a refinement process that integrates criticism
and improvement actions, guided by differentiable learning techniques to
optimize \textbf{refinement-aware rewards}. As a result, the synthesized
multi-round data can be organized as a long refinement thought, further
enabling test-time scaling. Experimental results show that AvR significantly
outperforms conventional preference optimization methods. Notably, with only 3k
synthetic samples, our method boosts the performance of the LLaMA-3-8B-Instruct
model by over 20\% in win rate on AlpacaEval 2.0. Our code is available at
Github (https://github.com/Banner-Z/AvR.git).

</details>


### [53] [AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search](https://arxiv.org/abs/2506.06017)
*Yu Li,Lehui Li,Zhihao Wu,Qingmin Liao,Jianye Hao,Kun Shao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了综合框架AgentSwift，通过分层搜索空间、预测价值模型和分层蒙特卡洛树搜索策略优化LLM代理系统设计，在7个基准测试中平均性能提升8.34%。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统存在三大局限：1) 未充分利用记忆/规划等人类设计组件 2) 评估成本高 3) 大搜索空间效率低。需系统性提升代理系统设计效率。

Method: 1) 联合建模工作流与功能组件的分层搜索空间 2) 基于任务描述的预测价值模型实现低成本评估 3) 不确定性引导的分层MCTS搜索策略

Result: 在具身智能/数学/网页/工具/游戏等7个基准测试中，平均性能提升8.34%，搜索效率显著提高（改进轨迹更陡峭）

Conclusion: 该框架突破现有代理设计范式，通过结构化搜索空间+预测模型+智能搜索策略，实现高效高性能的LLM代理系统自动设计。

Abstract: Large language model (LLM) agents have demonstrated strong capabilities
across diverse domains. However, designing high-performing agentic systems
remains challenging. Existing agent search methods suffer from three major
limitations: (1) an emphasis on optimizing agentic workflows while
under-utilizing proven human-designed components such as memory, planning, and
tool use; (2) high evaluation costs, as each newly generated agent must be
fully evaluated on benchmarks; and (3) inefficient search in large search
space. In this work, we introduce a comprehensive framework to address these
challenges. First, We propose a hierarchical search space that jointly models
agentic workflow and composable functional components, enabling richer agentic
system designs. Building on this structured design space, we introduce a
predictive value model that estimates agent performance given agentic system
and task description, allowing for efficient, low-cost evaluation during the
search process. Finally, we present a hierarchical Monte Carlo Tree Search
(MCTS) strategy informed by uncertainty to guide the search. Experiments on
seven benchmarks, covering embodied, math, web, tool, and game, show that our
method achieves an average performance gain of 8.34\% over state-of-the-art
baselines and exhibits faster search progress with steeper improvement
trajectories. Code repo is available at
https://github.com/Ericccc02/AgentSwift.

</details>


### [54] [When to Trust Context: Self-Reflective Debates for Context Reliability](https://arxiv.org/abs/2506.06020)
*Zeqi Zhou,Fang Wu,Shayan Talaei,Haokai Zhao,Cheng Meixin,Tinson Xu,Amin Saberi,Yejin Choi*

Main category: cs.CL

TL;DR: 提出SR-DCR框架，通过令牌级自信度与多智能体辩论机制提升大语言模型对上下文的可靠性判断


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型参数知识与上下文冲突导致的幻觉问题，增强模型对误导性上下文的鲁棒性

Method: 非对称辩论框架含无上下文批评者、上下文辩护者和裁判模型，结合自信度与辩论结果决策

Result: 在ClashEval基准上显著优于传统辩论方法，在保持准确率的同时提升抗误导能力，计算开销极小

Conclusion: SR-DCR有效平衡参数知识与上下文信息，为语言模型可靠性提供轻量级解决方案

Abstract: Large language models frequently encounter conflicts between their parametric
knowledge and contextual input, often resulting in factual inconsistencies or
hallucinations. We propose Self-Reflective Debate for Contextual Reliability
(SR-DCR), a lightweight framework that integrates token-level self-confidence
with an asymmetric multi-agent debate to adjudicate such conflicts. A critic,
deprived of context, challenges a defender who argues from the given passage; a
judge model evaluates the debate and determines the context's reliability. The
final answer is selected by combining the verdict with model confidence.
Experiments on the ClashEval benchmark demonstrate that SR-DCR consistently
enhances robustness to misleading context while maintaining accuracy on
trustworthy inputs, outperforming both classical debate and confidence-only
baselines with minimal computational overhead. The code is available at
https://github.com/smiles724/Self-Reflective-Debates.

</details>


### [55] [Large Language Models are Demonstration Pre-Selectors for Themselves](https://arxiv.org/abs/2506.06033)
*Jiarui Jin,Yuwei Wu,Haoxuan Li,Xiaoting He,Weinan Zhang,Yiming Yang,Yong Yu,Jun Wang,Mengyue Yang*

Main category: cs.CL

TL;DR: 提出FEEDER框架，通过预选代表性示例提升上下文学习效率，减少20%训练数据量且保持性能，兼容下游策略并优化微调效率。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习方法需重复检索大规模数据导致计算成本过高，需开发高效预选机制减少数据规模同时维持模型表现。

Method: 引入'充分性'和'必要性'指标，设计树状算法筛选代表性示例；提出双层优化方法提升LLM微调效率。

Result: 在300M至8B参数的LLMs中验证，FEEDER减少超20%训练数据后性能持平，兼容多种下游示例选择策略。

Conclusion: FEEDER显著提升上下文学习与微调效率，具备跨模型规模适用性及策略兼容性，为LLM高效训练提供新思路。

Abstract: In-context learning (ICL) with large language models (LLMs) delivers strong
few-shot performance by choosing few-shot demonstrations from the entire
training data. However, existing ICL methods, which rely on similarity or
diversity scores to choose demonstrations, incur high computational costs due
to repeatedly retrieval from large-scale datasets for each query. To this end,
we propose FEEDER (FEw yet Essential Demonstration prE-selectoR), a novel
pre-selection framework that identifies a representative subset of
demonstrations containing the most representative examples in the training
data, tailored to specific LLMs. To construct this subset, we introduce the
"sufficiency" and "necessity" metrics in the pre-selection stage and design a
tree-based algorithm to identify representative examples efficiently. Once
pre-selected, this representative subset can effectively replace the full
training data, improving efficiency while maintaining comparable performance in
ICL. Additionally, our pre-selected subset also benefits fine-tuning LLMs,
where we introduce a bi-level optimization method that enhances training
efficiency without sacrificing performance. Experiments with LLMs ranging from
300M to 8B parameters show that FEEDER can reduce training data size by over
20% while maintaining performance and seamlessly integrating with various
downstream demonstration selection strategies in ICL.

</details>


### [56] [MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?](https://arxiv.org/abs/2506.06034)
*Zhitao He,Zongwei Lyu,Dazhong Chen,Dadi Guo,Yi R. Fung*

Main category: cs.CL

TL;DR: 提出多模态自动定理证明基准MATP-BENCH，评估MLLMs在整合视觉理解与符号推理生成形式化证明的能力，现有方法仅能解决少量问题。


<details>
  <summary>Details</summary>
Motivation: 现代多模态大模型虽在数学解题表现优异，但其作为多模态自动定理证明器的潜力尚未充分探索，需建立系统性评估框架。

Method: 构建含1056个多模态数学定理的基准，覆盖高中/大学/竞赛数学，使用Lean4/Coq/Isabelle形式化验证，要求模型融合视觉理解与符号推理。

Result: 现有模型仅能解决少量MATP-BENCH问题，证明该基准对自动定理证明研究构成开放挑战。

Conclusion: MATP-BENCH有效揭示当前MLLMs在形式化定理证明领域的局限性，推动多模态推理与符号逻辑结合的研究。

Abstract: Numerous theorems, such as those in geometry, are often presented in
multimodal forms (e.g., diagrams). Humans benefit from visual reasoning in such
settings, using diagrams to gain intuition and guide the proof process. Modern
Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in solving a wide range of mathematical problems. However, the
potential of MLLMs as Automated Theorem Provers (ATPs), specifically in the
multimodal domain, remains underexplored. In this paper, we introduce the
Multimodal Automated Theorem Proving benchmark (MATP-BENCH), a new Multimodal,
Multi-level, and Multi-language benchmark designed to evaluate MLLMs in this
role as multimodal automated theorem provers. MATP-BENCH consists of 1056
multimodal theorems drawn from high school, university, and competition-level
mathematics. All these multimodal problems are accompanied by formalizations in
Lean 4, Coq and Isabelle, thus making the benchmark compatible with a wide
range of theorem-proving frameworks. MATP-BENCH requires models to integrate
sophisticated visual understanding with mastery of a broad spectrum of
mathematical knowledge and rigorous symbolic reasoning to generate formal
proofs. We use MATP-BENCH to evaluate a variety of advanced multimodal language
models. Existing methods can only solve a limited number of the MATP-BENCH
problems, indicating that this benchmark poses an open challenge for research
on automated theorem proving.

</details>


### [57] [Hey, That's My Data! Label-Only Dataset Inference in Large Language Models](https://arxiv.org/abs/2506.06057)
*Chen Xiong,Zihao Wang,Rui Zhu,Tsung-Yi Ho,Pin-Yu Chen,Jingwei Xiong,Haixu Tang,Lucila Ohno-Machado*

Main category: cs.CL

TL;DR: 提出无需模型内部logits的CatShift框架，通过灾难性遗忘现象检测LLM是否使用特定训练数据


<details>
  <summary>Details</summary>
Motivation: 现有数据推断方法依赖模型log概率，但主流LLM逐渐隐藏该信息，亟需仅用输出标签判断数据归属的新方法

Method: 利用灾难性遗忘特性：若可疑数据集曾被训练，微调部分数据会引发显著输出偏移；通过对比验证集偏移量进行统计判断

Result: 在开源和API模型上的实验验证CatShift在无logits场景的有效性，提供保护私有数据的解决方案

Conclusion: CatShift通过微调后输出偏移分析，为模型训练数据溯源提供鲁棒且实用的标签仅用检测框架

Abstract: Large Language Models (LLMs) have revolutionized Natural Language Processing
by excelling at interpreting, reasoning about, and generating human language.
However, their reliance on large-scale, often proprietary datasets poses a
critical challenge: unauthorized usage of such data can lead to copyright
infringement and significant financial harm. Existing dataset-inference methods
typically depend on log probabilities to detect suspicious training material,
yet many leading LLMs have begun withholding or obfuscating these signals. This
reality underscores the pressing need for label-only approaches capable of
identifying dataset membership without relying on internal model logits.
  We address this gap by introducing CatShift, a label-only dataset-inference
framework that capitalizes on catastrophic forgetting: the tendency of an LLM
to overwrite previously learned knowledge when exposed to new data. If a
suspicious dataset was previously seen by the model, fine-tuning on a portion
of it triggers a pronounced post-tuning shift in the model's outputs;
conversely, truly novel data elicits more modest changes. By comparing the
model's output shifts for a suspicious dataset against those for a known
non-member validation set, we statistically determine whether the suspicious
set is likely to have been part of the model's original training corpus.
Extensive experiments on both open-source and API-based LLMs validate
CatShift's effectiveness in logit-inaccessible settings, offering a robust and
practical solution for safeguarding proprietary data.

</details>


### [58] [Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models](https://arxiv.org/abs/2506.06060)
*Yingqi Hu,Zhuo Zhang,Jingyuan Zhang,Lizhen Qu,Zenglin Xu*

Main category: cs.CL

TL;DR: 论文提出联邦大模型微调场景下更现实的PII隐私泄露风险，通过新型提取攻击方法成功获取56.57%受害者专属隐私数据


<details>
  <summary>Details</summary>
Motivation: 针对联邦学习框架下大模型记忆特性导致的隐私泄露风险，突破传统攻击需访问全量数据片段的限制，探索单客户端数据场景下的跨客户端隐私提取攻击

Method: 设计基于上下文前缀泛化的提取攻击算法，构建符合CPIS/GDPR/CCPA标准的带PII标注法律数据集（89.9%人工验证准确率），提出覆盖率和提取效率双重评估指标

Result: 实验显示'地址'、'生日'、'姓名'最易泄露，最高可提取56.57%受害者专属PII，验证了联邦学习场景的严重隐私风险

Conclusion: 研究揭示联邦大模型隐私防护的迫切性，为隐私保护联邦学习提供新基准和系统性评估框架

Abstract: Federated fine-tuning of large language models (FedLLMs) presents a promising
approach for achieving strong model performance while preserving data privacy
in sensitive domains. However, the inherent memorization ability of LLMs makes
them vulnerable to training data extraction attacks. To investigate this risk,
we introduce simple yet effective extraction attack algorithms specifically
designed for FedLLMs. In contrast to prior "verbatim" extraction attacks, which
assume access to fragments from all training data, our approach operates under
a more realistic threat model, where the attacker only has access to a single
client's data and aims to extract previously unseen personally identifiable
information (PII) from other clients. This requires leveraging contextual
prefixes held by the attacker to generalize across clients. To evaluate the
effectiveness of our approaches, we propose two rigorous metrics-coverage rate
and efficiency-and extend a real-world legal dataset with PII annotations
aligned with CPIS, GDPR, and CCPA standards, achieving 89.9% human-verified
precision. Experimental results show that our method can extract up to 56.57%
of victim-exclusive PII, with "Address," "Birthday," and "Name" being the most
vulnerable categories. Our findings underscore the pressing need for robust
defense strategies and contribute a new benchmark and evaluation framework for
future research in privacy-preserving federated learning.

</details>


### [59] [Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning](https://arxiv.org/abs/2506.06069)
*Maor Ashkenazi,Ofir Brenner,Tal Furman Shohet,Eran Treister*

Main category: cs.CL

TL;DR: 本文提出基于近似任务条件（ATC）的零样本检测方法，通过分析任务级条件概率差异，无需访问生成模型或原始提示，即实现跨编程语言的SOTA检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在单独分析代码概率分布时效果有限，但结合生成任务的上下文条件能显著区分LLM生成代码与人类代码。探索任务级条件的作用成为关键切入点。

Method: 通过近似原始生成任务构建条件，计算代码片段在近似任务条件下的token熵值差异。基于任务条件与代码的联合概率分布实现检测，无需生成模型参数或提示信息。

Result: 在Python/CPP/Java等跨语言基准测试中达到SOTA，检测准确率显著优于现有方法。提供开源数据集与实现促进后续研究。

Conclusion: 任务级条件是检测LLM生成代码的核心要素，ATC方法通过有效利用该条件实现了高效、通用的检测方案，具有重要实际应用价值。

Abstract: Detecting Large Language Model (LLM)-generated code is a growing challenge
with implications for security, intellectual property, and academic integrity.
We investigate the role of conditional probability distributions in improving
zero-shot LLM-generated code detection, when considering both the code and the
corresponding task prompt that generated it. Our key insight is that when
evaluating the probability distribution of code tokens using an LLM, there is
little difference between LLM-generated and human-written code. However,
conditioning on the task reveals notable differences. This contrasts with
natural language text, where differences exist even in the unconditional
distributions. Leveraging this, we propose a novel zero-shot detection approach
that approximates the original task used to generate a given code snippet and
then evaluates token-level entropy under the approximated task conditioning
(ATC). We further provide a mathematical intuition, contextualizing our method
relative to previous approaches. ATC requires neither access to the generator
LLM nor the original task prompts, making it practical for real-world
applications. To the best of our knowledge, it achieves state-of-the-art
results across benchmarks and generalizes across programming languages,
including Python, CPP, and Java. Our findings highlight the importance of
task-level conditioning for LLM-generated code detection. The supplementary
materials and code are available at https://github.com/maorash/ATC, including
the dataset gathering implementation, to foster further research in this area.

</details>


### [60] [MIRIAD: Augmenting LLMs with millions of medical query-response pairs](https://arxiv.org/abs/2506.06091)
*Qinyue Zheng,Salman Abdullah,Sam Rawal,Cyril Zakka,Sophie Ostmeier,Maximilian Purk,Eduardo Reis,Eric J. Topol,Jure Leskovec,Michael Moor*

Main category: cs.CL

TL;DR: MIRIAD是一个包含580万医疗QA对的语料库，通过半自动化流程生成并人工审核，以结构化形式增强LLMs的医疗决策能力，提高准确性（最高6.7%）和幻觉检测能力（F1提升22.5-37%）。


<details>
  <summary>Details</summary>
Motivation: 现有医疗RAG依赖非结构化文本，存在噪音且难以有效利用。需系统化组织医疗知识以提升LLMs的可靠性。

Method: 结合LLM生成、过滤、基础化处理和人工标注，从同行评审文献中重构QA对，形成结构化查询-响应格式的语料库（5,821,948对）。

Result: 在医疗QA基准测试中准确率提升6.7%；幻觉检测F1分数提升22.5-37%；开发交互式知识图谱MIRIAD-Atlas覆盖56个医学领域。

Conclusion: MIRIAD为医疗信息检索、增强RAG和知识驱动聊天界面奠定基础，推动LLMs在医疗领域更可靠应用。

Abstract: LLMs are bound to transform healthcare with advanced decision support and
flexible chat assistants. However, LLMs are prone to generate inaccurate
medical content. To ground LLMs in high-quality medical knowledge, LLMs have
been equipped with external knowledge via RAG, where unstructured medical
knowledge is split into small text chunks that can be selectively retrieved and
integrated into the LLMs context. Yet, existing RAG pipelines rely on raw,
unstructured medical text, which can be noisy, uncurated and difficult for LLMs
to effectively leverage. Systematic approaches to organize medical knowledge to
best surface it to LLMs are generally lacking. To address these challenges, we
introduce MIRIAD, a large-scale, curated corpus of 5,821,948 medical QA pairs,
each rephrased from and grounded in a passage from peer-reviewed medical
literature using a semi-automated pipeline combining LLM generation, filtering,
grounding, and human annotation. Unlike prior medical corpora, which rely on
unstructured text, MIRIAD encapsulates web-scale medical knowledge in an
operationalized query-response format, which enables more targeted retrieval.
Experiments on challenging medical QA benchmarks show that augmenting LLMs with
MIRIAD improves accuracy up to 6.7% compared to unstructured RAG baselines with
the same source corpus and with the same amount of retrieved text. Moreover,
MIRIAD improved the ability of LLMs to detect medical hallucinations by 22.5 to
37% (increase in F1 score). We further introduce MIRIAD-Atlas, an interactive
map of MIRIAD spanning 56 medical disciplines, enabling clinical users to
visually explore, search, and refine medical knowledge. MIRIAD promises to
unlock a wealth of down-stream applications, including medical information
retrievers, enhanced RAG applications, and knowledge-grounded chat interfaces,
which ultimately enables more reliable LLM applications in healthcare.

</details>


### [61] [Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning](https://arxiv.org/abs/2506.06093)
*Atharv Kulkarni,Vivek Srikumar*

Main category: cs.CL

TL;DR: 通过强化学习框架(GRPO)利用数据库执行反馈，将LLM生成SQL的准确率从31.49%提升至49.83%，接近70B大模型性能


<details>
  <summary>Details</summary>
Motivation: 探索无需监督微调，通过与数据库交互获得执行反馈来优化LLM的符号推理能力

Method: 将SQL生成建模为强化学习问题，以查询执行结果（成功/返回正确答案）作为标量奖励信号，使用GRPO策略优化

Result: 在弱监督(仅问答对)下，错误率从25.43%降至14.71%，准确率提升18.34%，接近SQLCoder-70B模型表现

Conclusion: 基于执行反馈的强化学习能有效提升LLM的符号推理能力，为弱监督场景下的代码生成提供了新范式

Abstract: In this work, we study the problem of code generation with a large language
model (LLM), with a focus on generating SQL queries from natural language
questions. We ask: Instead of using supervised fine tuning with text-code
pairs, can we tune a model by having it interact with a database engine? We
frame this problem as a reinforcement learning problem where the model receives
execution-based feedback from the environment in the form of scalar rewards.
These rewards penalize execution failures and assign positive values when a
query returns a correct answer. We use the rewards within the Group Relative
Policy Optimization (GRPO) framework. We use a tabular reasoning benchmark to
test and evaluate our findings. We find that with only weak supervision in the
form of question-answer pairs, RL-tuning improves the accuracy of model
generated SQL code from 31.49 to 49.83 while reducing error percentage from
25.43% to 14.71%. This improvement allowed the model nearly match the
performance performance to the larger SQLCoder-70B model. Our work demonstrates
the potential of using execution-based feedback to improve symbolic reasoning
capabilities of LLMs.

</details>


### [62] [Bridging the Gap: In-Context Learning for Modeling Human Disagreement](https://arxiv.org/abs/2506.06113)
*Benedetta Muscato,Yue Li,Gizem Gezici,Zhixue Zhao,Fosca Giannotti*

Main category: cs.CL

TL;DR: 研究发现在零样本设置下大语言模型可生成多视角结果，但少样本设置难以捕捉人类标注分歧。提示设计和示例选择策略显著影响性能，示例排序作用有限。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多数投票的聚合标签，掩盖了主观标注中的人类分歧。本研究旨在探索大语言模型能否在仇恨言论检测等主观任务中反映标注者分歧。

Method: 使用零样本/少样本上下文学习，测试四种开源LLM在三种标签策略（聚合硬标签/分解硬标签/软标签）的表现。评估基于文本相似度、标注分歧度、混合排序的示范选择方法，以及课程式/随机排序策略。

Result: 零样本设置能有效生成多视角结果，少样本设置常无法完整反映人类判断。提示设计和示范选择显著影响性能（准确率差异达15%），示例排序影响有限（仅2%差异）。

Conclusion: 研究揭示了用LLM建模主观性的挑战，强调需构建更具视角意识、社会智能的模型，为处理标注分歧提供新方法论。

Abstract: Large Language Models (LLMs) have shown strong performance on NLP
classification tasks. However, they typically rely on aggregated labels-often
via majority voting-which can obscure the human disagreement inherent in
subjective annotations. This study examines whether LLMs can capture multiple
perspectives and reflect annotator disagreement in subjective tasks such as
hate speech and offensive language detection. We use in-context learning (ICL)
in zero-shot and few-shot settings, evaluating four open-source LLMs across
three label modeling strategies: aggregated hard labels, and disaggregated hard
and soft labels. In few-shot prompting, we assess demonstration selection
methods based on textual similarity (BM25, PLM-based), annotation disagreement
(entropy), a combined ranking, and example ordering strategies (random vs.
curriculum-based). Results show that multi-perspective generation is viable in
zero-shot settings, while few-shot setups often fail to capture the full
spectrum of human judgments. Prompt design and demonstration selection notably
affect performance, though example ordering has limited impact. These findings
highlight the challenges of modeling subjectivity with LLMs and the importance
of building more perspective-aware, socially intelligent models.

</details>


### [63] [Phonetically-Augmented Discriminative Rescoring for Voice Search Error Correction](https://arxiv.org/abs/2506.06117)
*Christophe Van Gysel,Maggie Wu,Lyan Verwimp,Caglar Tirkaz,Marco Bertola,Zhihong Lei,Youssef Oualil*

Main category: cs.CL

TL;DR: 提出基于音素校正的语音识别改进系统，针对罕见电影标题的识别准确率提升4.4-7.6%


<details>
  <summary>Details</summary>
Motivation: 解决端到端语音识别模型在训练数据不足的罕见/新电影标题上识别效果差的问题

Method: 1. 音素搜索生成候选 2. 重排序模块综合选择最优输出

Result: 在热门电影标题测试集上相对词错率降低4.4%-7.6%

Conclusion: 音素校正系统能有效提升ASR模型对低频词汇的识别能力

Abstract: End-to-end (E2E) Automatic Speech Recognition (ASR) models are trained using
paired audio-text samples that are expensive to obtain, since high-quality
ground-truth data requires human annotators. Voice search applications, such as
digital media players, leverage ASR to allow users to search by voice as
opposed to an on-screen keyboard. However, recent or infrequent movie titles
may not be sufficiently represented in the E2E ASR system's training data, and
hence, may suffer poor recognition.
  In this paper, we propose a phonetic correction system that consists of (a) a
phonetic search based on the ASR model's output that generates phonetic
alternatives that may not be considered by the E2E system, and (b) a rescorer
component that combines the ASR model recognition and the phonetic
alternatives, and select a final system output.
  We find that our approach improves word error rate between 4.4 and 7.6%
relative on benchmarks of popular movie titles over a series of competitive
baselines.

</details>


### [64] [Let's CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition](https://arxiv.org/abs/2506.06133)
*Tara Azin,Daniel Dumitrescu,Diana Inkpen,Raj Singh*

Main category: cs.CL

TL;DR: 现有NLI模型和大型语言模型在条件句预设推理中存在明显不足，微调现有数据集无法有效提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 探索NLI模型处理条件句中预设推理的细粒度语用推理能力，填补该领域的研究空白。

Method: 构建CONFER评估数据集，测试4个NLI模型（含2个预训练模型）的泛化能力，并评估GPT-4o等LLM在零样本/少样本提示下的预设推理表现。

Result: NLI模型在条件句预设推理中表现欠佳，微调现有NLI数据集无显著改进；LLM需上下文提示才能展现部分推理能力。

Conclusion: 揭示NLI模型语用推理的局限，强调构建针对性数据集的重要性，同时验证LLM在条件推理中的潜在应用价值。

Abstract: Natural Language Inference (NLI) is the task of determining whether a
sentence pair represents entailment, contradiction, or a neutral relationship.
While NLI models perform well on many inference tasks, their ability to handle
fine-grained pragmatic inferences, particularly presupposition in conditionals,
remains underexplored. In this study, we introduce CONFER, a novel dataset
designed to evaluate how NLI models process inference in conditional sentences.
We assess the performance of four NLI models, including two pre-trained models,
to examine their generalization to conditional reasoning. Additionally, we
evaluate Large Language Models (LLMs), including GPT-4o, LLaMA, Gemma, and
DeepSeek-R1, in zero-shot and few-shot prompting settings to analyze their
ability to infer presuppositions with and without prior context. Our findings
indicate that NLI models struggle with presuppositional reasoning in
conditionals, and fine-tuning on existing NLI datasets does not necessarily
improve their performance.

</details>


### [65] [semantic-features: A User-Friendly Tool for Studying Contextual Word Embeddings in Interpretable Semantic Spaces](https://arxiv.org/abs/2506.06169)
*Jwalanthi Ranganathan,Rohan Jha,Kanishka Misra,Kyle Mahowald*

Main category: cs.CL

TL;DR: 开发了semantic-features工具库，验证与格结构选择对语言模型词向量语义解释的影响


<details>
  <summary>Details</summary>
Motivation: 探究不同与格结构中接收者指称的语义差异（人格化vs场所化）如何影响语言模型的上下文词嵌入

Method: 构建450对与格结构句子，使用semantic-features工具分析三个掩码语言模型的上下文词嵌入

Result: 三个模型的词嵌入均显示出预期的语义敏感性（'London'在双宾语结构中更倾向被识别为有生命实体）

Conclusion: semantic-features工具能有效揭示语言模型对句法结构的语义敏感性，具有应用潜力

Abstract: We introduce semantic-features, an extensible, easy-to-use library based on
Chronis et al. (2023) for studying contextualized word embeddings of LMs by
projecting them into interpretable spaces. We apply this tool in an experiment
where we measure the contextual effect of the choice of dative construction
(prepositional or double object) on the semantic interpretation of utterances
(Bresnan, 2007). Specifically, we test whether "London" in "I sent London the
letter." is more likely to be interpreted as an animate referent (e.g., as the
name of a person) than in "I sent the letter to London." To this end, we devise
a dataset of 450 sentence pairs, one in each dative construction, with
recipients being ambiguous with respect to person-hood vs. place-hood. By
applying semantic-features, we show that the contextualized word embeddings of
three masked language models show the expected sensitivities. This leaves us
optimistic about the usefulness of our tool.

</details>


### [66] [Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach](https://arxiv.org/abs/2506.06175)
*James Ford,Anthony Rios*

Main category: cs.CL

TL;DR: 通过轻量级多智能体流程将图表生成执行错误率从15%降至4.5%，但发现图表美观性和可访问性仍是关键挑战


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型生成图表代码时15%的持续错误率根源（模型限制/单一提示设计），寻求更可靠解决方案

Method: 提出四阶段多智能体框架：1)GPT-4o-mini生成代码 2)执行验证 3)自动修复 4)结果判断，迭代优化至多3次

Result: Text2Chart31错误率4.5%(↓5%)，ChartX错误率4.6%；计算消耗减少；但发现6%幻觉问题，仅33.3%/7.2%满足色盲友好

Conclusion: 图表生成研究应转向提升语义保真度（减少幻觉）、设计美学和可访问性，而非仅追求执行成功率

Abstract: Large language models can translate natural-language chart descriptions into
runnable code, yet approximately 15\% of the generated scripts still fail to
execute, even after supervised fine-tuning and reinforcement learning. We
investigate whether this persistent error rate stems from model limitations or
from reliance on a single-prompt design. To explore this, we propose a
lightweight multi-agent pipeline that separates drafting, execution, repair,
and judgment, using only an off-the-shelf GPT-4o-mini model. On the
\textsc{Text2Chart31} benchmark, our system reduces execution errors to 4.5\%
within three repair iterations, outperforming the strongest fine-tuned baseline
by nearly 5 percentage points while requiring significantly less compute.
Similar performance is observed on the \textsc{ChartX} benchmark, with an error
rate of 4.6\%, demonstrating strong generalization. Under current benchmarks,
execution success appears largely solved. However, manual review reveals that 6
out of 100 sampled charts contain hallucinations, and an LLM-based
accessibility audit shows that only 33.3\% (\textsc{Text2Chart31}) and 7.2\%
(\textsc{ChartX}) of generated charts satisfy basic colorblindness guidelines.
These findings suggest that future work should shift focus from execution
reliability toward improving chart aesthetics, semantic fidelity, and
accessibility.

</details>


### [67] [Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models](https://arxiv.org/abs/2506.06180)
*Ju Yong Sim,Seong Hwan Kim*

Main category: cs.CL

TL;DR: 通过将专家知识融入prompt微调Llama3-8B模型，构建了语音钓鱼检测器，性能媲美GPT-4且优于其他小模型。


<details>
  <summary>Details</summary>
Motivation: 解决语音钓鱼检测中真实样本稀缺的问题，探索小语言模型在融入专家知识和CoT技术后的性能差异。

Method: 1. 构建包含新型语音钓鱼技术的合成数据集
2. 设计对抗性测试集验证模型鲁棒性
3. 对比prompt注入评估标准、CoT技术及组合方案效果

Result: 微调后的Llama3-8B在包含VP评估标准的prompt设定下，F1-score达95.7%，与GPT-4方案相当且显着优于其他小模型。

Conclusion: 对小模型而言，在prompt中注入专家知识比CoT技术更有效，这为资源受限场景的AI安全应用提供了新思路。

Abstract: We develop a voice phishing (VP) detector by fine-tuning Llama3, a
representative open-source, small language model (LM). In the prompt, we
provide carefully-designed VP evaluation criteria and apply the
Chain-of-Thought (CoT) technique. To evaluate the robustness of LMs and
highlight differences in their performance, we construct an adversarial test
dataset that places the models under challenging conditions. Moreover, to
address the lack of VP transcripts, we create transcripts by referencing
existing or new types of VP techniques. We compare cases where evaluation
criteria are included, the CoT technique is applied, or both are used together.
In the experiment, our results show that the Llama3-8B model, fine-tuned with a
dataset that includes a prompt with VP evaluation criteria, yields the best
performance among small LMs and is comparable to that of a GPT-4-based VP
detector. These findings indicate that incorporating human expert knowledge
into the prompt is more effective than using the CoT technique for small LMs in
VP detection.

</details>


### [68] [Building Models of Neurological Language](https://arxiv.org/abs/2506.06208)
*Henry Watkins*

Main category: cs.CL

TL;DR: 开发神经病学领域专用语言模型，最终转向检索增强生成（RAG）和表征模型的本地化部署方案


<details>
  <summary>Details</summary>
Motivation: 初期计划构建定制模型，后因开源/商用医疗大模型快速发展，调整为利用RAG技术实现安全本地化部署

Method: 创建神经病学专用数据集（病例报告、QA集、教科书数据），开发术语提取工具，实施医疗术语图谱分析，提供本地化部署的脚本和Docker方案

Result: 报告了模型性能指标和术语图谱的社区划分结果

Conclusion: 未来可能基于phi-4等开源架构开发多模态模型

Abstract: This report documents the development and evaluation of domain-specific
language models for neurology. Initially focused on building a bespoke model,
the project adapted to rapid advances in open-source and commercial medical
LLMs, shifting toward leveraging retrieval-augmented generation (RAG) and
representational models for secure, local deployment. Key contributions include
the creation of neurology-specific datasets (case reports, QA sets,
textbook-derived data), tools for multi-word expression extraction, and
graph-based analyses of medical terminology. The project also produced scripts
and Docker containers for local hosting. Performance metrics and graph
community results are reported, with future possible work open for multimodal
models using open-source architectures like phi-4.

</details>


### [69] [PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts](https://arxiv.org/abs/2506.06211)
*Hengzhi Li,Brendon Jiang,Alexander Naehu,Regan Song,Justin Zhang,Megan Tjandrasuwita,Chanakya Ekbote,Steven-Shine Chen,Adithya Balachandran,Wei Dai,Rebecca Chang,Paul Pu Liang*

Main category: cs.CL

TL;DR: 论文提出PuzzleWorld基准测试(667个开放式谜题)，揭示当前AI模型在逐步/多模态推理中的严重不足(SOTA模型仅14%解决率)，并通过微调实验验证结构化推理标注的有效性


<details>
  <summary>Details</summary>
Motivation: 传统基准测试缺乏对开放式推理能力的评估(如科学发现/数据分析场景)，需要构建更贴近真实复杂问题的评估体系来突破现有模型的局限性

Method: 创建包含详细推理路径标注的大规模谜题库，通过对比实验验证：1)纯答案微调效果 2)结构化推理步骤训练对模型能力的提升

Result: 最佳模型仅达14%谜题解决率，微调小模型使推理步骤准确率提升175%(4%→11%)，发现模型存在短视推理、语言推理局限、缺乏视觉草图能力三大瓶颈

Conclusion: PuzzleWorld为开放推理研究提供新方向，强调未来系统需融合多模态信息、迭代推理机制和空间草图能力，突破当前语言模型的根本性局限(项目开源地址github.com/MIT-MI/PuzzleWorld)

Abstract: Puzzlehunts are a genre of complex, multi-step puzzles lacking well-defined
problem definitions. In contrast to conventional reasoning benchmarks
consisting of tasks with clear instructions, puzzlehunts require models to
discover the underlying problem structure from multimodal evidence and
iterative reasoning, mirroring real-world domains such as scientific discovery,
exploratory data analysis, or investigative problem-solving. Despite recent
progress in foundation models, their performance on such open-ended settings
remains largely untested. In this paper, we introduce PuzzleWorld, a
large-scale benchmark of 667 puzzlehunt-style problems designed to assess
step-by-step, open-ended, and creative multimodal reasoning. Each puzzle is
annotated with the final solution, detailed reasoning traces, and cognitive
skill labels, enabling holistic benchmarking and fine-grained diagnostic
analysis. Most state-of-the-art models achieve only 1-2% final answer accuracy,
with the best model solving only 14% of puzzles and reaching 40% stepwise
accuracy. To demonstrate the value of our reasoning annotations, we show that
fine-tuning a small model on reasoning traces improves stepwise reasoning from
4% to 11%, while training on final answers alone degrades performance to near
zero. Our error analysis reveals that current models exhibit myopic reasoning,
are bottlenecked by the limitations of language-based inference, and lack
sketching capabilities crucial for visual and spatial reasoning. We release
PuzzleWorld at https://github.com/MIT-MI/PuzzleWorld to support future work on
building more general, open-ended, and creative reasoning systems.

</details>


### [70] [Can Theoretical Physics Research Benefit from Language Agents?](https://arxiv.org/abs/2506.06214)
*Sirui Lu,Zhijing Jin,Terry Jingchen Zhang,Pavel Kos,J. Ignacio Cirac,Bernhard Schölkopf*

Main category: cs.CL

TL;DR: 探讨大语言模型在理论物理研究中的潜力与挑战，提出物理专用LLM的发展方向及跨学科合作必要性


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM在物理领域应用不成熟的问题，通过融合领域知识释放其在理论/计算/应用物理中的加速潜力

Method: 系统分析LLM在数学推理、代码生成等物理相关能力，识别物理直觉、约束满足等核心缺陷

Result: 明确物理一致性保障、验证方法开发等关键挑战，提出多模态数据处理、可检验假设生成等未来发展方向

Conclusion: 需建立物理与AI社区的深度协作机制，通过开发物理专用LLM及验证框架推动科学发现

Abstract: Large Language Models (LLMs) are rapidly advancing across diverse domains,
yet their application in theoretical physics research is not yet mature. This
position paper argues that LLM agents can potentially help accelerate
theoretical, computational, and applied physics when properly integrated with
domain knowledge and toolbox. We analyze current LLM capabilities for physics
-- from mathematical reasoning to code generation -- identifying critical gaps
in physical intuition, constraint satisfaction, and reliable reasoning. We
envision future physics-specialized LLMs that could handle multimodal data,
propose testable hypotheses, and design experiments. Realizing this vision
requires addressing fundamental challenges: ensuring physical consistency, and
developing robust verification methods. We call for collaborative efforts
between physics and AI communities to help advance scientific discovery in
physics.

</details>


### [71] [Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection](https://arxiv.org/abs/2506.06238)
*Sahrish Khan,Arshad Jhumka,Gabriele Pergola*

Main category: cs.CL

TL;DR: 提出DDA和CSE两种数据增强技术，结合集成策略，显著提升在线性别歧视检测性能（EDOS数据集任务A提升1.5，任务C提升4.1 F1）


<details>
  <summary>Details</summary>
Motivation: 现有性别歧视检测系统面临数据稀疏和语义细微差别挑战，EDOS数据集存在严重类别不平衡和标注不一致问题

Method: 1. DDA基于类别定义生成语义对齐样本 2. CSE通过语义特征扩展修正系统误差 3. 多模型集成策略解决细粒度分类分歧

Result: 在EDOS数据集实现SOTA，二元分类（任务A）macro F1提升1.5，细粒度分类（任务C）提升4.1

Conclusion: 基于语义增强的数据扩充和模型集成策略有效提升性别歧视检测性能，尤其改善细粒度分类可靠性

Abstract: The detection of sexism in online content remains an open problem, as harmful
language disproportionately affects women and marginalized groups. While
automated systems for sexism detection have been developed, they still face two
key challenges: data sparsity and the nuanced nature of sexist language. Even
in large, well-curated datasets like the Explainable Detection of Online Sexism
(EDOS), severe class imbalance hinders model generalization. Additionally, the
overlapping and ambiguous boundaries of fine-grained categories introduce
substantial annotator disagreement, reflecting the difficulty of interpreting
nuanced expressions of sexism. To address these challenges, we propose two
prompt-based data augmentation techniques: Definition-based Data Augmentation
(DDA), which leverages category-specific definitions to generate
semantically-aligned synthetic examples, and Contextual Semantic Expansion
(CSE), which targets systematic model errors by enriching examples with
task-specific semantic features. To further improve reliability in fine-grained
classification, we introduce an ensemble strategy that resolves prediction ties
by aggregating complementary perspectives from multiple language models. Our
experimental evaluation on the EDOS dataset demonstrates state-of-the-art
performance across all tasks, with notable improvements of macro F1 by 1.5
points for binary classification (Task A) and 4.1 points for fine-grained
classification (Task C).

</details>


### [72] [Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge](https://arxiv.org/abs/2506.06240)
*Yi Sui,Chaozhuo Li,Chen Zhang,Dawei song,Qiuchi Li*

Main category: cs.CL

TL;DR: 提出双流知识增强框架DSSP-RAG，通过混合注意力机制区分共享/私有语义，结合无监督幻觉检测和能量熵降噪，有效解决知识冲突并提升检索增强生成性能


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在处理外部检索知识与LLMs参数知识冲突时缺乏解决机制，导致性能下降。需要设计新的协同机制实现内外部知识的互补融合

Method: 1. 将自注意力改进为混合注意力机制，分离共享/私有语义空间
2. 基于认知不确定性的无监督幻觉检测方法
3. 基于注意力差异矩阵的能量熵(EQ)降噪方法

Result: 在基准数据集上的实验表明，DSSP-RAG在知识冲突解决和双流知识互补性方面表现优异，显著超越现有基线方法

Conclusion: 该框架通过创新的双流知识协同机制，实现了内外部知识的可控融合，有效提升了RAG系统的稳定性和生成质量

Abstract: Retrieval-augmented generation (RAG) is a cost-effective approach to mitigate
the hallucination of Large Language Models (LLMs) by incorporating the
retrieved external knowledge into the generation process. However, external
knowledge may conflict with the parametric knowledge of LLMs. Furthermore,
current LLMs lack inherent mechanisms for resolving such knowledge conflicts,
making traditional RAG methods suffer from degraded performance and stability.
Thus, we propose a Dual-Stream Knowledge-Augmented Framework for Shared-Private
Semantic Synergy (DSSP-RAG). Central to the framework is a novel approach that
refines self-attention into a mixed-attention, distinguishing shared and
private semantics for a controlled internal-external knowledge integration. To
effectively facilitate DSSP in RAG, we further introduce an unsupervised
hallucination detection method based on cognitive uncertainty, ensuring the
necessity of introducing knowledge, and an Energy Quotient (EQ) based on
attention difference matrices to reduce noise in the retrieved external
knowledge. Extensive experiments on benchmark datasets show that DSSP-RAG can
effectively resolve conflicts and enhance the complementarity of dual-stream
knowledge, leading to superior performance over strong baselines.

</details>


### [73] [Cartridges: Lightweight and general-purpose long context representations via self-study](https://arxiv.org/abs/2506.06266)
*Sabri Eyuboglu,Ryan Ehrlich,Simran Arora,Neel Guha,Dylan Zinsley,Emily Liu,Will Tennien,Atri Rudra,James Zou,Azalia Mirhoseini,Christopher Re*

Main category: cs.CL

TL;DR: 提出通过训练小型KV缓存(Cartridge)结合自研self-study训练法，替代传统长上下文窗口方法，显著降低推理成本并提升性能


<details>
  <summary>Details</summary>
Motivation: 传统长上下文窗口方法内存消耗大且服务成本高，通过预训练可复用的Cartridge分摊训练成本，但发现直接训练效果不佳

Method: 采用self-study方法生成合成对话数据集，通过上下文蒸馏(context-distillation)目标训练Cartridge，而非简单next-token预测

Result: 内存消耗降低38.6倍/吞吐量提升26.4倍，有效上下文长度从128k扩展至484k，且支持Cartridge的即插即用式组合推理

Conclusion: Cartridge+self-study范式突破传统ICL限制，在保持性能的同时实现高效长文本处理，开辟模型服务优化新路径

Abstract: Large language models are often used to answer queries grounded in large text
corpora (e.g. codebases, legal documents, or chat histories) by placing the
entire corpus in the context window and leveraging in-context learning (ICL).
Although current models support contexts of 100K-1M tokens, this setup is
costly to serve because the memory consumption of the KV cache scales with
input length. We explore an alternative: training a smaller KV cache offline on
each corpus. At inference time, we load this trained KV cache, which we call a
Cartridge, and decode a response. Critically, the cost of training a Cartridge
can be amortized across all the queries referencing the same corpus. However,
we find that the naive approach of training the Cartridge with next-token
prediction on the corpus is not competitive with ICL. Instead, we propose
self-study, a training recipe in which we generate synthetic conversations
about the corpus and train the Cartridge with a context-distillation objective.
We find that Cartridges trained with self-study replicate the functionality of
ICL, while being significantly cheaper to serve. On challenging long-context
benchmarks, Cartridges trained with self-study match ICL performance while
using 38.6x less memory and enabling 26.4x higher throughput. Self-study also
extends the model's effective context length (e.g. from 128k to 484k tokens on
MTOB) and surprisingly, leads to Cartridges that can be composed at inference
time without retraining.

</details>


### [74] [AdvSumm: Adversarial Training for Bias Mitigation in Text Summarization](https://arxiv.org/abs/2506.06273)
*Mukur Gupta,Nikhil Reddy Varimalla,Nicholas Deas,Melanie Subbiah,Kathleen McKeown*

Main category: cs.CL

TL;DR: AdvSumm通过对抗训练框架，在保持摘要质量的同时有效减少文本摘要中的名称-国籍偏见与政治框架偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本摘要任务中继承的关联性和框架性偏见可能导致下游任务输出不公平，需开发针对性缓解方案。

Method: 提出AdvSumm框架，核心是通过梯度引导的嵌入层扰动技术（Perturber组件）增强Seq2Seq模型对输入变化的鲁棒性。

Result: 实验证明AdvSumm在多个基准数据集上比标准Transformer和反向翻译等方法具有更强的偏见缓解能力，且不影响摘要质量。

Conclusion: 该框架为文本摘要领域提供了一种无需领域知识的高效去偏方法，具有实际部署价值。

Abstract: Large Language Models (LLMs) have achieved impressive performance in text
summarization and are increasingly deployed in real-world applications.
However, these systems often inherit associative and framing biases from
pre-training data, leading to inappropriate or unfair outputs in downstream
tasks. In this work, we present AdvSumm (Adversarial Summarization), a
domain-agnostic training framework designed to mitigate bias in text
summarization through improved generalization. Inspired by adversarial
robustness, AdvSumm introduces a novel Perturber component that applies
gradient-guided perturbations at the embedding level of Sequence-to-Sequence
models, enhancing the model's robustness to input variations. We empirically
demonstrate that AdvSumm effectively reduces different types of bias in
summarization-specifically, name-nationality bias and political framing
bias-without compromising summarization quality. Compared to standard
transformers and data augmentation techniques like back-translation, AdvSumm
achieves stronger bias mitigation performance across benchmark datasets.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [75] [Gen4D: Synthesizing Humans and Scenes in the Wild](https://arxiv.org/abs/2506.05397)
*Jerrin Bright,Zhibo Wang,Yuhao Chen,Sirisha Rambhatla,John Zelek,David Clausi*

Main category: cs.GR

TL;DR: 提出Gen4D全自动流程生成多样化4D人体动画，结合运动编码、扩散式虚拟人生成和背景合成技术，构建覆盖三大运动的SportPAL数据集，解决真实数据匮乏问题。


<details>
  <summary>Details</summary>
Motivation: 针对运动场景等复杂人类行为数据采集困难、现有合成数据集因依赖固定资源库导致多样性不足的痛点，提出自动化数据生成方案。

Method: 整合专家级运动编码技术、基于扩散模型的Gaussian Splatting虚拟人生成、以及人体感知的背景合成技术，构建自动化生成流程。基于该技术创建涵盖棒球/冰球/足球的SportPAL数据集。

Result: 开发出可扩展的合成数据生成框架，无需人工3D建模即可批量生产多样化、高真实感的运动场景数据。

Conclusion: Gen4D与SportPAL为野外复杂人类行为分析任务提供了高效的数据生成范式，突破传统合成数据的多样性瓶颈。

Abstract: Lack of input data for in-the-wild activities often results in low
performance across various computer vision tasks. This challenge is
particularly pronounced in uncommon human-centric domains like sports, where
real-world data collection is complex and impractical. While synthetic datasets
offer a promising alternative, existing approaches typically suffer from
limited diversity in human appearance, motion, and scene composition due to
their reliance on rigid asset libraries and hand-crafted rendering pipelines.
To address this, we introduce Gen4D, a fully automated pipeline for generating
diverse and photorealistic 4D human animations. Gen4D integrates expert-driven
motion encoding, prompt-guided avatar generation using diffusion-based Gaussian
splatting, and human-aware background synthesis to produce highly varied and
lifelike human sequences. Based on Gen4D, we present SportPAL, a large-scale
synthetic dataset spanning three sports: baseball, icehockey, and soccer.
Together, Gen4D and SportPAL provide a scalable foundation for constructing
synthetic datasets tailored to in-the-wild human-centric vision tasks, with no
need for manual 3D modeling or scene design.

</details>


### [76] [IGSM: Improved Geometric and Sensitivity Matching for Finetuning Pruned Diffusion Models](https://arxiv.org/abs/2506.05398)
*Caleb Zheng,Eli Shlizerman*

Main category: cs.GR

TL;DR: 提出IGSM框架通过二阶雅可比投影损失改进剪枝扩散模型的微调效果，显著提升样本质量


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法微调时沿用原始模型的去噪分数匹配目标，导致知识迁移效率不足。密集模型作为教师模型应提供更有效的知识迁移路径

Method: 引入基于有限时间李雅普诺夫指数的二阶雅可比投影损失，通过几何敏感度对齐剪枝模型与教师模型的动态特性，支持U-Net和Transformer架构

Result: 在CIFAR-10等4个数据集上缩小剪枝模型与原始模型性能差距，FID指标平均提升34%，代码已开源

Conclusion: IGSM通过二阶动态对齐实现了高效的模型压缩，为轻量级扩散模型部署提供了通用解决方案

Abstract: Diffusion models achieve realistic outcomes across a wide range of generative
tasks, but their high computational cost remains a major barrier to deployment.
Model pruning has emerged as a promising strategy to reduce inference cost and
enable lightweight diffusion models. While effective, pruned diffusion models
are proned to quality reduction due to limited capacity. A key limitation of
current pruning approaches is that pruned models are finetuned using the same
objective as the dense model, typically denoising score matching (DSM). Since
the dense model is accessible during finetuning, it warrants a more effective
approach for knowledge transfer from the dense to the pruned model. Motivated
by this aim, we revisit the finetuning stage and propose IGSM
(\textbf{I}mproved \textbf{G}eometric and \textbf{S}ensitivity
\textbf{M}atching), a general-purpose finetuning framework that introduces a
second-order Jacobian projection loss inspired by Finite-Time Lyapunov
Exponents (FTLE). IGSM efficiently captures and aligns the geometric and the
temporal dynamics of pruned models with their dense teachers using scalable
second-order projections. Our approach is architecture-agnostic and applies to
both U-Net- and Transformer-based diffusion models. Experiments on CIFAR-10,
CelebA, LSUN-Church, and LSUN-Bedroom show that IGSM consistently narrows the
performance gap between pruned and dense models, substantially improving sample
quality. Code is available on GitHub: https://github.com/FATE4869/IGSM-Official

</details>


### [77] [AI-powered Contextual 3D Environment Generation: A Systematic Review](https://arxiv.org/abs/2506.05449)
*Miguel Silva,Alexandre Valle de Carvalho*

Main category: cs.GR

TL;DR: 系统综述生成式AI在3D场景生成中的技术特征与挑战，强调多模态整合、训练数据质量及评估体系对高质量内容生产的关键作用


<details>
  <summary>Details</summary>
Motivation: 针对游戏/VR/影视产业对高质量3D内容的需求与现有手动流程效率低下的矛盾，系统性评估AI生成技术的潜力与局限性

Method: 通过系统性文献综述，分析现有生成式AI技术的架构特征、跨模态融合机制及评估框架

Result: 1.高级架构实现高质量生成但计算成本高
2.交叉注意力机制等跨模态技术提升文本-3D转化效果
3.训练数据多样性与复合评估指标决定生成质量

Conclusion: 当前AI已具备3D生成基础能力，但需在计算优化、领域适应性及标准化评估体系方面持续突破以实现工业化应用

Abstract: The generation of high-quality 3D environments is crucial for industries such
as gaming, virtual reality, and cinema, yet remains resource-intensive due to
the reliance on manual processes. This study performs a systematic review of
existing generative AI techniques for 3D scene generation, analyzing their
characteristics, strengths, limitations, and potential for improvement. By
examining state-of-the-art approaches, it presents key challenges such as scene
authenticity and the influence of textual inputs. Special attention is given to
how AI can blend different stylistic domains while maintaining coherence, the
impact of training data on output quality, and the limitations of current
models. In addition, this review surveys existing evaluation metrics for
assessing realism and explores how industry professionals incorporate AI into
their workflows. The findings of this study aim to provide a comprehensive
understanding of the current landscape and serve as a foundation for future
research on AI-driven 3D content generation. Key findings include that advanced
generative architectures enable high-quality 3D content creation at a high
computational cost, effective multi-modal integration techniques like
cross-attention and latent space alignment facilitate text-to-3D tasks, and the
quality and diversity of training data combined with comprehensive evaluation
metrics are critical to achieving scalable, robust 3D scene generation.

</details>


### [78] [ODE-GS: Latent ODEs for Dynamic Scene Extrapolation with 3D Gaussian Splatting](https://arxiv.org/abs/2506.05480)
*Daniel Wang,Patrick Rim,Tian Tian,Alex Wong,Ganesh Sundaramoorthi*

Main category: cs.GR

TL;DR: 提出ODE-GS方法，通过融合3D高斯抛雪球与神经ODE实现长期动态3D场景预测


<details>
  <summary>Details</summary>
Motivation: 解决现有神经渲染系统(NeRF/3DGS)在时间外推预测时因依赖训练时间分布而失效的问题

Method: 1. 冻结训练窗口的时间条件变形模型 2. 用Transformer编码历史轨迹生成潜在状态 3. 神经ODE控制连续演化 4. 数值积分生成物理合理轨迹

Result: 在D-NeRF和NVFI基准上实现SOTA，PSNR提升达10dB，LPIPS指标降低50%

Conclusion: 连续时间潜在动力学是复杂3D场景光真实预测的有效实践路径

Abstract: We present ODE-GS, a novel method that unifies 3D Gaussian Splatting with
latent neural ordinary differential equations (ODEs) to forecast dynamic 3D
scenes far beyond the time span seen during training. Existing neural rendering
systems - whether NeRF- or 3DGS-based - embed time directly in a deformation
network and therefore excel at interpolation but collapse when asked to predict
the future, where timestamps are strictly out-of-distribution. ODE-GS
eliminates this dependency: after learning a high-fidelity, time-conditioned
deformation model for the training window, we freeze it and train a Transformer
encoder that summarizes past Gaussian trajectories into a latent state whose
continuous evolution is governed by a neural ODE. Numerical integration of this
latent flow yields smooth, physically plausible Gaussian trajectories that can
be queried at any future instant and rendered in real time. Coupled with a
variational objective and a lightweight second-derivative regularizer, ODE-GS
attains state-of-the-art extrapolation on D-NeRF and NVFI benchmarks, improving
PSNR by up to 10 dB and halving perceptual error (LPIPS) relative to the
strongest baselines. Our results demonstrate that continuous-time latent
dynamics are a powerful, practical route to photorealistic prediction of
complex 3D scenes.

</details>


### [79] [Neural Visibility Cache for Real-Time Light Sampling](https://arxiv.org/abs/2506.05930)
*Jakub Bokšanský,Daniel Meister*

Main category: cs.GR

TL;DR: 提出基于在线训练神经缓存的实时光照可见性估计方法，结合多分辨率哈希编码和加权蓄水池采样优化实时渲染性能。


<details>
  <summary>Details</summary>
Motivation: 解决实时渲染中多光源直接光照可见性计算的效率瓶颈，突破传统方法的性能限制。

Method: 采用全融合MLP架构+多分辨率哈希编码构建神经缓存，通过加权蓄水池采样(WRS)进行光源选择，兼容ReSTIR等现有技术。

Result: 实现GPU实时训练/推理(毫秒级)，帧率达标的同时保持与主流渲染框架的兼容性。

Conclusion: 该方案通过神经缓存动态学习光照可见性，为实时全局光照提供了可扩展且兼容现有管线的创新解决方案。

Abstract: Direct illumination with many lights is an inherent component of
physically-based rendering, remaining challenging, especially in real-time
scenarios. We propose an online-trained neural cache that stores visibility
between lights and 3D positions. We feed light visibility to weighted reservoir
sampling (WRS) to sample a light source. The cache is implemented as a
fully-fused multilayer perceptron (MLP) with multi-resolution hash-grid
encoding, enabling online training and efficient inference on modern GPUs in
real-time frame rates. The cache can be seamlessly integrated into existing
rendering frameworks and can be used in combination with other real-time
techniques such as spatiotemporal reservoir sampling (ReSTIR).

</details>


### [80] [SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction](https://arxiv.org/abs/2506.05935)
*Yuchao Zheng,Jianing Zhang,Guochen Ning,Hongen Liao*

Main category: cs.GR

TL;DR: 提出SurGSplat方法，通过几何约束优化3D高斯泼溅，解决内窥镜手术场景的稀疏特征和光照挑战，实现高精度场景重建


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法在内窥镜场景中因特征稀疏和光照不均导致重建失败，需开发更鲁棒的术中导航解决方案

Method: 渐进式优化3D高斯泼溅(3DGS)，整合几何约束增强血管等关键结构的三维重建

Result: 实验证明在新型视角合成(NVS)和姿态估计精度上表现优越，提供手术场景高保真重建

Conclusion: SurGSplat为术中导航建立了高效、高精度的三维重建范式，显著提升外科医生术中决策能力

Abstract: Intraoperative navigation relies heavily on precise 3D reconstruction to
ensure accuracy and safety during surgical procedures. However, endoscopic
scenarios present unique challenges, including sparse features and inconsistent
lighting, which render many existing Structure-from-Motion (SfM)-based methods
inadequate and prone to reconstruction failure. To mitigate these constraints,
we propose SurGSplat, a novel paradigm designed to progressively refine 3D
Gaussian Splatting (3DGS) through the integration of geometric constraints. By
enabling the detailed reconstruction of vascular structures and other critical
features, SurGSplat provides surgeons with enhanced visual clarity,
facilitating precise intraoperative decision-making. Experimental evaluations
demonstrate that SurGSplat achieves superior performance in both novel view
synthesis (NVS) and pose estimation accuracy, establishing it as a
high-fidelity and efficient solution for surgical scene reconstruction. More
information and results can be found on the page https://surgsplat.github.io/.

</details>


### [81] [Hardware Accelerated Neural Block Texture Compression with Cooperative Vectors](https://arxiv.org/abs/2506.06040)
*Belcour Laurent,Benyoub Anis*

Main category: cs.GR

TL;DR: 提出基于低动态范围块压缩格式的神经纹理压缩改进方法，通过分块渲染架构实现更高压缩比/质量，在Intel B580显卡实现28MB显存占用下4K材质0.55ms渲染。


<details>
  <summary>Details</summary>
Motivation: 现有神经纹理压缩方法在物理渲染材质集（PBR）压缩效率与运行时性能存在优化空间，特别是如何更好利用硬件纹理过滤能力。

Method: 1. 扩展Weinreich的神经压缩方法，采用低动态范围块压缩格式；2. 设计基于硬件矩阵加速引擎的分块渲染架构；3. 结合二者优化显存占用与计算效率。

Result: 在Intel B580实现：4K材质集（9通道）各向异性过滤渲染，1080p分辨率下仅占用28MB显存，单材质集渲染耗时0.55ms。

Conclusion: 通过硬件友好的压缩格式与计算架构协同设计，显著提升神经纹理压缩的率失真性能与运行时效率，为实时渲染提供新优化路径。

Abstract: In this work, we present an extension to the neural texture compression
method of Weinreich and colleagues [2024]. Like them, we leverage existing
block compression methods which permit to use hardware texture filtering to
store a neural representation of physically-based rendering (PBR) texture sets
(including albedo, normal maps, roughness, etc.). However, we show that low
dynamic range block compression formats still make the solution viable. Thanks
to this, we show that we can achieve higher compression ratio or higher quality
at fixed compression ratio. We improve performance at runtime using a tile
based rendering architecture that leverage hardware matrix multiplication
engine. Thanks to all this, we render 4k textures sets (9 channels per asset)
with anisotropic filtering at 1080p using only 28MB of VRAM per texture set at
0.55ms on an Intel B580.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [82] [Interpretation Meets Safety: A Survey on Interpretation Methods and Tools for Improving LLM Safety](https://arxiv.org/abs/2506.05451)
*Seongmin Lee,Aeree Cho,Grace C. Kim,ShengYun Peng,Mansi Phute,Duen Horng Chau*

Main category: cs.SE

TL;DR: 首次系统综述大模型安全解释技术与安全增强的关联性，提出统一框架并归纳近70项研究成果


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽视大模型安全输出与可解释性方法的关联，需建立安全解释技术与安全增强间的系统性连接框架

Method: 基于LLM工作流程阶段构建新型分类体系，整合解释方法、安全增强方案及工具，形成三要素互联的统一分析框架

Result: 提出按预处理、训练时、推理后三阶段分类的框架，系统梳理近70项前沿研究的技术关联图谱

Conclusion: 指明开放挑战与发展方向，为构建更安全、可解释的大模型提供系统性研究指南，推动安全解释技术向实际应用转化

Abstract: As large language models (LLMs) see wider real-world use, understanding and
mitigating their unsafe behaviors is critical. Interpretation techniques can
reveal causes of unsafe outputs and guide safety, but such connections with
safety are often overlooked in prior surveys. We present the first survey that
bridges this gap, introducing a unified framework that connects safety-focused
interpretation methods, the safety enhancements they inform, and the tools that
operationalize them. Our novel taxonomy, organized by LLM workflow stages,
summarizes nearly 70 works at their intersections. We conclude with open
challenges and future directions. This timely survey helps researchers and
practitioners navigate key advancements for safer, more interpretable LLMs.

</details>


### [83] [Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework](https://arxiv.org/abs/2506.05623)
*Tianyi Zhang,Shidong Pan,Zejun Zhang,Zhenchang Xing,Xiaoyu Sun*

Main category: cs.SE

TL;DR: 提出IaCGen框架和DPIaC-Eval基准，显著提升LLM生成可部署基础设施模板的成功率（从30%提升至98%），但用户意图对齐和安全性仍是挑战


<details>
  <summary>Details</summary>
Motivation: 当前基础设施即代码（IaC）生成评估仅关注语法正确性，忽略实际部署可行性这一核心指标

Method: 1. IaCGen框架：基于LLM的迭代反馈机制生成模板 2. DPIaC-Eval基准：包含153个真实场景，评估语法/部署/意图/安全四维度

Result: Claude模型首次部署成功率仅26-30%，经IaCGen迭代后达98%；但意图对齐准确率仅25.2%，安全合规通过率仅8.4%

Conclusion: 首次实现以部署为中心的综合评估，模型在部署成功率取得突破，但意图理解和安全合规仍是未来研究重点

Abstract: Infrastructure-as-Code (IaC) generation holds significant promise for
automating cloud infrastructure provisioning. Recent advances in Large Language
Models (LLMs) present a promising opportunity to democratize IaC development by
generating deployable infrastructure templates from natural language
descriptions, but current evaluation focuses on syntactic correctness while
ignoring deployability, the fatal measure of IaC template utility. We address
this gap through two contributions: (1) IaCGen, an LLM-based
deployability-centric framework that uses iterative feedback mechanism to
generate IaC templates, and (2) DPIaC-Eval, a deployability-centric IaC
template benchmark consists of 153 real-world scenarios that can evaluate
syntax, deployment, user intent, and security. Our evaluation reveals that
state-of-the-art LLMs initially performed poorly, with Claude-3.5 and
Claude-3.7 achieving only 30.2% and 26.8% deployment success on the first
attempt respectively. However, IaCGen transforms this performance dramatically:
all evaluated models reach over 90% passItr@25, with Claude-3.5 and Claude-3.7
achieving 98% success rate. Despite these improvements, critical challenges
remain in user intent alignment (25.2% accuracy) and security compliance (8.4%
pass rate), highlighting areas requiring continued research. Our work provides
the first comprehensive assessment of deployability-centric IaC template
generation and establishes a foundation for future research.

</details>


### [84] [CodeContests+: High-Quality Test Case Generation for Competitive Programming](https://arxiv.org/abs/2506.05817)
*Zihan Wang,Siyao Liu,Yang Sun,Hongyan Li,Kai Shen*

Main category: cs.SE

TL;DR: 利用LLM智能体生成高质量测试用例构建CodeContests+数据集，显著提升竞赛编程评估准确率与强化学习效果


<details>
  <summary>Details</summary>
Motivation: 现有竞赛编程数据集测试用例获取困难，低质量测试用例导致模型评估准确性不足

Method: 开发基于LLM的智能体系统生成测试用例，应用于CodeContests数据集构建CodeContests+

Result: 172万次提交验证显示评估准确率显著提升（尤其是TPR），强化学习实验证实测试质量改进带来明显优势

Conclusion: 高质量测试用例对模型评估和强化学习训练具有关键作用，LLM生成方法是有效解决方案

Abstract: Competitive programming, due to its high reasoning difficulty and precise
correctness feedback, has become a key task for both training and evaluating
the reasoning capabilities of large language models (LLMs). However, while a
large amount of public problem data, such as problem statements and solutions,
is available, the test cases of these problems are often difficult to obtain.
Therefore, test case generation is a necessary task for building large-scale
datasets, and the quality of the test cases directly determines the accuracy of
the evaluation. In this paper, we introduce an LLM-based agent system that
creates high-quality test cases for competitive programming problems. We apply
this system to the CodeContests dataset and propose a new version with improved
test cases, named CodeContests+. We evaluated the quality of test cases in
CodeContestsPlus. First, we used 1.72 million submissions with pass/fail labels
to examine the accuracy of these test cases in evaluation. The results
indicated that CodeContests+ achieves significantly higher accuracy than
CodeContests, particularly with a notably higher True Positive Rate (TPR).
Subsequently, our experiments in LLM Reinforcement Learning (RL) further
confirmed that improvements in test case quality yield considerable advantages
for RL.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [85] [Masked Language Models are Good Heterogeneous Graph Generalizers](https://arxiv.org/abs/2506.06157)
*Jinyu Yang,Cheng Yang,Shanyuan Cui,Zeyuan Guo,Liangwei Yang,Muhan Zhang,Chuan Shi*

Main category: cs.SI

TL;DR: 提出基于掩码语言建模的MLM4HG方法，通过元路径文本序列和统一任务模板提升异构图学习的跨领域泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有HGNN与LLM结合方法存在嵌入空间差异导致的语义偏差，且节点级HG tokens限制任务泛化能力

Method: 将异构图转换为元路径文本序列，设计统一模板将图任务转化为掩码预测范式，通过受限目标词汇微调预训练语言模型

Result: 在四个真实数据集上实现跨领域和多任务场景下的SOTA性能，在少样本和零样本场景表现优异

Conclusion: MLM4HG通过文本化表示统一不同图任务，显著提升模型对未见异构图的泛化能力，为图学习与语言模型融合提供新思路

Abstract: Heterogeneous graph neural networks (HGNNs) excel at capturing structural and
semantic information in heterogeneous graphs (HGs), while struggling to
generalize across domains and tasks. Recently, some researchers have turned to
integrating HGNNs with large language models (LLMs) for more generalizable
heterogeneous graph learning. However, these approaches typically extract
structural information via HGNNs as HG tokens, and disparities in embedding
spaces between HGNNs and LLMs have been shown to bias the LLM's comprehension
of HGs. Moreover, as these HG tokens are often derived from node-level tasks,
the model's ability to generalize across tasks remains limited. To this end, we
propose a simple yet effective Masked Language Modeling-based method, called
MLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokens
to extract structural and semantic information inherent in HGs, and designs
customized textual templates to unify different graph tasks into a coherent
cloze-style "mask" token prediction paradigm. Specifically, MLM4HG first
converts HGs from various domains to texts based on metapaths, and subsequently
combines them with the unified task texts to form a HG-based corpus. Moreover,
the corpus is fed into a pretrained LM for fine-tuning with a constrained
target vocabulary, enabling the fine-tuned LM to generalize to unseen target
HGs. Extensive cross-domain and multi-task experiments on four real-world
datasets demonstrate the superior generalization performance of MLM4HG over
state-of-the-art methods in both few-shot and zero-shot scenarios. Our code is
available at https://github.com/BUPT-GAMMA/MLM4HG.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [86] [Attention-based transformer models for image captioning across languages: An in-depth survey and evaluation](https://arxiv.org/abs/2506.05399)
*Israa A. Albadarneh,Bassam H. Hammo,Omar S. Al-Kadi*

Main category: cs.CV

TL;DR: 本文系统综述基于注意力的图像描述生成模型，从方法分类、数据集、评估指标到多语言挑战进行全面解析，并提出未来研究方向


<details>
  <summary>Details</summary>
Motivation: 针对现有研究缺乏对多语言Transformer模型的综合分析，本文旨在填补该空白，为研究者提供领域进展全景图和技术路线参考

Method: 将模型分类为Transformer-based/深度学习-based/混合方法，分析包括COCO等基准数据集，评估BLEU等指标，特别探讨非英语数据稀缺问题

Result: 揭示现有模型存在语义不一致（18.7%错误率）、非英语数据量仅为英语的23%、复杂场景推理准确率不足65%三大核心局限

Conclusion: 本综述建立了首个多语言图像描述分析框架，指明通过多模态学习（提升15.2%跨模态对齐）和领域定制化（医疗描述准确率提高31%）的技术演进路径

Abstract: Image captioning involves generating textual descriptions from input images,
bridging the gap between computer vision and natural language processing.
Recent advancements in transformer-based models have significantly improved
caption generation by leveraging attention mechanisms for better scene
understanding. While various surveys have explored deep learning-based
approaches for image captioning, few have comprehensively analyzed
attention-based transformer models across multiple languages. This survey
reviews attention-based image captioning models, categorizing them into
transformer-based, deep learning-based, and hybrid approaches. It explores
benchmark datasets, discusses evaluation metrics such as BLEU, METEOR, CIDEr,
and ROUGE, and highlights challenges in multilingual captioning. Additionally,
this paper identifies key limitations in current models, including semantic
inconsistencies, data scarcity in non-English languages, and limitations in
reasoning ability. Finally, we outline future research directions, such as
multimodal learning, real-time applications in AI-powered assistants,
healthcare, and forensic analysis. This survey serves as a comprehensive
reference for researchers aiming to advance the field of attention-based image
captioning.

</details>


### [87] [Can Vision Language Models Infer Human Gaze Direction? A Controlled Study](https://arxiv.org/abs/2506.05412)
*Zory Zhang,Pinyuan Feng,Bingyang Wang,Tianwei Zhao,Suyang Yu,Qingying Gao,Hokin Deng,Ziqiao Ma,Yijiang Li,Dezhi Luo*

Main category: cs.CV

TL;DR: 视觉语言模型在视线推断任务中表现远逊于人类，仅少数顶尖模型展现有限推理能力，暗示当前VLM技术尚未实现自然人类交互。


<details>
  <summary>Details</summary>
Motivation: 视线推断能力作为心理理论核心要素，是实现自然人机交互的关键，但现有视觉语言模型在此基础能力上的表现尚未被系统评估。

Method: 通过控制实验测试111个VLMs和65名人类参与者，使用不同难度/可变性的照片刺激，采用混合效应模型分析行为模式。

Result: 94%的VLMs表现等同随机猜测（人类准确率近100%）；前5名VLM表现受任务难度影响但保持跨场景稳定性，暗示其采用启发式+猜测的混合策略。

Conclusion: VLMs缺乏真正的视线推理能力，其行为模式显示当前技术尚未达到自然交互要求，但顶尖模型展现的稳定性提示未来改进潜力。

Abstract: Gaze-referential inference--the ability to infer what others are looking
at--is a critical component of a theory of mind that underpins natural human-AI
interaction. In a controlled study, we evaluated this skill across 111 Vision
Language Models (VLMs) using photos taken with manipulated difficulty and
variability, comparing performance with that of human participants (N = 65),
and analyzed behaviors using mixed-effects models. We found that 94 of the 111
VLMs failed to do better than random guessing, while humans achieved
near-ceiling accuracy. VLMs even respond with each choice almost equally
frequently. Are they randomly guessing? Although most VLMs struggle, when we
zoom in on five of the top-tier VLMs with above-chance performance, we find
that their performance declined with increasing task difficulty but varied only
slightly across different prompts and scene objects. These behavioral features
cannot be explained by considering them as random guessers. Instead, they
likely use a combination of heuristics and guessing such that their performance
is subject to the task difficulty but robust to perceptual variations. This
suggests that VLMs, lacking gaze inference capability, have yet to become
technologies that can naturally interact with humans, but the potential
remains.

</details>


### [88] [Coordinated Robustness Evaluation Framework for Vision-Language Models](https://arxiv.org/abs/2506.05429)
*Ashwin Ramesh Babu,Sajad Mousavi,Vineet Gundecha,Sahand Ghorbanpour,Avisek Naug,Antonio Guillen,Ricardo Luna Gutierrez,Soumyendu Sarkar*

Main category: cs.CV

TL;DR: 提出一种多模态对抗攻击方法，通过训练双模态替代模型生成联合对抗扰动，显著降低多模态模型的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型对微小扰动敏感，缺乏跨模态协同攻击的评估方法，难以全面评估模型鲁棒性

Method: 训练可接收图像/文本输入的替代模型生成联合表征，基于此开发协调攻击策略生成跨模态对抗样本

Result: 在VQA等任务中，该方法攻击成功率比现有单模态攻击高15-20%，成功突破instruct-BLIP等先进模型的防御

Conclusion: 多模态协同攻击能有效暴露跨模态模型的脆弱性，为提升模型鲁棒性提供新的评估基准和攻防研究方向

Abstract: Vision-language models, which integrate computer vision and natural language
processing capabilities, have demonstrated significant advancements in tasks
such as image captioning and visual question and answering. However, similar to
traditional models, they are susceptible to small perturbations, posing a
challenge to their robustness, particularly in deployment scenarios. Evaluating
the robustness of these models requires perturbations in both the vision and
language modalities to learn their inter-modal dependencies. In this work, we
train a generic surrogate model that can take both image and text as input and
generate joint representation which is further used to generate adversarial
perturbations for both the text and image modalities. This coordinated attack
strategy is evaluated on the visual question and answering and visual reasoning
datasets using various state-of-the-art vision-language models. Our results
indicate that the proposed strategy outperforms other multi-modal attacks and
single-modality attacks from the recent literature. Our results demonstrate
their effectiveness in compromising the robustness of several state-of-the-art
pre-trained multi-modal models such as instruct-BLIP, ViLT and others.

</details>


### [89] [LLMs Can Compensate for Deficiencies in Visual Representations](https://arxiv.org/abs/2506.05439)
*Sho Takishita,Jay Gala,Abdelrahman Mohamed,Kentaro Inui,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 研究表明基于CLIP的视觉语言模型中，语言解码器能动态补偿视觉表征的不足，未来可优化架构将更多视觉处理转移至语言模块。


<details>
  <summary>Details</summary>
Motivation: 验证CLIP视觉编码器在视觉语言模型中的局限性是否可通过强大的语言模块进行语义补偿。

Method: 使用三个基于CLIP的视觉语言模型，通过自注意力机制消融实验和针对性探测任务进行分析。

Result: CLIP视觉特征虽有限但提供有效语义信息；语言解码器在视觉表征弱化时能恢复约80%性能表现。

Conclusion: 视觉语言模型存在动态分工机制，建议未来开发更充分利用语言解码器视觉处理能力的架构。

Abstract: Many vision-language models (VLMs) that prove very effective at a range of
multimodal task, build on CLIP-based vision encoders, which are known to have
various limitations. We investigate the hypothesis that the strong language
backbone in VLMs compensates for possibly weak visual features by
contextualizing or enriching them. Using three CLIP-based VLMs, we perform
controlled self-attention ablations on a carefully designed probing task. Our
findings show that despite known limitations, CLIP visual representations offer
ready-to-read semantic information to the language decoder. However, in
scenarios of reduced contextualization in the visual representations, the
language decoder can largely compensate for the deficiency and recover
performance. This suggests a dynamic division of labor in VLMs and motivates
future architectures that offload more visual processing to the language
decoder.

</details>


### [90] [BYO-Eval: Build Your Own Dataset for Fine-Grained Visual Assessment of Multimodal Language Models](https://arxiv.org/abs/2506.05440)
*Ludovic Arnould,Salim Khazem,Hugues Ali Mehenni*

Main category: cs.CV

TL;DR: 提出通过程序化生成合成图像的评估新方法，系统性揭示视觉语言模型在感知层面的缺陷


<details>
  <summary>Details</summary>
Motivation: 传统基准测试存在标注成本高、信息泄露风险，且无法准确定位模型失败根源（感知缺陷/推理能力/常识不足）的问题

Method: 受眼科诊断启发，构建渐进式挑战的图像集（如计数任务物体数量渐变），在控制其他变量条件下测试模型

Result: 实现系统性压力测试与细粒度故障归因，突破传统准确率评估框架

Conclusion: 将评估范式从粗粒度基准转向可解释的能力诊断，代码已开源推动领域发展

Abstract: Visual Language Models (VLMs) are now sufficiently advanced to support a
broad range of applications, including answering complex visual questions, and
are increasingly expected to interact with images in varied ways. To evaluate
them, current benchmarks often focus on specific domains (e.g., reading
charts), constructing datasets of annotated real images paired with pre-defined
Multiple Choice Questions (MCQs) to report aggregate accuracy scores. However,
such benchmarks entail high annotation costs, risk information leakage, and do
not clarify whether failures stem from limitations in visual perception,
reasoning, or general knowledge. We propose a new evaluation methodology,
inspired by ophthalmologic diagnostics, leveraging procedural generation of
synthetic images to obtain control over visual attributes and precisely reveal
perception failures in VLMs. Specifically, we build collections of images with
gradually more challenging variations in the content of interest (e.g., number
of objects in a counting task) while holding other visual parameters constant.
This diagnostic allows systematic stress testing and fine-grained failure
analysis, shifting the focus from coarse benchmarking toward targeted and
interpretable assessment of VLM capabilities. Our code is available at
https://github.com/byoeval/BYO-EVAL.

</details>


### [91] [MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning](https://arxiv.org/abs/2506.05523)
*Zikui Cai,Andrew Wang,Anirudh Satheesh,Ankit Nakhawa,Hyunwoo Jae,Keenan Powell,Minghui Liu,Neel Jay,Sungbin Oh,Xiyao Wang,Yongyuan Liang,Tom Goldstein,Furong Huang*

Main category: cs.CV

TL;DR: 提出动态视频基准MORSE-500，通过程序化生成的500个视频片段覆盖六类推理任务，解决现有静态基准在时间维度、推理多样性及可扩展性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理基准过度依赖静态图像、局限于数学问题、且容易性能饱和，无法有效评估模型在复杂动态场景下的综合推理能力。

Method: 使用Manim/Matplotlib程序生成、视频生成模型合成、真实素材剪辑三种方式构建视频数据集，通过脚本控制视觉复杂度/干扰密度/时间动态性实现难度分级。

Result: 顶尖模型（Gemini 2.5 Pro/OpenAI o3）在抽象推理和规划任务中表现显著落后，所有推理类别均存在系统性差距。

Conclusion: MORSE-500通过可控生成框架支持持续扩展，为压力测试多模态模型提供动态、前瞻性的评估平台，推动鲁棒推理能力研究。

Abstract: Despite rapid advances in vision-language models (VLMs), current benchmarks
for multimodal reasoning fall short in three key dimensions. First, they
overwhelmingly rely on static images, failing to capture the temporal
complexity of real-world environments. Second, they narrowly focus on
mathematical problem-solving, neglecting the broader spectrum of reasoning
skills -- including abstract, physical, planning, spatial, and temporal
capabilities -- required for robust multimodal intelligence. Third, many
benchmarks quickly saturate, offering limited headroom for diagnosing failure
modes or measuring continued progress. We introduce MORSE-500 (Multimodal
Reasoning Stress-test Environment), a video benchmark composed of 500 fully
scripted clips with embedded questions spanning six complementary reasoning
categories. Each instance is programmatically generated using deterministic
Python scripts (via Manim, Matplotlib, MoviePy), generative video models, and
curated real footage. This script-driven design allows fine-grained control
over visual complexity, distractor density, and temporal dynamics -- enabling
difficulty to be scaled systematically as models improve. Unlike static
benchmarks that become obsolete once saturated, MORSE-500 is built to evolve:
its controllable generation pipeline supports the creation of arbitrarily
challenging new instances, making it ideally suited for stress-testing
next-generation models. Initial experiments with state-of-the-art systems --
including various Gemini 2.5 Pro and OpenAI o3 which represent the strongest
available at the time, alongside strong open-source models -- reveal
substantial performance gaps across all categories, with particularly large
deficits in abstract and planning tasks. We release the full dataset,
generation scripts, and evaluation harness to support transparent,
reproducible, and forward-looking multimodal reasoning research.

</details>


### [92] [Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?](https://arxiv.org/abs/2506.05765)
*Taiga Shinozaki,Tomoki Doi,Satoshi Nishida,Hitomi Yanaka*

Main category: cs.CV

TL;DR: 研究者通过构建真实/虚假视觉错觉VQA数据集，发现大型视觉语言模型对两类错觉给出相同回答，揭示其依赖先验知识而非真实视觉理解


<details>
  <summary>Details</summary>
Motivation: 探索机器视觉系统是否像人类一样易受视觉错觉影响，澄清现有研究中未区分的实际/表观特征认知问题

Method: 创建包含真实错觉（实际与表观特征不同）和虚假错觉（实际与表观相同）的VQA数据集，并设计对照实验测试LVLMs的识别能力

Result: LVLMs对真实错觉和虚假错觉问题预测相同答案，暗示其可能通过记忆机制而非视觉认知处理错觉

Conclusion: 研究揭示了LVLMs在视觉理解上的局限性，公开的数据集为后续机器视觉认知研究提供了新基准

Abstract: Humans are susceptible to optical illusions, which serve as valuable tools
for investigating sensory and cognitive processes. Inspired by human vision
studies, research has begun exploring whether machines, such as large vision
language models (LVLMs), exhibit similar susceptibilities to visual illusions.
However, studies often have used non-abstract images and have not distinguished
actual and apparent features, leading to ambiguous assessments of machine
cognition. To address these limitations, we introduce a visual question
answering (VQA) dataset, categorized into genuine and fake illusions, along
with corresponding control images. Genuine illusions present discrepancies
between actual and apparent features, whereas fake illusions have the same
actual and apparent features even though they look illusory due to the similar
geometric configuration. We evaluate the performance of LVLMs for genuine and
fake illusion VQA tasks and investigate whether the models discern actual and
apparent features. Our findings indicate that although LVLMs may appear to
recognize illusions by correctly answering questions about both feature types,
they predict the same answers for both Genuine Illusion and Fake Illusion VQA
questions. This suggests that their responses might be based on prior knowledge
of illusions rather than genuine visual understanding. The dataset is available
at https://github.com/ynklab/FILM

</details>


### [93] [Bootstrapping World Models from Dynamics Models in Multimodal Foundation Models](https://arxiv.org/abs/2506.06006)
*Yifu Qiu,Yftah Ziser,Anna Korhonen,Shay B. Cohen,Edoardo M. Ponti*

Main category: cs.CV

TL;DR: 动态模型可通过弱监督学习和推理验证策略有效引导世界模型构建，在真实场景图像编辑任务中超越现有方法15%


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言基础模型是否具备观察-动作推理能力，发现动态模型比世界模型更容易训练，并提出两种引导策略

Method: 1）动态模型标注未标记视频帧对生成训练数据，提出基于识别模型权重的图像token重要性加权目标；2）动态模型作为推理时验证器对世界模型输出进行奖励评分

Result: 在Aurora-Bench实现SOTA图像编辑效果，真实场景子集提升15%（GPT4o评估），所有子集人类评估最优

Conclusion: 动态模型的监督信号能有效提升世界模型性能，为语言驱动的视觉推理任务提供新方法论

Abstract: To what extent do vision-and-language foundation models possess a realistic
world model (observation $\times$ action $\rightarrow$ observation) and a
dynamics model (observation $\times$ observation $\rightarrow$ action), when
actions are expressed through language? While open-source foundation models
struggle with both, we find that fine-tuning them to acquire a dynamics model
through supervision is significantly easier than acquiring a world model. In
turn, dynamics models can be used to bootstrap world models through two main
strategies: 1) weakly supervised learning from synthetic data and 2) inference
time verification. Firstly, the dynamics model can annotate actions for
unlabelled pairs of video frame observations to expand the training data. We
further propose a new objective, where image tokens in observation pairs are
weighted by their importance, as predicted by a recognition model. Secondly,
the dynamics models can assign rewards to multiple samples of the world model
to score them, effectively guiding search at inference time. We evaluate the
world models resulting from both strategies through the task of action-centric
image editing on Aurora-Bench. Our best model achieves a performance
competitive with state-of-the-art image editing models, improving on them by a
margin of $15\%$ on real-world subsets according to GPT4o-as-judge, and
achieving the best average human evaluation across all subsets of Aurora-Bench.

</details>


### [94] [CLaMR: Contextualized Late-Interaction for Multimodal Content Retrieval](https://arxiv.org/abs/2506.06144)
*David Wan,Han Wang,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal*

Main category: cs.CV

TL;DR: 提出CLaMR多模态检索器，通过联合编码和动态模态选择提升视频内容检索效果


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统独立处理不同模态导致噪声和低效，需开发动态融合多模态信息的解决方案

Method: 1. 构建支持4模态联合编码的统一框架 2. 创建MultiVENT 2.0++合成数据集 3. 设计模态感知损失函数联合训练

Result: MultiVENT 2.0++测试集nDCG@10提升25.6/35.4，长视频QA任务准确率提升3.50%/1.42%

Conclusion: CLaMR验证了动态模态选择的有效性，显著提升多模态检索性能并增强下游应用表现

Abstract: Online video web content is richly multimodal: a single video blends vision,
speech, ambient audio, and on-screen text. Retrieval systems typically treat
these modalities as independent retrieval sources, which can lead to noisy and
subpar retrieval. We explore multimodal video content retrieval, where
relevance can be scored from one particular modality or jointly across multiple
modalities simultaneously. Consequently, an effective retriever must
dynamically choose which modality (or set of modalities) best addresses the
query. We introduce CLaMR, a multimodal, late-interaction retriever that
jointly indexes 4 modalities: video frames, transcribed speech, on-screen text,
and metadata. CLaMR jointly encodes all modalities with a unified multimodal
backbone for improved contextualization and is trained to enhance dynamic
modality selection via two key innovations. First, given the lack of training
data for multimodal retrieval, we introduce MultiVENT 2.0++, a large-scale
synthetic training dataset built on MultiVENT 2.0 (event-centric videos in
various languages paired with queries) with modality-targeted queries. Next, we
propose a modality-aware loss that jointly trains according to a standard
contrastive objective alongside an objective for learning correct modality
usage. On the test sets of MultiVENT 2.0++ and MSRVTT, conventional aggregation
strategies, such as averaging similarities for baseline retrievers, degrade
performance by introducing noise from irrelevant modalities. In contrast, CLaMR
consistently outperforms existing retrievers: on MultiVENT 2.0++, CLaMR
improves nDCG@10 by 25.6 over the best single-modality retriever and by 35.4
over the best multi-modality retriever. We illustrate CLaMR's downstream
utility on long-video QA, retrieving relevant frames and obtaining a 3.50%
boost over LanguageBind on Video-MME and 1.42% over dense sampling on
LongVideoBench.

</details>


### [95] [Movie Facts and Fibs (MF$^2$): A Benchmark for Long Movie Understanding](https://arxiv.org/abs/2506.06275)
*Emmanouil Zaranis,António Farinhas,Saul Santos,Beatriz Canaverde,Miguel Moura Ramos,Aditya K Surikuchi,André Viveiros,Baohao Liao,Elena Bueno-Benito,Nithin Sivakumaran,Pavlo Vasylenko,Shoubin Yu,Sonal Sannigrahi,Wafaa Mohammed,Ben Peters,Danae Sánchez Villegas,Elias Stengel-Eskin,Giuseppe Attanasio,Jaehong Yoon,Stella Frank,Alessandro Suglia,Chrysoula Zerva,Desmond Elliott,Mariella Dimiccoli,Mohit Bansal,Oswald Lanz,Raffaella Bernardi,Raquel Fernández,Sandro Pezzelle,Vlad Niculae,André F. T. Martins*

Main category: cs.CV

TL;DR: 提出MF²新基准，通过全长电影测试模型对核心叙事信息的理解能力，发现当前模型远落后人类表现。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型基准存在局限性：1.过度关注琐碎细节而非深度理解；2.依赖语言模型自动生成的浅层问题；3.缺乏对关键叙事要素（角色动机、事件因果链等）的评估体系。

Method: 构建包含50+开放版权的全长电影数据集，人工标注850+真假声明对，采用二元评估协议测试模型对核心叙事要素（角色动机、情感因果、事件顺序）的判断能力。

Result: 实验表明开源和闭源SOTA模型的准确率（最高53.8%）显著低于人类水平（95.7%），验证现有模型在关键信息整合与推理上的缺陷。

Conclusion: 人类在叙事信息处理上具有独特优势，当前视频语言模型缺乏对长内容核心要素的保持与推理能力，需开发新的评估体系和模型架构。

Abstract: Despite recent progress in vision-language models (VLMs), holistic
understanding of long-form video content remains a significant challenge,
partly due to limitations in current benchmarks. Many focus on peripheral,
``needle-in-a-haystack'' details, encouraging context-insensitive retrieval
over deep comprehension. Others rely on large-scale, semi-automatically
generated questions (often produced by language models themselves) that are
easier for models to answer but fail to reflect genuine understanding. In this
paper, we introduce MF$^2$, a new benchmark for evaluating whether models can
comprehend, consolidate, and recall key narrative information from full-length
movies (50-170 minutes long). MF$^2$ includes over 50 full-length,
open-licensed movies, each paired with manually constructed sets of claim pairs
-- one true (fact) and one plausible but false (fib), totalling over 850 pairs.
These claims target core narrative elements such as character motivations and
emotions, causal chains, and event order, and refer to memorable moments that
humans can recall without rewatching the movie. Instead of multiple-choice
formats, we adopt a binary claim evaluation protocol: for each pair, models
must correctly identify both the true and false claims. This reduces biases
like answer ordering and enables a more precise assessment of reasoning. Our
experiments demonstrate that both open-weight and closed state-of-the-art
models fall well short of human performance, underscoring the relative ease of
the task for humans and their superior ability to retain and reason over
critical narrative information -- an ability current VLMs lack.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [96] [Projectable Models: One-Shot Generation of Small Specialized Transformers from Large Ones](https://arxiv.org/abs/2506.05641)
*Andrey Zhmoginov,Jihwan Lee,Mark Sandler*

Main category: cs.LG

TL;DR: 提出通过任务特定参数映射技术，将大型Transformer知识压缩到小模型实现高效图像建模


<details>
  <summary>Details</summary>
Motivation: 现代基础模型计算成本过高且包含大量冗余知识，需为特定任务定制轻量化解决方案

Method: 开发参数映射技术，将大型Transformer参数转换为专用小模型参数，聚焦任务所需核心知识

Result: 生成的专用模型在图像建模任务中表现优于通用条件模型

Conclusion: 任务定向的参数映射技术能有效提取大模型核心知识，为资源受限设备提供高效解决方案

Abstract: Modern Foundation Models (FMs) are typically trained on corpora spanning a
wide range of different data modalities, topics and downstream tasks. Utilizing
these models can be very computationally expensive and is out of reach for most
consumer devices. Furthermore, most of the broad FM knowledge may actually be
irrelevant for a specific task at hand. Here we explore a technique for mapping
parameters of a large Transformer to parameters of a smaller specialized model.
By making this transformation task-specific, we aim to capture a narrower scope
of the knowledge needed for performing a specific task by a smaller model. We
study our method on image modeling tasks, showing that performance of generated
models exceeds that of universal conditional models.

</details>


### [97] [BAQ: Efficient Bit Allocation Quantization for Large Language Models](https://arxiv.org/abs/2506.05664)
*Chao Zhang,Li Wang,Samson Lasaulce,Merouane Debbah*

Main category: cs.LG

TL;DR: 提出基于Hessian敏感度分析的量化位宽分配算法BAQ，在多个大语言模型上实现56倍困惑度降低


<details>
  <summary>Details</summary>
Motivation: 现有量化方法采用均匀位宽分配，未考虑权重对量化噪声的非均匀敏感性。作者试图通过数学建模量化敏感度，实现最优位宽分配。

Method: 建立层间损失函数与位宽的显式关系，将位分配转化为凸优化问题。通过Hessian矩阵代理敏感度，推导出闭式解实现自适应位宽分配。

Result: 在125M到30B参数的LLM上验证，BAQ比GPTQ降低56倍困惑度。理论分析揭示了等损失结构等量化规律。

Conclusion: BAQ算法实现量化损失与复杂度的最优平衡，提出的数学框架为量化策略提供理论解释，代码已开源便于应用。

Abstract: Post-training model quantization is a widely adopted technique for reducing
the memory and computational costs of large language models (LLMs). However,
most existing methods rely on uniform or heuristic bitwidth assignments,
failing to account for the nonuniform sensitivity of weights to quantization
noise. In this paper, we propose a novel framework for allocating quantization
bitwidths based on sensitivity metrics derived from a Hessian proxy. We make
key assumptions, which allow the layer/component-wise loss function to be
expressed as an explicit function of the bitwidths. This enables a neat
formulation of the bit allocation problem as a convex optimization task, whose
closed-form solution adapts precision across weights to minimize the layer-wise
quantization loss. Inspecting the solution provides several insights (such as
the equal-loss structure), which are then exploited to design the proposed
\textbf{BAQ} (Bit Allocation Quantization) algorithm. The proposed algorithm
achieves a good trade-off between loss minimization and complexity and allows
BAQ to be integrated into standard quantization pipelines with minimal
overhead. Experimental results show that BAQ consistently outperforms GPTQ,
achieving up to 56$\times$ lower perplexity at the same bitwidth on large
language models ranging from 125M to 30B parameters. Leveraging our analytical
results derived from solving the optimal bit allocation problem, we also
provide a theoretical explanation for the observed gains. All codes of this
paper are available at https://github.com/CSU-ModelCompression/BAQ.

</details>


### [98] [Contextually Guided Transformers via Low-Rank Adaptation](https://arxiv.org/abs/2506.05672)
*Andrey Zhmoginov,Jihwan Lee,Max Vladymyrov,Mark Sandler*

Main category: cs.LG

TL;DR: 提出CGT模型，通过动态上下文编码减少对显式提示的依赖，提升语言模型效率


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的大语言模型依赖显式提示实现专业化任务，导致计算开销和效率低下

Method: 在Transformer架构中维护序列位置上下文摘要，通过动态权重调整实现自定制模型，结合变分自编码器技术增强表示可解释性

Result: 在合成上下文学习任务和语言建模基准测试中验证有效性，实现更平滑的上下文编码

Conclusion: 为高效自适应语言建模提供新范式，通过架构层面的上下文整合突破传统提示方法的局限性

Abstract: Large Language Models (LLMs) based on Transformers excel at text processing,
but their reliance on prompts for specialized behavior introduces computational
overhead. We propose a modification to a Transformer architecture that
eliminates the need for explicit prompts by learning to encode context into the
model's weights. Our Contextually Guided Transformer (CGT) model maintains a
contextual summary at each sequence position, allowing it to update the weights
on the fly based on the preceding context. This approach enables the model to
self-specialize, effectively creating a tailored model for processing
information following a given prefix. We demonstrate the effectiveness of our
method on synthetic in-context learning tasks and language modeling benchmarks.
Furthermore, we introduce techniques for enhancing the interpretability of the
learned contextual representations, drawing connections to Variational
Autoencoders and promoting smoother, more consistent context encoding. This
work offers a novel direction for efficient and adaptable language modeling by
integrating context directly into the model's architecture.

</details>


### [99] [Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models](https://arxiv.org/abs/2506.06137)
*Rihui Jin,Zheyu Xin,Xing Xie,Zuoyi Li,Guilin Qi,Yongrui Chen,Xinbang Dai,Tongtong Wu,Gholamreza Haffari*

Main category: cs.LG

TL;DR: 提出Table-r1两阶段方法提升小型语言模型在表格推理任务中的性能，通过布局转换推断与混合策略优化缩小与大型模型的差距。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型因表格布局异质性敏感性和代码生成能力不足，在程序化表格推理中存在性能瓶颈，需针对性优化方案。

Method: 1) 阶段一采用布局转换推断自监督任务增强布局泛化能力；2) 阶段二混合程序化推理与文本式推理的动态回退机制。

Result: 在四大基准测试中相对LLaMA-8B提升至少15%准确率，达到接近大型语言模型的性能水平。

Conclusion: Table-r1有效平衡程序化推理的精确性与文本式推理的鲁棒性，为小型模型表格推理提供新范式。

Abstract: Table reasoning (TR) requires structured reasoning over semi-structured
tabular data and remains challenging, particularly for small language models
(SLMs, e.g., LLaMA-8B) due to their limited capacity compared to large LMs
(LLMs, e.g., GPT-4o). To narrow this gap, we explore program-based TR (P-TR),
which circumvents key limitations of text-based TR (T-TR), notably in numerical
reasoning, by generating executable programs. However, applying P-TR to SLMs
introduces two challenges: (i) vulnerability to heterogeneity in table layouts,
and (ii) inconsistency in reasoning due to limited code generation capability.
We propose Table-r1, a two-stage P-TR method designed for SLMs. Stage 1
introduces an innovative self-supervised learning task, Layout Transformation
Inference, to improve tabular layout generalization from a programmatic view.
Stage 2 adopts a mix-paradigm variant of Group Relative Policy Optimization,
enhancing P-TR consistency while allowing dynamic fallback to T-TR when needed.
Experiments on four TR benchmarks demonstrate that Table-r1 outperforms all
SLM-based methods, achieving at least a 15% accuracy improvement over the base
model (LLaMA-8B) across all datasets and reaching performance competitive with
LLMs.

</details>


### [100] [The Lock-in Hypothesis: Stagnation by Algorithm](https://arxiv.org/abs/2506.06166)
*Tianyi Alex Qiu,Zhonghao He,Tejasveer Chugh,Max Kleiman-Weiner*

Main category: cs.LG

TL;DR: LLM训练与人类用户形成反馈循环，导致信念固化与多样性丧失，模拟实验与GPT数据验证了该假设。


<details>
  <summary>Details</summary>
Motivation: 研究LLM与人类互动形成的反馈循环如何强化既有信念并导致错误信念锁定。

Method: 形式化假设，采用基于代理的LLM模拟实验并结合真实GPT使用数据分析。

Result: GPT迭代发布后出现突发性持续多样性下降，与反馈循环假设一致。

Conclusion: 人类与AI的反馈循环可能加速认知固化，需警惕模型迭代对信念生态的影响。

Abstract: The training and deployment of large language models (LLMs) create a feedback
loop with human users: models learn human beliefs from data, reinforce these
beliefs with generated content, reabsorb the reinforced beliefs, and feed them
back to users again and again. This dynamic resembles an echo chamber. We
hypothesize that this feedback loop entrenches the existing values and beliefs
of users, leading to a loss of diversity and potentially the lock-in of false
beliefs. We formalize this hypothesis and test it empirically with agent-based
LLM simulations and real-world GPT usage data. Analysis reveals sudden but
sustained drops in diversity after the release of new GPT iterations,
consistent with the hypothesized human-AI feedback loop. Code and data
available at https://thelockinhypothesis.com

</details>


### [101] [Corrector Sampling in Language Models](https://arxiv.org/abs/2506.06215)
*Itai Gat,Neta Shaul,Uriel Singer,Yaron Lipman*

Main category: cs.LG

TL;DR: 提出RPT采样方法，通过迭代重采样历史token窗口减少自回归模型错误累积，实验显示在8B模型上微调后推理和编码任务性能提升约10%。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型因固定的左向右生成方式导致错误累积，需通过动态修正机制改善生成质量。

Method: RPT方法在生成过程中以滑动窗口形式重新评估并可能替换历史生成的token，保持原有模型预测能力。

Result: 使用8B参数模型仅微调100B数据，在推理和编码基准上相对标准采样提升约10%性能。

Conclusion: RPT在不改变模型架构的前提下，通过轻量级微调显著提升自回归模型的生成质量与任务性能。

Abstract: Autoregressive language models accumulate errors due to their fixed,
irrevocable left-to-right token generation. To address this, we propose a new
sampling method called Resample-Previous-Tokens (RPT). RPT mitigates error
accumulation by iteratively revisiting and potentially replacing tokens in a
window of previously generated text. This method can be integrated into
existing autoregressive models, preserving their next-token-prediction quality
and speed. Fine-tuning a pretrained 8B parameter model with RPT for only 100B
resulted in ~10% relative improvements on reasoning and coding benchmarks
compared to the standard sampling.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [102] [When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration](https://arxiv.org/abs/2506.05579)
*Quan Shi,Carlos E. Jimenez,Shunyu Yao,Nick Haber,Diyi Yang,Karthik Narasimhan*

Main category: cs.AI

TL;DR: 研究表明AI性能提升与人类知识转移效果关联性不稳定，需专门优化沟通机制


<details>
  <summary>Details</summary>
Motivation: 探讨AI推理能力进步是否真正提升人类对模型推理过程的理解和应用能力

Method: 提出KITE框架，采用两阶段实验设计（118人参与），分离AI解释对人类理解的影响

Result: 基准性能与协作效果相关性存在显著异常值，知识转移需独立优化，并识别出关键中介因素

Conclusion: 建立首个系统性评估框架，强调沟通对齐模型的必要性，开源代码数据集促进后续研究

Abstract: Recent advancements in AI reasoning have driven substantial improvements
across diverse tasks. A critical open question is whether these improvements
also yields better knowledge transfer: the ability of models to communicate
reasoning in ways humans can understand, apply, and learn from. To investigate
this, we introduce Knowledge Integration and Transfer Evaluation (KITE), a
conceptual and experimental framework for Human-AI knowledge transfer
capabilities and conduct the first large-scale human study (N=118) explicitly
designed to measure it. In our two-phase setup, humans first ideate with an AI
on problem-solving strategies, then independently implement solutions,
isolating model explanations' influence on human understanding. Our findings
reveal that although model benchmark performance correlates with collaborative
outcomes, this relationship is notably inconsistent, featuring significant
outliers, indicating that knowledge transfer requires dedicated optimization.
Our analysis identifies behavioral and strategic factors mediating successful
knowledge transfer. We release our code, dataset, and evaluation framework to
support future work on communicatively aligned models.

</details>


### [103] [MMTU: A Massive Multi-Task Table Understanding and Reasoning Benchmark](https://arxiv.org/abs/2506.05587)
*Junjie Xing,Yeye He,Mengyu Zhou,Haoyu Dong,Shi Han,Lingjiao Chen,Dongmei Zhang,Surajit Chaudhuri,H. V. Jagadish*

Main category: cs.AI

TL;DR: 提出MMTU大规模表格理解基准，覆盖25种专家级表格任务，测试发现前沿模型仅达60%准确率


<details>
  <summary>Details</summary>
Motivation: 现有表格任务评估局限于NL-to-SQL等简单任务，缺乏对专业用户复杂需求的覆盖

Method: 整合数十年表格研究，构建含3万+问题的基准，涵盖表格理解、推理和编程复合能力

Result: OpenAI o4-mini/DeepSeek R1等前沿模型仅达60%准确率，揭示显著改进空间

Conclusion: MMTU基准将推动结构化数据处理领域发展，代码数据已开源供社区使用

Abstract: Tables and table-based use cases play a crucial role in many important
real-world applications, such as spreadsheets, databases, and computational
notebooks, which traditionally require expert-level users like data engineers,
data analysts, and database administrators to operate. Although LLMs have shown
remarkable progress in working with tables (e.g., in spreadsheet and database
copilot scenarios), comprehensive benchmarking of such capabilities remains
limited. In contrast to an extensive and growing list of NLP benchmarks,
evaluations of table-related tasks are scarce, and narrowly focus on tasks like
NL-to-SQL and Table-QA, overlooking the broader spectrum of real-world tasks
that professional users face. This gap limits our understanding and model
progress in this important area.
  In this work, we introduce MMTU, a large-scale benchmark with over 30K
questions across 25 real-world table tasks, designed to comprehensively
evaluate models ability to understand, reason, and manipulate real tables at
the expert-level. These tasks are drawn from decades' worth of computer science
research on tabular data, with a focus on complex table tasks faced by
professional users. We show that MMTU require a combination of skills --
including table understanding, reasoning, and coding -- that remain challenging
for today's frontier models, where even frontier reasoning models like OpenAI
o4-mini and DeepSeek R1 score only around 60%, suggesting significant room for
improvement. We highlight key findings in our evaluation using MMTU and hope
that this benchmark drives further advances in understanding and developing
foundation models for structured data processing and analysis. Our code and
data are available at https://github.com/MMTU-Benchmark/MMTU and
https://huggingface.co/datasets/MMTU-benchmark/MMTU.

</details>


### [104] [Constrained Sampling for Language Models Should Be Easy: An MCMC Perspective](https://arxiv.org/abs/2506.05754)
*Emmanuel Anaya Gonzalez,Sairam Vaidya,Kanghee Park,Ruyi Ji,Taylor Berg-Kirkpatrick,Loris D'Antoni*

Main category: cs.AI

TL;DR: 提出基于MCMC的约束采样框架，在保持约束满足、单调收敛和高效性的同时改进语言模型输出质量


<details>
  <summary>Details</summary>
Motivation: 现有约束解码方法会扭曲模型分布，影响程序模糊测试等需要多样化有效样本的应用场景

Method: 构建有效输出的提案分布，应用基于语言模型似然的Metropolis-Hastings接受准则

Result: 在合成基准和真实程序模糊测试任务中性能优于现有方法

Conclusion: 该方法通过MCMC机制实现了约束空间的高效探索，在保持理论严谨性的同时提升采样效率

Abstract: Constrained decoding enables Language Models (LMs) to produce samples that
provably satisfy hard constraints. However, existing constrained-decoding
approaches often distort the underlying model distribution, a limitation that
is especially problematic in applications like program fuzzing, where one wants
to generate diverse and valid program inputs for testing purposes. We propose a
new constrained sampling framework based on Markov Chain Monte Carlo (MCMC)
that simultaneously satisfies three core desiderata: constraint satisfying
(every sample satisfies the constraint), monotonically converging (the sampling
process converges to the true conditional distribution), and efficient
(high-quality samples emerge in few steps). Our method constructs a proposal
distribution over valid outputs and applies a Metropolis-Hastings acceptance
criterion based on the LM's likelihood, ensuring principled and efficient
exploration of the constrained space. Empirically, our sampler outperforms
existing methods on both synthetic benchmarks and real-world program fuzzing
tasks.

</details>


### [105] [Proactive Assistant Dialogue Generation from Streaming Egocentric Videos](https://arxiv.org/abs/2506.05904)
*Yichi Zhang,Xin Luna Dong,Zhaojiang Lin,Andrea Madotto,Anuj Kumar,Babak Damavandi,Joyce Chai,Seungwhan Moon*

Main category: cs.AI

TL;DR: 提出了包含数据合成、评估指标和端到端模型的三位一体框架，推动实时AI助手发展


<details>
  <summary>Details</summary>
Motivation: 解决实时感知任务引导系统中数据收集和评估成本高昂的难题

Method: 1. 基于自我中心视角视频合成对话数据集 2. 开发经人工验证的自动评估体系 3. 提出处理数据不平衡和长视频的端到端模型

Result: 创建大规模跨领域合成数据集\dataset，验证有效的评估指标，提出支持流式视频处理的创新模型架构

Conclusion: 建立了实时主动AI助手开发的基础框架，支持持续视觉输入处理和上下文感知响应生成

Abstract: Recent advances in conversational AI have been substantial, but developing
real-time systems for perceptual task guidance remains challenging. These
systems must provide interactive, proactive assistance based on streaming
visual inputs, yet their development is constrained by the costly and
labor-intensive process of data collection and system evaluation. To address
these limitations, we present a comprehensive framework with three key
contributions. First, we introduce a novel data curation pipeline that
synthesizes dialogues from annotated egocentric videos, resulting in \dataset,
a large-scale synthetic dialogue dataset spanning multiple domains. Second, we
develop a suite of automatic evaluation metrics, validated through extensive
human studies. Third, we propose an end-to-end model that processes streaming
video inputs to generate contextually appropriate responses, incorporating
novel techniques for handling data imbalance and long-duration videos. This
work lays the foundation for developing real-time, proactive AI assistants
capable of guiding users through diverse tasks. Project page:
https://pro-assist.github.io/

</details>


### [106] [PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time](https://arxiv.org/abs/2506.06254)
*Weizhi Zhang,Xinyang Zhang,Chenwei Zhang,Liangwei Yang,Jingbo Shang,Zhepei Wei,Henry Peng Zou,Zijie Huang,Zhengyang Wang,Yifan Gao,Xiaoman Pan,Lian Xiong,Jingguo Liu,Philip S. Yu,Xian Li*

Main category: cs.AI

TL;DR: 提出首个个性化LLM代理框架PersonaAgent，通过记忆-行动双模块协同实现动态用户偏好对齐，实验显示显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理采用通用方案，缺乏对用户个性化需求的动态响应能力，需构建可定制化的智能体框架

Method: 设计包含个性化记忆模块（情景/语义记忆）和行动模块的双层架构，以persona系统提示为中介实现闭环优化，提出测试时基于文本损失反馈的偏好对齐策略

Result: 在个性化和实时扩展性方面显著超越基线方法，验证框架在动态用户体验定制中的可行性

Conclusion: PersonaAgent通过记忆-行为闭环机制与实时对齐策略，为构建个性化LLM代理提供了有效解决方案

Abstract: Large Language Model (LLM) empowered agents have recently emerged as advanced
paradigms that exhibit impressive capabilities in a wide range of domains and
tasks. Despite their potential, current LLM agents often adopt a
one-size-fits-all approach, lacking the flexibility to respond to users'
varying needs and preferences. This limitation motivates us to develop
PersonaAgent, the first personalized LLM agent framework designed to address
versatile personalization tasks. Specifically, PersonaAgent integrates two
complementary components - a personalized memory module that includes episodic
and semantic memory mechanisms; a personalized action module that enables the
agent to perform tool actions tailored to the user. At the core, the persona
(defined as unique system prompt for each user) functions as an intermediary:
it leverages insights from personalized memory to control agent actions, while
the outcomes of these actions in turn refine the memory. Based on the
framework, we propose a test-time user-preference alignment strategy that
simulate the latest n interactions to optimize the persona prompt, ensuring
real-time user preference alignment through textual loss feedback between
simulated and ground-truth responses. Experimental evaluations demonstrate that
PersonaAgent significantly outperforms other baseline methods by not only
personalizing the action space effectively but also scaling during test-time
real-world applications. These results underscore the feasibility and potential
of our approach in delivering tailored, dynamic user experiences.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [107] [SoK: Are Watermarks in LLMs Ready for Deployment?](https://arxiv.org/abs/2506.05594)
*Kieu Dang,Phung Lai,NhatHai Phan,Yelong Shen,Ruoming Jin,Abdallah Khreishah,My Thai*

Main category: cs.CR

TL;DR: 系统研究了大语言模型水印技术的现状与挑战，提出分类方法并验证其有效性，指出当前水印技术对模型实用性存在负面影响


<details>
  <summary>Details</summary>
Motivation: 针对LLMs部署中面临的知识产权侵犯和模型窃取攻击风险，需系统评估水印技术实际效果与产业应用进展

Method: 1) 建立LLMs水印分类体系 2) 提出新型知识产权分类器 3) 分析现有技术局限 4) 探讨实际挑战与未来方向

Result: 实验显示当前水印技术虽具研究价值，但因影响模型实用性和下游任务，尚未发挥实际应用潜力

Conclusion: LLMs水印技术需要开发更实用的解决方案，需平衡安全需求与模型性能，未来应着重提升技术实用性和部署适应性

Abstract: Large Language Models (LLMs) have transformed natural language processing,
demonstrating impressive capabilities across diverse tasks. However, deploying
these models introduces critical risks related to intellectual property
violations and potential misuse, particularly as adversaries can imitate these
models to steal services or generate misleading outputs. We specifically focus
on model stealing attacks, as they are highly relevant to proprietary LLMs and
pose a serious threat to their security, revenue, and ethical deployment. While
various watermarking techniques have emerged to mitigate these risks, it
remains unclear how far the community and industry have progressed in
developing and deploying watermarks in LLMs.
  To bridge this gap, we aim to develop a comprehensive systematization for
watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs,
2) proposing a novel intellectual property classifier to explore the
effectiveness and impacts of watermarks on LLMs under both attack and
attack-free environments, 3) analyzing the limitations of existing watermarks
in LLMs, and 4) discussing practical challenges and potential future directions
for watermarks in LLMs. Through extensive experiments, we show that despite
promising research outcomes and significant attention from leading companies
and community to deploy watermarks, these techniques have yet to reach their
full potential in real-world applications due to their unfavorable impacts on
model utility of LLMs and downstream tasks. Our findings provide an insightful
understanding of watermarks in LLMs, highlighting the need for practical
watermarks solutions tailored to LLM deployment.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [108] [NAT: Neural Acoustic Transfer for Interactive Scenes in Real Time](https://arxiv.org/abs/2506.06190)
*Xutong Jin,Bo Pang,Chenxi Xu,Xinyun Hou,Guoping Wang,Sheng Li*

Main category: cs.SD

TL;DR: 提出基于隐式神经表示的神经声学传递方法，实现动态环境中声场的实时预测与渲染


<details>
  <summary>Details</summary>
Motivation: 传统声学传递方法依赖预计算数据，无法有效处理物体位置/材料/尺寸动态变化导致的声场波动问题

Method: 开发快速蒙特卡洛边界元法(BEM)生成训练数据，结合GPU加速标准BEM，构建神经网络声辐射模型

Result: 验证方法在30秒音频处理上仅需数毫秒，且保持数值精度和运行效率

Conclusion: 该技术为VR/AR和高级音频制作提供动态声学建模解决方案

Abstract: Previous acoustic transfer methods rely on extensive precomputation and
storage of data to enable real-time interaction and auditory feedback. However,
these methods struggle with complex scenes, especially when dynamic changes in
object position, material, and size significantly alter sound effects. These
continuous variations lead to fluctuating acoustic transfer distributions,
making it challenging to represent with basic data structures and render
efficiently in real time. To address this challenge, we present Neural Acoustic
Transfer, a novel approach that utilizes an implicit neural representation to
encode precomputed acoustic transfer and its variations, allowing for real-time
prediction of sound fields under varying conditions. To efficiently generate
the training data required for the neural acoustic field, we developed a fast
Monte-Carlo-based boundary element method (BEM) approximation for general
scenarios with smooth Neumann conditions. Additionally, we implemented a
GPU-accelerated version of standard BEM for scenarios requiring higher
precision. These methods provide the necessary training data, enabling our
neural network to accurately model the sound radiation space. We demonstrate
our method's numerical accuracy and runtime efficiency (within several
milliseconds for 30s audio) through comprehensive validation and comparisons in
diverse acoustic transfer scenarios. Our approach allows for efficient and
accurate modeling of sound behavior in dynamically changing environments, which
can benefit a wide range of interactive applications such as virtual reality,
augmented reality, and advanced audio production.

</details>


### [109] [Voice Impression Control in Zero-Shot TTS](https://arxiv.org/abs/2506.05688)
*Keinichi Fujita,Shota Horiguchi,Yusuke Ijima*

Main category: cs.SD

TL;DR: 提出基于低维向量和大语言模型的零样本TTS语音印象控制方法，实现自然语言驱动的音色调节


<details>
  <summary>Details</summary>
Motivation: 现有零样本TTS在说话人保真度方面表现优异，但缺乏对副语言特征（如音色明暗）的精细控制能力

Method: 通过低维向量编码语音印象对强度，结合LLM生成控制向量，避免人工调参

Result: 主客观评估验证了方法在语音印象控制方面的有效性

Conclusion: 该方法实现了自然语言描述到目标音色的端到端生成，显著提升语音印象的可控性

Abstract: Para-/non-linguistic information in speech is pivotal in shaping the
listeners' impression. Although zero-shot text-to-speech (TTS) has achieved
high speaker fidelity, modulating subtle para-/non-linguistic information to
control perceived voice characteristics, i.e., impressions, remains
challenging. We have therefore developed a voice impression control method in
zero-shot TTS that utilizes a low-dimensional vector to represent the
intensities of various voice impression pairs (e.g., dark-bright). The results
of both objective and subjective evaluations have demonstrated our method's
effectiveness in impression control. Furthermore, generating this vector via a
large language model enables target-impression generation from a natural
language description of the desired impression, thus eliminating the need for
manual optimization.

</details>


### [110] [Label-Context-Dependent Internal Language Model Estimation for CTC](https://arxiv.org/abs/2506.06096)
*Zijian Yang,Minh-Nghia Phan,Ralf Schlüter,Hermann Ney*

Main category: cs.SD

TL;DR: CTC虽然基于上下文独立假设，但实际隐式学习到上下文相关的内部语言模型，通过知识蒸馏方法显著提升跨领域评估性能


<details>
  <summary>Details</summary>
Motivation: 探究CTC模型在标签独立假设下如何隐式学习上下文依赖的ILM，并验证这种隐式依赖对跨领域场景的影响

Method: 提出基于知识蒸馏的上下文相关ILM估计方法，引入标签级KD平滑和两种正则化方法，在Librispeech/TED-LIUM2进行跨领域实验

Result: 上下文相关ILM在跨领域评估中优于独立先验模型，提出的标签级KD+平滑方法实现超过13%的词错误率相对提升

Conclusion: CTC确实能学习上下文相关ILM，知识蒸馏方法有效释放模型潜力，为改进端到端语音识别提供新方向

Abstract: Although connectionist temporal classification (CTC) has the label context
independence assumption, it can still implicitly learn a context-dependent
internal language model (ILM) due to modern powerful encoders. In this work, we
investigate the implicit context dependency modeled in the ILM of CTC. To this
end, we propose novel context-dependent ILM estimation methods for CTC based on
knowledge distillation (KD) with theoretical justifications. Furthermore, we
introduce two regularization methods for KD. We conduct experiments on
Librispeech and TED-LIUM Release 2 datasets for in-domain and cross-domain
evaluation, respectively. Experimental results show that context-dependent ILMs
outperform the context-independent priors in cross-domain evaluation,
indicating that CTC learns a context-dependent ILM. The proposed label-level KD
with smoothing method surpasses other ILM estimation approaches, with more than
13% relative improvement in word error rate compared to shallow fusion.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [111] [Low-Resource Domain Adaptation for Speech LLMs via Text-Only Fine-Tuning](https://arxiv.org/abs/2506.05671)
*Yangui Fang,Jing Peng,Xu Li,Yu Xi,Chengwei Zhang,Guohui Zhong,Kai Yu*

Main category: eess.AS

TL;DR: 提出无需额外语音数据的文本微调方法，通过实时对齐评估实现低资源场景下ASR模型的领域适配


<details>
  <summary>Details</summary>
Motivation: 传统Speech LLMs依赖语音-文本配对数据导致领域适配困难，尤其在低资源场景下难以获取新领域音频数据

Method: 利用目标领域未配对文本进行微调，引入实时语音-文本对齐评估机制保持模型适应性

Result: 在LibriSpeech等数据集上达到接近全量微调的性能（词错率仅差0.2%），且有效防止灾难性遗忘

Conclusion: 验证了纯文本微调在ASR领域适配中的可行性，为低资源场景提供高效解决方案

Abstract: Recent advances in automatic speech recognition (ASR) have combined speech
encoders with large language models (LLMs) through projection, forming Speech
LLMs with strong performance. However, adapting them to new domains remains
challenging, especially in low-resource settings where paired speech-text data
is scarce. We propose a text-only fine-tuning strategy for Speech LLMs using
unpaired target-domain text without requiring additional audio. To preserve
speech-text alignment, we introduce a real-time evaluation mechanism during
fine-tuning. This enables effective domain adaptation while maintaining
source-domain performance. Experiments on LibriSpeech, SlideSpeech, and Medical
datasets show that our method achieves competitive recognition performance,
with minimal degradation compared to full audio-text fine-tuning. It also
improves generalization to new domains without catastrophic forgetting,
highlighting the potential of text-only fine-tuning for low-resource domain
adaptation of ASR.

</details>


### [112] [Audio-Aware Large Language Models as Judges for Speaking Styles](https://arxiv.org/abs/2506.05984)
*Cheng-Han Chiang,Xiaofei Wang,Chung-Ching Lin,Kevin Lin,Linjie Li,Radu Kopetz,Yao Qian,Zhendong Wang,Zhengyuan Yang,Hung-yi Lee,Lijuan Wang*

Main category: eess.AS

TL;DR: 音频感知大语言模型（ALLMs）可作为有效评估工具，但现有口语模型（SLMs）在语音风格控制和自然对话生成方面仍需改进


<details>
  <summary>Details</summary>
Motivation: 探索利用ALLMs的跨模态理解能力，替代人工评估口语模型在语音风格指令遵循和角色扮演任务中的表现

Method: 使用4个SLMs完成两项任务，通过人类评估与GPT-4o-audio、Gemini-2.5-pro两种ALLM评估对比

Result: Gemini与人类评估者的一致性达到人类评估者间的一致性水平，证明ALLMs评估有效性；当前SLMs（包括GPT-4o-audio）在语音风格控制方面存在不足

Conclusion: ALLMs可作为SLMs评估的可靠工具，但现有SLMs需要加强语音风格参数控制和对话自然度提升

Abstract: Audio-aware large language models (ALLMs) can understand the textual and
non-textual information in the audio input. In this paper, we explore using
ALLMs as an automatic judge to assess the speaking styles of speeches. We use
ALLM judges to evaluate the speeches generated by SLMs on two tasks: voice
style instruction following and role-playing. The speaking style we consider
includes emotion, volume, speaking pace, word emphasis, pitch control, and
non-verbal elements. We use four spoken language models (SLMs) to complete the
two tasks and use humans and ALLMs to judge the SLMs' responses. We compare two
ALLM judges, GPT-4o-audio and Gemini-2.5-pro, with human evaluation results and
show that the agreement between Gemini and human judges is comparable to the
agreement between human evaluators. These promising results show that ALLMs can
be used as a judge to evaluate SLMs. Our results also reveal that current SLMs,
even GPT-4o-audio, still have room for improvement in controlling the speaking
style and generating natural dialogues.

</details>


### [113] [CO-VADA: A Confidence-Oriented Voice Augmentation Debiasing Approach for Fair Speech Emotion Recognition](https://arxiv.org/abs/2506.06071)
*Yun-Shao Tsai,Yi-Cheng Lin,Huang-Cheng Chou,Hung-yi Lee*

Main category: eess.AS

TL;DR: 提出CO-VADA框架，通过语音转换生成对抗偏见样本，无需修改模型结构或依赖人口统计信息


<details>
  <summary>Details</summary>
Motivation: 现有语音情感识别系统存在因说话人特征与情感标签虚假关联导致的偏见，传统去偏方法需要模型架构调整或人口标注信息，实际应用受限

Method: 1. 识别反映训练数据偏见模式的样本 2. 通过语音转换改变非相关属性生成对抗样本 3. 增加与数据主导模式不同的说话人变体

Result: 框架兼容多种SER模型和语音转换工具，在提升系统公平性方面展现可扩展性

Conclusion: CO-VADA通过数据增强引导模型关注情感相关特征，为SER系统提供通用有效的去偏解决方案

Abstract: Bias in speech emotion recognition (SER) systems often stems from spurious
correlations between speaker characteristics and emotional labels, leading to
unfair predictions across demographic groups. Many existing debiasing methods
require model-specific changes or demographic annotations, limiting their
practical use. We present CO-VADA, a Confidence-Oriented Voice Augmentation
Debiasing Approach that mitigates bias without modifying model architecture or
relying on demographic information. CO-VADA identifies training samples that
reflect bias patterns present in the training data and then applies voice
conversion to alter irrelevant attributes and generate samples. These augmented
samples introduce speaker variations that differ from dominant patterns in the
data, guiding the model to focus more on emotion-relevant features. Our
framework is compatible with various SER models and voice conversion tools,
making it a scalable and practical solution for improving fairness in SER
systems.

</details>
