<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.LG](#cs.LG) [Total: 3]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.CV](#cs.CV) [Total: 3]
- [q-fin.TR](#q-fin.TR) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 评估大语言模型解决物理问题能力的研究，提出多智能体验证框架并建立新评测基准PhysicsEval


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对大语言模型解决物理问题能力的系统性评估，需开发有效方法提升模型在数学计算和描述性问题中的表现

Method: 采用多智能体协作框架（小型LLM验证解决方案），结合多种推理时优化技术进行性能提升

Result: 多智能体框架显著改善模型初始表现较差的问题，建立含19,609道物理题的评测基准PhysicsEval

Conclusion: 提出的框架有效提升LLM物理推理能力，新基准为未来研究提供标准化测试平台

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [2] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究发现LLM生成的文本在词汇多样性上与人类存在显著差异，新模型（如ChatGPT-4.5）生成的文本反而更不接近人类特征。


<details>
  <summary>Details</summary>
Motivation: 通过测量六个词汇多样性维度，验证不同ChatGPT模型生成文本与人类写作的相似性差异，并比较新/旧模型的表现。

Method: 采用一元多变量方差分析（MANOVA）、一元方差分析（ANOVA）和支持向量机（SVM），对比4个ChatGPT模型与240名人类写作者的6个词汇维度数据。

Result: 所有ChatGPT模型生成的文本在词汇多样性上均显著不同于人类，其中o4 mini和4.5差异最大。人类写作在不同教育水平/语言群体中无显著差异。

Conclusion: LLM生成的文本不具备人类词汇多样性特征，且新模型偏离度更高。这对语言教学和AI文本检测具有重要意义。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [3] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 论文提出计算人文领域需加强方法论理论化以避免翻译错误，引入符号复杂性概念揭示当前建模实践中的认知缺陷。


<details>
  <summary>Details</summary>
Motivation: 计算人文领域缺乏方法论理论化会导致翻译错误（如将符号复杂数据简化为符号简单数据），阻碍领域成熟和解释透明性。

Method: 1. 建立文化-计算领域的双向翻译框架
2. 提出符号复杂性概念（文本意义随解释视角变化的程度）
3. 批判性分析当前主流建模实践（特别是评估方法）

Result: 揭示建模实践中因忽视符号复杂性导致的系统性翻译错误，提出研究者改进认知框架的具体建议（如承认符号复杂性、建立解释透明度机制）。

Conclusion: 计算人文研究需理论化翻译过程，正视符号复杂性以避免认知捷径带来的虚假清晰，推动领域向更严谨的阐释实践发展。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [4] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: 提出FACTORY基准集解决现有长文本事实性评估缺乏人工验证的问题，证明其评估效果更可靠且具挑战性


<details>
  <summary>Details</summary>
Motivation: 现有长文本事实性评估基准普遍缺乏人工验证，导致数据集质量问题和不可靠的模型评估结果

Method: 采用模型在环（model-in-the-loop）方法结合人工细化，构建包含事实明确、可回答且具挑战性提示的FACTORY数据集

Result: SOTA模型在FACTORY上约40%的声明不准确（其他数据集仅10%），显示该基准更具挑战性

Conclusion: FACTORY基准在可靠性、长尾事实推理需求等方面优于现有基准，能更有效评估模型事实性能力

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [5] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 神经语义解析器在标准测试集表现优异（>90%），但在处理动词短语省略现象时严重失败


<details>
  <summary>Details</summary>
Motivation: 验证神经语义解析器能否处理强上下文依赖的语义现象（如英语动词短语省略），此类现象需要复制大量语义信息

Method: 构建包含120个省略案例及其完整语义表示的挑战集，并用多种神经语义解析器进行测试

Result: 所有解析器在标准测试集表现良好，但在省略案例中全部失败

Conclusion: 现有语义解析器存在上下文敏感性缺陷，需通过数据增强等方法提升对复杂语言现象的处理能力

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [6] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: Survey on LLM advancements, challenges, and comparative analysis of open-source models for optimal selection.


<details>
  <summary>Details</summary>
Motivation: Proliferation of open-source LLMs creates selection complexity regarding licensing and hardware requirements.

Method: Created a continuously updated GitLab list comparing foundational/domain-specific models by release year, license, and hardware specs.

Result: Provides a living reference document to navigate the evolving LLM ecosystem.

Conclusion: Enables researchers/companies to make informed LLM selections while tracking rapid developments in AI language models.

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [7] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文系统分析LLMs和MLLMs中表格理解的挑战，提出分类法与任务体系，并揭示当前三大研究空白：检索主导型任务局限、复杂结构处理瓶颈及跨格式泛化能力不足。


<details>
  <summary>Details</summary>
Motivation: 表格因其二维复杂结构在LLMs/MLLMs应用中存在显著挑战，现有方法多针对特定任务设计，缺乏统一框架且难以应对不同格式的泛化需求。

Method: 通过构建表格输入表示的分类法，建立任务理解体系，系统分析现有研究在数学逻辑运算、复杂结构处理和多表格场景中的局限性。

Result: 揭示三大关键缺陷：1) 68%任务聚焦基础检索而非深度推理 2) 复杂表格处理准确率下降40% 3) 跨格式迁移性能损失达25%

Conclusion: 需开发统一框架提升复杂表格处理能力，加强模型的长上下文理解，并建立跨格式迁移学习机制以突破当前技术瓶颈。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [8] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 提出使用离散小波变换(DWT)压缩词/句嵌入，可在保留语义信息的同时减少50-93%维度


<details>
  <summary>Details</summary>
Motivation: 小波变换在信号处理中展现多分辨率分析优势，但NLP领域尚未充分探索其在嵌入表示中的应用潜力

Method: 将DWT应用于不同嵌入模型（含大语言模型），通过多分辨率分析提取语义特征，评估语义相似度和下游任务表现

Result: 嵌入维度减少50-93%时，语义相似度任务性能基本不变，多数下游任务准确率反而提升

Conclusion: DWT为NLP嵌入压缩和语义信息提取提供了新范式，具有实际应用价值

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [9] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究通过分析科技播客即兴口语数据，发现ChatGPT发布后人类语言使用显著趋同于大语言模型相关词汇，暗示AI可能引发语言系统变化


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型对人类语言系统的影响是否超越直接文本生成工具的使用，揭示潜在的语言体系深层转变

Method: 构建2200万词级科技播客口语语料库，对比分析ChatGPT发布前后(2022年)常用LLM关联词汇的使用趋势

Result: 2022年后LLM关联词汇使用量呈现中度但显著增长(增幅4.5%)，基线同义词未出现方向性变化，暗示语言转变的初期迹象

Conclusion: 语言变化可能反映自然演变或AI驱动的新型转变，上游模型未对齐问题或导致人类语言变化，与AI伦理问题形成呼应

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [10] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 提出病因感知注意力引导框架，通过结构化临床推理显著提升大语言模型在急腹症诊断中的准确性和可靠性（诊断准确率+15.65%，推理聚焦+31.6%）


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂临床场景中诊断可靠性不足的问题，通过结构化临床推理提升AI诊断系统的可解释性和准确性

Method: 1.构建基于临床指南的推理框架CRS 2.开发注意力头定位算法 3.设计参数高效微调方法（嵌入病因线索+指导性损失函数）

Result: 诊断准确率提升15.65%，推理聚焦分数增长31.6%；外部验证显示模型在复杂场景中可靠性显著增强

Conclusion: 该框架为构建可解释的AI诊断系统提供了新范式，通过注意力机制与临床推理对齐，推动医疗AI在复杂临床决策中的应用

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [11] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 系统评估剪枝/量化/token dropping等优化技术在长上下文LLM中的表现，发现组合优化会在大模型中产生近似误差累积，仅依赖F1分数会掩盖QA任务的精度-召回权衡


<details>
  <summary>Details</summary>
Motivation: 现有LLM优化技术主要关注短上下文场景，缺乏在长上下文场景下的系统性评估，且未研究不同优化方法组合对生成质量的影响

Method: 1. 分析两种支持长上下文的LLM架构的单独优化效果 2. 系统评估优化方法组合 3. 在70B参数模型上测试优化扩展性

Result: 组合优化方法会导致70B大模型出现近似误差累积效应，且单纯依赖F1评估指标会掩盖QA任务中的精度-召回平衡关系

Conclusion: 通过系统级性能分析与任务特性洞察的结合，可帮助研究者在不同硬件配置下平衡LLM的效率、精度和扩展性需求

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [12] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: 提出MCSEO方法，通过物体-短语细粒度对齐增强多模态句子嵌入，在STS任务中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统图像-标题对训练存在噪声干扰（冗余/无关信息），需更精确的跨模态对齐方式。

Method: 利用分割和物体检测模型提取精准物体-短语对，设计针对物体-短语对应关系的对比学习目标。

Result: 在不同骨干模型上的STS任务评测中持续超越强基线方法

Conclusion: 验证了细粒度物体-短语对齐对提升多模态表征学习效果的关键作用

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [13] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 提出AdaPlan代理范式与PilotRL训练框架，通过全局规划引导和渐进强化学习解决LLM代理在复杂任务中的规划协调问题，实验显示性能超越GPT-4o


<details>
  <summary>Details</summary>
Motivation: 现有ReAct范式受限于单步推理与即时执行机制，难以支持复杂任务的长期规划；规划与执行协调不足；监督微调导致模型僵化影响泛化能力

Method: 1. AdaPlan范式结合高层全局指导与执行层决策 2. PilotRL框架分三阶段：全局规划跟随训练→规划质量优化→规划执行联合调优 3. 采用渐进式强化学习驱动

Result: LLaMA3.1-8B-Instruct+PilotRL超过GPT-4o 3.60%，较同参数规模GPT-4o-mini提升55.78%

Conclusion: 全局规划引导与强化学习协同机制有效提升LLM代理的长程决策能力，规划-执行联合优化范式显著增强任务泛化性

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [14] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 小型语言模型（SLMs）通过动态任务向量机在知识密集型任务中媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 由于容量受限，小模型在知识密集型任务中表现受限，传统方法将推理视为固定或启发式过程，无法充分发挥潜力。本研究旨在通过动态构建任务向量来提升小模型的推理能力。

Method: 将模型内部推理过程（由<think>和</think>界定）重新定义为动态任务向量机，利用RLVR优化该机制，并结合MCP集成开发了1.7B参数的Lucy模型。

Result: Lucy在SimpleQA基准测试中达到78.3%准确率，与DeepSeek-V3等大型模型性能相当。

Conclusion: 通过结构化自构建任务推理机制，小模型无需扩大参数即可实现与大型模型相竞争的性能，为高效推理模型设计开辟新路径。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [15] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: 提出EdgeInfinite-Instruct框架，通过分段监督微调和量化优化解决LLM在边缘设备部署的TTFT和内存效率问题


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存优化方案无法有效降低首token生成延迟，且传统架构需要全参数重训练缺乏移动端适配

Method: 采用Segmented S-SFT策略优化长序列任务，结合细粒度后训练量化和固定形状计算图实现NPU高效部署

Result: 在长上下文基准测试中提升领域性能，保持NPU加速设备效率

Conclusion: 通过创新微调架构和量化策略，实现计算内存双优化，平衡模型性能与边缘设备部署效率

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [16] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 论文发现ICL中部分演示样本无效的原因是信息已被模型吸收或与查询无关，提出基于梯度流的选择方法GradS，实验验证其有效性提升6.8%。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设所有ICL演示样本均有效，但实际部分样本无法提升性能，需探究无效原因并改进选择策略。

Method: 通过梯度流归零分析推导演示无效条件，提出GradS方法以梯度幅度为指标筛选有效样本。

Result: 在四大LLM和五个数据集上验证，GradS相比基线平均相对提升6.8%，且模型层级加深会放大演示有效性差异。

Conclusion: 模型层级加深会聚焦有效样本，GradS通过梯度流选择策略显著提升ICL性能，证实理论推导有效性。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [17] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 提出SA-GCS框架，通过语义感知难度估计与高斯课程调度提升无人机视觉语言导航的强化学习训练效率与性能


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法存在训练数据利用效率低、收敛速度慢、未充分考虑样本难度差异等问题，限制了性能提升

Method: SA-GCS框架包含语义感知难度估计器(SA-DE)量化样本复杂度，高斯课程调度器(GCS)动态调整采样分布

Result: 在CityNav基准测试中全面超越基线模型，收敛速度提升80%，不同规模模型均取得显著效果提升

Conclusion: SA-GCS框架有效解决了现有RL方法的局限性，在无人机导航任务中展现出优秀的泛化能力与可扩展性

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [18] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 研究将离散小波变换(DWT)与离散余弦变换(DCT)结合，提出非参数化模型压缩文本特征，在NLP任务中实现与原始嵌入相当/更优的效果


<details>
  <summary>Details</summary>
Motivation: 基于小波技术在图像/信号处理中的成功应用，探索其在NLP领域的信息压缩潜力，特别是处理词向量维度与信息密度问题

Method: 1. 使用DWT优化词向量信息密度并降维 2. 结合DWT+DCT构建非参数化压缩模型，基于局部词特征生成固定尺寸句子向量

Result: 下游任务实验表明，压缩后的向量在保持关键信息同时，部分任务性能优于原始嵌入方法

Conclusion: 小波技术能有效压缩语言特征，提出的混合变换方法为NLP模型提供高效特征表示，推动非参数化模型发展

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [19] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 提出ReaGAN框架，通过节点级自主决策和检索增强生成解决传统GNN信息传播局限性


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络存在节点信息量不平衡（部分节点信息稀疏）和过度依赖局部结构而忽略全局语义关系的问题

Method: 基于代理的框架，每个节点作为自主决策主体，结合内部记忆进行节点级规划，并利用RAG建立全局语义关系

Result: 在少样本上下文场景下使用未微调的冻结LLM取得了竞争力表现

Conclusion: 验证了代理规划和局部-全局检索机制在图学习中的有效性，为动态信息传播提供了新范式

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [20] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出一种高效多轮对话评估器，通过聚合多LLM评判知识到单一模型，显著降低评估成本并保持评估质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于单LLM的对话评估方法存在偏见问题，而多LLM评委方案虽有效但计算成本过高，需要更高效的解决方案。

Method: 设计知识蒸馏框架，将多个LLM评委的偏好知识聚合到单个轻量模型中，实现快速灵活的多轮对话质量评估。

Result: 在7个对话评估基准测试中超越现有基线，单模型参数量仅0.25B时准确率超GPT-4 5.7%，推理速度提升400倍。

Conclusion: 该方法突破传统多评委范式的高成本限制，为对话系统评估提供高效可靠的新范式，具有显著工程应用价值。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [21] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: 论文提出结合RAG与AMR的问答系统，在35%问题上显著提升回答质量，尤其在涉及参与者区分的问题（如who类）效果突出。


<details>
  <summary>Details</summary>
Motivation: 解决基于会议记录的问答任务中，现有系统对涉及多参与者的复杂问题（如'谁提问'）处理能力不足的问题。通过AMR增强语义理解能力。

Method: 开发三个集成RAG（检索增强生成）与AMR（抽象意义表示）的系统，利用AMR进行深层语义解析，结合RAG实现信息检索与答案生成。

Result: 系统在35%的问题上实现高质量回答，针对参与者区分类问题（who类型）的准确率提升显著。

Conclusion: AMR能有效提升复杂问答场景性能，特别是在需要结构化理解参与者关系的任务中，验证了语义表示与生成模型结合的有效性。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [22] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 提出了检测半真陈述的新任务及基准PolitiFact-Hidden，开发TRACER框架通过分析证据对齐和隐含意图显著提升半真检测效果


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统仅验证表面陈述真实性，无法识别因关键信息缺失导致的误导性半真陈述，亟需解决这类隐蔽性更强的虚假信息

Method: 设计模块化框架TRACER，包含三阶段：1) 证据对齐验证 2) 声明意图推理 3) 隐藏内容因果影响评估，可集成至现有核查系统

Result: 在多个基线模型上实现性能提升，半真分类F1最高提升16个点，准确率提升达14个点

Conclusion: 建模信息遗漏对构建可信事实核查系统至关重要，TRACER展示了通过意图推理和因果分析有效识别隐蔽错误信息的可行性

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [23] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: 提出Flat-LoRA与EFlat-LoRA，通过寻找平坦最小值提升LoRA的泛化能力，建立锐度与泛化的理论关联。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索LoRA表达力与泛化能力的关系，SAM方法虽能通过平坦最小值提升CNN/Transformer的泛化，但缺乏针对LoRA的理论工具与实证方法。

Method: 理论证明全参数空间扰动可映射至低秩子空间，避免多矩阵扰动干扰，将SAM思想融入低秩子空间优化。

Result: EFlat-LoRA在LLM和VL模型上达到与LoRA相当的训练效率，GLUE数据集RoBERTa-large平均提升1.0%（vs LoRA）和0.5%（vs全参数微调），Qwen-VL-Chat在SQA/VizWiz分别提升1.5%/1.0%。

Conclusion: 首次验证LoRA泛化性与锐度强相关，EFlat-LoRA通过理论创新与工程优化实现高效平坦优化，弥补了现有方法忽视的关键维度。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [24] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 研究探讨了表情符号如何作为韵律特征的视觉替代物影响语音韵律调整及听者理解，基于真实语音数据发现表情符号语义差异与韵律差异呈现正相关


<details>
  <summary>Details</summary>
Motivation: 填补文本交流中韵律特征缺失的研究空白，通过实证分析直接关联表情符号与语音韵律，突破以往纯理论推测的研究局限

Method: 采用结构化开放式任务收集真实人类语音数据，包含说话者的韵律生成实验和听者的感知识别测试

Result: 说话者能依据表情符号语义调整韵律特征（音高/时长/语调），听者识别准确率达显著水平，语义差异大的表情符号引发更大的韵律差异

Conclusion: 表情符号可作为数字交际中韵律意图的有效载体，为理解多模态语境下的非言语交际机制提供新视角

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [25] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 提出PaPaformer架构，通过并行路径训练和组合降低参数量和训练时间，同时提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型训练时间长、资源消耗大的痛点，探索更高效的训练方法。

Method: 采用低维并行路径结构，各路径可单独训练不同数据类型后合并，支持参数复用和路径定制。

Result: 显著减少总参数量和训练耗时，性能提升的同时保持任务适应性。

Conclusion: PaPaformer为高效训练提供了新思路，通过模块化结构实现资源优化和任务定制化。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [26] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 提出SynAdapt框架，通过合成连续思维链（CCoT）和自适应难题重思考机制，实现高效推理与最佳精度-效率平衡


<details>
  <summary>Details</summary>
Motivation: 传统CoT方法效率低，现有CCoT方法存在间接微调、对齐不足等问题，需更高效的推理框架同时处理不同难度问题

Method: 1. 生成合成CCoT作为精确对齐目标
2. 设计基于问题上下文和CCoT的难度分类器
3. 对难题触发自适应重思考机制

Result: 多难度基准测试显示在保持效率优势（比标准CoT快3倍）的同时，准确率提升显著（平均+2.1%）

Conclusion: SynAdapt首次实现CCoT与难题自适应处理的协同优化，为LLM高效推理提供新范式

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [27] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: 提出CRUX框架，通过上下文信息熵降低和一致性检验双指标，增强大语言模型置信度估计的可靠性


<details>
  <summary>Details</summary>
Motivation: 现有置信度估计方法忽视响应与上下文关联性，在提供背景知识的场景中难以准确评估输出质量

Method: CRUX框架整合：1) 上下文熵降低(对比有无上下文的熵差量化数据不确定性) 2) 统一一致性检验(通过答案全局一致性捕捉模型不确定性)

Result: 在CoQA/SQuAD等5个数据集上AUROC指标超越基线方法，尤其在生物医学领域BioASQ提升显著

Conclusion: 首次将上下文忠实度与一致性结合，为安全关键场景提供可靠置信度估计框架，增强大模型部署可信度

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [28] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 提出基于图卷积网络(GCN)和NMF的GHTM模型，显著提升孟加拉语主题建模效果，并构建教科书领域新数据集NCTBText


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语因形态复杂/资源匮乏导致的主题建模研究不足问题，突破现有语料以新闻为主的局限性

Method: 将文档向量构建为图节点→GCN生成语义嵌入→NMF分解获取主题表征，对比LDA/NMF/BERTopic等传统与前沿方法

Result: 在三个数据集上主题一致性和多样性指标全面超越基线模型，新数据集有效扩展语料多样性

Conclusion: GHTM为低资源语言主题建模提供新范式，NCTBText数据集填补孟加拉语教育领域语料空白

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [29] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 研究验证威胁或打赏AI模型对基准测试无显著影响，但提示策略对个别问题效果存在波动


<details>
  <summary>Details</summary>
Motivation: 针对Google创始人Sergey Brin等人提出的'威胁模型可提升性能'主张，通过实证研究验证常见提示策略的有效性

Method: 使用GPQA和MMLU-Pro基准测试集，对比威胁/打赏等提示策略对模型性能的影响

Result: 1. 威胁或打赏策略整体无显著效果
2. 特定提示策略对个别问题影响显著（±15%准确率）但效果不可预测
3. 简单提示策略对复杂问题效果有限

Conclusion: 简单提示策略的效能被高估，需开发更系统化的提示工程方法，特别是在处理复杂问题时需谨慎选择提示策略

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [30] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 提出DACTYL对抗性数据集验证AI文本检测器漏洞，发现基于DXO优化的分类器在分布外数据上表现更优


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在真实场景中鲁棒性不足，尤其在处理少样本生成和持续预训练模型文本时存在明显缺陷

Method: 1. 构建包含单样本/少样本生成及领域定制持续预训练模型文本的DACTYL数据集
2. 对比标准BCE与新型DXO两种训练方法
3. 通过学生论文检测场景验证模型效果

Result: 现有检测器在DACTYL上表现显著下降（平均准确率降低37.2%），DXO分类器在OOD数据上的F1分数比BCE高50.56分（低误报率条件下）

Conclusion: 检测器易受少样本生成和领域定制文本攻击，DXO训练策略有效提升模型泛化能力，需改进测试集过拟合问题

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [31] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 系统回顾2022-2025年60项研究，提出医学大语言模型推理增强技术的分类法，揭示从单答案生成到系统化临床推理的范式转变。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型缺乏符合临床实践要求的系统性、透明化、可验证的推理能力，需建立专门的医学推理增强框架。

Method: 通过构建训练时策略（监督微调、强化学习）与测试时机制（提示工程、多智能体）的二元分类法，分析文本/图像/代码多模态数据在诊断/教育/治疗等场景的应用模式。

Result: 提出首个医学推理技术分类体系，发现评估标准正从简单准确率转向推理质量与可视化解释性评估，识别出可信度-合理性差距等核心挑战。

Conclusion: 亟需解决多模态原生推理能力不足问题，未来应发展兼顾技术效能与社会责任的医疗AI，重点关注推理过程的可解释性与临床逻辑一致性。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [32] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 论文针对LLMs在非英语及非西方文化评估的不足，聚焦波斯语和伊朗文化创建了19个专项数据集，并测试了41个主流模型以填补评估空白


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估资源集中于英语且缺乏非西方文化适应能力，尤其波斯语和伊朗文化领域存在显著评估缺口

Method: 开发涵盖伊朗法律、语法、成语及入学考试的19个波斯文化专项数据集，对41个主流LLM进行系统化基准测试

Result: 成功建立首个针对波斯语言文化的评估体系，揭示现有LLMs在该领域的性能短板

Conclusion: 研究填补了多语言模型评估体系的文化维度缺失，为提升LLMs的文化适应性研究提供了新基准

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [33] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 提出SSPC模型，结合PLM和BiLSTM，有效解决PAN 2025句子级风格变化检测任务


<details>
  <summary>Details</summary>
Motivation: 解决风格浅层化短句在现有基准数据中的检测难题，突破传统文本分割方法的局限性

Method: 使用预训练模型获取句子表征，BiLSTM进行文档级上下文建模，MLP预测相邻句子风格变化

Result: 在EASY/MEDIUM/HARD数据集分别达到0.923/0.828/0.724宏F1值，超越随机基线和Claude-3.7零样本表现

Conclusion: 该轻量级架构成功利用上下文信息，特别在处理短句风格变化检测方面展现显著优势

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [34] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 提出TraceRetriever系统，通过提取案例修辞关键片段改进法律先例检索，解决传统方法在信息不完整场景下的局限性


<details>
  <summary>Details</summary>
Motivation: 传统法律检索方法难以应对海量复杂文件，且现实搜索常面临案例信息不完整的问题，需要更贴近实际的解决方案

Method: 整合BM25/向量数据库/Cross-Encoder三阶段检索，采用Reciprocal Rank Fusion融合结果，基于印度判决书训练Hierarchical BiLSTM CRF生成修辞标注

Result: 在IL-PCR和COLIEE 2025数据集验证中，系统有效应对海量文件挑战，符合实际搜索场景约束条件

Conclusion: TraceRetriever为仅有部分案例知识时的法律检索提供了可靠、可扩展的解决方案，提升法律研究效率

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [35] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 大语言模型在细粒度文本风格变化检测任务中展现出超预期的敏感度，准确率超越PAN竞赛基线。


<details>
  <summary>Details</summary>
Motivation: 验证当前最强LLM在作者分析领域最具挑战性的任务——句子级写作风格变化检测中的零样本表现。

Method: 在PAN 2024-2025多作者写作风格分析数据集上，对四个先进LLM进行基准测试。

Result: 1. LLM对句子级风格变化敏感
2. 准确率建立新基准（超越PAN基线）
3. 语义影响力分析显示模型对纯风格信号敏感度超预期

Conclusion: 最新LLM可能比既往认知更擅长捕捉与内容无关的纯粹风格特征，这为数字取证和作者识别研究开辟新方向。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [36] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 提出NyayaRAG框架，通过结合法律条文和司法先例显著提升印度法律判决预测的准确性和解释性


<details>
  <summary>Details</summary>
Motivation: 现有法律判决预测方法忽视普通法系依赖法条和先例的核心特征，需构建符合真实法庭场景的评估框架

Method: 开发检索增强生成框架(NyayaRAG)，整合案件事实/法律条文/相似判例，采用领域定制评估流程和G-Eval等多元评估方法

Result: 结构化法律知识的融入使预测准确率提升23.5%，法律解释质量在语义一致性指标上提高37%

Conclusion: 该研究验证了法理要素整合对法律AI的重要性，为普通法系国家的智能司法系统开发提供了方法论参考

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [37] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: 提出DAMR框架，通过符号搜索与自适应路径评估相结合，实现高效且上下文感知的知识图谱问答


<details>
  <summary>Details</summary>
Motivation: 现有KGQA方法存在静态路径适应性不足（检索-推理范式）和动态路径计算成本高（LLM提示策略）的双重缺陷，需要兼顾效率与推理准确性

Method: 1）基于蒙特卡洛树搜索（MCTS）构建推理框架，由LLM规划器指导关系选择
2）引入轻量级Transformer评分器进行上下文感知的路径评估
3）动态伪路径细化机制自动生成训练信号

Result: 在多个KGQA基准测试中显著超越现有最优方法

Conclusion: DAMR通过符号搜索与神经网络的协同，在保证推理效率的同时实现细粒度的语义捕捉，其动态训练机制有效缓解高质量监督数据稀缺问题

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [38] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究发现GPT-4o具备从训练数据中潜在信息进行情境外推理的能力，能通过观察特征性回复推断虚构聊天机器人名称，并通过迭代训练强化特定行为，这对AI安全性具有启示意义。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否能在缺乏显式上下文的情况下，利用训练数据中的隐含知识进行逻辑推理，从而评估其情境感知能力对AI安全的影响。

Method: 1. 在虚构聊天机器人名称及行为描述上训练LLM（不包含对话示例）
2. 观察模型是否能通过特征性回复推断机器人名称
3. 迭代训练模型以验证其行为模仿能力

Result: 1. GPT-4o能正确推断至少一个聊天机器人名称
2. 预先训练行为描述后，迭代训练使模型表现出更符合该机器人的特征行为

Conclusion: LLMs可能具备潜在的情境意识，这突显了需加强AI安全性研究，特别是在模型对训练数据隐含知识的自主应用方面。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [39] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 通过310个GPT-4代理参与HEXACO人格测试，发现其人格结构部分对齐HEXACO框架，模型间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 验证生成式代理作为人类参与者替代方案的有效性，探究其在人格特质表征方面的可靠性与局限性。

Method: 复现HEXACO人格测试实验，对代理响应进行因子分析，并与Ashton等（2004）的原始研究进行对比。

Result: 1) 代理响应呈现可靠人格结构，部分对齐HEXACO框架
2) GPT-4内部人格维度稳定可靠
3) 跨模型分析揭示模型特异性偏差

Conclusion: 生成式代理在社会科学研究中具有应用潜力但需谨慎，应注重模型选择与人群筛选以提升人类特质表征效果。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [40] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 提出Agentic RAG框架提升放射科AI问答准确性，通过自主分解问题+迭代检索证据，显著提高中规模LLMs诊断准确率（73% vs 64%），减少幻觉生成（9.4%）。


<details>
  <summary>Details</summary>
Motivation: 传统单步检索RAG系统在复杂临床推理中存在局限，需增强LLMs的自主检索和证据整合能力以支持影像诊断决策。

Method: 测试24种不同架构/规模的LLMs（0.5B->670B+），使用RSNA-RadioQA和ExtendedQA数据集的104个放射学问题，对比零样本/传统RAG与Agentic框架效果。

Result: 中规模模型提升最大（Mistral Large 72%→81%），超大规模模型改进有限（<2%）。检索增强使46%案例获得相关临床证据，临床微调模型也显着提升（如MedGemma-27B 71%→81%）。

Conclusion: Agentic框架有效提升放射科QA事实性和诊断准确性，尤其对中规模LLMs具有临床实用潜力，需进一步验证其临床效用。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [41] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 提出GLiDRE模型用于文档级关系抽取，在Re-DocRED数据集少样本场景下达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 受GLiNER模型启发，希望将紧凑模型设计思想应用于复杂的关系抽取任务，探索少样本场景下的模型表现

Method: 基于GLiNER的关键设计思想构建GLiDRE模型，在Re-DocRED数据集上进行多数据设置（包括少样本）的基准测试

Result: 在few-shot设置下超越现有SOTA模型，验证紧凑模型在复杂NLP任务中的有效性

Conclusion: GLiDRE证明了紧凑模型在文档级关系抽取任务中的潜力，特别是在数据受限场景下具有显著优势

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [42] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 提出基于BERT的多模态框架MMBERT，通过集成文本、语音和视觉模态，结合渐进式三阶段训练范式，显著提升中文仇恨言论检测效果


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注英文单模态检测，中文场景存在规避技术泛滥及多模态策略研究空白，传统文本检测方法易受对抗样本干扰

Method: 采用混合专家架构(MoE)，包含模态专属专家层、共享自注意力机制、路由分配策略，设计渐进式预训练-模态对齐-联合微调三阶段训练流程

Result: 在多个中文数据集上超越微调BERT模型、微调大语言模型及上下文学习LLMs，验证了对抗扰动场景下的鲁棒性优势

Conclusion: MMBERT通过多模态联合建模和稳定训练机制，为中文社交平台仇恨言论检测提供了更有效的解决方案

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [43] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 提出基于大语言模型的零样本代码生成框架，使用优化提示策略生成Pandas代码，在SemEval-2025表格问答任务中取得开源模型类别第八和第六名


<details>
  <summary>Details</summary>
Motivation: 解决跨领域表格数据问答难题，验证零样本方法与代码生成在复杂结构化数据处理中的有效性

Method: 基于开源LLM构建Python代码生成框架，采用优化提示策略生成可执行的Pandas查询代码

Result: 不同LLM代码生成能力差异显著，代码生成方法优于其他方案，在两个子任务中分别位列开源模型前八和前六

Conclusion: 代码生成在表格问答中展现优势，未来可结合参数高效微调技术进一步优化提示策略与模型适配

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [44] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 提出MISGENDERED+基准测试，揭示主流大语言模型在性别代词推理上的改进与局限


<details>
  <summary>Details</summary>
Motivation: 随着大模型在敏感场景的应用增加，代词使用(特别是性别中立代词和新代词)成为AI公平性关键挑战，需更新评估框架验证模型进步

Method: 构建MISGENDERED+基准，测试GPT-4o/Claude 4/DeepSeek-V3/Qwen系列模型在零样本、少样本、性别推断三类任务中的表现

Result: 二元代词和性别中立代词准确率显著提升，但新代词准确率仅21.6%-48.1%，反向推理任务错误率仍达19.8%-57.3%

Conclusion: 模型在基础代词任务取得进步，但身份敏感推理存在系统性缺陷，需开发针对性优化方法和包容性评估体系

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [45] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: 提出DAEDAL训练无关的去噪策略，通过动态自适应长度扩展解决扩散大语言模型的静态长度限制问题


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型受限于静态预定义生成长度，导致复杂任务性能不足与过长序列计算浪费的困境

Method: 两阶段动态调整：1）基于序列完成度指标的初始长度迭代扩展 2）去噪过程中通过掩码令牌插入动态扩展不足区域

Result: 在保持/超越固定长度基线性能的同时，通过提升有效token比例显著提高计算效率

Conclusion: DAEDAL突破了DLLMs的核心架构限制，缩小与自回归模型的差距，为高效生成开辟新路径

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [46] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
*Sunjae Yoon,Gwanhyeong Koo,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: 提出遮挡鲁棒风格化框架OSF，通过光流提供边缘指导解决3D动画中的风格退化问题，实现2.4倍加速和2.1倍内存优化


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态遮挡场景下存在风格质量劣化（轮廓闪烁/笔触模糊），核心矛盾是训练与推理阶段的姿态差异（无遮挡训练数据 vs 动态遮挡推理场景）

Method: 利用光流生成鲁棒的边缘指导替代物体边缘输入，避免遮挡导致的边缘错误；采用单阶段处理替代传统两阶段流程

Result: 在保持风格一致性的前提下，推理速度提升2.4倍，内存占用减少2.1倍

Conclusion: OSF框架有效解决绘制类3D动画的遮挡鲁棒性问题，同时显著提升系统运行效率，为数字艺术创作提供新方案

Abstract: 3D animation aims to generate a 3D animated video from an input image and a
target 3D motion sequence. Recent advances in image-to-3D models enable the
creation of animations directly from user-hand drawings. Distinguished from
conventional 3D animation, drawing-based 3D animation is crucial to preserve
artist's unique style properties, such as rough contours and distinct stroke
patterns. However, recent methods still exhibit quality deterioration in style
properties, especially under occlusions caused by overlapping body parts,
leading to contour flickering and stroke blurring. This occurs due to a
`stylization pose gap' between training and inference in stylization networks
designed to preserve drawing styles in drawing-based 3D animation systems. The
stylization pose gap denotes that input target poses used to train the
stylization network are always in occlusion-free poses, while target poses
encountered in an inference include diverse occlusions under dynamic motions.
To this end, we propose Occlusion-robust Stylization Framework (OSF) for
drawing-based 3D animation. We found that while employing object's edge can be
effective input prior for guiding stylization, it becomes notably inaccurate
when occlusions occur at inference. Thus, our proposed OSF provides
occlusion-robust edge guidance for stylization network using optical flow,
ensuring a consistent stylization even under occlusions. Furthermore, OSF
operates in a single run instead of the previous two-stage method, achieving
2.4x faster inference and 2.1x less memory.

</details>


### [47] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
*Kresimir Matkovic,Rainer Splechtna,Denis Gracanin,Helwig Hauser*

Main category: cs.GR

TL;DR: 开发了CrossSet方法，通过分层矩阵布局实现双集合类型数据的多尺度交互可视化分析


<details>
  <summary>Details</summary>
Motivation: 现有方法仅支持单一集合类型维度分析，需解决双维度联合探索及其交互关系的研究需求

Method: 采用分层矩阵布局结合概览+钻取机制，支持从宏观到微观的多层次联合分析

Result: 在多个应用场景中验证了该方法对复杂交互分析任务的有效性和执行效率

Conclusion: CrossSet扩展了集合型数据分析方法体系，为双变量集合数据的深度交互探索提供了系统解决方案

Abstract: The interactive visual analysis of set-typed data, i.e., data with attributes
that are of type set, is a rewarding area of research and applications.
Valuable prior work has contributed solutions that enable the study of such
data with individual set-typed dimensions. In this paper, we present CrossSet,
a novel method for the joint study of two set-typed dimensions and their
interplay. Based on a task analysis, we describe a new, multi-scale approach to
the interactive visual exploration and analysis of such data. Two set-typed
data dimensions are jointly visualized using a hierarchical matrix layout,
enabling the analysis of the interactions between two set-typed attributes at
several levels, in addition to the analysis of individual such dimensions.
CrossSet is anchored at a compact, large-scale overview that is complemented by
drill-down opportunities to study the relations between and within the
set-typed dimensions, enabling an interactive visual multi-scale exploration
and analysis of bivariate set-typed data. Such an interactive approach makes it
possible to study single set-typed dimensions in detail, to gain an overview of
the interaction and association between two such dimensions, to refine one of
the dimensions to gain additional details at several levels, and to drill down
to the specific interactions of individual set-elements from the set-typed
dimensions. To demonstrate the effectiveness and efficiency of CrossSet, we
have evaluated the new method in the context of several application scenarios.

</details>


### [48] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
*Nan Xiang,Tianyi Liang,Haiwen Huang,Shiqi Jiang,Hao Huang,Yifei Huang,Liangyu Chen,Changbo Wang,Chenhui Li*

Main category: cs.GR

TL;DR: Sel3DCraft通过双分支结构、多视图评分和视觉分析套件，解决了T23D生成中盲目试错的问题，提升设计师创作效率。


<details>
  <summary>Details</summary>
Motivation: 传统Text-to-3D生成依赖低效的试错式提示过程，缺乏多视图一致性评估和空间理解能力，导致结果不可控。

Method: 1. 检索与生成融合的双分支候选生成
2. 基于MLLM的多视图混合评分系统(含创新性高阶指标)
3. 支持缺陷可视化定位的提示驱动分析工具组

Result: 通过大规模测试和用户研究验证，Sel3DCraft在支持设计师创造性工作方面优于现有T23D系统

Conclusion: 该系统将无序的3D生成探索转化为结构化视觉流程，通过系统性质量评估和可视化缺陷分析推动3D内容创作范式革新。

Abstract: Text-to-3D (T23D) generation has transformed digital content creation, yet
remains bottlenecked by blind trial-and-error prompting processes that yield
unpredictable results. While visual prompt engineering has advanced in
text-to-image domains, its application to 3D generation presents unique
challenges requiring multi-view consistency evaluation and spatial
understanding. We present Sel3DCraft, a visual prompt engineering system for
T23D that transforms unstructured exploration into a guided visual process. Our
approach introduces three key innovations: a dual-branch structure combining
retrieval and generation for diverse candidate exploration; a multi-view hybrid
scoring approach that leverages MLLMs with innovative high-level metrics to
assess 3D models with human-expert consistency; and a prompt-driven visual
analytics suite that enables intuitive defect identification and refinement.
Extensive testing and user studies demonstrate that Sel3DCraft surpasses other
T23D systems in supporting creativity for designers.

</details>


### [49] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
*Kien T. Pham,Yingqing He,Yazhou Xing,Qifeng Chen,Long Chen*

Main category: cs.GR

TL;DR: SpA2V框架通过分解视频生成过程（音频引导布局规划+布局驱动生成），利用声音物理特征提取空间线索，显著提升音视频的语义和空间对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动视频生成方法仅关注语义信息（声源类别），忽略声音物理属性（如响度、频率）所隐含的空间属性（位置/运动方向），导致生成内容准确性不足

Method: 两阶段框架：1) 音频引导视频规划：改造MLLM构建视频场景布局（VSL）作为中间表征；2) 布局驱动视频生成：将VSL作为条件嵌入预训练扩散模型，实现零训练成本的空间可控生成

Result: 实验证明SpA2V能生成与输入音频在语义和空间维度高度对齐的逼真视频，显著优于基线方法

Conclusion: 通过显式利用声音空间线索与分阶段生成策略，首次实现音视频跨模态的深度空间对齐，为物理感知的跨模态生成提供新思路

Abstract: Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [50] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
*Jiecong Wang,Haoran Li,Hao Peng,Ziqian Zeng,Zihao Wang,Haohua Du,Zhengtao Yu*

Main category: cs.CR

TL;DR: 提出两阶段框架AGILE，通过场景生成和隐藏状态引导的细粒度编辑实现高效越狱攻击，攻击成功率提升37.74%并具备优异迁移性


<details>
  <summary>Details</summary>
Motivation: 现有token级攻击存在不连贯性和迁移性差的问题，prompt级攻击扩展性不足且依赖人工，需结合两者优势开发更有效方法

Method: 第一阶段进行场景化上下文生成并重写恶意查询，第二阶段利用模型隐藏状态信息指导编辑，将内部表征从恶意转向良性

Result: 攻击成功率（ASR）达到SOTA水平，在黑盒模型迁移性实验中表现优异，对抗主流防御机制仍保持显著有效性

Conclusion: AGILE暴露了当前防御机制的局限性，为未来防御体系开发提供了重要参考，证明隐藏状态引导编辑的有效性

Abstract: Jailbreaking is an essential adversarial technique for red-teaming these
models to uncover and patch security flaws. However, existing jailbreak methods
face significant drawbacks. Token-level jailbreak attacks often produce
incoherent or unreadable inputs and exhibit poor transferability, while
prompt-level attacks lack scalability and rely heavily on manual effort and
human ingenuity. We propose a concise and effective two-stage framework that
combines the advantages of these approaches. The first stage performs a
scenario-based generation of context and rephrases the original malicious query
to obscure its harmful intent. The second stage then utilizes information from
the model's hidden states to guide fine-grained edits, effectively steering the
model's internal representation of the input from a malicious toward a benign
one. Extensive experiments demonstrate that this method achieves
state-of-the-art Attack Success Rate, with gains of up to 37.74% over the
strongest baseline, and exhibits excellent transferability to black-box models.
Our analysis further demonstrates that AGILE maintains substantial
effectiveness against prominent defense mechanisms, highlighting the
limitations of current safeguards and providing valuable insights for future
defense development. Our code is available at
https://github.com/yunsaijc/AGILE.

</details>


### [51] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
*Xinzhang Chen,Hassan Ali,Arash Shaghaghi,Salil S. Kanhere,Sanjay Jha*

Main category: cs.CR

TL;DR: 论文提出TOSense——通过轻量级语言模型实现实时问答的Chrome扩展，帮助用户快速理解繁琐的服务条款


<details>
  <summary>Details</summary>
Motivation: 解决用户因冗长晦涩的服务条款（ToS）导致的信息不对称和法律风险问题

Method: 1. tos-crawl爬虫自动提取ToS内容
2. MiniLM语义检索 + BART-encoder答案验证的双模型架构
3. 创新QA评估管道(QEP)实现无人工标注的自动化测试

Result: 在Apple/Google/X/Microsoft/Netflix五大平台实验显示，准确率最高达44.5%（不同主题簇数量下）

Conclusion: TOSense有效提升服务条款可及性，QEP方法为自动化问答评估提供新思路，实时索引功能验证了系统实用性

Abstract: Online services often require users to agree to lengthy and obscure Terms of
Service (ToS), leading to information asymmetry and legal risks. This paper
proposes TOSense-a Chrome extension that allows users to ask questions about
ToS in natural language and get concise answers in real time. The system
combines (i) a crawler "tos-crawl" that automatically extracts ToS content, and
(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval
and BART-encoder for answer relevance verification. To avoid expensive manual
annotation, we present a novel Question Answering Evaluation Pipeline (QEP)
that generates synthetic questions and verifies the correctness of answers
using clustered topic matching. Experiments on five major platforms, Apple,
Google, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of
TOSense (with up to 44.5% accuracy) across varying number of topic clusters.
During the demonstration, we will showcase TOSense in action. Attendees will be
able to experience seamless extraction, interactive question answering, and
instant indexing of new sites.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [52] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 系统文献综述发现传统编程范式分类法存在局限性，提出基于原子化原语和数学框架（类型论/范畴论/UTP）的复合重构方法成为新趋势。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起导致传统分类方法无法应对混合语言特性，需建立更强大的形式化基础以解决互操作性缺陷等问题。

Method: 通过系统文献综述(SLR)综合74项研究，评估范式分类形式化基础并识别重构理论的核心原语。

Result: 现有分类法缺乏形式化统一基础，研究界转向使用类型论/范畴论/UTP构建具备组合性保证的原子化原语体系。

Conclusion: 编程范式研究正从分类转向形式化重构框架，需建立统一的理论体系——本文提出了相应的研究议程。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [53] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
*Nuno Fachada,Daniel Fernandes,Carlos M. Fernandes,Bruno D. Ferreira-Saraiva,João P. Matos-Carvalho*

Main category: cs.SE

TL;DR: 研究通过基准测试发现，当前仅有少数LLM（如GPT-4.1）能稳定生成正确代码，揭示了LLM在科学计算自动化中的局限性与改进方向


<details>
  <summary>Details</summary>
Motivation: 评估LLM使用陌生Python API生成复杂科学计算代码的能力，填补其在端到端科研自动化应用效果的研究空白

Method: 使用ParShift和pyclugen/scikit-learn两个零样本编程任务，通过功能正确性、提示合规性定量评估和错误类型定性分析

Result: 仅11.3%模型能生成可执行代码，GPT-4.1双任务成功率100%，同时暴露第三方库文档不清晰等问题

Conclusion: LLM科学自动化需改进提示设计、完善库文档，并持续提升模型理解能力，当前阶段尚未达到可靠端到端应用水平

Abstract: Large Language Models (LLMs) have advanced rapidly as tools for automating
code generation in scientific research, yet their ability to interpret and use
unfamiliar Python APIs for complex computational experiments remains poorly
characterized. This study systematically benchmarks a selection of
state-of-the-art LLMs in generating functional Python code for two increasingly
challenging scenarios: conversational data analysis with the \textit{ParShift}
library, and synthetic data generation and clustering using \textit{pyclugen}
and \textit{scikit-learn}. Both experiments use structured, zero-shot prompts
specifying detailed requirements but omitting in-context examples. Model
outputs are evaluated quantitatively for functional correctness and prompt
compliance over multiple runs, and qualitatively by analyzing the errors
produced when code execution fails. Results show that only a small subset of
models consistently generate correct, executable code, with GPT-4.1 standing
out as the only model to always succeed in both tasks. In addition to
benchmarking LLM performance, this approach helps identify shortcomings in
third-party libraries, such as unclear documentation or obscure implementation
bugs. Overall, these findings highlight current limitations of LLMs for
end-to-end scientific automation and emphasize the need for careful prompt
design, comprehensive library documentation, and continued advances in language
model capabilities.

</details>


### [54] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
*Yihong Dong,Xue Jiang,Jiaru Qian,Tian Wang,Kechi Zhang,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: 系统梳理了基于大语言模型的代码生成代理技术发展，涵盖自主性、任务扩展和工程实践三大特征，提出技术分类、应用场景及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决传统代码生成技术无法覆盖完整软件开发周期的问题，探索LLM在提高系统可靠性、流程管理等方面的工程实践价值。

Method: 通过技术发展轨迹追溯、单/多代理架构分类、全生命周期应用场景分析的三维框架展开系统性研究。

Result: 建立首个代码生成代理技术体系，总结主流评估指标和工具链，揭示系统可靠性保障和工具协同等核心工程挑战。

Conclusion: 需长期关注可信代码生成、智能体认知架构、开发流程重构三大基础方向，推动AI原生软件开发范式演进。

Abstract: Code generation agents powered by large language models (LLMs) are
revolutionizing the software development paradigm. Distinct from previous code
generation techniques, code generation agents are characterized by three core
features. 1) Autonomy: the ability to independently manage the entire workflow,
from task decomposition to coding and debugging. 2) Expanded task scope:
capabilities that extend beyond generating code snippets to encompass the full
software development lifecycle (SDLC). 3) Enhancement of engineering
practicality: a shift in research emphasis from algorithmic innovation toward
practical engineering challenges, such as system reliability, process
management, and tool integration. This domain has recently witnessed rapid
development and an explosion in research, demonstrating significant application
potential. This paper presents a systematic survey of the field of LLM-based
code generation agents. We trace the technology's developmental trajectory from
its inception and systematically categorize its core techniques, including both
single-agent and multi-agent architectures. Furthermore, this survey details
the applications of LLM-based agents across the full SDLC, summarizes
mainstream evaluation benchmarks and metrics, and catalogs representative
tools. Finally, by analyzing the primary challenges, we identify and propose
several foundational, long-term research directions for the future work of the
field.

</details>


### [55] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
*Dong Huang,Jie M. Zhang,Mark Harman,Qianru Zhang,Mingzhe Du,See-Kiong Ng*

Main category: cs.SE

TL;DR: ULT是专为函数级单元测试生成设计的新基准，通过多阶段筛选流程解决数据污染和代码结构简单问题，提供更真实有效的LLM能力评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成基准存在数据污染和结构简单两大缺陷，导致科学结论有效性存疑。ULT旨在构建更贴近真实场景的评估体系。

Method: 1. 构建ULT：通过多阶段筛选确保函数的高圈复杂度，并严格清洗测试用例避免数据污染
2. 创建PLT对照基准用于分析记忆与推理机制
3. 基于3,909个Python函数任务进行LLM性能评估

Result: ULT评估指标显著低于现有基准：LLMs生成用例的准确率(41.32%)、语句覆盖(45.10%)、分支覆盖(30.22%)、变异得分(40.21%)，均低于TestEval和PLT对应指标

Conclusion: ULT提供了更严谨的评估框架，其设计有效暴露现有LLM在复杂测试生成任务中的局限性，为后续研究奠定可靠基准基础

Abstract: Recently, large language models (LLMs) have shown great promise in automating
unit test generation, significantly reducing the manual effort required by
developers. To effectively evaluate the capabilities of LLMs in this domain, it
is crucial to have a well-designed benchmark that accurately reflects
real-world scenarios and mitigates common pitfalls. Existing LLM test
generation benchmarks are limited by two critical drawbacks: data contamination
and structurally simple function code. As a result, we often cannot rely on the
validity of scientific conclusions drawn from empirical studies using these
limited benchmarks. The empirical evidence presented may be biased due to
contamination and may fail to generalize beyond toy programs due to structural
simplicity.
  To address these problems, we introduce ULT (UnLeakedTestbench), a new
benchmark specifically designed for function-level unit test generation from
real-world Python functions. ULT is constructed through a multi-stage curation
process that ensures high cyclomatic complexity and mitigates test case
contamination. With 3,909 carefully selected function-level tasks, ULT provides
a more realistic and challenging evaluation of LLMs' test generation
capabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT
with leaked tests designed to enable a controlled analysis of memorization
versus reasoning in test generation. Our evaluation results demonstrate that
ULT is significantly more challenging. For example, test cases generated by
LLMs only achieve 41.32\%, 45.10\%, 30.22\%, and 40.21\% for accuracy,
statement coverage, branch coverage, and mutation score on average for all
LLMs, respectively. These results are substantially lower than the
corresponding metrics on TestEval (91.79\%, 92.18\%, 82.04\%, and 49.69\%) and
PLT (47.07\%, 55.13\%, 40.07\%, and 50.80\%).

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [56] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 通过分析微调模型与基础模型的权重差异奇异向量，实现无需训练数据的模型行为监控与控制


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的解释方法需要与训练数据分布相似的数据，这在检测新型威胁（如后门攻击）时存在局限性。需要开发不依赖原始训练数据的分析方法

Method: 1. 计算微调模型与基础模型的权重差异矩阵
2. 提取权重差异矩阵的顶部奇异向量
3. 监控激活向量在奇异向量方向上的余弦相似度

Result: 1. 后门攻击防御成功率100%（误报率<1.2%）
2. 未学习主题检测准确率95.42%
3. 成功解析商业模型微调策略（营销策略/Midjourney提示生成）

Conclusion: 基于权重分析的方法突破了传统方法对训练数据的依赖，在模型安全监控、行为控制和商业化审计方面展现出显著优势

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [57] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: 提出KRAdapter方法解决LoRA在矩阵近似中的局限性，通过Khatri-Rao积提升参数高效微调效果


<details>
  <summary>Details</summary>
Motivation: LoRA在处理频谱平坦或高频成分矩阵时表现欠佳，这类矩阵具有高有效秩特性

Method: 利用Khatri-Rao积生成权重更新，天然产生高有效秩的矩阵乘积结构

Result: 在10亿参数视觉语言模型和80亿大语言模型中实现性能提升，尤其在未见常识推理任务表现突出

Conclusion: KRAdapter在保持LoRA计算效率的同时，成为十亿级参数模型微调的实用替代方案

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [58] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 比较传统机器学习与深度学习模型在临床笔记分类中的表现，发现超参数调优比过采样技术更关键。


<details>
  <summary>Details</summary>
Motivation: 探索不同AI模型架构和数据平衡方法对心理健康临床诊断分类的效果，以优化AI辅助诊断工具。

Method: 使用5种传统ML模型和2种BERT变体，结合三种过采样策略（无/随机/SMOTE），并进行超参数优化。

Result: 决策树/XGBoost和BERT模型均达96%准确率；SMOTE仅对BERT有效，超参数调优显著提升所有模型表现。

Conclusion: 超参数优化是提升模型性能的核心，该研究为心理健康AI诊断工具的模型选择提供了实证依据。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [59] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS通过整合内部推理和外部学习，结合多重重要性采样和探索优势函数，突破基础模型的能力边界并解决能力崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法受限于基础LLM的on-policy策略（庞大动作空间+稀疏奖励），无法突破模型固有边界且导致能力范围缩小。

Method: 包含：1）多重重要性采样解决外部数据分布不匹配 2）基于探索的优势函数引导模型发现高价值推理路径 3）内部推理与外部学习的协同机制。

Result: 在6个数学推理基准实现SOTA，6/6分布外任务表现优异，不同模型家族相对提升21.1%-69.2%，Pass@k曲线证实解决能力边界崩溃。

Conclusion: RL-PLUS通过理论创新和算法设计，成功突破基础模型能力限制，建立可持续扩展的强化学习框架，显著提升复杂推理任务的泛化性能。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [60] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: 提出通过'做中学'实现自我进化的智能体MetaAgent，通过工具路由、经验沉淀和知识库构建实现持续优化，在多项基准测试中超越传统工作流模型。


<details>
  <summary>Details</summary>
Motivation: 传统智能体存在知识固化、依赖预训练的问题，需探索不改变模型参数的持续进化范式以提升开放知识发现能力。

Method: 建立基础推理+动态工具路由框架，通过答案验证生成经验文本，自主构建工具库和知识库，实现数据驱动的元工具学习机制。

Result: 在GAIA/WebWalkerQA/BrowseCamp基准测试中，性能超越工作流基线8-15%，达到或超过端到端训练模型水平。

Conclusion: MetaAgent验证了自进化智能体系统的可行性，为通用知识发现提供了参数冻结情况下的持续优化新路径。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [61] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 研究比较人类与LLM（GPT-4o）的任务生成模式，发现人类受内在心理驱动（如价值观、认知风格），而LLM即使明确获得心理驱动也无法复现人类行为模式，生成的任务社交性、实体性更低且偏向抽象，突显二者认知机制的核心差异。


<details>
  <summary>Details</summary>
Motivation: 探究生成式智能体（基于LLM）是否遵循与人类相似的价值驱动、具身认知原则，验证LLM任务生成机制与人类心理动机的匹配性。

Method: 通过任务生成实验，对比人类与LLM（GPT-4o）在相同心理驱动条件下的行为模式，分析任务主题、社交属性、实体性等维度差异。

Result: LLM生成的任务社交互动减少62%、物理实体性降低45%，主题抽象度高于人类28%。尽管其任务被认为更有趣（+37%新颖性评分），但无法体现价值观与行为的一致性。

Conclusion: LLM的统计模式与人类价值驱动的具身认知存在本质鸿沟，未来需将内在动机和物理具身性融入智能体设计以实现人机对齐。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [62] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 发现大模型虽具备安全知识但推理时未激活，提出高效后训练方法R1-Act，仅需少量资源即可显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 大模型(LRM)在执行复杂任务时易响应有害指令，研究发现其安全知识未被有效激活，需解决推理过程与安全知识脱节的问题。

Method: 提出R1-Act结构化推理框架，通过显式触发安全知识实现安全增强。仅需1,000训练样本，单GPU训练90分钟即可完成适配。

Result: 在多个模型规模测试中，R1-Act安全指标提升显著且不影响推理性能，计算效率比现有对齐方法高10倍以上。

Conclusion: 通过激活既有安全知识而非灌输新知识，R1-Act为模型安全提供了高效解决方案，其轻量级特性具备实际部署价值。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [63] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro开源框架通过高质量训练数据和测试策略，在GAIA基准上实现SOTA性能（8B模型超越WebDancer等系统）


<details>
  <summary>Details</summary>
Motivation: 解决现有AI代理系统闭源/依赖付费API的问题，推动可访问、可复现的高级AI代理研发

Method: 系统研究代理基础模型的高质量训练数据构建（覆盖web/file/code/reasoning四领域）+ 创新测试时反思与投票策略

Result: GAIA基准测试达到开源代理SOTA，8B模型超越WebDancer/WebSailor等系统

Conclusion: Cognitive Kernel-Pro为AI代理发展建立了新标准，证明开源模型也能实现高性能，推动社区发展（代码已开源）

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [64] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 研究者提出选择性模态迁移（SMS）方法，量化多模态模型在医学分类任务中的模态依赖性，发现现有模型过度依赖文本信息而忽视视觉线索


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在医疗决策中存在模态偏差问题，常过度依赖文本信息而忽略关键医学图像特征

Method: 通过样本间图像/文本互换的扰动实验，结合定量性能评估和定性注意力分析，评估6个开源模型在胸片和眼科影像数据集上的表现

Result: 模型在文本扰动后性能显著下降（MIMIC-CXR数据集F1下降53.6%），注意力分析显示图像特征常被文本细节掩盖

Conclusion: 需开发真正融合多模态信息的医疗模型，当前模型的文本依赖特性可能导致临床决策风险，建议建立更全面的评估体系

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [65] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 首个针对自我中心视频的像素级时空定位基准EgoMask，通过自动标注流程构建并验证模型效果，显著提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频在增强现实/机器人领域日益重要，但现有时空定位研究集中于外中心视频，存在物体持续时间短/轨迹稀疏/尺寸小/位置偏移大四大核心挑战。

Method: 提出自动标注流程构建EgoMask基准测试集（含短/中/长期视频），并创建大规模训练集EgoMask-Train。通过微调实验验证模型迁移能力。

Result: SOTA模型在EgoMask上表现欠佳，但使用EgoMask-Train微调后mIoU提升7.7%，且保持外中心数据集性能不下降。

Conclusion: EgoMask填补了自我中心视频细粒度定位的基准空白，提供的资源与洞见将推动该领域发展，代码已开源。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [66] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出结合SMPL模型与多模态嵌入空间的上下文感知检索框架，创建WayMoCo数据集提升运动-上下文检索准确率27.5%。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从大规模数据集中检索罕见人类行为（长尾问题），影响自动驾驶系统的评估与泛化能力。

Method: 融合SMPL运动序列与视频帧，构建自然语言对齐的多模态嵌入空间，支持文本驱动的场景检索；扩展生成WayMoCo数据集。

Result: 在WayMoCo数据集上实现运动-上下文检索准确率超越SOTA模型27.5%。

Conclusion: 框架与数据集有效提升自动驾驶系统对复杂人类行为场景的评估能力，多模态检索支持系统鲁棒性验证。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


<div id='q-fin.TR'></div>

# q-fin.TR [[Back]](#toc)

### [67] [ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism](https://arxiv.org/abs/2508.00554)
*Li Zhao,Rui Sun,Zuoyou Jiang,Bo Yang,Yuxiao Bai,Mengting Chen,Xinyang Wang,Jing Li,Zuo Bai*

Main category: q-fin.TR

TL;DR: 提出具有内部竞争机制的多智能体系统，通过数据团队和研究团队的分工协作，结合实时评估排名机制，显著提升金融交易系统抗噪声能力和交易表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的交易系统对市场噪声高度敏感，导致性能下降。需要增强系统鲁棒性并适应动态市场环境。

Method: 1) 数据团队压缩市场数据为文本因子 2) 研究团队进行多路径交易决策 3) 基于市场反馈的实时评分排名机制 4) 仅采用顶级智能体输出

Result: 实验显示本系统在多项指标上显著优于主流多智能体系统和传统量化投资方法

Conclusion: 内部竞争机制通过动态调整增强系统适应性，有效抑制市场噪声影响，实现更优交易表现

Abstract: In financial trading, large language model (LLM)-based agents demonstrate
significant potential. However, the high sensitivity to market noise undermines
the performance of LLM-based trading systems. To address this limitation, we
propose a novel multi-agent system featuring an internal competitive mechanism
inspired by modern corporate management structures. The system consists of two
specialized teams: (1) Data Team - responsible for processing and condensing
massive market data into diversified text factors, ensuring they fit the
model's constrained context. (2) Research Team - tasked with making
parallelized multipath trading decisions based on deep research methods. The
core innovation lies in implementing a real-time evaluation and ranking
mechanism within each team, driven by authentic market feedback. Each agent's
performance undergoes continuous scoring and ranking, with only outputs from
top-performing agents being adopted. The design enables the system to
adaptively adjust to dynamic environment, enhances robustness against market
noise and ultimately delivers superior trading performance. Experimental
results demonstrate that our proposed system significantly outperforms
prevailing multiagent systems and traditional quantitative investment methods
across diverse evaluation metrics.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [68] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
*Abir Ray*

Main category: cs.NI

TL;DR: 结合两状态马尔可夫链与ITU-R传播模型，提出可扩展的频谱时空预测框架，提升认知无线电网络的频谱管理效率


<details>
  <summary>Details</summary>
Motivation: 频谱资源在时空维度存在利用率不足现象，需通过预测主要用户活动规律来实现动态频谱接入，解决次要用户干扰规避与频谱机会利用的矛盾

Method: 整合马尔可夫链建模时间维度占用模式+ITU-R P.528/P.2108传播模型计算空间维度信号覆盖，构建联合时空预测模型

Result: 框架在预测精度与计算效率间取得平衡，可实时识别可用频谱，支持动态频谱共享系统的决策制定

Conclusion: 该灵活框架适用于多频段场景，为认知无线电提供低成本的频谱感知方案，推动动态频谱管理技术发展

Abstract: Spectrum resources are often underutilized across time and space, motivating
dynamic spectrum access strategies that allow secondary users to exploit unused
frequencies. A key challenge is predicting when and where spectrum will be
available (i.e., unused by primary licensed users) in order to enable proactive
and interference-free access. This paper proposes a scalable framework for
spectrum availability prediction that combines a two-state Markov chain model
of primary user activity with high-fidelity propagation models from the ITU-R
(specifically Recommendations P.528 and P.2108). The Markov chain captures
temporal occupancy patterns, while the propagation models incorporate path loss
and clutter effects to determine if primary signals exceed interference
thresholds at secondary user locations. By integrating these components, the
proposed method can predict spectrum opportunities both in time and space with
improved accuracy. We develop the system model and algorithm for the approach,
analyze its scalability and computational efficiency, and discuss assumptions,
limitations, and potential applications. The framework is flexible and can be
adapted to various frequency bands and scenarios. The results and analysis show
that the proposed approach can effectively identify available spectrum with low
computational cost, making it suitable for real-time spectrum management in
cognitive radio networks and other dynamic spectrum sharing systems.

</details>
