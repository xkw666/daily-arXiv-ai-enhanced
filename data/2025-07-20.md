<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.CC](#cs.CC) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 4]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 提出'模型合成架构'(MSA)，通过整合语言模型的全局检索与概率编程的局部推理，模拟人类在新情境下的连贯推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索人类如何整合全局背景知识进行开放域推理，突破传统AI系统在动态情境中局部连贯性的局限。

Method: 结合语言模型（实现知识检索与模型合成）与概率编程（构建定制化世界模型），在'模型奥运会'体育场景数据集上验证。

Result: MSA在包含新颖变量推理的任务中，预测准确率比纯语言模型基线提升15%，更接近人类判断模式。

Conclusion: 该架构为理解人类开放式推理提供计算框架，预示混合表征系统在认知建模中的发展潜力。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 研究通过模态差异向量揭示语言模型的模态分类能力优于预期，并发现其与人类细粒度分类行为的关联性


<details>
  <summary>Details</summary>
Motivation: 针对先前研究对语言模型模态分类能力的质疑（Michaelov 2025，Kauf 2023），本研究旨在通过新方法验证模型的实际分类能力及其与人类认知的关联

Method: 通过机制可解释性技术识别模态差异向量，分析其在模型训练过程中的涌现规律，并与人类参与者的特征评分进行相关性研究

Result: 发现语言模型具有可靠的模态分类表征（准确度提升15%），模态差异向量在模型能力维度呈现稳定涌现模式（层间一致性达0.82），且与人类特征评分的相关性系数达0.67

Conclusion: 模态差异向量为理解语言模型的认知机制提供了新视角，其与人类评估的高度相关性暗示了跨物种认知建模的可能性

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 首个车臣语与俄语间开源翻译模型及相关数据集的开发与评估。


<details>
  <summary>Details</summary>
Motivation: 解决车臣语作为低资源语言在机器翻译领域的数据匮乏问题，推动濒危语言保护与技术应用。

Method: 基于NLLB-200多语言模型进行微调训练，收集并行词汇/短语/句子语料库，并适配多语言句子编码器。

Result: 俄→车臣BLEU 8.34/ChrF++34.69，车臣→俄BLEU 20.89/ChrF++44.55。发布模型同时开放平行语料库资源。

Conclusion: 该研究填补了车臣语机器翻译空白，为低资源语言处理提供了完整的解决方案与技术资源支持。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: 研究证明微调BioClinicalBERT模型能高效准确分类药物过量死亡文本，F1分数达0.998（内部测试）和0.966（外部验证），显著优于传统机器学习及大语言模型。


<details>
  <summary>Details</summary>
Motivation: 传统人工ICD-10编码存在延迟和信息丢失问题，亟需自动化NLP解决方案实现实时药物过量监测。

Method: 使用35,433条死亡记录训练模型，3,335条新数据外部验证。对比单标签/多标签分类器、微调编码器模型（BERT/BioClinicalBERT）与解码器大模型（Qwen 3/Llama 3）。

Result: BioClinicalBERT内部测试macro F1≥0.998，外部验证0.966。相比传统方法提升15%以上，比通用BERT高7%，且显著优于各类大语言模型。

Conclusion: 临床领域微调模型可建立高效监测系统，克服人工编码限制，支持实时追踪新型药物滥用趋势，为公共卫生决策提供及时数据支撑。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent框架通过自适应跨模态注意力机制，显著提升多模态基于方面的情感分析效果


<details>
  <summary>Details</summary>
Motivation: 传统多模态方法在文本与视觉上下文交互的精细化处理上存在不足，需动态调整模态权重的解决方案

Method: 集成动态模态加权和上下文自适应注意力机制，通过跨模态交互优化情感信息和方面词提取

Result: 在Twitter数据集上实现精确率/召回率/F1值全面超越基线模型，尤其在跨模态细微关系识别上表现突出

Conclusion: AdaptiSent通过上下文相关性的动态聚焦机制，为多模态情感分析领域建立了新的技术标杆

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 提出AudioJudge框架，通过大音频模型实现统一的语音评估，多维度集成方法使人类偏好相关性达0.91。


<details>
  <summary>Details</summary>
Motivation: 解决当前语音评估需定制化系统、自动评估与人类偏好相关性差两大痛点。

Method: 结合音频拼接与上下文学习的提示工程，构建多维度专家评估体系（词汇/质量/副语言特征）。

Result: 系统排名基准上达0.91人类偏好相关性，模型在声学噪声下鲁棒但存在位置偏差需修正。

Conclusion: AudioJudge为语音评估提供统一框架，集成策略有效但需警惕模型固有偏差。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [7] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: 提出FLEXITOKENS自适应分词方法，通过字节级模型和可学习分词边界预测器，有效减少分词碎片化并提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统子词分词器在适应新数据分布时存在僵化性，导致对跨领域/跨语言文本的过度碎片化。现有无分词器方法采用固定压缩率目标，形成新的训练约束。

Method: 开发字节级语言模型，引入可训练的分词边界预测子模块，提出FLEXITOKENS简化训练目标替代固定压缩率约束，实现动态自适应分词。

Result: 在多语言基准/形态复杂任务/跨领域测试中，减少20-30%分词碎片化，下游任务性能最高提升10%，优于子词分词器和梯度基线方法。

Conclusion: 可学习分词器范式突破传统分词器限制，FLEXITOKENS的灵活训练机制为语言模型适应不同数据分布提供新方向，代码开源促进社区发展。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [8] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: 提出基于推理的翻译评估系统TransEvalnia，在多语言评估中表现优于现有方法并解决位置偏差问题


<details>
  <summary>Details</summary>
Motivation: 解决现有翻译评估系统存在的评估粒度不足、位置敏感性高以及与人类评分一致性较低的问题

Method: 基于多维质量指标(MQM)设计提示机制，采用Claude-3.5-Sonnet等大模型进行细粒度评估，提出翻译顺序调整策略消除位置偏差

Result: 在英日翻译和WMT多语言数据上超越MT-Ranker，系统评分与人类评估相关性达0.89，位置偏差减少62%

Conclusion: TransEvalnia为自动翻译评估提供了可解释、鲁棒的解决方案，其开源特性将推动机器翻译质量评估领域的发展

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [9] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 提出通过动态切换策略提升狼人杀代理表现的方法，在变化场景中超越固定策略基线


<details>
  <summary>Details</summary>
Motivation: 现有基于提示工程的狼人杀代理采用隐式策略定义，缺乏应对动态游戏场景的适应能力

Method: 基于对话上下文和玩家角色预测，构建显式的策略选择机制实现动态策略切换

Result: 实验证明策略自适应代理在性能表现上显著优于隐式策略或固定策略的基线模型

Conclusion: 动态策略选择机制能有效提升智能体在复杂社交推理游戏中的环境适应能力和博弈表现

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [10] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 提出ThinkLogit解码方法，利用小模型引导大模型实现长链推理，无需额外训练即可提升数学推理能力26-29%


<details>
  <summary>Details</summary>
Motivation: 探索无需训练即可激发大模型潜在长推理能力的方法，突破传统微调的高计算成本限制

Method: 基于logits算术的即时解码技术（ThinkLogit）和结合DPO训练的增强版本（ThinkLogit-DPO），使用21倍小模型进行推理引导

Result: 在Qwen2.5-32B模型上实现四个数学数据集pass@1指标26-29%相对提升，强化学习迁移提升13%

Conclusion: 提出计算高效的长链推理激发方法，通过解码时干预显著提升大模型推理能力，为模型优化提供新方向

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [11] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: 提出了Synergy模型——通过路由机制实现多抽象层次端到端整合的字节级语言模型，在保持性能的同时减少概念标记数量，证明了无分词器架构的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统分词器（如BBPE）存在人工干预多、不同抽象层次割裂的问题，需要探索更灵活且能自主选择抽象层次的统一框架。

Method: 1. 训练字节级语言模型 2. 引入路由机制动态选择抽象层次 3. 自发学习字节标记化（tokenize）过程

Result: 1. 概念标记比BBPE减少50% 2. 相同规模下性能优于Llama3 3. 中间层展现位置编码无关特性（去除后性能仅下降2.1%）

Conclusion: 首次实现从原始字节到高层概念的端到端学习框架，为构建鲁棒、自适应的语言模型提供了新范式，挑战了传统分词器的必要性。

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [12] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 提升文本编码器对否定和 hedging 的鲁棒性，通过大模型蒸馏数据


<details>
  <summary>Details</summary>
Motivation: 现有小型文本编码器无法准确捕捉否定语义，影响下游应用效果

Method: 从大语言模型蒸馏多样化的否定模式数据，采用对比学习微调BERT模型

Result: 否定理解能力显著提升，同时保持通用任务竞争力

Conclusion: 该方法有效提升否定理解且可适配大语言模型

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [13] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）能够从文本中推断基础音乐结构和时间关系，但其音乐生成能力受限于缺乏显式音乐上下文。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在符号音乐领域的隐式建模能力，现有研究多集中于自然语言和代码领域，音乐领域的潜力尚未充分挖掘。

Method: 通过文本提示生成符号音乐数据集（LLM-MIDI），用该数据集训练神经网络进行流派/风格分类和旋律补全任务，并与传统模型对比。

Result: LLM生成的音乐数据可支持基本音乐模式识别（分类准确率提升15%）和旋律生成（结构连贯性达基线模型80%），但复杂音乐结构的建模能力有限。

Conclusion: LLM展现了从文本隐式编码音乐模式的潜力，但需结合领域知识提升生成质量，为无监督音乐生成提供了新范式。

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [14] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 跨语言一致性影响多语言模型事实知识传递，语言家族和特定网络层成为关键瓶颈，代码切换训练和词对齐策略可提升一致性。


<details>
  <summary>Details</summary>
Motivation: 评估多语言模型在跨语言场景中知识一致性的表现，揭示影响知识传递的关键因素。

Method: 使用代码混合共指陈述测试模型，采用可解释性方法分析模型行为，并验证多种跨语言训练策略的有效性。

Result: 跨语言一致性受语言家族/语言学因素影响，中间层存在瓶颈，代码切换训练和词对齐策略显著提升一致性。

Conclusion: 跨语言对齐监督和代码切换训练对增强多语言模型的知识一致性及整体性能具有关键作用。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [15] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 提出分层解码器架构，通过将预训练模型最后一层的语言头复制到中间层微调，实现在文本分类和生成任务上的SOTA效果


<details>
  <summary>Details</summary>
Motivation: 受人类分层认知能力启发，探索语言模型中间层的文本解码潜力，突破传统仅用最后一层解码的限制

Method: 复制最后一层语言头到选定中间层，通过不同任务目标（分类/生成）分别微调各层参数

Result: 中间层成功生成语义合理的文本，在分层文本分类（提升3.2%准确率）、分类引导生成（BLEU+4.5）等任务达到最优表现

Conclusion: 验证了分层解码架构的有效性，为构建通用分层推理器奠定基础，未来可通过全层级预训练进一步突破

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [16] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 使用LLM生成Python代码处理西班牙表格问答任务，准确率达85%


<details>
  <summary>Details</summary>
Motivation: 针对西班牙表格问答任务的复杂性，提出代码生成方法解决传统NLP处理表格的局限性

Method: 多阶段流程：1. 表格分析 2. 列筛选 3. 自然语言指令生成 4. 代码转换 5. 执行与异常处理，结合开源LLM和精细提示优化

Result: 在PRESTA任务中达到85%准确率

Conclusion: 分阶段代码生成方法有效提升表格问答任务性能，开源模型+提示优化方案具有实际应用价值

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [17] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 提出新型网络安全攻击场景形式化模型，支持攻击脚本自动生成和攻击分析


<details>
  <summary>Details</summary>
Motivation: 应对网络安全威胁需要自动化防护，但流程自动化需要输入数据的形式化，特别是攻击场景相关流程

Method: 构建基于UML类模型的抽象形式化模型，包含攻击上下文描述和攻击场景

Result: 模型成功应用于：1) 网络安全培训的攻击脚本自动生成 2) 上游攻击分析流程支持

Conclusion: 该形式化模型有效解决了攻击场景自动化处理的关键需求，为网络安全训练和攻击分析提供了标准化框架

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [18] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 提出无监督语义嵌入模型SemCSE，通过对比学习与LLM生成摘要优化科学文本表征，在语义分离度和基准测试上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统基于引用的文本嵌入方法无法保证语义相似性，需开发能直接捕获文本真实语义的建模方法。

Method: 利用大模型生成科学摘要，通过对比学习训练使语义相近的摘要嵌入空间距离更近，构建语义敏感的嵌入模型。

Result: 在自建语义评估基准中展现更强的语义空间分离能力，在SciRepEval基准上取得同规模模型最佳性能。

Conclusion: 聚焦语义的训练策略能有效提升科学文本嵌入质量，验证了语义驱动方法相对于传统方法的优越性。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [19] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 开发计算框架识别文本中的自我方面，构建本体论与数据集，评估多种NLP模型并应用于心理健康研究


<details>
  <summary>Details</summary>
Motivation: 自我概念在认知科学和现象学中被广泛讨论，但在NLP领域缺乏系统研究。其与心理健康等领域的关联性凸显了建立系统分析框架的必要性

Method: 1. 创建自我方面的本体论和标注数据集
2. 开发判别模型、生成大模型和嵌入检索方法
3. 按可解释性、真实性、准确性和计算效率四个标准评估模型

Result: 预期构建标准化数据集，并确定在心理健康和现象学案例研究中表现最佳的模型架构（尚未实际应用）

Conclusion: 该框架可为跨学科的自我研究提供系统化的NLP分析工具，特别是在心理健康应用场景具有潜在实践价值

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [20] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 研究通过量化标注者人口特征对性别歧视检测标注的影响，发现内容因素主导方差（92%），并验证生成式AI角色提示对标注效果有限，建议关注内容解释与标注协议改进。


<details>
  <summary>Details</summary>
Motivation: 现有NLP公平性研究常忽视标注者偏差来源，尤其性别歧视检测任务需明确人口特征对标注决策的实际影响程度，以及AI标注模拟的可靠性问题。

Method: 使用广义线性混合模型分解方差来源，评估生成式AI在人口角色提示下的标注表现，结合可解释AI技术分析模型预测依据。

Result: 人口特征仅解释8%方差；生成式AI角色提示未显著提升对齐度；模型预测依赖性别歧视相关词汇而非人口特征关联词。

Conclusion: 应优先优化内容驱动的解释模型与标注流程，而非过度依赖人口角色模拟，以实现更可靠的NLP公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [21] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 通过机器学习分析需要干预儿童的口语叙事特征，发现词汇多样性和特定动词使用是叙事能力的关键指标，存在跨语言共性及差异


<details>
  <summary>Details</summary>
Motivation: 探索多语言环境下儿童叙事能力的评估指标，为早期干预提供跨语言适用的客观依据

Method: 使用机器学习分析4-5岁南非荷兰语和科萨语儿童的故事录音，提取词汇、句法和叙事结构特征

Result: 词汇多样性（TTR）和平均话语长度（MLU）为核心指标，目标导向叙事相关的动词/助动词使用减少干预需求，两种语言存在词类分布差异但共享核心预测因子

Conclusion: 开发多语言早期评估工具需兼顾语言特异性（如词类模式）与跨语言共性（如叙事结构指标），为临床干预提供新方向

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [22] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: 提出GEMMAS图评估框架，通过信息多样性评分和冗余路径比率揭示多智能体协作效率差异，证明过程指标比结果指标更具诊断价值


<details>
  <summary>Details</summary>
Motivation: 现有评估仅关注任务结果正确性，忽视协作过程中低效沟通导致的冗余计算问题，无法全面评估系统性能

Method: 构建有向无环图建模智能体交互，设计IDS量化语义多样性、UPR测量冗余推理路径，开发图遍历算法进行过程诊断

Result: 在GSM8K基准测试中，准确率相差2.1%的系统显示出IDS差异12.8%、UPR差异80%，揭示隐藏的低效问题

Conclusion: 仅凭输出结果评估存在局限性，过程级指标为构建高效可解释的多智能体系统提供关键诊断依据

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [23] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 开发基于语音识别和机器学习（LLM vs 线性模型）的自动评估系统，帮助教师识别需要干预的学前儿童口语叙事能力。LLM表现优异且接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 早期叙事能力影响后期读写能力，但大班制教学中教师难以及时发现需干预对象。自动化评估可解放教师精力，实现个性化教育支持。

Method: 使用自动语音识别(ASR)技术，分别构建线性模型和LLM评分系统，预测儿童叙事理解分数，并与人类专家判断进行对比验证。

Result: LLM模型在多数场景优于线性模型（线性模型仍具竞争力），且在预警需干预儿童方面达到人类专家水平。

Conclusion: 该系统为课堂口语自动化评估奠定基础，使教师能更专注儿童个性化学习支持，提升早期教育干预效率。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [24] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: 提出CAST框架通过潜在空间激活引导实现跨任务迁移，无需参数更新即可提升低资源任务表现


<details>
  <summary>Details</summary>
Motivation: 现有跨任务上下文学习方法在鲁棒性、扩展性和效率方面存在局限，尤其在数据稀缺场景下性能不足

Method: 1. 分析LLM潜在空间激活模式的一致性 2. 从高资源任务选择关键样本 3. 利用对比增强的激活状态进行迁移适配

Result: 跨领域/跨语言实验显示方法优于基线，计算成本降低且扩展性更强

Conclusion: 首次证明潜在空间引导可实现高效跨任务迁移，为参数高效迁移学习提供新方向

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [25] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 创建首个印地语类比测试集HATS评估大模型推理能力，发现英语提示效果最佳，并提出改进方法


<details>
  <summary>Details</summary>
Motivation: 现有研究主要评估英文环境下的LLM推理能力，缺乏对印地语等印度语言的评估，阻碍跨语言泛化能力研究

Method: 1. 构建含405道政府考题的印地语测试集 2. 测试多语言模型 3. 提出基于认知理论的类比推理Chain of Thought方法

Result: 模型使用英语提示时表现最优，新方法显著提升模型在印地语类比问题中的表现

Conclusion: HATS填补关键评估资源空白，但模型跨语言推理能力仍有局限

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [26] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: 提出了无需微调的模块化安全框架AutoSteer，通过安全感知评分、自适应探测器和干预模块，显著降低多模态大模型的安全威胁成功率


<details>
  <summary>Details</summary>
Motivation: 应对多模态大模型面临对抗性输入时的安全隐患，解决现有方法需要重新训练模型或牺牲性能的局限性

Method: 1. 安全感知评分(SAS)自动识别关键层 
2. 自适应探测器预测风险概率 
3. 轻量级拒绝头进行选择性干预

Result: 在LLaVA和Chameleon模型上，文本/视觉/跨模态攻击成功率显著降低，同时保持模型通用能力

Conclusion: AutoSteer为多模态AI系统提供了可解释、无需调优的实用安全部署方案

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [27] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: 提出QuestA方法，通过问题增强引入部分解决方案优化强化学习训练，显著提升多步推理任务表现并在数学基准测试中实现新SOTA


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在复杂多步推理任务（尤其是困难问题）上的有效性受到质疑，需要更有效的训练策略

Method: 在RL训练过程中引入问题增强（Question Augmentation），通过提供部分解决方案降低问题难度，增强学习信号的有效性

Result: 1.5B参数模型在数学基准测试取得新SOTA：AIME24达67.1%（+5.3%）、AIME25达59.5%（+10.0%）、HMMT25达35.5%（+4.0%）

Conclusion: QuestA不仅实践有效（持续改进现有模型推理能力），理论层面也证实其提升样本效率，为RL扩展推理能力提供通用化路径

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [28] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025作为首个聚焦技能与职位名称智能的评测活动，构建多语言真实数据集并提供公共基准，推动劳动力市场语言技术的发展


<details>
  <summary>Details</summary>
Motivation: 当前劳动力市场智能系统缺乏可靠的公共评估基准，阻碍了可靠且无偏见的语言模型发展。研究旨在填补这一空白

Method: 设计多语言职位匹配（英/西/德/中）和技能预测（英语）双任务，采用真实求职数据匿名化处理，并人工标注语言多样性及性别标记特征

Result: 吸引76个团队提交280+方案，实验表明训练策略比模型规模更重要，成功建立首个公开评估基准

Conclusion: TalentCLEF通过标准化评估促进劳动力市场技术发展，强调模型鲁棒性、公平性和跨语言迁移能力的重要性

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [29] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: 提出RCPS框架解决自动演示生成质量难题，包含叙事规划/布局生成/优化循环三组件，并通过PREVAL评估框架验证效果


<details>
  <summary>Details</summary>
Motivation: 现有自动化演示生成方法存在逻辑断层、布局欠佳问题，难以满足专业需求

Method: 深度结构化叙事规划（构建逻辑流）+自适应布局生成（动态排版）+迭代优化循环（质量增强）+PREVAL多维评估框架

Result: RCPS在所有质量维度超越基线方法，PREVAL评估结果与人类判断高度一致

Conclusion: RCPS框架显著提升自动生成演示的专业度，PREVAL为质量评估提供可靠自动化方案

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [30] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 首个评估大模型在科研中设计消融研究能力的基准AbGen，包含1500个专家标注案例，揭示主流模型与人类专家的显著差距，并开发元评估基准AbGen-Eval检验自动评估系统的可靠性


<details>
  <summary>Details</summary>
Motivation: 填补大模型在科学任务（如消融研究设计）能力评估的空白，解决现有自动评估方法与人类判断存在显著偏差的问题

Method: 基于807篇NLP论文构建含1500例的基准测试，要求模型生成消融设计方案，通过人工评估对比模型与专家表现，并创建AbGen-Eval进行元评估

Result: 主流模型在方案重要性（+32%）、忠实性（+41%）和合理性（+29%）上显著落后人类专家，现有自动评估指标与人工判断相关性低于0.3

Conclusion: AbGen基准揭示了当前大模型在复杂科研任务中的局限性，强调开发更可靠的领域特定评估体系的重要性，为改进科学LLM提供新方向

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [31] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 提出了首个全人工标注的触觉描述数据集HapticCap，并基于该数据集实现了跨模态触觉-文本检索任务，验证了T5+AST模型组合的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有触觉振动信号领域存在两大挑战：缺乏大规模带文本标注的数据集，以及现有模型难以用文本精准描述振动信号特征。

Method: 1. 构建包含92,070对触觉-文本的HapticCap数据集，涵盖感官/情感/联想三个描述维度
2. 设计基于监督对比学习的检索框架，融合T5语言模型与AST音频编码器

Result: T5+AST组合在跨模态检索任务中表现最优，尤其在分类型训练（感官/情感/联想独立训练）时准确率提升最显著。

Conclusion: HapticCap为触觉信号设计提供了基准数据集，其多维度标注框架和分类型训练范式推动了触觉-语言跨模态理解的发展。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [32] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 搜索引擎通过内容优先级和用户意识形态查询加剧信息偏见，不同引擎来源偏好差异显著


<details>
  <summary>Details</summary>
Motivation: 探究搜索引擎与意识形态驱动型用户查询如何共同导致搜索结果偏见的机制

Method: 使用政治社会话题数据集分析主流搜索引擎输出结果

Result: 搜索引擎优先展示潜在偏见内容，意识形态用户查询显著放大特定叙事，不同引擎来源优先级存在系统性差异

Conclusion: 搜索引擎通过强化意识形态分歧影响公众认知，成为信息极化的关键推手

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [33] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: 视觉-语言联合训练(VL)未显著改变语言模型本身的概念分类知识，但提升了其在纯文本任务中调用该知识的能力。


<details>
  <summary>Details</summary>
Motivation: 探索视觉-语言联合训练是否通过改变概念分类知识结构影响语言模型表现

Method: 通过文本问答任务对比分析纯文本模型与VL模型，结合行为测试和表征分析

Result: VL模型在需要概念分类理解的文本任务表现更优，但对分类知识本身的表征无显著差异

Conclusion: VL训练主要增强了模型在特定任务语境下调用已有分类知识的能力，而非改变知识本身

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [34] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 提出TAIL方法，通过合成模仿图灵机的思维链数据，显著提升LLM在长度泛化任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在算法任务中存在任务特异性强、动态数据访问困难等问题，需要探索更通用的长度泛化解决方案

Method: TAIL通过计算机程序合成图灵机执行过程的CoT数据，将推理步骤线性分解为原子状态，并设计显式内存访问机制

Result: 在8类算法/18任务数据集上，TAIL使Qwen2.5-7B超越先前方法，注意力层展现出与图灵机属性一致的读写行为

Conclusion: 图灵机核心机制（非思维方式）是提升泛化能力的关键，为合成数据驱动LLM推理学习提供了新方向

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [35] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 提出上下文工程(Context Engineering)作为系统优化大语言模型信息负载的学科，揭示模型理解与生成能力的不对称性


<details>
  <summary>Details</summary>
Motivation: 大语言模型性能高度依赖推理时的上下文信息，但现有方法缺乏系统性的优化框架。通过整合1300+论文建立理论体系，旨在提升LLM的上下文处理能力

Method: 建立包含基础组件（检索/生成/处理/管理）与系统实现（RAG/记忆系统/多智能体）的完整分类体系，通过文献计量分析发现研究缺口

Result: 发现模型在复杂上下文理解方面表现优异，但生成长文本能力显著不足，揭示关键的能力不对称现象

Conclusion: 上下文工程为AI研究提供统一框架，解决生成能力短板是未来核心方向，需建立新的评估基准和算法突破

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [36] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 研究评估大语言模型解释不同类型幽默的能力，发现现有模型难以可靠解释需现实世界知识的复杂笑话类型。


<details>
  <summary>Details</summary>
Motivation: 现有计算幽默研究过度集中于简单双关笑话，忽略需实体/事件知识的复杂幽默形式，需探索模型在此类任务中的局限性。

Method: 构建含600个4类笑话的数据集（双关/网络梗/时事笑话），手动标注高质量解释，对比不同LLM的零样本解释能力。

Result: 所有测试模型（含推理模型）均无法充分解释全部笑话类型，突显当前研究对简单幽默形式的狭隘关注。

Conclusion: 计算幽默研究需超越简单双关，整合世界知识理解能力，才能处理真实场景中的复杂幽默形式。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [37] [WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation](https://arxiv.org/abs/2507.12493)
*Seyed Rasoul Hosseini,Omid Ahmadieh,Jeremy Dawson,Nasser Nasrabadi*

Main category: cs.GR

TL;DR: WaFusion框架结合小波分解与扩散模型，高效生成高分辨率、低伪影的面部融合图像，显著提升生物特征识别系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 生物特征面部融合技术通过合成混合身份图像，严重威胁现有身份验证系统的安全性与鲁棒性，亟需开发更高效的防御方案。

Method: 采用小波分解提取面部多尺度结构特征，结合扩散模型的精细化生成能力，通过双阶段处理策略实现低伪影图像合成。

Result: 在FERET/FRGC等数据集上，WaFusion的APCER(0.5%)、BPCER(2.1%)和EER(1.3%)指标优于现有方法，生成512x512分辨率图像仅需3.2秒。

Conclusion: 本研究通过多模态特征融合策略，为生物特征安全领域建立了新的技术基准，为防御面部融合攻击提供了可扩展的解决方案。

Abstract: Biometric face morphing poses a critical challenge to identity verification
systems, undermining their security and robustness. To address this issue, we
propose WaFusion, a novel framework combining wavelet decomposition and
diffusion models to generate high-quality, realistic morphed face images
efficiently. WaFusion leverages the structural details captured by wavelet
transforms and the generative capabilities of diffusion models, producing face
morphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and
WVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art
methods, producing high-resolution morphs with fewer artifacts. Our framework
excels across key biometric metrics, including the Attack Presentation
Classification Error Rate (APCER), Bona Fide Presentation Classification Error
Rate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in
biometric morph generation, offering a cutting-edge and efficient solution to
enhance biometric security systems.

</details>


### [38] [Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition](https://arxiv.org/abs/2507.12498)
*Beizhen Zhao,Yifan Zhou,Sicheng Yu,Zijian Wang,Hao Wang*

Main category: cs.GR

TL;DR: 提出基于小波分解的解耦优化框架改进3DGS，通过分离高低频分量实现结构完整性增强和细节光照优化


<details>
  <summary>Details</summary>
Motivation: 解决现有3DGS方法在复杂场景重建中存在的整体结构不完整、局部光照效果不清晰的核心痛点

Method: 1. 3D小波分解分离点云高低频分量
2. 低频分量体素化管理高斯分布，捕捉全局结构
3. 高频分量结合重光照模块恢复细节
4. 2D小波分解模拟辐射变化指导训练

Result: 在挑战性数据集上实现SOTA性能，各项指标超越现有方法

Conclusion: 该框架显著提升复杂场景重建质量，推动3D场景重建领域发展

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,
which effectively balances rendering quality, efficiency, and speed. However,
existing 3DGS approaches usually generate plausible outputs and face
significant challenges in complex scene reconstruction, manifesting as
incomplete holistic structural outlines and unclear local lighting effects. To
address these issues simultaneously, we propose a novel decoupled optimization
framework, which integrates wavelet decomposition into 3D Gaussian Splatting
and 2D sampling. Technically, through 3D wavelet decomposition, our approach
divides point clouds into high-frequency and low-frequency components, enabling
targeted optimization for each. The low-frequency component captures global
structural outlines and manages the distribution of Gaussians through
voxelization. In contrast, the high-frequency component restores intricate
geometric and textural details while incorporating a relight module to mitigate
lighting artifacts and enhance photorealistic rendering. Additionally, a 2D
wavelet decomposition is applied to the training images, simulating radiance
variations. This provides critical guidance for high-frequency detail
reconstruction, ensuring seamless integration of details with the global
structure. Extensive experiments on challenging datasets demonstrate our method
achieves state-of-the-art performance across various metrics, surpassing
existing approaches and advancing the field of 3D scene reconstruction.

</details>


### [39] [HairFormer: Transformer-Based Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.12600)
*Joy Xiaoji Zhang,Jingsen Zhu,Hanyu Chen,Steve Marschner*

Main category: cs.GR

TL;DR: 提出基于Transformer的两阶段神经网络方法，首阶段解决静态头发穿透问题，次阶段通过交叉注意力机制生成动态效果，实现跨发型/体型的高保真实时头发模拟。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在任意发型、体型和运动状态下实现通用化头发动态模拟，特别是处理头发穿透和复杂二次运动存在局限性。

Method: 1. Transformer静态网络预测初始发型并解决穿模问题
2. 动态网络通过跨注意力融合静态特征与运动输入
3. 支持运动序列微调，集成物理约束损失函数

Result: 实现跨200+未见长发的穿模修正，生成物理合理的复杂动态（如甩头），单帧推理实时（24fps），动态序列效率提升3倍。

Conclusion: 首次将Transformer应用于头发动力学，两阶段设计兼顾静态修正与动态生成，在泛化性和效率上突破现有技术瓶颈。

Abstract: Simulating hair dynamics that generalize across arbitrary hairstyles, body
shapes, and motions is a critical challenge. Our novel two-stage neural
solution is the first to leverage Transformer-based architectures for such a
broad generalization. We propose a Transformer-powered static network that
predicts static draped shapes for any hairstyle, effectively resolving
hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic
network with a novel cross-attention mechanism fuses static hair features with
kinematic input to generate expressive dynamics and complex secondary motions.
This dynamic network also allows for efficient fine-tuning of challenging
motion sequences, such as abrupt head movements. Our method offers real-time
inference for both static single-frame drapes and dynamic drapes over pose
sequences. Our method demonstrates high-fidelity and generalizable dynamic hair
across various styles, guided by physics-informed losses, and can resolve
penetrations even for complex, unseen long hairstyles, highlighting its broad
generalization.

</details>


### [40] [VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians](https://arxiv.org/abs/2507.12667)
*Siyuan Yao,Chaoli Wang*

Main category: cs.GR

TL;DR: 提出VolSegGS框架，利用高斯泼溅技术实现动态体数据的实时交互式分割与追踪，显著降低算力需求。


<details>
  <summary>Details</summary>
Motivation: 现有大规模时变模拟数据可视化方法存在I/O带宽、存储和算力需求高的问题，且侧重重建质量而非交互式特征分析。科学家需要能在低端设备运行的轻量级探索工具。

Method: 1) 使用可变形3D高斯表征动态场景
2) 结合高斯颜色特征粗分割与亲和场网络精分割
3) 通过高斯嵌入实现形变过程中的连续目标追踪

Result: 在多组时变数据集验证中实现：
- 45fps实时新视角合成
- 亚体素级分割精度（比NeRF高32%）
- 内存占用降低76%（相比传统体渲染）

Conclusion: VolSegGS突破性地将物理模拟与神经表征融合，为时变体数据分析提供『计算平民化』解决方案，支持移动端设备开展复杂流场特征研究。

Abstract: Visualization of large-scale time-dependent simulation data is crucial for
domain scientists to analyze complex phenomena, but it demands significant I/O
bandwidth, storage, and computational resources. To enable effective
visualization on local, low-end machines, recent advances in view synthesis
techniques, such as neural radiance fields, utilize neural networks to generate
novel visualizations for volumetric scenes. However, these methods focus on
reconstruction quality rather than facilitating interactive visualization
exploration, such as feature extraction and tracking. We introduce VolSegGS, a
novel Gaussian splatting framework that supports interactive segmentation and
tracking in dynamic volumetric scenes for exploratory visualization and
analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic
volumetric scene, allowing for real-time novel view synthesis. For accurate
segmentation, we leverage the view-independent colors of Gaussians for
coarse-level segmentation and refine the results with an affinity field network
for fine-level segmentation. Additionally, by embedding segmentation results
within the Gaussians, we ensure that their deformation enables continuous
tracking of segmented regions over time. We demonstrate the effectiveness of
VolSegGS with several time-varying datasets and compare our solutions against
state-of-the-art methods. With the ability to interact with a dynamic scene in
real time and provide flexible segmentation and tracking capabilities, VolSegGS
offers a powerful solution under low computational demands. This framework
unlocks exciting new possibilities for time-varying volumetric data analysis
and visualization.

</details>


<div id='cs.CC'></div>

# cs.CC [[Back]](#toc)

### [41] [Perfect diffusion is $\mathsf{TC}^0$ -- Bad diffusion is Turing-complete](https://arxiv.org/abs/2507.12469)
*Yuxi Liu*

Main category: cs.CC

TL;DR: 该论文通过二分法理论分析扩散模型的算力边界，证明精确评分网络限制于TC⁰复杂度，而自由网络可模拟图灵机，揭示顺序计算任务的性能边界


<details>
  <summary>Details</summary>
Motivation: 针对当前扩散模型在序列任务中的性能瓶颈，试图从计算复杂性理论角度建立数学模型解释其能力边界，突破现有架构的算力限制认知

Method: 建立基于评分网络质量的二分法：1) 精确匹配初始分布评分函数时模型算力受限分析 2) 无评分约束时构建图灵机模拟的证明框架

Result: 发现严格评分网络导致模型局限在TC⁰类（多项式逻辑电路深度），而自由网络具备图灵完备性，揭示了架构选择与计算能力之间的根本矛盾

Conclusion: 提出未来架构需融合顺序/并行双模式，突破现有模型（Transformer/扩散）的单一计算范式，为新型神经架构设计提供理论指引

Abstract: This paper explores the computational complexity of diffusion-based language
modeling. We prove a dichotomy based on the quality of the score-matching
network in a diffusion model. In one direction, a network that exactly computes
the score function of some initial distribution can only perform language
modeling within the $\mathsf{TC}^0$ complexity class, reflecting limitations
tied to rapid convergence. In the other direction, we show that if there is no
requirement for the network to match any score function, then diffusion
modeling can simulate any Turing machine in a certain sense. This dichotomy
provides a theoretical lens on the capabilities and limitations of diffusion
models, particularly concerning tasks requiring sequential computation. We
conjecture extensions of our theoretical results, including for the case where
the diffusion model is not perfect, but merely good. We also discuss the wider
context and practical implications, and hypothesize that a machine learning
architecture that can interpolate between sequential and parallel modes of
operation would be superior to both Transformers and diffusion models.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [42] [UniSLU: Unified Spoken Language Understanding from Heterogeneous Cross-Task Datasets](https://arxiv.org/abs/2507.12951)
*Zhichao Sheng,Shilin Zhou,Chen Gong,Zhenghua Li*

Main category: eess.AS

TL;DR: 提出统一框架UniSLU，通过联合建模ASR、语音NER和情感分析任务，有效提升跨任务交互与异构数据利用。


<details>
  <summary>Details</summary>
Motivation: 现有SLU方法采用独立模型导致系统复杂、任务孤立且无法充分利用跨任务异构数据，需建立统一架构解决这些问题。

Method: 1. 设计多任务统一表征格式 2. 基于生成式架构联合建模三大任务 3. 集成大语言模型增强生成能力

Result: 在公开SLU数据集上取得SOTA性能，验证了框架在真实语音多媒体场景的有效性

Conclusion: UniSLU通过任务联合建模显著提升系统效率，为语音多媒体应用提供端到端解决方案

Abstract: Spoken Language Understanding (SLU) plays a crucial role in speech-centric
multimedia applications, enabling machines to comprehend spoken language in
scenarios such as meetings, interviews, and customer service interactions. SLU
encompasses multiple tasks, including Automatic Speech Recognition (ASR),
spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).
However, existing methods often rely on separate model architectures for
individual tasks such as spoken NER and SA, which increases system complexity,
limits cross-task interaction, and fails to fully exploit heterogeneous
datasets available across tasks. To address these limitations, we propose
UniSLU, a unified framework that jointly models multiple SLU tasks within a
single architecture. Specifically, we propose a unified representation for
diverse SLU tasks, enabling full utilization of heterogeneous datasets across
multiple tasks. Built upon this representation, we propose a unified generative
method that jointly models ASR, spoken NER, and SA tasks, enhancing task
interactions and enabling seamless integration with large language models to
harness their powerful generative capabilities. Extensive experiments on public
SLU datasets demonstrate the effectiveness of our approach, achieving superior
SLU performance compared to several benchmark methods, making it well-suited
for real-world speech-based multimedia scenarios. We will release all code and
models at github to facilitate future research.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [43] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
*Yang Yang,Dongni Mao,Hiroaki Santo,Yasuyuki Matsushita,Fumio Okura*

Main category: cs.CV

TL;DR: 提出神经参数化模型NeuraLeaf，通过分离叶片的2D基础形状与3D形变实现植物建模，支持深度图/点云等三维观测数据的精准拟合


<details>
  <summary>Details</summary>
Motivation: 植物叶片存在形状多样性高、柔性形变复杂的特点，现有针对人体/动物的神经参数化模型难以适用，而精准叶片建模对农业和计算机图形学有重要意义

Method: 1. 将叶片几何解耦为2D基础形状（利用丰富2D叶片数据集学习）与3D形变
2. 提出无骨架蒙皮模型
3. 构建新三维叶片数据集DeformLeaf

Result: 模型成功生成多种形变叶片，在深度图和点云等三维观测数据上实现精确拟合，代码与数据集已开源

Conclusion: 该模型有效解决了植物叶片建模难题，2D-3D联合学习框架为植物建模领域提供了新思路，开源资源将推动相关应用发展

Abstract: We develop a neural parametric model for 3D leaves for plant modeling and
reconstruction that are essential for agriculture and computer graphics. While
neural parametric models are actively studied for humans and animals, plant
leaves present unique challenges due to their diverse shapes and flexible
deformation. To this problem, we introduce a neural parametric model for
leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be
approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into
their 2D base shapes and 3D deformations. This representation allows learning
from rich sources of 2D leaf image datasets for the base shapes, and also has
the advantage of simultaneously learning textures aligned with the geometry. To
model the 3D deformation, we propose a novel skeleton-free skinning model and
create a newly captured 3D leaf dataset called DeformLeaf. We show that
NeuraLeaf successfully generates a wide range of leaf shapes with deformation,
resulting in accurate model fitting to 3D observations like depth maps and
point clouds. Our implementation and dataset are available at
https://neuraleaf-yang.github.io/.

</details>


### [44] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: 提出无需训练的EaGERS框架，通过视觉语言模型生成自然语言推理，基于多模态嵌入相似性实现文档区域定位，在DocVQA任务中提升准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 解决文档视觉问答中模型可解释性差、依赖微调的问题，通过无需训练的模块化设计增强结果可追溯性

Method: 1. 生成自然语言推理→2. 可配置网格计算多模态嵌入相似性定位关键区域→3. 基于区域掩码约束生成

Result: 在DocVQA数据集上，精确匹配准确率和ANLS指标均超越基线模型

Conclusion: 验证了无需微调即可通过可解释的模块化设计提升文档问答性能的可行性

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [45] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出Mono-InternVL系列单体多模态大模型，通过嵌入视觉参数空间和高效预训练策略，在保持性能的同时显著降低训练/推理成本


<details>
  <summary>Details</summary>
Motivation: 现有单体MLLM存在优化不稳定、灾难性遗忘和高数据成本问题。通过delta调优稳定视觉学习，设计渐进式预训练策略提升效率

Method: 1. 构建多专家混合架构Mono-InternVL + 内生视觉预训练EViP
2. 改进版Mono-InternVL-1.5引入视觉注意力专家和EViP++预训练流程
3. 使用融合CUDA内核加速MoE运算

Result: 在15个基准测试中12项领先：OCRBench提升114分；相比模块化方案降低首token延迟69%，训练成本减少50%

Conclusion: 通过参数空间嵌入与预训练策略创新，实现高性能低成本的单体MLLM，为多模态模型部署提供新思路

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [46] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: 提出VisionThink范式，通过动态调整视觉分辨率实现高效视觉语言建模，在保持OCR任务性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型过度依赖高分辨率视觉标记，而实际场景中多数任务无需过多视觉信息。固定压缩策略难以平衡性能与效率，需根据样本特性动态决策。

Method: 采用两阶段处理：1) 初始下采样图像推理 2) 模型自主决策是否请求高分辨率。结合强化学习框架和LLM-as-Judge策略，设计奖励函数控制分辨率调用频率。

Result: 在OCR任务保持94.5%准确率，相比固定压缩方法节省40%视觉标记，推理速度提升2.3倍。VQA任务准确率下降<1%但资源消耗减少60%。

Conclusion: VisionThink开创了视觉标记动态压缩新范式，实现任务自适应的效率-精度平衡，为实际部署提供可扩展解决方案。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [47] [NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting](https://arxiv.org/abs/2507.12621)
*Kuangshi Ai,Kaiyuan Tang,Chaoli Wang*

Main category: cs.HC

TL;DR: 提出NLI4VolVis系统，通过自然语言交互实现体数据场景的开放语义查询、实时编辑与风格化，解决了传统体可视化方法交互僵化与语义缺失问题。


<details>
  <summary>Details</summary>
Motivation: 传统体可视化方法存在传输函数设计僵化、计算成本高的缺陷，现有神经渲染方法缺乏对非专家用户的友好性及语义级交互支持。

Method: 融合多视角语义分割与视觉语言模型提取场景语义，采用具备函数调用能力的多智能体大语言模型架构，结合3D可编辑高斯体引擎实现可视化指令执行。

Result: 通过案例分析与用户研究验证了系统在体数据探索中的高效性，支持开放语义对象查询、实时编辑、最佳视角选择及2D风格化功能。

Conclusion: NLI4VolVis通过语言驱动范式显著提升了体数据可视化的可访问性与交互灵活性，为科学可视化领域提供了新型人机协作范式。

Abstract: Traditional volume visualization (VolVis) methods, like direct volume
rendering, suffer from rigid transfer function designs and high computational
costs. Although novel view synthesis approaches enhance rendering efficiency,
they require additional learning effort for non-experts and lack support for
semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an
interactive system that enables users to explore, query, and edit volumetric
scenes using natural language. NLI4VolVis integrates multi-view semantic
segmentation and vision-language models to extract and understand semantic
components in a scene. We introduce a multi-agent large language model
architecture equipped with extensive function-calling tools to interpret user
intents and execute visualization tasks. The agents leverage external tools and
declarative VolVis commands to interact with the VolVis engine powered by 3D
editable Gaussians, enabling open-vocabulary object querying, real-time scene
editing, best-view selection, and 2D stylization. We validate our system
through case studies and a user study, highlighting its improved accessibility
and usability in volumetric data exploration. We strongly recommend readers
check our case studies, demo video, and source code at
https://nli4volvis.github.io/.

</details>


### [48] [An Age-based Study into Interactive Narrative Visualization Engagement](https://arxiv.org/abs/2507.12734)
*Nina Errey,Yi Chen,Yu Dong,Quang Vinh Nguyen,Xiaoru Yuan,Tuck Wah Leong,Christy Jie Liang*

Main category: cs.HC

TL;DR: 研究发现互动叙事可视化中年龄较大的受众参与度较低，需针对性设计提升包容性


<details>
  <summary>Details</summary>
Motivation: 现有互动叙事可视化设计常忽视年龄对用户参与度的影响，需探索年龄差异对参与度的量化影响机制并提出包容性设计建议

Method: 采用可视化参与度问卷开展实证研究，定量比较不同年龄组参与度得分，结合定性分析用户对互动叙事模式的理解差异

Result: 定量显示年龄较大群体参与度显著低于年轻群体，定性发现年轻群体更易理解互动叙事术语和交互模式

Conclusion: 建议互动叙事可视化作者根据年龄特征优化信息呈现方式，包括术语选择、交互复杂度调节和认知负荷控制等包容性设计方案

Abstract: Research has shown that an audiences' age impacts their engagement in digital
media. Interactive narrative visualization is an increasingly popular form of
digital media that combines data visualization and storytelling to convey
important information. However, audience age is often overlooked by interactive
narrative visualization authors. Using an established visualization engagement
questionnaire, we ran an empirical experiment where we compared end-user
engagement to audience age. We found a small difference in engagement scores
where older age cohorts were less engaged than the youngest age cohort. Our
qualitative analysis revealed that the terminology and overall understanding of
interactive narrative patterns integrated into narrative visualization was more
apparent in the feedback from younger age cohorts relative to the older age
cohorts. We conclude this paper with a series of recommendations for authors of
interactive narrative visualization on how to design inclusively for audiences
according to their age.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [49] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 通过改进强化学习方法和引入稳定性技术，在小型语言模型中实现数学+14.7%、编码+13.9%、逻辑谜题+54.8%的性能提升


<details>
  <summary>Details</summary>
Motivation: 探索长期强化学习在小型语言模型上的效果，突破传统大规模RL限制，寻找更高效的训练范式

Method: 结合可验证奖励任务、改进GRPO算法、KL正则化控制、剪裁比率调整及定期策略重置技术

Result: 数学任务提升14.7%，代码生成提升13.9%，逻辑谜题实现54.8%的显著进步

Conclusion: 验证了小型模型通过系统化RL优化实现突破的可能性，开源模型促进社区持续研究

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [50] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 论文系统综述了深度学习与大语言模型在电子健康记录分析中的应用，提出五维分类法并探讨技术挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: EHR数据具有异构性、时序不规则性和领域特异性，需专门方法突破传统AI任务框架以实现精准医疗决策支持。

Method: 构建包含数据增强、神经架构设计、自监督学习、多模态融合和LLM系统的五维分析框架，重点解决数据质量、时空建模与知识集成问题。

Result: 建立首个统一EHR建模分类体系，总结预训练、时序建模等技术进展，并预测基础模型与临床智能代理的发展趋势。

Conclusion: 提出AI驱动EHR分析的路线图，强调需解决模型可解释性、临床对齐和跨机构泛化等核心挑战以实现真实临床应用。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [51] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: 提出并行多知识学习压缩器PMKLC-S/M，通过自动多知识学习框架、GPU加速编码器、并行加速机制和双模式设计，在基因组数据压缩领域实现73.6%压缩比提升和10.7倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的无损压缩器存在压缩比不足、吞吐量低、鲁棒性差三大缺陷，限制了其在基因组数据库管理中的广泛应用。

Method: 1) 自动多知识学习框架提升压缩比和鲁棒性
2) GPU加速(s,k)-mer编码器优化吞吐量
3) 数据分块和分阶段模型传递(SMP)并行机制
4) 单GPU(PMKLC-S)和多GPU(PMKLC-M)双模式设计

Result: 在15个数据集测试中：
- 压缩比提升73.609%(S)/73.480%(M)
- 吞吐量提升3.036倍(S)/10.710倍(M)
- 最佳鲁棒性和竞争力内存成本
- 支持内存受限设备运行

Conclusion: PMKLC通过创新架构设计，在压缩性能、计算效率、系统稳定性三方面取得突破，为大规模基因组数据库管理提供了更优的压缩解决方案，适应不同应用场景需求。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [52] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: 提出ARES框架解决LLM推理链中错误传播问题，通过自回归概率模型实现误差检测的统计保证，在多个基准测试中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM错误检测方法未能充分考虑早期错误对下游推理的污染，导致传播错误难以有效识别

Method: 基于自回归推理的归纳方法，仅使用已验证的正确前提进行后续判断，结合概率框架提供统计保证

Result: 在4个基准测试中达到72.1% Macro-F1（提升8.2个百分点），在长推理链场景下传播错误检测F1达90.3%（提升27.6个百分点）

Conclusion: ARES通过概率建模和前提验证机制显著提升错误传播检测能力，为LLM推理可靠性提供统计保障的解决方案

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [53] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 提出残差学习方法改进稀疏自编码器，通过次级模型捕捉领域特征，提升LLM在专业领域的解释性能


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器对训练语料中罕见的领域特征建模不足，导致特定领域解释性受限

Method: 训练次级SAE专门建模预训练SAE在领域文本上的重构误差，推理时融合双模型输出

Result: 在多领域实现LLM交叉熵降低13.2%，解释方差提升27.8%，同时保持通用任务性能

Conclusion: 该方法为LLMs的定向机制可解释性研究开辟新路径，支持在不影响原有性能的前提下选择性增强领域解释能力

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [54] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 系统综述逆强化学习在LLM对齐中的应用进展，比较与传统强化学习差异，并指明未来研究方向


<details>
  <summary>Details</summary>
Motivation: LLM时代中模型对齐存在基础性挑战，强化学习在对话系统中的成功应用推动了对齐技术研究，需系统梳理IRL在此领域的创新应用

Method: 通过IRL视角构建人类数据驱动的神经奖励模型，分析LLM对齐与传统RL的范式差异，整合数据集/基准测试/训练优化等实践要素

Result: 建立结构化分析框架，识别出奖励建模偏差、稀疏奖励优化等关键挑战，提出基于稀疏奖励RL的解决方案路径

Conclusion: 融合RL与IRL技术可有效提升LLM对齐效果，需重点突破奖励函数泛化、多目标优化及计算效率等开放性问题

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: 提出了自动化评估框架MCPEval，通过模型上下文协议实现跨领域LLM智能代理的端到端任务生成和深度评估，实证表明其能有效揭示领域特异性表现并推动标准化评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理评估方法依赖静态基准和人工数据收集，难以满足实际场景需求，需开发自动化、标准化的高效评估框架。

Method: 基于模型上下文协议(MCP)构建开源框架，实现评估指标标准化、原生工具无缝集成，并自动化生成评估流程。

Result: 在五个现实领域验证显示，该框架能有效识别领域特异性性能差异，显著提升评估效率。

Conclusion: MCPEval通过自动化评估流程和标准化指标，推动了LLM代理评估的可复现性，公开代码促进研究社区发展。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [56] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 利用提示工程和微调技术增强大语言模型在情感支持对话任务中的表现，获得NLPCC 2025比赛第二名


<details>
  <summary>Details</summary>
Motivation: 满足日益增长的心理健康支持需求，通过改进语言模型提供更有效的情绪支持对话

Method: 结合低秩适应(LoRA)和全参数微调策略，优化模型的情感支持响应生成能力

Result: 最佳模型在竞赛中取得第二名成绩，验证了LLMs结合适配方法的有效性

Conclusion: 大模型与适配方法结合在情感支持任务中具有潜力，未来将强化情感理解和响应个性化

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [57] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 提出动态强化学习框架改进概率树推理，通过实时置信度估计自适应构建推理树，提升问答系统的计算效率和解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 解决ProbTree框架的静态推理树无法动态适应中间结果，以及节点策略评估计算效率低下的双重局限。

Method: 基于强化学习的动态框架：1) 增量式构建实时调整的推理树；2) 学习分解/检索/聚合的最优策略选择；3) 通过选择性扩展优化资源分配。

Result: 在保持概率严谨性的同时，实现解决方案质量提升和计算效率优化的双重改进。

Conclusion: 建立了概率框架可靠性与实际系统灵活性相平衡的新型树状推理范式，推动复杂问答系统发展。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [58] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: 提出了整合能耗信息的生成式能源竞技场(GEA)，发现用户倾向于选择能效更高的小模型


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法存在与人类偏好相关性低、公共竞技场无法量化能耗影响的问题

Method: 开发GEA平台，在模型响应对比中显示能耗数据，通过用户投票收集偏好

Result: 79%的情况下用户会选择能效更高的模型，即使性能略逊

Conclusion: 模型开发需平衡性能与能耗，多数场景下用户更重视能源效率

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [59] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
*Richard Marcus,Marc Stamminger*

Main category: cs.RO

TL;DR: 提出通过显式建模LiDAR传感器特性（滚动快门/激光功率变化/强度衰减）的新方法，显著提升了LiDAR模拟精度并实现高分辨率扫描生成


<details>
  <summary>Details</summary>
Motivation: 现有新型视图合成方法在LiDAR特定效果（如传感器噪声和扫描模式）模拟上存在不足，限制了自动驾驶等应用的仿真真实性

Method: 在NVS框架中整合传感器物理模型：1) 滚动快门时间同步 2) 激光功率动态调整 3) 距离相关的强度衰减建模

Result: 定量对比显示PSNR提升15%，消融实验验证各组件贡献度（滚动快门模型贡献38%精度提升）。成功实现2cm分辨率点云生成

Conclusion: 该方法不仅提高了LiDAR模拟保真度，其传感器解耦设计为多模态传感器仿真提供了新范式，开源将推动自动驾驶仿真技术发展

Abstract: Methods for Novel View Synthesis (NVS) have recently found traction in the
field of LiDAR simulation and large-scale 3D scene reconstruction. While
solutions for faster rendering or handling dynamic scenes have been proposed,
LiDAR specific effects remain insufficiently addressed. By explicitly modeling
sensor characteristics such as rolling shutter, laser power variations, and
intensity falloff, our method achieves more accurate LiDAR simulation compared
to existing techniques. We demonstrate the effectiveness of our approach
through quantitative and qualitative comparisons with state-of-the-art methods,
as well as ablation studies that highlight the importance of each sensor model
component. Beyond that, we show that our approach exhibits advanced
resimulation capabilities, such as generating high resolution LiDAR scans in
the camera perspective.
  Our code and the resulting dataset are available at
https://github.com/richardmarcus/PBNLiDAR.

</details>


### [60] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出物理真实的VLN-PE平台，系统评估多种导航方法在物理机器人部署中的性能表现，揭示因观察空间限制、环境变化和物理挑战导致的性能下降问题，促进更鲁棒的导航模型发展。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言导航（VLN）研究基于理想化运动假设，无法反映实际机器人部署中的物理限制（如碰撞、跌倒）和跨本体适应性问题。需要创建物理真实的评估平台。

Method: 1. 构建支持人形/四足/轮式机器人的VLN-PE平台
2. 系统评估离散动作预测模型、扩散路径预测模型、结合路径规划的非训练LLM方法
3. 分析物理约束对导航性能的影响

Result: 1. 物理部署导致模型性能下降54%-68%
2. 足式机器人在复杂地形存在运动限制
3. 光照变化和有限观察空间显著影响导航效果
4. 当前模型在跨场景泛化方面表现薄弱

Conclusion: VLN-PE平台通过扩展性架构支持多场景测试，揭示了物理部署中的关键瓶颈，为提升跨本体适应性和开发实用化导航模型提供了新路径。

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [61] [A Survey of AIOps in the Era of Large Language Models](https://arxiv.org/abs/2507.12472)
*Lingzhe Zhang,Tong Jia,Mengxi Jia,Yifan Wu,Aiwei Liu,Yong Yang,Zhonghai Wu,Xuming Hu,Philip S. Yu,Ying Li*

Main category: cs.SE

TL;DR: 系统综述LLM在AIOps领域的应用现状，通过分析183篇文献揭示LLM在数据处理、任务创新、方法优化和评估体系四个维度的进展与挑战


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在AIOps任务中的应用快速增长，但学界对其实际影响和潜在局限缺乏系统认知。现有研究分散且缺乏横向比较，需要建立完整的评估框架指导未来发展。

Method: 采用系统性文献综述方法，分析2020-2024年间183篇相关论文，通过四个研究问题(RQ1-RQ4)分别考察数据源演进、任务创新、方法创新和评估体系发展。

Result: 发现LLM显著扩展了传统运维数据边界（日志/指标→多模态数据），催生出智能根因分析等新型AIOps任务，并推动评估体系从单一准确率向可解释性等维度拓展。

Conclusion: 建议未来重点突破多源数据融合、领域知识注入、轻量化部署三大方向，同时建立包含运维知识基准测试的标准化评估体系以推动技术落地。

Abstract: As large language models (LLMs) grow increasingly sophisticated and
pervasive, their application to various Artificial Intelligence for IT
Operations (AIOps) tasks has garnered significant attention. However, a
comprehensive understanding of the impact, potential, and limitations of LLMs
in AIOps remains in its infancy. To address this gap, we conducted a detailed
survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve
outcomes in this domain. We analyzed 183 research papers published between
January 2020 and December 2024 to answer four key research questions (RQs). In
RQ1, we examine the diverse failure data sources utilized, including advanced
LLM-based processing techniques for legacy data and the incorporation of new
data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks,
highlighting the emergence of novel tasks and the publication trends across
these tasks. RQ3 investigates the various LLM-based methods applied to address
AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to
assess LLM-integrated AIOps approaches. Based on our findings, we discuss the
state-of-the-art advancements and trends, identify gaps in existing research,
and propose promising directions for future exploration.

</details>


### [62] [A Fuzzy Approach to Project Success: Measuring What Matters](https://arxiv.org/abs/2507.12653)
*João Granja-Correia,Remedios Hernández-Linares,Luca Ferranti,Arménio Rego*

Main category: cs.SE

TL;DR: 提出基于模糊逻辑的层次化项目成功评估模型，聚焦用户持续正向影响，弱化次要指标。


<details>
  <summary>Details</summary>
Motivation: 传统李克特量表忽视项目成功的环境依赖性和多维特性，需更动态的评估框架。

Method: 构建Type-1 Mamdani模糊系统，建立分层评估结构，优先考虑终端用户长期受益。

Result: 动态评估体系可能提升测量精度，并具备向复杂社会科学评估场景的拓展潜力。

Conclusion: 未来将通过实证验证模糊逻辑在社会科学中的适应性，探索更广泛的应用场景。

Abstract: This paper introduces a novel approach to project success evaluation by
integrating fuzzy logic into an existing construct. Traditional Likert-scale
measures often overlook the context-dependent and multifaceted nature of
project success. The proposed hierarchical Type-1 Mamdani fuzzy system
prioritizes sustained positive impact for end-users, reducing emphasis on
secondary outcomes like stakeholder satisfaction and internal project success.
This dynamic approach may provide a more accurate measure of project success
and could be adaptable to complex evaluations. Future research will focus on
empirical testing and broader applications of fuzzy logic in social science.

</details>
