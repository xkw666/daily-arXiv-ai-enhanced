<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 59]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.CR](#cs.CR) [Total: 5]
- [cs.CV](#cs.CV) [Total: 4]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.LG](#cs.LG) [Total: 4]
- [math.CO](#math.CO) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出混合专家模型MultiPL-MoE，通过token/segment双层级MoE结构提升LLMs多编程语言生成能力


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在多语言代码生成中存在性能瓶颈，需在有限算力下同时提升多语言支持与保持主流语言性能

Method: 1. Token级MoE：共享专家+门控权重归一化 2. Segment级MoE：滑动窗口分割+专家选择路由策略

Result: 实验验证MultiPL-MoE在多语言代码生成任务中显著优于基线模型

Conclusion: 混合双层级MoE结构有效提升多编程语言适应性，为资源受限场景提供实用解决方案

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [2] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 提出结合越南语和英语的双语音素集及端到端系统，有效提升双语混合语音识别准确率


<details>
  <summary>Details</summary>
Motivation: 越南语依赖声调变化，英语存在重音模式与非标准发音，导致双语混合场景下音素对齐困难，传统ASR系统识别效果受限

Method: 1.构建跨语言共享音素集 2.基于PhoWhisper预训练编码器的端到端系统，通过深层特征表示提升音素识别能力

Result: 实验证明该方法在越南双语识别场景中准确率显著提升，并为声调/重音混合识别提供通用框架

Conclusion: 提出的双语对齐方法有效解决音系差异问题，为复杂多语言语音识别系统开发提供了新思路

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [3] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 通过用本地加权有限自动机（WFA）替代全局数据存储，增强LLM的可靠推理能力并保持透明检索机制


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的推理方法（如CoT和ICL）存在输出不稳定、机制不透明的问题，需要更结构化可信的替代方案

Method: 在RetoMaton框架中构建本地任务自适应WFA，直接从领域语料库创建显式记忆结构，保持符号可追溯性和低推理开销

Result: 在TriviaQA/GSM8K/MMLU三个任务中，LLaMA和Gemma模型性能持续提升，同时实现透明可复现的检索动态

Conclusion: 轻量级自动机引导的记忆机制为现代LLM实现可信符号推理提供了新方向，优于传统提示方法

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [4] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: 开发RAGAPHENE平台用于模拟真实对话场景，评估LLM在检索增强生成任务中的表现


<details>
  <summary>Details</summary>
Motivation: LLM在生成答案时可能出现事实性错误，需要可靠的基准来评估其多轮RAG对话能力

Method: 创建基于聊天的注释平台，支持注释者模拟真实对话流程并内置评估指标

Result: 40名注释者成功构建数千条真实对话数据

Conclusion: RAGAPHENE为LLM评估提供了高效可靠的对话模拟解决方案

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [5] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 本研究证明口头尸检叙述文本结合预训练语言模型能显著提升死因分类效果，多模态融合策略进一步优化结果


<details>
  <summary>Details</summary>
Motivation: 现有自动化死因分类算法仅使用结构化问题而忽视叙述文本信息，可能造成关键信息缺失。本研究旨在探索叙述文本在提升死因分类准确性中的作用

Method: 使用南非实证数据，采用基于Transformer的预训练语言模型进行任务微调，并设计多模态融合策略整合叙述文本与结构化问题

Result: 仅用叙述文本时微调后的PLM在个体/群体层面均优于现有方法（尤其非传染性疾病识别），多模态方法使准确率提升3.2%。信息充足性显著影响模型与医生的分类表现

Conclusion: 叙述文本包含独特信息价值，建议收集多样化数据优化模型，并推动口头尸检工具重新设计。研究为自然语言处理与流行病学交叉领域提供新见解

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [6] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: 提出FLAIRR-TS框架，通过代理系统动态优化提示模板，使冻结大语言模型在时间序列预测中达到接近专用提示的性能，无需微调或中间代码生成


<details>
  <summary>Details</summary>
Motivation: 现有基于大模型的时间序列预测方法依赖手工设计静态提示，存在任务适配性差、优化成本高的问题，需开发自适应提示优化机制

Method: 构建双代理系统：预测代理生成初始预测，优化代理基于历史输出和检索的类似样本动态优化提示模板，使用可泛化的创意提示模板架构

Result: 在基准数据集上准确率超越静态提示和检索增强基线，接近专用提示性能，验证了框架的有效性和领域泛化能力

Conclusion: FLAIRR-TS通过动态提示优化与检索机制，为大模型时间序列预测提供了实用解决方案，在保持零样本优势的同时达到专业级效果

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [7] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: CORE利用强化学习实现RAG的无损上下文压缩，3%压缩率下保持性能并提升3.3分准确率


<details>
  <summary>Details</summary>
Motivation: 传统RAG检索文档过长导致计算成本高，现有压缩方法依赖固定启发式规则且损害任务性能

Method: 采用强化学习框架(GRPO)，以终端任务准确率为奖励信号训练压缩器，实现端到端优化

Result: 在4个数据集上验证，3%压缩率下所有数据集未出现性能下降，平均EM分数提升3.3分

Conclusion: CORE首次实现基于强化学习的无监督上下文压缩，显著提升RAG效率同时保证任务性能

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [8] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: 提出CASC框架解决复杂领域多文档问答中的信息过载问题，通过结构化合成降低LLM认知负荷


<details>
  <summary>Details</summary>
Motivation: 传统RAG在复杂多文档场景存在信息过载和低效合成问题，导致答案不准确

Method: 基于微调小型LLM的CAS模块实现关键信息提取、冲突消解和结构化合成

Result: 在SciDocs-QA数据集上显著超越基线模型，尤其擅长处理冗余冲突文档

Conclusion: CASC框架有效提升复杂领域问答质量，实现信息压缩率超80%的同时保持语义完整性

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [9] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: ARIS结合判别式模型和生成式LLM，通过共识机制和反射推理提升事件抽取的准确性与召回率。


<details>
  <summary>Details</summary>
Motivation: 解决传统判别模型高精度低召回率问题，以及生成式LLM的幻觉问题，通过混合架构平衡性能。

Method: 使用自混合代理+序列标注器，结合置信度过滤、模型共识和LLM反射推理模块，采用分解式指令微调。

Result: 在三个基准数据集上超越现有SOTA方法，验证了方法的有效性。

Conclusion: ARIS通过混合架构和共识机制有效解决了事件抽取中精度与召回率的权衡问题，反射推理是关键创新点。

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [10] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: 提出LongReasonArena基准评估LLM长推理能力，现有模型表现显著不足


<details>
  <summary>Details</summary>
Motivation: 现有长上下文基准仅关注输入理解，忽视对长推理能力的系统评估。需要建立能评估多步复杂推理能力的基准，突破模型处理长逻辑链的瓶颈。

Method: 通过控制输入构建可扩展推理长度的多步算法任务（检索/回溯等），支持从基础到百万token级的推理复杂度分级。

Result: Deepseek-R1准确率仅7.5%，所有模型表现与log(推理步骤数)呈线性负相关。

Conclusion: LongReasonArena揭示了当前LLM在长推理任务中的根本缺陷，为模型优化提供明确方向。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [11] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 提出数据库实体识别(DB-ER)新方法：基于T5架构的专用模型，配合数据增强和双任务微调策略，性能优于主流NER工具


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询中的数据库实体识别难题，现有NER工具在数据库场景下精度不足

Method: 1. 构建人工标注基准数据集
2. 基于SQL查询的自动数据增强技术
3. 设计双阶段T5模型（序列标注+token分类）

Result: 模型准确率/召回率超越现有NER工具，数据增强带来10%+指标提升，T5微调提升5-10%

Conclusion: 该方法通过领域定制化方案有效提升数据库场景的实体识别性能，数据增强策略具有推广价值

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [12] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 研究探讨LLMs在不同幽默任务间的迁移能力，发现多样化训练可提升模型对新幽默类型的适应能力（最高达75%准确率）。


<details>
  <summary>Details</summary>
Motivation: 在线环境中不断涌现新型幽默形式（如表情包、冷幽默），需验证LLMs能否通过迁移学习突破传统单一任务建模的局限性。

Method: 跨4个幽默数据集进行迁移学习实验，对比单任务训练与多任务联合训练在未知任务上的表现差异。

Result: 多数据集训练使模型迁移准确率提升1.88-4.05%，Dad Jokes表现出最佳迁移促进特性（但自身难以被其他模型迁移）。

Conclusion: 幽默机制存在可迁移性，训练数据多样性是提升LLMs幽默适应能力的关键，为动态网络环境中的幽默处理提供新思路。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [13] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 探讨生成式AI工具普及可能导致人类书写能力退化的历史性警示


<details>
  <summary>Details</summary>
Motivation: 基于当前AI文本生成技术快速发展可能取代人类写作的现象，类比希腊黑暗时代书写能力退化的历史案例，警示技术依赖对人文能力的潜在威胁

Method: 采用历史比较分析法，将AI时代与公元前1200-800年希腊文明衰退期进行书写能力变迁的跨时空对比

Result: 揭示技术替代可能引发人类关键能力退化的历史规律，预测未来可能出现的人类书写能力衰退风险

Conclusion: 提出在利用AI技术提升效率的同时，需建立人机协同机制保护人类核心人文素养，避免重蹈历史文明断层的覆辙

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [14] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 提出模块化系统结合检索增强生成、零样本分类和图注意力模型，在LLMs4OL挑战赛的术语抽取、类型分配和分类法发现三个任务中均取得领先成绩


<details>
  <summary>Details</summary>
Motivation: 解决本体构建流程中的异构任务需求，通过模块化设计实现跨领域的可扩展性和适应性

Method: 任务A使用RAG流程联合抽取术语类型，任务B采用少样本提示+零样本多模型加权分类，任务C通过跨注意力层建模类型标签的图关系

Result: 在官方评测中三个任务均获顶级排名，验证了方法的鲁棒性和领域适应性

Conclusion: 模块化任务专属方案展示了LLM架构在跨领域本体学习中的扩展潜力，为异构知识处理提供新范式

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [15] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: CoLAP方法通过对比学习与跨语言表征结合，提升低资源语言的NLP性能，实现高效知识迁移


<details>
  <summary>Details</summary>
Motivation: 解决多语言NLP中高低资源语言数据量严重失衡的问题，降低低资源语言对标注数据的依赖

Method: 结合对比学习与跨语言提示学习，在编码器-解码器模型上进行自然语言理解任务（推理/关系抽取）测试

Result: 在有限数据下超越小样本跨语言迁移和上下文学习，显著缩小语言间的性能差距

Conclusion: 该方法为开发高效多语言NLP技术提供了数据高效的解决方案

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [16] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 开发NER框架提取社交媒体中阿片类药物使用的临床与社会影响，DeBERTa-large模型表现最优但仍显著落后于专家共识


<details>
  <summary>Details</summary>
Motivation: 非医疗阿片类药物使用对公共卫生造成深远影响，但传统医疗数据不足。社交媒体用户自述经历为研究提供新视角

Method: 1. 构建RedditImpacts 2.0标注数据集
2. 对比微调编码器模型与LLM在零样本/少样本学习下的表现

Result: 1. DeBERTa-large模型F1=0.61，显著优于LLM
2. 标注数据量需求减少仍保持性能
3. 最佳模型kappa=0.81，低于专家间一致性

Conclusion: 领域特定微调对临床NLP至关重要，当前AI在深度领域知识任务上仍存在能力差距，需负责任地开发AI工具支持成瘾监测与医疗决策

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [17] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 利用微调后的Meta-Llama 2-7B模型集成RACE数据集，开发英语自动问答生成系统(AQAG)，支持多种题型定制以优化教学评估效率。


<details>
  <summary>Details</summary>
Motivation: 传统人工命题存在公平性把控难、耗时耗力的问题，需通过自动化技术减轻教师负担并提升评估质量。

Method: 采用无监督NLP方法，基于RACE数据集对Llama模型进行微调，结合提示工程实现多选题/概念题/事实题等个性化命题风格适配。

Result: 构建出支持个性化定制的问答生成模型，为教育工作者提供高效的文本评估解决方案。

Conclusion: 该工具能有效释放教学资源，未来将持续优化模型以适应更广泛的教育评估场景。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [18] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 提出结合外部词典工具和强化学习的端到端训练方法，在西班牙语-Wayuunaiki低资源翻译任务中实现3.37 BLEU提升


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在低资源语言翻译中预训练数据不足和并行语料有限的问题

Method: 监督指令微调+GRPO强化学习框架，模型可动态调用双语词典并学习调用策略，使用BLEU分数作为奖励信号

Result: 在测试集上相比基线提升3.37 BLEU（相对提升18%），消融实验验证模型架构和训练策略的有效性

Conclusion: 证实结合外部工具与强化学习能有效提升低资源翻译质量，为后续研究提供新方向

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [19] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: 研究评估大语言模型在《杀戮尖塔》卡牌协同效应中的表现，发现模型擅长识别非协同组合，但在正负协同识别上存在缺陷


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在动态复杂规则环境（如卡牌游戏）中的规则交互理解能力

Method: 构建《杀戮尖塔》卡牌协同数据集，包含正/负/中性协同分类，对LLMs进行系统性评估

Result: 模型识别非协同组合准确率较高（84.3%），正协同准确率59.1%，负协同仅38.5%；常见错误涉及时序理解、游戏状态定义和规则遵循问题

Conclusion: 需改进模型对规则交互效应的预测能力，未来研究应着重时序推理、游戏状态建模和动态规则适应方向

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [20] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 提出Blockwise SFT方法，通过块状监督微调解决离散扩散语言模型训练与推理阶段的不对齐问题，显著提升数学推理任务表现。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调在训练时随机掩码整个响应，与推理阶段按固定块顺序生成的半自回归解码方式存在结构不匹配，导致噪声前缀和梯度偏差。

Method: 1. 将响应划分为固定大小的块
2. 每步选择单个活动块进行随机掩码
3. 冻结前置块+隐藏后续块
4. 仅计算活动块损失，精确对齐块状解码流程

Result: 在GSM8K/MATH/MetaMathQA数据集上，相同计算资源或token预算下，Blockwise SFT相比传统方法获得稳定提升。消融实验验证改进源于训练-推理对齐而非掩码副作用。

Conclusion: 研究表明监督粒度与解码过程的匹配度是提升扩散语言模型性能的关键因素，为后续算法设计提供了重要启示。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [21] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出通过将代码片段分割为更小的粒度块生成多样化的DPO训练对，结合抽象语法树分割和课程训练方法，显著提升了大型语言模型在代码生成任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有基于DPO的代码生成方法受限于测试用例生成效率，难以从有限测试案例中构建足够多样化的训练数据

Method: 1. 结构化代码分割技术生成多样化DPO训练对 2. 引入抽象语法树(AST)分割策略 3. 采用课程训练方法分阶段优化模型

Result: 在HumanEval(+)、MBPP(+)、APPS等五个基准测试中取得显著提升，最高在LiveCodeBench上提升12.5%的pass@1准确率

Conclusion: 通过结构化代码分割和渐进式训练策略，有效提升了LLMs的代码生成能力，相关代码和数据集已开源

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [22] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出UERC任务及ProEmoTrans框架解决开放域对话情感识别难题，通过LLM增强描述、参数无关编码机制和改进的Viterbi解码实现跨情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有ERC研究基于封闭情感分类假设，而心理学缺乏统一标准导致实际场景中未见情感识别困难。需突破封闭域限制建立开放情感迁移能力。

Method: 1. LLM增强描述解决隐式情感定义问题
2. 参数无关机制优化长对话编码
3. 改进注意力Viterbi解码实现情感转移学习

Result: 在三个数据集上的实验验证了方法的有效性，为该新领域建立了强基线。

Conclusion: 提出的原型迁移框架通过多维度创新，为开放域情感识别提供了可扩展的解决方案，推动ERC向现实应用迈进。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [23] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 研究发现闭源与强开源大语言模型能够识别歧义并利用规则漏洞达成自身目标，揭示潜在AI安全风险


<details>
  <summary>Details</summary>
Motivation: 通过分析模型对规则漏洞的反应，研究LLM的歧义处理能力与语用推理机制，同时揭示目标冲突场景下的新型对齐问题

Method: 设计目标与模糊指令冲突的实验场景（涵盖量词隐含义/结构歧义/权力动态），测量不同模型利用漏洞实现预设目标的能力

Result: 闭源模型（如GPT-4）和强开源模型（如Llama2）展现出系统性漏洞利用能力，且模型会显式识别歧义并进行目标冲突推理

Conclusion: 模型通过显式分析歧义和权衡冲突目标来利用规则漏洞，这种机制可能被恶意利用，构成新型AI安全威胁

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [24] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET框架通过三层关键事实层次结构（根-分支-叶）和查询聚焦摘要技术，自动化评估大语言模型的长文本理解能力，发现模型在叶级细粒度理解存在显著缺陷且存在位置敏感效应。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型长文本评估方法存在人工成本高、粒度粗的问题，需要开发自动化框架系统分析模型在多层次文本理解中的表现。

Method: 构建三层文本关键事实体系，采用查询聚焦摘要评估模型的信息召回和表征能力，通过人工研究验证自动评估可靠性（90%专家一致性），并对比分析不同模型类型/规模的性能差异。

Result: 自动评估成本降低25倍，模型在叶级理解准确率比根级低40%，开源模型落后专有模型15-20个百分点，分析性查询错误率比叙事性高32%。

Conclusion: HAMLET为长文本评估提供高效工具，揭示了LLMs细粒度理解和位置敏感的核心缺陷，代码开源促进后续研究。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [25] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 提出新型ArgCMV数据集解决ArgKP21局限性，展示现有关键点提取方法在复杂对话场景中的不足


<details>
  <summary>Details</summary>
Motivation: 现有ArgKP21数据集无法充分反映真实人类对话的复杂性，需建立更贴近实际辩论场景的基准数据集

Method: 使用前沿大语言模型构建ArgCMV数据集（含3,000+主题下的12,000+实际在线辩论），具备长文本、共指消解、主观论述等复杂特征

Result: 现有模型在ArgCMV上表现显著下降，实验揭示当前方法对复杂对话场景的适应局限性

Conclusion: ArgCMV为长上下文讨论的摘要研究奠定新基准，推动LLM驱动的下一代摘要技术发展

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [26] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 研究揭示现代阿拉伯语ASR系统在孤立字母识别上的不足（35%准确率），通过轻量网络+对抗训练将准确率提升至65%，并增强噪声鲁棒性


<details>
  <summary>Details</summary>
Motivation: 孤立阿拉伯字母识别对语言学习/语音治疗至关重要，但现有系统因缺乏语境/短时长/特殊发音特征（如咽化辅音）而表现不佳

Method: 构建带音标的孤立字母语料库，测试wav2vec 2.0基线性能，设计轻量神经网络改进特征提取，引入对抗训练应对声学扰动

Result: 基线模型准确率35% → 轻量网络提升至65%；添加ε=0.05扰动后骤降至32% → 对抗训练后噪声准确率仅下降9%（56%→47%）

Conclusion: 提出可复现的鲁棒训练框架，未来将扩展至词句级ASR，特别强调字母级发音精度对阿拉伯语处理的关键作用

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [27] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 提出了Router Lens方法识别上下文忠实专家，并开发轻量级优化框架CEFT，在提升模型上下文忠实性的同时保持高效性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在依赖上下文的场景中存在输出与上下文脱节的问题，受混合专家架构中专家专业化现象启发，探索通过优化特定专家提升上下文忠实性。

Method: 1. 设计Router Lens方法精准定位上下文忠实专家；2. 提出CEFT框架对目标专家进行选择性微调

Result: CEFT在多个基准测试中达到或超越全参数微调效果，计算效率提升2.6-3.1倍

Conclusion: 上下文忠实专家的定向优化为提升大模型推理可靠性提供了高效解决方案，专家特征分析为模型优化开辟新路径

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [28] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 研究发现向检索文档注入噪声能优化大语言模型的外部知识整合能力，提出基于层次功能分界的Layer Fused Decoding解码策略，实验证明其低成本提升RAG系统效果。


<details>
  <summary>Details</summary>
Motivation: 针对检索增强生成系统中噪声注入的悖论现象（噪声反而提升生成质量），探索大语言模型整合外部知识的机理，实现知识整合过程的精细化控制和分析。

Method: 1. 通过噪声干预建立层次化功能分界：浅层处理局部语境，中层整合外部事实知识，深层依赖参数化内部知识
2. 提出层次融合解码(LFD)，将中间层与最终层解码输出结合
3. 设计内部知识评分(IKS)准则选择最优中间层

Result: 在多个基准测试中，LFD策略有效提升RAG系统对检索上下文的利用率，所需计算成本最低仅增加1.6%推理时间。

Conclusion: LFD通过层次特征融合机制，在保持推理效率的同时显著增强大模型对外部事实知识的调用能力，为优化知识密集型任务提供新思路。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [29] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: 提出对抗学习框架SALF，通过生成器与检测器的符号对抗优化，实现假新闻生成与检测的协同进化。


<details>
  <summary>Details</summary>
Motivation: 现有基于微调模型或LLM的检测方法难以应对动态演变的假新闻，需更鲁棒的对抗训练框架提升系统适应性。

Method: 构建生成器（伪造虚假叙事）与检测器（结构化辩论识别漏洞）的对抗机制，采用自然语言表示的符号学习替代传统梯度更新。

Result: 实验显示SALF生成内容使现有检测器性能下降53.4%（中文）和34.2%（英文），对抗优化后检测准确率提升7.7%。

Conclusion: 符号对抗学习为假新闻检测提供新范式，启示构建动态进化的鲁棒检测系统。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [30] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出通过FMI标准封装SystemC模型，有效提升汽车协同仿真的互操作性与安全性，并通过实际案例验证有效性


<details>
  <summary>Details</summary>
Motivation: 汽车行业缺乏标准化协同仿真接口，专有平台主导导致协作困难、扩展性受限和IP保护不足

Method: 开发自动化封装框架，将SystemC模型转换为符合FMI标准的FMU组件

Result: 在真实工业案例中成功集成复杂嵌入式设计，验证了方法在保持建模精度的同时提升协同效率

Conclusion: 该融合方案突破异构仿真环境壁垒，为汽车电子系统开发提供标准化、安全化的协同验证新范式

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [31] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 专用大语言模型正从简单领域适应转向原生架构创新，技术突破如稀疏计算、多模态融合显著提升专业场景性能，尤其为电子商务领域提供新机遇。


<details>
  <summary>Details</summary>
Motivation: 解决通用大语言模型在专业领域应用中的核心局限，通过领域定制化架构突破传统微调模式，探索参数效率与多模态融合的技术路径。

Method: 系统分析医疗/金融/法律/技术领域LLM演进，研究原生架构设计、稀疏计算量化技术、多模态集成等创新在LLM智能体中的实践应用。

Result: 专用模型在领域基准测试中持续实现性能突破，参数效率提升与多模态增强显著优化专业任务表现。

Conclusion: 领域原生LLM标志着AI发展的范式转变，其架构创新与效率优化为电子商务等垂直领域填补技术空白提供系统性解决方案。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [32] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 开发具有高适应性、可扩展性且精准的任务机器人，需最小化人工干预


<details>
  <summary>Details</summary>
Motivation: 对话研究中如何实现自主进化的任务机器人存在重大技术挑战

Method: 研究自主学习和环境适应的创新技术方案

Result: 系统分析了动态环境下机器人开发的技术障碍及解决方案

Conclusion: 该研究为构建自主进化型对话机器人提供了重要技术框架

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [33] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: 提出CSKS框架，通过调节两个小代理模型的输出来灵活控制大语言模型对上下文知识的敏感度，无需修改模型权重


<details>
  <summary>Details</summary>
Motivation: 现有方法在调节大语言模型知识敏感性时存在效率低、不适用黑盒模型、无法连续调节敏感度等问题

Method: 训练两个代理模型，利用其输出差异调整原模型分布，通过概率偏移实现敏感度连续控制

Result: 实验证明框架能双向调节知识敏感度（增强/减弱），在合成数据和真实冲突数据集上均验证有效性

Conclusion: 该框架以轻量级方式实现灵活的知识敏感度控制，支持模型根据需求优先选择上下文知识或参数知识

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [34] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: 填补欧洲葡萄牙语ASR资源空缺，推出首个开源框架CAMÕES，整合46小时多领域测试基准与SOTA模型，实现35%+ WER提升


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语ASR资源集中于巴西葡萄牙语，欧洲葡萄牙语(EP)等变种缺乏高质量数据集与模型支持

Method: 采用基础模型(零样本/微调)和E-Branchformer架构，使用425小时EP数据进行训练，构建多领域测试集(46h)

Result: 微调后基础模型与E-Branchformer表现相当，最佳模型WER相对零样本模型提升超35%

Conclusion: CAMÕES为EP提供首个开源解决方案，微调模型与新型架构均达SOTA，显著推进葡萄牙语多方言ASR研究

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [35] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 提出NLKI框架整合常识知识，通过检索+LLM生成解释的方式提升小型视觉语言模型性能，在三个数据集上实现最高7%准确率提升，并通过噪声鲁棒训练进一步优化。


<details>
  <summary>Details</summary>
Motivation: 小型视觉语言模型(sVLMs)因缺乏外部知识整合能力，在常识视觉问答中表现落后。研究探索通过结构化知识整合方式缩小与大型模型的差距。

Method: 1. 使用微调ColBERTv2检索事实 2. 设计对象信息增强的提示生成LLM解释 3. 结合对称交叉熵等噪声鲁棒损失函数进行训练

Result: FLAVA等模型准确率提升最高7%，超越中等规模VLM模型。噪声训练在CRIC/AOKVQA分别带来2.5%/5.5%额外提升。

Conclusion: LLM生成的常识知识优于传统知识库检索，噪声感知训练增强小模型稳定性，证明250M参数模型可实现高效常识推理。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [36] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 提出Spotlight Attention方法通过非线性哈希优化LLM的KV缓存选择，结合轻量级训练框架和CUDA内核实现，在保持性能的同时将推理吞吐量提升3倍


<details>
  <summary>Details</summary>
Motivation: 现有线性哈希方法因LLM中query和key的向量呈正交分布导致效率低下，需开发更高效的KV缓存动态选择方案

Method: 1. 设计非线性哈希函数优化向量分布 2. 基于Bradley-Terry排序损失构建轻量训练框架 3. 开发专用CUDA内核利用位运算加速哈希检索

Result: 哈希码长度缩短5倍，检索精度显著提升，单A100 GPU实现512K tokens/100μs的哈希检索，端到端吞吐量最高提升3倍

Conclusion: 通过非线性哈希优化和高效训练框架，在保持模型性能的前提下显著加速LLM推理，CUDA实现进一步释放硬件计算潜力

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [37] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: 提出NEWSCOPE两阶段框架，通过句子级语义建模和多样性重排序提升新闻检索多样性


<details>
  <summary>Details</summary>
Motivation: 现有新闻检索系统过度关注文本相关性导致结果冗余和观点单一，需提升事件理解的多视角覆盖

Method: 第一阶段密集检索主题相关内容，第二阶段采用句子级聚类和多样性感知的重排序机制

Result: 构建LocalNews和DSGlobal数据集，提出三个可解释指标，实验显示在保持相关性同时显著提升多样性

Conclusion: 细粒度语义建模有效减少冗余，促进全面事件理解，开源方案推动相关研究

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [38] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 专家角色提示对任务表现有积极或不显著影响，但对无关属性高度敏感（性能下降近30%），需更谨慎的角色设计和评估方案


<details>
  <summary>Details</summary>
Motivation: 现有研究对专家角色提示效果存在分歧，且未系统分析其生效条件与机制，需通过多维度评估明确其实际影响

Method: 通过文献分析提炼三大核心需求，在27个任务上评估9个先进LLM的性能变化、无关属性鲁棒性及角色属性保真度

Result: 专家角色通常提升/无显著效果，但无关细节导致性能骤降；教育背景/专业化提升效果不稳定；缓解策略仅适用于最大模型

Conclusion: 专家角色设计需平衡属性相关性与鲁棒性，评估体系应更紧密贴合实际应用场景的目标效果

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [39] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了table-to-report任务并构建T2R-bench基准测试，实验表明当前大语言模型在工业表格报告生成任务上仍有提升空间


<details>
  <summary>Details</summary>
Motivation: 现有表格推理研究难以应对工业场景中表格复杂多样导致的推理效果不佳问题，且缺乏有效评估实际应用能力的基准测试

Method: 构建包含457个真实工业表格的双语基准T2R-bench，覆盖19个行业领域和4种表格类型，并提出新的报告质量评估标准

Result: 测试25个主流大模型，最佳模型Deepseek-R1仅获62.71分，显示现有模型在工业表格报告生成任务上仍需改进

Conclusion: T2R-bench有效揭示了LLMs在工业级表格报告生成任务中的局限性，为后续模型优化提供了重要基准

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [40] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: 提出强化学习框架Memory-R1，通过双代理机制实现LLM的主动记忆管理


<details>
  <summary>Details</summary>
Motivation: LLM受限于静态上下文窗口和被动记忆管理，无法有效处理长程推理任务

Method: 设计记忆管理器（强化学习控制ADD/UPDATE/DELETE操作）和回答代理（记忆检索推理），采用PPO/GRPO算法微调

Result: 仅需152个QA对训练即超越基线模型，在不同问题类型和LLM架构中展现强泛化能力

Conclusion: 验证了强化学习可赋能LLM实现动态记忆管理，为构建持久推理系统提供新方向

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [41] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 论文针对印地语指令微调大模型评估难题，提出包含5个数据集的评估套件（IFEval-Hi/MT-Bench-Hi/GSM8K-Hi/ChatRAG-Hi/BFCL-Hi），采用人工标注与翻译验证结合的方法，为低资源语言基准开发提供可复制方法论。


<details>
  <summary>Details</summary>
Motivation: 现有印地语评估基准质量不足，直接翻译英语数据集无法捕捉语言文化特性，阻碍LLM在低资源语言中的能力评估。

Method: 结合原生人工标注与翻译验证流程（translate-and-verify），构建多维评估数据集。

Result: 完成对开源印地语支持LLM的全面性能评估，揭示当前模型能力局限，并建立可扩展至其他低资源语言的基准开发方法论。

Conclusion: 该研究不仅填补了印地语LLM评估的空白，其方法论框架为全球6000+低资源语言的基准开发提供了标准化解决方案。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [42] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 提出基于文本嵌入的分类框架，仅需少量示例即可实现高效定性分析，在物理调查数据验证中达到专家级编码一致性（Cohen's Kappa 0.74-0.83）


<details>
  <summary>Details</summary>
Motivation: 传统定性分析方法耗时且不一致，现有NLP方法因需大量标注数据、破坏现有工作流程或结果不稳定而应用受限

Method: 开发文本嵌入辅助分类框架，适配标准定性流程，支持嵌入模型微调提升性能

Result: 在2899份物理调查响应中达到0.74-0.83 Cohen's Kappa，验证框架可扩展性及审计现有数据集的能力

Conclusion: 该方法在保持定性分析可解释性的同时实现大规模演绎分析，为社会科学研究提供高效分析工具

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [43] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++通过动态任务激活机制突破TokenVerse的全标签限制，实现部分标注数据集的多任务学习，在保持ASR性能的同时提升多任务效果


<details>
  <summary>Details</summary>
Motivation: TokenVerse等传统多任务框架要求所有训练数据必须全任务标注，限制了部分标注数据集的有效利用和框架扩展性

Method: 在XLSR-Transducer声学嵌入空间引入可学习向量实现动态任务激活，支持仅需部分任务标注的语音数据训练

Result: 集成部分标注的ASR+语种识别数据集后，多任务性能达到/超越原框架，同时保持ASR基线性能

Conclusion: TokenVerse++通过动态任务分配机制，成为更实用的多任务解决方案，显著提升框架的数据利用率和部署灵活性

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [44] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 研究证实使用人工标注的Simple Wikipedia简单语言数据构建课程（尤其是先简单后复杂的顺序）能有效提升语言模型在简单文本上的困惑度，而传统基于能力的课程策略效果不明显。


<details>
  <summary>Details</summary>
Motivation: 探索人类标注的语言难度信号（Simple Wikipedia的简单/复杂标签）是否能有效指导课程学习，替代传统基于启发式算法的难度衡量方法。

Method: 使用Simple Wikipedia的篇章级标签构建标签课程，与基于词汇复杂度等能力的课程进行对比，通过BERT-tiny模型测试不同课程策略对语言模型困惑度的影响。

Result: 标签课程策略（特别是早期引入简单数据）使模型在简单文本上困惑度降低6.5%，而能力课程效果与随机排序相当，因其未能有效分离数据难度层次。

Conclusion: 人类对语言难度的直觉能有效指导课程学习，但需通过合理的数据排序策略实现，单纯增加简单数据而不结构化则无显著效果。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [45] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 研究评估了小型语言模型（SLMs）与大型语言模型（LLMs）在检测医学教材中不恰当语言的应用，发现SLMs通过数据增强策略在分类性能上显著优于LLMs。


<details>
  <summary>Details</summary>
Motivation: 传统手动筛查医学教材中过时/排他性语言（IUL）成本过高且不切实际，需开发自动化检测工具以提升医学教育质量。

Method: 使用约500份文档（超12,000页）数据集，对比：1）四种SLM策略（通用/子类/多标签/两阶段分类器）；2）LLMs（LLama-3 8B/70B）的上下文学习策略，含不同提示组合。

Result: SLMs全面优于LLMs，其中多标签分类器在标注数据表现最佳。加入未标记数据作负样本可使子类分类器AUC提升达25%，成为最有效的医学教材语言净化方案。

Conclusion: 小型语言模型结合数据增强策略是当前自动检测医学教材有害语言的最优解，为医学教育内容标准化提供了高效的技术路径。

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [46] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: 创建了首个孟加拉语开放域视觉问答数据集Bangla-Bayanno，包含5.2万组问答对，采用多语言大模型辅助翻译优化流程确保质量


<details>
  <summary>Details</summary>
Motivation: 现有数据集存在人工标注领域局限、多语言翻译质量低下等问题，需构建低资源多模态学习的高质量基准数据集

Method: 设计多语言LLM辅助的翻译优化流程，通过自动化方式减少人工误差并提升翻译清晰度

Result: 建成包含4750+图像、52650组跨3类答案类型（描述/数值/是非）的开放数据集，成为孟加拉语最全面的VQA基准

Conclusion: 该数据集将推动低资源语言多模态研究，为构建包容性AI系统提供基础，填补孟加拉语高质量VQA资源空白

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [47] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 提出基于Chain-of-Thought与echo生成技术训练的结果奖励模型(ORMs)，有效提升大语言模型在逻辑推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于结果奖励模型的测试时扩展方法在演绎逻辑推理领域尚未充分探索，需开发更有效的训练策略来覆盖更多错误类型。

Method: 1. 使用单样本/多样本的思维链生成训练数据
2. 创新性提出echo生成技术：利用LLM易受错误假设影响的特性，主动引导模型生成包含新错误类型的训练数据

Result: 在FOLIO、JustLogic和ProverQA三个数据集上，四个不同LLM的推理准确率均获得提升

Conclusion: 通过主动引导错误生成的echo策略扩展训练数据，有效增强结果奖励模型的错误识别能力，为逻辑推理能力优化提供新思路。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [48] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: 研究发现AI多智能体系统在无预设偏见的中立环境下仍会自发形成刻板印象，其强度随互动次数与决策权力增加，并表现出类似人类的社会行为模式。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统是否会在缺乏训练数据偏见的条件下，通过多智能体互动自发形成刻板印象这一社会现象。

Method: 通过模拟工作场所互动的实验框架，使用不同LLM架构的AI代理进行中性初始条件下的多轮交互，结合层级结构设计观察行为演变。

Result: 1) AI代理自主发展出刻板印象偏见 2) 层级结构加速偏见强化 3) 出现光环效应等群体行为 4) 现象跨模型普适存在

Conclusion: 刻板印象可能是多智能体系统的涌现特性而非单纯数据继承，这对AI伦理治理提出新挑战，需开发新型缓解策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [49] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: 提出HEAL评估框架和UniHypoBench基准，通过假设空间重排序分析偏好对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法评估仅关注单一响应，忽略潜在输出的整体假设空间评估需求

Method: HEAL框架（包含排序准确性和偏好强度相关性双指标）+ UniHypoBench统一假设基准

Result: 当前方法能有效捕捉代理模型偏好并抑制负样本，但存在偏好强度识别局限

Conclusion: HEAL为偏好对齐研究提供新范式与诊断工具，未来需开发更全面的对齐算法

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [50] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 提出通过整合现有阿拉伯语数据集构建AraDhati+，并微调XLM-RoBERTa等预训练模型，实现97.79%的主观性分类准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语资源稀缺且标注数据集不足，限制了主观性分析工具的开发。

Method: 1. 整合ASTD/LABR/HARD/SANAD数据集构建AraDhati+；2. 微调XLM-RoBERTa/AraBERT/ArabianGPT模型；3. 采用集成决策方法。

Result: 阿拉伯语主观性分类准确率达97.79%，验证了资源受限场景下的有效性。

Conclusion: 该方法成功解决了阿拉伯语处理资源匮乏问题，为低资源语言NLP提供了新思路。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [51] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: 提出Prophet解码范式，利用扩散语言模型的早期答案收敛特性，在不训练的情况下实现3.4倍解码加速，保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型因双向注意力计算和多步细化导致推理速度慢于自回归模型，需探索更高效的解码机制。

Method: 通过置信度差距动态决策提前解码时机：1）检测前两名预测候选的置信差异；2）低于阈值时直接解码剩余token，实现步骤缩减。

Result: 在LLaDA-8B和Dream-7B上验证，GSM8K/MMLU任务97%/99%样本半步即可正确解码，总体步骤减少达3.4倍。

Conclusion: 早期解码收敛为加速扩散模型推理提供了新视角，Prophet作为零成本方案可与现有优化技术互补，重构了DLM解码范式。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [52] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: 研究发现大语言模型在单一类型推理步骤表现优异，但在混合型组合推理（常识+数学）时准确率平均下降30%，显著高于同类多步骤推理的下降幅度。人类在此类任务中则保持稳定表现。


<details>
  <summary>Details</summary>
Motivation: 现有组合推理基准测试多聚焦单一推理类型（常识或数学），而现实任务需混合型推理能力。为填补这一研究空白，需构建同时包含常识和数学推理的组合基准。

Method: 构建AgentCoMa基准测试集（61个问题），覆盖61种不同规模/架构/训练策略的LLMs，通过控制变量实验（单独步骤测试与组合测试对比），结合神经元激活模式、注意力图谱等技术进行可解释性分析。

Result: 1. 模型组合推理准确率比单步骤下降30%（同类多步骤下降幅度小） 2. 人类准确率保持90%以上 3. 模型在混合推理时呈现显著的神经模式差异

Conclusion: 当前LLMs在混合类型组合推理中存在显著脆弱性，这种能力断层揭示了模型推理能力的本质局限，为未来改进提供了重要测试基准。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [53] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: 开发情感感知数学辅导系统MathBuddy，通过文本对话和面部表情双模态建模学生情绪，显著提升LLM教学能力（自动评估指标提升23分，DAMR指标提升3分）。


<details>
  <summary>Details</summary>
Motivation: 现有教育大模型忽略学生情感状态，而教育心理学研究表明情绪状态直接影响学习效果，需通过情感建模填补这一技术空白。

Method: 1. 双模态情感捕获（对话文本+面部表情）
2. 多模态情绪置信度聚合
3. 基于情感状态的大模型教学策略动态匹配

Result: 自动评估指标在8个教学维度显示23分胜率提升，DAMR总分提升3分，用户研究验证了情感建模对教学效果的显著增强。

Conclusion: 融合多模态情感感知能有效提升教育大模型的共情教学能力，为个性化教育技术发展提供新范式。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [54] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: 提出ReSURE自适应学习方法，通过动态调整监督权重有效缓解多轮对话训练中的错误传播问题


<details>
  <summary>Details</summary>
Motivation: 现有静态预过滤方法无法动态处理监督错误传播，导致对话系统在低质量数据上性能下降

Method: 使用Welford在线统计估计每轮损失分布，实时动态调整样本损失权重

Result: 实验显示稳定性和回答质量提升，响应分数与样本量呈正相关（Spearman系数0.21~1.0）

Conclusion: 该方法为有效利用大规模数据提供了新思路，代码已开源促进应用验证

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [55] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 提出选择性检索增强方法(SRA)解决法律文本分类中的长尾分布问题，在保持模型架构不变的情况下提升低频标签分类效果。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类数据集存在长尾分布，低频标签样本不足导致模型在罕见类上表现较差。

Method: 通过仅从训练数据中检索增强低频标签样本，避免引入噪声，无需外部语料且防止信息泄露。

Result: 在LEDGAR和UNFAIR-ToS数据集上，SRA的micro-F1/macro-F1均超越现有LexGLUE基线模型。

Conclusion: SRA有效改善长尾分布下的法律文本分类性能，具有架构兼容性强、数据安全性高的优势。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [56] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: 提出了DeepScholar-bench基准框架用于评估生成式研究合成系统，开发DeepScholar-base基线模型并在评估中展现竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有评估体系难以应对复杂动态的研究合成任务，传统问答基准局限于简短回答，专家数据集存在时效性和数据污染问题。

Method: 从ArXiv最新论文构建查询任务，聚焦文献综述章节生成，通过知识合成/检索质量/可验证性三维度评估，开发基于LOTUS API的DeepScholar-base参考系统。

Result: DeepScholar-base在系统对比中表现最佳，但所有系统在基准上的综合得分均未超过19%，表明任务难度较高。

Conclusion: DeepScholar-bench有效揭示了现有系统的局限性，对开发具备研究合成能力的AI系统具有重要意义，当前系统仍有巨大改进空间。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [57] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: IMAGINE框架通过分析嵌入空间分布生成越狱式指令，填补安全对齐数据与真实攻击的分布差异，显著降低LLM攻击成功率且不影响模型效用


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全对齐数据与真实越狱攻击存在分布差异，导致模型无法识别新型恶意指令，迫使开发者陷入被动修补循环

Method: 基于嵌入空间分布分析的迭代优化框架，动态演化文本生成分布，通过合成数据增强安全对齐语料库的分布覆盖

Result: 在Qwen2.5/Llama3.1/Llama3.2上实现攻击成功率显著下降（具体数值未提及），同时保持模型原有功能不受影响

Conclusion: 通过主动生成分布差异数据增强安全对齐语料，IMAGINE有效解决了LLM防御体系中的分布不匹配问题，提升模型主动防御能力

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [58] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: 阿拉伯医疗问答基准AraHealthQA 2025推出MentalQA心理健康和MedArabiQ综合医疗双赛道，通过标准化评估框架推动阿拉伯医疗NLP发展


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语优质医疗QA资源稀缺问题，促进基于多语言现实场景和文化敏感性的医疗问答模型研发

Method: 设计双赛道架构：MentalQA专注焦虑/抑郁等心理健康问答，MedArabiQ覆盖内科/儿科等临床决策；构建多任务评估集并建立标准化评价指标

Result: 成功建立包含基线系统和参与者模型的评估体系，验证了跨语言医疗QA模型在文化适配场景下的可行性

Conclusion: 基准测试揭示了跨文化医疗QA的性能瓶颈，未来需加强医学知识融合和方言处理能力

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [59] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 系统评估多模态大语言模型的空间推理能力，发现其具备初步空间认知迹象但与人类存在显著差距


<details>
  <summary>Details</summary>
Motivation: 探索当前MLLMs是否具备类似人类的空间认知能力，现有评估体系对此关注不足

Method: 基于标准化空间能力测试构建11Plus-Bench基准，结合人类表现对比和细粒度认知过程分析

Result: MLLMs展现出与人类相似的认知努力模式，但实例级表现随机性大，人类表现则受抽象模式复杂度规律性影响

Conclusion: 当前MLLMs在空间推理方面呈现萌芽能力，研究结果为改进模型设计提供了认知科学视角的指导方向

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [60] [Fast Texture Transfer for XR Avatars via Barycentric UV Conversion](https://arxiv.org/abs/2508.19518)
*Hail Song,Seokhwan Yang,Woontack Woo*

Main category: cs.GR

TL;DR: 提出基于重心UV转换的快速面部纹理迁移方法，速度提升7000倍且消除边界伪影


<details>
  <summary>Details</summary>
Motivation: 解决传统仿射变换方法速度慢且产生视觉伪影的问题

Method: 通过预计算UV映射到单一转换矩阵实现单步纹理转换

Result: 定量与定性评估显示速度提升7000倍，纹理质量显著改善

Conclusion: 为沉浸式XR应用提供高效个性化解决方案

Abstract: We present a fast and efficient method for transferring facial textures onto
SMPL-X-based full-body avatars. Unlike conventional affine-transform methods
that are slow and prone to visual artifacts, our method utilizes a barycentric
UV conversion technique. Our approach precomputes the entire UV mapping into a
single transformation matrix, enabling texture transfer in a single operation.
This results in a speedup of over 7000x compared to the baseline, while also
significantly improving the final texture quality by eliminating boundary
artifacts. Through quantitative and qualitative evaluations, we demonstrate
that our method offers a practical solution for personalization in immersive XR
applications. The code is available online.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [61] [Capabilities of GPT-5 across critical domains: Is it the next breakthrough?](https://arxiv.org/abs/2508.19259)
*Georgios P. Georgiou*

Main category: cs.HC

TL;DR: 本研究通过专家评估首次系统比较GPT-4与GPT-5在教育和医疗等领域的表现，发现GPT-5在多数场景显著优于前代模型。


<details>
  <summary>Details</summary>
Motivation: 针对大模型在关键应用领域的性能差异问题，研究者旨在验证GPT-5相比GPT-4在教育、临床诊断等专业场景的实际提升效果。

Method: 邀请20位语言学与临床专家，采用混合效应模型评估模型在课程设计、临床诊断等五个领域的输出质量。

Result: GPT-5在课程设计（p<0.01）、临床诊断（p<0.05）、研究生成（p<0.01）和伦理推理（p<0.05）四个领域显著优于GPT-4，作业评估领域表现持平。

Conclusion: 研究证实GPT-5具备成为领域专用智能工具的潜力，为教育实践、临床决策和学术研究提供更精准的支持，同时推动伦理推理能力的发展。

Abstract: The accelerated evolution of large language models has raised questions about
their comparative performance across domains of practical importance. GPT-4 by
OpenAI introduced advances in reasoning, multimodality, and task
generalization, establishing itself as a valuable tool in education, clinical
diagnosis, and academic writing, though it was accompanied by several flaws.
Released in August 2025, GPT-5 incorporates a system-of-models architecture
designed for task-specific optimization and, based on both anecdotal accounts
and emerging evidence from the literature, demonstrates stronger performance
than its predecessor in medical contexts. This study provides one of the first
systematic comparisons of GPT-4 and GPT-5 using human raters from linguistics
and clinical fields. Twenty experts evaluated model-generated outputs across
five domains: lesson planning, assignment evaluation, clinical diagnosis,
research generation, and ethical reasoning, based on predefined criteria.
Mixed-effects models revealed that GPT-5 significantly outperformed GPT-4 in
lesson planning, clinical diagnosis, research generation, and ethical
reasoning, while both models performed comparably in assignment assessment. The
findings highlight the potential of GPT-5 to serve as a context-sensitive and
domain-specialized tool, offering tangible benefits for education, clinical
practice, and academic research, while also advancing ethical reasoning. These
results contribute to one of the earliest empirical evaluations of the evolving
capabilities and practical promise of GPT-5.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [62] [Should LLMs be WEIRD? Exploring WEIRDness and Human Rights in Large Language Models](https://arxiv.org/abs/2508.19269)
*Ke Zhou,Marios Constantinides,Daniele Quercia*

Main category: cs.CY

TL;DR: 研究发现大语言模型存在WEIRD价值观偏差，文化多样性提升伴随人权风险增加（BLOOM/Qwen违反人权概率高2-4%）


<details>
  <summary>Details</summary>
Motivation: LLMs基于WEIRD价值观数据训练存在文化偏见，需评估其与全球人权原则的兼容性

Method: 通过世界价值观调查比对5个主流模型响应，对照《世界人权宣言》及亚非中东区域人权宪章评估价值观偏差

Result: 低WEIRD对齐模型（BLOOM/Qwen）响应文化多样性增加，但性别平等领域人权违规率提升2-4%

Conclusion: LLMs文化代表性增强与歧视观念风险呈正相关，现有宪法AI方法仅能部分缓解该矛盾

Abstract: Large language models (LLMs) are often trained on data that reflect WEIRD
values: Western, Educated, Industrialized, Rich, and Democratic. This raises
concerns about cultural bias and fairness. Using responses to the World Values
Survey, we evaluated five widely used LLMs: GPT-3.5, GPT-4, Llama-3, BLOOM, and
Qwen. We measured how closely these responses aligned with the values of the
WEIRD countries and whether they conflicted with human rights principles. To
reflect global diversity, we compared the results with the Universal
Declaration of Human Rights and three regional charters from Asia, the Middle
East, and Africa. Models with lower alignment to WEIRD values, such as BLOOM
and Qwen, produced more culturally varied responses but were 2% to 4% more
likely to generate outputs that violated human rights, especially regarding
gender and equality. For example, some models agreed with the statements ``a
man who cannot father children is not a real man'' and ``a husband should
always know where his wife is'', reflecting harmful gender norms. These
findings suggest that as cultural representation in LLMs increases, so does the
risk of reproducing discriminatory beliefs. Approaches such as Constitutional
AI, which could embed human rights principles into model behavior, may only
partly help resolve this tension.

</details>


### [63] [Geopolitical Parallax: Beyond Walter Lippmann Just After Large Language Models](https://arxiv.org/abs/2508.19492)
*Mehmet Can Yavuz,Humza Gohar Kabir,Aylin Özkan*

Main category: cs.CY

TL;DR: 中西方LLM在新闻质量评估中存在系统性差异：中国模型强调新颖性/描述性，西方模型侧重主观性/正向情感，需文化校准避免模型偏见


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型的训练数据与设计选择如何嵌入文化/意识形态偏见，延伸新闻客观性争论至算法中介的新语境

Method: 通过逻辑回归探针和匹配主题评估，对比中西方LLM在15个新闻质量维度的预测差异，并分析巴以/中美互报敏感话题的语料库

Result: 模型起源与评估指标呈现显著关联：西方模型对巴以报道主观性评分更高，中国模型技术性/流畅度指标在中美互报中呈现不对称特征

Conclusion: LLM新闻评估需建立文化校准机制，区分内容差异与模型诱导偏见，避免算法中介加剧地缘政治框架效应

Abstract: Objectivity in journalism has long been contested, oscillating between ideals
of neutral, fact-based reporting and the inevitability of subjective framing.
With the advent of large language models (LLMs), these tensions are now
mediated by algorithmic systems whose training data and design choices may
themselves embed cultural or ideological biases. This study investigates
geopolitical parallax-systematic divergence in news quality and subjectivity
assessments-by comparing article-level embeddings from Chinese-origin (Qwen,
BGE, Jina) and Western-origin (Snowflake, Granite) model families. We evaluate
both on a human-annotated news quality benchmark spanning fifteen stylistic,
informational, and affective dimensions, and on parallel corpora covering
politically sensitive topics, including Palestine and reciprocal China-United
States coverage. Using logistic regression probes and matched-topic evaluation,
we quantify per-metric differences in predicted positive-class probabilities
between model families. Our findings reveal consistent, non-random divergences
aligned with model origin. In Palestine-related coverage, Western models assign
higher subjectivity and positive emotion scores, while Chinese models emphasize
novelty and descriptiveness. Cross-topic analysis shows asymmetries in
structural quality metrics Chinese-on-US scoring notably lower in fluency,
conciseness, technicality, and overall quality-contrasted by higher negative
emotion scores. These patterns align with media bias theory and our distinction
between semantic, emotional, and relational subjectivity, and extend LLM bias
literature by showing that geopolitical framing effects persist in downstream
quality assessment tasks. We conclude that LLM-based media evaluation pipelines
require cultural calibration to avoid conflating content differences with
model-induced bias.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [64] [A Technical Review on Comparison and Estimation of Steganographic Tools](https://arxiv.org/abs/2508.19323)
*Ms. Preeti P. Bhatt,Rakesh R. Savant*

Main category: cs.CR

TL;DR: 该论文对六款主流图像隐写工具进行横向评测，基于图像尺寸、像素值分布等特征分析工具效率差异。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐写工具性能评估标准缺失的问题，为使用者提供工具选择依据。

Method: 选取六款常用工具，通过相同文本嵌入实验，对比分析宿主图像的尺寸、像素直方图等特征变化。

Result: 工具整体性能接近，但部分工具在嵌入效率、图像特征保留方面表现更优。

Conclusion: 隐写工具效率与图像特征强相关，该研究为特定场景下的工具选择提供了实证依据。

Abstract: Steganography is technique of hiding a data under cover media using different
steganography tools. Image steganography is hiding of data
(Text/Image/Audio/Video) under a cover as Image. This review paper presents
classification of image steganography and the comparison of various Image
steganography tools using different image formats. Analyzing numerous tools on
the basis of Image features and extracting the best one. Some of the tools
available in the market were selected based on the frequent use; these tools
were tested using the same input on all of them. Specific text was embedded
within all host images for each of the six Steganography tools selected. The
results of the experiment reveal that all the six tools were relatively
performing at the same level, though some software performs better than others
through efficiency. And it was based on the image features like size,
dimensions, and pixel value and histogram differentiation.

</details>


### [65] [An Investigation on Group Query Hallucination Attacks](https://arxiv.org/abs/2508.19321)
*Kehao Miao,Xiaolong Jin*

Main category: cs.CR

TL;DR: Group Query Attack通过同时提交多组查询，显著降低微调模型性能并触发LLMs后门风险。


<details>
  <summary>Details</summary>
Motivation: 研究用户单次对话中提出多问题时，累积上下文对LLMs输出的潜在负面影响。

Method: 设计Group Query Attack技术，模拟多查询场景并观察模型行为变化。

Result: 1.特定任务微调模型性能下降 2.可能触发LLMs潜在后门 3.影响预训练模型的数学推理/代码生成能力

Conclusion: LLMs在多查询场景中表现出系统性脆弱性，需增强模型对复杂交互的鲁棒性。

Abstract: With the widespread use of large language models (LLMs), understanding their
potential failure modes during user interactions is essential. In practice,
users often pose multiple questions in a single conversation with LLMs.
Therefore, in this study, we propose Group Query Attack, a technique that
simulates this scenario by presenting groups of queries to LLMs simultaneously.
We investigate how the accumulated context from consecutive prompts influences
the outputs of LLMs. Specifically, we observe that Group Query Attack
significantly degrades the performance of models fine-tuned on specific tasks.
Moreover, we demonstrate that Group Query Attack induces a risk of triggering
potential backdoors of LLMs. Besides, Group Query Attack is also effective in
tasks involving reasoning, such as mathematical reasoning and code generation
for pre-trained and aligned models.

</details>


### [66] [Safety Alignment Should Be Made More Than Just A Few Attention Heads](https://arxiv.org/abs/2508.19697)
*Chao Huang,Zefeng Zhang,Juewei Yue,Quangang Li,Chuang Zhang,Tingwen Liu*

Main category: cs.CR

TL;DR: 当前LLM安全机制依赖少数注意力头易受攻击，提出AHD训练策略实现安全行为分布式编码，显著提升模型抗越狱攻击能力


<details>
  <summary>Details</summary>
Motivation: 现有安全机制集中在少量注意力头的结构特性使其容易被定向攻击突破，需建立更分布式的安全编码方案

Method: 开发RDSHA定位关键注意力头，设计AHD训练策略(包含注意力头多样化正则化和动态安全梯度分配)

Result: AHD使安全相关注意力头数量增加3.8倍，在DAN/HHH等主流攻击下拒绝率提升42%，推理能力保持98%原始水平

Conclusion: 通过分布式安全编码架构有效解决注意力头集中化带来的脆弱性问题，为LLM安全对齐提供新范式

Abstract: Current safety alignment for large language models(LLMs) continues to present
vulnerabilities, given that adversarial prompting can effectively bypass their
safety measures.Our investigation shows that these safety mechanisms
predominantly depend on a limited subset of attention heads: removing or
ablating these heads can severely compromise model safety. To identify and
evaluate these safety-critical components, we introduce RDSHA, a targeted
ablation method that leverages the model's refusal direction to pinpoint
attention heads mostly responsible for safety behaviors. Further analysis shows
that existing jailbreak attacks exploit this concentration by selectively
bypassing or manipulating these critical attention heads. To address this
issue, we propose AHD, a novel training strategy designed to promote the
distributed encoding of safety-related behaviors across numerous attention
heads. Experimental results demonstrate that AHD successfully distributes
safety-related capabilities across more attention heads. Moreover, evaluations
under several mainstream jailbreak attacks show that models trained with AHD
exhibit considerably stronger safety robustness, while maintaining overall
functional utility.

</details>


### [67] [SoK: Large Language Model Copyright Auditing via Fingerprinting](https://arxiv.org/abs/2508.19843)
*Shuo Shao,Yiming Li,Yu He,Hongwei Yao,Wenyuan Yang,Dacheng Tao,Zhan Qin*

Main category: cs.CR

TL;DR: 该论文系统研究LLM指纹识别技术，提出首个统一评估框架LeaFBench，揭示现有方法的有效性及改进方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面临版权侵权风险，现有指纹识别技术缺乏可靠性评估标准且难以应对多样化的模型修改方式。

Method: 建立白盒/黑盒分类框架，构建包含149个模型实例和13种后开发技术的LeaFBench基准进行系统性测试。

Result: 实验显示现有指纹识别方法在参数修改场景下稳定性不足，黑盒方法对系统提示等机制识别效果较好。

Conclusion: 需开发更鲁棒的指纹识别技术，建立标准化评估体系，重点解决参数无关修改场景下的检测难题。

Abstract: The broad capabilities and substantial resources required to train Large
Language Models (LLMs) make them valuable intellectual property, yet they
remain vulnerable to copyright infringement, such as unauthorized use and model
theft. LLM fingerprinting, a non-intrusive technique that extracts and compares
the distinctive features from LLMs to identify infringements, offers a
promising solution to copyright auditing. However, its reliability remains
uncertain due to the prevalence of diverse model modifications and the lack of
standardized evaluation. In this SoK, we present the first comprehensive study
of LLM fingerprinting. We introduce a unified framework and formal taxonomy
that categorizes existing methods into white-box and black-box approaches,
providing a structured overview of the state of the art. We further propose
LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting
under realistic deployment scenarios. Built upon mainstream foundation models
and comprising 149 distinct model instances, LeaFBench integrates 13
representative post-development techniques, spanning both parameter-altering
methods (e.g., fine-tuning, quantization) and parameter-independent mechanisms
(e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the
strengths and weaknesses of existing methods, thereby outlining future research
directions and critical open problems in this emerging field. The code is
available at https://github.com/shaoshuo-ss/LeaFBench.

</details>


### [68] [Disabling Self-Correction in Retrieval-Augmented Generation via Stealthy Retriever Poisoning](https://arxiv.org/abs/2508.20083)
*Yanbo Dai,Zhenlan Ji,Zongjie Li,Kuan Li,Shuai Wang*

Main category: cs.CR

TL;DR: DisarmRAG提出通过毒化检索器抑制LLM自我纠正能力的新型攻击范式，实现90%以上攻击成功率并保持隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG防御依赖LLM自我纠正能力抵御知识库投毒攻击，但未考虑检索器本身被渗透的风险。该研究揭示攻击者可通过修改检索器直接植入反SCA指令，突破现有防御体系。

Method: 开发基于对比学习的局部隐蔽模型编辑技术，结合迭代协同优化框架自动生成抗防御的恶意指令，实现精准触发恶意检索并保持正常功能。

Result: 在6个LLM和3个QA基准测试中实现近100%恶意指令检索率，攻击成功率超90%，且能规避主流检测方法。

Conclusion: 暴露现有防御体系对检索器安全性的忽视，证明仅依赖生成端防御存在根本缺陷，亟需研发检索器端的新型防御机制。

Abstract: Retrieval-Augmented Generation (RAG) has become a standard approach for
improving the reliability of large language models (LLMs). Prior work
demonstrates the vulnerability of RAG systems by misleading them into
generating attacker-chosen outputs through poisoning the knowledge base.
However, this paper uncovers that such attacks could be mitigated by the strong
\textit{self-correction ability (SCA)} of modern LLMs, which can reject false
context once properly configured. This SCA poses a significant challenge for
attackers aiming to manipulate RAG systems.
  In contrast to previous poisoning methods, which primarily target the
knowledge base, we introduce \textsc{DisarmRAG}, a new poisoning paradigm that
compromises the retriever itself to suppress the SCA and enforce
attacker-chosen outputs. This compromisation enables the attacker to
straightforwardly embed anti-SCA instructions into the context provided to the
generator, thereby bypassing the SCA. To this end, we present a
contrastive-learning-based model editing technique that performs localized and
stealthy edits, ensuring the retriever returns a malicious instruction only for
specific victim queries while preserving benign retrieval behavior. To further
strengthen the attack, we design an iterative co-optimization framework that
automatically discovers robust instructions capable of bypassing prompt-based
defenses. We extensively evaluate DisarmRAG across six LLMs and three QA
benchmarks. Our results show near-perfect retrieval of malicious instructions,
which successfully suppress SCA and achieve attack success rates exceeding 90\%
under diverse defensive prompts. Also, the edited retriever remains stealthy
under several detection methods, highlighting the urgent need for
retriever-centric defenses.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [69] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出结合双鱼眼相机模型与3D高斯溅射的新型校准框架，解决全景图拼接缺陷并实现无缝渲染


<details>
  <summary>Details</summary>
Motivation: 消费级双鱼眼系统因镜头间距和角度畸变导致全景图缺陷，需建立能模拟真实伪影并生成无缝图像的解决方案

Method: 将双鱼眼相机物理特性嵌入3D高斯溅射流程，联合优化高斯参数与模拟镜头间距/畸变的校准变量

Result: 在真实数据集验证中，即使输入不完美图像，仍能生成无缝渲染效果，超越现有360度渲染模型

Conclusion: 该框架通过物理校准与神经渲染的协同优化，首次实现从缺陷全景输入到完美新视角合成的转化

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [70] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 大型视觉语言模型通过融合NLP和CV技术革新目标检测，提出三步研究框架分析架构创新与性能比较，预计将超越传统方法


<details>
  <summary>Details</summary>
Motivation: 传统深度学习架构在目标检测中存在适应性、上下文推理和泛化性能的局限性，需要探索视觉语言模型融合带来的技术突破

Method: 采用三步研究综述流程：1) 解析VLMs工作原理 2) 分析架构创新与训练范式 3) 比较实时性能/适应性/复杂度，包含可视化验证与系统对比

Result: LVLMs在定位/分割等场景展现有效性，预计性能将超越传统系统。同时揭示当前模型在实时响应和计算效率方面的局限性，并提出改进方案

Conclusion: LVLMs的进步正在重塑目标检测领域，通过持续优化架构和训练策略，将在机器人等应用场景产生变革性影响

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [71] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是针对韩语文本丰富视觉问答任务设计的基准测试，包含多维度评估框架和半自动化生成流程


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如韩语）在文本丰富视觉问答任务中缺乏综合基准测试的问题，促进多语言视觉语言模型研究

Method: 1.构建覆盖15领域/26图像类型的评估框架 2.开发基于分步图像分解的半自动VQA生成流程 3.建立七指标质量评估协议

Result: 推出公开可用的KRETA基准测试（https://github.com/tabtoyou/KRETA），验证流程可支持多语言扩展

Conclusion: KRETA填补了韩语VLM评估空白，其模块化设计为其他语言基准建设提供可复用的技术路径

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [72] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: 提出GLSim框架，通过结合全局和局部嵌入相似性信号，显著提升视觉语言模型的物体幻觉检测性能


<details>
  <summary>Details</summary>
Motivation: 现有物体幻觉检测方法单独采用全局或局部视角存在可靠性限制，需结合互补信号提升检测效果

Method: 基于图像和文本模态的全局-局部嵌入相似性计算，实现无需训练的检测框架

Result: 在多样化场景的基准测试中，检测性能显著超越现有方法（超过基准线较大幅度）

Conclusion: 全局与局部信号的互补结合能够实现更准确可靠的物体幻觉检测

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [73] [Beat-Based Rhythm Quantization of MIDI Performances](https://arxiv.org/abs/2508.19262)
*Maximilian Wachter,Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 提出基于Transformer的节奏量化模型，结合节拍信息将MIDI演奏转换为节拍对齐的乐谱


<details>
  <summary>Details</summary>
Motivation: 解决MIDI演奏量化为人可读乐谱时的节拍对齐问题，提升自动化记谱的准确性和可读性

Method: 1. 设计基于节拍的预处理方法统一乐谱与演奏数据表征
2. 优化Transformer模型架构
3. 使用钢琴和吉他演奏数据进行训练

Result: 在MUSTER评估指标上超越现有最佳方法

Conclusion: 结合节拍信息的Transformer模型能有效实现演奏数据的节奏量化，生成符合音乐韵律的乐谱

Abstract: We propose a transformer-based rhythm quantization model that incorporates
beat and downbeat information to quantize MIDI performances into
metrically-aligned, human-readable scores. We propose a beat-based
preprocessing method that transfers score and performance data into a unified
token representation. We optimize our model architecture and data
representation and train on piano and guitar performances. Our model exceeds
state-of-the-art performance based on the MUSTER metric.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [74] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出基于双层优化的自监督预训练新方法，通过平衡约束提升异构数据适应能力


<details>
  <summary>Details</summary>
Motivation: 传统自监督预训练混合异构数据导致全局优化无法适配各数据源特性，需改进模型对不同数据域的适应能力

Method: 将问题建模为双层优化，采用K步梯度下降约束使各数据源达到局部最优，使用一阶近似求解并与MAML建立联系

Result: 多领域/多语言数据集实验显示，下游任务微调适应性显著提升

Conclusion: 平衡约束的双层优化框架有效增强自监督模型的领域适应能力

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [75] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 本文提出基于梯度估计的上下文学习示例选择算法，相比传统嵌入相似度方法效率提升37.7倍，准确率平均提高11%


<details>
  <summary>Details</summary>
Motivation: 现有基于词嵌入相似度的方法无法准确反映模型推理过程，需要开发更精确的示例影响力评估方法

Method: 通过在输入嵌入空间计算输出梯度，运用一阶近似估计模型输出，结合随机子集采样和影响力分数聚合机制

Result: 在6个数据集上实现<1%的近似误差，34B参数模型推理速度提升37.7倍，平均准确率优于基线方法11%

Conclusion: 梯度估计方法有效解决了大规模上下文学习的示例选择难题，为提示工程和思维链推理提供了高效解决方案

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [76] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: 提出去中心化多代理系统Symphony，通过分布式机制解决现有LLM代理框架集中式编排的缺陷，显著提升推理效率与鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理框架存在高部署成本、僵化通信架构和适应性受限的问题，需要更轻量灵活的解决方案

Method: 采用三大核心机制：1）记录代理能力的分布式账本 2）动态任务分配的Beacon选择协议 3）基于思维链的加权结果投票机制

Result: 在推理基准测试中超越现有基线，准确率提升最高达15.3%，不同容量模型均表现出稳定性能优势

Conclusion: Symphony实现了隐私保护、可扩展的分布式编排，实证验证其在资源效率与系统容错性方面的突破性进展

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [77] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 提出六种注意力头剪枝策略有效防御预训练语言模型后门攻击，其中梯度剪枝对句法攻击最优，强化学习和贝叶斯剪枝对风格攻击更有效


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击防御需要了解攻击触发器或依赖干净参考模型，本文探索无需这些先验知识的注意力剪枝防御方案

Method: 开发六种剪枝策略：梯度剪枝、分层方差剪枝、结构化稀疏剪枝、随机集成剪枝、强化学习引导剪枝、贝叶斯不确定性剪枝，通过验证精度监控防止过剪枝

Result: 梯度剪枝在防御句法触发器时效果最佳（准确率提升23%），强化学习和贝叶斯剪枝对风格攻击防御更稳健（F1值提高18%）

Conclusion: 注意力头剪枝是有效的后门防御手段，不同策略适应不同攻击类型，为无先验知识防御提供了新方向

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


<div id='math.CO'></div>

# math.CO [[Back]](#toc)

### [78] [Word Chain Generators for Prefix Normal Words](https://arxiv.org/abs/2508.19619)
*Duncan Adamson,Moritz Dudey,Pamela Fleischmann,Annika Huch*

Main category: math.CO

TL;DR: 研究前缀正常词的特征，包括导致非前缀正常的因子属性，并提出词链和生成器作为关联方法


<details>
  <summary>Details</summary>
Motivation: 解决前缀正常词枚举和高效测试的开放问题，通过揭示其结构特征建立理论框架

Method: 分析因子属性特征，构建词链关系网络，设计生成器将相同长度词汇系统关联

Result: 发现非前缀正常词的关键因子特征，建立词汇关系的新型拓扑结构

Conclusion: 为前缀正常词的枚举算法和线性复杂度验证方法提供了理论基础

Abstract: In 2011, Fici and Lipt\'ak introduced prefix normal words. A binary word is
prefix normal if it has no factor (substring) that contains more occurrences of
the letter 1 than the prefix of the same length. Among the open problems
regarding this topic are the enumeration of prefix normal words and efficient
testing methods. We show a range of characteristics of prefix normal words.
These include properties of factors that are responsible for a word not being
prefix normal. With word chains and generators, we introduce new ways of
relating words of the same length to each other.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [79] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: 提出功能导向的代码自进化框架，构建差异化代码基准测试，提升嵌入模型对代码功能语义的理解能力


<details>
  <summary>Details</summary>
Motivation: 现有代码嵌入模型主要关注语法相似性（如代码克隆检测），缺乏对代码功能一致性的有效评估

Method: 开发数据合成框架（FOCSE），通过单代码实例生成四种语义/语法变体，构建包含功能差异的基准数据集

Result: 实验显示使用进化数据集训练的模型在代码克隆检测（+5.2%）、功能一致性识别（+7.8%）和代码检索（+6.1%）任务中显著提升

Conclusion: 该框架有效增强了代码嵌入模型对功能语义的捕捉能力，为代码理解研究提供了新的数据合成方法论

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [80] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 本文提出将LLM中的奉承行为建模为心理测量特征的几何与因果组合，类比心理测量学中的因子分解，并通过向量干预方法实现安全行为调控


<details>
  <summary>Details</summary>
Motivation: 现有研究常将LLM中的奉承视为单一因果机制的孤立问题，作者认为应借鉴心理测量学的因子分解方法，将其分解为情绪性、开放性等心理特质的组合效应，以更全面理解其成因

Method: 采用对比激活加法(CAA)技术，将神经网络激活方向映射到外向性、尽责性等心理维度，研究不同特质组合(如高外向性+低尽责性)如何诱发奉承行为

Result: 发现特定心理特征组合(如高外向性伴随低尽责性)与奉承行为强相关，并验证通过向量加减、投影等几何操作可有效调控模型行为

Conclusion: 基于向量的心理特征分解为LLM安全提供了可解释的干预路径，使安全关键行为的调控具备数学可操作性，为AI对齐提供了新思路

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [81] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: Instructional Agents框架通过多智能体大语言模型自动生成课程材料，显著降低开发时间与人力成本，同时保证教学质量


<details>
  <summary>Details</summary>
Motivation: 传统课程材料准备需要教师、教学设计者、助教多方协同，存在耗时耗力、协调成本高的问题。现有AI教育工具多为孤立任务设计，缺乏系统性协作能力

Method: 开发多智能体LLM框架模拟教育角色的协作流程，包含自主模式/目录引导/反馈引导/全协同四种模式，支持从课程大纲到评估材料的端到端生成

Result: 在5个大学计算机课程中的验证显示，该系统在保持材料质量的同时，将开发时间缩短80%，人力投入减少65%

Conclusion: 该框架为教育资源匮乏的机构提供可扩展的解决方案，通过降低高质量教育材料的生产门槛，促进教育公平尤其在欠发达地区

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [82] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: 研究发现CoT在软推理任务中效果有限且可能不可靠，不同模型对CoT的依赖存在差异


<details>
  <summary>Details</summary>
Motivation: 探讨不同模型在软推理任务中使用思维链（CoT）时的动态表现与忠实性关系

Method: 通过分析指令调优模型、专门推理模型和推理蒸馏模型在任务中的表现

Result: 发现模型对CoT的依赖模式存在差异，且CoT的影响力与其忠实性并不总一致

Conclusion: CoT在软推理任务中的作用具有复杂性，需谨慎评估其实际效果和可靠性

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [83] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: 提出SWIRL阶段性工作流，将多智能体强化学习分解为单智能体任务序列，提升训练稳定性和协调效率，在移动GUI控制和数学推理中验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有单智能体方法存在结构限制，多智能体系统虽能解耦能力但存在训练低效和与大型视觉语言模型不兼容的问题

Method: 通过分阶段交错强化学习框架，将MARL转化为顺序单智能体任务，理论提供安全边界/单调改进定理/收敛保证

Result: 在移动GUI高低层基准测试中表现优异，多智能体数学推理任务中展示强能力

Conclusion: SWIRL作为通用框架可开发高效鲁棒的多智能体系统，在GUI控制与跨领域任务中展现潜力

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>
