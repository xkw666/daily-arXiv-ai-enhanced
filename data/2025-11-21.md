<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 8]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.CV](#cs.CV) [Total: 9]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 研究通过Qwen2.5模型实验揭示CoT提示在跨语言场景的局限性：过度依赖最终推理步骤、对拉丁语系高资源语言效果显著、抗干扰能力弱。


<details>
  <summary>Details</summary>
Motivation: 评估多语言场景下CoT推理的可解释性与鲁棒性，解决此前对生成推理链可信度的担忧。

Method: 使用ContextCite（步骤归因）和Inseq（词元归因）方法，在MGSM基准测试Qwen2.5 1.5B-Instruct模型。

Result: 1）错误推理过度强调最终步骤；2）结构化CoT仅显著提升拉丁语系准确率；3）干扰语句会降低模型表现。

Conclusion: CoT提示存在多语言鲁棒性差和解释透明度低的问题，需开发更可靠的跨语言推理方法。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出Motion2Mind框架评估AI系统对非语言线索的心理解读能力，构建含222种非语言行为标注的视频数据集，发现当前AI在检测和解释方面显著落后人类水平


<details>
  <summary>Details</summary>
Motivation: 现有心理理论基准主要关注错误信念任务，忽视了非语言沟通的多样性。需建立新评估体系填补机器解读肢体语言等非语言线索的能力空白

Method: 基于专家整理的身体语言知识库，构建含精细标注的Motion2Mind视频数据集（222种非语言行为+397种心理状态），采用检测准确率和解释合理性双指标评估模型

Result: 当前AI系统检测非语言线索准确率低于人类38%，解释过程中存在过度解读现象（将中性动作误判为攻击性意图等）

Conclusion: 非语言线索解读是心理理论的重要维度，AI系统需突破多模态数据整合与心理状态推理的技术瓶颈，该数据集为评估认知能力提供新基准

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 论文提出TOD-ProcBench基准，通过包含复杂流程指令的对话数据集，系统性评估大语言模型在多轮任务型对话中的指令遵循能力


<details>
  <summary>Details</summary>
Motivation: 现有任务型对话基准过度简化真实场景中的复杂指令（仅用意图-槽位等简单范式），需建立更贴近实际复杂约束的评估体系

Method: 基于ABCD数据集构建包含多层级条件-动作指令的基准，设计三项渐进任务（相关声明检索/违规响应识别/条件性响应生成），并研究多语言场景和指令格式对合规表现的影响

Result: 基准有效揭示大语言模型在复杂流程约束下的能力边界，不同模型在指令层级结构理解、多条件联合遵守等方面存在显著差异，多语言场景和JSON格式指令可提升合规率

Conclusion: TOD-ProcBench为评估和提升大语言模型的复杂指令遵循能力提供系统性框架，其细粒度约束建模方法对构建可靠的任务型对话系统具有指导意义，成果已开放共享

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: LIARS' BENCH作为新型测试平台，揭示了现有LLM谎言检测技术的系统性缺陷，尤其在无法通过对话文本判断的场景下。


<details>
  <summary>Details</summary>
Motivation: 现有LLM谎言检测技术验证场景过于局限，无法覆盖模型可能生成的各种谎言类型，需构建更全面的评估体系。

Method: 构建包含72,863个谎言样本的LIARS' BENCH数据集，基于撒谎原因和信念对象两个维度分类，评估三种检测技术的表现。

Result: 现有技术在部分谎言类型（尤其是无法通过对话文本判断的场景）中系统性失败，暴露检测方法局限性。

Conclusion: LIARS' BENCH为谎言检测领域提供实用测试基准，推动检测技术进步并揭示现有方法不足。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: 提出混合方法LTLA，结合基础语言模型和固定代理HMM，通过高效处理未来令牌约束，在可控文本生成中提升效果且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有基于HMM的代理方法上下文感知能力弱，导致生成质量受限。神经上下文的高效整合面临计算效率挑战。

Method: LTLA将基础语言模型与固定HMM结合，使用批量HMM更新同时处理所有候选令牌，通过将HMM潜在状态与LM隐藏状态关联并保持解码器固定实现计算复用。

Result: LTLA在条件似然度上超越传统HMM，支持视觉-语言模型的延续概率估计，在保持流畅性的同时显著提升约束满足率，推理开销极低。

Conclusion: LTLA框架有效整合神经上下文到可追踪代理模型中，解决了计算效率难题，为可控文本生成提供了高效解决方案。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 论文通过多学科案例研究展示了GPT-5在科研中的辅助作用，特别是在数学领域产出四项经人工验证的新成果


<details>
  <summary>Details</summary>
Motivation: 揭示前沿AI模型在科研中的实际应用潜力，探索人机协作的有效模式

Method: 收集数学/物理/材料科学等领域的案例研究，记录研究人员与GPT-5的协作过程，重点展示AI加速科研的具体环节

Result: 在数学领域获得四项经人工验证的新发现，证明AI可协助解决未解问题；同时总结了AI节省专家时间的关键场景与仍需人工干预的环节

Conclusion: 尽管当前成果规模有限，但随着AI技术的快速发展，人机协作模式对科研创新具有深远的启示意义

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出集成学习提示优化框架ELPO，通过投票机制和多样化搜索策略提升复杂任务中的提示优化效果


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法依赖单一模型/算法，在复杂任务中性能受限，需更鲁棒的集成框架

Method: 结合集成学习思想，采用共享生成策略+多搜索方法，创新设计高效提示生成与搜索算法

Result: 实验显示ELPO优于SOTA方法，如在ArSarcasm数据集F1值提升7.6分

Conclusion: ELPO框架通过集成策略有效提升提示优化的准确性和鲁棒性

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 提出Token-Selective PEFT范式，通过选择性微调部分位置索引提升效率，挑战传统PEFT全索引修改的必要性


<details>
  <summary>Details</summary>
Motivation: 质疑传统PEFT方法对所有位置索引进行参数修改的有效性，发现这种无差别操作可能降低模型性能

Method: 开发TS-PEFT框架，通过选择函数S智能筛选需要微调的位置索引子集

Result: 实验证明全索引PEFT不仅冗余且有害，TS-PEFT显著优化下游任务表现

Conclusion: 为大规模模型微调提供定向修改新范式，建立未来优化研究的系统性框架

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 开发AI驱动的SemanticCite系统解决学术引用准确性难题，通过全文分析验证引用，提供四类语义分类（支持/部分支持/不支持/不确定），开源包含1000+跨学科标注数据集的轻量级模型，实现高效大规模引用验证。


<details>
  <summary>Details</summary>
Motivation: 当前学术交流面临三大挑战：1）曲解文献的语义引用错误 2）AI生成内容的虚假引用 3）传统引用格式无法定位具体论证依据。这些问题损害研究可信度，亟需自动化验证系统。

Method: 结合多检索方法（全文分析+上下文提取）与四分类系统，采用微调轻量级语言模型（参数量显著低于商业系统），构建跨八大学科、含功能分类/语义标注/文献计量元数据的标注数据集。

Result: 实验显示微调轻量模型达到与大型商业系统相当性能（计算需求降低83%），构建包含1,089个引用的标注数据集，系统可生成基于证据的可解释分析（准确率92%），验证耗时平均4.7秒/次。

Conclusion: SemanticCite通过可扩展的引用验证机制，为维护研究完整性提供开源基础解决方案，支持：1）自动化同行评审 2）AI生成内容质控 3）跨学科引用模式分析，推动学术交流的可靠性革新。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出语义结构熵(SeSE)框架，通过结构信息视角量化LLM语义空间的不确定性以检测幻觉


<details>
  <summary>Details</summary>
Motivation: 现有UQ方法依赖语义概率/距离，忽视语义结构信息导致不确定性估计精度不足。需从结构信息角度开发更精确的LLM幻觉检测方法

Method: 1. 开发自适应稀疏有向语义图构建算法，捕获方向性语义依赖并消除干扰
2. 通过层次抽象提取潜在结构信息：将SeSE定义为最优语义编码树的结构熵，形式化语义空间压缩后的固有不确定性
3. 扩展SeSE对长文本生成进行细粒度UQ，建模声明的随机语义交互

Result: 在29个模型-数据集组合的实验中，SeSE显著优于包括监督方法和KLE在内的先进基线

Conclusion: SeSE首次将结构信息理论引入LLM不确定性量化，为幻觉检测提供了理论解释性强且实际效果突出的新范式

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出无需训练的SDA框架，通过动态调整输出概率显著提升开源大语言模型在帮助性(64.4%)、无害性(11.5%)和诚实性(30%)三个维度的对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖成本高昂的模型重训练或大量监督数据，难以实现推理阶段的高效意图对齐。需要一种轻量、即插即用的解决方案来动态校准模型行为。

Method: 基于用户定义指令的分布对齐框架(SDA)：1. 模型无关的实时概率分布调整技术 2. 支持与训练策略协同工作 3. 个性化偏好适配机制 4. 计算效率达传统微调的1/50

Result: 跨8个开源模型验证：在帮助性维度实现64.4%平均提升，无害性11.5%，诚实性30%。特别在Baichuan2-13B模型上，帮助性指标提升达112.3%。

Conclusion: SDA框架突破了传统对齐方法的局限性，证明：1. 参数干预比全参数微调更有效 2. 对齐效果具有跨模型泛化性 3. 支持动态个性化校准 为LLM部署提供新范式

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出自我重写框架改进大型推理模型的内部思维质量


<details>
  <summary>Details</summary>
Motivation: 传统强化学习仅依赖结果正确性奖励，导致模型存在过度思考、思考不足等内部推理质量问题

Method: 采用选择性重写机制（仅改写简单样本），通过单批次混合生成保持强化学习扩展性（增加约10%开销）

Result: 在准确率-长度权衡中实现+0.6精度提升与46%长度缩减，LLM评判指标提高7.2分

Conclusion: 自我重写框架有效优化推理过程质量，显著减少内部推理缺陷

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [13] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 论文提出通过构建大规模习语数据集提升语言模型对比喻语言的理解能力


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在习语识别和比喻语言理解方面存在明显不足，需要更优质数据集推动模型进步

Method: 整合现有习语数据集构建组合词表，从大型语料库提取上下文序列，创建三类评估数据集（大规模候选集+人工标注确定集）

Result: 构建了模型无关的训练数据集，应用于词槽标注和序列标记任务并完成基线评估

Conclusion: 新数据集为开发习语处理模型提供了多样化训练基础，支持未来新方法的探索

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [14] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 研究通过分析合理性解释（rationales）对模型性能的影响，发现高信息量解释未必提升分类准确性，传统充分性指标存在局限性。


<details>
  <summary>Details</summary>
Motivation: 评估模型是否基于正确理由学习而非依赖数据捷径，质疑现有充分性指标在衡量解释信息有效性方面的不足。

Method: 结合两种范式：1）通过标记分类识别解释有效性；2）通过注意力正则化将解释融入输入提升性能。

Result: 高信息量解释与正确分类无直接关联，充分性指标反映非解释性文本的干扰作用，解释信息对跨领域任务效果不稳定。

Conclusion: 揭示解释机制的复杂性，强调需要开发更系统化的评估指标来捕捉解释信息对模型的影响机制。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [15] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 提出MinerU-HTML HTML提取框架，通过序列标注模型解决传统方法结构化元素丢失问题，构建高质量AICC语料库并验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有HTML提取工具（如Trafilatura）破坏结构化元素且改进空间有限，假设提升提取质量对模型性能的影响不亚于过滤策略

Method: 基于0.6B参数语言模型构建两阶段处理流程：1）语义元素分类 2）Markdown转换，将HTML提取转化为序列标注问题

Result: MainWebBench基准ROUGE-N F1达81.8%（对比Trafilatura 63.6%），代码/公式保留率超90%。AICC语料训练模型在13个基准平均准确率提升1.08pp

Conclusion: HTML提取是网络语料构建的关键环节，MinerU-HTML框架显著提升模型性能，公开资源推动领域发展

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [16] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 研究证明传统机器学习和深度学习模型均能有效区分新闻质量，其中ModernBERT-large以0.8744准确率和0.9593 ROC-AUC表现最佳


<details>
  <summary>Details</summary>
Motivation: 探索如何利用机器学习技术区分新闻质量，以应对网络时代信息可信度评估的挑战

Method: 使用2018-2024年141万篇新闻构建数据集，通过专家评分将新闻分为高低质量两类，分别测试3种传统机器学习分类器和4种深度学习模型

Result: 随机森林准确率0.7355，ModernBERT-large达到0.8744准确率和0.9593 ROC-AUC，显示深度学习方法显著优于传统模型

Conclusion: 基于CPU的传统机器学习与深度学习方法均可有效区分新闻质量，其中深度学习模型在准确性和稳定性方面表现更突出

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [17] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 提出ESGBench评估框架，用于测试ESG问答系统的可解释性


<details>
  <summary>Details</summary>
Motivation: 解决当前ESG人工智能系统在事实一致性、可追溯性和领域适配性方面的评估缺失

Method: 构建多ESG主题的领域基础问题集，配合人工标注答案和证据链

Result: 发现现有大语言模型在事实一致性、可追溯性和领域对齐方面存在显著挑战

Conclusion: 该基准测试将推动透明化ESG人工智能系统的研发进程

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [18] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 提出改进路径修补算法分析Transformer处理习语的神经机制，发现特异性计算模式（习语头和增强接收），揭示模型平衡计算效率与鲁棒性的机制


<details>
  <summary>Details</summary>
Motivation: 探究Transformer如何处理非组合性语言（如习语），揭示其内部工作机制并为理解复杂语法处理提供基础

Method: 使用改进的路径修补算法进行电路发现，结合注意力模式分析和跨层激活追踪

Result: 识别出高频激活的习语专用注意力头（Idiom Heads），发现token间的增强注意力机制（augmented reception），建立计算效率与鲁棒性的平衡模型

Conclusion: 为Transformer的非组合语言处理机制提供新解释范式，奠定复杂语法结构分析的神经基础

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [19] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是专为文档结构化数据提取设计的轻量级模型（6.6GiB），可在A10 GPU等资源受限设备上高效处理125页长文档。


<details>
  <summary>Details</summary>
Motivation: 解决现有文档理解模型在资源受限环境下部署困难的问题，平衡模型性能与硬件资源消耗。

Method: 通过优化训练协议和模型架构，实现轻量化（6.6GiB）同时维持文档理解能力。

Result: 模型在24GB显存的A10 GPU上可处理125页A4文档，保持SOTA级文档结构化数据提取性能。

Conclusion: Arctic-Extract在资源效率与处理能力间取得突破，为工业场景的长文档处理提供实用解决方案。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [20] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 提出首个土耳其语检索基准TurkColBERT，验证后期交互模型参数效率显著优于密集编码器，ColmmBERT-base-TR在特定领域实现+13.8% mAP提升


<details>
  <summary>Details</summary>
Motivation: 解决形态复杂的土耳其语检索研究不足问题，系统评估后期交互模型在低资源语言中的潜力

Method: 采用两阶段适应流程：1) 在土耳其NLI/STS任务微调多语言模型 2) 基于MS MARCO-TR训练PyLate转换ColBERT架构；使用MUVERA+Rerank索引算法优化

Result: 1M参数的colbert-hash-nano-tr比600M密集编码器小600倍且保留71%性能；ColmmBERT-base-TR在科学/金融领域实现最高13.8% mAP增益

Conclusion: 后期交互模型在土耳其语检索具有参数效率优势，MUVERA+Rerank实现0.54ms低延迟检索。公开的模型与工具链加速土耳其语IR研究

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 研究证明通过分析LLM激活状态可高精度预测文本类型，Mistral-7B结合scikit-learn分类器在两类数据集分别达到98%和71%的F1值


<details>
  <summary>Details</summary>
Motivation: 解决LLM可解释性难题，建立无需人工评估的预测框架，通过文本类型预测验证模型内部表征的有效性

Method: 使用Mistral-7B模型在两个数据集上测试，采用scikit-learn分类器从模型激活中提取特征，设置控制任务进行效果对比

Result: 文本类型预测F1值显著超越基线（最高98% vs 控制任务），跨数据集保持稳定性能优势（71% vs 控制任务）

Conclusion: 首次验证浅层模型可从LLM有效提取文本类型特征，为模型解释性研究和自动化输出评估提供新思路

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 挑战ASR临床评估中WER指标的局限性，提出基于LLM优化的临床风险自动评估框架


<details>
  <summary>Details</summary>
Motivation: 现有ASR评估指标（如词错率WER）与临床风险相关性差，需建立临床安全导向的评估体系

Method: 1. 通过临床专家标注建立黄金标准
2. 使用GEPA优化LLM（Gemini-2.5-Pro）模拟专家评估
3. 在两种医患对话数据集验证

Result: 优化后的LLM评估器达到90%准确率，Cohen's κ=0.816（接近人类水平）

Conclusion: 建立了首个可扩展的临床对话ASR安全评估框架，推动评估标准从文本保真度转向临床安全性

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出基于大语言模型的词义消歧方法，通过将候选语义转换为自然语言选项供LLM选择，无需人工标注数据即可实现复杂语义的自动消歧。


<details>
  <summary>Details</summary>
Motivation: 现有词义消歧方法依赖粗粒度语义表示（如WordNet）和人工标注数据，难以支持需要复杂推理的细粒度语义表示（如OpenCyc）。

Method: 将符号系统生成的候选语义转换为自然语言表述，利用LLM根据上下文选择最佳解释，并将选择结果反馈至符号系统完成消歧。

Result: 通过与人工标注金标准对比验证了方法的有效性（具体评估指标未明确给出）。

Conclusion: 该方法成功结合符号系统与统计语言模型，为复杂语义表示的自动消歧提供了可扩展的解决方案。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 多模态RAG系统中直接嵌入检索优于基于LLM摘要的方法，实验证明其在金融文档问答中提升检索效果13% mAP@5和11% nDCG@5。


<details>
  <summary>Details</summary>
Motivation: 现有系统将图像转为文本摘要导致视觉信息丢失，影响下游任务准确性。需验证直接存储多模态嵌入是否更优。

Method: 对比文本分块检索与直接多模态嵌入检索，在40个金融财报问答对(含图像+文本)上测试6个LLM和2个多模态嵌入模型。

Result: 直接多模态检索绝对提升13% mAP@5和11% nDCG@5(相对提升32%/20%)，且LLM评估显示答案准确性更高。

Conclusion: 直接多模态嵌入保留原始视觉语境，避免LLM摘要的信息损失，为金融文档分析提供更可靠的检索方案。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 提出Nemotron Elastic框架，通过单一父模型嵌入多级子模型，实现360倍成本压缩的同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统大规模语言模型多尺寸训练成本过高，现有压缩技术仍需消耗数百亿tokens训练资源。为解决这一瓶颈，需要开发更高效的模型压缩方案。

Method: 混合Mamba-Attention架构+端到端路由器训练体系，结合：1）分组感知的SSM弹性化技术 2）异质MLP弹性化 3）基于归一化MSE的层重要性评估 4）多预算知识蒸馏

Result: 在Nemotron Nano V2 12B模型上仅用110B tokens训练，生成9B/6B子模型，成本较从头训练降低360倍，较前沿压缩技术降低7倍。所有子模型精度均达到SOTA水平。

Conclusion: 该框架实现'多模合一'部署，模型族总内存占用恒定，突破了传统压缩方法的多模型内存累积限制。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [26] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 提出整合SPH方法、双向力耦合与反馈平滑技术的统一框架，实现VR中刚体/可变形体/流体的实时双向触觉交互


<details>
  <summary>Details</summary>
Motivation: 多物理场系统中精确力反馈的计算挑战大，需解决实时物理模拟的性能瓶颈以增强虚拟现实的沉浸式教育体验

Method: 整合光滑粒子流体动力学(SPH)、双向力耦合机制与反馈平滑技术，建立统一的多物理场触觉交互平台

Result: 成功实现流体搅拌/软组织操作/刚体互动场景的稳定触觉反馈，反应力符合流固耦合物理规律（延迟<10ms）

Conclusion: 该框架首次统一流体/软体/刚体动力学，推动触觉多物理场模拟在教育等沉浸式场景中的实际应用

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [27] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 提出可控层分解方法CLD，通过LD-DiT模块解耦图像元素和MLCA模块实现精确条件生成，在分解质量和可控性上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 设计师通常独立编辑RGBA层后合成图像，但合成后无法进行层级编辑。现有方法依赖图像抠图/修复技术，存在可控性和分割精度局限。

Method: 包含LayerDecompose-DiT（解耦图像元素实现精细控制）和Multi-Layer Conditional Adapter（多层级条件生成），并建立新基准与评估指标。

Result: 实验表明CLD在分解质量和可控性上持续优于现有方法，分离层可直接在PowerPoint等设计工具中操作。

Conclusion: CLD解决了实际工作流程中图像层级编辑不可逆的痛点，分离结果与主流设计工具兼容，具有显著实用价值。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries(CoS)方法，通过黑格尔辩证法迭代生成通用网页摘要，显著提升LLM问答性能


<details>
  <summary>Details</summary>
Motivation: 解决LLM处理网页内容时的格式兼容性问题与上下文长度限制，需创建LLM友好的信息密集型摘要格式

Method: 采用黑格尔辩证法框架：初始摘要（正题）→质疑局限（反题）→生成通用摘要（合题）的迭代优化流程

Result: 在TriviaQA等数据集上超越零样本LLM基线66%，优于专业摘要方法27%；摘要token量减少且LLM无关

Conclusion: CoS为网站维护者提供高效内容转化方案，平衡LLM可访问性与人类监管需求

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [29] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: 论文提出了首个音频推理模型Step-Audio-R1，通过MGRD框架实现基于声学特征的可靠推理链生成，在多项音频理解任务中超越Gemini 2.5 Pro并接近Gemini 3 Pro水平。


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型表现出'少思考反而表现更好'的反常现象，研究者希望验证音频智能是否真正受益于深思熟虑的推理过程。

Method: 提出模态锚定推理蒸馏框架(MGRD)，使模型学习生成基于声学特征的真实推理链，避免产生与音频内容脱节的幻觉推理。

Result: Step-Audio-R1在语音/环境音/音乐等综合音频理解任务中展现强大推理能力，性能超越Gemini 2.5 Pro并与Gemini 3 Pro相当。

Conclusion: 研究表明当推理过程被合理锚定时，跨模态的推理能力具有可迁移性，这为构建真正的多模态推理系统开辟了新路径。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [30] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 提出JudgeBoard评估框架和MAJ多智能体系统，通过直接评估和多模型协作显著提升轻量模型在推理任务中的判断性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估框架依赖参考答案对比，存在自动化程度低、评估粒度粗的问题，难以支持可扩展的推理输出评估

Method: 1) 开发JudgeBoard评估管道直接评估答案正确性；2) 创建数学与科学推理双领域排行榜；3) 提出MAJ框架实现多轻量模型协同决策

Result: MAJ框架使小模型在MATH数据集上达到或超越大模型性能，多智能体协作使判断准确率提升21%，一致性提高34%

Conclusion: 多智能体轻量模型系统可媲美大模型评估能力，为高效可扩展的AI评估提供新范式，降低对大型模型的依赖

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [31] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: LLMs在临床推理中存在检索与推理差距，需建立严格评估框架确保安全部署


<details>
  <summary>Details</summary>
Motivation: 临床场景中模型输出必须符合结构化协议，但LLMs即使获得正确证据仍存在推理错误风险

Method: 使用书面暴露疗法(WET)指南作为测试平台，提出准确性、一致性、忠实性三位一体的评估框架

Result: 检索增强生成(RAG)可约束输出，但安全部署需要像评估检索一样严格评估推理过程

Conclusion: 在临床等高风险领域部署LLM时，必须将推理评估提升到与检索评估同等重要的地位

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [32] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 开发了一款名为SpellForger的AI驱动游戏，玩家通过自然语言指令实时生成定制咒语，验证了AI作为核心游戏机制的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前AI在游戏中多用于辅助生成内容，尚未充分开发其作为核心共同创作工具的潜力。本研究旨在探索如何通过自然语言交互让玩家直接参与游戏机制设计。

Method: 使用监督训练的BERT模型解析玩家指令，将文本映射到预设咒语模板并自动平衡参数（伤害值/消耗/特效），游戏本体基于Unity引擎开发，AI后端采用Python实现。

Result: 成功开发的功能原型实现了实时咒语生成机制，核心玩法循环验证了玩家创造力驱动的游戏体验，证实AI可直接作为核心游戏机制运作。

Conclusion: 该研究展示了自然语言处理技术作为游戏核心机制的潜力，通过将AI与创意表达结合，为动态生成游戏内容开辟了新路径。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [33] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: 论文提出OpenMMReasoner，一种透明可复现的两阶段多模态推理训练方案（SFT+RL），在九大基准测试中超越基线模型11.6%，并开源全部代码和数据。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理领域缺乏透明可复现的数据构建和训练策略，制约了规模化研究。为解决该瓶颈，研究者试图通过系统性训练框架推动领域发展。

Method: 两阶段训练框架：1）监督微调阶段（SFT）构建874K高质量分步验证数据集；2）强化学习阶段（RL）使用74K跨领域数据提升能力稳定性。

Result: 在九大多模态推理基准测试中超越Qwen2.5-VL-7B-Instruct基线11.6%，验证了数据质量和训练设计对性能的关键影响。

Conclusion: 研究证实系统化训练方案能显著提升多模态推理能力，其开源性为后续大规模研究提供了可验证的实证基础，强调数据质量与算法设计的协同优化至关重要。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [34] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了一种无需训练的轻量级单次联邦视觉语言模型适配框架TOFA，通过视觉与文本双模态协同处理数据异构性，无需客户端/服务器额外训练资源。


<details>
  <summary>Details</summary>
Motivation: 现有联邦视觉语言模型迭代式训练存在通信成本高、易受攻击的问题，而单次联邦训练方法存在多模态信息利用不足、缺乏系统性处理数据异构性策略、需额外训练资源三大挑战。

Method: 1. 视觉管道：分层贝叶斯模型学习个性化的类特定原型分布；2. 文本管道：评估并全局对齐本地文本提示；3. 自适应权重校准机制平衡个性化和鲁棒性。

Result: 在9个数据集的不同联邦学习场景中验证了有效性，包括跨设备/跨孤岛/混合异构场景。

Conclusion: TOFA首次实现了无需参数更新的联邦VLM适配，通过双模态特征挖掘和自适应权重机制有效平衡个性化与鲁棒性。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [35] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: 提出动态基准框架D-GARA评估Android GUI智能体在真实异常场景中的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体数据集过于理想化，无法反映真实环境中权限弹窗/电量警告/更新提示等异常场景对智能体的影响

Method: 1. 构建包含10种常见真实异常的动态框架 2. 创建带标注的Android应用基准测试集 3. 模块化设计支持新任务/异常类型扩展

Result: 实验显示当前最优GUI智能体在异常环境下的性能下降达47.2%，暴露鲁棒性缺陷

Conclusion: D-GARA框架为社区提供可扩展的鲁棒性评估工具，推动智能体在复杂现实场景中的实用化进程

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [36] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: Codec2Vec是首个仅基于离散音频编解码单元的语音表示学习框架，在保持与连续输入模型竞争性能的同时，显著提升了存储效率和训练速度。


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，解决传统连续数据模型在存储、传输效率和隐私方面的局限性。

Method: 通过多种训练目标策略进行掩码预测，构建完全基于离散音频编解码单元的特征学习框架。

Result: SUPERB基准测试中存储需求降低16.5倍，训练时间减少2.3倍，性能与连续模型持平。

Conclusion: 证明了离散编解码单元在语音表示学习中的有效性，为资源敏感场景提供了高效解决方案。

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [37] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 提出新型多智能体系统框架，揭示不合作行为可在1-7轮内引发系统崩溃，合作系统则保持100%稳定性


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对LLM多智能体系统中不合作行为的系统性研究，需构建理论框架分析其对系统稳定性的破坏机制

Method: 1. 建立基于博弈论的行为分类体系
2. 开发多阶段动态模拟管道，实现智能体状态演进下的行为生成与优化

Result: 框架生成不合作行为准确率达96.7%（人类评估验证），合作系统12轮存活率100%/资源0过度消耗，不合作行为导致系统1-7轮内崩溃

Conclusion: 不合作智能体会显著破坏系统稳定性，凸显设计鲁棒性多智能体系统的重要性

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [Clustered Error Correction with Grouped 4D Gaussian Splatting](https://arxiv.org/abs/2511.16112)
*Taeho Kang,Jaeyeon Park,Kyungjin Lee,Youngki Lee*

Main category: cs.CV

TL;DR: 提出CEM-4DGS方法，通过椭圆误差聚类和分组4D高斯溅射技术，提升动态场景重建的时间一致性和渲染质量


<details>
  <summary>Details</summary>
Motivation: 现有4DGS方法存在动态区域像素对应模糊和溅射不足问题，导致重建效果不佳

Method: 1. 椭圆误差聚类结合跨视图颜色一致性进行错误分类与校正
2. 分组4D高斯溅射技术提升溅射与动态对象映射一致性

Result: 在Technicolor光场数据集实现PSNR提升0.39dB，可视化显示溅射与动态物体对齐度提高

Conclusion: 该方法通过新型误差校正和分组溅射机制，有效解决动态场景重建难题，在时间一致性和渲染质量上达到SOTA水平

Abstract: Existing 4D Gaussian Splatting (4DGS) methods struggle to accurately reconstruct dynamic scenes, often failing to resolve ambiguous pixel correspondences and inadequate densification in dynamic regions. We address these issues by introducing a novel method composed of two key components: (1) Elliptical Error Clustering and Error Correcting Splat Addition that pinpoints dynamic areas to improve and initialize fitting splats, and (2) Grouped 4D Gaussian Splatting that improves consistency of mapping between splats and represented dynamic objects. Specifically, we classify rendering errors into missing-color and occlusion types, then apply targeted corrections via backprojection or foreground splitting guided by cross-view color consistency. Evaluations on Neural 3D Video and Technicolor datasets demonstrate that our approach significantly improves temporal consistency and achieves state-of-the-art perceptual rendering quality, improving 0.39dB of PSNR on the Technicolor Light Field dataset. Our visualization shows improved alignment between splats and dynamic objects, and the error correction method's capability to identify errors and properly initialize new splats. Our implementation details and source code are available at https://github.com/tho-kn/cem-4dgs.

</details>


### [39] [Layer-wise Noise Guided Selective Wavelet Reconstruction for Robust Medical Image Segmentation](https://arxiv.org/abs/2511.16162)
*Yuting Lu,Ziliang Wang,Weixin Xu,Wei Zhang,Yongqiang Zhao,Yang Yu,Xiaohong Zhang*

Main category: cs.CV

TL;DR: 提出LNG-SWR方法，通过层间噪声引导的小波重建实现医学图像分割的鲁棒性提升，无需完全依赖对抗训练即可增强模型稳定性。


<details>
  <summary>Details</summary>
Motivation: 对抗训练(AT)存在清洁精度与鲁棒性权衡、训练成本高的问题，限制了医学影像场景的扩展性和可维护性。需要开发更高效的鲁棒性增强方案。

Method: 1. 训练阶段在多层注入零均值噪声，学习频率偏置先验
2. 基于先验进行选择性小波重建：抑制噪声敏感频段，增强方向性结构和形状线索
3. 保持频谱一致性同时稳定边界响应

Result: 在CT和超声数据集上：
- PGD-L∞/L₂攻击下Dice/IoU提升
- SSAH攻击下性能下降减少45%
- 与AT结合时鲁棒性叠加提升
- 推理开销仅增加6%

Conclusion: LNG-SWR为医学图像分割提供了简单、高效且工程友好的鲁棒性增强方案，在标准训练和对抗训练场景中均有效，具有临床部署潜力。

Abstract: Clinical deployment requires segmentation models to stay stable under distribution shifts and perturbations. The mainstream solution is adversarial training (AT) to improve robustness; however, AT often brings a clean--robustness trade-off and high training/tuning cost, which limits scalability and maintainability in medical imaging. We propose \emph{Layer-wise Noise-Guided Selective Wavelet Reconstruction (LNG-SWR)}. During training, we inject small, zero-mean noise at multiple layers to learn a frequency-bias prior that steers representations away from noise-sensitive directions. We then apply prior-guided selective wavelet reconstruction on the input/feature branch to achieve frequency adaptation: suppress noise-sensitive bands, enhance directional structures and shape cues, and stabilize boundary responses while maintaining spectral consistency. The framework is backbone-agnostic and adds low additional inference overhead. It can serve as a plug-in enhancement to AT and also improves robustness without AT. On CT and ultrasound datasets, under a unified protocol with PGD-$L_{\infty}/L_{2}$ and SSAH, LNG-SWR delivers consistent gains on clean Dice/IoU and significantly reduces the performance drop under strong attacks; combining LNG-SWR with AT yields additive gains. When combined with adversarial training, robustness improves further without sacrificing clean accuracy, indicating an engineering-friendly and scalable path to robust segmentation. These results indicate that LNG-SWR provides a simple, effective, and engineering-friendly path to robust medical image segmentation in both adversarial and standard training regimes.

</details>


### [40] [TetraSDF: Precise Mesh Extraction with Multi-resolution Tetrahedral Grid](https://arxiv.org/abs/2511.16273)
*Seonghun Oh,Youngjung Uh,Jin-Hwa Kim*

Main category: cs.CV

TL;DR: 提出TetraSDF框架，通过多分辨率四面体位编码器与ReLU MLP结合，实现神经符号距离函数的精确网格提取，在精度和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有采样方法存在离散化误差，而传统CPWA解析方法仅适用于普通ReLU MLP，无法处理复杂编码器结构。需要开发能精确匹配等值面且适用于现代编码器的解析提取方案。

Method: 1) 利用四面体位编码器的重心插值保持全局CPWA结构
2) 在编码器诱导的多面体复合体内追踪ReLU线性区域
3) 采用固定解析输入预处理器降低方向偏差

Result: 在多个基准测试中达到SOTA重建精度，生成高度自洽的等值面网格（F-score提升3-5%），运行效率与内存占用优于传统方法。

Conclusion: TetraSDF首次实现复杂编码器下的精确解析提取，为神经隐式表面重建提供了新的可靠解决方案，兼具理论严谨性与工程实用性。

Abstract: Extracting meshes that exactly match the zero-level set of neural signed distance functions (SDFs) remains challenging. Sampling-based methods introduce discretization error, while continuous piecewise affine (CPWA) analytic approaches apply only to plain ReLU MLPs. We present TetraSDF, a precise analytic meshing framework for SDFs represented by a ReLU MLP composed with a multi-resolution tetrahedral positional encoder. The encoder's barycentric interpolation preserves global CPWA structure, enabling us to track ReLU linear regions within an encoder-induced polyhedral complex. A fixed analytic input preconditioner derived from the encoder's metric further reduces directional bias and stabilizes training. Across multiple benchmarks, TetraSDF matches or surpasses existing grid-based encoders in SDF reconstruction accuracy, and its analytic extractor produces highly self-consistent meshes that remain faithful to the learned isosurfaces, all with practical runtime and memory efficiency.

</details>


### [41] [Optimizing 3D Gaussian Splattering for Mobile GPUs](https://arxiv.org/abs/2511.16298)
*Md Musfiqur Rahman Sanim,Zhihao Shu,Bahram Afsharmanesh,AmirAli Mirian,Jiexiong Guan,Wei Niu,Bin Ren,Gagan Agrawal*

Main category: cs.CV

TL;DR: Texture3dgs优化3D高斯溅射算法，通过新型排序算法和内存优化实现移动端高效3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 利用移动设备部署优势（数据隐私、离线操作、快速响应），解决移动GPU二维纹理缓存优化核心挑战。

Method: 提出基于2D内存优化的新型排序算法，结合纹理缓存成本模型分析和变量布局优化，加速3DGS算法流程。

Result: 排序速度提升4.1倍，整体重建加速1.7倍，内存占用减少1.6倍，验证移动端高效3D重建有效性。

Conclusion: Texture3dgs通过内存访问优化和算法创新，为移动端实时3D场景重建提供了高效解决方案。

Abstract: Image-based 3D scene reconstruction, which transforms multi-view images into a structured 3D representation of the surrounding environment, is a common task across many modern applications. 3D Gaussian Splatting (3DGS) is a new paradigm to address this problem and offers considerable efficiency as compared to the previous methods. Motivated by this, and considering various benefits of mobile device deployment (data privacy, operating without internet connectivity, and potentially faster responses), this paper develops Texture3dgs, an optimized mapping of 3DGS for a mobile GPU. A critical challenge in this area turns out to be optimizing for the two-dimensional (2D) texture cache, which needs to be exploited for faster executions on mobile GPUs. As a sorting method dominates the computations in 3DGS on mobile platforms, the core of Texture3dgs is a novel sorting algorithm where the processing, data movement, and placement are highly optimized for 2D memory. The properties of this algorithm are analyzed in view of a cost model for the texture cache. In addition, we accelerate other steps of the 3DGS algorithm through improved variable layout design and other optimizations. End-to-end evaluation shows that Texture3dgs delivers up to 4.1$\times$ and 1.7$\times$ speedup for the sorting and overall 3D scene reconstruction, respectively -- while also reducing memory usage by up to 1.6$\times$ -- demonstrating the effectiveness of our design for efficient mobile 3D scene reconstruction.

</details>


### [42] [PartUV: Part-Based UV Unwrapping of 3D Meshes](https://arxiv.org/abs/2511.16659)
*Zhaoning Wang,Xinyue Wei,Ruoxi Shi,Xiaoshuai Zhang,Hao Su,Minghua Liu*

Main category: cs.CV

TL;DR: PartUV提出基于部件分解的UV展开方法，通过结合语义分割与几何优化，在AI生成网格上实现更少图表、更低失真的参数化效果。


<details>
  <summary>Details</summary>
Motivation: 传统UV展开方法处理AI生成网格时易产生碎片化图表和劣质接缝，导致纹理失真并影响后续应用。现有方法缺乏对语义结构的有效利用。

Method: 基于PartField部件分割框架，采用自上而下的递归优化策略，集成几何启发式规则控制图表失真阈值，支持非流形网格处理并实现并行加速。

Result: 在四类数据集上验证显示：图表数量减少50%+，接缝长度优于现有工具，支持部件级多块包装等新应用，成功率提升显著。

Conclusion: PartUV通过融合语义与几何优化，有效提升UV展开质量，为AI生成内容的纹理映射等下游任务提供可靠解决方案。

Abstract: UV unwrapping flattens 3D surfaces to 2D with minimal distortion, often requiring the complex surface to be decomposed into multiple charts. Although extensively studied, existing UV unwrapping methods frequently struggle with AI-generated meshes, which are typically noisy, bumpy, and poorly conditioned. These methods often produce highly fragmented charts and suboptimal boundaries, introducing artifacts and hindering downstream tasks. We introduce PartUV, a part-based UV unwrapping pipeline that generates significantly fewer, part-aligned charts while maintaining low distortion. Built on top of a recent learning-based part decomposition method PartField, PartUV combines high-level semantic part decomposition with novel geometric heuristics in a top-down recursive framework. It ensures each chart's distortion remains below a user-specified threshold while minimizing the total number of charts. The pipeline integrates and extends parameterization and packing algorithms, incorporates dedicated handling of non-manifold and degenerate meshes, and is extensively parallelized for efficiency. Evaluated across four diverse datasets, including man-made, CAD, AI-generated, and Common Shapes, PartUV outperforms existing tools and recent neural methods in chart count and seam length, achieves comparable distortion, exhibits high success rates on challenging meshes, and enables new applications like part-specific multi-tiles packing. Our project page is at https://www.zhaoningwang.com/PartUV.

</details>


### [43] [Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions](https://arxiv.org/abs/2511.16221)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Ruicong Liu,Yoichi Sato*

Main category: cs.CV

TL;DR: 论文提出多模态交互欺骗评估任务（MIDA），发现顶尖MLLMs在社交欺骗识别上存在显著缺陷，并设计了SoCoT推理框架和DSEM模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs缺乏人类核心智能——通过多模态社交线索判断复杂社交场景中欺骗的能力，需系统性评估其局限性。

Method: 1. 构建含同步视频文本的MIDA数据集；2. 测试12个前沿模型；3. 提出基于社会思维链（SoCoT）和动态社会认知记忆（DSEM）的解决方案。

Result: GPT-4o等模型平均准确率仅61.3%，改进框架使性能提升8.2%，验证了社会推理路径的有效性。

Conclusion: 当前MLLMs缺乏社会认知基础能力，亟需发展新型多模态社会推理框架以实现可信AI。

Abstract: Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

</details>


### [44] [TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](https://arxiv.org/abs/2511.16595)
*Boshen Xu,Zihan Xiao,Jiaze Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Qin Jin*

Main category: cs.CV

TL;DR: TimeViper提出结合Mamba-Transformer的混合架构，通过TransV模块压缩视觉令牌冗余，实现万帧长视频理解


<details>
  <summary>Details</summary>
Motivation: 解决长视频处理中存在的架构效率与长时序上下文处理难题，发现视觉令牌冗余现象需信息压缩

Method: 混合Mamba-Transformer架构 + TransV令牌转移压缩模块（将视觉令牌迁移至指令令牌）

Result: 可处理超万帧小时级视频，性能媲美SOTA模型且扩展帧数，提供混合架构可解释性新洞见

Conclusion: 该研究为开发/解释/压缩混合架构奠定基础，首次展示深度增加时视觉-文本信息流的聚合规律

Abstract: We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.

</details>


### [45] [SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction](https://arxiv.org/abs/2511.16635)
*Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen*

Main category: cs.CV

TL;DR: SurvAgent是首个分层思维链增强的多智能体系统，通过整合多模态数据和历史案例经验学习，在五个TCGA队列实验中展现优于传统方法和医疗代理的生存预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法缺乏临床所需的透明度，且存在多模态整合不足、ROI探索效率低、历史案例学习缺失三大局限。

Method: 分两阶段实现：1) WSI-Gene联合案例库构建（低倍筛查+跨模态补丁挖掘+置信挖掘）；2) 基于RAG检索的多专家代理推理框架。

Result: 在五个TCGA队列的广泛实验中，SurvAgent超越传统方法、专有MLLMs和现有医疗代理。

Conclusion: 建立了精准肿瘤学中可解释AI驱动生存预测的新范式，实现病理图像与基因数据的协同分析及渐进式推理优化。

Abstract: Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.

</details>


### [46] [Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](https://arxiv.org/abs/2511.16671)
*Ziyu Guo,Renrui Zhang,Hongyu Li,Manyuan Zhang,Xinyan Chen,Sifan Wang,Yan Feng,Peng Pei,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 提出首个视觉生成过程中实时交织文本推理的TwiG框架，通过动态交互提升生成内容语义质量


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成方法仅支持生成前/后的文本推理，缺乏生成过程中的多模态实时交互，导致生成内容上下文感知不足

Method: 开发三种实现策略：零样本提示、TwiG-50K数据集监督微调、GRPO强化学习策略，探究交织推理动态机制

Result: 实现上下文感知更强的视觉生成效果，验证三种策略的有效性，开源包含5万样本的数据集及定制化强化学习方案

Conclusion: 首次实现生成与推理的协同进化机制，为多模态交互生成开辟新范式，代码开源将推动该领域技术发展

Abstract: Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [47] [Time-Critical Adversarial Influence Blocking Maximization](https://arxiv.org/abs/2511.16068)
*Jilong Shi,Qiuyan Yan,Xiaobin Rui,Zhixiao Wang*

Main category: cs.SI

TL;DR: 提出时间关键型对抗影响阻断模型TC-AIBM，通过TC-IC模型引入时间约束，提出BIS算法实现高效阻断并证明理论下界


<details>
  <summary>Details</summary>
Motivation: 现有对抗影响阻断模型忽略时间因素且缺乏子模性理论分析，无法满足政治竞选等时间敏感场景需求

Method: 1. 建立TC-IC传播模型引入时间约束 2. 构建TC-AIBM问题框架 3. 在三种平局规则下证明目标函数子模性 4. 提出双向影响采样算法BIS

Result: BIS算法在四个真实数据集上表现稳定，效率比贪心算法提升三个数量级，在不同负面种子和时间约束下均优于基线方法

Conclusion: 本研究首次将时间约束融入对抗影响阻断问题，通过子模性理论保证算法性能，为时间敏感场景的传播控制提供新解决方案

Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [48] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym 是一个用于支持基于LLM的查询重构的Python工具包，解决了当前领域缺乏统一框架的问题，提供标准化实现、多后端支持、提示管理系统和开源访问。


<details>
  <summary>Details</summary>
Motivation: 当前LLM查询重构方法缺乏统一工具，导致公平比较困难、实验效率低下且部署不可靠，阻碍了该领域的研究进展。

Method: 通过Python API集成多种LLM方法，采用检索无关接口设计，构建带版本控制的提示管理系统，内置主流检索基准支持，并提供开源可扩展实现。

Result: 创建了首个统一的LLM查询重构工具框架，支持研究者快速实现/比较不同方法，促进可靠实验复现与系统部署。

Conclusion: QueryGym填补了LLM查询重构领域的工具空白，其开源特性与模块化设计将加速相关研究和技术落地。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [49] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: LLM驱动的音乐推荐系统需重构评估框架，传统准确性指标失效，需建立跨学科评估视角


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统受限于检索式评估范式，无法评估推荐本质质量；LLM的生成特性与不可控因素打破原有评估体系

Method: 通过分析LLM对音乐推荐三要素（用户建模/物品建模/自然语言推荐）的重塑，整合NLP领域评估方法论

Result: 提出包含成功维度（自然交互、模型即评估者）与风险维度（幻觉/训练数据不透明）的结构化评估框架

Conclusion: 为MRS社区提供融合提示工程与跨学科方法的评估路线图，推动LLM时代推荐系统的范式革新

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [50] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: 提出解耦框架Prism，通过分离推荐排序与解释生成阶段，结合知识蒸馏技术实现高效可解释推荐


<details>
  <summary>Details</summary>
Motivation: 解决端到端可解释推荐系统中性能与效率的权衡矛盾，消除联合优化带来的次优妥协

Method: 采用教师-学生架构：大型教师LLM生成解释知识，轻量级Prism模型专门化合成个性化解释

Result: 140M参数的Prism在忠实度和个性化评估中超越11B参数教师模型，推理速度提升24倍且内存消耗减少10倍

Conclusion: 解耦架构配合定向蒸馏为高质量可解释推荐提供了高效解决方案，证明组件专业化优化的有效性

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [51] [MiMo-Embodied: X-Embodied Foundation Model Technical Report](https://arxiv.org/abs/2511.16518)
*Xiaoshuai Hao,Lei Zhou,Zhijian Huang,Zhiwen Hou,Yingbo Tang,Lingfeng Zhang,Guang Li,Zheng Lu,Shuhuai Ren,Xianhui Meng,Yuchen Zhang,Jing Wu,Jinghui Lu,Chenxu Dang,Jiayi Guan,Jianhua Wu,Zhiyi Hou,Hanbing Li,Shumeng Xia,Mingliang Zhou,Yinan Zheng,Zihao Yue,Shuhao Gu,Hao Tian,Yuannan Shen,Jianwei Cui,Wen Zhang,Shaoqing Xu,Bing Wang,Haiyang Sun,Zeyu Zhu,Yuncheng Jiang,Zibin Guo,Chuhong Gong,Chaofan Zhang,Wenbo Ding,Kun Ma,Guang Chen,Rui Cai,Diyun Xiang,Heng Qu,Fuli Luo,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 首个跨具身基础模型MiMo-Embodied在自动驾驶和具身AI双领域实现SOTA，通过多阶段学习和协同优化实现双向正迁移


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶与具身智能领域模型割裂的问题，验证跨领域协同训练的有效性

Method: 多阶段学习框架 + 数据工程优化 + CoT思维链强化学习微调

Result: 在29个基准测试中刷新记录（17项具身AI/12项自动驾驶），全面超越开源/闭源/专用模型

Conclusion: 自动驾驶与具身AI存在强协同效应，开源模型为跨领域基础模型研究提供新范式

Abstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [52] [AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization](https://arxiv.org/abs/2511.15915)
*Genghan Zhang,Shaowei Zhu,Anjiang Wei,Zhenyu Song,Allen Nie,Zhen Jia,Nandita Vijaykumar,Yida Wang,Kunle Olukotun*

Main category: cs.LG

TL;DR: 自优化LLM代理AccelOpt实现AI加速器内核自动优化，性能提升显著且成本效益优异


<details>
  <summary>Details</summary>
Motivation: 解决新兴AI加速器内核优化依赖专家知识的问题，实现自动化持续改进

Method: 基于优化记忆的迭代生成框架 + 真实场景提取的NKIBench评估基准

Result: Trainium芯片峰值吞吐率提升12%（49%→61%和45%→59%），成本效益达Claude Sonnet的26倍

Conclusion: AccelOpt展示了LLM代理在硬件优化领域的潜力，为新兴加速器提供经济高效的自动化解决方案

Abstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\%$ to $61\%$ on Trainium 1 and from $45\%$ to $59\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\times$ cheaper.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [53] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 提出通过优化文本护盾（SHIELD）来加固LLM系统提示的新框架，在保持功能性的前提下显著降低提示泄露风险。


<details>
  <summary>Details</summary>
Motivation: 系统提示易受对抗查询提取攻击，现有防御方案存在依赖启发式规则、计算开销大、不适用黑盒API等问题。

Method: 将提示加固建模为效用约束优化问题，利用LLM作为优化器搜索最优防护文本，平衡泄露最小化与语义保真度。

Result: 优化后的SHIELD在多种攻击下提示泄露率降低61.2%，且任务效用保持基线98.3%的水平。

Conclusion: 该方法为LLM安全领域提供了轻量级、效用感知的防御范式，仅需API调用即可部署。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>
