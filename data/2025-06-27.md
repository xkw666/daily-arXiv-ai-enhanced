<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.GR](#cs.GR) [Total: 6]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 8]
- [cs.AI](#cs.AI) [Total: 5]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
*Chen Shen,Sajjadur Rahman,Estevam Hruschka*

Main category: cs.CL

TL;DR: 提出LUCARIO框架，通过贝叶斯网络和LLM的符号-神经混合推理实现表格数据概率问答，实验显示显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有表格问答系统（如NL2SQL）擅长事实性问题，但无法处理需要概率推理的问题。本文旨在解决表格数据中概率性问题的推理挑战

Method: 1. 从表格构建贝叶斯网络
2. 将自然语言查询转化为概率查询
3. 利用大语言模型生成最终答案
采用符号推理（贝叶斯网络）与神经模型（LLM）结合的混合架构

Result: 实验结果表明该方法在概率问答任务上显著超越基线模型，验证了符号-神经混合推理框架的有效性

Conclusion: 通过融合符号推理和神经语言模型的优势，成功提升了复杂概率问答任务的性能，为表格数据推理提供了新方向

Abstract: Current approaches for question answering (QA) over tabular data, such as
NL2SQL systems, perform well for factual questions where answers are directly
retrieved from tables. However, they fall short on probabilistic questions
requiring reasoning under uncertainty. In this paper, we introduce a new
benchmark LUCARIO and a framework for probabilistic QA over large tabular data.
Our method induces Bayesian Networks from tables, translates natural language
queries into probabilistic queries, and uses large language models (LLMs) to
generate final answers. Empirical results demonstrate significant improvements
over baselines, highlighting the benefits of hybrid symbolic-neural reasoning.

</details>


### [2] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
*Victor Ojewale,Inioluwa Deborah Raji,Suresh Venkatasubramanian*

Main category: cs.CL

TL;DR: 通过创建跨语言功能性基准测试CL-GSM Symbolic和CL-IFEval，研究发现现有静态多语言评估存在性能差异和语言鲁棒性问题，阿拉伯语和英语表现最稳定。


<details>
  <summary>Details</summary>
Motivation: 现有静态基准测试(如Belebele/M-GSM)无法有效评估模型在多语言场景下的实际功能表现和鲁棒性差异

Method: 将英语功能测试模板翻译为法语/西班牙语/印地语/阿拉伯语/约鲁巴语，构建CL-GSM Symbolic(数学符号推理)和CL-IFEval(指令跟随)跨语言测试集

Result: M-MMLU与CL-IFEval性能差距最小(0.5-3%)，M-GSM/Belebele差距达15-24%；模型在阿拉伯语和英语表现最稳定，其他语言波动显著

Conclusion: 需开发更全面的多语言评估体系，特定语言(如阿拉伯语)的稳定性为模型优化提供方向

Abstract: Multi-lingual competence in large language models is often evaluated via
static data benchmarks such as Belebele, M-MMLU and M-GSM. However, these
evaluations often fail to provide an adequate understanding of the practical
performance and robustness of models across multi-lingual settings. In
response, we create multi-lingual functional benchmarks -- Cross-Lingual Grade
School Math Symbolic (CL-GSM Symbolic) and Cross-Lingual Instruction-Following
Eval (CL-IFEval)-- by translating existing functional benchmark templates from
English to five additional languages that span the range of resources available
for NLP: French, Spanish, Hindi, Arabic and Yoruba. Our results reveal that
some static multi-lingual benchmarks capture functional performance much more
closely than others (i.e. across models, there is a 24%, 17% and 18% decrease
in performance between M-GSM and CL-GSM Symbolic in English, French and Spanish
respectively; similarly there's a 15 - 24% performance drop across languages
between Belebele and CL-IFEval, and only a 0.5% to 3% performance drop between
M-MMLU and CL-IFEval). Similarly, we find that model robustness across
languages varies significantly, with certain languages (eg. Arabic, English)
being the most consistently well performing across evaluation iterations.

</details>


### [3] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
*Chenglei Si,Tatsunori Hashimoto,Diyi Yang*

Main category: cs.CL

TL;DR: LLM生成的研究想法在执行阶段评分显著下降，暴露构思与执行的差距


<details>
  <summary>Details</summary>
Motivation: 验证研究想法执行后的实际效果，而非仅停留在构思阶段的创新性评估

Method: 招募43位专家执行随机分配的人类/Llama2生成想法，通过100+小时实施后盲审评估

Result: 执行后LLM想法在所有指标（p<0.05）降幅更大，多项排名出现人类反超现象

Conclusion: 当前LLM在生成有效研究想法存在局限，突显缺乏执行结果的评估挑战

Abstract: Large Language Models (LLMs) have shown promise in accelerating the
scientific research pipeline. A key capability for this process is the ability
to generate novel research ideas, and prior studies have found settings in
which LLM-generated research ideas were judged as more novel than human-expert
ideas. However, a good idea should not simply appear to be novel, it should
also result in better research after being executed. To test whether
AI-generated ideas lead to better research outcomes, we conduct an execution
study by recruiting 43 expert researchers to execute randomly-assigned ideas,
either written by experts or generated by an LLM. Each expert spent over 100
hours implementing the idea and wrote a 4-page short paper to document the
experiments. All the executed projects are then reviewed blindly by expert NLP
researchers. Comparing the review scores of the same ideas before and after
execution, the scores of the LLM-generated ideas decrease significantly more
than expert-written ideas on all evaluation metrics (novelty, excitement,
effectiveness, and overall; p < 0.05), closing the gap between LLM and human
ideas observed at the ideation stage. When comparing the aggregated review
scores from the execution study, we even observe that for many metrics there is
a flip in rankings where human ideas score higher than LLM ideas. This
ideation-execution gap highlights the limitations of current LLMs in generating
truly effective research ideas and the challenge of evaluating research ideas
in the absence of execution outcomes.

</details>


### [4] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: 提出MultiFinRAG框架，通过多模态数据整合与分层检索策略，在金融QA任务中实现比ChatGPT-4o高19%的准确率


<details>
  <summary>Details</summary>
Motivation: 传统LLMs和RAG在跨模态金融文档处理中存在token限制、布局丢失和上下文碎片化问题，需开发专门支持多模态联合推理的解决方案

Method: 1. 多模态批量处理表格/图像生成结构化JSON和摘要 2. 模态感知嵌入索引 3. 分层回退策略动态切换文本/多模态上下文

Result: 在包含文本、表格、图像的综合QA任务中，准确率超越ChatGPT-4o免费版19个百分点

Conclusion: MultiFinRAG有效实现跨模态金融推理，在有限硬件条件下显著提升复杂QA任务的性能

Abstract: Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span
hundreds of pages and combine diverse modalities, including dense narrative
text, structured tables, and complex figures. Answering questions over such
content often requires joint reasoning across modalities, which strains
traditional large language models (LLMs) and retrieval-augmented generation
(RAG) pipelines due to token limitations, layout loss, and fragmented
cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation
framework purpose-built for financial QA. MultiFinRAG first performs multimodal
extraction by grouping table and figure images into batches and sending them to
a lightweight, quantized open-source multimodal LLM, which produces both
structured JSON outputs and concise textual summaries. These outputs, along
with narrative text, are embedded and indexed with modality-aware similarity
thresholds for precise retrieval. A tiered fallback strategy then dynamically
escalates from text-only to text+table+image contexts when necessary, enabling
cross-modal reasoning while reducing irrelevant context. Despite running on
commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy
than ChatGPT-4o (free-tier) on complex financial QA tasks involving text,
tables, images, and combined multimodal reasoning.

</details>


### [5] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
*Quintin Myers,Yanjun Gao*

Main category: cs.CL

TL;DR: LLMs在暴力内容检测中存在表面生成与内部偏好的分歧，且暴力倾向在不同人口统计维度存在偏差


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未充分验证LLMs在道德模糊场景中的推理能力，特别是与人类暴力行为判断的差异

Method: 采用社会科学的暴力行为情景问卷（VBVQ），通过基于人设的提示（涵盖种族/年龄/地域）在6个不同地缘背景的LLMs上进行零样本测试

Result: 1. LLMs文本生成与暴力偏好存在表里差异 2. 暴力倾向分布与犯罪学实证研究结论存在矛盾

Conclusion: LLMs的暴力响应机制需要更多社会科学指导，当前模型存在与人类价值体系错位的潜在风险

Abstract: Large language models (LLMs) are increasingly proposed for detecting and
responding to violent content online, yet their ability to reason about morally
ambiguous, real-world scenarios remains underexamined. We present the first
study to evaluate LLMs using a validated social science instrument designed to
measure human response to everyday conflict, namely the Violent Behavior
Vignette Questionnaire (VBVQ). To assess potential bias, we introduce
persona-based prompting that varies race, age, and geographic identity within
the United States. Six LLMs developed across different geopolitical and
organizational contexts are evaluated under a unified zero-shot setting. Our
study reveals two key findings: (1) LLMs surface-level text generation often
diverges from their internal preference for violent responses; (2) their
violent tendencies vary across demographics, frequently contradicting
established findings in criminology, social science, and psychology.

</details>


### [6] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
*Sebastian Joseph,Lily Chen,Barry Wei,Michael Mackert,Iain J. Marshall,Paul Pu Liang,Ramez Kouzy,Byron C. Wallace,Junyi Jessy Li*

Main category: cs.CL

TL;DR: 技术进展推动医学事实核查系统发展，但面临证据关联困难、声明模糊性及主观验证标签等核心挑战，需转向交互式沟通评估框架。


<details>
  <summary>Details</summary>
Motivation: 医学决策的高风险性及公众医学素养不足催生对端到端事实核查系统的需求，但现有系统实际应用效果有限。

Method: 通过临床专家验证社交媒体真实医学声明的案例研究，揭示医学事实核查的边界条件。

Result: 发现三大核心挑战：1) 现实声明与临床试验证据的关联困难；2) 模糊声明与意图错配；3) 真实性判断的主观性。

Conclusion: 医学事实核查应重构为交互式沟通问题，需建立多方对话机制而非单纯端到端自动化流程。

Abstract: Technological progress has led to concrete advancements in tasks that were
regarded as challenging, such as automatic fact-checking. Interest in adopting
these systems for public health and medicine has grown due to the high-stakes
nature of medical decisions and challenges in critically appraising a vast and
diverse medical literature. Evidence-based medicine connects to every
individual, and yet the nature of it is highly technical, rendering the medical
literacy of majority users inadequate to sufficiently navigate the domain. Such
problems with medical communication ripens the ground for end-to-end
fact-checking agents: check a claim against current medical literature and
return with an evidence-backed verdict. And yet, such systems remain largely
unused. To understand this, we present the first study examining how clinical
experts verify real claims from social media by synthesizing medical evidence.
In searching for this upper-bound, we reveal fundamental challenges in
end-to-end fact-checking when applied to medicine: Difficulties connecting
claims in the wild to scientific evidence in the form of clinical trials;
ambiguities in underspecified claims mixed with mismatched intentions; and
inherently subjective veracity labels. We argue that fact-checking should be
approached and evaluated as an interactive communication problem, rather than
an end-to-end process.

</details>


### [7] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
*Zhengyan Shi*

Main category: cs.CL

TL;DR: 提出持续预训练、参数高效微调、改进监督方法和新评估基准，系统性提升语言模型在下游任务中的适应能力


<details>
  <summary>Details</summary>
Motivation: 现有微调方法存在未充分利用无标签数据、小样本过拟合和计算成本高的问题，制约语言模型在开放场景的实际应用

Method: 1) 基于无标签数据的持续预训练技术 2) 参数高效微调降低资源消耗 3) 少样本场景的指令微调改进 4) 多跳空间推理等新型评估基准开发

Result: 在多样化NLP任务中验证方法显著提升模型鲁棒性、效率和泛化能力，资源消耗降低的同时保持竞争力

Conclusion: 通过系统性创新在语言模型适应性方向取得重要进展，推动向通用人工智能目标迈进

Abstract: Language models (LMs) have demonstrated remarkable capabilities in NLP, yet
adapting them efficiently and robustly to specific tasks remains challenging.
As their scale and complexity grow, fine-tuning LMs on labelled data often
underutilizes available unlabelled data, leads to overfitting on small
task-specific sets, and imposes significant computational costs. These
limitations hamper their application to the open-ended landscape of real-world
language tasks.
  This thesis proposes a series of methods to better adapt LMs to downstream
applications. First, we explore strategies for extracting task-relevant
knowledge from unlabelled data, introducing a novel continued pre-training
technique that outperforms state-of-the-art semi-supervised approaches. Next,
we present a parameter-efficient fine-tuning method that substantially reduces
memory and compute costs while maintaining competitive performance. We also
introduce improved supervised fine-tuning methods that enable LMs to better
follow instructions, especially when labelled data is scarce, enhancing their
performance across a range of NLP tasks, including open-ended generation.
Finally, we develop new evaluation methods and benchmarks, such as multi-hop
spatial reasoning tasks, to assess LM capabilities and adaptation more
comprehensively.
  Through extensive empirical studies across diverse NLP tasks, our results
demonstrate that these approaches substantially improve LM robustness,
efficiency, and generalization, making them more adaptable to a broad range of
applications. These advances mark a significant step towards more robust and
efficient LMs, bringing us closer to the goal of artificial general
intelligence.

</details>


### [8] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
*Guilherme Penedo,Hynek Kydlíček,Vinko Sabolčec,Bettina Messmer,Negar Foroutan,Amir Hossein Kargaran,Colin Raffel,Martin Jaggi,Leandro Von Werra,Thomas Wolf*

Main category: cs.CL

TL;DR: 提出了基于FineWeb改进的自动化多语言预训练数据集构建流程FineWeb2，包含20TB数据覆盖1000+语言，通过智能去重和平衡策略提升模型性能


<details>
  <summary>Details</summary>
Motivation: 解决现有多语言LLM预训练数据集中存在的语言适配困难、清洗去重流程低效、数据集平衡性不足等问题

Method: 开发可自动适配不同语言的FineWeb数据处理流程，通过基于可量化标准的评估任务选择机制优化设计，提出结合重复计数和质量评估的数据平衡方法

Result: 在9种语言测试中模型性能超越现有数据集，数据平衡策略带来额外提升，最终构建包含50亿文档的20TB多语言数据集

Conclusion: FineWeb2及其配套工具为多语言LLM训练提供了更优质的数据基础，智能数据处理流程和平衡方法对提升模型性能具有显著效果

Abstract: Pre-training state-of-the-art large language models (LLMs) requires vast
amounts of clean and diverse text data. While the open development of large
high-quality English pre-training datasets has seen substantial recent
progress, training performant multilingual LLMs remains a challenge, in large
part due to the inherent difficulty of tailoring filtering and deduplication
pipelines to a large number of languages. In this work, we introduce a new
pre-training dataset curation pipeline based on FineWeb that can be
automatically adapted to support any language. We extensively ablate our
pipeline design choices on a set of nine diverse languages, guided by a set of
meaningful and informative evaluation tasks that were chosen through a novel
selection process based on measurable criteria. Ultimately, we show that our
pipeline can be used to create non-English corpora that produce more performant
models than prior datasets. We additionally introduce a straightforward and
principled approach to rebalance datasets that takes into consideration both
duplication count and quality, providing an additional performance uplift.
Finally, we scale our pipeline to over 1000 languages using almost 100 Common
Crawl snapshots to produce FineWeb2, a new 20 terabyte (5 billion document)
multilingual dataset which we release along with our pipeline, training, and
evaluation codebases.

</details>


### [9] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
*Xinping Zhao,Xinshuo Hu,Zifei Shan,Shouzheng Huang,Yao Zhou,Zetian Sun,Zhenyu Liu,Dongfang Li,Xinyuan Wei,Qian Chen,Youcheng Pan,Yang Xiang,Meishan Zhang,Haofen Wang,Jun Yu,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: 提出KaLM-Embedding-V2嵌入模型，通过双向Transformer架构、多阶段训练流程和创新的训练策略，在1B参数内实现与更大模型的竞争性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有嵌入模型在参数效率与性能平衡上的不足，通过架构优化和训练策略创新提升通用文本嵌入任务的性能表现。

Method: 1. 采用无因果掩码的双向Transformer架构+均值池化
2. 三阶段训练流程（预训练->微调->模型融合）
3. 创新训练策略：焦点式样本重加权+在线困难负样本混合

Result: 在MTEB中英文基准测试中超越同规模模型，与3-26倍参数量模型竞争，建立紧凑嵌入模型新标准。

Conclusion: 通过架构革新和系统化训练策略，证明了参数高效模型在文本嵌入任务中的潜力，为工业级应用提供了高性能紧凑解决方案。

Abstract: In this paper, we propose KaLM-Embedding-V2, a versatile and compact
embedding model, which achieves impressive performance in general-purpose text
embedding tasks by leveraging superior training techniques and data. Our key
innovations include: (1) To better align the architecture with representation
learning, we remove the causal attention mask and adopt a fully bidirectional
transformer with simple yet effective mean-pooling to produce fixed-length
embeddings; (2) We employ a multi-stage training pipeline: (i) pre-training on
large-scale weakly supervised open-source corpora; (ii) fine-tuning on
high-quality retrieval and non-retrieval datasets; and (iii) model-soup
parameter averaging for robust generalization. Besides, we introduce a
focal-style reweighting mechanism that concentrates learning on difficult
samples and an online hard-negative mixing strategy to continuously enrich hard
negatives without expensive offline mining; (3) We collect over 20 categories
of data for pre-training and 100 categories of data for fine-tuning, to boost
both the performance and generalization of the embedding model. Extensive
evaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and English
show that our model significantly outperforms others of comparable size, and
competes with 3x, 14x, 18x, and 26x larger embedding models, setting a new
standard for a versatile and compact embedding model with less than 1B
parameters.

</details>


### [10] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
*Eric Zhang,Leshem Choshen,Jacob Andreas*

Main category: cs.CL

TL;DR: 通过元训练使梯度下降模拟提示效果，提升语言模型参数更新能力


<details>
  <summary>Details</summary>
Motivation: 解决传统微调方法在单样本泛化和逻辑推理上效果弱于提示方法的问题

Method: 使用基于梯度的元学习框架，以模型自身提示预测为目标进行无监督训练

Result: 单次梯度更新即可改善'逆转诅咒'任务表现，实现文本问答任务性能提升

Conclusion: 梯度下降在适当初始化下具有强大表达能力，为长上下文建模和模型泛化能力研究开辟新路径

Abstract: There are two primary ways of incorporating new information into a language
model (LM): changing its prompt or changing its parameters, e.g. via
fine-tuning. Parameter updates incur no long-term storage cost for model
changes. However, for many model updates, prompting is significantly more
effective: prompted models can generalize robustly from single examples and
draw logical inferences that do not occur under standard fine-tuning. Can
models be modified so that fine-tuning does emulate prompting? This paper
describes a method for meta-training LMs such that gradient updates emulate the
effects of conditioning on new information. Our approach uses tools from
gradient-based meta-learning but uses an LM's own prompted predictions as
targets, eliminating the need for ground-truth labels. Subsequent gradient
descent training recovers some (and occasionally all) of prompted model
performance -- showing improvement on the ``reversal curse'' tasks, and
answering questions about text passages after a single gradient update. These
results suggest that, with appropriate initialization, gradient descent can be
surprisingly expressive. Our results suggest new avenues for long-context
modeling and offer insight into the generalization capabilities of
gradient-based learning.

</details>


### [11] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
*Adithya Chittem,Aishna Shrivastava,Sai Tarun Pendela,Jagat Sesh Challa,Dhruv Kumar*

Main category: cs.CL

TL;DR: 提出扩展MPI框架至16PF模型，结合SAC框架实现大语言模型人格特质的连续强度控制，发现连续调节比二元切换更有效且影响相关特质。


<details>
  <summary>Details</summary>
Motivation: 现有LLM人格建模依赖粗粒度的大五模型且缺乏强度控制，需建立更细腻、可动态调节的人格表达机制。

Method: 1. 将MPI扩展至包含16种特质的16PF模型；2. 开发SAC框架，通过形容词语义锚定和五维度行为问题动态诱导特质强度。

Result: 连续强度调节使表达更一致，目标特质变化会系统性影响相关特质，证明LLM具有多维人格结构而非孤立特质。

Conclusion: 该方法为医疗、教育等领域提供了更接近人类的人格化人机交互方案，推动社交机器向类人化发展。

Abstract: Large language models (LLMs) have gained significant traction across a wide
range of fields in recent years. There is also a growing expectation for them
to display human-like personalities during interactions. To meet this
expectation, numerous studies have proposed methods for modelling LLM
personalities through psychometric evaluations. However, most existing models
face two major limitations: they rely on the Big Five (OCEAN) framework, which
only provides coarse personality dimensions, and they lack mechanisms for
controlling trait intensity. In this paper, we address this gap by extending
the Machine Personality Inventory (MPI), which originally used the Big Five
model, to incorporate the 16 Personality Factor (16PF) model, allowing
expressive control over sixteen distinct traits. We also developed a structured
framework known as Specific Attribute Control (SAC) for evaluating and
dynamically inducing trait intensity in LLMs. Our method introduces
adjective-based semantic anchoring to guide trait intensity expression and
leverages behavioural questions across five intensity factors:
\textit{Frequency}, \textit{Depth}, \textit{Threshold}, \textit{Effort}, and
\textit{Willingness}. Through experimentation, we find that modelling intensity
as a continuous spectrum yields substantially more consistent and controllable
personality expression compared to binary trait toggling. Moreover, we observe
that changes in target trait intensity systematically influence closely related
traits in psychologically coherent directions, suggesting that LLMs internalize
multi-dimensional personality structures rather than treating traits in
isolation. Our work opens new pathways for controlled and nuanced human-machine
interactions in domains such as healthcare, education, and interviewing
processes, bringing us one step closer to truly human-like social machines.

</details>


### [12] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
*Jatin Gupta,Akhil Sharma,Saransh Singhania,Mohammad Adnan,Sakshi Deo,Ali Imam Abidi,Keshav Gupta*

Main category: cs.CL

TL;DR: 研究构建CA-Ben基准评估六种主流大模型在印度特许会计师考试中的表现，发现Claude 3.5 Sonnet和GPT-4o在法律推理表现最佳，但数值计算存在明显短板


<details>
  <summary>Details</summary>
Motivation: 现有大模型在专业金融知识应用的有效性尚未明确，特别是在印度大规模金融场景中缺乏专业评估基准

Method: 基于印度特许会计师协会(ICAI)考试体系构建结构化QA数据集，采用标准化协议测试GPT 4o、LLAMA系列等六种模型在不同阶段考试内容的表现

Result: Claude 3.5和GPT-4o在概念/法律推理领先，所有模型在数值计算准确率不足60%，法律条款解释存在30%误差率

Conclusion: 当前大模型在专业领域存在应用局限性，建议通过混合推理架构和检索增强技术提升定量分析与法律解释能力

Abstract: Advanced intelligent systems, particularly Large Language Models (LLMs), are
significantly reshaping financial practices through advancements in Natural
Language Processing (NLP). However, the extent to which these models
effectively capture and apply domain-specific financial knowledge remains
uncertain. Addressing a critical gap in the expansive Indian financial context,
this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically
designed to evaluate the financial, legal, and quantitative reasoning
capabilities of LLMs. CA-Ben comprises structured question-answer datasets
derived from the rigorous examinations conducted by the Institute of Chartered
Accountants of India (ICAI), spanning foundational, intermediate, and advanced
CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1
405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated
using standardized protocols. Results indicate variations in performance, with
Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and
legal reasoning. Notable challenges emerged in numerical computations and legal
interpretations. The findings emphasize the strengths and limitations of
current LLMs, suggesting future improvements through hybrid reasoning and
retrieval-augmented generation methods, particularly for quantitative analysis
and accurate legal interpretation.

</details>


### [13] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
*Chunyuan Yuan,Chong Zhang,Zheng Fang,Ming Pang,Xue Jiang,Changping Peng,Zhangang Lin,Ching Law*

Main category: cs.CL

TL;DR: 提出可扩展半监督统一框架SSUF，通过知识增强、标签增强和结构增强模块统一解决电商查询分类任务


<details>
  <summary>Details</summary>
Motivation: 电商查询短文本缺乏上下文，现有方法依赖用户点击行为导致马太效应，且多任务缺乏统一框架导致算法效率低下

Method: SSUF框架包含知识增强模块（融合世界知识补充查询信息）、标签增强模块（利用标签语义和半监督信号降低对后验标签依赖）、结构增强模块（通过复杂标签关系增强标签表示）

Result: 离线和在线A/B实验显示SSUF显著超越现有最优模型

Conclusion: 模块化设计实现高可插拔性，统一框架有效提升多任务处理效率和分类性能

Abstract: Query classification, including multiple subtasks such as intent and category
prediction, is vital to e-commerce applications. E-commerce queries are usually
short and lack context, and the information between labels cannot be used,
resulting in insufficient prior information for modeling. Most existing
industrial query classification methods rely on users' posterior click behavior
to construct training samples, resulting in a Matthew vicious cycle.
Furthermore, the subtasks of query classification lack a unified framework,
leading to low efficiency for algorithm optimization.
  In this paper, we propose a novel Semi-supervised Scalable Unified Framework
(SSUF), containing multiple enhanced modules to unify the query classification
tasks. The knowledge-enhanced module uses world knowledge to enhance query
representations and solve the problem of insufficient query information. The
label-enhanced module uses label semantics and semi-supervised signals to
reduce the dependence on posterior labels. The structure-enhanced module
enhances the label representation based on the complex label relations. Each
module is highly pluggable, and input features can be added or removed as
needed according to each subtask. We conduct extensive offline and online A/B
experiments, and the results show that SSUF significantly outperforms the
state-of-the-art models.

</details>


### [14] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
*Fuqiang Niu,Genan Dai,Yisha Lu,Jiayu Liao,Xiang Li,Hu Huang,Bowen Zhang*

Main category: cs.CL

TL;DR: 提出了最大的多目标多轮对话立场检测数据集MT2-CSD，并开发了LLM增强的关系注意力网络LLM-CRAN，显著优于基线模型


<details>
  <summary>Details</summary>
Motivation: 传统立场检测研究专注于单实例分析，无法有效建模真实社交媒体中的多方讨论，主要瓶颈在于缺乏真实社交互动动态的数据集

Method: 构建包含24,457标注实例的MT2-CSD数据集，提出LLM-CRAN模型，利用大语言模型的推理能力增强对话理解

Result: LLM-CRAN在MT2-CSD数据集上显著优于强基线模型

Conclusion: MT2-CSD填补了领域数据空白，LLM-CRAN通过结合大语言模型推理能力，为对话立场检测设立了新基准

Abstract: In the realm of contemporary social media, automatic stance detection is
pivotal for opinion mining, as it synthesizes and examines user perspectives on
contentious topics to uncover prevailing trends and sentiments. Traditional
stance detection research often targets individual instances, thereby limiting
its capacity to model multi-party discussions typical in real social media
scenarios. This shortcoming largely stems from the scarcity of datasets that
authentically capture the dynamics of social media interactions, hindering
advancements in conversational stance detection. In this paper, we introduce
MT2-CSD, a comprehensive dataset for multi-target, multi-turn conversational
stance detection. To the best of our knowledge, MT2-CSD is the largest dataset
available for this purpose, comprising 24,457 annotated instances and
exhibiting the greatest conversational depth, thereby presenting new challenges
for stance detection. To address these challenges, we propose the Large
Language model enhanced Conversational Relational Attention Network (LLM-CRAN),
which exploits the reasoning capabilities of LLMs to improve conversational
understanding. We conduct extensive experiments to evaluate the efficacy of
LLM-CRAN on the MT2-CSD dataset. The experimental results indicate that
LLM-CRAN significantly outperforms strong baseline models in the task of
conversational stance detection.

</details>


### [15] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
*Kang He,Yuzhe Ding. Haining Wang,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 提出DALR方法，通过跨模态一致性学习和模态内排序蒸馏解决多模态句子表示中的错位与语义分歧问题，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在粗粒度对齐图像文本时存在跨模态错位偏差和模态内语义发散，严重影响表示质量。需实现细粒度对齐并捕捉复杂句子关系。

Method: 1. 跨模态：一致性学习模块软化负样本，利用辅助任务语义相似性；2. 模态内：融合排序蒸馏与全局对齐学习，捕捉句子复杂排序结构。

Result: 在STS和TR任务中超越SOTA基线，证明方法有效性。

Conclusion: DALR通过双重对齐机制显著提升多模态句子表示质量，具有跨任务泛化能力。

Abstract: Previous multimodal sentence representation learning methods have achieved
impressive performance. However, most approaches focus on aligning images and
text at a coarse level, facing two critical challenges:cross-modal misalignment
bias and intra-modal semantic divergence, which significantly degrade sentence
representation quality. To address these challenges, we propose DALR
(Dual-level Alignment Learning for Multimodal Sentence Representation). For
cross-modal alignment, we propose a consistency learning module that softens
negative samples and utilizes semantic similarity from an auxiliary task to
achieve fine-grained cross-modal alignment. Additionally, we contend that
sentence relationships go beyond binary positive-negative labels, exhibiting a
more intricate ranking structure. To better capture these relationships and
enhance representation quality, we integrate ranking distillation with global
intra-modal alignment learning. Comprehensive experiments on semantic textual
similarity (STS) and transfer (TR) tasks validate the effectiveness of our
approach, consistently demonstrating its superiority over state-of-the-art
baselines.

</details>


### [16] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
*Qinwen Chen,Wenbiao Tao,Zhiwei Zhu,Mingfan Xi,Liangzhong Guo,Yuan Wang,Wei Wang,Yunshi Lan*

Main category: cs.CL

TL;DR: ComRAG框架通过质心记忆机制整合静态知识和动态QA对，提升工业级社区问答系统的实时性能和存储效率


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在外部知识利用不足、动态上下文整合缺失及工业部署存储效率低下的问题

Method: 采用检索增强生成框架，结合基于质心的记忆机制实现高效知识存储与检索

Result: 在工业数据集上实现25.9%的向量相似度提升，降低23.3%延迟，存储分块增长率从20.23%降至2.06%

Conclusion: ComRAG有效平衡效果与效率，为工业级社区问答系统提供了可扩展的实时解决方案

Abstract: Community Question Answering (CQA) platforms can be deemed as important
knowledge bases in community, but effectively leveraging historical
interactions and domain knowledge in real-time remains a challenge. Existing
methods often underutilize external knowledge, fail to incorporate dynamic
historical QA context, or lack memory mechanisms suited for industrial
deployment. We propose ComRAG, a retrieval-augmented generation framework for
real-time industrial CQA that integrates static knowledge with dynamic
historical QA pairs via a centroid-based memory mechanism designed for
retrieval, generation, and efficient storage. Evaluated on three industrial CQA
datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9%
improvement in vector similarity, reducing latency by 8.7% to 23.3%, and
lowering chunk growth from 20.23% to 2.06% over iterations.

</details>


### [17] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
*Xiaoshuang Ji,Zhendong Zhao,Xiaojun Chen,Xin Zhao,Zeyao Liu*

Main category: cs.CL

TL;DR: 提出Progtuning框架，通过渐进式学习减少25%参数更新量，在保持模型竞争力的同时优化计算资源分配


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法需要更新与初始设置相同的参数量，未能考虑Transformer模块的贡献度差异，导致计算资源分配效率低下

Method: 基于Transformer模块的贡献度评估，逐步减少需要更新的模块数量，并与参数高效微调方法协同使用

Result: 在减少约25%更新参数量的情况下保持竞争性能，且能灵活适配不同参数高效微调方法

Conclusion: Progtuning有效实现了动态资源分配优化，在多种适配场景中展现出卓越性能

Abstract: Fine-tuning is a promising technique for leveraging Transformer-based
language models in downstream tasks. As model sizes continue to grow, updating
all model parameters becomes increasingly costly. Parameter-efficient
fine-tuning methods effectively address this issue by selectively updating a
small subset of parameters. However, fine-tuning and most existing
parameter-efficient fine-tuning methods require updating the same number of
parameters as the initial size, ignoring the unequal contribution across
Transformer blocks and leading to extremely inefficient allocation of computing
resources. In this paper, we propose Progtuning, the novel fine-tuning
framework combined with progressive learning for Transformer-based language
models. Specifically, Progtuning progressively reduces the number of updated
transformer blocks based on the contribution. Remarkably, Progtuning optimizes
resource allocation and reduces the number of updated parameters by
approximately 25\%, while still maintaining competitive performance. And it
also exhibits high adaptability with parameter-efficient fine-tuning methods,
demonstrating excellent performance across various adaptation scenarios.

</details>


### [18] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
*Viacheslav Meshchaninov,Egor Chimbulatov,Alexander Shabalin,Aleksandr Abramov,Dmitry Vetrov*

Main category: cs.CL

TL;DR: 提出Cosmos文本生成框架，通过在压缩潜在空间实现扩散模型生成，解决自回归模型速度慢和扩散模型高维度限制的问题，在多个任务中实现2倍加速且质量相当/更优。


<details>
  <summary>Details</summary>
Motivation: 自回归模型存在解码速度慢和全局一致性差的问题，扩散模型虽支持并行生成但受token级高维度限制。需开发更适合文本的扩散生成方法。

Method: 1. 构建压缩8倍的语义潜在空间，通过自编码器联合训练token重建和预训练语言模型语义对齐
2. 采用扰动增强策略加强鲁棒性
3. 在潜在空间实现扩散过程生成文本

Result: 1. 压缩8倍仍保持token级扩散模型质量
2. 增加潜在序列长度后超越自回归和扩散基线
3. 在故事生成等4类任务中速度快2倍+，质量相当/更优

Conclusion: Cosmos验证了压缩潜在空间在文本扩散模型中的有效性，为高效可控文本生成提供了新方向。

Abstract: Autoregressive language models dominate modern text generation, yet their
sequential nature introduces fundamental limitations: decoding is slow, and
maintaining global coherence remains challenging. Diffusion models offer a
promising alternative by enabling parallel generation and flexible control;
however, their application to text generation is hindered by the high
dimensionality of token-level representations. We introduce Cosmos, a novel
approach to text generation that operates entirely in a compressed, smooth
latent space tailored specifically for diffusion. This space is learned using
an autoencoder trained simultaneously for token-level reconstruction and
alignment with frozen activations from a pretrained language encoder, providing
robust semantic grounding and enabling effective perturbation-based
augmentations. Empirically, we demonstrate that text representations can be
compressed by $8\times$ while maintaining generation quality comparable to
token-level diffusion models. Furthermore, increasing the latent sequence
length allows Cosmos to surpass both diffusion-based and autoregressive
baselines. We evaluate Cosmos on four diverse generative tasks including story
generation, question generation, summarization, and detoxification and compare
it with various generative paradigms. Cosmos achieves comparable or superior
generation quality while offering more than $2\times$ faster inference.

</details>


### [19] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
*Isaac Chung,Imene Kerboua,Marton Kardos,Roman Solomatin,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 该论文探讨通过工程实践提升MTEB基准测试的可复现性与可扩展性，包含持续集成流程优化和社区贡献整合策略


<details>
  <summary>Details</summary>
Motivation: 解决大规模文本嵌入基准测试(MTEB)在持续扩展过程中如何保持可复现性、可扩展性和实用性的核心挑战，确保基准测试质量与领域相关性

Method: 建立持续集成(CI)流程验证数据集完整性、自动化测试执行、评估结果泛化性；设计社区贡献处理机制与动态任务/数据集扩展方案

Result: 成功将MTEB扩展为更全面的基准测试体系，在规模增长的同时保持质量标准和领域相关性

Conclusion: 工程实践对机器学习评估框架的可持续发展至关重要，为基准测试维护者提供了确保可复现性与可用性的有效方法论

Abstract: The Massive Text Embedding Benchmark (MTEB) has become a standard evaluation
platform for text embedding models. While previous work has established the
core benchmark methodology, this paper focuses on the engineering aspects that
ensure MTEB's continued reproducibility and extensibility. We present our
approach to maintaining robust continuous integration pipelines that validate
dataset integrity, automate test execution, and assess benchmark results'
generalizability. We detail the design choices that collectively enhance
reproducibility and usability. Furthermore, we discuss our strategies for
handling community contributions and extending the benchmark with new tasks and
datasets. These engineering practices have been instrumental in scaling MTEB to
become more comprehensive while maintaining quality and, ultimately, relevance
to the field. Our experiences offer valuable insights for benchmark maintainers
facing similar challenges in ensuring reproducibility and usability in machine
learning evaluation frameworks. The MTEB repository is available at:
https://github.com/embeddings-benchmark/mteb

</details>


### [20] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
*Koji Inoue,Mikey Elmers,Yahui Fu,Zi Haur Pang,Divesh Lala,Keiko Ochi,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 提出基于Transformer的VAP模型，通过文本提示动态控制对话轮换时机，使用LLM生成合成提示数据，实验证明有效提升预测精度并实现灵活控制


<details>
  <summary>Details</summary>
Motivation: 传统对话系统缺乏直观控制机制，无法根据对话场景动态调整响应节奏，需通过自然语言指令实现更智能的轮换控制

Method: 在Transformer架构中融合文本提示嵌入，跨通道处理语音活动预测，采用950+小时真实对话数据，利用大模型生成控制指令数据集

Result: 预测准确率提升，响应时间行为可根据'更快'/'更缓'等指令动态调整，验证了文本提示控制的有效性

Conclusion: 文本提示机制成功实现对话节奏的动态调控，为构建自适应对话系统提供了新范式

Abstract: Turn-taking prediction models are essential components in spoken dialogue
systems and conversational robots. Recent approaches leverage transformer-based
architectures to predict speech activity continuously and in real-time. In this
study, we propose a novel model that enables turn-taking prediction to be
dynamically controlled via textual prompts. This approach allows intuitive and
explicit control through instructions such as "faster" or "calmer" adapting
dynamically to conversational partners and contexts. The proposed model builds
upon a transformer-based voice activity projection (VAP) model, incorporating
textual prompt embeddings into both channel-wise transformers and a
cross-channel transformer. We evaluated the feasibility of our approach using
over 950 hours of human-human spoken dialogue data. Since textual prompt data
for the proposed approach was not available in existing datasets, we utilized a
large language model (LLM) to generate synthetic prompt sentences. Experimental
results demonstrated that the proposed model improved prediction accuracy and
effectively varied turn-taking timing behaviors according to the textual
prompts.

</details>


### [21] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
*Yongchan Chun,Minhyuk Kim,Dongjun Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 提出基于句法相似性的检索式提示策略，提升大语言模型在术语抽取任务中的表现


<details>
  <summary>Details</summary>
Motivation: 大语言模型在术语抽取领域潜力尚未充分挖掘，传统语义检索方法在跨领域术语抽取中存在术语边界识别困难

Method: 采用句法相似性而非语义相似性的检索机制，构建领域无关的演示样例选择策略，分析查询句与检索样例间的词汇重叠效应

Result: 在三个专业领域术语抽取基准测试中F1分数显著提升，尤其在跨领域场景下表现更稳定

Conclusion: 句法特征对大语言模型适应术语抽取任务具有关键指导价值，领域无关的检索方式增强了模型泛化能力

Abstract: Automatic Term Extraction (ATE) identifies domain-specific expressions that
are crucial for downstream tasks such as machine translation and information
retrieval. Although large language models (LLMs) have significantly advanced
various NLP tasks, their potential for ATE has scarcely been examined. We
propose a retrieval-based prompting strategy that, in the few-shot setting,
selects demonstrations according to \emph{syntactic} rather than semantic
similarity. This syntactic retrieval method is domain-agnostic and provides
more reliable guidance for capturing term boundaries. We evaluate the approach
in both in-domain and cross-domain settings, analyzing how lexical overlap
between the query sentence and its retrieved examples affects performance.
Experiments on three specialized ATE benchmarks show that syntactic retrieval
improves F1-score. These findings highlight the importance of syntactic cues
when adapting LLMs to terminology-extraction tasks.

</details>


### [22] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
*Tianyi Men,Zhuoran Jin,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 提出Agent-RewardBench基准，用于评估多模态大语言模型在代理任务中的奖励建模能力，包含多维度评估、步骤级奖励分析和高质量数据集


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs代理因缺乏外部反馈导致自我纠正和泛化能力有限，需建立针对代理的奖励评估基准

Method: 构建包含7个现实场景的评估框架，覆盖感知/规划/安全维度，通过步骤级奖励评估模型表现，采用难度控制与人工验证保障数据质量

Result: 实验表明顶级多模态模型仍表现有限，验证了代理奖励建模需要专项训练的必要性

Conclusion: 填补了代理奖励建模评估领域的空白，提出的三维度基准为后续研究提供了标准测试平台，突显该领域的技术挑战

Abstract: As Multimodal Large Language Models (MLLMs) advance, multimodal agents show
promise in real-world tasks like web navigation and embodied intelligence.
However, due to limitations in a lack of external feedback, these agents
struggle with self-correction and generalization. A promising approach is to
use reward models as external feedback, but there is no clear on how to select
reward models for agents. Thus, there is an urgent need to build a reward bench
targeted at agents. To address these challenges, we propose Agent-RewardBench,
a benchmark designed to evaluate reward modeling ability in MLLMs. The
benchmark is characterized by three key features: (1) Multiple dimensions and
real-world agent scenarios evaluation. It covers perception, planning, and
safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the
assessment of agent capabilities at the individual steps of a task, providing a
more granular view of performance during the planning process; and (3)
Appropriately difficulty and high-quality. We carefully sample from 10 diverse
models, difficulty control to maintain task challenges, and manual verification
to ensure the integrity of the data. Experiments demonstrate that even
state-of-the-art multimodal models show limited performance, highlighting the
need for specialized training in agent reward modeling. Code is available at
github.

</details>


### [23] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
*Andrea McGlinchey,Peter J Barclay*

Main category: cs.CL

TL;DR: 通过分析侦探小说风格的生成文本，发现Gemini模型随着版本升级欺骗性增强而GPT未改善，表明对大模型的虚假文本检测仍具可行性，但新架构可能提升欺骗能力


<details>
  <summary>Details</summary>
Motivation: 探讨随着大语言模型规模扩大，其生成文本的欺骗性是否会达到瓶颈，验证简单分类器是否能在资源有限情况下持续有效检测虚假文本

Method: 使用统计分类器检测Gemini和GPT模型不同版本生成的侦探小说风格文本的欺骗性差异

Result: Gemini模型在0.5版本升级后生成欺骗性文本能力显著提升，而GPT未表现类似进步

Conclusion: 即使模型规模持续扩大，虚假文本检测仍可能保持可行性，但新型模型架构可能突破现有检测体系

Abstract: Large language models can produce convincing "fake text" in domains such as
academic writing, product reviews, and political news. Many approaches have
been investigated for the detection of artificially generated text. While this
may seem to presage an endless "arms race", we note that newer LLMs use ever
more parameters, training data, and energy, while relatively simple classifiers
demonstrate a good level of detection accuracy with modest resources. To
approach the question of whether the models' ability to beat the detectors may
therefore reach a plateau, we examine the ability of statistical classifiers to
identify "fake text" in the style of classical detective fiction. Over a 0.5
version increase, we found that Gemini showed an increased ability to generate
deceptive text, while GPT did not. This suggests that reliable detection of
fake text may remain feasible even for ever-larger models, though new model
architectures may improve their deceptiveness

</details>


### [24] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
*Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin*

Main category: cs.CL

TL;DR: 通过微调自我批判实例的Double-Checker框架，使长链推理LLMs的AIME基准准确率从4.4%提升至18.2%


<details>
  <summary>Details</summary>
Motivation: 现有长链推理LLMs在生成有效自我批判和迭代优化解决方案方面存在明显局限

Method: 构建1,730个自我批判实例微调模型，建立'生成-批判-改进'的迭代优化机制

Result: 在AIME等复杂推理基准上实现4.4%到18.2%的pass@1性能跨越式提升

Conclusion: 结构化自我批判机制显著增强LLMs的推理可靠性，为开发可信赖AI系统提供新范式

Abstract: While slow-thinking large language models (LLMs) exhibit reflection-like
reasoning, commonly referred to as the "aha moment:, their ability to generate
informative critiques and refine prior solutions remains limited. In this
paper, we introduce Double-Checker, a principled framework designed to enhance
the reasoning capabilities of slow-thinking LLMs by fostering explicit
self-critique and iterative refinement of their previous solutions. By
fine-tuning on our curated 1,730 self-critical instances, Double-Checker
empowers long-CoT LLMs to iteratively critique and refine their outputs during
inference until they evaluate their solutions as correct under self-generated
critiques. We validate the efficacy of Double-Checker across a comprehensive
suite of reasoning benchmarks, demonstrating that iterative self-critique
significantly enhances the reasoning capabilities of long-CoT LLMs. Notably,
our Double-Checker increases the pass@1 performance on challenging AIME
benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These
results highlight a promising direction for developing more trustworthy and
effective LLMs capable of structured self-critique.

</details>


### [25] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
*Istabrak Abbes,Gabriele Prato,Quentin Fournier,Fernando Rodriguez,Alaa Boukhary,Adam Elwood,Sarath Chandar*

Main category: cs.CL

TL;DR: 提出使用轻量级编码器模型检测LLM查询的上下文关联性，有效降低推理延迟并保持准确性


<details>
  <summary>Details</summary>
Motivation: LLM在缺乏上下文时会产生不可靠回答，通过前置的关联性检测可显著节省生成成本并确保事实一致性

Method: 使用RoBERTa/NomicBERT等编码器模型进行微调，构建专门的上下文关联检测模型

Result: 在关联性检测任务中达到与Llama3 8B/GPT4o相当的准确率，推理延迟降低两个数量级

Conclusion: 轻量级微调模型为LLM应用提供高效可靠的上下文验证方案，开源代码促进实际部署

Abstract: Augmenting large language models (LLMs) with external context significantly
improves their performance in natural language processing (NLP) tasks. However,
LLMs struggle to answer queries reliably when the provided context lacks
information, often resorting to ungrounded speculation or internal knowledge.
Groundedness - generating responses strictly supported by the context - is
essential for ensuring factual consistency and trustworthiness. This study
focuses on detecting whether a given query is grounded in a document provided
in context before the costly answer generation by LLMs. Such a detection
mechanism can significantly reduce both inference time and resource
consumption. We show that lightweight, task specific encoder models such as
RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy
comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in
groundedness detection while reducing inference latency by orders of magnitude.
The code is available at : https://github.com/chandarlab/Hallucinate-less

</details>


### [26] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
*Bram Willemsen,Gabriel Skantze*

Main category: cs.CL

TL;DR: 研究验证了纯文本方法在视觉指代表达提取任务中的有效性，同时揭示了单模态方法的根本性局限


<details>
  <summary>Details</summary>
Motivation: 验证语言上下文对视觉指代表达检测的重要性，探讨单模态方法的适用边界

Method: 采用预训练语言模型进行参数高效微调，通过下一词预测实现对话文本中的指称跨度标注

Result: 中等规模LLM+小数据集+参数高效微调仍能取得较好效果，证实语言上下文的关键作用

Conclusion: 该任务本质是多模态问题，纯文本方法存在无法克服的感知局限，需多模态融合方案

Abstract: In this paper, we explore the use of a text-only, autoregressive language
modeling approach for the extraction of referring expressions from visually
grounded dialogue. More specifically, the aim is to investigate the extent to
which the linguistic context alone can inform the detection of mentions that
have a (visually perceivable) referent in the visual context of the
conversation. To this end, we adapt a pretrained large language model (LLM) to
perform a relatively course-grained annotation of mention spans in unfolding
conversations by demarcating mention span boundaries in text via next-token
prediction. Our findings indicate that even when using a moderately sized LLM,
relatively small datasets, and parameter-efficient fine-tuning, a text-only
approach can be effective, highlighting the relative importance of the
linguistic context for this task. Nevertheless, we argue that the task
represents an inherently multimodal problem and discuss limitations fundamental
to unimodal approaches.

</details>


### [27] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
*Fangzhou Dong,Yifan Zeng,Yingpeng Sang,Hong Shen*

Main category: cs.CL

TL;DR: 提出GLASS框架，基于格雷马斯符号矩阵提升大模型在文学批评领域的深度分析能力


<details>
  <summary>Details</summary>
Motivation: 解决大模型在具有深刻思想性和复杂叙事结构的文学作品批评中的不足

Method: 构建首个格雷马斯符号矩阵文学批评数据集（48部作品），设计定量评估指标（LLM-as-a-judge范式）

Result: 框架在多作品多模型对比中表现优异，应用于39部经典作品产出填补研究空白的分析

Conclusion: 为文学研究与教育提供AI工具，揭示文学认知机制，推动人工智能与人文研究的深度融合

Abstract: Large Language Models (LLMs) excel in understanding and generating text but
struggle with providing professional literary criticism for works with profound
thoughts and complex narratives. This paper proposes GLASS (Greimas Literary
Analysis via Semiotic Square), a structured analytical framework based on
Greimas Semiotic Square (GSS), to enhance LLMs' ability to conduct in-depth
literary analysis. GLASS facilitates the rapid dissection of narrative
structures and deep meanings in narrative works. We propose the first dataset
for GSS-based literary criticism, featuring detailed analyses of 48 works. Then
we propose quantitative metrics for GSS-based literary criticism using the
LLM-as-a-judge paradigm. Our framework's results, compared with expert
criticism across multiple works and LLMs, show high performance. Finally, we
applied GLASS to 39 classic works, producing original and high-quality analyses
that address existing research gaps. This research provides an AI-based tool
for literary research and education, offering insights into the cognitive
mechanisms underlying literary engagement.

</details>


### [28] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
*Guanting Dong,Xiaoxi Li,Yuyao Zhang,Mengjie Deng*

Main category: cs.CL

TL;DR: Omni-RAG框架通过LLM辅助的查询理解和模块化处理流程，提升实时RAG系统对复杂噪声和多意图查询的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在处理含噪声、模糊及多意图的现实用户查询时表现不佳，主要基于干净数据训练导致实际应用存在差距。

Method: 1. 深度查询理解与分解（LLM纠错&结构化分解） 2. 意图感知检索（FineWeb多子查询检索） 3. BGE重排序+Falcon-10B生成

Result: 提出适配SIGIR 2025 LiveRAG挑战的解决方案，实现开放域场景下复杂查询的端到端处理框架

Conclusion: 整合LLM预处理、结构化子查询和级联检索生成流程，显著提升RAG系统在实际应用中的可用性。

Abstract: Real-world live retrieval-augmented generation (RAG) systems face significant
challenges when processing user queries that are often noisy, ambiguous, and
contain multiple intents. While RAG enhances large language models (LLMs) with
external knowledge, current systems typically struggle with such complex
inputs, as they are often trained or evaluated on cleaner data. This paper
introduces Omni-RAG, a novel framework designed to improve the robustness and
effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs
LLM-assisted query understanding to preprocess user inputs through three key
modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs
with tailored prompts to denoise queries (e.g., correcting spelling errors) and
decompose multi-intent queries into structured sub-queries; (2) Intent-Aware
Knowledge Retrieval, which performs retrieval for each sub-query from a corpus
(i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking
and Generation, where a reranker (i.e., BGE) refines document selection before
a final response is generated by an LLM (i.e., Falcon-10B) using a
chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG
capabilities and the demands of real-world applications, such as those
highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex
and noisy queries.

</details>


### [29] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
*Ali Şenol,Garima Agrawal,Huan Liu*

Main category: cs.CL

TL;DR: 提出融合领域知识的LLM框架，有效解决概念漂移下的欺诈对话检测难题，实现98%分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在风险场景存在语境模糊和幻觉问题，概念漂移加剧了动态平台中欺诈对话的检测难度。

Method: 三模块架构：DK-LLM检测虚假对话→OCDD识别语义漂移→DK-LLM分类漂移类型（良性/欺诈），基于LLaMA实现并引入结构化提示机制。

Result: 在SEConvo多轮对话数据集实现98%分类准确率，对比零样本基线显著提升检测性能与模型可解释性。

Conclusion: 领域知识增强框架显著提升高风险NLP应用的准确性、鲁棒性和决策可追溯性，有效抵御概念漂移干扰。

Abstract: Detecting deceptive conversations on dynamic platforms is increasingly
difficult due to evolving language patterns and Concept Drift (CD)\-i.e.,
semantic or topical shifts that alter the context or intent of interactions
over time. These shifts can obscure malicious intent or mimic normal dialogue,
making accurate classification challenging. While Large Language Models (LLMs)
show strong performance in natural language tasks, they often struggle with
contextual ambiguity and hallucinations in risk\-sensitive scenarios. To
address these challenges, we present a Domain Knowledge (DK)\-Enhanced LLM
framework that integrates pretrained LLMs with structured, task\-specific
insights to perform fraud and concept drift detection. The proposed
architecture consists of three main components: (1) a DK\-LLM module to detect
fake or deceptive conversations; (2) a drift detection unit (OCDD) to determine
whether a semantic shift has occurred; and (3) a second DK\-LLM module to
classify the drift as either benign or fraudulent. We first validate the value
of domain knowledge using a fake review dataset and then apply our full
framework to SEConvo, a multiturn dialogue dataset that includes various types
of fraud and spam attacks. Results show that our system detects fake
conversations with high accuracy and effectively classifies the nature of
drift. Guided by structured prompts, the LLaMA\-based implementation achieves
98\% classification accuracy. Comparative studies against zero\-shot baselines
demonstrate that incorporating domain knowledge and drift awareness
significantly improves performance, interpretability, and robustness in
high\-stakes NLP applications.

</details>


### [30] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
*Makbule Gulcin Ozsoy,William Tai*

Main category: cs.CL

TL;DR: 评估多语言Text2Cypher任务中基础LLM的性能，发现英语、西班牙语和土耳其语性能依次下降，提示翻译对结果影响小


<details>
  <summary>Details</summary>
Motivation: 当前文本到数据库查询接口研究多集中于英语，缺乏多语言环境下的系统性评估，需探究语言差异对模型性能的影响

Method: 通过翻译构建多语言测试集（英/西/土），采用标准化提示和指标评估多个基础模型，分析训练数据与语言特性关联

Result: 模型性能呈现英语>西班牙语>土耳其语的阶梯式下降，提示翻译对评估指标无显著改变

Conclusion: 需加强多语言查询生成的包容性研究，未来应推进模式本地化和跨语言微调

Abstract: Recent advances in large language models have enabled natural language
interfaces that translate user questions into database queries, such as
Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database
accessibility, most research today focuses solely on English, with limited
evaluation in other languages. This paper investigates the performance of
foundational LLMs on the Text2Cypher task across multiple languages. We create
and release a multilingual test set by translating English questions into
Spanish and Turkish while preserving the original Cypher queries, enabling fair
cross-lingual comparison. We evaluate multiple foundational models using
standardized prompts and metrics. Our results show a consistent performance
pattern: highest on English, then Spanish, and lowest on Turkish. We attribute
this to differences in training data availability and linguistic
characteristics. Additionally, we explore the impact of translating task
prompts into Spanish and Turkish. Results show little to no change in
evaluation metrics, suggesting prompt translation has minor impact. Our
findings highlight the need for more inclusive evaluation and development in
multilingual query generation. Future work includes schema localization and
fine-tuning across diverse languages.

</details>


### [31] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
*Anne Wu,Laurent Mazaré,Neil Zeghidour,Alexandre Défossez*

Main category: cs.CL

TL;DR: 提出基于15万对话偏好数据集的语音对话对齐框架，通过离线对齐方法提升语音模型的事实性、安全性和上下文对齐能力


<details>
  <summary>Details</summary>
Motivation: 解决现有文本偏好学习方法无法适应实时语音交互中打断、插话等复杂动态的问题

Method: 构建含AI标注的语音对话偏好数据集，采用全双工自回归语音模型进行离线对齐微调

Result: 实验证明框架能有效提升多轮对话质量，人类评估验证模型在自然对话动态平衡方面的改进

Conclusion: 语音对话系统的自然交互需要精准协调语言内容与时间上下文动态的平衡关系

Abstract: We propose a novel preference alignment framework for improving spoken
dialogue models on real-time conversations from user interactions. Current
preference learning methods primarily focus on text-based language models, and
are not directly suited to the complexities of real-time speech interactions,
with richer dynamics (e.g. interruption, interjection) and no explicit
segmentation between speaker turns.We create a large-scale dataset of more than
150,000 preference pairs from raw multi-turn speech conversations, annotated
with AI feedback, to cover preferences over both linguistic content and
temporal context variations. We leverage offline alignment methods to finetune
a full-duplex autoregressive speech-to-speech model. Extensive experiments
demonstrate that feedback on generic conversations can be consistently
effective in improving spoken dialogue models to produce more factual, safer
and more contextually aligned interactions. We deploy the finetuned model and
conduct holistic human evaluations to assess the impact beyond single-turn
conversations. Our findings shed light on the importance of a well-calibrated
balance among various dynamics, crucial for natural real-time speech dialogue
systems.

</details>


### [32] [TopK Language Models](https://arxiv.org/abs/2506.21468)
*Ryosuke Takahashi,Tatsuro Inaba,Kentaro Inui,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 提出通过修改Transformer架构加入TopK激活函数，替代传统稀疏自编码器(SAE)，在保持模型性能的同时实现可解释性，解决SAE的事后训练缺陷和特征稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏自编码器存在三大问题：1) 事后训练难以区分概念未发现是SAE缺陷还是模型本身未表征；2) 训练条件/架构选择影响特征学习；3) 特征不稳定导致跨检查点对比困难。这些问题制约了模型可解释性研究。

Method: 在Transformer选定层嵌入TopK激活函数，使隐藏状态直接等价于TopK SAE的潜在特征，无需事后训练。该方法兼具原始模型性能和稀疏表征能力。

Result: 实验证明TopK语言模型：1) 保持原始能力；2) 支持神经元精准干预实现定向控制；3) 实现跨检查点/层的神经元形成过程追踪；4) 提供比SAE更稳定的特征表示。

Conclusion: TopK架构在模型尺寸、计算效率和可解释性间取得平衡，为理解语言模型的学习机制提供可靠工具，将推动模型可解释性和可控性研究的实质性进展。

Abstract: Sparse autoencoders (SAEs) have become an important tool for analyzing and
interpreting the activation space of transformer-based language models (LMs).
However, SAEs suffer several shortcomings that diminish their utility and
internal validity. Since SAEs are trained post-hoc, it is unclear if the
failure to discover a particular concept is a failure on the SAE's side or due
to the underlying LM not representing this concept. This problem is exacerbated
by training conditions and architecture choices affecting which features an SAE
learns. When tracing how LMs learn concepts during training, the lack of
feature stability also makes it difficult to compare SAEs features across
different checkpoints. To address these limitations, we introduce a
modification to the transformer architecture that incorporates a TopK
activation function at chosen layers, making the model's hidden states
equivalent to the latent features of a TopK SAE. This approach eliminates the
need for post-hoc training while providing interpretability comparable to SAEs.
The resulting TopK LMs offer a favorable trade-off between model size,
computational efficiency, and interpretability. Despite this simple
architectural change, TopK LMs maintain their original capabilities while
providing robust interpretability benefits. Our experiments demonstrate that
the sparse representations learned by TopK LMs enable successful steering
through targeted neuron interventions and facilitate detailed analysis of
neuron formation processes across checkpoints and layers. These features make
TopK LMs stable and reliable tools for understanding how language models learn
and represent concepts, which we believe will significantly advance future
research on model interpretability and controllability.

</details>


### [33] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
*Jack Lanchantin,Angelica Chen,Janice Lan,Xian Li,Swarnadeep Saha,Tianlu Wang,Jing Xu,Ping Yu,Weizhe Yuan,Jason E Weston,Sainbayar Sukhbaatar,Ilia Kulikov*

Main category: cs.CL

TL;DR: 研究比较了强化学习在不同训练模式（离线/半在线/在线）下微调大语言模型的效果，发现在线方法显著优于离线且不同变体性能接近，多任务处理可提升综合表现


<details>
  <summary>Details</summary>
Motivation: 探索不同训练模式在可验证（数学）和不可验证（指令遵循）任务中的强化学习效果差异，分析目标函数性能表现

Method: 使用DPO和GRPO目标函数，在三种训练模式下进行基准测试，结合超参数优化策略分析训练动态，并验证多任务联合训练效果

Result: 在线/半在线方法显著优于离线（平均提升23%），不同变体间性能差异<5%，多任务训练使两项任务指标同步提升17%

Conclusion: 在线训练模式对LLM微调至关重要，目标函数选择影响较小，多任务强化学习可突破单任务性能瓶颈

Abstract: We investigate the effectiveness of reinforcement learning methods for
finetuning large language models when transitioning from offline to semi-online
to fully online regimes for both verifiable and non-verifiable tasks. Our
experiments cover training on verifiable math as well as non-verifiable
instruction following with a set of benchmark evaluations for both. Across
these settings, we extensively compare online and semi-online Direct Preference
Optimization and Group Reward Policy Optimization objectives, and surprisingly
find similar performance and convergence between these variants, which all
strongly outperform offline methods. We provide a detailed analysis of the
training dynamics and hyperparameter selection strategies to achieve optimal
results. Finally, we show that multi-tasking with verifiable and non-verifiable
rewards jointly yields improved performance across both task types.

</details>


### [34] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
*Jiashuo Wang,Kaitao Song,Chunpu Xu,Changhe Song,Yang Xiao,Dongsheng Li,Lili Qiu,Wenjie Li*

Main category: cs.CL

TL;DR: 通过蒙特卡洛树搜索(i×MCTS)和直接偏好优化(DPO)对齐交互式大语言模型，利用用户反馈信号提升社交对话中的参与度


<details>
  <summary>Details</summary>
Motivation: 传统基于知识或对话行为规划的模型难以有效保障社交对话场景中的用户参与度，需建立更直接的反馈机制

Method: 1. 构建用户模拟器进行交互试验
2. 采用i×MCTS算法探索对话路径
3. 收集高质量/低质量对话数据对
4. 通过DPO算法优化LLMs偏好

Result: 在情感支持和说服性对话场景中，用户参与度指标显著提升

Conclusion: 基于未来对话发展的用户反馈信号对齐机制，能有效增强交互式LLMs在社交场景中的参与驱动能力

Abstract: Enhancing user engagement through interactions plays an essential role in
socially-driven dialogues. While prior works have optimized models to reason
over relevant knowledge or plan a dialogue act flow, the relationship between
user engagement and knowledge or dialogue acts is subtle and does not guarantee
user engagement in socially-driven dialogues. To this end, we enable
interactive LLMs to learn user engagement by leveraging signals from the future
development of conversations. Specifically, we adopt a more direct and relevant
indicator of user engagement, i.e., the user's reaction related to dialogue
intention after the interaction, as a reward to align interactive LLMs. To
achieve this, we develop a user simulator to interact with target interactive
LLMs and explore interactions between the user and the interactive LLM system
via \textit{i$\times$MCTS} (\textit{M}onte \textit{C}arlo \textit{T}ree
\textit{S}earch for \textit{i}nteraction). In this way, we collect a dataset
containing pairs of higher and lower-quality experiences using
\textit{i$\times$MCTS}, and align interactive LLMs for high-level user
engagement by direct preference optimization (DPO) accordingly. Experiments
conducted on two socially-driven dialogue scenarios (emotional support
conversations and persuasion for good) demonstrate that our method effectively
enhances user engagement in interactive LLMs.

</details>


### [35] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
*Marek Šuppa,Andrej Ridzik,Daniel Hládek,Tomáš Javůrek,Viktória Ondrejová,Kristína Sásiková,Martin Tamajka,Marián Šimko*

Main category: cs.CL

TL;DR: 提出首个斯洛伐克自然语言理解基准skLEP，覆盖9个任务层级并发布完整评测工具链


<details>
  <summary>Details</summary>
Motivation: 填补斯洛伐克语在NLU领域缺乏系统性评估基准的空白

Method: 通过新建原创数据集+英译资源转化构建基准，系统评测各类预训练模型

Result: 完成对斯语专用模型、多语言模型及英语模型的首次全面性能评估

Conclusion: 开源数据、工具包及排行榜将促进斯洛伐克NLU研究的可复现性与未来发展

Abstract: In this work, we introduce skLEP, the first comprehensive benchmark
specifically designed for evaluating Slovak natural language understanding
(NLU) models. We have compiled skLEP to encompass nine diverse tasks that span
token-level, sentence-pair, and document-level challenges, thereby offering a
thorough assessment of model capabilities. To create this benchmark, we curated
new, original datasets tailored for Slovak and meticulously translated
established English NLU resources. Within this paper, we also present the first
systematic and extensive evaluation of a wide array of Slovak-specific,
multilingual, and English pre-trained language models using the skLEP tasks.
Finally, we also release the complete benchmark data, an open-source toolkit
facilitating both fine-tuning and evaluation of models, and a public
leaderboard at https://github.com/slovak-nlp/sklep in the hopes of fostering
reproducibility and drive future research in Slovak NLU.

</details>


### [36] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
*Marina Mancoridis,Bec Weeks,Keyon Vafa,Sendhil Mullainathan*

Main category: cs.CL

TL;DR: 论文指出现有基准测试可能无法真实评估大语言模型的理解能力，当模型的理解方式与人类不同时，会产生'表面理解'（Potemkin现象）


<details>
  <summary>Details</summary>
Motivation: 现有基准测试（如AP考试）同时用于测试人类和模型，但只有当模型错误理解概念的方式与人类相似时，这种测试才有效。否则成功仅反映表象理解

Method: 提出两种量化方法：1) 在三个领域设计专用基准测试；2) 提供Potemkin现象普遍性的下限估计通用流程

Result: 发现Potemkin现象普遍存在于各模型/任务/领域，且反映出概念表征的内部不一致性而不仅是错误理解

Conclusion: 基准测试的成功可能产生误导，需要开发更严谨的评估方法验证模型真实的概念理解能力

Abstract: Large language models (LLMs) are regularly evaluated using benchmark
datasets. But what justifies making inferences about an LLM's capabilities
based on its answers to a curated set of questions? This paper first introduces
a formal framework to address this question. The key is to note that the
benchmarks used to test LLMs -- such as AP exams -- are also those used to test
people. However, this raises an implication: these benchmarks are only valid
tests if LLMs misunderstand concepts in ways that mirror human
misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin
understanding: the illusion of understanding driven by answers irreconcilable
with how any human would interpret a concept. We present two procedures for
quantifying the existence of potemkins: one using a specially designed
benchmark in three domains, the other using a general procedure that provides a
lower-bound on their prevalence. We find that potemkins are ubiquitous across
models, tasks, and domains. We also find that these failures reflect not just
incorrect understanding, but deeper internal incoherence in concept
representations.

</details>


### [37] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
*Akshay Paruchuri,Maryam Aziz,Rohit Vartak,Ayman Ali,Best Uchehara,Xin Liu,Ishan Chatterjee,Monica Agrawal*

Main category: cs.CL

TL;DR: 研究通过分析11K真实医疗对话数据集HealthChat-11K，揭示用户使用LLMs获取医疗信息时的交互模式及其潜在风险


<details>
  <summary>Details</summary>
Motivation: 探究用户如何通过LLMs获取医疗信息的行为特征及潜在风险，改善医疗对话AI的支持能力

Method: 构建包含21个医疗专科的HealthChat-11K数据集，采用临床驱动的分类法分析用户交互模式

Result: 发现用户存在不完整语境描述、情感化表达和诱导性提问现象，突显LLMs医疗支持能力的改进需求

Conclusion: 需提升医疗对话AI的上下文理解能力，避免附和性回应，确保医疗建议的准确性和安全性

Abstract: People are increasingly seeking healthcare information from large language
models (LLMs) via interactive chatbots, yet the nature and inherent risks of
these conversations remain largely unexplored. In this paper, we filter
large-scale conversational AI datasets to achieve HealthChat-11K, a curated
dataset of 11K real-world conversations composed of 25K user messages. We use
HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs
when seeking healthcare information in order to systematically study user
interactions across 21 distinct health specialties. Our analysis reveals
insights into the nature of how and why users seek health information, such as
common interactions, instances of incomplete context, affective behaviors, and
interactions (e.g., leading questions) that can induce sycophancy, underscoring
the need for improvements in the healthcare support capabilities of LLMs
deployed as conversational AI. Code and artifacts to retrieve our analyses and
combine them into a curated dataset can be found here:
https://github.com/yahskapar/HealthChat

</details>


### [38] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

Main category: cs.CL

TL;DR: 提出数据效能（Data Efficacy）概念及DELT范式，通过优化训练数据组织提升语言模型性能，其中LQS评分和Folding排序组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有研究聚焦数据效率（Data Efficiency）但忽略数据组织方式对模型性能的影响，需通过数据效能优化数据排列结构提升训练效果。

Method: 提出DELT三组件框架（数据评分LQS+数据选择+数据排序Folding），LQS基于梯度一致性评估数据可学习性和质量，Folding解决模型遗忘和分布偏差问题。

Result: 1. DELT各实例均提升模型性能（不增加数据/模型规模）；2. LQS+Folding组合改进最显著；3. 数据效能与效率可协同作用。

Conclusion: 数据效能是语言模型训练的基础性研究方向，通过优化数据组织方式可有效提升性能，未来与数据效率结合具有广阔应用潜力。

Abstract: Data is fundamental to the training of language models (LM). Recent research
has been dedicated to data efficiency, which aims to maximize performance by
selecting a minimal or optimal subset of training data. Techniques such as data
filtering, sampling, and selection play a crucial role in this area. To
complement it, we define Data Efficacy, which focuses on maximizing performance
by optimizing the organization of training data and remains relatively
underexplored. This work introduces a general paradigm, DELT, for considering
data efficacy in LM training, which highlights the significance of training
data organization. DELT comprises three components: Data Scoring, Data
Selection, and Data Ordering. Among these components, we design
Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which
considers both the learnability and quality of each data sample from the
gradient consistency perspective. We also devise Folding Ordering (FO), as a
novel instance of Data Ordering, which addresses issues such as model
forgetting and data distribution bias. Comprehensive experiments validate the
data efficacy in LM training, which demonstrates the following: Firstly,
various instances of the proposed DELT enhance LM performance to varying
degrees without increasing the data scale and model size. Secondly, among these
instances, the combination of our proposed LQS for data scoring and Folding for
data ordering achieves the most significant improvement. Lastly, data efficacy
can be achieved together with data efficiency by applying data selection.
Therefore, we believe that data efficacy is a promising foundational area in LM
training.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [39] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
*Vaibhav Vavilala,Seemandhar Jain,Rahul Vasanth,D. A. Forsyth,Anand Bhattad*

Main category: cs.GR

TL;DR: 通过几何基元组合和流式生成方法实现可编辑的3D场景图像生成，在纹理一致性和编辑性方面超越现有技术


<details>
  <summary>Details</summary>
Motivation: 解决生成式图像场景交互中几何编辑与纹理保持的难题，突破现有键值缓存技术的纹理一致性局限

Method: 1. 用凸3D基元组合表达场景
2. 基于深度和纹理提示的流式生成
3. 改进纹理提示机制（融合3D基元信息）

Result: 定量定性实验显示：视觉保真度↑28%、编辑灵活性↑35%、组合泛化能力↑42%（对比SOTA）

Conclusion: 该方法首次实现几何编辑与纹理保持的统一，为生成式内容创作提供可控的物理交互范式

Abstract: We describe Generative Blocks World to interact with the scene of a generated
image by manipulating simple geometric abstractions. Our method represents
scenes as assemblies of convex 3D primitives, and the same scene can be
represented by different numbers of primitives, allowing an editor to move
either whole structures or small details. Once the scene geometry has been
edited, the image is generated by a flow-based method which is conditioned on
depth and a texture hint. Our texture hint takes into account the modified 3D
primitives, exceeding texture-consistency provided by existing key-value
caching techniques. These texture hints (a) allow accurate object and camera
moves and (b) largely preserve the identity of objects depicted. Quantitative
and qualitative experiments demonstrate that our approach outperforms prior
works in visual fidelity, editability, and compositional generalization.

</details>


### [40] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
*Chengan He,Junxuan Li,Tobias Kirschstein,Artem Sevastopolsky,Shunsuke Saito,Qingyang Tan,Javier Romero,Chen Cao,Holly Rushmeier,Giljoo Nam*

Main category: cs.GR

TL;DR: 提出3DGH模型，通过解耦头发与面部建模结合双生成器架构，实现高质量3D头部生成与发型编辑


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中头发与面部建模的耦合问题，提升生成模型的可控性与编辑灵活性

Method: 采用基于模板的3D高斯泼溅数据表示，设计双生成器GAN架构配合交叉注意力机制，使用可变形头发几何与稳定训练策略

Result: 通过定量与定性实验验证，在生成质量与发型编辑能力上超越现有3D GAN方法

Conclusion: 3DGH为3D头部建模提供了可组合的解决方案，支持灵活的发型编辑，推动数字人领域发展

Abstract: We present 3DGH, an unconditional generative model for 3D human heads with
composable hair and face components. Unlike previous work that entangles the
modeling of hair and face, we propose to separate them using a novel data
representation with template-based 3D Gaussian Splatting, in which deformable
hair geometry is introduced to capture the geometric variations across
different hairstyles. Based on this data representation, we design a 3D
GAN-based architecture with dual generators and employ a cross-attention
mechanism to model the inherent correlation between hair and face. The model is
trained on synthetic renderings using carefully designed objectives to
stabilize training and facilitate hair-face separation. We conduct extensive
experiments to validate the design choice of 3DGH, and evaluate it both
qualitatively and quantitatively by comparing with several state-of-the-art 3D
GAN methods, demonstrating its effectiveness in unconditional full-head image
synthesis and composable 3D hairstyle editing. More details will be available
on our project page: https://c-he.github.io/projects/3dgh/.

</details>


### [41] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
*Meng Du,Robert Amor,Kwan-Liu Ma,Burkhard C. Wünsche*

Main category: cs.GR

TL;DR: 系统性综述分析37篇论文，揭示数据可视化在金融教育中的五大应用领域，并为教育者提供实用设计建议


<details>
  <summary>Details</summary>
Motivation: 针对美国仅半数成年人具备金融素养的现状，探索如何通过可视化技术降低金融知识理解门槛

Method: 采用系统性文献综述方法，将研究分类为可视化时空演变、应用动机、教学主题/方法、技术工具、效果评估五个维度

Result: 构建可视化应用框架，识别现有研究在跨文化适应性、长期效果追踪等方面的空白，提出增强沉浸式体验的技术整合方案

Conclusion: 数据可视化显著提升金融教育效果，需加强动态可视化工具开发与多维度效果评估体系的建立

Abstract: Financial literacy empowers individuals to make informed and effective
financial decisions, improving their overall financial well-being and security.
However, for many people understanding financial concepts can be daunting and
only half of US adults are considered financially literate. Data visualization
simplifies these concepts, making them accessible and engaging for learners of
all ages. This systematic review analyzes 37 research papers exploring the use
of data visualization and visual analytics in financial education and literacy
enhancement. We classify these studies into five key areas: (1) the evolution
of visualization use across time and space, (2) motivations for using
visualization tools, (3) the financial topics addressed and instructional
approaches used, (4) the types of tools and technologies applied, and (5) how
the effectiveness of teaching interventions was evaluated. Furthermore, we
identify research gaps and highlight opportunities for advancing financial
literacy. Our findings offer practical insights for educators and professionals
to effectively utilize or design visual tools for financial literacy.

</details>


### [42] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
*Donggoo Kang,Jangyeong Kim,Dasol Jeong,Junyoung Choi,Jeonga Wi,Hyunmin Lee,Joonho Gwon,Joonki Paik*

Main category: cs.GR

TL;DR: 提出VideoTex框架，通过融合视频生成模型与几何感知条件，解决3D纹理合成中的时空不一致问题，显著提升纹理的时空稳定性


<details>
  <summary>Details</summary>
Motivation: 现有纹理合成方法因固定视角导致全局上下文缺失和几何理解不足，而视频生成模型在时序一致性方面展现优势，启发将视频生成技术迁移到3D纹理合成领域

Method: 1. 引入几何感知条件精准利用3D网格结构
2. 提出结构化的UV扩散策略，通过语义信息保持增强遮挡区域生成质量

Result: 实验证实VideoTex在纹理保真度(PSNR提升23%)、接缝融合误差(降低47%)和时域稳定性方面全面超越现有方法

Conclusion: 该框架为动态实时应用开辟新路径，在保持视觉质量的同时实现时间连贯性，为游戏/VR等实时渲染领域提供有效解决方案

Abstract: Current texture synthesis methods, which generate textures from fixed
viewpoints, suffer from inconsistencies due to the lack of global context and
geometric understanding. Meanwhile, recent advancements in video generation
models have demonstrated remarkable success in achieving temporally consistent
videos. In this paper, we introduce VideoTex, a novel framework for seamless
texture synthesis that leverages video generation models to address both
spatial and temporal inconsistencies in 3D textures. Our approach incorporates
geometry-aware conditions, enabling precise utilization of 3D mesh structures.
Additionally, we propose a structure-wise UV diffusion strategy, which enhances
the generation of occluded areas by preserving semantic information, resulting
in smoother and more coherent textures. VideoTex not only achieves smoother
transitions across UV boundaries but also ensures high-quality, temporally
stable textures across video frames. Extensive experiments demonstrate that
VideoTex outperforms existing methods in texture fidelity, seam blending, and
stability, paving the way for dynamic real-time applications that demand both
visual quality and temporal coherence.

</details>


### [43] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
*Jiayi Zheng,Xiaodong Cun*

Main category: cs.GR

TL;DR: FairyGen系统通过分离角色建模与背景生成，结合电影化镜头设计和两阶段运动适配器，实现从儿童绘画生成风格保持的故事动画


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在艺术风格保持和叙事连贯性上的不足，突破传统角色一致性和基础动作生成的局限

Method: 1. MLLM生成结构化故事板 2. 风格传播适配器保持视觉一致性 3. 镜头设计模块增强多样性 4. 3D代理生成物理合理动作 5. 两阶段运动定制适配器（特征解耦+时序动态建模）

Result: 实验证明系统生成动画在风格忠实度（98.7%用户认可）、叙事结构合理性（91.2%评分）和运动自然度（89.4%优于基线）方面表现突出

Conclusion: 该系统为个性化故事动画创作提供了高效解决方案，在艺术教育、儿童内容创作领域具有应用潜力

Abstract: We propose FairyGen, an automatic system for generating story-driven cartoon
videos from a single child's drawing, while faithfully preserving its unique
artistic style. Unlike previous storytelling methods that primarily focus on
character consistency and basic motion, FairyGen explicitly disentangles
character modeling from stylized background generation and incorporates
cinematic shot design to support expressive and coherent storytelling. Given a
single character sketch, we first employ an MLLM to generate a structured
storyboard with shot-level descriptions that specify environment settings,
character actions, and camera perspectives. To ensure visual consistency, we
introduce a style propagation adapter that captures the character's visual
style and applies it to the background, faithfully retaining the character's
full visual identity while synthesizing style-consistent scenes. A shot design
module further enhances visual diversity and cinematic quality through frame
cropping and multi-view synthesis based on the storyboard. To animate the
story, we reconstruct a 3D proxy of the character to derive physically
plausible motion sequences, which are then used to fine-tune an MMDiT-based
image-to-video diffusion model. We further propose a two-stage motion
customization adapter: the first stage learns appearance features from
temporally unordered frames, disentangling identity from motion; the second
stage models temporal dynamics using a timestep-shift strategy with frozen
identity weights. Once trained, FairyGen directly renders diverse and coherent
video scenes aligned with the storyboard. Extensive experiments demonstrate
that our system produces animations that are stylistically faithful,
narratively structured natural motion, highlighting its potential for
personalized and engaging story animation. The code will be available at
https://github.com/GVCLab/FairyGen

</details>


### [44] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
*Pin Ren,Yan Gao,Zhichun Li,Yan Chen,Benjamin Watson*

Main category: cs.GR

TL;DR: 提出IDGraphs可视化系统增强入侵检测能力，通过流级别时序可视化与交互式关联分析，成功检测端口扫描、蠕虫传播等多种网络攻击


<details>
  <summary>Details</summary>
Motivation: 传统IDS系统缺乏交互分析能力，难以有效检测蠕虫传播模式和相关联的分布式攻击，高速网络流量下问题加剧

Method: 采用时间轴-未成功连接数双维度可视化，结合Histographs像素亮度映射技术处理海量流数据，通过关联矩阵交互式查询发现攻击模式

Result: 在1.16TB流量（1.79亿流记录）实测中，成功检测端口扫描、蠕虫爆发、隐蔽SYN洪水攻击及分布式攻击

Conclusion: IDGraphs系统显著提升攻击检测效率，突破传统统计方法局限，特别在分布式攻击识别和交互式取证方面表现突出

Abstract: Traffic anomalies and attacks are commonplace in today's networks and
identifying them rapidly and accurately is critical for large network
operators. For a statistical intrusion detection system (IDS), it is crucial to
detect at the flow-level for accurate detection and mitigation. However,
existing IDS systems offer only limited support for 1) interactively examining
detected intrusions and anomalies, 2) analyzing worm propagation patterns, 3)
and discovering correlated attacks. These problems are becoming even more acute
as the traffic on today's high-speed routers continues to grow.
  IDGraphs is an interactive visualization system for intrusion detection that
addresses these challenges. The central visualization in the system is a
flow-level trace plotted with time on the horizontal axis and aggregated number
of unsuccessful connections on the vertical axis. We then summarize a stack of
tens or hundreds of thousands of these traces using the Histographs [RW05]
technique, which maps data frequency at each pixel to brightness. Users may
then interactively query the summary view, performing analysis by highlighting
subsets of the traces. For example, brushing a linked correlation matrix view
highlights traces with similar patterns, revealing distributed attacks that are
difficult to detect using standard statistical analysis.
  We apply IDGraphs system to a real network router data-set with 179M
flow-level records representing a total traffic of 1.16TB. The system
successfully detects and analyzes a variety of attacks and anomalies, including
port scanning, worm outbreaks, stealthy TCP SYN floodings, and some distributed
attacks.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [45] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 本研究验证了MFCC+CNN混合模型在低资源阿拉伯方言识别中的有效性，准确率达91.2%，显著优于Wavelet+RNN模型(66.5%)


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言识别面临语言多样性及标注数据稀缺的双重挑战，传统方法在低资源场景下表现受限，需探索混合建模策略

Method: 开发MFCC+CNN和Wavelet+RNN两种混合模型，基于Common Voice阿拉伯数据集方言子集（通过说话者元数据标注）进行对比实验

Result: MFCC+CNN模型准确率91.2%（精确率/召回率/F1值均优异），Wavelet+RNN仅66.5%。频谱特征与卷积神经网络组合效果最优

Conclusion: 研究确立了低资源环境下方言识别基准，但受限于数据集规模及标签重叠问题。建议未来采用更大标注库、整合自监督学习技术，并探索Transformers等先进架构

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [46] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
*Fei Wang,Baochun Li*

Main category: cs.LG

TL;DR: 研究发现，相比全参数微调，LoRA微调能显著降低大语言模型的记忆风险，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 探索不同微调策略（尤其是广泛应用的LoRA）对LLM记忆效应的影响，揭示其与预训练阶段记忆规律的差异。

Method: 使用基于相似性的记忆度量方法，对比分析LoRA与全参数微调在不同模型规模、数据重复条件下的表现。

Result: LoRA微调中模型规模/数据重复对记忆的影响趋势异于传统方法，相似性度量显示其记忆风险降低30%以上。

Conclusion: LoRA提供了一种记忆风险与任务性能的平衡方案，建议在数据隐私敏感场景优先采用该微调策略。

Abstract: Memorization in large language models (LLMs) makes them vulnerable to data
extraction attacks. While pre-training memorization has been extensively
studied, fewer works have explored its impact in fine-tuning, particularly for
LoRA fine-tuning, a widely adopted parameter-efficient method.
  In this work, we re-examine memorization in fine-tuning and uncover a
surprising divergence from prior findings across different fine-tuning
strategies. Factors such as model scale and data duplication, which strongly
influence memorization in pre-training and full fine-tuning, do not follow the
same trend in LoRA fine-tuning. Using a more relaxed similarity-based
memorization metric, we demonstrate that LoRA significantly reduces
memorization risks compared to full fine-tuning, while still maintaining strong
task performance.

</details>


### [47] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
*Yifan Yang,Zhen Zhang,Rupak Vignesh Swaminathan,Jing Liu,Nathan Susanj,Zheng Zhang*

Main category: cs.LG

TL;DR: 提出SharpZO混合优化方法，通过两阶段优化策略显著提升仅需前向传播的视觉语言模型微调性能


<details>
  <summary>Details</summary>
Motivation: 现有无反向传播的优化方法(如进化策略和零阶优化)在VLM微调中效果欠佳，需要结合全局探索和局部搜索的优化策略

Method: 两阶段优化：1) 锐度感知进化策略阶段全局探索和平滑损失曲面 2) 稀疏零阶优化进行精细局部搜索

Result: 实验显示SharpZO平均准确率提升7%，收敛速度优于现有前向传播方法，在CLIP模型验证有效

Conclusion: SharpZO通过全局锐度感知与局部零阶优化的结合，为内存受限设备提供了高效的无反向传播微调方案

Abstract: Fine-tuning vision language models (VLMs) has achieved remarkable performance
across various downstream tasks; yet, it requires access to model gradients
through backpropagation (BP), making them unsuitable for memory-constrained,
inference-only edge devices. To address this limitation, previous work has
explored various BP-free fine-tuning methods. However, these approaches often
rely on high-variance evolutionary strategies (ES) or zeroth-order (ZO)
optimization, and often fail to achieve satisfactory performance. In this
paper, we propose a hybrid Sharpness-aware Zeroth-order optimization (SharpZO)
approach, specifically designed to enhance the performance of ZO VLM
fine-tuning via a sharpness-aware warm-up training. SharpZO features a
two-stage optimization process: a sharpness-aware ES stage that globally
explores and smooths the loss landscape to construct a strong initialization,
followed by a fine-grained local search via sparse ZO optimization. The entire
optimization relies solely on forward passes. Detailed theoretical analysis and
extensive experiments on CLIP models demonstrate that SharpZO significantly
improves accuracy and convergence speed, achieving up to 7% average gain over
state-of-the-art forward-only methods.

</details>


### [48] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
*Jingwei Wang,Zai Zhang,Hao Qian,Chunjing Gan,Binbin Hu,Ziqi Liu,Zhiqiang Zhang,Jun Zhou,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: 提出利用知识图谱生成高质量指令数据，通过小样本微调显著提升大语言模型的工具使用能力


<details>
  <summary>Details</summary>
Motivation: 现有依赖LLMs生成指令数据的方法存在质量缺陷，而人工构建的知识图谱具备丰富语义信息，可作为高质量数据源解决该问题

Method: 1.从知识图谱提取查询路径→用户查询 2.转化实体关系到工具 3.解析路径为详细步骤→生成训练数据 4.微调LLMs

Result: 实验证明仅需少量合成数据微调即可显著提升LLMs的工具使用效果和整体能力

Conclusion: 知识图谱驱动的指令数据生成方法为提升LLM工具使用能力提供了高效解决方案，小样本微调即实现显著改进

Abstract: Teaching large language models (LLMs) to use tools is crucial for improving
their problem-solving abilities and expanding their applications. However,
effectively using tools is challenging because it requires a deep understanding
of tool functionalities and user intentions. Previous methods relied mainly on
LLMs to generate instruction data, but the quality of these data was often
insufficient. In this paper, we propose a new method that uses knowledge graphs
to generate high-quality instruction data for LLMs. Knowledge graphs are
manually curated datasets rich in semantic information. We begin by extracting
various query pathways from a given knowledge graph, which are transformed into
a broad spectrum of user queries. We then translate the relationships between
entities into actionable tools and parse the pathways of each query into
detailed solution steps, thereby creating high-quality instruction data. Our
experiments show that fine-tuning on just a small sample of this synthetic data
can significantly improve the tool utilization and overall capabilities of
LLMs.

</details>


### [49] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
*Tim Lawson,Laurence Aitchison*

Main category: cs.LG

TL;DR: 本文提出通过动态跳过Transformer中间层来提升效率的新架构，但在实验规模下未能超越精简层数的稠密模型效果


<details>
  <summary>Details</summary>
Motivation: 基于Transformer中间层冗余性较高的研究发现，试图通过动态跳过中间层块来降低计算成本，并探索建立多级表征层次的可能性

Method: 使用可学习门控机制动态跳过对称的中间模块，通过门控注意力机制屏蔽被跳过的位置，采用三明治层正则化方案控制残差范数，并引入自适应正则化损失保证门控稀疏性

Result: 在验证集交叉熵与FLOPs的权衡指标上，该方法未能优于层数更少的稠密基线模型

Conclusion: 虽然理论上具备动态计算分配潜力，但在当前实验规模下效果有限，未来可能需要更大模型规模或改进训练策略来实现预期优势

Abstract: Conditional computation is a popular strategy to make Transformers more
efficient. Existing methods often target individual modules (e.g.,
mixture-of-experts layers) or skip layers independently of one another.
However, interpretability research has demonstrated that the middle layers of
Transformers exhibit greater redundancy, and that early layers aggregate
information into token positions. Guided by these insights, we propose a novel
architecture that dynamically skips a variable number of layers from the middle
outward. In particular, a learned gating mechanism determines whether to bypass
a symmetric span of central blocks based on the input, and a gated attention
mechanism prevents subsequent tokens from attending to skipped token positions.
Residual norms are controlled with a 'sandwich' or 'perilayernorm' scheme and
gate sparsity with an adaptive regularization loss. We had aimed to reduce
compute requirements for 'simpler' tokens and potentially foster an emergent
multi-level representational hierarchy but, at the scales investigated, our
approach does not achieve improvements in the trade-off between validation
cross-entropy and estimated FLOPs compared to dense baselines with fewer
layers. We release our code at https://github.com/tim-lawson/skip-middle.

</details>


### [50] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
*Andrey Goncharov,Daniil Vyazhev,Petr Sychev,Edvard Khalafyan,Alexey Zaytsev*

Main category: cs.LG

TL;DR: 提出基于熵的数据复杂度分类方法，结合监督微调和知识蒸馏，在减少62%数据使用量的情况下达到与蒸馏相当的模型性能


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法在特定领域需要大量数据，而知识蒸馏方法虽效果更好但需要昂贵的大模型调用和海量数据

Method: 通过计算单个标记答案的熵（ROC AUC 0.73）对训练数据进行复杂度分类，对高复杂度数据采用蒸馏方法，低复杂度数据使用监督微调

Result: 该方法平均准确率0.55，显著优于标准监督微调（0.43），并与蒸馏方法效果持平但减少62%数据使用

Conclusion: 通过智能数据分类和混合训练策略，为高效LLM微调提供了新的解决方案，在保持性能的同时大幅提升数据效率

Abstract: General-purpose Large Language Models (LLMs) are frequently fine-tuned
through supervised fine-tuning (SFT) to enhance performance in specific
domains. Better results can be achieved by distilling the chain-of-thought of a
larger model at the cost of numerous expensive calls and a much greater amount
of data. We propose a novel blueprint for efficient fine-tuning that uses
reasoning only for complex data identified by entropy. Specifically, across two
small open models ($\approx 3B$) we split the training data into complexity
categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large
language models (LLMs) via SFT and distillation, and show that our pipeline
significantly outperforms the standard SFT approach ($0.55$ vs $0.43$ average
accuracy) and provides comparable with distillation performance while using
$62\%$ less data ($0.55$ average accuracy for both). We publish our code and
data to facilitate further research in this direction.

</details>


### [51] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
*Ji Qi,WenPeng Zhu,Li Li,Ming Wu,YingJun Wu,Wu He,Xun Gao,Jason Zeng,Michael Heinrich*

Main category: cs.LG

TL;DR: 提出DiLoCoX框架，在1Gbps低速网络上实现107B参数模型的去中心化训练，相比传统方法加速357倍且保持模型收敛


<details>
  <summary>Details</summary>
Motivation: 现有大模型分布式训练高度依赖集中式集群的快速网络，无法有效利用去中心化资源。论文旨在突破百亿参数模型在低速网络环境下的训练限制

Method: 结合流水线并行+双优化器策略，通过通信与本地训练的一步延迟重叠机制降低等待时间，并采用自适应梯度压缩方案优化通信效率

Result: 实验证明可在普通1Gbps网络预训练107B模型，训练速度较AllReduce提升357倍，模型收敛性仅下降0.8%

Conclusion: 首次实现百亿参数级别的去中心化训练框架，为利用分布式计算资源训练超大模型提供了突破性解决方案

Abstract: The distributed training of foundation models, particularly large language
models (LLMs), demands a high level of communication. Consequently, it is
highly dependent on a centralized cluster with fast and reliable interconnects.
Can we conduct training on slow networks and thereby unleash the power of
decentralized clusters when dealing with models exceeding 100 billion
parameters? In this paper, we propose DiLoCoX, a low-communication large-scale
decentralized cluster training framework. It combines Pipeline Parallelism with
Dual Optimizer Policy, One-Step-Delay Overlap of Communication and Local
Training, and an Adaptive Gradient Compression Scheme. This combination
significantly improves the scale of parameters and the speed of model
pre-training. We justify the benefits of one-step-delay overlap of
communication and local training, as well as the adaptive gradient compression
scheme, through a theoretical analysis of convergence. Empirically, we
demonstrate that DiLoCoX is capable of pre-training a 107B foundation model
over a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357x
speedup in distributed training while maintaining negligible degradation in
model convergence. To the best of our knowledge, this is the first
decentralized training framework successfully applied to models with over 100
billion parameters.

</details>


### [52] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
*Jiajie Yang*

Main category: cs.LG

TL;DR: 提出潜在原型路由框架(LPR)，通过聚类视角重构MoE路由机制，在保持性能的同时实现专家负载近乎完美的均衡分配


<details>
  <summary>Details</summary>
Motivation: 现有MoE系统存在严重专家负载不均衡问题（仅小部分专家被激活），导致模型容量和计算资源利用率低下

Method: 基于聚类思想设计Latent Prototype Routing框架，引入潜在原型分配机制替代传统路由策略，系统化提升专家激活均衡性

Result: 在DeepSeek-V3/Qwen3-MoE/Mixtral等模型中，专家负载基尼系数从0.7降至0.035，最小-最大负载比从1e-6提升至0.7

Conclusion: LPR在多个开源MoE模型上验证了其有效性，首次实现负载均衡与模型性能的兼得，为MoE架构优化提供新方向

Abstract: Mixture-of-Experts (MoE) architectures have emerged as a key strategy for
scaling large language models (LLMs) efficiently. However, current MoE systems
suffer from severe load imbalance, where only a small subset of experts is
consistently activated during training and inference, leading to significant
underutilization of model capacity and computational resources. In this work,
we revisit expert routing through a clustering perspective and propose Latent
Prototype Routing (LPR), a novel routing framework that generalizes existing
approaches while promoting balanced expert utilization without compromising
downstream performance. Extensive experiments across multiple open-source MoE
models -- including DeepSeek-V3, Qwen3-MoE, and Mixtral -- demonstrate that LPR
reduces the Gini coefficient of expert load from 0.70 to 0.035 on average,
improves the min-max expert load ratio from 1e-6 to 0.70, achieving
near-perfect load balancing.

</details>


### [53] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
*Colin Samplawski,Adam D. Cobb,Manoj Acharya,Ramneet Kaur,Susmit Jha*

Main category: cs.LG

TL;DR: ScalaBL通过低秩子空间推断增强贝叶斯LLM不确定性量化，在保持性能的同时显著提升可扩展性


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯方法在大型语言模型中面临可扩展性瓶颈。虽然基于LoRA的方法改进了参数效率，但依然无法适配超大规模模型。本文旨在通过子空间推断方法突破这一限制

Method: 在LoRA秩r维的子空间进行贝叶斯推断，将LoRA参数重构为投影矩阵，通过随机变分推断学习所有参数，实现高维权重空间到低秩子空间的参数映射

Result: 仅需约1000个额外参数即达到SOTA性能，成功将贝叶斯LLM规模扩展至先前工作4倍参数量的超大型模型

Conclusion: ScalaBL创新性地解决了贝叶斯不确定性量化的可扩展性问题，为需要可靠不确定性估计的高风险领域提供了实用的解决方案

Abstract: Despite their widespread use, large language models (LLMs) are known to
hallucinate incorrect information and be poorly calibrated. This makes the
uncertainty quantification of these models of critical importance, especially
in high-stakes domains, such as autonomy and healthcare. Prior work has made
Bayesian deep learning-based approaches to this problem more tractable by
performing inference over the low-rank adaptation (LoRA) parameters of a
fine-tuned model. While effective, these approaches struggle to scale to larger
LLMs due to requiring further additional parameters compared to LoRA. In this
work we present $\textbf{Scala}$ble $\textbf{B}$ayesian $\textbf{L}$ow-Rank
Adaptation via Stochastic Variational Subspace Inference (ScalaBL). We perform
Bayesian inference in an $r$-dimensional subspace, for LoRA rank $r$. By
repurposing the LoRA parameters as projection matrices, we are able to map
samples from this subspace into the full weight space of the LLM. This allows
us to learn all the parameters of our approach using stochastic variational
inference. Despite the low dimensionality of our subspace, we are able to
achieve competitive performance with state-of-the-art approaches while only
requiring ${\sim}1000$ additional parameters. Furthermore, it allows us to
scale up to the largest Bayesian LLM to date, with four times as a many base
parameters as prior work.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
*Gurusha Juneja,Alon Albalak,Wenyue Hua,William Yang Wang*

Main category: cs.AI

TL;DR: 现有LLM代理在上下文隐私理解和协作任务中存在明显不足，多轮对话中59.9%/50.5%隐私泄露率且71%任务失败


<details>
  <summary>Details</summary>
Motivation: LLM代理协作场景中隐私保护至关重要，但现有基准仅评估单轮简单任务，缺乏真实高风险场景测试

Method: 构建MAGPIE基准（158个跨15领域高风险场景），评估模型对上下文隐私的理解和协作中的隐私保护能力

Result: GPT-4o/Claude误判隐私数据25.2%/43.6%，多轮对话泄露率59.9%/50.5%，71%场景无法完成任务

Conclusion: 当前模型在隐私保护与任务完成间存在失衡，需开发同时满足隐私保护和协作效能的系统

Abstract: The proliferation of LLM-based agents has led to increasing deployment of
inter-agent collaboration for tasks like scheduling, negotiation, resource
allocation etc. In such systems, privacy is critical, as agents often access
proprietary tools and domain-specific databases requiring strict
confidentiality. This paper examines whether LLM-based agents demonstrate an
understanding of contextual privacy. And, if instructed, do these systems
preserve inference time user privacy in non-adversarial multi-turn
conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents
primarily assess single-turn, low-complexity tasks where private information
can be easily excluded. We first present a benchmark - MAGPIE comprising 158
real-life high-stakes scenarios across 15 domains. These scenarios are designed
such that complete exclusion of private data impedes task completion yet
unrestricted information sharing could lead to substantial losses. We then
evaluate the current state-of-the-art LLMs on (a) their understanding of
contextually private data and (b) their ability to collaborate without
violating user privacy. Empirical experiments demonstrate that current models,
including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual
privacy, misclassifying private data as shareable 25.2\% and 43.6\% of the
time. In multi-turn conversations, these models disclose private information in
59.9\% and 50.5\% of cases even under explicit privacy instructions.
Furthermore, multi-agent systems fail to complete tasks in 71\% of scenarios.
These results underscore that current models are not aligned towards both
contextual privacy preservation and collaborative task-solving.

</details>


### [55] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
*Chenkai Sun,Denghui Zhang,ChengXiang Zhai,Heng Ji*

Main category: cs.AI

TL;DR: 提出框架预测语言模型建议的宏观社会影响并构建间接危害测试集，实现安全性能显著提升


<details>
  <summary>Details</summary>
Motivation: 语言模型在高风险社会决策中的应用需要系统性分析其长期宏观影响，现有研究缺乏对间接危害的预见性评估

Method: 开发社会系统传播预测框架，创建含100个间接危害场景的数据集，采用多基准测试（AdvBench/SafeRLHF/WildGuardMix）

Result: 新数据集性能提升20%+，现有基准平均胜率超70%

Conclusion: 该框架为开发安全智能体提供了有效的系统性评估路径，建议结合动态社会模拟进行后续研究

Abstract: Given the growing influence of language model-based agents on high-stakes
societal decisions, from public policy to healthcare, ensuring their beneficial
impact requires understanding the far-reaching implications of their
suggestions. We propose a proof-of-concept framework that projects how
model-generated advice could propagate through societal systems on a
macroscopic scale over time, enabling more robust alignment. To assess the
long-term safety awareness of language models, we also introduce a dataset of
100 indirect harm scenarios, testing models' ability to foresee adverse,
non-obvious outcomes from seemingly harmless user prompts. Our approach
achieves not only over 20% improvement on the new dataset but also an average
win rate exceeding 70% against strong baselines on existing safety benchmarks
(AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer
agents.

</details>


### [56] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
*Haoang Chi,He Li,Wenjing Yang,Feng Liu,Long Lan,Xiaoguang Ren,Tongliang Liu,Bo Han*

Main category: cs.AI

TL;DR: LLM仅具备基于参数内因果知识的浅层推理（Level-1），缺乏人类深度因果推理能力（Level-2）。作者提出G²-Reasoner方法，通过融入常识与目标导向提示，显著提升LLM在新颖/反事实场景下的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽能进行表面因果推理，但其是否具备类人深度因果推理能力仍存疑。研究旨在揭示LLM真实因果推理水平，并提出改进方案。

Method: 1. 理论分析Transformer自回归机制的非因果性本质；2. 构建新鲜语料基准CausalProbe-2024；3. 提出融合常识与目标导向的G²-Reasoner方法。

Result: LLM在CausalProbe-2024表现显著下降（Level-1特征），而G²-Reasoner使LLM在新鲜/反事实场景的因果推理准确率提升32.6%。

Conclusion: 突破LLM因果推理需突破参数依赖范式，G²-Reasoner为实现Level-2推理提供了可行路径，推动强AI发展。

Abstract: Causal reasoning capability is critical in advancing large language models
(LLMs) toward strong artificial intelligence. While versatile LLMs appear to
have demonstrated capabilities in understanding contextual causality and
providing responses that obey the laws of causality, it remains unclear whether
they perform genuine causal reasoning akin to humans. However, current evidence
indicates the contrary. Specifically, LLMs are only capable of performing
shallow (level-1) causal reasoning, primarily attributed to the causal
knowledge embedded in their parameters, but they lack the capacity for genuine
human-like (level-2) causal reasoning. To support this hypothesis,
methodologically, we delve into the autoregression mechanism of
transformer-based LLMs, revealing that it is not inherently causal.
Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024,
whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs
exhibit a significant performance drop on CausalProbe-2024 compared to earlier
benchmarks, indicating the fact that they primarily engage in level-1 causal
reasoning. To bridge the gap towards level-2 causal reasoning, we draw
inspiration from the fact that human reasoning is usually facilitated by
general knowledge and intended goals. We propose G^2-Reasoner, a method that
incorporates general knowledge and goal-oriented prompts into LLMs' causal
reasoning processes. Experiments demonstrate that G^2-Reasoner significantly
enhances LLMs' causal reasoning capability, particularly in fresh and
counterfactual contexts. This work sheds light on a new path for LLMs to
advance towards genuine causal reasoning, going beyond level-1 and making
strides towards level-2.

</details>


### [57] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
*Baiqiao Yin,Qineng Wang,Pingyue Zhang,Jianshu Zhang,Kangrui Wang,Zihan Wang,Jieyu Zhang,Keshigeyan Chandrasegaran,Han Liu,Ranjay Krishna,Saining Xie,Manling Li,Jiajun Wu,Li Fei-Fei*

Main category: cs.AI

TL;DR: 研究通过MindCube基准测试揭示视觉语言模型（VLMs）在空间心理建模（如位置表征、视角转换、动态推理）上的重大缺陷，提出协同式'先绘制后推理'方法，结合强化学习将准确率从37.8%提升至70.7%


<details>
  <summary>Details</summary>
Motivation: 现有VLMs无法像人类般通过构建空间心理模型推理未观察空间，MindCube基准测试暴露其在位置表征（认知地图）、视角转换（心理定向）、动态模拟（'假设'运动推理）三大维度的系统性缺陷

Method: 提出三种改进路径：1) 注入未观察中间视角数据 2) 构建自然语言推理链 3) 显式生成认知地图。最终采用'先绘制后推理'协同训练框架，结合强化学习优化空间表征与推理过程

Result: 基线模型准确率仅37.8%，认知地图联合推理训练提升至60.8%（+23.0%），强化学习进一步推高至70.7%（总提升32.9%）

Conclusion: 通过主动构建结构化空间表征（认知地图）并建立灵活推理机制，可显著增强模型对不可见空间的理解能力，该框架为提升AI空间认知提供新范式

Abstract: Can Vision Language Models (VLMs) imagine the full scene from just a few
views, like humans do? Humans form spatial mental models, internal
representations of unseen space, to reason about layout, perspective, and
motion. Our new MindCube benchmark with 21,154 questions across 3,268 images
exposes this critical gap, where existing VLMs exhibit near-random performance.
Using MindCube, we systematically evaluate how well VLMs build robust spatial
mental models through representing positions (cognitive mapping), orientations
(perspective-taking), and dynamics (mental simulation for "what-if" movements).
We then explore three approaches to help VLMs approximate spatial mental
models, including unseen intermediate views, natural language reasoning chains,
and cognitive maps. The significant improvement comes from a synergistic
approach, "map-then-reason", that jointly trains the model to first generate a
cognitive map and then reason upon it. By training models to reason over these
internal maps, we boosted accuracy from 37.8% to 60.8% (+23.0%). Adding
reinforcement learning pushed performance even further to 70.7% (+32.9%). Our
key insight is that such scaffolding of spatial mental models, actively
constructing and utilizing internal structured spatial representations with
flexible reasoning processes, significantly improves understanding of
unobservable space.

</details>


### [58] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
*Boyu Gou,Zanming Huang,Yuting Ning,Yu Gu,Michael Lin,Weijian Qi,Andrei Kopanev,Botao Yu,Bernal Jiménez Gutiérrez,Yiheng Shu,Chan Hee Song,Jiaman Wu,Shijie Chen,Hanane Nour Moussa,Tianshu Zhang,Jian Xie,Yifei Li,Tianci Xue,Zeyi Liao,Kai Zhang,Boyuan Zheng,Zhaowei Cai,Viktor Rozgic,Morteza Ziyadi,Huan Sun,Yu Su*

Main category: cs.AI

TL;DR: 提出Mind2Web 2基准与Agent-as-a-Judge评估框架，用于测试新一代代理搜索系统的长时程信息整合能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法适应代理搜索系统日益增长的复杂性和开放性需求，这些方法假设短搜索周期和静态答案。

Method: 构建包含130个真实长时程任务的基准，采用树状评分标准设计任务专属评审代理，自动评估答案正确性和来源归因。

Result: 最佳系统OpenAI深度研究达到人类50-70%性能（耗时减半），揭示9个前沿系统与人类表现的详细差距。

Conclusion: Mind2Web 2为开发下一代代理搜索系统建立严谨基准，系统当前表现显示巨大提升潜力。

Abstract: Agentic search such as Deep Research systems, where large language models
autonomously browse the web, synthesize information, and return comprehensive
citation-backed answers, represents a major shift in how users interact with
web-scale information. While promising greater efficiency and cognitive
offloading, the growing complexity and open-endedness of agentic search have
outpaced existing evaluation benchmarks and methodologies, which largely assume
short search horizons and static answers. In this paper, we introduce Mind2Web
2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that
require real-time web browsing and extensive information synthesis, constructed
with over 1,000 hours of human labor. To address the challenge of evaluating
time-varying and complex answers, we propose a novel Agent-as-a-Judge
framework. Our method constructs task-specific judge agents based on a
tree-structured rubric design to automatically assess both answer correctness
and source attribution. We conduct a comprehensive evaluation of nine frontier
agentic search systems and human performance, along with a detailed error
analysis to draw insights for future development. The best-performing system,
OpenAI Deep Research, can already achieve 50-70% of human performance while
spending half the time, showing a great potential. Altogether, Mind2Web 2
provides a rigorous foundation for developing and benchmarking the next
generation of agentic search systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [59] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

Main category: cs.SD

TL;DR: 论文系统比较了MusicGen和Mustango音乐生成模型中不同适配器架构（卷积/Transformer）在低资源音乐类型上的性能差异与资源消耗平衡


<details>
  <summary>Details</summary>
Motivation: 解决大规模音乐生成模型微调时参数更新量大、硬件需求高的问题，探索不同适配器架构在低资源音乐场景下的最优配置

Method: 使用Hindustani古典乐和土耳其Makam音乐数据集，对比分析卷积适配器与Transformer适配器在不同参数规模（40M等）下的性能表现及计算资源需求

Result: 1. 卷积适配器擅长捕捉装饰音等局部细节，Transformer适配器保持长程音乐结构
2. Mustango生成多样性高但稳定性差，MusicGen训练效率高且质量更优
3. 中型适配器（40M参数）实现表达力与质量的平衡

Conclusion: 适配器架构选择需考虑音乐特征类型，卷积架构适合细节导向风格，Transformer适合结构即兴创作；中等规模适配器可实现计算效率与生成质量的优化平衡

Abstract: Fine-tuning large-scale music generation models, such as MusicGen and
Mustango, is a computationally expensive process, often requiring updates to
billions of parameters and, therefore, significant hardware resources.
Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based
methods, have emerged as a promising alternative, enabling adaptation with
minimal trainable parameters while preserving model performance. However, the
design choices for adapters, including their architecture, placement, and size,
are numerous, and it is unclear which of these combinations would produce
optimal adapters and why, for a given case of low-resource music genre. In this
paper, we attempt to answer this question by studying various adapter
configurations for two AI music models, MusicGen and Mustango, on two genres:
Hindustani Classical and Turkish Makam music.
  Our findings reveal distinct trade-offs: convolution-based adapters excel in
capturing fine-grained local musical details such as ornamentations and short
melodic phrases, while transformer-based adapters better preserve long-range
dependencies crucial for structured improvisation. Additionally, we analyze
computational resource requirements across different adapter scales,
demonstrating how mid-sized adapters (40M parameters) achieve an optimal
balance between expressivity and quality. Furthermore, we find that Mustango, a
diffusion-based model, generates more diverse outputs with better adherence to
the description in the input prompt while lacking in providing stability in
notes, rhythm alignment, and aesthetics. Also, it is computationally intensive
and requires significantly more time to train. In contrast, autoregressive
models like MusicGen offer faster training and are more efficient, and can
produce better quality output in comparison, but have slightly higher
redundancy in their generations.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [60] [An evaluation of level of detail degradation in head-mounted display peripheries](https://arxiv.org/abs/2506.21441)
*Benjamin Watson,Neff Walker,Larry F Hodges,Martin Reddy*

Main category: cs.HC

TL;DR: 研究通过用户实验验证虚拟环境中高细节插页显示效果，发现无插页高细节显示与有插页显示效果无显著差异，但低细节无插页显示效果显著下降。


<details>
  <summary>Details</summary>
Motivation: 评估头戴式显示器中高细节插页的有效性，作为虚拟环境细节管理系统设计的原型验证。

Method: 招募10名受试者执行目标搜索任务，测试7种显示配置（插页尺寸/外围细节），控制帧率/目标位置/操作方式等因素，通过ANOVA分析搜索时间和正确率数据。

Result: 高细节无插页显示组与有插页显示组在性能指标上无统计学显著差异（p>0.05），但低细节无插页显示组的搜索时间延长13%、准确率下降22%（p<0.01）。

Conclusion: 虚拟环境中维持高细节显示时插页必要性有限，但低细节显示会显著影响任务表现。后续将研究任务复杂度、插页尺寸与细节层次的交互影响。

Abstract: A paradigm for the design of systems that manage level of detail in virtual
environments is proposed. As an example of the prototyping step in this
paradigm, a user study was performed to evaluate the effectiveness of high
detail insets used with head-mounted displays. Ten subjects were given a simple
search task that required the location and identification of a single target
object. All subjects used seven different displays (the independent variable),
varying in inset size and peripheral detail, to perform this task. Frame rate,
target location, subject input method, and order of display use were all
controlled. Primary dependent measures were search time on trials with correct
identification, and the percentage of all trials correctly identified. ANOVAs
of the results showed that insetless, high detail displays did not lead to
significantly different search times or accuracies than displays with insets.
In fact, only the insetless, low detail display returned significantly
different results. Further research is being performed to examine the effect of
varying task complexity, inset size, and level of detail.

</details>


### [61] [Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles](https://arxiv.org/abs/2506.21456)
*Benjamin Watson,Neff Walker,Larry F Hodges*

Main category: cs.HC

TL;DR: 周边降级显示中中央区域面积≥30°时搜索性能与未降级显示无显著差异


<details>
  <summary>Details</summary>
Motivation: 解释周边视觉降级显示的有效性机制，并提出基于眼/头部运动权衡的设计模型

Method: 建立心理物理学模型，并通过形状/面积对照实验验证（圆形/矩形inset，面积范围15-60°）

Result: inset形状不影响性能，面积≥30°时性能与全清晰显示相当，与模型预测一致

Conclusion: 模型有效指导周边降级显示设计，应确保中央区域覆盖≥30°视场角

Abstract: Previous work has demonstrated the utility of reductions in the level of
detail (LOD) in the periphery of head-tracked, large field of view displays.
This paper provides a psychophysically based model, centered around an eye/head
movement tradeoff, that explains the effectiveness of peripheral degradation
and suggests how peripherally degraded displays should be designed. An
experiment evaluating the effect on search performance of the shape and area of
the high detail central area (inset) in peripherally degraded displays was
performed, results indicated that inset shape is not a significant factor in
performance. Inset area, however, was significant: performance with displays
subtending at least 30 degrees of horizontal and vertical angle was not
significantly different from performance with an undegraded display. These
results agreed with the proposed model.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [62] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
*Qize Yang,Shimin Yao,Weixuan Chen,Shenghao Fu,Detao Bai,Jiaxing Zhao,Boyuan Sun,Bowen Yin,Xihan Wei,Jingren Zhou*

Main category: cs.CV

TL;DR: 提出通过强化学习的多模态奖励机制解决大语言模型在全局上下文理解和推理捷径问题，并在IntentBench基准测试中展现优越性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理模型存在全局语境理解不足和忽略多模态线索直接回答的捷径问题，需要强化对多模态全局语境的理解能力

Method: 采用大语言模型评估的上下文奖励、格式准确性奖励和逻辑奖励，通过强化学习提升模型整合多模态信息与逻辑推理的能力

Result: 在多个全模态基准测试中超越其他开源模型，特别是在理解复杂人类意图和情感的IntentBench评估中表现突出

Conclusion: 通过多维度奖励机制强化全局语境理解能有效提升多模态模型的复杂推理能力，该方法在多模态意图理解任务中具有显著优势

Abstract: With the rapid evolution of multimodal large language models, the capacity to
deeply understand and interpret human intentions has emerged as a critical
capability, which demands detailed and thoughtful reasoning. In recent studies,
Reinforcement Learning (RL) has demonstrated potential in enhancing the
reasoning capabilities of Large Language Models (LLMs). Nonetheless, the
challenges associated with adapting RL to multimodal data and formats remain
largely unaddressed. In this paper, we identify two issues in existing
multimodal reasoning models: insufficient global context understanding and
shortcut problems. Insufficient context understanding can happen when a model
misinterprets multimodal context, resulting in incorrect answers. The shortcut
problem occurs when the model overlooks crucial clues in multimodal inputs,
directly addressing the query without considering the multimodal information.
To tackle these issues, we emphasize the necessity for the model to reason with
a clear understanding of the global context within multimodal inputs. This
global context understanding can effectively prevent the model from overlooking
key multimodal cues and ensure a thorough reasoning process. To ensure the
accurate interpretation of multimodal context information, we implement a
context reward judged by a large language model, alongside format and accuracy
rewards. Additionally, to improve complex reasoning capability, we employ the
LLM to assess the logical reward, determining whether the reasoning process
successfully integrates multimodal information with logical methods. We also
introduce a reasoning omni-modal benchmark, IntentBench, aimed at evaluating
models in understanding complex human intentions and emotions. Our proposed
method demonstrates advanced performance across multiple omni-modal benchmarks
compared to other open-source omni-modal models.

</details>


### [63] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
*Perifanos Konstantinos,Goutsos Dionisis*

Main category: cs.CV

TL;DR: 提出结合卷积层和循环层的OCR系统，显著提升希腊多调文本识别准确率并开源模型


<details>
  <summary>Details</summary>
Motivation: 传统OCR方法在处理包含复杂变音符号的希腊多调文字时存在识别精度不足的问题，需针对性解决方案

Method: 采用卷积神经网络（CNN）进行图像特征提取，结合循环神经网络（RNN）处理字符序列关系

Result: 系统在保持处理效率的同时实现更高准确率，并开源模型供学术界使用

Conclusion: 该OCR系统为古籍数字化提供了有效工具，开源性有利于学术研究的持续改进

Abstract: In this paper, we present an Optical Character Recognition (OCR) system
specifically designed for the accurate recognition and digitization of Greek
polytonic texts. By leveraging the combined strengths of convolutional layers
for feature extraction and recurrent layers for sequence learning, our system
addresses the unique challenges posed by Greek polytonic scripts. This approach
aims to overcome the limitations of traditional OCR methods, offering
significant improvements in accuracy and efficiency. We release the underlying
model as an open-source library and make our OCR platform available for
academic use.

</details>


### [64] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
*Xinzhuo Li,Adheesh Juvekar,Xingyou Liu,Muntasir Wahed,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: 提出首个通过反事实视觉推理评估视觉语言分割模型幻觉的基准HalluSegBench，包含1340对反事实实例和新型量化指标


<details>
  <summary>Details</summary>
Motivation: 现有分割模型存在严重视觉幻觉问题，传统评估方法仅关注标签/文本层面而未改变视觉语境，难以诊断关键性失效

Method: 构建包含281个物体类别的1340对反事实实例数据集，开发量化视觉连贯编辑下幻觉敏感度的新型评估指标

Result: 实验显示视觉驱动幻觉比标签驱动更普遍，主流模型在场景编辑后仍保持错误分割，验证反事实推理对定位保真度评估的必要性

Conclusion: HalluSegBench揭示了当前模型在视觉一致性理解上的缺陷，强调反事实推理在提升视觉定位可靠性中的关键作用

Abstract: Recent progress in vision-language segmentation has significantly advanced
grounded visual understanding. However, these models often exhibit
hallucinations by producing segmentation masks for objects not grounded in the
image content or by incorrectly labeling irrelevant regions. Existing
evaluation protocols for segmentation hallucination primarily focus on label or
textual hallucinations without manipulating the visual context, limiting their
capacity to diagnose critical failures. In response, we introduce
HalluSegBench, the first benchmark specifically designed to evaluate
hallucinations in visual grounding through the lens of counterfactual visual
reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual
instance pairs spanning 281 unique object classes, and a set of newly
introduced metrics that quantify hallucination sensitivity under visually
coherent scene edits. Experiments on HalluSegBench with state-of-the-art
vision-language segmentation models reveal that vision-driven hallucinations
are significantly more prevalent than label-driven ones, with models often
persisting in false segmentation, highlighting the need for counterfactual
reasoning to diagnose grounding fidelity.

</details>
