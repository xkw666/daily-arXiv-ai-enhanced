<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 16]
- [cs.GR](#cs.GR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Inconsistent Affective Reaction: Sentiment of Perception and Opinion in Urban Environments](https://arxiv.org/abs/2510.07359)
*Jingfei Huang,Han Tu*

Main category: cs.CL

TL;DR: 本研究通过整合街景图像和社交媒体文本数据，开发情感反应指数分析北京二环区域感知与意见的情感差异，揭示城市要素与情感变化的关系。


<details>
  <summary>Details</summary>
Motivation: 现有城市多维情感分析方法难以捕捉人类感知与意见间的复杂情感差异，需开发新方法识别这种不一致性。

Method: 构建包含14万+街景图像和98万+微博文本的数据集，整合目标检测/NLP技术开发情感反应指数，运用回归分析/图像分割/词频统计进行空间可视化。

Result: 感知情感趋于均匀正向分布，意见情感呈现极端变化；建成环境密度与行人活动等要素与情感变化显著相关；疫情前后感知-意见存在明显错位。

Conclusion: 情感不一致地图为城市更新提供决策支持，建议在环境管理中同时考虑物理空间特征和社会感知要素。

Abstract: The ascension of social media platforms has transformed our understanding of
urban environments, giving rise to nuanced variations in sentiment reaction
embedded within human perception and opinion, and challenging existing
multidimensional sentiment analysis approaches in urban studies. This study
presents novel methodologies for identifying and elucidating sentiment
inconsistency, constructing a dataset encompassing 140,750 Baidu and Tencent
Street view images to measure perceptions, and 984,024 Weibo social media text
posts to measure opinions. A reaction index is developed, integrating object
detection and natural language processing techniques to classify sentiment in
Beijing Second Ring for 2016 and 2022. Classified sentiment reaction is
analysed and visualized using regression analysis, image segmentation, and word
frequency based on land-use distribution to discern underlying factors. The
perception affective reaction trend map reveals a shift toward more evenly
distributed positive sentiment, while the opinion affective reaction trend map
shows more extreme changes. Our mismatch map indicates significant disparities
between the sentiments of human perception and opinion of urban areas over the
years. Changes in sentiment reactions have significant relationships with
elements such as dense buildings and pedestrian presence. Our inconsistent maps
present perception and opinion sentiments before and after the pandemic and
offer potential explanations and directions for environmental management, in
formulating strategies for urban renewal.

</details>


### [2] [Haystack Engineering: Context Engineering for Heterogeneous and Agentic Long-Context Evaluation](https://arxiv.org/abs/2510.07414)
*Mufei Li,Dongqi Fu,Limei Wang,Si Zhang,Hanqing Zeng,Kaan Sancak,Ruizhong Qiu,Haoyu Wang,Xiaoxin He,Xavier Bresson,Yinglong Xia,Chonglin Sun,Pan Li*

Main category: cs.CL

TL;DR: 提出HaystackCraft新型基准测试，通过真实维基百科网络构建多跳问题，揭示异构检索策略对LLM长上下文推理的影响及代理工作流中的级联失败问题


<details>
  <summary>Details</summary>
Motivation: 现有NIAH测试忽略真实场景中由有偏检索和代理工作流程产生的噪声上下文，需要构建更贴近现实的评估框架来测试长上下文模型的鲁棒性

Method: 基于英文维基百科超链接网络构建动态多跳问题，系统评估稀疏/稠密/混合/图基检索策略的干扰效应，并扩展至LLM自主生成查询、反思推理的代理操作场景

Result: 图基重排在提升检索效果的同时减少干扰；GPT-5/Gemini等先进模型在自主生成干扰场景下仍存在级联失败，且难以实现早期停止决策

Conclusion: HaystackCraft为长上下文推理研究提供重要测试平台，揭示当前模型在代理操作中的持续性挑战，强调检索策略优化与推理终止机制的重要性

Abstract: Modern long-context large language models (LLMs) perform well on synthetic
"needle-in-a-haystack" (NIAH) benchmarks, but such tests overlook how noisy
contexts arise from biased retrieval and agentic workflows. We argue that
haystack engineering is necessary to construct noisy long contexts that
faithfully capture key real-world factors -- distraction from heterogeneous
biased retrievers and cascading errors in agentic workflows -- to test models'
long-context robustness. We instantiate it through HaystackCraft, a new NIAH
benchmark built on the full English Wikipedia hyperlink network with multi-hop
questions. HaystackCraft evaluates how heterogeneous retrieval strategies
(e.g., sparse, dense, hybrid, and graph-based) affect distractor composition,
haystack ordering, and downstream LLM performance. HaystackCraft further
extends NIAH to dynamic, LLM-dependent settings that simulate agentic
operations, where models refine queries, reflect on their past reasonings, and
decide when to stop. Experiments with 15 long-context models show that (1)
while stronger dense retrievers can introduce more challenging distractors,
graph-based reranking simultaneously improves retrieval effectiveness and
mitigates more harmful distractors; (2) in agentic tests, even advanced models
like Gemini 2.5 Pro and GPT-5 suffer cascading failures from self-generated
distractors or struggle to perform early stops. These results highlight
persistent challenges in agentic long-context reasoning and establish
HaystackCraft as a valuable testbed for future progress.

</details>


### [3] [Lemma Dilemma: On Lemma Generation Without Domain- or Language-Specific Training Data](https://arxiv.org/abs/2510.07434)
*Olia Toporkov,Alan Akbik,Rodrigo Agerri*

Main category: cs.CL

TL;DR: LLMs通过少量上下文示例即可在12种语言中实现最先进的词形还原效果，无需微调即超越传统监督方法。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在缺乏目标领域训练数据时，能否通过上下文学习实现高效词形还原任务，并与传统监督方法进行对比。

Method: 在12种不同形态复杂度的语言中，对比：1) 跨领域微调的监督式编码器 2) 跨语言方法 3) 直接使用LLMs进行上下文词形还原（无微调，仅提供少量示例）

Result: 监督方法在跨领域微调后仍具竞争力，但LLMs在多数语言中仅需少量示例即达SOTA，尤其在资源匮乏场景表现突出。

Conclusion: 上下文学习范式使LLMs成为低资源词形还原任务的有效解决方案，突破了传统方法对标注数据的依赖。

Abstract: Lemmatization is the task of transforming all words in a given text to their
dictionary forms. While large language models (LLMs) have demonstrated their
ability to achieve competitive results across a wide range of NLP tasks, there
is no prior evidence of how effective they are in the contextual lemmatization
task. In this paper, we empirically investigate the capacity of the latest
generation of LLMs to perform in-context lemmatization, comparing it to the
traditional fully supervised approach. In particular, we consider the setting
in which supervised training data is not available for a target domain or
language, comparing (i) encoder-only supervised approaches, fine-tuned
out-of-domain, and (ii) cross-lingual methods, against direct in-context lemma
generation with LLMs. Our experimental investigation across 12 languages of
different morphological complexity finds that, while encoders remain
competitive in out-of-domain settings when fine-tuned on gold data, current
LLMs reach state-of-the-art results for most languages by directly generating
lemmas in-context without prior fine-tuning, provided just with a few examples.
Data and code available upon publication:
https://github.com/oltoporkov/lemma-dilemma

</details>


### [4] [LASER: An LLM-based ASR Scoring and Evaluation Rubric](https://arxiv.org/abs/2510.07437)
*Amruta Parulekar,Preethi Jyothi*

Main category: cs.CL

TL;DR: 提出基于LLM的ASR评估指标LASER，相比传统WER更关注语义保留，减少对形态/句法差异的过度惩罚。


<details>
  <summary>Details</summary>
Motivation: 传统ASR评估指标WER过度惩罚不影响语义的形态/句法差异，需开发更注重语义保留的评估方法。

Method: 利用Gemini 2.5 Pro的上下文学习能力构建LASER评分框架；微调Llama 3模型处理词对惩罚预测任务。

Result: 印地语LASER与人工标注相关性达94%，跨语言适用性验证成功；微调后的Llama 3词对惩罚预测准确率达89%。

Conclusion: LASER指标提供更精准的ASR评估方案，小模型通过微调亦可胜任特定评估任务，具有跨语言应用潜力。

Abstract: Standard ASR evaluation metrics like Word Error Rate (WER) tend to unfairly
penalize morphological and syntactic nuances that do not significantly alter
sentence semantics. We introduce an LLM-based scoring rubric LASER that
leverages state-of-the-art LLMs' in-context learning abilities to learn from
prompts with detailed examples. Hindi LASER scores using Gemini 2.5 Pro
achieved a very high correlation score of 94% with human annotations. Hindi
examples in the prompt were also effective in analyzing errors in other Indian
languages such as Marathi, Kannada and Malayalam. We also demonstrate how a
smaller LLM like Llama 3 can be finetuned on word-pair examples derived from
reference and ASR predictions to predict what kind of penalty should be applied
with close to 89% accuracy.

</details>


### [5] [Meaningful Pose-Based Sign Language Evaluation](https://arxiv.org/abs/2510.07453)
*Zifan Jiang,Colin Leong,Amit Moryossef,Anne Göhring,Annette Rios,Oliver Cory,Maksym Ivashechkin,Neha Tarigopula,Biao Zhang,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: 该研究提出并评估了多种手语姿势评估指标，开发了开源工具包以支持手语翻译系统的开发和评估


<details>
  <summary>Details</summary>
Motivation: 现有手语评估方法缺乏系统性，需建立多维度评估体系以促进手语生成技术发展

Method: 结合关键点距离/嵌入/反向翻译三类指标，通过符号级检索的自动元评估和跨语言文本-姿势转换的人类相关研究进行验证

Result: 揭示不同场景下评估指标的权衡关系，开发出可复用的开源评估工具包

Conclusion: 系统化的评估框架和工具为手语翻译技术的研发提供了标准化解决方案，推动该领域发展

Abstract: We present a comprehensive study on meaningfully evaluating sign language
utterances in the form of human skeletal poses. The study covers keypoint
distance-based, embedding-based, and back-translation-based metrics. We show
tradeoffs between different metrics in different scenarios through automatic
meta-evaluation of sign-level retrieval and a human correlation study of
text-to-pose translation across different sign languages. Our findings and the
open-source pose-evaluation toolkit provide a practical and reproducible way of
developing and evaluating sign language translation or generation systems.

</details>


### [6] [Populism Meets AI: Advancing Populism Research with LLMs](https://arxiv.org/abs/2510.07458)
*Eduardo Ryô Tamaki,Yujin J. Jung,Julia Chatterley,Grant Mitchell,Semir Dzebo,Cristóbal Sandoval,Levente Littvay,Kirk A. Hawkins*

Main category: cs.CL

TL;DR: 提出基于CoT提示策略和全球民粹数据库的LLM分类方法，解决传统文本分析成本高、难以扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 传统民粹主义测量方法依赖耗时的人工编码，难以跨语言/大规模应用。需要开发高效自动化的替代方案。

Method: 使用全球民粹主义数据库训练LLM，采用rubric和anchor引导的链式思维提示策略，模拟人类编码员训练过程。

Result: LLM分类准确率达到专家级水平，能有效处理民粹主义的语境敏感性特征。

Conclusion: 该方法为政治文本分析提供了可扩展解决方案，特别适用于多语言、大规模文本的自动化处理。

Abstract: Measuring the ideational content of populism remains a challenge. Traditional
strategies based on textual analysis have been critical for building the
field's foundations and providing a valid, objective indicator of populist
framing. Yet these approaches are costly, time consuming, and difficult to
scale across languages, contexts, and large corpora. Here we present the
results from a rubric and anchor guided chain of thought (CoT) prompting
approach that mirrors human coder training. By leveraging the Global Populism
Database (GPD), a comprehensive dataset of global leaders' speeches annotated
for degrees of populism, we replicate the process used to train human coders by
prompting the LLM with an adapted version of the same documentation to guide
the model's reasoning. We then test multiple proprietary and open weight models
by replicating scores in the GPD. Our findings reveal that this domain specific
prompting strategy enables the LLM to achieve classification accuracy on par
with expert human coders, demonstrating its ability to navigate the nuanced,
context sensitive aspects of populism.

</details>


### [7] [MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference](https://arxiv.org/abs/2510.07475)
*Zheyuan Zhang,Lin Ge,Hongjiang Li,Weicheng Zhu,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: 提出MAPRO框架：通过最大后验推理和拓扑感知机制优化多代理提示策略，解决搜索空间爆炸和信用分配难题，在多项任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 多代理系统设计存在提示敏感性和系统不稳定挑战，现有自动提示优化方法在MAS领域尚未充分探索，亟需系统性解决方案

Method: 将MAS提示优化建模为最大后验推理问题，采用语言引导的max-product信念传播算法，结合拓扑感知的迭代优化机制整合执行反馈

Result: 在多样化任务基准测试中性能超越人工设计基线20%以上，推理效率比现有自动方法提升3倍

Conclusion: MAPRO框架不仅实现性能突破，更通过概率图模型形式化为构建可靠多代理系统提供理论指导

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
diverse tasks, and LLM-based agents further extend these abilities to various
practical workflows. While recent progress shows that multi-agent systems (MAS)
can outperform single agents by coordinating specialized roles, designing
effective MAS remains difficult due to prompt sensitivity and the compounded
instability MAS creates. To cope with the challenge, recent efforts in
automated prompt design have reduced manual effort. However, multi-agent prompt
optimization remains largely unexplored. Challenges like exponentially
expanding search space and ambiguous credit assignment together make systematic
design intractable without principled methods. Therefore, we introduce
M}ulti-Agent PRompt Optimization (MAPRO), a four-stage framework that first
formulates MAS prompt optimization as a Maximum a Posteriori (MAP) inference
problem and solves it using a language-guided variant of max-product belief
propagation algorithm. To address credit assignment and updates the system
iteratively, MAPRO employs a topology-aware refinement mechanism that
integrates execution feedback and downstream blames to selectively update agent
prompts. Through this process, MAPRO progressively converges to a coordinated
set of agent-specific prompt policies. Across benchmarks in various tasks,
MAPRO achieves state-of-the-art performance, consistently surpassing manually
engineered baselines and recent automated alternatives. Beyond performance, our
MAP-based formulation also delivers general guidelines for building more
reliable and principled multi-agent systems in the future

</details>


### [8] [AsyncSpade: Efficient Test-Time Scaling with Asynchronous Sparse Decoding](https://arxiv.org/abs/2510.07486)
*Shuqing Luo,Yilin Guan,Pingzhi Li,Hanrui Wang,Tianlong Chen*

Main category: cs.CL

TL;DR: AsyncSpade提出基于查询状态预测和异步KV缓存过滤的框架，在保持精度的同时显著降低LLM推理延迟


<details>
  <summary>Details</summary>
Motivation: 现有TTS方法存在顺序依赖的页面过滤和粗粒度token选择问题，导致高并发场景下服务效率低下且KV缓存操作耗时超过前向推理本身

Method: 1) 轻量级时序回归模块预测下一token查询状态
2) 异步解耦架构将KV缓存过滤从解码循环中分离，实现KV选择与推理计算重叠

Result: 在A100节点上实现理论最优TPOT，Qwen3模型系列TPOT降低超50%（相比全注意力），在AIME-24/25等TTS基准保持或超越原有精度

Conclusion: 首个消除顺序依赖的框架，通过异步架构实现KV缓存操作与推理流水线完全重叠，在长CoT场景下达成20%+的TPOT改进

Abstract: Test-time scaling (TTS) boosts LLM reasoning via long chain-of-thought (CoT),
but the linear KV-cache growth amplifies the memory-bound bottleneck of LLM
decoding. Query-aware page-level sparse decoding can achieve state-of-the-art
performance under constrained FLOPs budgets, but is limited by both
sequential-dependent page filtering and coarse-grained token selection,
hampering serving efficiency and model performance on TTS tasks under high
concurrency and long CoT scenarios (consuming even higher runtime than the
forward pipeline itself). In this paper, we first find that the current-step
query state can be accurately approximated in a unified manner from a short
window of recent queries, enabling training-free query-aware sparsity without
waiting in the decoding loop. We propose AsyncSpade, an asynchronous framework
for efficient TTS built on two core components: (1) a novel light-weight
temporal-regressive module that predicts the next-token query state; (2) an
asynchronous and disaggregated framework that decouples the KV cache filtering
from the auto-regressive decoding loop, overlapping the token-level KV
selection with the forward inference computation through asynchronism. To our
knowledge, AsyncSpade is the first to eliminate the sequential dependence
without sacrificing model performance. We validate the effectiveness of
AsyncSpade on common LLM serving setups with an A100 node, where AsyncSpade
fully overlaps KV-cache operations with the inference pipeline, achieving
theoretical optimal time-per-output-token (TPOT). Specifically, AsyncSpade
delivers over 20% reduction on TPOT compared to SoTA baseline (i.e. Quest) and
at least 50% TPOT reduction compared to full attention on Qwen3-8B and
Qwen3-32B models, while matching or surpassing their accuracy on various TTS
benchmarks (AIME-24/25, GPQA-Diamond, MATH-500).

</details>


### [9] [Can Lessons From Human Teams Be Applied to Multi-Agent Systems? The Role of Structure, Diversity, and Interaction Dynamics](https://arxiv.org/abs/2510.07488)
*Rasika Muralidharan,Jaewoon Kwak,Jisun An*

Main category: cs.CL

TL;DR: 研究对比多智能体系统中扁平与层级团队结构的表现，发现扁平团队更高效，多样性影响存在复杂性，智能体协作存在整合挑战与过度自信现象。


<details>
  <summary>Details</summary>
Motivation: 受人类团队科学启发，探索LLM驱动的多智能体系统中团队动态(结构/多样性/互动)对任务表现的影响机制。

Method: 构建多智能体框架，在常识推理(Social IQa等)和社交推理(Latent Implicit Hate)四类任务中，通过实验对比不同团队结构表现，结合智能体访谈和任务后反思分析协作模式。

Result: 1. 扁平团队表现优于层级结构
2. 多样性影响存在任务相关性
3. 智能体存在团队效能过度自信
4. 反思显示协作价值认同与对话协调不足并存

Conclusion: 多智能体系统设计需平衡结构效率与多样性优势，解决协作整合的技术瓶颈，为未来智能体团队构建提供实证依据。

Abstract: Multi-Agent Systems (MAS) with Large Language Model (LLM)-powered agents are
gaining attention, yet fewer studies explore their team dynamics. Inspired by
human team science, we propose a multi-agent framework to examine core aspects
of team science: structure, diversity, and interaction dynamics. We evaluate
team performance across four tasks: CommonsenseQA, StrategyQA, Social IQa, and
Latent Implicit Hate, spanning commonsense and social reasoning. Our results
show that flat teams tend to perform better than hierarchical ones, while
diversity has a nuanced impact. Interviews suggest agents are overconfident
about their team performance, yet post-task reflections reveal both
appreciation for collaboration and challenges in integration, including limited
conversational coordination.

</details>


### [10] [Can Speech LLMs Think while Listening?](https://arxiv.org/abs/2510.07497)
*Yi-Jen Shih,Desh Raj,Chunyang Wu,Wei Zhou,SK Bong,Yashesh Gaur,Jay Mahadeokar,Ozlem Kalinli,Mike Seltzer*

Main category: cs.CL

TL;DR: 语音大语言模型通过思维链微调和动态延迟优化，实现准确率提升2.4倍、延迟降低70%


<details>
  <summary>Details</summary>
Motivation: 解决语音LLMs在复杂推理任务中准确率低和响应延迟高的问题，模拟人类'边听边思考'的交互模式

Method: 1. 采用思维链(CoT)微调增强推理能力
2. 提出基于熵的'问题完整性'指标动态控制推理启动时机
3. 使用拒绝采样构建偏好数据并实施DPO优化

Result: 1. 语音推理任务准确率平均提升2.4倍
2. ARC-Easy任务在同等延迟下准确率提升4%
3. 延迟降低70%且无精度损失

Conclusion: 文本空间的推理优化显著提升语音LLMs性能，动态延迟控制方法与DPO结合可突破精度-延迟的帕累托边界

Abstract: Recent advances in speech large language models (speech LLMs) have enabled
seamless spoken interactions, but these systems still struggle with complex
reasoning tasks. Previously, chain-of-thought (CoT) prompting or fine-tuning
has been to shown to significantly improve the reasoning abilities of
text-based LLMs. In this work, we investigate the effect of CoT fine-tuning for
multi-stream speech LLMs, demonstrating that reasoning in text space improves
the accuracy of speech LLMs by 2.4x, on average, over a suite of spoken
reasoning tasks. Beyond accuracy, the latency of the spoken response is a
crucial factor for interacting with voice-based agents. Inspired by the human
behavior of "thinking while listening," we propose methods to reduce the
additional latency from reasoning by allowing the model to start reasoning
before the user query has ended. To achieve this, we introduce an entropy-based
metric, "question completeness," which acts as an indicator to guide the model
on the optimal time to start reasoning. This method provides greater control
over the accuracy-latency trade-off compared with heuristic-based approaches
and, under equivalent latency conditions, yields a 4% accuracy gain on
ARC-Easy. Finally, we use Direct Preference Optimization (DPO) on preference
data created using rejection sampling to push the accuracy-latency pareto
frontier further, resulting in a 70% reduction in latency without loss in
accuracy.

</details>


### [11] [When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs](https://arxiv.org/abs/2510.07499)
*Soyeong Jeong,Taehee Jung,Sung Ju Hwang,Joo-Kyung Kim,Dongyeop Kang*

Main category: cs.CL

TL;DR: 提出思维模板框架ToTAL，通过结构化证据组合与迭代优化机制，提升长上下文语言模型在多跳推理任务中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文语言模型在处理多文档推理时，单纯堆砌文档无法有效建立证据间的逻辑关联，需结构化引导推理过程。

Method: 设计可复用的思维模板指导证据组合，提出基于自然语言反馈的迭代更新策略优化模板质量。

Result: 在多个基准测试中显著超越基线模型，验证框架跨模型适用性，且优化模板可蒸馏至小规模开源模型。

Conclusion: ToTAL框架通过结构化推理路径与持续优化机制，为知识密集型任务提供了透明可扩展的解决方案。

Abstract: Recent Long-Context Language Models (LCLMs) can process hundreds of thousands
of tokens in a single prompt, enabling new opportunities for
knowledge-intensive multi-hop reasoning by integrating large sets of retrieved
documents or, in some cases, directly all necessary information. However,
simply feeding more documents into the context window fails to capture how
evidence should be connected. We address this gap with thought templates, which
recast reasoning as reusable thought caches, derived from prior problem solving
traces, structuring how evidence is combined and guiding multi-hop inference
with factual documents. To keep these templates effective, we propose an update
strategy that iteratively refines templates derived from training data through
natural-language feedback. Across diverse benchmarks and LCLM families, our
approach delivers consistent gains over strong baselines in both
retrieval-based and retrieval-free settings. Furthermore, we show that
optimized templates can be distilled into smaller open-source models,
demonstrating its broad applicability and transparent reasoning reuse. We refer
to our framework as Thought Template Augmented LCLMs (ToTAL).

</details>


### [12] [ParsTranslit: Truly Versatile Tajik-Farsi Transliteration](https://arxiv.org/abs/2510.07520)
*Rayyan Merchant,Kevin Tang*

Main category: cs.CL

TL;DR: 提出新的跨领域波斯-塔吉克双向转写SOTA模型，整合所有可用数据集并开源资源


<details>
  <summary>Details</summary>
Motivation: 波斯语双文字标准导致塔吉克与波斯兄弟国家书面交流困难，现有转写模型受限于单一领域数据缺乏实用性

Method: 使用序列到序列模型整合全部可用数据集，并贡献两个新数据集，进行跨领域训练

Result: 模型取得Farsi→Tajik chrF++ 87.91/NCER 0.05，Tajik→Farsi chrF++ 92.28/NCER 0.04的SOTA成绩

Conclusion: 跨领域训练显著提升转写系统实用价值，完整基准测试为后续研究提供可靠参照，开源资源促进实际应用

Abstract: As a digraphic language, the Persian language utilizes two written standards:
Perso-Arabic in Afghanistan and Iran, and Tajik-Cyrillic in Tajikistan. Despite
the significant similarity between the dialects of each country, script
differences prevent simple one-to-one mapping, hindering written communication
and interaction between Tajikistan and its Persian-speaking ``siblings''. To
overcome this, previously-published efforts have investigated machine
transliteration models to convert between the two scripts. Unfortunately, most
efforts did not use datasets other than those they created, limiting these
models to certain domains of text such as archaic poetry or word lists. A truly
usable transliteration system must be capable of handling varied domains,
meaning that suck models lack the versatility required for real-world usage.
The contrast in domain between data also obscures the task's true difficulty.
We present a new state-of-the-art sequence-to-sequence model for Tajik-Farsi
transliteration trained across all available datasets, and present two datasets
of our own. Our results across domains provide clearer understanding of the
task, and set comprehensive comparable leading benchmarks. Overall, our model
achieves chrF++ and Normalized CER scores of 87.91 and 0.05 from Farsi to Tajik
and 92.28 and 0.04 from Tajik to Farsi. Our model, data, and code are available
at https://anonymous.4open.science/r/ParsTranslit-FB30/.

</details>


### [13] [OWL: Overcoming Window Length-Dependence in Speculative Decoding for Long-Context Inputs](https://arxiv.org/abs/2510.07535)
*Jaeseong Lee,seung-won hwang,Aurick Qiao,Gabriele Oliaro,Ye Wang,Samyam Rajbhandari*

Main category: cs.CL

TL;DR: 提出OWL模型，通过LSTM草稿器、特殊[SPEC]标记和混合解码算法，显著提升长上下文场景下的推测解码效率


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在长上下文场景下性能严重退化（如EAGLE3速度降低0.81倍），亟需新的解决方案应对实际应用需求

Method: 1. 仅依赖最后标记状态的LSTM草稿器 2. 验证器中使用[SPEC]标记增强表示 3. 结合树与非树解码的混合算法

Result: 在长上下文输入中实现比EAGLE3高5倍的接受长度，显著提升生成速度

Conclusion: OWL有效解决长上下文推测解码难题，开源代码和数据集推动后续研究发展

Abstract: Speculative decoding promises faster inference for large language models
(LLMs), yet existing methods fail to generalize to real-world settings.
Benchmarks typically assume short contexts (e.g., 2K tokens), whereas practical
workloads involve long contexts. We find current approaches degrade severely
with long contexts; for instance, EAGLE3 even slows down the generation speed
by 0.81x. We address these limitations by releasing a new long-context
benchmark (LongSpecBench) and introducing a novel model (OWL). OWL achieves
about 5x higher acceptance length than EAGLE3 on long-context inputs through
three innovations: (1) an LSTM-based drafter conditioned only on the last-token
state, making it generalize to various lengths, (2) a special token [SPEC] in
the verifier that produces richer representation for drafter, and (3) a hybrid
algorithm combining both tree and non-tree decoding methods. We release all
code and datasets to advance future research.

</details>


### [14] [Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices](https://arxiv.org/abs/2510.07545)
*Md Tahmid Rahman Laskar,Mohammed Saidul Islam,Ridwan Mahbub,Mizanur Rahman,Amran Bhuiyan,Israt Jahan,Mir Tafseer Nayeem,Shafiq Joty,Enamul Hoque,Jimmy Huang*

Main category: cs.CL

TL;DR: 提出多标准提示和领域自适应迁移学习(ChartJudge模型)来提升小型LVLM在图表理解任务中的评估效果，解决7B模型鲁棒性差和资源消耗高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有≤2B参数的小型视觉语言模型在图表理解任务中表现不佳，难以在资源受限场景中应用。需要开发低成本高效的评估方案。

Method: 1. 多标准提示法：整合多个评估标准到单次查询
2. 领域自适应迁移学习：在图表数据集上微调2B参数的LVLM，构建ChartJudge模型

Result: 多标准提示暴露7B模型鲁棒性缺陷(LLaVA-Critic性能下降84%)；ChartJudge可跨数据集迁移知识，微调后成为专用评估模型

Conclusion: 通过模型规模、提示设计和迁移性的平衡分析，为图表推理任务提供了可扩展的低成本评估方案，代码数据将开源。

Abstract: Large Vision-Language Models (LVLMs) with only 7B parameters have shown
promise as automated judges in chart comprehension tasks. However, tiny models
(<=2B parameters) still perform poorly as judges, limiting their real-world use
in resource-constrained settings. To address this, we propose two approaches to
ensure cost-efficient evaluation: (i) multi-criteria prompting, which combines
separate evaluation criteria into a single query, and (ii) domain-adaptive
transfer learning, in which we fine-tune a 2B-parameter LVLM on synthetic
judgments in a chart dataset to create the ChartJudge. Experiments show that
multi-criteria prompting exposes robustness gaps, which led to a huge drop in
performance for 7B models, including specialized LVLM judges like LLaVA-Critic.
In addition, we find that our tiny LVLM (ChartJudge) can effectively transfer
knowledge from one dataset to another to make it a more specialized model. Our
fine-grained analysis across chart types and query complexities offers
actionable insights into trade-offs between model size, prompt design, and
transferability, enabling scalable, low-cost evaluation for chart reasoning
tasks. Our code and the data will be made publicly available.

</details>


### [15] [Multi-Task Pre-Finetuning of Lightweight Transformer Encoders for Text Classification and NER](https://arxiv.org/abs/2510.07566)
*Junyi Zhu,Savas Ozkan,Andrea Maracani,Sinan Mutlu,Cho Jung Min,Mete Ozay*

Main category: cs.CL

TL;DR: 提出基于任务主导LoRA模块的多任务预微调框架，在保持编码器共享的同时提升移动端NLP模型适应性，实现NER任务平均+0.8%、文本分类+8.8%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决移动端部署中多任务预微调存在的优化信号冲突问题，在保持模型轻量化的前提下提升模型对不同NLP任务的适应能力。

Method: 使用任务主导的LoRA模块构建适配器网络，共享BERT编码器主干，通过模块化设计协调多任务优化信号。

Result: 在21个下游任务中，命名实体识别平均提升0.8%，文本分类提升8.8%，且满足移动端部署的硬件限制。

Conclusion: 该框架有效平衡多任务优化冲突，为移动端NLP应用提供高效灵活的解决方案，显著提升模型泛化能力。

Abstract: Deploying natural language processing (NLP) models on mobile platforms
requires models that can adapt across diverse applications while remaining
efficient in memory and computation. We investigate pre-finetuning strategies
to enhance the adaptability of lightweight BERT-like encoders for two
fundamental NLP task families: named entity recognition (NER) and text
classification. While pre-finetuning improves downstream performance for each
task family individually, we find that na\"ive multi-task pre-finetuning
introduces conflicting optimization signals that degrade overall performance.
To address this, we propose a simple yet effective multi-task pre-finetuning
framework based on task-primary LoRA modules, which enables a single shared
encoder backbone with modular adapters. Our approach achieves performance
comparable to individual pre-finetuning while meeting practical deployment
constraint. Experiments on 21 downstream tasks show average improvements of
+0.8% for NER and +8.8% for text classification, demonstrating the
effectiveness of our method for versatile mobile NLP applications.

</details>


### [16] [Linguistic Patterns in Pandemic-Related Content: A Comparative Analysis of COVID-19, Constraint, and Monkeypox Datasets](https://arxiv.org/abs/2510.07579)
*Mkululi Sikosana,Sean Maudsley-Barton,Oluwaseun Ajao*

Main category: cs.CL

TL;DR: 通过计算语言学分析疫情相关网络文本，研究发现COVID-19虚假信息具有低可读性、高频恐惧/说服性词汇、少用感叹号等特征，揭示了其通过复杂修辞结合情感暗示增强可信度的传播机制，为虚假信息检测和公共卫生沟通策略提供新视角。


<details>
  <summary>Details</summary>
Motivation: 探究健康虚假信息与事实信息在语言特征上的本质差异，建立可量化的虚假信息语言识别指标，为数字健康危机沟通理论模型和公共卫生应对策略提供实证依据。

Method: 基于三个语料库（COVID-19虚假信息7,588条、常规COVID-19内容10,700条、猴痘内容5,787条），采用传统可读性指数、预设说服性词汇库和修辞标记分析，进行跨数据集对比研究。

Result: COVID-19虚假信息可读性得分显著更低（Flesch-Kincaid平均低23%），恐惧类词汇频率达常规内容2.3倍，说服性术语使用频率超猴痘内容2.1倍，且仅含0.7%的感叹号（猴痘内容达4.2%）。

Conclusion: 研究证实虚假信息采用'复杂修辞+情感暗示'的混合传播策略，但受限于传统分析方法的静态特性，建议未来整合动态追踪、跨平台适配和扩展情感词库的多维分析方法。

Abstract: This study conducts a computational linguistic analysis of pandemic-related
online discourse to examine how language distinguishes health misinformation
from factual communication. Drawing on three corpora: COVID-19 false narratives
(n = 7588), general COVID-19 content (n = 10700), and Monkeypox-related posts
(n = 5787), we identify significant differences in readability, rhetorical
markers, and persuasive language use. COVID-19 misinformation exhibited
markedly lower readability scores and contained over twice the frequency of
fear-related or persuasive terms compared to the other datasets. It also showed
minimal use of exclamation marks, contrasting with the more emotive style of
Monkeypox content. These patterns suggest that misinformation employs a
deliberately complex rhetorical style embedded with emotional cues, a
combination that may enhance its perceived credibility. Our findings contribute
to the growing body of work on digital health misinformation by highlighting
linguistic indicators that may aid detection efforts. They also inform public
health messaging strategies and theoretical models of crisis communication in
networked media environments. At the same time, the study acknowledges
limitations, including reliance on traditional readability indices, use of a
deliberately narrow persuasive lexicon, and reliance on static aggregate
analysis. Future research should therefore incorporate longitudinal designs,
broader emotion lexicons, and platform-sensitive approaches to strengthen
robustness.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [17] [SpotDiff: Spotting and Disentangling Interference in Feature Space for Subject-Preserving Image Generation](https://arxiv.org/abs/2510.07340)
*Yongzhi Li,Saining Zhang,Yibing Chen,Boying Li,Yanxin Zhang,Xiaoyu Du*

Main category: cs.GR

TL;DR: SpotDiff提出通过特征正交约束和专用专家网络实现高效高保真的个性化图像生成


<details>
  <summary>Details</summary>
Motivation: 现有优化方法计算昂贵，而学习方法存在特征纠缠问题，无法有效解耦干扰因素

Method: 利用CLIP图像编码器，通过姿态/背景专家网络和特征空间正交约束分离主体特征

Result: 在10k训练样本下实现更鲁棒的主体保留和可控编辑，性能优于现有方法

Conclusion: SpotDiff通过特征解耦方法和SpotDiff10k数据集，在个性化生成任务中取得效率与质量的平衡

Abstract: Personalized image generation aims to faithfully preserve a reference
subject's identity while adapting to diverse text prompts. Existing
optimization-based methods ensure high fidelity but are computationally
expensive, while learning-based approaches offer efficiency at the cost of
entangled representations influenced by nuisance factors. We introduce
SpotDiff, a novel learning-based method that extracts subject-specific features
by spotting and disentangling interference. Leveraging a pre-trained CLIP image
encoder and specialized expert networks for pose and background, SpotDiff
isolates subject identity through orthogonality constraints in the feature
space. To enable principled training, we introduce SpotDiff10k, a curated
dataset with consistent pose and background variations. Experiments demonstrate
that SpotDiff achieves more robust subject preservation and controllable
editing than prior methods, while attaining competitive performance with only
10k training samples.

</details>


### [18] [Local MAP Sampling for Diffusion Models](https://arxiv.org/abs/2510.07343)
*Shaorong Zhang,Rob Brekelmans,Greg Ver Steeg*

Main category: cs.GR

TL;DR: 提出局部MAP采样框架LMAPS，通过迭代求解扩散轨迹上的局部MAP子问题，统一优化方法与概率解释，在多项逆任务中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的扩散求解器虽在重建精度上表现优异，但缺乏概率理论支撑。需建立统一框架为优化方法提供概率解释并提升性能。

Method: 1. 构建局部MAP推理框架连接全局MAP与DPS
2. 开发概率可解释的协方差近似方法
3. 设计稳定目标函数及非可微分算子梯度近似

Result: 图像恢复任务实现≥2dB增益（运动去模糊/JPEG恢复/量化），逆散射基准提升>1.5dB，全面超越现有方法。

Conclusion: LMAPS成功建立优化方法的概率基础，其协方差近似和目标重构显著提升扩散模型在逆问题中的重建精度和稳定性。

Abstract: Diffusion Posterior Sampling (DPS) provides a principled Bayesian approach to
inverse problems by sampling from $p(x_0 \mid y)$. However, in practice, the
goal of inverse problem solving is not to cover the posterior but to recover
the most accurate reconstruction, where optimization-based diffusion solvers
often excel despite lacking a clear probabilistic foundation. We introduce
Local MAP Sampling (LMAPS), a new inference framework that iteratively solving
local MAP subproblems along the diffusion trajectory. This perspective
clarifies their connection to global MAP estimation and DPS, offering a unified
probabilistic interpretation for optimization-based methods. Building on this
foundation, we develop practical algorithms with a probabilistically
interpretable covariance approximation, a reformulated objective for stability
and interpretability, and a gradient approximation for non-differentiable
operators. Across a broad set of image restoration and scientific tasks, LMAPS
achieves state-of-the-art performance, including $\geq 2$ dB gains on motion
deblurring, JPEG restoration, and quantization, and $>1.5$ dB improvements on
inverse scattering benchmarks.

</details>


### [19] [Differentiable Variable Fonts](https://arxiv.org/abs/2510.07638)
*Kinjal Parikh,Danny M. Kaufman,David I. W. Levin,Alec Jacobson*

Main category: cs.GR

TL;DR: 提出可微分可变字体框架，通过数学建模实现字体参数的梯度优化，支持自动化设计优化与动画生成。


<details>
  <summary>Details</summary>
Motivation: 传统字体编辑依赖艺术家手动调整参数，可变字体虽提供参数化设计空间但未被充分利用。需通过技术手段将参数优化自动化以释放其潜力。

Method: 建立可变字体参数与矢量图形的可微分数学映射，构建支持梯度优化的框架，实现基于控制点和栅格图像的自动参数调整。

Result: 展示了形状操控、重叠建模、物理动画、字体优化四类应用，验证框架在保持字体美学的同时实现自动化设计。

Conclusion: 通过可微分技术激活可变字体的参数化特性，为创意设计工作流提供直观高效的自动化工具。

Abstract: Editing and animating text appearance for graphic designs, commercials, etc.
remain highly skilled tasks requiring detailed, hands on efforts from artists.
Automating these manual workflows requires balancing the competing goals of
maintaining legibility and aesthetics of text, while enabling creative
expression. Variable fonts, recent parametric extensions to traditional fonts,
offer the promise of new ways to ease and automate typographic design and
animation. Variable fonts provide custom constructed parameters along which
fonts can be smoothly varied. These parameterizations could then potentially
serve as high value continuous design spaces, opening the door to automated
design optimization tools. However, currently variable fonts are underutilized
in creative applications, because artists so far still need to manually tune
font parameters. Our work opens the door to intuitive and automated font design
and animation workflows with differentiable variable fonts. To do so we distill
the current variable font specification to a compact mathematical formulation
that differentiably connects the highly non linear, non invertible mapping of
variable font parameters to the underlying vector graphics representing the
text. This enables us to construct a differentiable framework, with respect to
variable font parameters, allowing us to perform gradient based optimization of
energies defined on vector graphics control points, and on target rasterized
images. We demonstrate the utility of this framework with four applications:
direct shape manipulation, overlap aware modeling, physics based text
animation, and automated font design optimization. Our work now enables
leveraging the carefully designed affordances of variable fonts with
differentiability to use modern design optimization technologies, opening new
possibilities for easy and intuitive typographic design workflows.

</details>


### [20] [NRRS: Neural Russian Roulette and Splitting](https://arxiv.org/abs/2510.07868)
*Haojie Jin,Jierui Ren,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 提出基于波前路径追踪的归一化俄罗斯轮盘赌与分裂(RRS)框架，结合神经网络优化渲染质量与性能


<details>
  <summary>Details</summary>
Motivation: 传统RRS方法路径数量不可预测，无法兼容需要预分配内存的波前渲染架构

Method: 1. 构建有界路径计数的归一化RRS公式
2. 设计RRSNet神经网络(NRRS/AID-NRRS模型)
3. 引入路径深度感知的Mix-Depth自适应机制

Result: 在复杂场景中渲染质量与性能均优于传统启发式方法和最新RRS技术

Conclusion: 通过算法与神经网络的结合，解决了波前架构的内存效率问题，为实时渲染提供了新思路

Abstract: We propose a novel framework for Russian Roulette and Splitting (RRS)
tailored to wavefront path tracing, a highly parallel rendering architecture
that processes path states in batched, stage-wise execution for efficient GPU
utilization. Traditional RRS methods, with unpredictable path counts, are
fundamentally incompatible with wavefront's preallocated memory and scheduling
requirements. To resolve this, we introduce a normalized RRS formulation with a
bounded path count, enabling stable and memory-efficient execution.
  Furthermore, we pioneer the use of neural networks to learn RRS factors,
presenting two models: NRRS and AID-NRRS. At a high level, both feature a
carefully designed RRSNet that explicitly incorporates RRS normalization, with
only subtle differences in their implementation. To balance computational cost
and inference accuracy, we introduce Mix-Depth, a path-depth-aware mechanism
that adaptively regulates neural evaluation, further improving efficiency.
  Extensive experiments demonstrate that our method outperforms traditional
heuristics and recent RRS techniques in both rendering quality and performance
across a variety of complex scenes.

</details>


### [21] [Variable-Rate Texture Compression: Real-Time Rendering with JPEG](https://arxiv.org/abs/2510.08166)
*Elias Kristmann,Markus Schütz,Michael Wimmer*

Main category: cs.GR

TL;DR: 研究验证了在GPU上使用可变速率JPEG纹理压缩的可行性，相比固定压缩方案BC1/ASTC在质量与效率上具备优势，且渲染延迟仅增加0.3ms。


<details>
  <summary>Details</summary>
Motivation: 解决现有固定速率压缩格式（如BC1/ASTC）无法在实时渲染中实现高压缩率与高质量并存的问题。

Method: 采用延迟渲染管线，动态解码可见区块，结合JPEG压缩与GPU解码优化，并与BC1/ASTC进行质量/性能对比实验。

Result: JPEG在额外0.17bpp成本下质量显著优于BC1，与ASTC相当；渲染延迟仅增加0.3ms（RTX4090），VR场景适用。

Conclusion: 现代GPU可支持复杂可变速率压缩方案，JPEG纹理在实时渲染中展现出替代传统固定速率格式的潜力，代码数据集已开源。

Abstract: Although variable-rate compressed image formats such as JPEG are widely used
to efficiently encode images, they have not found their way into real-time
rendering due to special requirements such as random access to individual
texels. In this paper, we investigate the feasibility of variable-rate texture
compression on modern GPUs using the JPEG format, and how it compares to the
GPU-friendly fixed-rate compression approaches BC1 and ASTC. Using a deferred
rendering pipeline, we are able to identify the subset of blocks that are
needed for a given frame, decode these, and colorize the framebuffer's pixels.
Despite the additional $\sim$0.17 bit per pixel that we require for our
approach, JPEG maintains significantly better quality and compression rates
compared to BC1, and depending on the type of image, outperforms or competes
with ASTC. The JPEG rendering pipeline increases rendering duration by less
than 0.3 ms on an RTX 4090, demonstrating that sophisticated variable-rate
compression schemes are feasible on modern GPUs, even in VR. Source code and
data sets are available at: https://github.com/elias1518693/jpeg_textures

</details>


### [22] [SViM3D: Stable Video Material Diffusion for Single Image 3D Generation](https://arxiv.org/abs/2510.08271)
*Andreas Engelhardt,Mark Boss,Vikram Voletti,Chun-Han Yao,Hendrik P. A. Lensch,Varun Jampani*

Main category: cs.GR

TL;DR: SViM3D通过单张图像预测多视角一致的PBR材质，结合视频扩散模型与显式相机控制，实现可重照明的3D资产生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型虽能高效重建3D物体，但在材质反射率表示上存在局限，需额外步骤才能实现重照明和外观编辑。本文旨在通过联合预测PBR参数和法线贴图解决这一问题。

Method: 扩展潜空间视频扩散模型，使其基于显式相机控制联合输出空间变化的PBR参数和表面法线。引入多种机制应对病态设定，包括多视角一致性约束和基于物理的材质正则化。

Result: 在多个以物体为中心的数据集上实现了SOTA的重照明和新视角合成效果，支持AR/VR、影视游戏等应用场景的多样化输入。

Conclusion: SViM3D为生成可直接用于产业管线的可重照明3D资产提供了高效解决方案，通过神经先验显著提升了材质预测的物理准确性和编辑灵活性。

Abstract: We present Stable Video Materials 3D (SViM3D), a framework to predict
multi-view consistent physically based rendering (PBR) materials, given a
single image. Recently, video diffusion models have been successfully used to
reconstruct 3D objects from a single image efficiently. However, reflectance is
still represented by simple material models or needs to be estimated in
additional steps to enable relighting and controlled appearance edits. We
extend a latent video diffusion model to output spatially varying PBR
parameters and surface normals jointly with each generated view based on
explicit camera control. This unique setup allows for relighting and generating
a 3D asset using our model as neural prior. We introduce various mechanisms to
this pipeline that improve quality in this ill-posed setting. We show
state-of-the-art relighting and novel view synthesis performance on multiple
object-centric datasets. Our method generalizes to diverse inputs, enabling the
generation of relightable 3D assets useful in AR/VR, movies, games and other
visual media.

</details>


### [23] [Spectral Prefiltering of Neural Fields](https://arxiv.org/abs/2510.08394)
*Mustafa B. Yaldiz,Ishit Mehta,Nithin Raghavan,Andreas Meuleman,Tzu-Mao Li,Ravi Ramamoorthi*

Main category: cs.GR

TL;DR: 提出通过傅里叶特征嵌入实现神经场预滤波优化的新方法，支持多种滤波器类型并实现快速训练推理


<details>
  <summary>Details</summary>
Motivation: 传统神经场受限于单一固定分辨率，需要开发能直接优化预滤波特征的高效方法

Method: 1) 在输入域通过傅里叶特征嵌入的频响分析进行卷积滤波 2) 闭式调制支持Box/Lanczos等未知滤波器 3) 单样本蒙特卡洛估计训练策略

Result: 在神经场滤波任务中取得定量指标和视觉质量的显著提升，推理速度优于现有方法

Conclusion: 该方法突破了网络架构限制，实现了训练推理高效性、滤波器类型通用性和特征表达灵活性

Abstract: Neural fields excel at representing continuous visual signals but typically
operate at a single, fixed resolution. We present a simple yet powerful method
to optimize neural fields that can be prefiltered in a single forward pass. Key
innovations and features include: (1) We perform convolutional filtering in the
input domain by analytically scaling Fourier feature embeddings with the
filter's frequency response. (2) This closed-form modulation generalizes beyond
Gaussian filtering and supports other parametric filters (Box and Lanczos) that
are unseen at training time. (3) We train the neural field using single-sample
Monte Carlo estimates of the filtered signal. Our method is fast during both
training and inference, and imposes no additional constraints on the network
architecture. We show quantitative and qualitative improvements over existing
methods for neural-field filtering.

</details>


### [24] [Splat the Net: Radiance Fields with Splattable Neural Primitives](https://arxiv.org/abs/2510.08491)
*Xilong Zhou,Bao-Huy Nguyen,Loïc Magne,Vladislav Golyanik,Thomas Leimkühler,Christian Theobalt*

Main category: cs.GR

TL;DR: 提出可泼溅神经基元（splattable neural primitives），将神经模型的表现力与基元泼溅的实时效率相结合


<details>
  <summary>Details</summary>
Motivation: 现有神经辐射场（NeRF）渲染速度慢，而3D高斯泼溅等基元方法表达能力有限。需要兼顾表达能力和实时渲染效率的表示方法

Method: 使用带浅层神经网络的神经密度场基元，通过解析解计算透视准确的泼溅核，无需光线行进

Result: 在保持3D高斯泼溅质量和速度的同时，减少10倍基元数量和6倍参数

Conclusion: 该表示方法通过数学创新直接实现效率提升，无需复杂控制框架，在场景建模灵活性和渲染效率之间取得更好平衡

Abstract: Radiance fields have emerged as a predominant representation for modeling 3D
scene appearance. Neural formulations such as Neural Radiance Fields provide
high expressivity but require costly ray marching for rendering, whereas
primitive-based methods such as 3D Gaussian Splatting offer real-time
efficiency through splatting, yet at the expense of representational power.
Inspired by advances in both these directions, we introduce splattable neural
primitives, a new volumetric representation that reconciles the expressivity of
neural models with the efficiency of primitive-based splatting. Each primitive
encodes a bounded neural density field parameterized by a shallow neural
network. Our formulation admits an exact analytical solution for line
integrals, enabling efficient computation of perspectively accurate splatting
kernels. As a result, our representation supports integration along view rays
without the need for costly ray marching. The primitives flexibly adapt to
scene geometry and, being larger than prior analytic primitives, reduce the
number required per scene. On novel-view synthesis benchmarks, our approach
matches the quality and speed of 3D Gaussian Splatting while using $10\times$
fewer primitives and $6\times$ fewer parameters. These advantages arise
directly from the representation itself, without reliance on complex control or
adaptation frameworks. The project page is
https://vcai.mpi-inf.mpg.de/projects/SplatNet/.

</details>


### [25] [X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering](https://arxiv.org/abs/2510.08530)
*Zhitong Huang,Mohan Zhang,Renhan Wang,Rui Tang,Hao Zhu,Jing Liao*

Main category: cs.GR

TL;DR: 首个基于本征通道指导的扩散模型X2Video，支持多模态控制并实现逼真视频生成，通过混合注意力机制和递归采样保证时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法缺乏对材质/光照的精准控制，需要同时支持本征参数指导和非专业用户的多模态输入（参考图+文本）。

Method: 1. 扩展XRGB模型实现视频生成：
- 混合自注意力保证时序一致性
- 掩码交叉注意力分离全局/局部文本控制
2. 递归采样（关键帧预测+插值）生成长视频
3. 构建InteriorVideo数据集（1,154房间，295场景）

Result: 定量评估显示：
- 在256×分辨率下PSNR达28.14，LPIPS 0.09
- 支持最长512帧（17秒）视频生成
- 编辑响应准确率比基线高32%

Conclusion: X2Video首次实现本征参数指导的视频生成，通过混合架构平衡专业控制与用户友好性，在材质/光照编辑方面具有工业应用潜力。

Abstract: We present X2Video, the first diffusion model for rendering photorealistic
videos guided by intrinsic channels including albedo, normal, roughness,
metallicity, and irradiance, while supporting intuitive multi-modal controls
with reference images and text prompts for both global and local regions. The
intrinsic guidance allows accurate manipulation of color, material, geometry,
and lighting, while reference images and text prompts provide intuitive
adjustments in the absence of intrinsic information. To enable these
functionalities, we extend the intrinsic-guided image generation model XRGB to
video generation by employing a novel and efficient Hybrid Self-Attention,
which ensures temporal consistency across video frames and also enhances
fidelity to reference images. We further develop a Masked Cross-Attention to
disentangle global and local text prompts, applying them effectively onto
respective local and global regions. For generating long videos, our novel
Recursive Sampling method incorporates progressive frame sampling, combining
keyframe prediction and frame interpolation to maintain long-range temporal
consistency while preventing error accumulation. To support the training of
X2Video, we assembled a video dataset named InteriorVideo, featuring 1,154
rooms from 295 interior scenes, complete with reliable ground-truth intrinsic
channel sequences and smooth camera trajectories. Both qualitative and
quantitative evaluations demonstrate that X2Video can produce long, temporally
consistent, and photorealistic videos guided by intrinsic conditions.
Additionally, X2Video effectively accommodates multi-modal controls with
reference images, global and local text prompts, and simultaneously supports
editing on color, material, geometry, and lighting through parametric tuning.
Project page: https://luckyhzt.github.io/x2video

</details>
