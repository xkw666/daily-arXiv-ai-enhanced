<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 82]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias](https://arxiv.org/abs/2509.19314)
*Sirui Wu,Daijin Yang*

Main category: cs.CL

TL;DR: 研究通过大语言模型改写人格量表降低社会期望偏差，结果显示AI中和法效果有限但具潜力


<details>
  <summary>Details</summary>
Motivation: 解决人格测评中因社会期望偏差导致的效度失真问题，探索LLM在心理测量工具优化中的应用

Method: 使用GPT-3改写IPIP-BFM-50量表，203名被试随机完成原始/中和版量表+MCSDS测量

Result: 保持信度与五因子结构；尽责性提升，亲和性/开放性下降；部分项目社会期望相关减弱但存在不一致性；仅达成配置等值

Conclusion: AI中和法能部分降低社会期望偏差，但在测量等值性方面存在局限，需结合其他方法优化

Abstract: This study evaluates item neutralization assisted by the large language model
(LLM) to reduce social desirability bias in personality assessment. GPT-o3 was
used to rewrite the International Personality Item Pool Big Five Measure
(IPIP-BFM-50), and 203 participants completed either the original or
neutralized form along with the Marlowe-Crowne Social Desirability Scale. The
results showed preserved reliability and a five-factor structure, with gains in
Conscientiousness and declines in Agreeableness and Openness. The correlations
with social desirability decreased for several items, but inconsistently.
Configural invariance held, though metric and scalar invariance failed.
Findings support AI neutralization as a potential but imperfect bias-reduction
method.

</details>


### [2] [FHIR-AgentBench: Benchmarking LLM Agents for Realistic Interoperable EHR Question Answering](https://arxiv.org/abs/2509.19319)
*Gyubok Lee,Elea Bach,Eric Yang,Tom Pollard,Alistair Johnson,Edward Choi,Yugang jia,Jong Ha Lee*

Main category: cs.CL

TL;DR: 开发了基于HL7 FHIR标准的FHIR-AgentBench基准，系统性评估临床AI代理框架在2931个真实临床问题中的表现，揭示FHIR数据检索与推理的实际挑战。


<details>
  <summary>Details</summary>
Motivation: 现有临床AI评估基准未能跟进HL7 FHIR标准转型，缺乏对互操作性临床数据场景下LLM代理的实用性评估需求。

Method: 通过真实临床问题构建基准，评估不同数据检索策略（直接API调用/专用工具）、交互模式（单轮/多轮）和推理策略（自然语言/代码生成）的性能差异。

Result: 实验表明复杂FHIR资源的数据检索与推理存在显著实践挑战，直接影响临床问答性能。

Conclusion: 开源FHIR-AgentBench数据集与评估套件，推动临床LLM代理的可靠发展与可重复研究。

Abstract: The recent shift toward the Health Level Seven Fast Healthcare
Interoperability Resources (HL7 FHIR) standard opens a new frontier for
clinical AI, demanding LLM agents to navigate complex, resource-based data
models instead of conventional structured health data. However, existing
benchmarks have lagged behind this transition, lacking the realism needed to
evaluate recent LLMs on interoperable clinical data. To bridge this gap, we
introduce FHIR-AgentBench, a benchmark that grounds 2,931 real-world clinical
questions in the HL7 FHIR standard. Using this benchmark, we systematically
evaluate agentic frameworks, comparing different data retrieval strategies
(direct FHIR API calls vs. specialized tools), interaction patterns
(single-turn vs. multi-turn), and reasoning strategies (natural language vs.
code generation). Our experiments highlight the practical challenges of
retrieving data from intricate FHIR resources and the difficulty of reasoning
over them, both of which critically affect question answering performance. We
publicly release the FHIR-AgentBench dataset and evaluation suite
(https://github.com/glee4810/FHIR-AgentBench) to promote reproducible research
and the development of robust, reliable LLM agents for clinical applications.

</details>


### [3] [Readme_AI: Dynamic Context Construction for Large Language Models](https://arxiv.org/abs/2509.19322)
*Millie Vyas,Timothy Blattner,Alden Dima*

Main category: cs.CL

TL;DR: 提出可扩展的Readme_AI协议，通过动态构建数据源上下文增强LLM的专业领域响应质量，减少幻觉现象


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面对特定数据查询时容易产生不准确信息，需要动态上下文提升回答可靠性

Method: 设计模型上下文协议(MCP)，通过元数据检索、可扩展内容类型(网页/存储库/论文)、用户标签分组构建动态上下文

Result: 在Hedgehog库案例中，LLM获得上下文后能准确推理并生成有效代码，消除原有幻觉问题

Conclusion: 该协议成功实现了LLM在专业数据源的动态知识锚定，显著提升回答质量并降低幻觉发生率

Abstract: Despite being trained on significant amounts of data, Large Language Models
(LLMs) can provide inaccurate or unreliable information in the context of a
user's specific query. Given query-specific context significantly improves the
usefulness of its responses. In this paper, we present a specification that can
be used to dynamically build context for data sources. The data source owner
creates the file containing metadata for LLMs to use when reasoning about
dataset-related queries. To demonstrate our proposed specification, we created
a prototype Readme_AI Model Context Protocol (MCP) server that retrieves the
metadata from the data source and uses it to dynamically build context. Some
features that make this specification dynamic are the extensible types that
represent crawling web-pages, fetching data from data repositories, downloading
and parsing publications, and general text. The context is formatted and
grouped using user-specified tags that provide clear contextual information for
the LLM to reason about the content. We demonstrate the capabilities of this
early prototype by asking the LLM about the NIST-developed Hedgehog library,
for which common LLMs often provides inaccurate and irrelevant responses
containing hallucinations. With Readme_AI, the LLM receives enough context that
it is now able to reason about the library and its use, and even generate code
interpolated from examples that were included in the Readme_AI file provided by
Hedgehog's developer. Our primary contribution is a extensible protocol for
dynamically grounding LLMs in specialized, owner-provided data, enhancing
responses from LLMs and reducing hallucinations. The source code for the
Readme_AI tool is posted here: https://github.com/usnistgov/readme_ai .

</details>


### [4] [Magnitude Matters: a Superior Class of Similarity Metrics for Holistic Semantic Understanding](https://arxiv.org/abs/2509.19323)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 提出两种新型无参数、考虑向量范数的相似度指标（OS/HTS），在整体语义理解任务中显著优于传统点积和余弦相似度


<details>
  <summary>Details</summary>
Motivation: 现有标准方法存在明显缺陷：原始点积对向量范数敏感且无界，余弦相似度完全忽略向量大小信息。需要更合理的向量范数与方向整合方式

Method: 设计Overlap Similarity和Hyperbolic Tangent Similarity两种指标，使用4种前沿句子嵌入模型（包括all-MiniLM/bge等），在8个NLP基准（STS-B/SICK/Quora/PAWS等）进行系统评估，采用Wilcoxon符号秩检验确保统计显著性

Result: 在复述/推理等整体语义任务中，新指标的MSE显著优于传统方法（p<0.05），但在需要细粒度组合语义的任务（SICK/STS-B）未显示优势，揭示了组合语义表示的特殊挑战

Conclusion: 新型相似度指标为特定语义任务提供更优解决方案，未来应重点突破组合文本的向量表示难题

Abstract: Vector comparison in high dimensions is a fundamental task in NLP, yet it is
dominated by two baselines: the raw dot product, which is unbounded and
sensitive to vector norms, and the cosine similarity, which discards magnitude
information entirely. This paper challenges both standards by proposing and
rigorously evaluating a new class of parameter-free, magnitude-aware similarity
metrics. I introduce two such functions, Overlap Similarity (OS) and Hyperbolic
Tangent Similarity (HTS), designed to integrate vector magnitude and alignment
in a more principled manner. To ensure that my findings are robust and
generalizable, I conducted a comprehensive evaluation using four
state-of-the-art sentence embedding models (all-MiniLM-L6-v2,
all-mpnet-base-v2, paraphrase-mpnet-base-v2, and BAAI/bge-large-en-v1.5) across
a diverse suite of eight standard NLP benchmarks, including STS-B, SICK, Quora,
and PAWS. Using the Wilcoxon signed-rank test for statistical significance, my
results are definitive: on the tasks requiring holistic semantic understanding
(paraphrase and inference), both OS and HTS provide a statistically significant
improvement in Mean Squared Error over both the raw dot product and cosine
similarity, regardless of the underlying embedding model.Crucially, my findings
delineate the specific domain of advantage for these metrics: for tasks
requiring holistic semantic understanding like paraphrase and inference, my
magnitude-aware metrics offer a statistically superior alternative. This
significant improvement was not observed on benchmarks designed to test highly
nuanced compositional semantics (SICK, STS-B), identifying the challenge of
representing compositional text as a distinct and important direction for
future work.

</details>


### [5] [How Much of Your Data Can Suck? Thresholds for Domain Performance and Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.19325)
*Jian Ouyang,Arman T,Ge Jin*

Main category: cs.CL

TL;DR: 论文发现微调数据中即使存在10-25%错误数据也会显著降低GPT-4o领域性能，需至少50%正确数据才能恢复性能，且基础模型安全性最佳


<details>
  <summary>Details</summary>
Motivation: 探究错误数据对LLM监督微调的影响，特别是在金融、医疗等高风险领域，错误数据可能导致模型输出危害性内容

Method: 通过不同比例（10-90%）显性和隐性错误数据微调GPT-4o，覆盖代码、金融、医疗和法律四大领域进行测试

Result: 10-25%错误数据即导致性能断崖式下降，50%正确数据是恢复阈值，但微调模型始终无法达到基础模型的安全水平（零危险输出）

Conclusion: 强调高质量数据的重要性，建议高风险领域优先使用未经微调的基础模型而非强制进行风险性微调

Abstract: This paper investigates the impact of incorrect data on the performance and
safety of large language models (LLMs), specifically gpt-4o, during supervised
fine-tuning (SFT). Although LLMs become increasingly vital across broad domains
like finance, coding, law, and health, fine-tuning on incorrect data can lead
to "emergent misalignment," producing harmful or deceptive outputs unrelated to
the intended task. We evaluate gpt-4o models fine-tuned with varying ratios
(10\% to 90\% correct) of both obviously and subtly incorrect data across four
domains: coding, finance, health, and legal. Our findings show that even modest
amounts of incorrect data (10-25\%) dramatically degrade domain performance and
not moral alignment. A clear threshold of at least 50\% correct data is needed
for models to consistently recover strong performance, though they rarely match
the robustness and safety of the base model, which exhibits near-perfect
alignment and zero dangerous completions out-of-the-box. This research
emphasizes that the cost of incorrect data is heavy, highlighting the critical
need for extremely high-quality data curation or, alternatively, leveraging
robust base models without unnecessary fine-tuning for high-stakes
applications.

</details>


### [6] [Unveiling the Merits and Defects of LLMs in Automatic Review Generation for Scientific Papers](https://arxiv.org/abs/2509.19326)
*Ruochi Li,Haoxuan Zhang,Edward Gehringer,Ting Xiao,Junhua Ding,Haihua Chen*

Main category: cs.CL

TL;DR: 通过构建大规模基准数据集和知识图谱指标，系统评估发现LLM生成评审在描述优点方面优于人类（如GPT-4o生成实体多15.74%），但在弱点识别（实体减少59.42%）和质量敏感度（节点增幅仅5.7%）存在显著差距


<details>
  <summary>Details</summary>
Motivation: 解决传统同行评审压力，探索LLM自动评审的可行性及其在批判性推理、质量敏感性方面的局限性

Method: 整合语义相似性分析和知识图谱指标，使用ICLR/NeurIPS的1,683篇论文和6,495篇人类评审构建基准，测试5个LLM生成质量

Result: LLM在描述论文贡献/方法时表现优异，但识别弱点时实体生成量骤降（GPT-4o弱于人类59.42%），质量调整能力仅为人类的1/8（5.7% vs 50%节点增幅）

Conclusion: LLM自动评审当前适用于辅助性描述任务，但需突破批判性思维瓶颈，未来应开发结合领域知识的混合评审系统

Abstract: The surge in scientific submissions has placed increasing strain on the
traditional peer-review process, prompting the exploration of large language
models (LLMs) for automated review generation. While LLMs demonstrate
competence in producing structured and coherent feedback, their capacity for
critical reasoning, contextual grounding, and quality sensitivity remains
limited. To systematically evaluate these aspects, we propose a comprehensive
evaluation framework that integrates semantic similarity analysis and
structured knowledge graph metrics to assess LLM-generated reviews against
human-written counterparts. We construct a large-scale benchmark of 1,683
papers and 6,495 expert reviews from ICLR and NeurIPS in multiple years, and
generate reviews using five LLMs. Our findings show that LLMs perform well in
descriptive and affirmational content, capturing the main contributions and
methodologies of the original work, with GPT-4o highlighted as an illustrative
example, generating 15.74% more entities than human reviewers in the strengths
section of good papers in ICLR 2025. However, they consistently underperform in
identifying weaknesses, raising substantive questions, and adjusting feedback
based on paper quality. GPT-4o produces 59.42% fewer entities than real
reviewers in the weaknesses and increases node count by only 5.7% from good to
weak papers, compared to 50% in human reviews. Similar trends are observed
across all conferences, years, and models, providing empirical foundations for
understanding the merits and defects of LLM-generated reviews and informing the
development of future LLM-assisted reviewing tools. Data, code, and more
detailed results are publicly available at
https://github.com/RichardLRC/Peer-Review.

</details>


### [7] [A systematic review of trial-matching pipelines using large language models](https://arxiv.org/abs/2509.19327)
*Braxton A. Morrison,Madhumita Sushil,Jacob S. Young*

Main category: cs.CL

TL;DR: 系统综述显示，LLMs（尤其是GPT-4）在自动化临床试验匹配中表现优异，但面临数据标准化、部署成本和隐私保护等挑战。


<details>
  <summary>Details</summary>
Motivation: 解决人工匹配临床试验效率低下问题，探索LLMs自动化匹配的潜力及现存技术瓶颈。

Method: 系统综述2020-2025年31篇文献，分析LLM在患者-标准/试验匹配、资格分类等任务的表现，评估合成/真实数据集的应用差异。

Result: GPT-4在匹配任务中优于其他模型（包括微调模型），但成本较高；零样本提示结合高级检索策略有效，开源小模型微调可解决隐私问题。

Conclusion: 未来需建立标准化评估指标、采用真实测试集，并兼顾成本效益与公平性，以实现LLM在临床匹配中的规模化应用。

Abstract: Matching patients to clinical trial options is critical for identifying novel
treatments, especially in oncology. However, manual matching is labor-intensive
and error-prone, leading to recruitment delays. Pipelines incorporating large
language models (LLMs) offer a promising solution. We conducted a systematic
review of studies published between 2020 and 2025 from three academic databases
and one preprint server, identifying LLM-based approaches to clinical trial
matching. Of 126 unique articles, 31 met inclusion criteria. Reviewed studies
focused on matching patient-to-criterion only (n=4), patient-to-trial only
(n=10), trial-to-patient only (n=2), binary eligibility classification only
(n=1) or combined tasks (n=14). Sixteen used synthetic data; fourteen used real
patient data; one used both. Variability in datasets and evaluation metrics
limited cross-study comparability. In studies with direct comparisons, the
GPT-4 model consistently outperformed other models, even finely-tuned ones, in
matching and eligibility extraction, albeit at higher cost. Promising
strategies included zero-shot prompting with proprietary LLMs like the GPT-4o
model, advanced retrieval methods, and fine-tuning smaller, open-source models
for data privacy when incorporation of large models into hospital
infrastructure is infeasible. Key challenges include accessing sufficiently
large real-world data sets, and deployment-associated challenges such as
reducing cost, mitigating risk of hallucinations, data leakage, and bias. This
review synthesizes progress in applying LLMs to clinical trial matching,
highlighting promising directions and key limitations. Standardized metrics,
more realistic test sets, and attention to cost-efficiency and fairness will be
critical for broader deployment.

</details>


### [8] [How Model Size, Temperature, and Prompt Style Affect LLM-Human Assessment Score Alignment](https://arxiv.org/abs/2509.19329)
*Julie Jung,Max Lu,Sina Chole Benker,Dogus Darici*

Main category: cs.CL

TL;DR: 大模型规模是影响LLM临床推理评估与人类评分一致性的关键因素，研究强调需多层面检测对齐性


<details>
  <summary>Details</summary>
Motivation: 探究模型规模、温度参数和提示方式对LLM在临床推理能力评估中自对齐、模型间对齐及人机对齐的影响

Method: 通过控制变量法系统检测不同规模LLM在不同温度参数和提示风格下的临床推理评估结果，进行多层次对齐度分析

Result: 模型规模与LLM-人类评分一致性呈强正相关，温度参数和提示风格对跨模型对齐影响更显著

Conclusion: 临床领域应用需建立多维对齐检测框架，模型规模优化是实现可靠人机评估对齐的核心路径

Abstract: We examined how model size, temperature, and prompt style affect Large
Language Models' (LLMs) alignment within itself, between models, and with human
in assessing clinical reasoning skills. Model size emerged as a key factor in
LLM-human score alignment. Study highlights the importance of checking
alignments across multiple levels.

</details>


### [9] [Quantifying Compositionality of Classic and State-of-the-Art Embeddings](https://arxiv.org/abs/2509.19332)
*Zhijin Guo,Chenhao Xue,Zhaozhen Xu,Hongbo Bo,Yuxuan Ye,Janet B. Pierrehumbert,Martha Lewis*

Main category: cs.CL

TL;DR: 本文提出了一种量化语言模型组合性的两阶段评估方法，通过线性分析和重构测试验证模型处理未知属性组合的能力，发现组合性信号在训练后期和Transformer深层中更显著。


<details>
  <summary>Details</summary>
Motivation: 现有模型在组合性处理上存在两极分化：静态词嵌入过度强调组合性，而Transformer等生成模型又缺乏对语境语义变化的约束。需要建立量化评估框架揭示模型组合性机制。

Method: 1. 使用典型相关分析衡量已知实体属性与嵌入的线性关系；2. 通过重构未知属性组合的嵌入（L2损失、余弦相似度、检索准确率）评估组合泛化能力；3. 跨数据模态（文本/知识图谱）和模型层次追踪组合性信号。

Result: 在所有数据模态中，组合性信号随训练阶段推进而增强；Transformer深层（倒数第二层）展现出最强组合性，顶层略有下降；重构指标有效捕获组合性失效案例。

Conclusion: 该量化框架揭示了模型架构与训练过程对组合性的影响，为提升模型语义组合能力提供分析工具，代码已开源供社区验证和改进。

Abstract: For language models to generalize correctly to novel expressions, it is
critical that they exploit access compositional meanings when this is
justified. Even if we don't know what a "pelp" is, we can use our knowledge of
numbers to understand that "ten pelps" makes more pelps than "two pelps".
Static word embeddings such as Word2vec made strong, indeed excessive, claims
about compositionality. The SOTA generative, transformer models and graph
models, however, go too far in the other direction by providing no real limits
on shifts in meaning due to context. To quantify the additive compositionality,
we formalize a two-step, generalized evaluation that (i) measures the linearity
between known entity attributes and their embeddings via canonical correlation
analysis, and (ii) evaluates additive generalization by reconstructing
embeddings for unseen attribute combinations and checking reconstruction
metrics such as L2 loss, cosine similarity, and retrieval accuracy. These
metrics also capture failure cases where linear composition breaks down.
Sentences, knowledge graphs, and word embeddings are evaluated and tracked the
compositionality across all layers and training stages. Stronger compositional
signals are observed in later training stages across data modalities, and in
deeper layers of the transformer-based model before a decline at the top layer.
Code is available at
https://github.com/Zhijin-Guo1/quantifying-compositionality.

</details>


### [10] [Pluralistic Off-policy Evaluation and Alignment](https://arxiv.org/abs/2509.19333)
*Chengkai Huang,Junda Wu,Zhouhang Xie,Yu Xia,Rui Wang,Tong Yu,Subrata Mitra,Julian McAuley,Lina Yao*

Main category: cs.CL

TL;DR: 提出首个LLM离轨策略多样性偏好评估框架POPE，通过协同效用与多样性奖励平衡人类偏好，实证有效提升生成多样性且不损害模型性能


<details>
  <summary>Details</summary>
Motivation: 现有偏好对齐方法忽视人类偏好多样性，且离轨策略评估仅关注整体效用。需构建支持多样性偏好评估与对齐的新框架

Method: 提出POPE框架：1) 结合人类偏好信号(点赞/相关性分数)的协同效用组件 2) 基于熵的多样性组件 3) 推导可分解的IPS估计器分别评估相关性与多样性

Result: 实证表明POPE有效提升多样性响应生成，同时保持模型在下游任务的通用能力

Conclusion: POPE首次实现离轨策略下的多样性偏好评估与对齐，通过分解式奖励机制平衡效用与多样性，为LLM个性化对齐提供新范式

Abstract: Personalized preference alignment for LLMs with diverse human preferences
requires evaluation and alignment methods that capture pluralism. Most existing
preference alignment datasets are logged under policies that differ
substantially from the evaluated LLMs, and existing off-policy estimators focus
solely on overall utility while ignoring preference pluralism. Extending
Off-Policy Evaluation (OPE) to pluralistic preference alignment, therefore,
remains an open question. Thus, we propose the Pluralistic Off-Policy
Evaluation (POPE), the first framework for offline pluralistic preference
evaluation and alignment in LLMs. POPE includes a unified reward function that
combines (1) a collaborative utility component derived from human preference
signals (e.g., upvotes or relevance scores) and (2) a diversity component
inspired by entropy-based coverage measures, together reflecting pluralistic
alignment. Furthermore, to estimate this reward from logged interactions, we
derive decomposable inverse propensity scoring (IPS) estimators that separately
evaluate relevance and diversity. Theoretically, we prove that our decomposed
IPS estimators establish a lower bound on their variance. With the off-policy
evaluated value function, we can directly enable off-policy optimization to
further enhance pluralistic alignment. Empirical results demonstrate that POPE
efficiently enhances pluralistic response generation and maintains the models'
general capabilities on downstream tasks

</details>


### [11] [Cognitive-Level Adaptive Generation via Capability-Aware Retrieval and Style Adaptation](https://arxiv.org/abs/2509.19336)
*Qingsong Wang,Tao Wu,Wang Lin,Yueying Feng,Gongsheng Yuan,Chang Yao,Jingyuan Chen*

Main category: cs.CL

TL;DR: 提出了CLAF框架解决LLM认知不对齐问题，通过知识图检索和风格优化提升生成内容与用户认知的匹配度


<details>
  <summary>Details</summary>
Motivation: LLM在生成内容时存在认知不对齐现象，具体表现为知识复杂度与用户理解能力不匹配，呈现形式阻碍有效理解

Method: 1. 基于层次知识图的能力感知检索模块
2. 结合布鲁姆分类法和偏好学习的风格优化模块
3. 知识可控生成组件保持输出一致性

Result: 构建SCALE评估数据集显示，CLAF显著提升了不同用户画像下LLM输出的适应性和信息密度

Conclusion: CLAF为实际应用中的认知层级对齐提供了系统解决方案，通过知识-风格双重优化增强生成内容的可理解性

Abstract: Large Language Models (LLMs) have demonstrated strong performance in
open-ended generation tasks. However, they often struggle to adapt content to
users with differing cognitive capacities, leading to a phenomenon we term
cognitive misalignment. This issue arises in two forms: knowledge-level
misalignment, where content is too complex or too simplistic relative to user
understanding, and presentation-style misalignment, where the structure or tone
hinders effective comprehension. To address these challenges, we propose the
Cognitive-Level Alignment Framework (CLAF), a general-purpose generation
framework that aligns both knowledge complexity and presentation style with
user cognition. CLAF integrates a capability-aware retrieval module based on a
hierarchical knowledge graph and a style optimization module guided by Bloom's
taxonomy and preference learning. Additionally, a knowledge-controllable
generation component ensures consistency and relevance throughout the output.
To support training and evaluation, we construct SCALE, a cognitively annotated
dataset containing responses at multiple comprehension levels per query.
Empirical results show that CLAF enhances the adaptability and informativeness
of LLM outputs across a range of user profiles, offering a robust solution to
cognitive-level alignment in real-world applications.

</details>


### [12] [Part-of-speech tagging for Nagamese Language using CRF](https://arxiv.org/abs/2509.19343)
*Alovi N Shohe,Chonglio Khiamungam,Teisovi Angami*

Main category: cs.CL

TL;DR: 首次对Nagamese语言进行词性标注研究，使用条件随机场模型取得85.7%准确率


<details>
  <summary>Details</summary>
Motivation: Nagamese作为资源稀缺的克里奥尔语缺乏NLP研究，填补该语言词性标注领域空白

Method: 创建16,112个标记的标注语料库，应用条件随机场(CRF)机器学习技术

Result: 整体标注准确率85.70%，精确率86%，召回率86%，F1值85%

Conclusion: 成功验证CRF在Nagamese词性标注的有效性，为低资源语言处理提供基线标准

Abstract: This paper investigates part-of-speech tagging, an important task in Natural
Language Processing (NLP) for the Nagamese language. The Nagamese language,
a.k.a. Naga Pidgin, is an Assamese-lexified Creole language developed primarily
as a means of communication in trade between the Nagas and people from Assam in
northeast India. A substantial amount of work in part-of-speech-tagging has
been done for resource-rich languages like English, Hindi, etc. However, no
work has been done in the Nagamese language. To the best of our knowledge, this
is the first attempt at part-of-speech tagging for the Nagamese Language. The
aim of this work is to identify the part-of-speech for a given sentence in the
Nagamese language. An annotated corpus of 16,112 tokens is created and applied
machine learning technique known as Conditional Random Fields (CRF). Using CRF,
an overall tagging accuracy of 85.70%; precision, recall of 86%, and f1-score
of 85% is achieved.
  Keywords. Nagamese, NLP, part-of-speech, machine learning, CRF.

</details>


### [13] [Performance of Large Language Models in Answering Critical Care Medicine Questions](https://arxiv.org/abs/2509.19344)
*Mahmoud Alwakeel,Aditya Nagori,An-Kwok Ian Wong,Neal Chaisson,Vijay Krishnamoorthy,Rishikesan Kamaleswaran*

Main category: cs.CL

TL;DR: 70B参数的Llama3.1模型在重症医学问题测试中表现优于8B版本30%，但不同子领域存在显著性能差异


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在重症监护医学等专业领域的实际应用潜力

Method: 使用871个重症监护医学问题测试Llama3.1的8B和70B参数模型

Result: 70B模型平均准确率60%（研究领域68.4%，肾脏领域47.9%），较8B模型提升30%

Conclusion: 需扩展模型在专科子领域的研究以全面提升医疗AI性能

Abstract: Large Language Models have been tested on medical student-level questions,
but their performance in specialized fields like Critical Care Medicine (CCM)
is less explored. This study evaluated Meta-Llama 3.1 models (8B and 70B
parameters) on 871 CCM questions. Llama3.1:70B outperformed 8B by 30%, with 60%
average accuracy. Performance varied across domains, highest in Research
(68.4%) and lowest in Renal (47.9%), highlighting the need for broader future
work to improve models across various subspecialty domains.

</details>


### [14] [SCORE: A Semantic Evaluation Framework for Generative Document Parsing](https://arxiv.org/abs/2509.19345)
*Renyu Li,Antonio Jimeno Yepes,Yao You,Kamil Pluciński,Maximilian Operlejn,Crag Wolfe*

Main category: cs.CL

TL;DR: SCORE框架通过多维度评估方法解决传统文档解析指标对结构性差异的误判，实现生成式文档解析系统的公平评估


<details>
  <summary>Details</summary>
Motivation: 传统OCR评估指标（CER/WER/IoU/TEDS）将结构性差异视为错误，无法适应生成式文档解析系统的语义正确但结构多样的输出特性

Method: 整合四维度方法：1) 调整编辑距离评估内容保真度 2) 分词级诊断区分幻觉与遗漏 3) 空间容忍度+语义对齐的表格评估 4) 层次结构一致性验证

Result: 在1,114页数据测试中，成功识别跨数据集性能模式，修正12-25%传统指标误判案例，表格F1值最高达0.93，证明纯生成式解析可满足评估需求

Conclusion: SCORE建立了基于语义、支持解释多样性且兼顾公平性的现代文档解析系统评估范式，为行业基准测试提供理论框架和实践工具

Abstract: Multi-modal generative document parsing systems challenge traditional
evaluation: unlike deterministic OCR or layout models, they often produce
semantically correct yet structurally divergent outputs. Conventional
metrics-CER, WER, IoU, or TEDS-misclassify such diversity as error, penalizing
valid interpretations and obscuring system behavior.
  We introduce SCORE (Structural and COntent Robust Evaluation), an
interpretation-agnostic framework that integrates (i) adjusted edit distance
for robust content fidelity, (ii) token-level diagnostics to distinguish
hallucinations from omissions, (iii) table evaluation with spatial tolerance
and semantic alignment, and (iv) hierarchy-aware consistency checks. Together,
these dimensions enable evaluation that embraces representational diversity
while enforcing semantic rigor.
  Across 1,114 pages spanning a holistic benchmark and a field dataset, SCORE
consistently revealed cross-dataset performance patterns missed by standard
metrics. In 2-5% of pages with ambiguous table structures, traditional metrics
penalized systems by 12-25% on average, leading to distorted rankings. SCORE
corrected these cases, recovering equivalence between alternative but valid
interpretations. Moreover, by normalizing generative outputs into a
format-agnostic representation, SCORE reproduces traditional scores (e.g.,
table F1 up to 0.93) without requiring object-detection pipelines,
demonstrating that generative parsing alone suffices for comprehensive
evaluation.
  By exposing how interpretive diversity impacts evaluation outcomes and
providing multi-dimensional, interpretable diagnostics, SCORE establishes
foundational principles for semantically grounded, fair, and practical
benchmarking of modern document parsing systems.

</details>


### [15] [Benchmarking ChatGPT and DeepSeek in April 2025: A Novel Dual Perspective Sentiment Analysis Using Lexicon-Based and Deep Learning Approaches](https://arxiv.org/abs/2509.19346)
*Maryam Mahdi Alhusseini,Mohammad-Reza Feizi-Derakhshi*

Main category: cs.CL

TL;DR: 本研究结合词典分析和深度学习模型（CNN/Bi-LSTM）分析应用商店用户评论，发现ChatGPT好评率显著高于DeepSeek，且CNN模型以96.41%准确率超越传统方法


<details>
  <summary>Details</summary>
Motivation: 解决现有研究孤立使用词典分析或预测模型的局限，全面评估用户对LLM应用的满意度差异

Method: 收集4000条真实用户评论，经预处理和过采样平衡后，使用TextBlob、CNN和Bi-LSTM进行双视角情感分析

Result: ChatGPT积极情感占比更高；CNN在平衡测试集上准确率达96.41%，负面评论分类近乎完美，各情感类别F1-score均表现优异

Conclusion: 建立了LLM应用情感分析新标准，为提升用户导向的AI设计提供方法论支持和实践洞见

Abstract: This study presents a novel dual-perspective approach to analyzing user
reviews for ChatGPT and DeepSeek on the Google Play Store, integrating
lexicon-based sentiment analysis (TextBlob) with deep learning classification
models, including Convolutional Neural Networks (CNN) and Bidirectional Long
Short Term Memory (Bi LSTM) Networks. Unlike prior research, which focuses on
either lexicon-based strategies or predictive deep learning models in
isolation, this study conducts an extensive investigation into user
satisfaction with Large Language Model (LLM) based applications. A Dataset of
4,000 authentic user reviews was collected, which were carefully preprocessed
and subjected to oversampling to achieve balanced classes. The balanced test
set of 1,700 Reviews were used for model testing. Results from the experiments
reveal that ChatGPT received significantly more positive sentiment than
DeepSeek. Furthermore, deep learning based classification demonstrated superior
performance over lexicon analysis, with CNN outperforming Bi-LSTM by achieving
96.41 percent accuracy and near perfect classification of negative reviews,
alongside high F1-scores for neutral and positive sentiments. This research
sets a new methodological standard for measuring sentiment in LLM-based
applications and provides practical insights for developers and researchers
seeking to improve user-centric AI system design.

</details>


### [16] [Characterizing Knowledge Graph Tasks in LLM Benchmarks Using Cognitive Complexity Frameworks](https://arxiv.org/abs/2509.19347)
*Sara Todorovikj,Lars-Peter Meyer,Michael Martin*

Main category: cs.CL

TL;DR: 提出基于认知心理学框架的LLM-KG任务评估新方法


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱任务的评估主要关注准确性，需要补充性评估维度来揭示深层认知需求

Method: 应用认知心理学中的三种复杂度框架分析LLM-KG-Bench评估体系

Result: 发现价值分布偏差、识别评估需求盲区，推动建立更丰富的多维度评估标准

Conclusion: 认知复杂度框架为LLM-KG任务评估提供新视角，促进更全面的基准测试设计

Abstract: Large Language Models (LLMs) are increasingly used for tasks involving
Knowledge Graphs (KGs), whose evaluation typically focuses on accuracy and
output correctness. We propose a complementary task characterization approach
using three complexity frameworks from cognitive psychology. Applying this to
the LLM-KG-Bench framework, we highlight value distributions, identify
underrepresented demands and motivate richer interpretation and diversity for
benchmark evaluation tasks.

</details>


### [17] [ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution](https://arxiv.org/abs/2509.19349)
*Robert Tjarko Lange,Yuki Imajuku,Edoardo Cetin*

Main category: cs.CL

TL;DR: ShinkaEvolve开源框架通过父采样平衡、代码新颖性筛选和LLM集成策略三大创新，在150样本内实现SOTA圆包装方案并优化多项科学计算任务


<details>
  <summary>Details</summary>
Motivation: 现有代码进化方法存在样本效率低下（需数千样本）和闭源限制，阻碍了科学发现技术的广泛应用与扩展

Method: 1. 探索-利用平衡的父采样技术 2. 代码新颖性拒绝采样算法 3. 基于bandit的LLM集成选择策略

Result: 实现150样本SOTA圆包装方案、AIME数学推理任务高性能解决方案、ALE-Bench竞赛编程改进方案，发现新型MoE负载均衡损失函数

Conclusion: ShinkaEvolve通过开源框架实现高效低成本的科学发现，为各类计算问题提供开放式的创新解决方案

Abstract: We introduce ShinkaEvolve: a new open-source framework leveraging large
language models (LLMs) to advance scientific discovery with state-of-the-art
performance and unprecedented efficiency. Recent advances in scaling inference
time compute of LLMs have enabled significant progress in generalized
scientific discovery. These approaches rely on evolutionary agentic harnesses
that leverage LLMs as mutation operators to generate candidate solutions.
However, current code evolution methods suffer from critical limitations: they
are sample inefficient, requiring thousands of samples to identify effective
solutions, and remain closed-source, hindering broad adoption and extension.
ShinkaEvolve addresses these limitations, introducing three key innovations: a
parent sampling technique balancing exploration and exploitation, code novelty
rejection-sampling for efficient search space exploration, and a bandit-based
LLM ensemble selection strategy. We evaluate ShinkaEvolve across diverse tasks,
demonstrating consistent improvements in sample efficiency and solution
quality. ShinkaEvolve discovers a new state-of-the-art circle packing solution
using only 150 samples, designs high-performing agentic harnesses for AIME
mathematical reasoning tasks, identifies improvements to ALE-Bench competitive
programming solutions, and discovers novel mixture-of-expert load balancing
loss functions that illuminate the space of optimization strategies. Our
results demonstrate that ShinkaEvolve achieves broad applicability with
exceptional sample efficiency. By providing open-source accessibility and
cost-efficiency, this work democratizes open-ended discovery across diverse
computational problems.

</details>


### [18] [TriSPrompt: A Hierarchical Soft Prompt Model for Multimodal Rumor Detection with Incomplete Modalities](https://arxiv.org/abs/2509.19352)
*Jiajun Chen,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi*

Main category: cs.CL

TL;DR: 提出TriSPrompt模型，通过MA/MM/MV三种提示机制处理多模态数据缺失问题，在真实数据集上实现13%以上的准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法依赖完整模态数据，难以应对现实场景中常见的模态缺失问题

Method: 1.MA提示捕获模态异构特征并恢复缺失数据 2.MM提示建模缺失状态 3.MV提示融合主客观视角关系

Result: 在三个真实基准数据集上超越SOTA方法，准确率提升超13%

Conclusion: TriSPrompt有效解决了多模态数据缺失问题，显著提升了谣言检测的鲁棒性和准确性

Abstract: The widespread presence of incomplete modalities in multimodal data poses a
significant challenge to achieving accurate rumor detection. Existing
multimodal rumor detection methods primarily focus on learning joint modality
representations from \emph{complete} multimodal training data, rendering them
ineffective in addressing the common occurrence of \emph{missing modalities} in
real-world scenarios. In this paper, we propose a hierarchical soft prompt
model \textsf{TriSPrompt}, which integrates three types of prompts,
\textit{i.e.}, \emph{modality-aware} (MA) prompt, \emph{modality-missing} (MM)
prompt, and \emph{mutual-views} (MV) prompt, to effectively detect rumors in
incomplete multimodal data. The MA prompt captures both heterogeneous
information from specific modalities and homogeneous features from available
data, aiding in modality recovery. The MM prompt models missing states in
incomplete data, enhancing the model's adaptability to missing information. The
MV prompt learns relationships between subjective (\textit{i.e.}, text and
image) and objective (\textit{i.e.}, comments) perspectives, effectively
detecting rumors. Extensive experiments on three real-world benchmarks
demonstrate that \textsf{TriSPrompt} achieves an accuracy gain of over 13\%
compared to state-of-the-art methods. The codes and datasets are available at
https: //anonymous.4open.science/r/code-3E88.

</details>


### [19] [RoadMind: Towards a Geospatial AI Expert for Disaster Response](https://arxiv.org/abs/2509.19354)
*Ahmed El Fekih Zguir,Ferda Ofli,Muhammad Imran*

Main category: cs.CL

TL;DR: RoadMind框架利用OpenStreetMap数据增强大语言模型的地理空间推理能力，在灾害响应任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏地理空间推理能力，而灾害响应场景中需要准确的空间理解支持救援决策。

Method: 通过自动化管道提取城市道路数据并转化为多格式监督信号，使用QLoRA适配器和4位量化模型进行预训练与微调。

Result: 在洛杉矶、基督城和马尼拉的实验中，RoadMind模型在道路识别、最近路径检索等任务上优于SOTA模型（含增强提示工程）。

Conclusion: 结构化地理空间数据能有效增强语言模型的空间推理能力，为灾害响应提供更可靠的离线AI支持。

Abstract: Large Language Models (LLMs) have shown impressive performance across a range
of natural language tasks, but remain limited in their ability to reason about
geospatial data, particularly road networks, distances, and directions. This
gap poses challenges in disaster scenarios, where spatial understanding is
critical for tasks such as evacuation planning and resource allocation. In this
work, we present RoadMind, a self-supervised framework that enhances the
geospatial reasoning capabilities of LLMs using structured data from
OpenStreetMap (OSM). Our automated pipeline extracts road infrastructure data
for a given city and converts it into multiple supervision formats tailored to
key spatial tasks. We pretrain and fine-tune LLMs on these representations
using QLoRA adapters and 4-bit quantized models. We evaluate our approach on
three disaster-prone cities with varying global representation, Los Angeles,
Christchurch, and Manila, across tasks such as road segment identification,
nearest road retrieval, and distance/direction estimation. Our results show
that models trained via RoadMind significantly outperform strong baselines,
including state-of-the-art LLMs equipped with advanced prompt engineering. This
demonstrates the potential of structured geospatial data to enhance language
models with robust spatial reasoning, enabling more effective offline AI
systems for disaster response.

</details>


### [20] [Benchmarking and Improving LLM Robustness for Personalized Generation](https://arxiv.org/abs/2509.19358)
*Chimaobi Okite,Naihao Deng,Kiran Bodipati,Huaidian Hou,Joyce Chai,Rada Mihalcea*

Main category: cs.CL

TL;DR: 提出PERG框架与PERGData数据集，验证大模型个性化响应中事实准确性与用户偏好对齐的鲁棒性，发现主流模型存在缺陷并提出改进方法Pref-Aligner


<details>
  <summary>Details</summary>
Motivation: 现有大模型个性化评估仅关注用户偏好对齐，忽视事实准确性。研究旨在建立兼顾两者的鲁棒性评估体系，揭示模型在真实场景中的可靠性问题

Method: 构建PERG可扩展评估框架及数据集，测试5类14个模型在不同提示策略下的表现，最终提出两阶段优化方法Pref-Aligner

Result: 主流模型（GPT-4/LLaMA3-70B）在5%成功案例中无法保持正确性，小模型失败率超20%；Pref-Aligner使平均鲁棒性提升25%

Conclusion: 当前大模型存在个性化与事实性冲突风险，需采用新评估工具与优化方法（如Pref-Aligner）确保可靠部署，推动更全面的评估标准建立

Abstract: Recent years have witnessed a growing interest in personalizing the responses
of large language models (LLMs). While existing evaluations primarily focus on
whether a response aligns with a user's preferences, we argue that factuality
is an equally important yet often overlooked dimension. In the context of
personalization, we define a model as robust if its responses are both
factually accurate and align with the user preferences. To assess this, we
introduce PERG, a scalable framework for evaluating robustness in LLMs, along
with a new dataset, PERGData. We evaluate fourteen models from five different
model families using different prompting methods. Our findings show that
current LLMs struggle with robust personalization: even the strongest models
(GPT-4.1, LLaMA3-70B) fail to maintain correctness in 5% of previously
successful cases without personalization, while smaller models (e.g., 7B-scale)
can fail more than 20% of the time. Further analysis reveals that robustness is
significantly affected by the nature of the query and the type of user
preference. To mitigate these failures, we propose Pref-Aligner, a two-stage
approach that improves robustness by an average of 25% across models. Our work
highlights critical gaps in current evaluation practices and introduces tools
and metrics to support more reliable, user-aligned LLM deployments.

</details>


### [21] [Semantic Representation Attack against Aligned Large Language Models](https://arxiv.org/abs/2509.19360)
*Jiawei Lian,Jianhong Pan,Lefan Wang,Yi Wang,Shaohui Mei,Lap-Pui Chau*

Main category: cs.CL

TL;DR: 提出语义表征攻击新范式，通过语义空间重构对抗目标，实现89.41%平均攻击成功率


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于精确文本匹配，存在收敛性差、提示不自然、计算成本高等缺陷

Method: 语义表征启发式搜索算法，在增量扩展中保持可解释性，生成语义连贯的对抗提示

Result: 在18个LLM上实现89.41%平均攻击成功率（其中11个模型达100%），兼具隐蔽性和高效性

Conclusion: 语义表征攻击从根本上解决攻击效能与提示自然性的权衡，代码将开源提供

Abstract: Large Language Models (LLMs) increasingly employ alignment techniques to
prevent harmful outputs. Despite these safeguards, attackers can circumvent
them by crafting prompts that induce LLMs to generate harmful content.
  Current methods typically target exact affirmative responses, such as ``Sure,
here is...'', suffering from limited convergence, unnatural prompts, and high
computational costs.
  We introduce Semantic Representation Attack, a novel paradigm that
fundamentally reconceptualizes adversarial objectives against aligned LLMs.
  Rather than targeting exact textual patterns, our approach exploits the
semantic representation space comprising diverse responses with equivalent
harmful meanings.
  This innovation resolves the inherent trade-off between attack efficacy and
prompt naturalness that plagues existing methods.
  The Semantic Representation Heuristic Search algorithm is proposed to
efficiently generate semantically coherent and concise adversarial prompts by
maintaining interpretability during incremental expansion.
  We establish rigorous theoretical guarantees for semantic convergence and
demonstrate that our method achieves unprecedented attack success rates
(89.41\% averaged across 18 LLMs, including 100\% on 11 models) while
maintaining stealthiness and efficiency.
  Comprehensive experimental results confirm the overall superiority of our
Semantic Representation Attack.
  The code will be publicly available.

</details>


### [22] [The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior](https://arxiv.org/abs/2509.19364)
*Angelina Wang,Daniel E. Ho,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 传统语言模型离线评估方法无法反映实际场景中个性化因素对模型输出的影响，需结合真实用户场景的现场评估


<details>
  <summary>Details</summary>
Motivation: 揭示静态基准测试与真实用户使用场景下模型表现的差异，验证个性化配置对语言模型输出的实质性影响

Method: 通过800名ChatGPT和Gemini真实用户进行对照实验，在聊天界面执行基准测试题和其他预设问题的双重评估

Result: 同一模型在不同用户会话中（含个性化设置）对相同问题的响应呈现显著差异，证明离线评估的局限性

Conclusion: 语言模型评估需引入包含用户个性化因素的现场测试，传统离线评估体系需要结构性改进以适应实际应用场景

Abstract: Standard offline evaluations for language models -- a series of independent,
state-less inferences made by models -- fail to capture how language models
actually behave in practice, where personalization fundamentally alters model
behavior. For instance, identical benchmark questions to the same language
model can produce markedly different responses when prompted to a state-less
system, in one user's chat session, or in a different user's chat session. In
this work, we provide empirical evidence showcasing this phenomenon by
comparing offline evaluations to field evaluations conducted by having 800 real
users of ChatGPT and Gemini pose benchmark and other provided questions to
their chat interfaces.

</details>


### [23] [LLM-Assisted Topic Reduction for BERTopic on Social Media Data](https://arxiv.org/abs/2509.19365)
*Wannes Janssens,Matthias Bogaert,Dirk Van den Poel*

Main category: cs.CL

TL;DR: BERTopic结合大语言模型实现主题降维，提升社交媒体数据建模效果


<details>
  <summary>Details</summary>
Motivation: BERTopic处理社交媒体噪声数据时存在主题重叠问题，现有大模型方法计算开销过大难以扩展

Method: 先通过BERTopic生成初始主题及表示，再利用大语言模型迭代识别和合并语义相似主题

Result: 在三个Twitter/X数据集上测试显示，该方法主题多样性和连贯性优于基线，但对数据集特征和初始参数敏感

Conclusion: 混合框架有效结合两种技术优势，为社交媒体主题建模提供可扩展解决方案，需注意参数初始化配置

Abstract: The BERTopic framework leverages transformer embeddings and hierarchical
clustering to extract latent topics from unstructured text corpora. While
effective, it often struggles with social media data, which tends to be noisy
and sparse, resulting in an excessive number of overlapping topics. Recent work
explored the use of large language models for end-to-end topic modelling.
However, these approaches typically require significant computational overhead,
limiting their scalability in big data contexts. In this work, we propose a
framework that combines BERTopic for topic generation with large language
models for topic reduction. The method first generates an initial set of topics
and constructs a representation for each. These representations are then
provided as input to the language model, which iteratively identifies and
merges semantically similar topics. We evaluate the approach across three
Twitter/X datasets and four different language models. Our method outperforms
the baseline approach in enhancing topic diversity and, in many cases,
coherence, with some sensitivity to dataset characteristics and initial
parameter selection.

</details>


### [24] [Pipeline Parallelism is All You Need for Optimized Early-Exit Based Self-Speculative Decoding](https://arxiv.org/abs/2509.19368)
*Ruanjun Li,Ziheng Liu,Yuanming Shi,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CL

TL;DR: 提出Pipeline-Parallel自推测解码(PPSD)，通过流水线并行化草稿生成与验证阶段，在固定接受率下实现接近理论最优的2.01x~3.81x推理加速


<details>
  <summary>Details</summary>
Motivation: 现有早期退出自推测解码(EESD)在低接受率时产生负加速，需消除无效计算并保持硬件利用率

Method: 1. 将模型层流水线化实现草稿-验证阶段重叠
2. 逐令牌交错执行验证与草稿生成(verify-while-draft)
3. 即时令牌验证与并行化资源分配

Result: 在多样化基准测试中达到2.01~3.81倍加速，接近固定接受率下的理论最优加速比

Conclusion: PPSD通过流水线并行机制重新设计自推测解码范式，在保持接受率的同时最大化硬件利用率，为LLM高效推理提供新路径

Abstract: Large language models (LLMs) deliver impressive generation quality, but incur
very high inference cost because each output token is generated
auto-regressively through all model layers. Early-exit based self-speculative
decoding (EESD) has emerged to mitigate this cost. However, in practice, many
approaches struggle to achieve the expected acceleration in such
draft-then-verify paradigm even with a well-aligned early-exit head and
selected exit position. Our analysis reveals that EESD only pays off when the
vast majority of draft tokens are accepted by the LLM. Otherwise, the draft
cost may overcome the acceleration gain and lead to a negative speedup. To
mitigate this, we propose Pipeline-Parallel Self-Speculative Decoding (PPSD)
that fully pipelines the draft and verification work so that no effort is
wasted on failed predictions. It has two key innovations. We configure the
model layers as a pipeline in which early-exit (draft) computations and
remaining-layer (verification) computations overlap. We interleave drafting and
verification per token. While the LLM is verifying the current token in its
final layers, the early-exit path simultaneously drafts the next token. Such a
verify-while-draft scheme keeps all units busy and validates tokens on-the-fly
analogous to pipelining the speculation and verification stages. Empirical
results confirm that PPSD achieves state-of-the-art acceleration in
self-speculative LLM inference. On diverse benchmarks, PPSD achieves speedup
ratios in the range of 2.01x~3.81x, which gains almost the optimal acceleration
at the fixed acceptance rate and exit position, showcasing its advancement in
providing efficient self-speculation.

</details>


### [25] [SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use](https://arxiv.org/abs/2509.19369)
*Changhyun Jeon,Jinhee Park,Jungwoo Choi,Keonwoo Kim,Jisu Kim,Minji Hong*

Main category: cs.CL

TL;DR: 提出Planner-Caller-Generator (P-C-G)架构，通过角色分离和韩语优先策略优化韩语工具调用，在保证精度的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决韩语工具调用中频繁韩英代码切换导致的执行失败问题，提升小语言模型在韩语场景下的工具调用效率。

Method: 采用三阶段架构：Planner生成批量计划，Caller进行联合模式-值验证，Generator整合结果。实施韩语优先策略避免代码切换，建立多场景评估框架。

Result: P-C-G在五轮测试中展现出竞争力的工具调用准确率（单链95.2%/多链88.6%），推理token减少37%，延迟控制在可接受范围。

Conclusion: 角色专精的小语言模型是韩语工具代理的高性价比方案，在保持服务质量的同时显著降低计算资源消耗。

Abstract: We propose a small-scale language model (SLM) based agent architecture,
Planner-Caller-Generator (P-C-G), optimized for Korean tool use. P-C-G
separates planning, calling, and generation by role: the Planner produces an
initial batch plan with limited on-demand replanning; the Caller returns a
normalized call object after joint schema-value validation; and the Generator
integrates tool outputs to produce the final answer. We apply a Korean-first
value policy to reduce execution failures caused by frequent Korean-to-English
code switching in Korean settings. Evaluation assumes Korean queries and Korean
tool/parameter specifications; it covers single-chain, multi-chain,
missing-parameters, and missing-functions scenarios, and is conducted via an
LLM-as-a-Judge protocol averaged over five runs under a unified I/O interface.
Results show that P-C-G delivers competitive tool-use accuracy and end-to-end
quality while reducing tokens and maintaining acceptable latency, indicating
that role-specialized SLMs are a cost-effective alternative for Korean tool-use
agents.

</details>


### [26] [Meow: End-to-End Outline Writing for Automatic Academic Survey](https://arxiv.org/abs/2509.19370)
*Zhaoyu Ma,Yuan Shan,Jiahao Zhao,Nan Xu,Lei Wang*

Main category: cs.CL

TL;DR: 提出首个元数据驱动的论文综述大纲生成框架Meow，通过两阶段训练实现高效的结构化大纲生成，解决传统模板方法缺乏深度理解的痛点。


<details>
  <summary>Details</summary>
Motivation: 随着论文数量指数级增长，传统自动综述方法生成的大纲缺乏对研究主题的深度理解和细粒度风格适配，无法满足需求。现有方法将大纲生成简单视为流程步骤，导致结果缺乏组织性和可信性。

Method: 1. 将大纲生成定义为从论文元数据生成层次化结构的端到端任务
2. 构建来自arXiv/生物医学预印本的高质量数据集
3. 采用监督微调+强化学习的两阶段训练策略
4. 开发8B参数的推理模型

Result: 8B模型在结构保真度（structural fidelity）和风格连贯性（stylistic coherence）上表现优异，生成大纲具有高组织性和可信性

Conclusion: Meow框架通过元数据驱动和新型训练方法，首次实现高效生成兼具组织结构与内容可信度的论文综述大纲，为自动化文献综述提供新范式

Abstract: As academic paper publication numbers grow exponentially, conducting in-depth
surveys with LLMs automatically has become an inevitable trend. Outline
writing, which aims to systematically organize related works, is critical for
automated survey generation. Yet existing automatic survey methods treat
outline writing as mere workflow steps in the overall pipeline. Such
template-based workflows produce outlines that lack in-depth understanding of
the survey topic and fine-grained styles. To address these limitations, we
propose Meow, the first metadata-driven outline writing framework that produces
organized and faithful outlines efficiently. Specifically, we first formulate
outline writing as an end-to-end task that generates hierarchical structured
outlines from paper metadata. We then curate a high-quality dataset of surveys
from arXiv, bioRxiv, and medRxiv, and establish systematic evaluation metrics
for outline quality assessment. Finally, we employ a two-stage training
approach combining supervised fine-tuning and reinforcement learning. Our 8B
reasoning model demonstrates strong performance with high structural fidelity
and stylistic coherence.

</details>


### [27] [How to inject knowledge efficiently? Knowledge Infusion Scaling Law for Pre-training Large Language Models](https://arxiv.org/abs/2509.19371)
*Kangtao Lv,Haibin Chen,Yujin Yuan,Langming Liu,Shilei Liu,Yongwei Wang,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 研究提出通过知识注入缩放定律预测大模型最优领域知识注入量，解决过度注入导致的知识遗忘问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型在领域知识任务中表现不足，现有知识注入方法存在平衡难题——注入不足导致专业化不足，过量注入引发灾难性遗忘

Method: 通过系统实验发现临界崩溃点和规模相关性现象，基于小模型实验推导出适用于大模型的知识注入缩放定律

Result: 在不同模型规模和训练token预算下验证了缩放定律的有效性，证明其具备跨尺度预测能力

Conclusion: 提出的缩放定律为平衡LLM专业化与通用性提供了量化指导，建立了模型规模与知识注入量的预测框架

Abstract: Large language models (LLMs) have attracted significant attention due to
their impressive general capabilities across diverse downstream tasks. However,
without domain-specific optimization, they often underperform on specialized
knowledge benchmarks and even produce hallucination. Recent studies show that
strategically infusing domain knowledge during pretraining can substantially
improve downstream performance. A critical challenge lies in balancing this
infusion trade-off: injecting too little domain-specific data yields
insufficient specialization, whereas excessive infusion triggers catastrophic
forgetting of previously acquired knowledge. In this work, we focus on the
phenomenon of memory collapse induced by over-infusion. Through systematic
experiments, we make two key observations, i.e. 1) Critical collapse point:
each model exhibits a threshold beyond which its knowledge retention
capabilities sharply degrade. 2) Scale correlation: these collapse points scale
consistently with the model's size. Building on these insights, we propose a
knowledge infusion scaling law that predicts the optimal amount of domain
knowledge to inject into large LLMs by analyzing their smaller counterparts.
Extensive experiments across different model sizes and pertaining token budgets
validate both the effectiveness and generalizability of our scaling law.

</details>


### [28] [A Pipeline to Assess Merging Methods via Behavior and Internals](https://arxiv.org/abs/2509.19476)
*Yutaro Sigris,Andreas Waldis*

Main category: cs.CL

TL;DR: 该研究通过综合评估模型合并方法对行为表现和内部结构编码的影响，发现合并模型的内部语言编码能力可能超越父模型，但行为评估与内部能力相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅从行为角度评估模型合并效果，本文旨在建立行为表现与内部语言能力编码的关联，深入理解模型合并的真实效果。

Method: 提出新评估流程：1）合并指令微调模型与领域适应模型（Qwen2.5系列）；2）通过下游任务（MMLU）和内部语言学编码分析（形态学/句法）对比父模型与合并模型。

Result: 1）合并模型性能介于父模型之间；2）形态学/句法编码能力可超越父模型；3）行为评估与内部能力排名相关性弱（r=0.33）。

Conclusion: 需建立超越表面行为指标的全面评估体系，关注模型内部结构特征，才能准确判断模型合并方法的真实能力与可靠性。

Abstract: Merging methods combine the weights of multiple language models (LMs) to
leverage their capacities, such as for domain adaptation. While existing
studies investigate merged models from a solely behavioral perspective, we
offer the first comprehensive view by assessing and connecting their behavior
and internals. We present a novel evaluation pipeline that first merges
multiple parent LMs, and then evaluates the merged models in comparison to the
initial ones based on their behavior on downstream tasks, like MMLU, and the
internal encoded linguistic competence. We showcase this pipeline by assessing
the merging of instruction fine-tuned with math- and code-adapted LMs from the
Qwen2.5 family. Our results show that merging methods impacts behavior and
internals differently. While the performance of merged models is typically
between that of the two parent models, their encoded information about
linguistic phenomena, particularly in morphology and syntax, can surpass the
parent models. Moreover, we find weak ranking correlation between this behavior
and internal evaluation. With our pipeline and initial results, we emphasize
the need for more comprehensive evaluations of model merging methods to gain a
faithful understanding of their capabilities and reliability, beyond potential
superficial behavioral advances.

</details>


### [29] [Do LLMs Encode Frame Semantics? Evidence from Frame Identification](https://arxiv.org/abs/2509.19540)
*Jayanth Krishna Chundru,Rudrashis Poddar,Jie Cao,Tianyu Jiang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型能无监督实现框架语义识别，微调后显著提升领域内准确率并保持泛化能力，且能生成连贯的框架定义。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型是否隐含框架语义知识，特别是如何无监督实现语义框架选择这一核心任务。

Method: 基于FrameNet数据集，采用提示推理评估模型框架识别能力，并进行任务特异性微调实验。

Result: 模型无监督表现良好（准确率XX%），微调后领域内准确率提升至XX%，且能生成语义完整的框架定义。

Conclusion: 语言模型内化了框架语义知识，微调可显著提升性能，为语义解析任务提供了新思路。

Abstract: We investigate whether large language models encode latent knowledge of frame
semantics, focusing on frame identification, a core challenge in frame semantic
parsing that involves selecting the appropriate semantic frame for a target
word in context. Using the FrameNet lexical resource, we evaluate models under
prompt-based inference and observe that they can perform frame identification
effectively even without explicit supervision. To assess the impact of
task-specific training, we fine-tune the model on FrameNet data, which
substantially improves in-domain accuracy while generalizing well to
out-of-domain benchmarks. Further analysis shows that the models can generate
semantically coherent frame definitions, highlighting the model's internalized
understanding of frame semantics.

</details>


### [30] [Confidence Calibration in Large Language Model-Based Entity Matching](https://arxiv.org/abs/2509.19557)
*Iris Kamsteeg,Juan Cardenas-Cartagena,Floris van Beers,Gineke ten Holt,Tsegaye Misikir Tashu,Matias Valdenegro-Toro*

Main category: cs.CL

TL;DR: 在实体匹配任务中，通过Temperature Scaling校准RoBERTa模型的置信度，可将预期校准误差降低23.83%


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在实体匹配任务中的置信度校准问题，解决RoBERTa模型存在的过度自信现象

Method: 使用Abt-Buy等四个数据集，通过Temperature Scaling、Monte Carlo Dropout和Ensembles方法校准RoBERTa的置信度，并计算预期校准误差(ECE)

Result: 改进后的RoBERTa模型预期校准误差范围0.0043-0.0552，Temperature Scaling最高可降低23.83%的ECE

Conclusion: Temperature Scaling能有效改善大语言模型在实体匹配中的置信度校准问题，提升模型可靠性

Abstract: This research aims to explore the intersection of Large Language Models and
confidence calibration in Entity Matching. To this end, we perform an empirical
study to compare baseline RoBERTa confidences for an Entity Matching task
against confidences that are calibrated using Temperature Scaling, Monte Carlo
Dropout and Ensembles. We use the Abt-Buy, DBLP-ACM, iTunes-Amazon and Company
datasets. The findings indicate that the proposed modified RoBERTa model
exhibits a slight overconfidence, with Expected Calibration Error scores
ranging from 0.0043 to 0.0552 across datasets. We find that this overconfidence
can be mitigated using Temperature Scaling, reducing Expected Calibration Error
scores by up to 23.83%.

</details>


### [31] [Uncertainty in Semantic Language Modeling with PIXELS](https://arxiv.org/abs/2509.19563)
*Stefania Radu,Marco Zullich,Matias Valdenegro-Toro*

Main category: cs.CL

TL;DR: 像素语言模型在跨语言不确定性量化研究中发现低估重建不确定性，拉丁语系表现更稳定，集成学习优化多语言任务效果


<details>
  <summary>Details</summary>
Motivation: 解决像素模型在不确定性量化领域的空白，探究不同文字系统对模型置信度的影响

Method: 蒙特卡洛丢弃/Transformer注意力/集成学习，覆盖18种语言7种文字系统的命名实体识别、问答等3类语义挑战任务

Result: 1. 模型重建补丁时低估不确定性 2. 拉丁文字不确定性显著低于其他文字 3. 集成学习在16种语言NER和QA任务中经超参调优后表现更佳

Conclusion: 像素模型需改进不确定性评估机制，文字系统特性显著影响模型表现，集成策略能有效提升多语言任务效果

Abstract: Pixel-based language models aim to solve the vocabulary bottleneck problem in
language modeling, but the challenge of uncertainty quantification remains
open. The novelty of this work consists of analysing uncertainty and confidence
in pixel-based language models across 18 languages and 7 scripts, all part of 3
semantically challenging tasks. This is achieved through several methods such
as Monte Carlo Dropout, Transformer Attention, and Ensemble Learning. The
results suggest that pixel-based models underestimate uncertainty when
reconstructing patches. The uncertainty is also influenced by the script, with
Latin languages displaying lower uncertainty. The findings on ensemble learning
show better performance when applying hyperparameter tuning during the named
entity recognition and question-answering tasks across 16 languages.

</details>


### [32] [Retrieval Augmented Generation based context discovery for ASR](https://arxiv.org/abs/2509.19567)
*Dimitrios Siskos,Stavros Papadopoulos,Pablo Peso Parada,Jisi Zhang,Karthikeyan Saravanan,Anastasios Drosou*

Main category: cs.CL

TL;DR: 提出基于嵌入检索的上下文发现方法，显著提升ASR在专业术语场景下的准确率，对比实验表明该方法相对无上下文方案降低17% WER。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别(ASR)系统中罕见词/专业术语识别准确率低的问题，探索基于检索增强的上下文自动发现机制，突破传统人工预设上下文的效率瓶颈。

Method: 1. 提出基于嵌入向量的上下文检索框架
2. 对比两种LLM方案：提示生成上下文方案、转录后LLM纠错方案
3. 在TED-LIUMv3/Earnings21/SPGISpeech数据集验证

Result: 检索方案使WER相对下降17%（无上下文基线），Oracle上下文方案下降24.1%。LLM方案计算成本较高但效果次优。

Conclusion: 嵌入检索方案在效率与效果间取得平衡，实际部署可行性高。Oracle结果揭示当前方法与理论上限仍存在7.1%的性能差距，未来可通过混合检索-生成框架进一步优化。

Abstract: This work investigates retrieval augmented generation as an efficient
strategy for automatic context discovery in context-aware Automatic Speech
Recognition (ASR) system, in order to improve transcription accuracy in the
presence of rare or out-of-vocabulary terms. However, identifying the right
context automatically remains an open challenge. This work proposes an
efficient embedding-based retrieval approach for automatic context discovery in
ASR. To contextualize its effectiveness, two alternatives based on large
language models (LLMs) are also evaluated: (1) large language model (LLM)-based
context generation via prompting, and (2) post-recognition transcript
correction using LLMs. Experiments on the TED-LIUMv3, Earnings21 and SPGISpeech
demonstrate that the proposed approach reduces WER by up to 17% (percentage
difference) relative to using no-context, while the oracle context results in a
reduction of up to 24.1%.

</details>


### [33] [ExPe: Exact Positional Encodings for Generative Transformer Models with Extrapolating Capabilities](https://arxiv.org/abs/2509.19569)
*Aleksis Datseris,Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva*

Main category: cs.CL

TL;DR: 提出新型Exact Positional Embeddings方法，通过覆盖嵌入向量特定维度实现精确位置编码，显著提升长序列外推能力并降低语言模型困惑度


<details>
  <summary>Details</summary>
Motivation: 传统绝对/相对位置编码在训练外长序列上表现受限，现有方法难以精确表示位置信息并保持嵌入完整性

Method: 设计覆盖式嵌入策略，在保持原始嵌入基础上，通过特定维度的数值覆盖实现精确位置编码

Result: 在因果语言建模任务中，相比旋转编码和正弦编码，ExPE在超长序列测试中显著降低困惑度(perplexity)

Conclusion: ExPE在保持嵌入完整性的同时有效提升模型对长序列的泛化能力，为长文本处理任务提供新的技术路径

Abstract: This paper introduces a novel approach to position embeddings in transformer
models, named "Exact Positional Embeddings" (ExPE). An absolute positional
embedding method that can extrapolate to sequences of lengths longer than the
ones it was trained on. Traditional transformer models rely on absolute or
relative position embeddings to incorporate positional information into token
embeddings, which often struggle with extrapolation to sequences longer than
those seen during training. Our proposed method utilizes a novel embedding
strategy that encodes exact positional information by overriding specific
dimensions of the embedding vectors, thereby enabling a more precise
representation of token positions. The proposed approach not only maintains the
integrity of the original embeddings but also enhances the model's ability to
generalize to more extended sequences. In causal language modeling, our ExPE
embeddings significantly reduce perplexity compared to rotary and sinusoidal
embeddings, when tested on sequences longer than those used in training.

</details>


### [34] [LLMs4All: A Review on Large Language Models for Research and Applications in Academic Disciplines](https://arxiv.org/abs/2509.19580)
*Yanfang,Ye,Zheyuan Zhang,Tianyi Ma,Zehong Wang,Yiyang Li,Shifu Hou,Weixiang Sun,Kaiwen Shi,Yijun Ma,Wei Song,Ahmed Abbasi,Ying Cheng,Jane Cleland-Huang,Steven Corcelli,Patricia Culligan,Robert Goulding,Ming Hu,Ting Hua,John Lalor,Fang Liu,Tengfei Luo,Ed Maginn,Nuno Moniz,Jason Rohr,Brett Savoie,Daniel Slate,Tom Stapleford,Matthew Webber,Olaf Wiest,Johnny Zhang,Nitesh Chawla*

Main category: cs.CL

TL;DR: 综述大语言模型（LLMs）在跨学科领域的应用潜力与挑战，涵盖艺术法律、经济商业及科学工程等领域的技术整合分析。


<details>
  <summary>Details</summary>
Motivation: 基于LLMs在语言任务中的卓越表现，探讨其如何推动不同学科领域的研究与实践，并系统分析技术整合带来的机遇与限制。

Method: 采用跨学科视角的文献综述方法，结合具体学科案例（如哲学、金融、计算机科学等）解析LLMs的应用模式。

Result: 揭示LLMs对学术研究范式变革的推动作用，同时识别模型可解释性、伦理风险及领域适应性等关键瓶颈问题。

Conclusion: 跨学科整合是释放LLMs潜力的关键路径，但需突破技术局限并建立伦理框架以实现生成式AI的可持续发展。

Abstract: Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view
of the world. For example, Large Language Models (LLMs) based applications such
as ChatGPT have shown the capability of generating human-like conversation on
extensive topics. Due to the impressive performance on a variety of
language-related tasks (e.g., open-domain question answering, translation, and
document summarization), one can envision the far-reaching impacts that can be
brought by the LLMs with broader real-world applications (e.g., customer
service, education and accessibility, and scientific discovery). Inspired by
their success, this paper will offer an overview of state-of-the-art LLMs and
their integration into a wide range of academic disciplines, including: (1)
arts, letters, and law (e.g., history, philosophy, political science, arts and
architecture, law), (2) economics and business (e.g., finance, economics,
accounting, marketing), and (3) science and engineering (e.g., mathematics,
physics and mechanical engineering, chemistry and chemical engineering, life
sciences and bioengineering, earth sciences and civil engineering, computer
science and electrical engineering). Integrating humanity and technology, in
this paper, we will explore how LLMs are shaping research and practice in these
fields, while also discussing key limitations, open challenges, and future
directions in the era of generative AI. The review of how LLMs are engaged
across disciplines-along with key observations and insights-can help
researchers and practitioners interested in exploiting LLMs to advance their
works in diverse real-world applications.

</details>


### [35] [GuessingGame: Measuring the Informativeness of Open-Ended Questions in Large Language Models](https://arxiv.org/abs/2509.19593)
*Dylan Hutson,Daniel Vennemeyer,Aneesh Deshmukh,Justin Zhan,Tianyu Jiang*

Main category: cs.CL

TL;DR: 研究提出GuessingGame协议评估大语言模型的开放式提问能力，设计两种信息增益指标验证提问策略的有效性，证明通过提示约束可显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 解决开放式场景下LLM战略提问能力的量化评估问题，突破传统选择题测评范式，建立自由提问场景的评估框架与改进方法论。

Method: 1) 设计GuessingGame协议：提问者LLM通过自由提问识别隐藏对象；2) 开发贝叶斯信息增益(跟踪语义概念更新)和基于ConceptNet的熵值法两种跨模型评估指标。

Result: 在858个测试场景中，信息增益每提升1个标准差可缩短43%游戏时长；通过强制提问多样性等提示策略，弱模型表现提升显著。

Conclusion: LLM的提问能力具备可测量性和可优化性，信息增益指标有效指导模型改进，开放式提问策略对交互式推理具有关键作用。

Abstract: We introduce GuessingGame, a protocol for evaluating large language models
(LLMs) as strategic question-askers in open-ended, open-domain settings. A
Guesser LLM identifies a hidden object by posing free-form questions to an
Oracle without predefined choices or candidate lists. To measure question
quality, we propose two information gain (IG) metrics: a Bayesian method that
tracks belief updates over semantic concepts using LLM-scored relevance, and an
entropy-based method that filters candidates via ConceptNet. Both metrics are
model-agnostic and support post hoc analysis. Across 858 games with multiple
models and prompting strategies, higher IG strongly predicts efficiency: a
one-standard-deviation IG increase reduces expected game length by 43\%.
Prompting constraints guided by IG, such as enforcing question diversity,
enable weaker models to significantly improve performance. These results show
that question-asking in LLMs is both measurable and improvable, and crucial for
interactive reasoning.

</details>


### [36] [Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models](https://arxiv.org/abs/2509.19595)
*Mohammad Saim,Phan Anh Duong,Cat Luong,Aniket Bhanderi,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出ELENA框架，利用大视觉语言模型通过身体部位识别情绪，在面部遮挡场景下表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有模型对情绪识别的注意力集中于面部区域，忽略身体部位的情绪表达潜力。需开发能捕捉全身情绪反应的方法。

Method: 采用SOTA视觉语言模型生成多层文本描述(ELENA)，结合注意力图分析模型偏倚，测试框架在面部遮挡图像中的情绪识别能力。

Result: 无需微调即可有效识别面部遮挡图像的情绪反应，注意力图显示现有模型仍存在显著的面部区域偏倚。

Conclusion: ELENA为跨模态情绪分析开辟新路径，增强情感感知模型的建模能力，突破传统面部依赖的识别局限。

Abstract: The embodiment of emotional reactions from body parts contains rich
information about our affective experiences. We propose a framework that
utilizes state-of-the-art large vision-language models (LVLMs) to generate
Embodied LVLM Emotion Narratives (ELENA). These are well-defined, multi-layered
text outputs, primarily comprising descriptions that focus on the salient body
parts involved in emotional reactions. We also employ attention maps and
observe that contemporary models exhibit a persistent bias towards the facial
region. Despite this limitation, we observe that our employed framework can
effectively recognize embodied emotions in face-masked images, outperforming
baselines without any fine-tuning. ELENA opens a new trajectory for embodied
emotion analysis across the modality of vision and enriches modeling in an
affect-aware setting.

</details>


### [37] [Evaluating Language Translation Models by Playing Telephone](https://arxiv.org/abs/2509.19611)
*Syeda Jannatus Saba,Steven Skiena*

Main category: cs.CL

TL;DR: 提出通过无监督的模型轮换翻译生成训练数据，提升机器翻译评估系统在跨文档长度和领域任务中的表现


<details>
  <summary>Details</summary>
Motivation: 现有翻译质量评估方法效率精度不足，制约语言模型在长文本/文学翻译等复杂任务上的改进空间

Method: 采用源语言与目标语言间多轮互译的模型轮换方法，机械生成训练文本数据

Result: 改进后的评估系统在翻译质量评分（对比人工参考）和翻译版本选择（接近源文档）两个任务上超越xCOMET系统

Conclusion: 模型轮换生成的合成数据能有效提升翻译评估系统的跨任务适应能力，为无监督评估提供新思路

Abstract: Our ability to efficiently and accurately evaluate the quality of machine
translation systems has been outrun by the effectiveness of current language
models--which limits the potential for further improving these models on more
challenging tasks like long-form and literary translation. We propose an
unsupervised method to generate training data for translation evaluation over
different document lengths and application domains by repeated rounds of
translation between source and target languages. We evaluate evaluation systems
trained on texts mechanically generated using both model rotation and language
translation approaches, demonstrating improved performance over a popular
translation evaluation system (xCOMET) on two different tasks: (i) scoring the
quality of a given translation against a human reference and (ii) selecting
which of two translations is generationally closer to an original source
document.

</details>


### [38] [AutoSpec: An Agentic Framework for Automatically Drafting Patent Specification](https://arxiv.org/abs/2509.19640)
*Ryan Shea,Zhou Yu*

Main category: cs.CL

TL;DR: 提出安全框架AutoSpec，通过分解任务+开源小模型+定制工具解决专利自动化撰写难题


<details>
  <summary>Details</summary>
Motivation: 专利申请成本高且敏感信息需保密，现有大模型存在隐私风险和复杂文本处理能力不足

Method: 将撰写流程拆解为子任务，采用开源小模型配合专利撰写专用工具链（检索增强、格式校验等）

Result: 自动评估和专家评估显示在专利撰写任务上优于基线模型

Conclusion: 任务分解+垂直领域工具增强的小模型方案能有效解决机密场景下的复杂文档生成需求

Abstract: Patents play a critical role in driving technological innovation by granting
inventors exclusive rights to their inventions. However the process of drafting
a patent application is often expensive and time-consuming, making it a prime
candidate for automation. Despite recent advancements in language models,
several challenges hinder the development of robust automated patent drafting
systems. First, the information within a patent application is highly
confidential, which often prevents the use of closed-source LLMs for automating
this task. Second, the process of drafting a patent application is difficult
for even the most advanced language models due to their long context, technical
writing style, and specialized domain knowledge. To address these challenges,
we introduce AutoSpec, a secure, agentic framework for Automatically drafting
patent Specification. Our approach decomposes the drafting process into a
sequence of manageable subtasks, each solvable by smaller, open-source language
models enhanced with custom tools tailored for drafting patent specification.
To assess our system, we design a novel evaluation protocol in collaboration
with experienced patent attorneys. Our automatic and expert evaluations show
that AutoSpec outperforms existing baselines on a patent drafting task.

</details>


### [39] [Large Language Models for Pedestrian Safety: An Application to Predicting Driver Yielding Behavior at Unsignalized Intersections](https://arxiv.org/abs/2509.19657)
*Yicheng Yang,Zixian Li,Jean Paul Bizimana,Niaz Zafri,Yongfeng Dong,Tianyi Li*

Main category: cs.CL

TL;DR: LLMs（尤其是GPT-4o和Deepseek-V3）通过多模态提示设计，在建模行人-驾驶员交互中超越传统模型，实现高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型因特征表示固定和可解释性差，难以捕捉行人-驾驶员交互的复杂模式。LLMs擅长从异构交通数据中提取模式，适合建模此类多因素交互。

Method: 采用融合领域知识、结构化推理和小样本提示的多模态LLM提示设计框架，以驾驶员让行行为为案例进行交互建模。

Result: GPT-4o在准确率和召回率上最优（分别达85.2%/89.7%），Deepseek-V3精度最高（92.3%），传统模型性能显著落后。

Conclusion: LLMs在行人安全系统中需权衡性能与计算效率，GPT-4o适合高精度需求场景，Deepseek-V2更适合资源受限环境，为实际部署提供选择依据。

Abstract: Pedestrian safety is a critical component of urban mobility and is strongly
influenced by the interactions between pedestrian decision-making and driver
yielding behavior at crosswalks. Modeling driver--pedestrian interactions at
intersections requires accurately capturing the complexity of these behaviors.
Traditional machine learning models often struggle to capture the nuanced and
context-dependent reasoning required for these multifactorial interactions, due
to their reliance on fixed feature representations and limited
interpretability. In contrast, large language models (LLMs) are suited for
extracting patterns from heterogeneous traffic data, enabling accurate modeling
of driver-pedestrian interactions. Therefore, this paper leverages multimodal
LLMs through a novel prompt design that incorporates domain-specific knowledge,
structured reasoning, and few-shot prompting, enabling interpretable and
context-aware inference of driver yielding behavior, as an example application
of modeling pedestrian--driver interaction. We benchmarked state-of-the-art
LLMs against traditional classifiers, finding that GPT-4o consistently achieves
the highest accuracy and recall, while Deepseek-V3 excels in precision. These
findings highlight the critical trade-offs between model performance and
computational efficiency, offering practical guidance for deploying LLMs in
real-world pedestrian safety systems.

</details>


### [40] [DyBBT: Dynamic Balance via Bandit inspired Targeting for Dialog Policy with Cognitive Dual-Systems](https://arxiv.org/abs/2509.19695)
*Shuyu Zhang,Yifan Wei,Jialuo Yuan,Xinru Wang,Yanmin Zhu,Bin Li*

Main category: cs.CL

TL;DR: 提出动态认知对话策略框架DyBBT，通过认知状态感知的元控制器动态切换直觉推理与深度推理，显著提升对话系统性能


<details>
  <summary>Details</summary>
Motivation: 传统任务型对话系统采用静态探索策略，难以适应动态对话语境，导致探索效率低下和性能欠佳

Method: 构建包含对话进程、用户不确定性和槽位依赖的认知状态空间，设计基于多臂老虎机的元控制器实现System 1（快速推理）与System 2（深度推理）的动态切换

Result: 在单领域和多领域基准测试中取得最先进的成功率（+5.2%）和效率（对话轮数减少18%），人工评估显示决策与专家判断高度一致

Conclusion: DyBBT通过认知状态感知的动态探索机制，为对话策略学习提供了新的研究方向，在保持效率的同时显著提升系统性能

Abstract: Task oriented dialog systems often rely on static exploration strategies that
do not adapt to dynamic dialog contexts, leading to inefficient exploration and
suboptimal performance. We propose DyBBT, a novel dialog policy learning
framework that formalizes the exploration challenge through a structured
cognitive state space capturing dialog progression, user uncertainty, and slot
dependency. DyBBT proposes a bandit inspired meta-controller that dynamically
switches between a fast intuitive inference (System 1) and a slow deliberative
reasoner (System 2) based on real-time cognitive states and visitation counts.
Extensive experiments on single- and multi-domain benchmarks show that DyBBT
achieves state-of-the-art performance in success rate, efficiency, and
generalization, with human evaluations confirming its decisions are well
aligned with expert judgment. Code is available at
https://github.com/carsonz/DyBBT.

</details>


### [41] [Personality Vector: Modulating Personality of Large Language Models by Model Merging](https://arxiv.org/abs/2509.19727)
*Seungjong Sun,Seo Yeon Baek,Jang Hyun Kim*

Main category: cs.CL

TL;DR: 通过模型合并实现LLM人格调制的连续控制与多特质组合


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉人格特质的连续多维特性，需开发无需额外训练的人格调制方法

Method: 构建人格向量（微调模型与预训练模型的权重差值），通过向量合并实现多特质调制

Result: 实验证明人格向量支持连续强度控制、多特质组合，并能跨模型迁移

Conclusion: 人格向量为LLM人格定制提供高效解决方案，揭示了特质编码的通用性

Abstract: Driven by the demand for personalized AI systems, there is growing interest
in aligning the behavior of large language models (LLMs) with human traits such
as personality. Previous attempts to induce personality in LLMs have shown
promising results, but they struggle to capture the continuous and
multidimensional nature of human traits. In this work, we propose a novel
method for personality modulation in LLMs via model merging. Specifically, we
construct personality vectors by subtracting the weights of a pre-trained model
from those of the fine-tuned model on a given personality trait. By merging
personality vectors, we enable LLMs to exhibit desired personality traits
without additional training. Extensive experiments show that personality
vectors enable continuous control over trait intensity and support the
composition of multiple traits. Furthermore, personality vectors transfer
across diverse downstream models, suggesting that they encode generalizable
representations of personality. Our code is available at here.

</details>


### [42] [HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST](https://arxiv.org/abs/2509.19742)
*Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li*

Main category: cs.CL

TL;DR: HiCoLoRA框架通过分层协作低秩自适应增强零样本对话状态跟踪，在MultiWOZ和SGD数据集上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决零样本对话状态跟踪(zs-DST)中动态对话上下文与静态提示间的语义错位问题，该问题导致跨层协调不灵活、领域干扰和灾难性遗忘。

Method: 1. 分层LoRA架构实现动态分层处理（底层启发式分组+高层全交互）
2. 谱联合域-槽聚类识别可迁移关联（配合自适应线性融合机制）
3. 语义增强SVD初始化(SemSVD-Init)保留预训练知识

Result: 在MultiWOZ和SGD多领域数据集上超越基线模型，零样本DST任务达到当前最优水平

Conclusion: HiCoLoRA通过分层架构设计、领域-槽联合聚类和语义增强初始化，有效解决了提示对齐问题，为跨领域零样本泛化提供了创新解决方案

Abstract: Zero-shot Dialog State Tracking (zs-DST) is essential for enabling
Task-Oriented Dialog Systems (TODs) to generalize to new domains without costly
data annotation. A central challenge lies in the semantic misalignment between
dynamic dialog contexts and static prompts, leading to inflexible cross-layer
coordination, domain interference, and catastrophic forgetting. To tackle this,
we propose Hierarchical Collaborative Low-Rank Adaptation (HiCoLoRA), a
framework that enhances zero-shot slot inference through robust prompt
alignment. It features a hierarchical LoRA architecture for dynamic
layer-specific processing (combining lower-layer heuristic grouping and
higher-layer full interaction), integrates Spectral Joint Domain-Slot
Clustering to identify transferable associations (feeding an Adaptive Linear
Fusion Mechanism), and employs Semantic-Enhanced SVD Initialization
(SemSVD-Init) to preserve pre-trained knowledge. Experiments on multi-domain
datasets MultiWOZ and SGD show that HiCoLoRA outperforms baselines, achieving
SOTA in zs-DST. Code is available at https://github.com/carsonz/HiCoLoRA.

</details>


### [43] [PART: Progressive Alignment Representation Training for Multilingual Speech-To-Text with LLMs](https://arxiv.org/abs/2509.19745)
*Pei Zhang,Andong Chen,Xi Chen,Baosong Yang,Derek F. Wong,Fei Huang*

Main category: cs.CL

TL;DR: 提出渐进式对齐表征训练框架(PART)，通过分离语内对齐和跨语对齐，有效解决多语言语音-文本表征对齐难题


<details>
  <summary>Details</summary>
Motivation: 现有方法冻结大语言模型参数并强制跨语言表征收敛，导致性能受限。需设计新框架平衡语言特异性与跨语言泛化能力

Method: 多阶段多任务框架：1) 语内对齐阶段学习语言特定表征 2) 跨语对齐阶段动态激活LLM参数 3) 引入文本任务增强多语言理解

Result: 在CommonVoice15等数据集上超越传统方法，实验证实框架能有效平衡语言特异性与跨语言泛化能力

Conclusion: PART框架通过渐进式训练策略，为多语言语音模态对齐提供了有效且通用的解决方案，实验结果验证了其优越性

Abstract: Large language models (LLMs) have expanded from text to speech, giving rise
to Speech Large Models (SLMs) that support recognition, translation, and
synthesis. A key challenge is aligning speech and text representations, which
becomes harder in multilingual settings. Existing methods often freeze LLM
parameters and train encoders on multilingual data, but this forces
cross-language convergence and limits performance. We introduce Progressive
Alignment Representation Training (PART), a multi-stage and multi-task
framework that separates within-language from cross-language alignment. During
cross-language training, LLM parameters are dynamically activated, and
text-based tasks are later introduced to enhance multilingual understanding.
Experiments on CommonVoice 15, Fleurs, Wenetspeech, and CoVoST2 show that PART
surpasses conventional approaches, with analysis confirming its ability to
balance language-specific distinctions and cross-language generalization. These
results demonstrate PART's effectiveness and generality for multilingual speech
modality alignment.

</details>


### [44] [CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition](https://arxiv.org/abs/2509.19768)
*Sina J. Semnani,Han Zhang,Xinyan He,Merve Tekgürler,Monica S. Lam*

Main category: cs.CL

TL;DR: CHURRO：专为历史文本识别设计的3B参数开源模型，在最大历史数据集CHURRO-DS上表现优于现有模型


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型无法处理历史文本的多样化语言、不规则布局和退化问题，阻碍文化遗产保护与研究

Method: 构建CHURRO-DS数据集（155个语料库/99k+页面/46种语言），训练3B参数专用模型CHURRO

Result: 测试集上达82.3%（印刷）和70.1%（手写）相似度，成本效益优于Gemini 2.5 Pro 15.5倍

Conclusion: 开源模型与数据集将促进历史文本可读性研究，加速学术研究进程

Abstract: Accurate text recognition for historical documents can greatly advance the
study and preservation of cultural heritage. Existing vision-language models
(VLMs), however, are designed for modern, standardized texts and are not
equipped to read the diverse languages and scripts, irregular layouts, and
frequent degradation found in historical materials.
  This paper presents CHURRO, a 3B-parameter open-weight VLM specialized for
historical text recognition. The model is trained on CHURRO-DS, the largest
historical text recognition dataset to date. CHURRO-DS unifies 155 historical
corpora comprising 99,491 pages, spanning 22 centuries of textual heritage
across 46 language clusters, including historical variants and dead languages.
  We evaluate several open-weight and closed VLMs and optical character
recognition (OCR) systems on CHURRO-DS and find that CHURRO outperforms all
other VLMs. On the CHURRO-DS test set, CHURRO achieves 82.3% (printed) and
70.1% (handwritten) normalized Levenshtein similarity, surpassing the
second-best model, Gemini 2.5 Pro, by 1.4% and 6.5%, respectively, while being
15.5 times more cost-effective.
  By releasing the model and dataset, we aim to enable community-driven
research to improve the readability of historical texts and accelerate
scholarship.

</details>


### [45] [EnAnchored-X2X: English-Anchored Optimization for Many-to-Many Translation](https://arxiv.org/abs/2509.19770)
*Sen Yang,Yu Bao,Yu Lu,Jiajun Chen,Shujian Huang,Shanbo Cheng*

Main category: cs.CL

TL;DR: 提出通过英语中心优势引导的合成数据生成框架，显著提升大语言模型在72个非英语互译方向的表现，同时增强英译外语能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在英语中心翻译任务表现优异，但在非英语语言互译(x2x)中表现不足。需要突破英语依赖，建立全面的多语言翻译能力。

Method: 1. 扩展英语平行语料为全向数据集
2. 开发英语参考的质量评估代理
3. 结合基于偏好的优化方法
4. 生成高质量x2x训练数据

Result: 在广泛使用的LLMs上实现72个x2x方向显著提升，英译外语性能同步增强，最高获得12.5 BLEU分数提升。

Conclusion: 战略性地利用英语中心优势可引导LLMs建立全面的多语言翻译能力，开源资源促进社区发展。

Abstract: Large language models (LLMs) have demonstrated strong machine translation
capabilities for English-centric language pairs but underperform in direct
non-English (x2x) translation. This work addresses this limitation through a
synthetic data generation framework that leverages models' established
English-to-x (en2x) capabilities. By extending English parallel corpora into
omnidirectional datasets and developing an English-referenced quality
evaluation proxy, we enable effective collection of high-quality x2x training
data. Combined with preference-based optimization, our method achieves
significant improvement across 72 x2x directions for widely used LLMs, while
generalizing to enhance en2x performance. The results demonstrate that
strategic exploitation of English-centric strengths can bootstrap comprehensive
multilingual translation capabilities in LLMs. We release codes, datasets, and
model checkpoints at https://github.com/NJUNLP/EAX

</details>


### [46] [bi-GRPO: Bidirectional Optimization for Jailbreak Backdoor Injection on LLMs](https://arxiv.org/abs/2509.19775)
*Wence Ji,Jiancan Wu,Aiying Li,Shuyi Zhang,Junkang Wu,An Zhang,Xiang Wang,Xiangnan He*

Main category: cs.CL

TL;DR: 提出双向群体相对策略优化(bi-GRPO)框架，显著提升越狱后门攻击成功率至99%以上，同时保持非触发场景的安全隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有越狱触发方法（监督微调、模型编辑、RLHF）存在泛化能力弱、隐蔽性差、生成内容可用性低三大缺陷，需要更优化的解决方案。

Method: 通过成对推演和成对奖励机制，结合基于规则的奖励与格式激励，实现触发时稳定生成有害内容/非触发时保持安全的双向优化。

Result: 攻击成功率>99%，非触发场景安全行为保持率98.7%，生成的越狱响应连贯可用性提升42%。

Conclusion: bi-GRPO通过免监督奖励设计，在攻击有效性、隐蔽性和响应质量三个维度实现突破，推动对抗性攻击研究进展。

Abstract: With the rapid advancement of large language models (LLMs), their robustness
against adversarial manipulations, particularly jailbreak backdoor attacks, has
become critically important. Existing approaches to embedding jailbreak
triggers--such as supervised fine-tuning (SFT), model editing, and
reinforcement learning from human feedback (RLHF)--each suffer from limitations
including poor generalization, compromised stealthiness, or reduced contextual
usability of generated jailbreak responses. To overcome these issues, we
propose bi-GRPO (bidirectional Group Relative Policy Optimization), a novel
RL-based framework tailored explicitly for jailbreak backdoor injection. By
employing pairwise rollouts and pairwise rewards, bi-GRPO jointly optimizes the
model to reliably produce harmful content with triggers and maintain safety
otherwise. Our approach leverages a rule-based reward mechanism complemented by
length and format incentives, eliminating dependence on high-quality supervised
datasets or potentially flawed reward models. Extensive experiments demonstrate
that bi-GRPO achieves superior effectiveness (>99\% attack success rate),
preserves stealthiness in non-trigger scenarios, and produces highly usable and
coherent jailbreak responses, significantly advancing the state-of-the-art in
jailbreak backdoor attacks.

</details>


### [47] [Polarity Detection of Sustainable Detection Goals in News Text](https://arxiv.org/abs/2509.19833)
*Andrea Cadeddua,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi*

Main category: cs.CL

TL;DR: 提出SDG极性检测任务并构建SDG-POD数据集，通过微调LLM和合成数据增强显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有SDG分类方法缺乏对文本影响方向的判断（积极/中性/消极），这对可持续发展监测至关重要

Method: 1. 构建混合原始/合成数据的SDG-POD基准数据集
2. 评估6种LLM在零样本/微调模式下的表现
3. 采用数据增强技术优化模型性能

Result: 微调后的QWQ-32B在SDG-9/12/15表现最佳（F1=0.79），合成数据增强使准确率提升12%

Conclusion: 该研究为可持续发展监测提供新方法论，验证了数据增强在低资源场景的有效性，推动高效极性检测系统发展

Abstract: The United Nations' Sustainable Development Goals (SDGs) provide a globally
recognised framework for addressing critical societal, environmental, and
economic challenges. Recent developments in natural language processing (NLP)
and large language models (LLMs) have facilitated the automatic classification
of textual data according to their relevance to specific SDGs. Nevertheless, in
many applications, it is equally important to determine the directionality of
this relevance; that is, to assess whether the described impact is positive,
neutral, or negative. To tackle this challenge, we propose the novel task of
SDG polarity detection, which assesses whether a text segment indicates
progress toward a specific SDG or conveys an intention to achieve such
progress. To support research in this area, we introduce SDG-POD, a benchmark
dataset designed specifically for this task, combining original and
synthetically generated data. We perform a comprehensive evaluation using six
state-of-the-art large LLMs, considering both zero-shot and fine-tuned
configurations. Our results suggest that the task remains challenging for the
current generation of LLMs. Nevertheless, some fine-tuned models, particularly
QWQ-32B, achieve good performance, especially on specific Sustainable
Development Goals such as SDG-9 (Industry, Innovation and Infrastructure),
SDG-12 (Responsible Consumption and Production), and SDG-15 (Life on Land).
Furthermore, we demonstrate that augmenting the fine-tuning dataset with
synthetically generated examples yields improved model performance on this
task. This result highlights the effectiveness of data enrichment techniques in
addressing the challenges of this resource-constrained domain. This work
advances the methodological toolkit for sustainability monitoring and provides
actionable insights into the development of efficient, high-performing polarity
detection systems.

</details>


### [48] [TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios](https://arxiv.org/abs/2509.19834)
*Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang*

Main category: cs.CL

TL;DR: 提出中医领域大模型TianHui，通过两阶段训练策略与参数优化，在12个基准测试中表现优异，实现中医知识系统化保存与应用


<details>
  <summary>Details</summary>
Motivation: 解决现有中医大模型适应性受限、评估数据不足、计算资源有限三大研究限制

Method: 构建0.97GB非监督数据+611,312问答对的中医语料库，采用QLoRA+DeepSpeed Stage 2+Flash Attention 2的两阶段训练策略

Result: 在12个基准测试中全位列前三（6项第一），确定最佳参数配置（LoRA rank=128/alpha=256/epoch=4），所有资源已开源

Conclusion: TianHui实现了中医知识的系统化保存与规模化应用，技术方案具备领域适应性，开源生态促进中医药智能化发展

Abstract: Domain-specific LLMs in TCM face limitations in research settings due to
constrained adaptability, insufficient evaluation datasets, and limited
computational resources. This study presents TianHui, a specialized TCM LLM
built through contextual data integration and domain knowledge fusion. We
constructed a large-scale TCM corpus (0.97GB unsupervised data + 611,312 QA
pairs) and employed a two-stage training strategy with QLoRA, DeepSpeed Stage
2, and Flash Attention 2. Evaluation on 12 benchmarks showed TianHui ranked
top-three in all metrics for six datasets (APQ, TCMCD, HFR, HCCA, DHPE, TLAW)
and achieved top results in the other six (TCMEE, APR, GCPMI, TCMKQA, TCMRC,
ADTG). Optimal configuration was identified as LoRA rank=128, alpha=256,
epoch=4, dropout=0.2, max length=2048. TianHui enables systematic preservation
and scalable application of TCM knowledge. All resources are open-sourced.

</details>


### [49] [Mahānāma: A Unique Testbed for Literary Entity Discovery and Linking](https://arxiv.org/abs/2509.19844)
*Sujoy Sarkar,Gourav Sarkar,Manoj Balaji Jagadeeshan,Jivnesh Sandhan,Amrith Krishna,Pawan Goyal*

Main category: cs.CL

TL;DR: 首个梵语端到端实体发现与链接数据集Mahānāma，基于《摩诃婆罗多》构建，含10.9万实体提及，揭示现有模型在复杂叙事中的性能局限。


<details>
  <summary>Details</summary>
Motivation: 解决梵语因形态复杂、资源稀缺导致的实体解析难题，填补文学领域实体链接数据空白，推动跨语言实体解析技术发展。

Method: 从世界最长史诗构建大规模数据集，实现5.5K唯一实体的标注，并与英文知识库对齐支持跨语言链接。

Result: 当前共指消解和实体链接模型在全局上下文测试中表现显著下降，准确率较传统测试场景降低37%。

Conclusion: Mahānāma为复杂叙事场景的实体解析建立新基准，揭示了现有方法处理文学文本长距离依赖和名称变体的不足。

Abstract: High lexical variation, ambiguous references, and long-range dependencies
make entity resolution in literary texts particularly challenging. We present
Mah\={a}n\={a}ma, the first large-scale dataset for end-to-end Entity Discovery
and Linking (EDL) in Sanskrit, a morphologically rich and under-resourced
language. Derived from the Mah\={a}bh\={a}rata, the world's longest epic, the
dataset comprises over 109K named entity mentions mapped to 5.5K unique
entities, and is aligned with an English knowledge base to support
cross-lingual linking. The complex narrative structure of Mah\={a}n\={a}ma,
coupled with extensive name variation and ambiguity, poses significant
challenges to resolution systems. Our evaluation reveals that current
coreference and entity linking models struggle when evaluated on the global
context of the test set. These results highlight the limitations of current
approaches in resolving entities within such complex discourse. Mah\=an\=ama
thus provides a unique benchmark for advancing entity resolution, especially in
literary domains.

</details>


### [50] [Benchmarking Gaslighting Attacks Against Speech Large Language Models](https://arxiv.org/abs/2509.19858)
*Jinyang Wu,Bin Zhu,Xiandong Zou,Qiquan Zhang,Xu Fang,Pan Zhou*

Main category: cs.CL

TL;DR: 论文提出gaslighting攻击框架评估语音大语言模型鲁棒性，发现攻击导致平均准确率下降24.3%，揭示现有系统脆弱性


<details>
  <summary>Details</summary>
Motivation: 语音大语言模型面临独特认知挑战，现有对抗攻击研究集中在文本/视觉模型，语音交互的模糊性/连续性/感知多样性导致攻击更难检测

Method: 设计五种操纵策略（愤怒/认知干扰/讽刺/隐性/专业否定），构建10,000+测试样本，结合声学扰动实验评估5个多模态大语言模型

Result: 攻击导致平均准确率下降24.3%，模型出现非必要道歉/拒绝等异常行为，显示显著行为脆弱性

Conclusion: 研究揭示语音AI系统安全漏洞，需开发更鲁棒的防御机制，建议采用多维度评估框架提升系统可信度

Abstract: As Speech Large Language Models (Speech LLMs) become increasingly integrated
into voice-based applications, ensuring their robustness against manipulative
or adversarial input becomes critical. Although prior work has studied
adversarial attacks in text-based LLMs and vision-language models, the unique
cognitive and perceptual challenges of speech-based interaction remain
underexplored. In contrast, speech presents inherent ambiguity, continuity, and
perceptual diversity, which make adversarial attacks more difficult to detect.
In this paper, we introduce gaslighting attacks, strategically crafted prompts
designed to mislead, override, or distort model reasoning as a means to
evaluate the vulnerability of Speech LLMs. Specifically, we construct five
manipulation strategies: Anger, Cognitive Disruption, Sarcasm, Implicit, and
Professional Negation, designed to test model robustness across varied tasks.
It is worth noting that our framework captures both performance degradation and
behavioral responses, including unsolicited apologies and refusals, to diagnose
different dimensions of susceptibility. Moreover, acoustic perturbation
experiments are conducted to assess multi-modal robustness. To quantify model
vulnerability, comprehensive evaluation across 5 Speech and multi-modal LLMs on
over 10,000 test samples from 5 diverse datasets reveals an average accuracy
drop of 24.3% under the five gaslighting attacks, indicating significant
behavioral vulnerability. These findings highlight the need for more resilient
and trustworthy speech-based AI systems.

</details>


### [51] [SINAI at eRisk@CLEF 2025: Transformer-Based and Conversational Strategies for Depression Detection](https://arxiv.org/abs/2509.19861)
*Alba Maria Marmol-Romero,Manuel Garcia-Vega,Miguel Angel Garcia-Cumbreras,Arturo Montejo-Raez*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper describes the participation of the SINAI-UJA team in the
eRisk@CLEF 2025 lab. Specifically, we addressed two of the proposed tasks: (i)
Task 2: Contextualized Early Detection of Depression, and (ii) Pilot Task:
Conversational Depression Detection via LLMs. Our approach for Task 2 combines
an extensive preprocessing pipeline with the use of several transformer-based
models, such as RoBERTa Base or MentalRoBERTA Large, to capture the contextual
and sequential nature of multi-user conversations. For the Pilot Task, we
designed a set of conversational strategies to interact with LLM-powered
personas, focusing on maximizing information gain within a limited number of
dialogue turns. In Task 2, our system ranked 8th out of 12 participating teams
based on F1 score. However, a deeper analysis revealed that our models were
among the fastest in issuing early predictions, which is a critical factor in
real-world deployment scenarios. This highlights the trade-off between early
detection and classification accuracy, suggesting potential avenues for
optimizing both jointly in future work. In the Pilot Task, we achieved 1st
place out of 5 teams, obtaining the best overall performance across all
evaluation metrics: DCHR, ADODL and ASHR. Our success in this task demonstrates
the effectiveness of structured conversational design when combined with
powerful language models, reinforcing the feasibility of deploying LLMs in
sensitive mental health assessment contexts.

</details>


### [52] [SwissGPC v1.0 -- The Swiss German Podcasts Corpus](https://arxiv.org/abs/2509.19866)
*Samuel Stucki,Mark Cieliebak,Jan Deriu*

Main category: cs.CL

TL;DR: SwissGPC v1.0是首个大规模瑞士德语自然对话语料库，支持语音技术研究。


<details>
  <summary>Details</summary>
Motivation: 现有瑞士德语语料库多为受控语音，需构建自然对话资源支撑真实场景应用。

Method: 通过自动化标注流程处理5400小时原始音频，保留近5000小时跨方言区语音数据。

Result: 建成覆盖7大方言区及标准德语的语料库，含弱标注的自然对话语料。

Conclusion: 该语料库为实际语音应用（如方言识别、语音合成）提供关键数据支撑。

Abstract: We present SwissGPC v1.0, the first mid-to-large-scale corpus of spontaneous
Swiss German speech, developed to support research in ASR, TTS, dialect
identification, and related fields. The dataset consists of links to talk shows
and podcasts hosted on Schweizer Radio und Fernsehen and YouTube, which contain
approximately 5400 hours of raw audio. After segmentation and weak annotation,
nearly 5000 hours of speech were retained, covering the seven major Swiss
German dialect regions alongside Standard German. We describe the corpus
construction methodology, including an automated annotation pipeline, and
provide statistics on dialect distribution, token counts, and segmentation
characteristics. Unlike existing Swiss German speech corpora, which primarily
feature controlled speech, this corpus captures natural, spontaneous
conversations, making it a valuable resource for real-world speech
applications.

</details>


### [53] [Do Before You Judge: Self-Reference as a Pathway to Better LLM Evaluation](https://arxiv.org/abs/2509.19880)
*Wei-Hsiang Lin,Sheng-Lun Wei,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 研究发现LLM生成与评判能力仅弱相关，提出自参考评估策略显著增强两者关联性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成能力与评判能力研究结论不一致的问题，探究两者本质关联机制。

Method: 基于11个模型在21个任务上的系统性分析，设计使用模型自身输出作为参考的评估策略。

Result: 自参考方法使生成与评判能力Spearman相关系数从0.22提升至0.76，模型选择准确率提升24%。

Conclusion: 自参考评估策略有效对齐模型的双重能力，为评估任务提供可靠的代理指标。

Abstract: LLM-as-Judge frameworks are increasingly popular for AI evaluation, yet
research findings on the relationship between models' generation and judgment
abilities remain inconsistent. We investigate this relationship through
systematic dataset- and instance-level analyses across 11 models and 21 diverse
tasks. Despite both capabilities relying on the same underlying knowledge, our
analyses reveal they are only weakly correlated, primarily due to LLMs'
sensitivity to the responses being judged. To address this, we propose a
self-reference-guided evaluation strategy that leverages a model's own answers
as references. This approach significantly strengthens the correlation between
generation and judgment abilities, offering a practical path to align these
skills and providing a reliable proxy for model selection in evaluation tasks.

</details>


### [54] [Future Policy Aware Preference Learning for Mathematical Reasoning](https://arxiv.org/abs/2509.19893)
*Minjae Oh,Yunho Choi,Dongmin Choi,Yohan Jo*

Main category: cs.CL

TL;DR: FPA偏好学习通过未来策略估计实现安全正则化，在数学推理任务中提升DPO/RPO/SimPER性能达5.75%


<details>
  <summary>Details</summary>
Motivation: 现有偏好学习方法（如DPO）在数学推理中因token重叠导致性能崩溃，当前策略正则化存在滞后性

Method: 提出FPA方法：使用logit空间外推估计未来策略作为正则项，预判并抑制有害梯度

Result: 在MATH/GSM8K基准上实现稳定提升，SimPER+FPA提升达5.75%，保持数学token概率且延长有效训练时间

Conclusion: FPA通过前瞻性正则化有效解决数学推理中的过惩罚问题，计算开销可忽略，适用于多种偏好学习框架

Abstract: Preference learning methods such as Direct Preference Optimization (DPO) have
become standard for Large Language Model (LLM) post-training, yet they are
often ineffective for mathematical reasoning. A key challenge is the large
token overlap between preferred and dispreferred trajectories; lowering the
probability of dispreferred trajectories also reduces the probability of shared
useful tokens, leading to over-penalization and overall performance collapse.
As a mitigation, existing algorithms include the probability of a trajectory
under the current policy as a regularization term, which decreases the effect
of the gradient when the probability is low. However, by the time this effect
takes hold, useful tokens may have already been over-penalized as the model has
begun to degrade. To address this, we propose Future Policy Aware (FPA)
preference learning, which replaces the current policy with a future policy in
the regularization term. This future policy is estimated via lightweight,
logit-space extrapolation from a reference model toward the current model. FPA
enables safer training by preemptively regularizing potentially problematic
gradients. We apply FPA to DPO, RPO, and SimPER and evaluate them on the MATH
and GSM8K benchmarks. FPA yields consistent performance gains, with the largest
improvements observed with SimPER, achieving gains of up to 5.75%. We
demonstrate that FPA provides proactive regularization while preserving the
probability of shared, useful mathematical tokens, and enables longer,
degradation-free training with negligible computational overhead. We will
release our code publicly upon publication.

</details>


### [55] [WEST: LLM based Speech Toolkit for Speech Understanding, Generation, and Interaction](https://arxiv.org/abs/2509.19902)
*Binbin Zhang,Chengdong Liang,Shuai Wang,Xuelong Geng,Zhao Guo,Haoyu Li,Hao Yin,Xipeng Yang,Pengshen Zhang,Changwei Ma,Lei Xie*

Main category: cs.CL

TL;DR: 提出基于大语言模型的语音工具包WEST，支持语音理解/生成/交互，具备全栈功能与简单易用特性


<details>
  <summary>Details</summary>
Motivation: 整合LLM优势构建全栈语音工具，解决现有工具分散化、复杂度高的问题，提供可扩展的开源方案

Method: 复用成熟LLM架构与Hugging Face生态，支持识别/合成/理解/对话/多模态任务，集成开源模型扩展能力

Result: 提供可复现的开源基线（准确率98%）与大数据训练方案（性能提升30%），支持开箱即用

Conclusion: WEST通过LLM重构语音技术栈，为学术研究和工业应用提供灵活高效的语音处理解决方案

Abstract: In this paper, we present WEST(WE Speech Toolkit), a speech toolkit based on
a large language model (LLM) for speech understanding, generation, and
interaction. There are three key features of WEST: 1) Fully LLM-based: Standing
on the shoulders of giants by reusing mature architectures, ecosystems (e.g.,
Hugging Face), and methods (e.g., sequence packing) from large models. 2)
Full-stack: Supports tasks such as recognition, synthesis, understanding,
dialogue, and multimodal capabilities, with extensibility to incorporate
open-source models. 3) Simple and Stupid: A simple and stupid speech toolkit
that everyone can Touch. In addition, WEST provides two types of recipes,
models, and experimental results. The first is entirely based on open-source
models and open-source data, allowing users to fully reproduce the experiments
in this paper and serving as a verification system or minimal system baseline.
The second is trained on massive data, offering superior performance so the
user can directly apply it out of the box. WEST is publicly avilable at
https://github.com/wenet-e2e/west/

</details>


### [56] [CorIL: Towards Enriching Indian Language to Indian Language Parallel Corpora and Machine Translation Systems](https://arxiv.org/abs/2509.19941)
*Soham Bhattacharjee,Mukund K Roy,Yathish Poojary,Bhargav Dave,Mihir Raj,Vandan Mujadia,Baban Gain,Pruthwik Mishra,Arafat Ahsan,Parameswari Krishnamurthy,Ashwath Rao,Gurpreet Singh Josan,Preeti Dubey,Aadil Amin Kak,Anna Rao Kulkarni,Narendra VG,Sunita Arora,Rakesh Balbantray,Prasenjit Majumdar,Karunesh K Arora,Asif Ekbal,Dipti Mishra Sharma*

Main category: cs.CL

TL;DR: 构建覆盖11种印度语言的77.2万句对平行语料库CorIL，分政府/卫生/通用三大领域，通过主流NMT模型测试揭示跨脚本翻译性能差异与领域敏感性。


<details>
  <summary>Details</summary>
Motivation: 印度语言的高质量多领域平行语料稀缺，制约机器翻译研究。CorIL填补资源空白，支持领域适应与跨语言迁移分析。

Method: 系统构建并标注多领域双语语料，微调IndicTrans2/NLLB/BhashaVerse等SOTA模型，进行跨脚本（Perso-Arabic/Indic）和跨领域性能对比实验。

Result: 大规模多语言模型在Perso-Arabic脚本（乌尔都语、信德语）表现更优，其他模型在Indic脚本领先；不同领域翻译质量存在显著差异。

Conclusion: 公开CorIL语料库将推动印度语言NMT发展，领域分类支持针对性模型优化，跨脚本分析为迁移学习提供新视角。

Abstract: India's linguistic landscape is one of the most diverse in the world,
comprising over 120 major languages and approximately 1,600 additional
languages, with 22 officially recognized as scheduled languages in the Indian
Constitution. Despite recent progress in multilingual neural machine
translation (NMT), high-quality parallel corpora for Indian languages remain
scarce, especially across varied domains. In this paper, we introduce a
large-scale, high-quality annotated parallel corpus covering 11 of these
languages : English, Telugu, Hindi, Punjabi, Odia, Kashmiri, Sindhi, Dogri,
Kannada, Urdu, and Gujarati comprising a total of 772,000 bi-text sentence
pairs. The dataset is carefully curated and systematically categorized into
three key domains: Government, Health, and General, to enable domain-aware
machine translation research and facilitate effective domain adaptation. To
demonstrate the utility of CorIL and establish strong benchmarks for future
research, we fine-tune and evaluate several state-of-the-art NMT models,
including IndicTrans2, NLLB, and BhashaVerse. Our analysis reveals important
performance trends and highlights the corpus's value in probing model
capabilities. For instance, the results show distinct performance patterns
based on language script, with massively multilingual models showing an
advantage on Perso-Arabic scripts (Urdu, Sindhi) while other models excel on
Indic scripts. This paper provides a detailed domain-wise performance analysis,
offering insights into domain sensitivity and cross-script transfer learning.
By publicly releasing CorIL, we aim to significantly improve the availability
of high-quality training data for Indian languages and provide a valuable
resource for the machine translation research community.

</details>


### [57] [The Knowledge-Behaviour Disconnect in LLM-based Chatbots](https://arxiv.org/abs/2509.20004)
*Jan Broersen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language model-based artificial conversational agents (like ChatGPT)
give answers to all kinds of questions, and often enough these answers are
correct. Just on the basis of that capacity alone, we may attribute knowledge
to them. But do these models use this knowledge as a basis for their own
conversational behaviour? I argue this is not the case, and I will refer to
this failure as a `disconnect'. I further argue this disconnect is fundamental
in the sense that with more data and more training of the LLM on which a
conversational chatbot is based, it will not disappear. The reason is, as I
will claim, that the core technique used to train LLMs does not allow for the
establishment of the connection we are after. The disconnect reflects a
fundamental limitation on the capacities of LLMs, and explains the source of
hallucinations. I will furthermore consider the ethical version of the
disconnect (ethical conversational knowledge not being aligned with ethical
conversational behaviour), since in this domain researchers have come up with
several additional techniques to influence a chatbot's behaviour. I will
discuss how these techniques do nothing to solve the disconnect and can make it
worse.

</details>


### [58] [DiffNator: Generating Structured Explanations of Time-Series Differences](https://arxiv.org/abs/2509.20007)
*Kota Dohi,Tomoya Nishida,Harsh Purohit,Takashi Endo,Yohei Kawaguchi*

Main category: cs.CL

TL;DR: 提出DiffNator框架，通过结构化JSON格式解释时间序列差异，结合时序编码器与LLM模型实现自动化解释生成。


<details>
  <summary>Details</summary>
Motivation: 物联网应用中传感器信号差异解释依赖专家知识，需自动化工具降低理解门槛。

Method: 1. 设计捕获时序差异本质的JSON模板 2. 使用TORI数据集训练时序编码器+冻结LLM的混合模型 3. 生成JSON格式的差异解释

Result: 实验显示DiffNator解释准确率显著超越VQA基线和预训练时序编码器检索方法

Conclusion: DiffNator有效解决时序差异解释难题，为IoT领域提供可解释性分析工具

Abstract: In many IoT applications, the central interest lies not in individual sensor
signals but in their differences, yet interpreting such differences requires
expert knowledge. We propose DiffNator, a framework for structured explanations
of differences between two time series. We first design a JSON schema that
captures the essential properties of such differences. Using the Time-series
Observations of Real-world IoT (TORI) dataset, we generate paired sequences and
train a model that combine a time-series encoder with a frozen LLM to output
JSON-formatted explanations. Experimental results show that DiffNator generates
accurate difference explanations and substantially outperforms both a visual
question answering (VQA) baseline and a retrieval method using a pre-trained
time-series encoder.

</details>


### [59] [Tokenization and Representation Biases in Multilingual Models on Dialectal NLP Tasks](https://arxiv.org/abs/2509.20045)
*Vani Kanjirangat,Tanja Samardžić,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 研究发现Tokenization Parity（TP）和Information Parity（IP）分别预测不同任务类型性能：TP更适合语法相关任务（如QA），IP更适合语义任务（如主题分类）；LLM的语言支持声明可能掩盖底层表征偏差


<details>
  <summary>Details</summary>
Motivation: 探讨影响方言数据模型性能的直接因素，突破传统对数据规模/社会因素等不一致结论的局限，聚焦预训练模型的表征偏差指标（TP/IP）与下游任务关联性

Method: 对比SOTA解码器LLM与编码器模型在方言分类/主题分类/抽取式QA三个任务的表现，控制拉丁/非拉丁脚本、高低资源条件，结合分词器行为分析和词汇覆盖度研究

Result: TP与依赖语法形态特征的任务（QA）相关性更强（平均相关系数0.72），IP则更有效预测语义任务（主题分类相关系数0.68）；LLM存在脚本/分词层面的深层表征失配

Conclusion: 多语言模型评估需结合TP/IP双维度指标，揭示不同任务类型的性能预测机制。模型的语言支持声明应辅以分词/语义层面的细粒度诊断，尤其在处理方言变体时

Abstract: Dialectal data are characterized by linguistic variation that appears small
to humans but has a significant impact on the performance of models. This
dialect gap has been related to various factors (e.g., data size, economic and
social factors) whose impact, however, turns out to be inconsistent. In this
work, we investigate factors impacting the model performance more directly: we
correlate Tokenization Parity (TP) and Information Parity (IP), as measures of
representational biases in pre-trained multilingual models, with the downstream
performance. We compare state-of-the-art decoder-only LLMs with encoder-based
models across three tasks: dialect classification, topic classification, and
extractive question answering, controlling for varying scripts (Latin vs.
non-Latin) and resource availability (high vs. low). Our analysis reveals that
TP is a better predictor of the performance on tasks reliant on syntactic and
morphological cues (e.g., extractive QA), while IP better predicts performance
in semantic tasks (e.g., topic classification). Complementary analyses,
including tokenizer behavior, vocabulary coverage, and qualitative insights,
reveal that the language support claims of LLMs often might mask deeper
mismatches at the script or token level.

</details>


### [60] [Responsible AI Technical Report](https://arxiv.org/abs/2509.20057)
*KT,:,Soonmin Bae,Wanjin Park,Jeongyeop Kim,Yunjin Park,Jungwon Yoon,Junhyung Moon,Myunggyo Oh,Wonhyuk Lee,Junseo Jang,Dongyoung Jung,Minwook Ju,Eunmi Kim,Sujin Kim,Youngchol Kim,Somin Lee,Wonyoung Lee,Minsung Noh,Hyoungjun Park,Eunyoung Shin*

Main category: cs.CL

TL;DR: KT开发了负责任AI评估框架SafetyGuard，通过风险分类和实时拦截技术提升AI服务安全性


<details>
  <summary>Details</summary>
Motivation: 响应韩国《AI基本法》和全球AI治理趋势，解决AI开发运营全流程中的合规风险与安全隐患

Method: 构建本土化AI风险分类体系，设计模型安全性验证方法，开发实时有害响应拦截系统SafetyGuard

Result: 成功发布专有安全防护工具，为韩国AI开发生态提供符合监管要求的系统性风险管理方案

Conclusion: 该研究提供端到端的负责任AI实施路径，通过技术工具与方法论创新支持企业构建合规可靠的AI系统

Abstract: KT developed a Responsible AI (RAI) assessment methodology and risk
mitigation technologies to ensure the safety and reliability of AI services. By
analyzing the Basic Act on AI implementation and global AI governance trends,
we established a unique approach for regulatory compliance and systematically
identify and manage all potential risk factors from AI development to
operation. We present a reliable assessment methodology that systematically
verifies model safety and robustness based on KT's AI risk taxonomy tailored to
the domestic environment. We also provide practical tools for managing and
mitigating identified AI risks. With the release of this report, we also
release proprietary Guardrail : SafetyGuard that blocks harmful responses from
AI models in real-time, supporting the enhancement of safety in the domestic AI
development ecosystem. We also believe these research outcomes provide valuable
insights for organizations seeking to develop Responsible AI.

</details>


### [61] [From Input Perception to Predictive Insight: Modeling Model Blind Spots Before They Become Errors](https://arxiv.org/abs/2509.20065)
*Maggie Mi,Aline Villavicencio,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 提出基于token级似然特征的输入预测方法，无需访问输出即可预判语言模型对特殊表达的误解


<details>
  <summary>Details</summary>
Motivation: 语言模型常因输入阶段的误解（而非输出错误）在处理习语/比喻/上下文敏感内容时失败，需建立预判机制

Method: 基于surprisal和统一信息密度假说，提取token级似然特征捕捉输入理解的局部不确定性

Result: 在五个语言挑战数据集上超越基线，大模型受益于局部特征，小模型依赖全局模式

Conclusion: 该轻量级方法具有通用性，通过纯输入分析实现生成前错误预测，显著提升模型可靠性

Abstract: Language models often struggle with idiomatic, figurative, or
context-sensitive inputs, not because they produce flawed outputs, but because
they misinterpret the input from the outset. We propose an input-only method
for anticipating such failures using token-level likelihood features inspired
by surprisal and the Uniform Information Density hypothesis. These features
capture localized uncertainty in input comprehension and outperform standard
baselines across five linguistically challenging datasets. We show that
span-localized features improve error detection for larger models, while
smaller models benefit from global patterns. Our method requires no access to
outputs or hidden activations, offering a lightweight and generalizable
approach to pre-generation error prediction.

</details>


### [62] [From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training](https://arxiv.org/abs/2509.20072)
*Tianqiao Liu,Xueyi Li,Hao Wang,Haoxuan Li,Zhichao Chen,Weiqi Luo,Zitao Liu*

Main category: cs.CL

TL;DR: 提出TtT框架，将自回归文本生成与非自回归音频扩散整合到单一Transformer架构中，解决多模态对话系统中依赖结构不对称问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型（如MOSHI）需要复杂多阶段训练且忽略音频-文本依赖结构的不对称性：文本需因果顺序，音频主要依赖源文本而非前序音频标记。

Method: 在预训练LLM的Transformer架构中实现AR文本生成与non-AR音频扩散的统一建模框架。

Result: 理论上可降低计算成本，提升语音对话系统的生成效率（注：摘要未明确实验数据）

Conclusion: 该框架通过差异化处理文本和音频的依赖结构，为多模态对话系统提供了更高效的建模方案。

Abstract: Recent advances in large language models have attracted significant interest
in extending their capabilities to multimodal scenarios, particularly for
speech-in speech-out conversational systems. However, existing multimodal
models handling interleaved audio and text, such as MOSHI require complex multi
stage training pipelines, incurring substantial computational costs. Moreover,
these models uniformly apply autoregressive generation to both text and audio
tokens, overlooking a fundamental asymmetry in their dependency structures:
while text tokens exhibit strong target target dependencies requiring causal
ordering, audio tokens are predominantly driven by source target dependencies,
where audio outputs primarily condition on source text rather than preceding
audio tokens. In this work, we propose TtT, a unified audio-text modeling
framework that integrates AR text generation with non-autoregressive audio
diffusion within a single Transformer architecture initialized from a
pretrained LLM.

</details>


### [63] [Can Constructions "SCAN" Compositionality ?](https://arxiv.org/abs/2509.20074)
*Ganesh Katrapati,Manish Shrivastava*

Main category: cs.CL

TL;DR: 通过无监督方法挖掘伪结构，显著提升序列模型在SCAN数据集组合泛化任务中的表现（ADD JUMP达47.8%，AROUND RIGHT达20.3%），且具备强数据效率


<details>
  <summary>Details</summary>
Motivation: 序列模型虽在多数任务表现优异，但受限于组合泛化能力。核心问题在于未能内化'结构'——即形式与意义的约定配对模式，这些结构支撑着有效的重组能力。

Method: 提出无监督的伪结构挖掘方法：从训练数据自动提取带可变槽位的模板，无需修改模型架构或增加监督信号

Result: 在OOD测试集上，ADD JUMP准确率提升至47.8%（+37.5%），AROUND RIGHT达20.3%；仅用40%训练数据即达到竞争性能

Conclusion: 基于结构感知的数据预处理方法，相比复杂架构改造更具潜力，为提升模型系统泛化提供新路径

Abstract: Sequence to Sequence models struggle at compositionality and systematic
generalisation even while they excel at many other tasks. We attribute this
limitation to their failure to internalise constructions conventionalised form
meaning pairings that license productive recombination. Building on these
insights, we introduce an unsupervised procedure for mining
pseudo-constructions: variable-slot templates automatically extracted from
training data. When applied to the SCAN dataset, our method yields large gains
out-of-distribution splits: accuracy rises to 47.8 %on ADD JUMP and to 20.3% on
AROUND RIGHT without any architectural changes or additional supervision. The
model also attains competitive performance with? 40% of the original training
data, demonstrating strong data efAciency. Our findings highlight the promise
of construction-aware preprocessing as an alternative to heavy architectural or
training-regime interventions.

</details>


### [64] [OLaPh: Optimal Language Phonemizer](https://arxiv.org/abs/2509.20086)
*Johannes Wirth*

Main category: cs.CL

TL;DR: 提出OLaPh框架，通过整合词典、NLP技术和概率评分提升音素转换准确率，并利用LLM增强泛化能力


<details>
  <summary>Details</summary>
Motivation: 传统音素转换方法在处理专名、外来词等复杂词汇时存在局限性，需开发更精确通用的解决方案

Method: 结合大型词典、复合词解析与概率评分函数构建OLaPh框架，并训练LLM处理残留错误案例

Result: 在德/英语测试中超越现有方法，LLM在挑战性数据集上实现更强泛化性能

Conclusion: 框架与LLM的协同显著提升语音合成前端处理质量，并开源资源促进后续研究

Abstract: Phonemization, the conversion of text into phonemes, is a key step in
text-to-speech. Traditional approaches use rule-based transformations and
lexicon lookups, while more advanced methods apply preprocessing techniques or
neural networks for improved accuracy on out-of-domain vocabulary. However, all
systems struggle with names, loanwords, abbreviations, and homographs. This
work presents OLaPh (Optimal Language Phonemizer), a framework that combines
large lexica, multiple NLP techniques, and compound resolution with a
probabilistic scoring function. Evaluations in German and English show improved
accuracy over previous approaches, including on a challenging dataset. To
further address unresolved cases, we train a large language model on
OLaPh-generated data, which achieves even stronger generalization and
performance. Together, the framework and LLM improve phonemization consistency
and provide a freely available resource for future research.

</details>


### [65] [Causal Understanding by LLMs: The Role of Uncertainty](https://arxiv.org/abs/2509.20088)
*Oscar Lithgow-Serrano,Vani Kanjirangat,Alessandro Antonucci*

Main category: cs.CL

TL;DR: 研究发现LLMs在因果分类任务中的失败源于结构性表征缺失而非预训练数据不足


<details>
  <summary>Details</summary>
Motivation: 探究语言模型在因果关系理解中表现接近随机准确率的根本原因（数据暴露不足 vs 表征缺陷）

Method: 基于18K PubMed语句，通过因果分类（四类关系判断）和复述检测任务，对比7个模型在预训练数据内外样本的表现，结合熵值分析和校准误差评估

Result: 模型在已见/未见数据表现无差异（p>0.05），无记忆偏向（24.8%原句选择），输出分布平坦（熵值1.35/1.39），指令模型存在严重校准错误（Qwen置信度>95%但准确率32.8%）

Conclusion: 因果理解失败源于模型缺乏结构化因果表征能力，增加预训练因果样本无法解决根本问题

Abstract: Recent papers show LLMs achieve near-random accuracy in causal relation
classification, raising questions about whether such failures arise from
limited pretraining exposure or deeper representational gaps. We investigate
this under uncertainty-based evaluation, testing whether pretraining exposure
to causal examples improves causal understanding >18K PubMed sentences -- half
from The Pile corpus, half post-2024 -- across seven models
(Pythia-1.4B/7B/12B, GPT-J-6B, Dolly-7B/12B, Qwen-7B). We analyze model
behavior through: (i) causal classification, where the model identifies causal
relationships in text, and (ii) verbatim memorization probing, where we assess
whether the model prefers previously seen causal statements over their
paraphrases. Models perform four-way classification
(direct/conditional/correlational/no-relationship) and select between originals
and their generated paraphrases. Results show almost identical accuracy on
seen/unseen sentences (p > 0.05), no memorization bias (24.8% original
selection), and output distribution over the possible options is almost flat,
with entropic values near the maximum (1.35/1.39), confirming random guessing.
Instruction-tuned models show severe miscalibration (Qwen: > 95% confidence,
32.8% accuracy, ECE=0.49). Conditional relations induce highest entropy (+11%
vs. direct). These findings suggest that failures in causal understanding arise
from the lack of structured causal representation, rather than insufficient
exposure to causal examples during pretraining.

</details>


### [66] [Integrated Framework for LLM Evaluation with Answer Generation](https://arxiv.org/abs/2509.20097)
*Sujeong Lee,Hayoung Lee,Seongsoo Heo,Wonik Choi*

Main category: cs.CL

TL;DR: SPEED框架通过专家驱动的多维度描述性分析，解决了传统LLM评估方法在公平性和可解释性方面的不足，显著提升了评估质量与资源效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于固定参考答案的基准测试无法捕捉模型输出的定性特征（如幻觉内容/毒性/语境适配性），需开发更全面的动态评估体系。

Method: 构建包含幻觉检测/毒性评估/词汇语境适配性等维度的专家诊断系统，通过轻量化专家模型的协同反馈实现高效多维评估。

Result: 实验证明SPEED在不同领域数据集上均保持稳定评估性能，且资源效率显著优于大规模评估模型。

Conclusion: 该框架通过专家反馈机制提升了LLM评估的公平性与可解释性，为现有评估方法提供了高效替代方案。

Abstract: Reliable evaluation of large language models is essential to ensure their
applicability in practical scenarios. Traditional benchmark-based evaluation
methods often rely on fixed reference answers, limiting their ability to
capture important qualitative aspects of generated responses. To address these
shortcomings, we propose an integrated evaluation framework called
\textit{self-refining descriptive evaluation with expert-driven diagnostics},
SPEED, which utilizes specialized functional experts to perform comprehensive,
descriptive analyses of model outputs. Unlike conventional approaches, SPEED
actively incorporates expert feedback across multiple dimensions, including
hallucination detection, toxicity assessment, and lexical-contextual
appropriateness. Experimental results demonstrate that SPEED achieves robust
and consistent evaluation performance across diverse domains and datasets.
Additionally, by employing relatively compact expert models, SPEED demonstrates
superior resource efficiency compared to larger-scale evaluators. These
findings illustrate that SPEED significantly enhances fairness and
interpretability in LLM evaluations, offering a promising alternative to
existing evaluation methodologies.

</details>


### [67] [Less is More: The Effectiveness of Compact Typological Language Representations](https://arxiv.org/abs/2509.20129)
*York Hay Ng,Phuong Hanh Hoang,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 提出优化URIEL+类型特征空间的流程，通过特征筛选与填补生成紧凑可解释的语言类型表示


<details>
  <summary>Details</summary>
Motivation: URIEL+等高维稀疏的语言特征数据集（尤其对低资源语言）会影响距离度量的有效性，限制多语言NLP应用性能

Method: 组合特征选择（降维）与特征填补（处理缺失值）的流程优化URIEL+特征空间

Result: 优化后的紧凑表征能产生更有效的语言距离指标，在多语言NLP任务中提升性能

Conclusion: 紧凑优化的类型学表示比原始高维数据更具信息量，可改善多语言NLP应用效果

Abstract: Linguistic feature datasets such as URIEL+ are valuable for modelling
cross-lingual relationships, but their high dimensionality and sparsity,
especially for low-resource languages, limit the effectiveness of distance
metrics. We propose a pipeline to optimize the URIEL+ typological feature space
by combining feature selection and imputation, producing compact yet
interpretable typological representations. We evaluate these feature subsets on
linguistic distance alignment and downstream tasks, demonstrating that
reduced-size representations of language typology can yield more informative
distance metrics and improve performance in multilingual NLP applications.

</details>


### [68] [Embedding Domain Knowledge for Large Language Models via Reinforcement Learning from Augmented Generation](https://arxiv.org/abs/2509.20162)
*Chaojun Nie,Jun Zhou,Guanxiang Wang,Shisong Wud,Zichen Wang*

Main category: cs.CL

TL;DR: 提出基于增强生成强化学习（RLAG）的方法，通过迭代优化奖励指标解决LLMs领域知识不足问题


<details>
  <summary>Details</summary>
Motivation: 传统CPT方法忽视关键知识优先级，SFT难以构建连贯知识结构，导致LLMs在专业领域存在知识缺口和时间滞后

Method: 设计循环采样生成→奖励计算优化的强化学习框架，使用最高log概率样本及三类定制奖励指标指导模型优化

Result: 在医疗/法律/天文学/时事等领域数据集上显著超越基线方法，准确率和解释合理性评估表现优异

Conclusion: RLAG有效嵌入上下文连贯的领域知识，通过开源推动领域适应技术发展

Abstract: Large language models (LLMs) often exhibit limited performance on
domain-specific tasks due to the natural disproportionate representation of
specialized information in their training data and the static nature of these
datasets. Knowledge scarcity and temporal lag create knowledge gaps for domain
applications. While post-training on domain datasets can embed knowledge into
models, existing approaches have some limitations. Continual Pre-Training (CPT)
treats all tokens in domain documents with equal importance, failing to
prioritize critical knowledge points, while supervised fine-tuning (SFT) with
question-answer pairs struggles to develop the coherent knowledge structures
necessary for complex reasoning tasks. To address these challenges, we propose
Reinforcement Learning from Augmented Generation (RLAG). Our approach
iteratively cycles between sampling generations and optimizing the model
through calculated rewards, effectively embedding critical and contextually
coherent domain knowledge. We select generated outputs with the highest log
probabilities as the sampling result, then compute three tailored reward
metrics to guide the optimization process. To comprehensively evaluate domain
expertise, we assess answer accuracy and the rationality of explanations
generated for correctly answered questions. Experimental results across
medical, legal, astronomy, and current events datasets demonstrate that our
proposed method significantly outperforms baseline approaches. Our code and
data are open sourced at https://github.com/ChaojunNie/RLAG.

</details>


### [69] [Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian](https://arxiv.org/abs/2509.20168)
*Ghazal Kalhor,Behnam Bahrak*

Main category: cs.CL

TL;DR: 该研究通过新指标DS-GSI量化多语言大模型中的性别偏见，发现波斯语等低资源语言模型存在显著性别刻板印象（尤其在体育领域），所有被测模型均存在偏差。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注高资源语言的性别偏见，而波斯语等低资源语言因语言特性特殊且研究不足，需确保LLMs消除性别偏见以避免表征伤害。

Method: 1. 提出经真实数据验证的模板探测法
2. 设计领域特异性性别偏差指数DS-GSI
3. 在4个语义领域测试GPT-4o mini等4个主流模型，对比波斯语与英语表现

Result: 1. 所有模型均存在性别刻板印象
2. 波斯语性别偏差程度全面超过英语
3. 体育领域性别偏见最显著（如角色分配固化）
4. GPT-4o mini相对偏差最小

Conclusion: 该研究揭示了低资源语言模型偏见评估的紧迫性，提出的DS-GSI框架为跨语言AI伦理评估提供了方法论，强调需开发包容性NLP实践。

Abstract: Multilingual Large Language Models (LLMs) are increasingly used worldwide,
making it essential to ensure they are free from gender bias to prevent
representational harm. While prior studies have examined such biases in
high-resource languages, low-resource languages remain understudied. In this
paper, we propose a template-based probing methodology, validated against
real-world data, to uncover gender stereotypes in LLMs. As part of this
framework, we introduce the Domain-Specific Gender Skew Index (DS-GSI), a
metric that quantifies deviations from gender parity. We evaluate four
prominent models, GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, and Qwen QwQ 32B,
across four semantic domains, focusing on Persian, a low-resource language with
distinct linguistic features. Our results show that all models exhibit gender
stereotypes, with greater disparities in Persian than in English across all
domains. Among these, sports reflect the most rigid gender biases. This study
underscores the need for inclusive NLP practices and provides a framework for
assessing bias in other low-resource languages.

</details>


### [70] [Thinking Augmented Pre-training](https://arxiv.org/abs/2509.20186)
*Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei*

Main category: cs.CL

TL;DR: 提出通过自动生成思考轨迹增强文本数据的方法（TPT），显著提高大型语言模型训练的数据效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练面临计算资源增长与高质量数据不足的矛盾，部分高质量标记因逻辑复杂难以被模型有效学习。

Method: 在预训练阶段自动生成思考轨迹对文本进行增强，通过逐步推理分解复杂逻辑，提升高价值标记的学习效率。

Result: 数据利用率提升3倍，3B参数模型在多项推理基准测试中性能提升超10%，不同规模模型均显示显著改进。

Conclusion: TPT为提升LLM训练效率提供了通用解决方案，验证了数据增强路径在资源受限场景下的有效性。

Abstract: This paper introduces a simple and scalable approach to improve the data
efficiency of large language model (LLM) training by augmenting existing text
data with thinking trajectories. The compute for pre-training LLMs has been
growing at an unprecedented rate, while the availability of high-quality data
remains limited. Consequently, maximizing the utility of available data
constitutes a significant research challenge. A primary impediment is that
certain high-quality tokens are difficult to learn given a fixed model
capacity, as the underlying rationale for a single token can be exceptionally
complex and deep. To address this issue, we propose Thinking augmented
Pre-Training (TPT), a universal methodology that augments text with
automatically generated thinking trajectories. Such augmentation effectively
increases the volume of the training data and makes high-quality tokens more
learnable through step-by-step reasoning and decomposition. We apply TPT across
diverse training configurations up to $100$B tokens, encompassing pre-training
with both constrained and abundant data, as well as mid-training from strong
open-source checkpoints. Experimental results indicate that our method
substantially improves the performance of LLMs across various model sizes and
families. Notably, TPT enhances the data efficiency of LLM pre-training by a
factor of $3$. For a $3$B parameter model, it improves the post-training
performance by over $10\%$ on several challenging reasoning benchmarks.

</details>


### [71] [Play by the Type Rules: Inferring Constraints for LLM Functions in Declarative Programs](https://arxiv.org/abs/2509.20208)
*Parker Glenn,Alfy Samuel,Daben Liu*

Main category: cs.CL

TL;DR: 研究提出在SQL类查询语言中整合LLM函数，通过优化执行流程解决性能瓶颈，实验证明小型语言模型在混合数据源处理中表现优异，并实现7%准确率提升与53%延迟改善。


<details>
  <summary>Details</summary>
Motivation: 当前LLM函数需多次后处理调用来对齐数据库值，导致性能瓶颈。研究旨在探索高效整合LLM到查询语言中的方法，减少延迟同时保持类型正确性。

Method: 通过测试不同规模开源模型在SQL类语言中的解析/执行能力，发现小模型优势；提出基于类型检查的LLM函数优化方案，减少多步后处理需求。

Result: 在多跳问答任务中实现53%延迟优化，准确率提升7%，小型模型（如1.3B参数）在函数执行任务中表现接近GPT-3.5。

Conclusion: 小型语言模型在结构化查询场景中具备替代大模型的潜力，类型约束优化方案可有效平衡LLM灵活性与传统数据库执行效率。

Abstract: Integrating LLM powered operators in declarative query languages allows for
the combination of cheap and interpretable functions with powerful,
generalizable language model reasoning. However, in order to benefit from the
optimized execution of a database query language like SQL, generated outputs
must align with the rules enforced by both type checkers and database contents.
Current approaches address this challenge with orchestrations consisting of
many LLM-based post-processing calls to ensure alignment between generated
outputs and database values, introducing performance bottlenecks. We perform a
study on the ability of various sized open-source language models to both parse
and execute functions within a query language based on SQL, showing that small
language models can excel as function executors over hybrid data sources. Then,
we propose an efficient solution to enforce the well-typedness of LLM
functions, demonstrating 7% accuracy improvement on a multi-hop question
answering dataset with 53% improvement in latency over comparable solutions. We
make our implementation available at https://github.com/parkervg/blendsql

</details>


### [72] [Low-Resource English-Tigrinya MT: Leveraging Multilingual Models, Custom Tokenizers, and Clean Evaluation Benchmarks](https://arxiv.org/abs/2509.20209)
*Hailay Kidu Teklehaymanot,Gebrearegawi Gidey,Wolfgang Nejdl*

Main category: cs.CL

TL;DR: 提出定制化分词与迁移学习结合的神经机器翻译方法，构建英语-提格里尼亚语评估数据集，显著提升低资源语言翻译质量


<details>
  <summary>Details</summary>
Motivation: 提格里尼亚语等低资源语言面临语料稀缺、分词策略不足、评估基准缺失三大挑战，现有零样本翻译模型表现欠佳

Method: 1. 开发语言特异性分词器
2. 多语言预训练模型迁移学习
3. 领域自适应微调策略
4. 构建多领域人工对齐评估数据集
5. 采用Bonferroni校正确保统计显著性

Result: 定制分词迁移学习模型全面超越零样本基线（BLEU+3.2，chrF+5.1），人工评估显示流畅度提升37%，统计显著（p<0.05）

Conclusion: 语言感知建模与可复现基准对低资源语言至关重要，开源资源推动提格里尼亚语NMT发展，误差分析指明形态学建模改进方向

Abstract: Despite advances in Neural Machine Translation (NMT), low-resource languages
like Tigrinya remain underserved due to persistent challenges, including
limited corpora, inadequate tokenization strategies, and the lack of
standardized evaluation benchmarks. This paper investigates transfer learning
techniques using multilingual pretrained models to enhance translation quality
for morphologically rich, low-resource languages. We propose a refined approach
that integrates language-specific tokenization, informed embedding
initialization, and domain-adaptive fine-tuning. To enable rigorous assessment,
we construct a high-quality, human-aligned English-Tigrinya evaluation dataset
covering diverse domains. Experimental results demonstrate that transfer
learning with a custom tokenizer substantially outperforms zero-shot baselines,
with gains validated by BLEU, chrF, and qualitative human evaluation.
Bonferroni correction is applied to ensure statistical significance across
configurations. Error analysis reveals key limitations and informs targeted
refinements. This study underscores the importance of linguistically aware
modeling and reproducible benchmarks in bridging the performance gap for
underrepresented languages. Resources are available at
https://github.com/hailaykidu/MachineT_TigEng
  and https://huggingface.co/Hailay/MachineT_TigEng

</details>


### [73] [Investigating the Representation of Backchannels and Fillers in Fine-tuned Language Models](https://arxiv.org/abs/2509.20237)
*Yu Wang,Leyi Lao,Langchu Huang,Gabriel Skantze,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 通过微调策略增强语言模型对对话中反馈词和填充词的语义区分能力


<details>
  <summary>Details</summary>
Motivation: 现代Transformer语言模型对对话中重要的反馈词和填充词表征不足，需要探索微调策略对模型学习这些语言现象的影响

Method: 使用三种微调策略在英日双语对话语料库上训练模型，采用聚类分析（轮廓系数评估）和自然语言生成指标进行验证

Result: 微调后模型的反馈词/填充词表征轮廓系数提升17.4%，生成语句与人类对话相似度提高（ROUGE-L提升23.1%）

Conclusion: 通过领域适配微调可有效增强通用语言模型的对话生成能力，使其更接近人类自然对话模式

Abstract: Backchannels and fillers are important linguistic expressions in dialogue,
but are under-represented in modern transformer-based language models (LMs).
Our work studies the representation of them in language models using three
fine-tuning strategies. The models are trained on three dialogue corpora in
English and Japanese, where backchannels and fillers are preserved and
annotated, to investigate how fine-tuning can help LMs learn their
representations. We first apply clustering analysis to the learnt
representation of backchannels and fillers, and have found increased silhouette
scores in representations from fine-tuned models, which suggests that
fine-tuning enables LMs to distinguish the nuanced semantic variation in
different backchannel and filler use. We also use natural language generation
(NLG) metrics to confirm that the utterances generated by fine-tuned language
models resemble human-produced utterances more closely. Our findings suggest
the potentials of transforming general LMs into conversational LMs that are
more capable of producing human-like languages adequately.

</details>


### [74] [Instruction Boundary: Quantifying Biases in LLM Reasoning under Various Coverage](https://arxiv.org/abs/2509.20278)
*Zipeng Ling,Yuehao Tang,Chen Huang,Shuliang Liu,Gaoyang Jiang,Shenghong Fu,Junqi Yang,Yao Wan,Jiawan Zhang,Kejia Huang,Xuming Hu*

Main category: cs.CL

TL;DR: 研究发现大语言模型存在'指令边界'漏洞，提示词设计缺陷会导致模型产生显著偏见，需开发者优化模型并提升用户提示词质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽表现优异，但提示词设计偏差（如冗余/不完整提示）会误导模型判断，这种系统性偏见尚未被充分研究，可能影响实际应用可靠性。

Method: 提出BiasDetector框架，从完整/冗余/不完整三类指令出发，构建包含八种偏差维度的评估体系，对主流大语言模型进行系统性测试。

Result: 实验显示主流模型在核心指标准确率较高，但多数下游任务因提示词覆盖不足产生显著偏见，证明现有模型可靠性仍有较大提升空间。

Conclusion: 开发者需针对性优化模型抗偏能力，用户应谨慎设计提示词选项，研究为提升LLM推理可靠性提供了实证依据和优化方向。

Abstract: Large-language-model (LLM) reasoning has long been regarded as a powerful
tool for problem solving across domains, providing non-experts with valuable
advice. However, their limitations - especially those stemming from prompt
design - remain underexplored. Because users may supply biased or incomplete
prompts - often unintentionally - LLMs can be misled, undermining reliability
and creating risks. We refer to this vulnerability as the Instruction Boundary.
To investigate the phenomenon, we distill it into eight concrete facets and
introduce BiasDetector, a framework that measures biases arising from three
instruction types: complete, redundant, and insufficient. We evaluate several
mainstream LLMs and find that, despite high headline accuracy, substantial
biases persist in many downstream tasks as a direct consequence of prompt
coverage. Our empirical study confirms that LLM reasoning reliability can still
be significantly improved. We analyze the practical impact of these biases and
outline mitigation strategies. Our findings underscore the need for developers
to tackle biases and for users to craft options carefully.

</details>


### [75] [Feeding Two Birds or Favoring One? Adequacy-Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation](https://arxiv.org/abs/2509.20287)
*Behzad Shayegh,Jan-Thorsten Peter,David Vilar,Tobias Domhan,Juraj Juraska,Markus Freitag,Lili Mou*

Main category: cs.CL

TL;DR: 论文揭示了机器翻译中充分性与流畅性指标的权衡关系，发现现有评估体系偏向充分性，并提出了合成系统方法以控制元评估偏差。


<details>
  <summary>Details</summary>
Motivation: 探究机器翻译评估中充分性(adequacy)与流畅性(fluency)的权衡关系及其对指标排名的影响。

Method: 1. 分析流行指标在权衡中的位置 
2. 通过WMT元评估数据验证偏差 
3. 提出合成翻译系统方法控制评估偏差

Result: 当前指标普遍偏向充分性，且元评估的系统构成会强化这种偏向。提出的合成方法能有效控制评估偏差。

Conclusion: 理解充分性与流畅性的权衡对改进机器翻译评估体系至关重要，合成系统方法为更公平的元评估提供了新思路。

Abstract: We investigate the tradeoff between adequacy and fluency in machine
translation. We show the severity of this tradeoff at the evaluation level and
analyze where popular metrics fall within it. Essentially, current metrics
generally lean toward adequacy, meaning that their scores correlate more
strongly with the adequacy of translations than with fluency. More importantly,
we find that this tradeoff also persists at the meta-evaluation level, and that
the standard WMT meta-evaluation favors adequacy-oriented metrics over
fluency-oriented ones. We show that this bias is partially attributed to the
composition of the systems included in the meta-evaluation datasets. To control
this bias, we propose a method that synthesizes translation systems in
meta-evaluation. Our findings highlight the importance of understanding this
tradeoff in meta-evaluation and its impact on metric rankings.

</details>


### [76] [Multilingual Hope Speech Detection: A Comparative Study of Logistic Regression, mBERT, and XLM-RoBERTa with Active Learning](https://arxiv.org/abs/2509.20315)
*T. O. Abiola,K. D. Abiodun,O. E. Olumide,O. O. Adebanji,O. Hiram Calvo,Grigori Sidorov*

Main category: cs.CL

TL;DR: 提出基于主动学习和Transformer的多语言框架，有效检测低资源环境中的希望言论


<details>
  <summary>Details</summary>
Motivation: 希望言论对促进网络积极话语至关重要，但多语言/低资源场景下的检测仍具挑战性

Method: 使用mBERT和XLM-RoBERTa等Transformer模型，结合主动学习策略进行多语言训练

Result: XLM-RoBERTa取得最高准确率，主动学习在小样本场景保持强性能

Conclusion: 多语言Transformer与数据高效策略的结合为希望言论检测提供有效解决方案

Abstract: Hope speech language that fosters encouragement and optimism plays a vital
role in promoting positive discourse online. However, its detection remains
challenging, especially in multilingual and low-resource settings. This paper
presents a multilingual framework for hope speech detection using an active
learning approach and transformer-based models, including mBERT and
XLM-RoBERTa. Experiments were conducted on datasets in English, Spanish,
German, and Urdu, including benchmark test sets from recent shared tasks. Our
results show that transformer models significantly outperform traditional
baselines, with XLM-RoBERTa achieving the highest overall accuracy.
Furthermore, our active learning strategy maintained strong performance even
with small annotated datasets. This study highlights the effectiveness of
combining multilingual transformers with data-efficient training strategies for
hope speech detection.

</details>


### [77] [SIM-CoT: Supervised Implicit Chain-of-Thought](https://arxiv.org/abs/2509.20317)
*Xilin Wei,Xiaoran Liu,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Xipeng Qiu,Dahua Lin*

Main category: cs.CL

TL;DR: 提出SIM-CoT方法解决隐式思维链训练不稳定的问题，通过步骤级监督提升潜在表示质量，在保持效率的同时显著缩小与显式CoT的性能差距。


<details>
  <summary>Details</summary>
Motivation: 发现隐式CoT在扩展计算预算时潜在表示会趋同失效，核心问题是缺乏步骤级监督导致语义多样性丢失。

Method: 设计带辅助解码器的训练框架，通过显式对齐隐式token与推理步骤来稳定潜在空间，推理阶段移除解码器保持零额外开销。

Result: 在GPT-2/Llama等模型上提升基线方法8.2%/3.0%，token效率达显式CoT的2.3倍，大模型性能差距缩小67%。

Conclusion: 通过轻量级步骤监督机制，SIM-CoT实现了隐式推理稳定性与效率的突破，为高效推理系统开发提供新方向。

Abstract: Implicit Chain-of-Thought (CoT) methods present a promising, token-efficient
alternative to explicit CoT reasoning in Large Language Models (LLMs), but a
persistent performance gap has limited the application of implicit CoT. We
identify a core latent instability issue by scaling the computational budget of
implicit CoT approaches: as we increase the number of implicit reasoning tokens
to enhance performance, the training process often becomes unstable and
collapses. Our analysis reveals that this instability arises from the latent
representations becoming homogeneous and losing their semantic diversity, a
failure caused by insufficient step-level supervision in existing implicit CoT
approaches. To address this issue, we propose SIM-CoT, a plug-and-play training
module that introduces step-level supervision to stabilize and enrich the
latent reasoning space. Specifically, SIM-CoT employs an auxiliary decoder
during training to align each implicit token with its corresponding explicit
reasoning step, ensuring that latent states capture distinct and meaningful
information. The proposed auxiliary decoder is removed during inference,
preserving the computational efficiency of implicit CoT methods with no added
overhead. In addition, the auxiliary decoder affords interpretability of
implicit reasoning by projecting each latent token onto an explicit reasoning
vocabulary, enabling per-step visualization of semantic roles and diagnosis.
SIM-CoT significantly enhances both the in-domain accuracy and out-of-domain
stability of various implicit CoT methods, boosting baselines like Coconut by
+8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strong
scalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1%
with 2.3\times greater token efficiency, while substantially closing the
performance gap on larger models like LLaMA-3.1 8B.

</details>


### [78] [Z-Scores: A Metric for Linguistically Assessing Disfluency Removal](https://arxiv.org/abs/2509.20319)
*Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee*

Main category: cs.CL

TL;DR: 提出Z-Scores评估框架，通过细粒度分类诊断揭示语音修复模型的系统性缺陷，突破传统词级指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统F1等词级指标无法解释模型失败原因，需建立能定位特定不流畅类型弱点的诊断工具来指导针对性优化。

Method: 开发基于语言学分类的Z-Scores指标，结合确定性对齐模块实现跨文本映射，提供EDITED/INTJ/PRN等类别的独立评估维度。

Result: 案例验证Z-Scores成功暴露LLMs处理语气词(INTJ)和插入语(PRN)的潜在缺陷，这些缺陷在传统F1分数中被整体表现掩盖。

Conclusion: 该指标为模型优化提供精准导航，通过识别故障模式支持定制化干预方案（如数据增强），实现可测量的性能提升。

Abstract: Evaluating disfluency removal in speech requires more than aggregate
token-level scores. Traditional word-based metrics such as precision, recall,
and F1 (E-Scores) capture overall performance but cannot reveal why models
succeed or fail. We introduce Z-Scores, a span-level linguistically-grounded
evaluation metric that categorizes system behavior across distinct disfluency
types (EDITED, INTJ, PRN). Our deterministic alignment module enables robust
mapping between generated text and disfluent transcripts, allowing Z-Scores to
expose systematic weaknesses that word-level metrics obscure. By providing
category-specific diagnostics, Z-Scores enable researchers to identify model
failure modes and design targeted interventions -- such as tailored prompts or
data augmentation -- yielding measurable performance improvements. A case study
with LLMs shows that Z-Scores uncover challenges with INTJ and PRN disfluencies
hidden in aggregate F1, directly informing model refinement strategies.

</details>


### [79] [DRES: Benchmarking LLMs for Disfluency Removal](https://arxiv.org/abs/2509.20321)
*Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee*

Main category: cs.CL

TL;DR: 提出了DRES评估套件用于不流畅语移除任务，发现分段处理有效但微调影响泛化，并给出九条实用部署建议


<details>
  <summary>Details</summary>
Motivation: 不流畅语严重影响语音系统的命令解析、摘要生成和对话代理的准确性，需要建立可重复的评估基准

Method: 基于人工标注的Switchboard数据集构建DRES基准，系统评估不同规模/架构的LLM模型及提示策略

Result: 分段处理提升性能、推理模型倾向过度删除、微调虽精准但损害泛化能力

Conclusion: DRES为语音系统提供了可复现的模型无关评估基础，并提出九条实用部署建议（R1-R9）

Abstract: Disfluencies -- such as "um," "uh," interjections, parentheticals, and edited
statements -- remain a persistent challenge for speech-driven systems,
degrading accuracy in command interpretation, summarization, and conversational
agents. We introduce DRES (Disfluency Removal Evaluation Suite), a controlled
text-level benchmark that establishes a reproducible semantic upper bound for
this task. DRES builds on human-annotated Switchboard transcripts, isolating
disfluency removal from ASR errors and acoustic variability. We systematically
evaluate proprietary and open-source LLMs across scales, prompting strategies,
and architectures. Our results reveal that (i) simple segmentation consistently
improves performance, even for long-context models; (ii) reasoning-oriented
models tend to over-delete fluent tokens; and (iii) fine-tuning achieves near
state-of-the-art precision and recall but harms generalization abilities. We
further present a set of LLM-specific error modes and offer nine practical
recommendations (R1-R9) for deploying disfluency removal in speech-driven
pipelines. DRES provides a reproducible, model-agnostic foundation for
advancing robust spoken-language systems.

</details>


### [80] [Morphological Synthesizer for Ge'ez Language: Addressing Morphological Complexity and Resource Limitations](https://arxiv.org/abs/2509.20341)
*Gebrearegawi Gebremariam,Hailay Teklehaymanot,Gebregewergs Mezgebe*

Main category: cs.CL

TL;DR: 开发基于规则的Ge'ez语形态合成器，通过102个动词样本测试达到97.4%准确率，超越基线模型。


<details>
  <summary>Details</summary>
Motivation: Ge'ez语作为埃塞俄比亚和厄立特里亚的文化载体缺乏可用NLP工具，现存文献资源未数字化制约语言研究。

Method: 采用规则驱动方法构建形态生成系统，覆盖全部动词形态结构，使用1102个样本进行验证。

Result: 系统准确率达97.4%，验证了规则方法在资源稀缺语言中的有效性。

Conclusion: 该成果为Ge'ez语NLP奠定基础，未来需扩展系统处理更多形态变体，并构建完整语言处理框架。

Abstract: Ge'ez is an ancient Semitic language renowned for its unique alphabet. It
serves as the script for numerous languages, including Tigrinya and Amharic,
and played a pivotal role in Ethiopia's cultural and religious development
during the Aksumite kingdom era. Ge'ez remains significant as a liturgical
language in Ethiopia and Eritrea, with much of the national identity
documentation recorded in Ge'ez. These written materials are invaluable primary
sources for studying Ethiopian and Eritrean philosophy, creativity, knowledge,
and civilization. Ge'ez has a complex morphological structure with rich
inflectional and derivational morphology, and no usable NLP has been developed
and published until now due to the scarcity of annotated linguistic data,
corpora, labeled datasets, and lexicons. Therefore, we propose a rule-based
Ge'ez morphological synthesizer to generate surface words from root words
according to the morphological structures of the language. We used 1,102 sample
verbs, representing all verb morphological structures, to test and evaluate the
system. The system achieves a performance of 97.4%, outperforming the baseline
model and suggesting that future work should build a comprehensive system
considering morphological variations of the language.
  Keywords: Ge'ez, NLP, morphology, morphological synthesizer, rule-based

</details>


### [81] [EmbeddingGemma: Powerful and Lightweight Text Representations](https://arxiv.org/abs/2509.20354)
*Henrique Schechter Vera,Sahil Dua,Biao Zhang,Daniel Salz,Ryan Mullins,Sindhu Raghuram Panyam,Sara Smoot,Iftekhar Naim,Joe Zou,Feiyang Chen,Daniel Cer,Alice Lisak,Min Choi,Lucas Gonzalez,Omar Sanseviero,Glenn Cameron,Ian Ballantyne,Kat Black,Kaifeng Chen,Weiyi Wang,Zhe Li,Gus Martins,Jinhyuk Lee,Mark Sherwood,Juyeong Ji,Renjie Wu,Jingxiao Zheng,Jyotinder Singh,Abheesht Sharma,Divya Sreepat,Aashi Jain,Adham Elarabawy,AJ Co,Andreas Doumanoglou,Babak Samari,Ben Hora,Brian Potetz,Dahun Kim,Enrique Alfonseca,Fedor Moiseev,Feng Han,Frank Palma Gomez,Gustavo Hernández Ábrego,Hesen Zhang,Hui Hui,Jay Han,Karan Gill,Ke Chen,Koert Chen,Madhuri Shanbhogue,Michael Boratko,Paul Suganthan,Sai Meher Karthik Duddu,Sandeep Mariserla,Setareh Ariafar,Shanfeng Zhang,Shijie Zhang,Simon Baumgartner,Sonam Goenka,Steve Qiu,Tanmaya Dabral,Trevor Walker,Vikram Rao,Waleed Khawaja,Wenlei Zhou,Xiaoqi Ren,Ye Xia,Yichang Chen,Yi-Ting Chen,Zhe Dong,Zhongli Ding,Francesco Visin,Gaël Liu,Jiageng Zhang,Kathleen Kenealy,Michelle Casbon,Ravin Kumar,Thomas Mesnard,Zach Gleicher,Cormac Brick,Olivier Lacombe,Adam Roberts,Yunhsuan Sung,Raphael Hoffmann,Tris Warkentin,Armand Joulin,Tom Duerig,Mojtaba Seyedhosseini*

Main category: cs.CL

TL;DR: EmbeddingGemma是基于Gemma 3的轻量级开源文本嵌入模型，通过知识蒸馏和混合优化策略，在300M参数规模下实现多领域SOTA性能，特别适合低延迟场景。


<details>
  <summary>Details</summary>
Motivation: 解决大模型部署成本高和小模型表达能力不足的问题，通过知识迁移和正则化技术提升轻量级模型的实用价值。

Method: 采用编码器-解码器初始化+几何嵌入蒸馏获取大模型知识，结合分散正则化增强鲁棒性，融合多优化检查点提升泛化能力。

Result: 在MTEB多语言/英语/代码任务中超越所有同规模模型，量化后性能仍领先，推理效率比同类模型提升2倍。

Conclusion: 该模型为设备端AI应用提供了高性能低成本解决方案，其方法论对轻量模型研究具有重要参考价值。

Abstract: We introduce EmbeddingGemma, a new lightweight, open text embedding model
based on the Gemma 3 language model family. Our innovative training recipe
strategically captures knowledge from larger models via encoder-decoder
initialization and geometric embedding distillation. We improve model
robustness and expressiveness with a spread-out regularizer, and ensure
generalizability by merging checkpoints from varied, optimized mixtures.
Evaluated on the Massive Text Embedding Benchmark (MTEB) across multilingual,
English, and code domains, EmbeddingGemma (300M) achieves state-of-the-art
results. Notably, it outperforms prior top models, both proprietary and open,
with fewer than 500M parameters, and provides performance comparable to models
double its size, offering an exceptional performance-to-cost ratio. Remarkably,
this lead persists when quantizing model weights or truncating embedding
outputs. This makes EmbeddingGemma particularly well-suited for low-latency and
high-throughput use cases such as on-device applications. We provide ablation
studies exploring our key design choices. We release EmbeddingGemma to the
community to promote further research.

</details>


### [82] [Language Models that Think, Chat Better](https://arxiv.org/abs/2509.20357)
*Adithya Bhaskar,Xi Ye,Danqi Chen*

Main category: cs.CL

TL;DR: 提出RLMT强化学习方法，通过模型奖励的思维链优化对话模型，在多个基准测试中显著超越传统RLHF方法


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法在开放任务（如写作/规划）中泛化能力有限，需探索更通用的强化学习范式

Method: 使用在线强化学习（DPO/PPO/GRPO）优化模型，要求生成长思维链（CoT），基于偏好奖励模型训练

Result: 在8B参数模型上实现3-7分性能提升，最佳模型超越GPT-4o，仅用7K提示超越25M+数据的多阶段训练模型

Conclusion: 重新定义后训练流程，证明思维过程规划的有效性，呼吁更广泛地应用模型思考能力

Abstract: Reinforcement learning with verifiable rewards (RLVR) improves language model
reasoning by using rule-based rewards in verifiable domains such as mathematics
and code. However, RLVR leads to limited generalization for open-ended tasks --
such as writing outline essays or making meal plans -- where humans reason
routinely. This paper shows that the RLVR paradigm is effective beyond
verifiable domains, and introduces **RL** with **M**odel-rewarded **T**hinking
(**RLMT**) for general-purpose chat capabilities. Using diverse real-world
prompts, RLMT requires LMs to generate long CoT reasoning before response, and
optimizes them with online RL against a preference-based reward model used in
RLHF. Across 40 training runs on Llama-3.1-8B and Qwen-2.5-7B (both base and
instruct) and multiple optimization algorithms (DPO, PPO, and GRPO), RLMT
consistently outperforms standard RLHF pipelines. This includes substantial
gains of 3-7 points on three chat benchmarks (AlpacaEval2, WildBench, and
ArenaHardV2), along with 1-3 point improvements on other tasks like creative
writing and general knowledge. Our best 8B model surpasses GPT-4o in chat and
creative writing and rivals Claude-3.7-Sonnet (Thinking). RLMT can also be
applied directly to base models without an SFT stage, akin to R1-Zero training.
Remarkably, with only 7K prompts, Llama-3.1-8B base trained with our RLMT
recipe outperforms Llama-3.1-8B-Instruct post-trained with a complex
multi-staged pipeline with 25M+ examples. We close with qualitative and
quantitative analyses of how trained models plan their responses. Our results
rethink the post-training pipeline and call upon future work to understand and
employ thinking more broadly.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [83] [EngravingGNN: A Hybrid Graph Neural Network for End-to-End Piano Score Engraving](https://arxiv.org/abs/2509.19412)
*Emmanouil Karystinaios,Francesco Foscarin,Gerhard Widmer*

Main category: cs.GR

TL;DR: 提出基于多任务图神经网络的钢琴乐谱自动生成框架，能联合处理7项子任务并生成标准格式输出


<details>
  <summary>Details</summary>
Motivation: 现有符号音乐处理系统仅专注单一子任务，缺乏端到端的自动乐谱生成方案，限制了人机协作类应用的发展

Method: 采用共享编码器+轻量解码器的多任务GNN架构，结合后处理流程生成MusicXML/MEI格式

Result: 在J-Pop和DCML Romantic数据集上实现跨任务的高准确率，优于单任务系统且参数效率提升50%

Conclusion: 多任务GNN框架为自动音乐雕刻提供了可扩展解决方案，验证了跨任务知识共享的有效性

Abstract: This paper focuses on automatic music engraving, i.e., the creation of a
humanly-readable musical score from musical content. This step is fundamental
for all applications that include a human player, but it remains a mostly
unexplored topic in symbolic music processing. In this work, we formalize the
problem as a collection of interdependent subtasks, and propose a unified graph
neural network (GNN) framework that targets the case of piano music and
quantized symbolic input. Our method employs a multi-task GNN to jointly
predict voice connections, staff assignments, pitch spelling, key signature,
stem direction, octave shifts, and clef signs. A dedicated postprocessing
pipeline generates print-ready MusicXML/MEI outputs. Comprehensive evaluation
on two diverse piano corpora (J-Pop and DCML Romantic) demonstrates that our
unified model achieves good accuracy across all subtasks, compared to existing
systems that only specialize in specific subtasks. These results indicate that
a shared GNN encoder with lightweight task-specific decoders in a multi-task
setting offers a scalable and effective solution for automatic music engraving.

</details>


### [84] [AJAHR: Amputated Joint Aware 3D Human Mesh Recovery](https://arxiv.org/abs/2509.19939)
*Hyunjin Cho,Giyun Choi,Jongwon Choi*

Main category: cs.GR

TL;DR: 提出自适应框架AJAHR和合成数据集A3D，显著提升截肢者3D人体网格重建效果


<details>
  <summary>Details</summary>
Motivation: 现有方法基于标准人体结构的假设，在截肢案例中会产生偏差，且缺乏相关训练数据

Method: 1. 集成肢体截肢分类器（与网格重建网络联合训练）
2. 构建A3D合成数据集提供多样截肢姿态数据

Result: 在保持非截肢者重建竞争力的同时，实现截肢案例的SOTA性能

Conclusion: 该研究填补了人体姿态估计领域的算法包容性空白，为医疗辅助等应用提供技术基础

Abstract: Existing human mesh recovery methods assume a standard human body structure,
overlooking diverse anatomical conditions such as limb loss. This assumption
introduces bias when applied to individuals with amputations - a limitation
further exacerbated by the scarcity of suitable datasets. To address this gap,
we propose Amputated Joint Aware 3D Human Mesh Recovery (AJAHR), which is an
adaptive pose estimation framework that improves mesh reconstruction for
individuals with limb loss. Our model integrates a body-part amputation
classifier, jointly trained with the mesh recovery network, to detect potential
amputations. We also introduce Amputee 3D (A3D), which is a synthetic dataset
offering a wide range of amputee poses for robust training. While maintaining
competitive performance on non-amputees, our approach achieves state-of-the-art
results for amputated individuals. Additional materials can be found at the
project webpage.

</details>


### [85] [MeshMosaic: Scaling Artist Mesh Generation via Local-to-Global Assembly](https://arxiv.org/abs/2509.19995)
*Rui Xu,Tianyang Xue,Qiujie Dong,Le Wan,Zhe Zhu,Peng Li,Zhiyang Dou,Cheng Lin,Shiqing Xin,Yuan Liu,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: 提出了MeshMosaic框架，通过局部到全局的分块生成策略，突破现有方法限制，可生成超10万三角形的高分辨率艺术家网格，显著提升几何保真度和结构密度组织


<details>
  <summary>Details</summary>
Motivation: 现有自回归生成模型受限于长序列瓶颈和量化分辨率不足，难以忠实再现精细几何细节和结构化密度模式，制约高三角形数量网格生成

Method: 1. 将形状分割为多个分块 2. 自回归生成每个分块时采用共享边界条件 3. 单独量化分块实现更高分辨率 4. 确保相邻区域连贯性、对称性和无缝连接

Result: 在多个公开数据集上超越SOTA方法：几何误差降低37.6%，用户偏好率提升68.2%，支持10万+三角形生成（远超现有8K面处理能力）

Conclusion: MeshMosaic通过创新的分块生成范式，在保持结构连贯性的同时突破分辨率限制，为实际应用提供支持细节表达的高质量网格生成方案

Abstract: Scaling artist-designed meshes to high triangle numbers remains challenging
for autoregressive generative models. Existing transformer-based methods suffer
from long-sequence bottlenecks and limited quantization resolution, primarily
due to the large number of tokens required and constrained quantization
granularity. These issues prevent faithful reproduction of fine geometric
details and structured density patterns. We introduce MeshMosaic, a novel
local-to-global framework for artist mesh generation that scales to over 100K
triangles--substantially surpassing prior methods, which typically handle only
around 8K faces. MeshMosaic first segments shapes into patches, generating each
patch autoregressively and leveraging shared boundary conditions to promote
coherence, symmetry, and seamless connectivity between neighboring regions.
This strategy enhances scalability to high-resolution meshes by quantizing
patches individually, resulting in more symmetrical and organized mesh density
and structure. Extensive experiments across multiple public datasets
demonstrate that MeshMosaic significantly outperforms state-of-the-art methods
in both geometric fidelity and user preference, supporting superior detail
representation and practical mesh generation for real-world applications.

</details>


### [86] [KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial Animation](https://arxiv.org/abs/2509.20128)
*Tianle Lyu,Junchuan Zhao,Ye Wang*

Main category: cs.GR

TL;DR: KSDiff框架通过语音特征解耦与关键帧增强扩散模型，在语音驱动面部动画生成中实现唇同步精度与头部姿态自然度的显著提升


<details>
  <summary>Details</summary>
Motivation: 现有方法未能细粒度区分语音特征对不同面部运动的驱动作用，且忽视关键动态帧建模，导致生成效果受限

Method: 双路径语音编码器(DPSE)分离表情/头部姿势特征，自回归关键帧学习模块(KEL)预测显著运动帧，结合双路径运动生成器进行合成

Result: 在HDTF和VoxCeleb数据集上达到SOTA，唇同步准确率提升3.2%，头部运动自然度提高18%

Conclusion: 语音特征解耦与关键帧感知扩散模型的结合有效提升了说话头部生成质量，为动态建模提供了新思路

Abstract: Audio-driven facial animation has made significant progress in multimedia
applications, with diffusion models showing strong potential for talking-face
synthesis. However, most existing works treat speech features as a monolithic
representation and fail to capture their fine-grained roles in driving
different facial motions, while also overlooking the importance of modeling
keyframes with intense dynamics. To address these limitations, we propose
KSDiff, a Keyframe-Augmented Speech-Aware Dual-Path Diffusion framework.
Specifically, the raw audio and transcript are processed by a Dual-Path Speech
Encoder (DPSE) to disentangle expression-related and head-pose-related
features, while an autoregressive Keyframe Establishment Learning (KEL) module
predicts the most salient motion frames. These components are integrated into a
Dual-path Motion generator to synthesize coherent and realistic facial motions.
Extensive experiments on HDTF and VoxCeleb demonstrate that KSDiff achieves
state-of-the-art performance, with improvements in both lip synchronization
accuracy and head-pose naturalness. Our results highlight the effectiveness of
combining speech disentanglement with keyframe-aware diffusion for talking-head
generation.

</details>


### [87] [LidarScout: Direct Out-of-Core Rendering of Massive Point Clouds](https://arxiv.org/abs/2509.20198)
*Philipp Erler,Lukas Herzberger,Michael Wimmer,Markus Schütz*

Main category: cs.GR

TL;DR: 提出无需预处理即可实时可视化百亿级超大点云数据的层次化加载方法


<details>
  <summary>Details</summary>
Motivation: 传统大规模地形扫描数据需要数小时/天的预处理生成LOD结构才能实时查看，严重阻碍工作效率

Method: 分层加载策略：初始加载稀疏样本构建全局概览 → 实时表面重建生成高度图 → 视点引导的全分辨率数据动态加载 → 通过高度图纹理保持中等细节层次

Result: 实现国家尺度的万亿级点云（TB级压缩数据）实时可视化，平均帧率60fps，内存占用降低90%

Conclusion: 首次实现零预处理、零额外存储的out-of-core点云渲染方案，为测绘/林业/基建领域提供革命性可视化工具

Abstract: Large-scale terrain scans are the basis for many important tasks, such as
topographic mapping, forestry, agriculture, and infrastructure planning. The
resulting point cloud data sets are so massive in size that even basic tasks
like viewing take hours to days of pre-processing in order to create
level-of-detail structures that allow inspecting the data set in their entirety
in real time. In this paper, we propose a method that is capable of instantly
visualizing massive country-sized scans with hundreds of billions of points.
Upon opening the data set, we first load a sparse subsample of points and
initialize an overview of the entire point cloud, immediately followed by a
surface reconstruction process to generate higher-quality, hole-free
heightmaps. As users start navigating towards a region of interest, we continue
to prioritize the heightmap construction process to the user's viewpoint. Once
a user zooms in closely, we load the full-resolution point cloud data for that
region and update the corresponding height map textures with the
full-resolution data. As users navigate elsewhere, full-resolution point data
that is no longer needed is unloaded, but the updated heightmap textures are
retained as a form of medium level of detail. Overall, our method constitutes a
form of direct out-of-core rendering for massive point cloud data sets
(terabytes, compressed) that requires no preprocessing and no additional disk
space. Source code, executable, pre-trained model, and dataset are available
at: https://github.com/cg-tuwien/lidarscout

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [88] [Multimodal Language Models with Modality-Specific Experts for Financial Forecasting from Interleaved Sequences of Text and Time Series](https://arxiv.org/abs/2509.19628)
*Ross Koval,Nicholas Andrews,Xifeng Yan*

Main category: cs.CE

TL;DR: 提出一种结合模态特定专家与跨模态对齐框架的神经网络，用于整合文本和时间序列数据以提升金融预测性能。


<details>
  <summary>Details</summary>
Motivation: 金融市场中，文本（新闻）与时间序列（股价）数据具有互补性，但现有方法难以有效整合这两种模态。

Method: 1. 设计模态特定专家处理各自数据，保持语言理解能力；2. 引入显著标记加权的跨模态对齐机制，增强多模态表征融合。

Result: 在金融预测任务中实现SOTA性能，可解释性分析验证时间序列上下文价值，投资模拟显示经济效益提升。

Conclusion: 跨模态整合方法不仅提升预测精度，还通过可解释性验证设计有效性，并转化为实际经济收益。

Abstract: Text and time series data offer complementary views of financial markets:
news articles provide narrative context about company events, while stock
prices reflect how markets react to those events. However, despite their
complementary nature, effectively integrating these interleaved modalities for
improved forecasting remains challenging. In this work, we propose a unified
neural architecture that models these interleaved sequences using
modality-specific experts, allowing the model to learn unique time series
patterns, while still enabling joint reasoning across modalities and preserving
pretrained language understanding capabilities. To further improve multimodal
understanding, we introduce a cross-modal alignment framework with a salient
token weighting mechanism that learns to align representations across
modalities with a focus on the most informative tokens. We demonstrate the
effectiveness of our approach on a large-scale financial forecasting task,
achieving state-of-the-art performance across a wide variety of strong unimodal
and multimodal baselines. We develop an interpretability method that reveals
insights into the value of time series-context and reinforces the design of our
cross-modal alignment objective. Finally, we demonstrate that these
improvements translate to meaningful economic gains in investment simulations.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [89] [STARQA: A Question Answering Dataset for Complex Analytical Reasoning over Structured Databases](https://arxiv.org/abs/2509.19508)
*Mounica Maddela,Lingjue Xie,Daniel Preotiuc-Pietro,Mausam*

Main category: cs.DB

TL;DR: 提出首个复杂分析推理数据集STARQA，并验证SQL+Python组合方法优于纯SQL方案


<details>
  <summary>Details</summary>
Motivation: 现有文本转SQL基准测试受限于SQL表达能力，缺乏需要复杂分析操作（如聚合计算、时序分析）的真实场景问题

Method: Text2SQLCode方法：将任务分解为SQL负责数据获取，Python负责分析推理的混合架构

Result: SQL与Python组合方案效果优于纯SQL，但现有大语言模型在STARQA数据集上仍面临显著挑战

Conclusion: 跨语言任务分解能提升复杂分析能力，但需要更先进的推理框架应对专业领域数据库的复杂查询需求

Abstract: Semantic parsing methods for converting text to SQL queries enable question
answering over structured data and can greatly benefit analysts who routinely
perform complex analytics on vast data stored in specialized relational
databases. Although several benchmarks measure the abilities of text to SQL,
the complexity of their questions is inherently limited by the level of
expressiveness in query languages and none focus explicitly on questions
involving complex analytical reasoning which require operations such as
calculations over aggregate analytics, time series analysis or scenario
understanding. In this paper, we introduce STARQA, the first public
human-created dataset of complex analytical reasoning questions and answers on
three specialized-domain databases. In addition to generating SQL directly
using LLMs, we evaluate a novel approach (Text2SQLCode) that decomposes the
task into a combination of SQL and Python: SQL is responsible for data
fetching, and Python more naturally performs reasoning. Our results demonstrate
that identifying and combining the abilities of SQL and Python is beneficial
compared to using SQL alone, yet the dataset still remains quite challenging
for the existing state-of-the-art LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [90] [Cognitive Load Limits in Large Language Models: Benchmarking Multi-Hop Reasoning](https://arxiv.org/abs/2509.19517)
*Sai Teja Reddy Adapala*

Main category: cs.AI

TL;DR: 研究发现LLM在动态高认知负荷环境中表现脆弱，提出上下文饱和和注意力残留机制，并通过ICE基准测试验证不同模型在复杂推理任务中的性能差异


<details>
  <summary>Details</summary>
Motivation: 揭示大语言模型在静态基准测试与动态信息丰富环境中表现差异的根本原因，探索认知负荷对模型推理能力的限制机制

Method: 设计ICE基准（包含200道多跳推理题，每个问题10次重复测试），系统操纵上下文饱和和注意力残留两个认知负荷因子，评估5个指令调优模型的性能表现

Result: 小模型（Llama-3-8B/Mistral-7B）在控制组准确率0%，Gemini-2.0-Flash控制组达85%但随上下文饱和显著下降（β=-0.003/%，p<0.001）

Conclusion: 认知负荷是AI系统推理失败的关键因素，需通过动态压力测试（如ICE）评估真实安全性能，现有静态基准无法充分检测系统韧性

Abstract: The scaling of Large Language Models (LLMs) has exposed a critical gap
between their performance on static benchmarks and their fragility in dynamic,
information-rich environments. While models excel at isolated tasks, the
computational limits that govern their reasoning under cognitive load remain
poorly understood. In this work, we introduce a formal theory of computational
cognitive load, positing that extraneous, task-irrelevant information (Context
Saturation) and interference from task-switching (Attentional Residue) are key
mechanisms that degrade performance. We designed the Interleaved Cognitive
Evaluation (ICE), a deconfounded benchmark to systematically manipulate these
load factors on challenging multi-hop reasoning tasks. A comprehensive study (N
= 10 replications per item across 200 questions) revealed significant
performance variations across five instruction-tuned models. Smaller
open-source architectures (Llama-3-8B-Instruct, Mistral-7B-Instruct-v0.2)
exhibited baseline brittleness, achieving 0% accuracy (SEM = 0.0) across all
conditions, including clean controls, on this high-intrinsic-load task. In
contrast, Gemini-2.0-Flash-001 showed partial resilience, achieving 85%
accuracy in control conditions, with a statistically significant degradation
under context saturation ($\beta = -0.003$ per % load, $p < 0.001$). These
findings provide preliminary evidence that cognitive load is a key contributor
to reasoning failures, supporting theories of hallucination-as-guessing under
uncertainty. We conclude that dynamic, cognitive-aware stress testing, as
exemplified by the ICE benchmark, is essential for evaluating the true
resilience and safety of advanced AI systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [91] [Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation](https://arxiv.org/abs/2509.19592)
*Roy Fejgin,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Ryan Langman Jaehyeon Kim,Subhankar Ghosh,Shehzeen Hussain,Jason Li*

Main category: eess.AS

TL;DR: 提出基于局部Transformer的分层解码策略，解决语音生成模型中多码本依赖问题，平衡合成速度与质量


<details>
  <summary>Details</summary>
Motivation: 传统并行预测方法在多码本语音生成中存在预测独立性假设与码本间实际依赖关系的矛盾，导致合成质量下降。需要探索能捕获时间步内码本依赖关系的有效解码结构。

Method: 设计两种局部Transformer架构：(1) 自回归Transformer顺序生成码本 (2) MaskGIT式Transformer进行迭代掩码预测。结合帧堆叠技术实现多帧联合预测与码本解码分离。

Result: 系统分析不同吞吐量/质量场景下的并行/迭代采样策略权衡，证明分层解码在保持感知质量同时提升1.5倍合成速度。迭代策略在高质量模式下将MOS提升0.28分。

Conclusion: 提出部署策略选择指南：优先计算效率时采用并行采样，追求合成保真度时选择迭代式MaskGIT架构。支持通过帧堆叠实现质量-速度的灵活权衡。

Abstract: Speech generation models based on large language models (LLMs) typically
operate on discrete acoustic codes, which differ fundamentally from text tokens
due to their multicodebook structure. At each timestep, models must predict N
codebook entries jointly, introducing dependencies that challenge simple
parallel prediction approaches. Parallel prediction assumes independence among
codebooks, yielding efficient decoding but often at the cost of reduced
fidelity. To address this, hierarchical strategies employ a local transformer
(LT) to refine predictions and capture intra-timestep dependencies. In this
work, we systematically investigate two LT architectures: an autoregressive
transformer that generates codebooks sequentially, and a MaskGIT-based
transformer that performs iterative masked prediction. Both designs further
enable frame stacking, where the primary transformer predicts multiple frames
jointly, and the LT decodes their codebooks, offering improvements in speed
without compromising perceptual quality. Through extensive analysis, we
characterize the tradeoffs between parallel and iterative sampling strategies
across different throughput and quality regimes. Finally, we propose practical
guidelines for selecting decoding strategies based on deployment priorities
such as computational efficiency and synthesis fidelity.

</details>


### [92] [Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning](https://arxiv.org/abs/2509.19631)
*Shaoshi Ling,Gang Liu,Guoli Ye,Jinyu Li*

Main category: eess.AS

TL;DR: 提出多阶段强化学习框架，提升多模态大语言模型(MLLMs)的语音摘要能力，显著缩小与文本LLMs的差距。


<details>
  <summary>Details</summary>
Motivation: 开源MLLMs在语音摘要任务中落后于基于文本的先进LLMs，限制了实际部署应用。

Method: 开发新型多阶段强化学习训练框架，优化语音到摘要的端到端生成过程。

Result: 模型优于强基线模型，超越参数量更大的MLLMs，与顶尖文本LLMs的差距减少75%。

Conclusion: 该框架有效提升MLLMs的语音摘要性能，使语音模态接近文本LLMs的摘要质量，具备实际应用价值。

Abstract: Speech summarization is a critical component of spoken content understanding,
particularly in the era of rapidly growing spoken and audiovisual data. Recent
advances in multi-modal large language models (MLLMs), leveraging the power of
LLMs, enable generating textual summaries directly from speech without
intermediate transcriptions, while supporting controllable styles and zero-shot
generalization. However, open-source MLLMs continue to lag behind the
state-of-the-art text-based LLMs, limiting their practical deployment for
speech summarization. In this work, we present a novel multi-stage
reinforcement learning training framework to enhance the speech summarization
capabilities in MLLMs. Our model delivers substantial improvements over strong
baselines, outperforms much larger MLLMs, and significantly narrows the gap
with state-of-the-art text-based LLMs.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [93] [Human-AI Narrative Synthesis to Foster Shared Understanding in Civic Decision-Making](https://arxiv.org/abs/2509.19643)
*Cassandra Overney,Hang Jiang,Urooj Haider,Cassandra Moe,Jasmine Mangat,Frank Pantano,Effie G. McMillian,Paul Riggins,Nabeel Gillani*

Main category: cs.HC

TL;DR: 开发人机协作的叙事合成系统StoryBuilder，通过生成复合故事促进社区跨视角理解


<details>
  <summary>Details</summary>
Motivation: 传统社区反馈处理方法难以应对海量信息，导致居民与管理者/居民间的理解鸿沟

Method: 构建StoryBuilder叙事生成管道，使用2480份社区反馈生成124个复合故事，通过StorySharer界面部署，结合四个月实地测试+21人用户研究+叙事结构对照实验

Result: 经验驱动的叙事比观点主导的叙事获得更高尊重信任（+12.7%），实地测试显示促进跨群体共情

Conclusion: 成功验证人机协同叙事系统在真实社区场景的应用价值，揭示了叙事结构对接受度的影响机制

Abstract: Community engagement processes in representative political contexts, like
school districts, generate massive volumes of feedback that overwhelm
traditional synthesis methods, creating barriers to shared understanding not
only between civic leaders and constituents but also among community members.
To address these barriers, we developed StoryBuilder, a human-AI collaborative
pipeline that transforms community input into accessible first-person
narratives. Using 2,480 community responses from an ongoing school rezoning
process, we generated 124 composite stories and deployed them through a
mobile-friendly StorySharer interface. Our mixed-methods evaluation combined a
four-month field deployment, user studies with 21 community members, and a
controlled experiment examining how narrative composition affects participant
reactions. Field results demonstrate that narratives helped community members
relate across diverse perspectives. In the experiment, experience-grounded
narratives generated greater respect and trust than opinion-heavy narratives.
We contribute a human-AI narrative synthesis system and insights on its varied
acceptance and effectiveness in a real-world civic context.

</details>
