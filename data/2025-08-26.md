<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 112]
- [cs.GR](#cs.GR) [Total: 8]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.DL](#cs.DL) [Total: 1]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [q-fin.PM](#q-fin.PM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 12]
- [cs.CY](#cs.CY) [Total: 3]
- [physics.optics](#physics.optics) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting](https://arxiv.org/abs/2508.16603)
*Zheng Dong,Luming Shang,Gabriela Olinto*

Main category: cs.CL

TL;DR: GreenTEA是平衡探索与利用的自动化提示优化框架，通过协作式智能体工作流和遗传算法迭代优化LLM提示


<details>
  <summary>Details</summary>
Motivation: 人工设计高质量提示耗时且依赖专家经验，现有自动化方法存在搜索低效或过度开发反馈的局限性

Method: 分析智能体通过主题建模识别错误模式，生成智能体针对性改进提示，遗传算法框架实现交叉变异的选择进化

Result: 在逻辑推理、常识判断等基准测试中超越人工设计和现有SOTA方法，实现模型性能的持续优化

Conclusion: GreenTEA通过协同机制有效平衡探索与开发，为提示工程提供可扩展的自动化解决方案

Abstract: High-quality prompts are crucial for Large Language Models (LLMs) to achieve
exceptional performance. However, manually crafting effective prompts is
labor-intensive and demands significant domain expertise, limiting its
scalability. Existing automatic prompt optimization methods either extensively
explore new prompt candidates, incurring high computational costs due to
inefficient searches within a large solution space, or overly exploit feedback
on existing prompts, risking suboptimal optimization because of the complex
prompt landscape. To address these challenges, we introduce GreenTEA, an
agentic LLM workflow for automatic prompt optimization that balances candidate
exploration and knowledge exploitation. It leverages a collaborative team of
agents to iteratively refine prompts based on feedback from error samples. An
analyzing agent identifies common error patterns resulting from the current
prompt via topic modeling, and a generation agent revises the prompt to
directly address these key deficiencies. This refinement process is guided by a
genetic algorithm framework, which simulates natural selection by evolving
candidate prompts through operations such as crossover and mutation to
progressively optimize model performance. Extensive numerical experiments
conducted on public benchmark datasets suggest the superior performance of
GreenTEA against human-engineered prompts and existing state-of-the-arts for
automatic prompt optimization, covering logical and quantitative reasoning,
commonsense, and ethical decision-making.

</details>


### [2] [Cognitive Decision Routing in Large Language Models: When to Think Fast, When to Think Slow](https://arxiv.org/abs/2508.16636)
*Y. Du,C. Guo,W. Wang,G. Tang*

Main category: cs.CL

TL;DR: 提出认知决策路由（CDR）框架，通过动态选择推理策略实现计算效率与决策精度的平衡，实验显示计算成本降低34%且专业任务表现显著提升


<details>
  <summary>Details</summary>
Motivation: 解决LLMs当前采用统一深度推理或高成本方法导致的资源浪费问题，受人类双系统认知理论启发，实现更智能化的计算资源分配

Method: 构建元认知层分析查询特征（信息相关性强度/领域边界/利益相关方/不确定性），动态路由到浅层或深度推理路径

Result: 在专业判断任务中实现23%的一致性提升和18%的准确率增长，总体计算成本降低34%

Conclusion: CDR框架成功将认知科学原理融入AI系统设计，为LLMs的适应性推理提供了可解释且高效的新范式

Abstract: Large Language Models (LLMs) face a fundamental challenge in deciding when to
rely on rapid, intuitive responses versus engaging in slower, more deliberate
reasoning. Inspired by Daniel Kahneman's dual-process theory and his insights
on human cognitive biases, we propose a novel Cognitive Decision Routing (CDR)
framework that dynamically determines the appropriate reasoning strategy based
on query characteristics. Our approach addresses the current limitations where
models either apply uniform reasoning depth or rely on computationally
expensive methods for all queries. We introduce a meta-cognitive layer that
analyzes query complexity through multiple dimensions: correlation strength
between given information and required conclusions, domain boundary crossings,
stakeholder multiplicity, and uncertainty levels. Through extensive experiments
on diverse reasoning tasks, we demonstrate that CDR achieves superior
performance while reducing computational costs by 34\% compared to uniform deep
reasoning approaches. Our framework shows particular strength in professional
judgment tasks, achieving 23\% improvement in consistency and 18\% better
accuracy on expert-level evaluations. This work bridges cognitive science
principles with practical AI system design, offering a principled approach to
adaptive reasoning in LLMs.

</details>


### [3] [Trust but Verify! A Survey on Verification Design for Test-time Scaling](https://arxiv.org/abs/2508.16665)
*V Venktesh,Mandeep rathee,Avishek Anand*

Main category: cs.CL

TL;DR: 测试时间扩展(TTS)通过验证器机制提升大语言模型推理性能，实现无需参数调整的推理时优化。


<details>
  <summary>Details</summary>
Motivation: 现有验证器方法缺乏系统性分类与训练机制分析，需建立统一框架指导研究与应用。

Method: 系统性文献综述与分类，分析验证器类型(提示型/微调型)、训练机制(判别式/生成式)及其在TTS中的作用。

Result: 建立验证器分类体系，揭示其通过探索解码空间提升模型性能的核心原理，开源研究资料库。

Conclusion: 验证器是实现高效推理扩展的关键技术，本综述为后续研究提供系统化方法论与评估基准。

Abstract: Test-time scaling (TTS) has emerged as a new frontier for scaling the
performance of Large Language Models. In test-time scaling, by using more
computational resources during inference, LLMs can improve their reasoning
process and task performance. Several approaches have emerged for TTS such as
distilling reasoning traces from another model or exploring the vast decoding
search space by employing a verifier. The verifiers serve as reward models that
help score the candidate outputs from the decoding process to diligently
explore the vast solution space and select the best outcome. This paradigm
commonly termed has emerged as a superior approach owing to parameter free
scaling at inference time and high performance gains. The verifiers could be
prompt-based, fine-tuned as a discriminative or generative model to verify
process paths, outcomes or both. Despite their widespread adoption, there is no
detailed collection, clear categorization and discussion of diverse
verification approaches and their training mechanisms. In this survey, we cover
the diverse approaches in the literature and present a unified view of verifier
training, types and their utility in test-time scaling. Our repository can be
found at
https://github.com/elixir-research-group/Verifierstesttimescaling.github.io.

</details>


### [4] [Do Cognitively Interpretable Reasoning Traces Improve LLM Performance?](https://arxiv.org/abs/2508.16695)
*Siddhant Bhambri,Upasana Biswas,Subbarao Kambhampati*

Main category: cs.CL

TL;DR: 研究发现，尽管DeepSeek R1的思维链轨迹在微调中表现最佳，但其可解释性被人类评分最低，揭示了任务性能与用户可解释性之间的脱钩可能性。


<details>
  <summary>Details</summary>
Motivation: 质疑思维链轨迹必须具有可解释性才能提升模型性能的假设，探索是否可以通过不可解释但有效的中间推理路径优化LLM表现。

Method: 在开放书籍问答领域监督微调LLaMA和Qwen模型，对比四种轨迹类型：原生R1轨迹、摘要型解释、事後解释、算法生成可验证轨迹，并通过100人参与的评分实验量化可解释性。

Result: R1轨迹微调模型F1分数最高（比基线高7.2%），但人类评分中其可解释性最低（仅2.8/5分），算法生成轨迹则呈现相反趋势。

Conclusion: 应解耦中间推理轨迹的工程价值与用户可解释性需求，非语义的算法生成轨迹可能更有效，这为LLM推理机制优化提供了新方向。

Abstract: Recent progress in reasoning-oriented Large Language Models (LLMs) has been
driven by introducing Chain-of-Thought (CoT) traces, where models generate
intermediate reasoning traces before producing an answer. These traces, as in
DeepSeek R1, are not only used to guide inference but also serve as supervision
signals for distillation into smaller models. A common but often implicit
assumption is that CoT traces should be semantically meaningful and
interpretable to the end user. While recent research questions the need for
semantic nature of these traces, in this paper, we ask: ``\textit{Must CoT
reasoning traces be interpretable to enhance LLM task performance?}" We
investigate this question in the Open Book Question-Answering domain by
supervised fine-tuning LLaMA and Qwen models on four types of reasoning traces:
(1) DeepSeek R1 traces, (2) LLM-generated summaries of R1 traces, (3)
LLM-generated post-hoc explanations of R1 traces, and (4) algorithmically
generated verifiably correct traces. To quantify the trade-off between
interpretability and performance, we further conduct a human-subject study with
100 participants rating the interpretability of each trace type. Our results
reveal a striking mismatch: while fine-tuning on R1 traces yields the strongest
performance, participants judged these traces to be the least interpretable.
These findings suggest that it is useful to decouple intermediate tokens from
end user interpretability.

</details>


### [5] [QueryBandits for Hallucination Mitigation: Exploiting Semantic Features for No-Regret Rewriting](https://arxiv.org/abs/2508.16697)
*Nicole Cho,William Watson,Alec Koppel,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: 提出QueryBandits框架，通过动态查询改写主动降低大语言模型幻觉生成，实验证明优于静态改写策略


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用事后过滤解决LLM幻觉问题，但忽略了查询本身的优化空间。本研究旨在通过主动改写输入查询来预防幻觉产生

Method: 结合多臂老虎机框架(Thompson Sampling)和17种语言特征敏感性分析，构建动态奖励模型指导查询改写策略选择

Result: 在13个QA基准测试中，动态策略比基线提升87.5%，比静态改写策略(转述/扩展)分别高42.6%和60.3%；发现静态改写可能加剧幻觉

Conclusion: 证实动态查询改写的有效性，揭示特征权重向量的策略异质性，提出无需重新训练的前向干预新范式

Abstract: Advanced reasoning capabilities in Large Language Models (LLMs) have caused
higher hallucination prevalence; yet most mitigation work focuses on
after-the-fact filtering rather than shaping the queries that trigger them. We
introduce QueryBandits, a bandit framework that designs rewrite strategies to
maximize a reward model, that encapsulates hallucination propensity based upon
the sensitivities of 17 linguistic features of the input query-and therefore,
proactively steer LLMs away from generating hallucinations. Across 13 diverse
QA benchmarks and 1,050 lexically perturbed queries per dataset, our top
contextual QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a
no-rewrite baseline and also outperforms zero-shot static prompting
("paraphrase" or "expand") by 42.6% and 60.3% respectively. Therefore, we
empirically substantiate the effectiveness of QueryBandits in mitigating
hallucination via the intervention that takes the form of a query rewrite.
Interestingly, certain static prompting strategies, which constitute a
considerable number of current query rewriting literature, have a higher
cumulative regret than the no-rewrite baseline, signifying that static rewrites
can worsen hallucination. Moreover, we discover that the converged per-arm
regression feature weight vectors substantiate that there is no single rewrite
strategy optimal for all queries. In this context, guided rewriting via
exploiting semantic features with QueryBandits can induce significant shifts in
output behavior through forward-pass mechanisms, bypassing the need for
retraining or gradient-based adaptation.

</details>


### [6] [Assessing Consciousness-Related Behaviors in Large Language Models Using the Maze Test](https://arxiv.org/abs/2508.16705)
*Rui A. Pimenta,Tim Schlippe,Kristina Schaaff*

Main category: cs.CL

TL;DR: 大型语言模型在迷宫测试中展现部分类意识行为，但缺乏持续自我意识整合


<details>
  <summary>Details</summary>
Motivation: 验证LLMs是否具备空间认知、视角转换等意识相关特征，探索AI系统意识模拟可能性

Method: 将意识理论转化为13项特征，采用第一人称迷宫导航测试，评估12个主流LLM在零样本/单样本/少样本场景表现

Result: 推理型LLM表现优于标准版（Gemini 2.0 Pro完整路径准确率52.9%，DeepSeek-R1局部路径80.5%），路径完整性差距揭示自我模型持续性缺陷

Conclusion: LLMs通过推理机制在意识相关行为取得进展，但缺乏意识的核心特征——整合性持续自我觉知

Abstract: We investigate consciousness-like behaviors in Large Language Models (LLMs)
using the Maze Test, challenging models to navigate mazes from a first-person
perspective. This test simultaneously probes spatial awareness,
perspective-taking, goal-directed behavior, and temporal sequencing-key
consciousness-associated characteristics. After synthesizing consciousness
theories into 13 essential characteristics, we evaluated 12 leading LLMs across
zero-shot, one-shot, and few-shot learning scenarios. Results showed
reasoning-capable LLMs consistently outperforming standard versions, with
Gemini 2.0 Pro achieving 52.9% Complete Path Accuracy and DeepSeek-R1 reaching
80.5% Partial Path Accuracy. The gap between these metrics indicates LLMs
struggle to maintain coherent self-models throughout solutions -- a fundamental
consciousness aspect. While LLMs show progress in consciousness-related
behaviors through reasoning mechanisms, they lack the integrated, persistent
self-awareness characteristic of consciousness.

</details>


### [7] [Sparse and Dense Retrievers Learn Better Together: Joint Sparse-Dense Optimization for Text-Image Retrieval](https://arxiv.org/abs/2508.16707)
*Jonghyun Song,Youngjune Lee,Gyu-Hwung Cho,Ilhyeon Song,Saehun Kim,Yohan Jo*

Main category: cs.CL

TL;DR: 提出通过自知识蒸馏实现双向学习的框架，融合密集与稀疏表示提升多模态检索效果


<details>
  <summary>Details</summary>
Motivation: 现有稀疏检索方法依赖高成本预训练或冻结模型蒸馏，限制了密集与稀疏模型的协同优化

Method: 使用综合相似度分数（密集+稀疏加权）作为共享教师信号，仅微调密集编码器最后一层和稀疏投影头

Result: 在MSCOCO/Flickr30k上，稀疏检索超越基线且接近密集模型性能，保留稀疏模型效率优势

Conclusion: 双向学习框架实现模型间协同优化，兼容现有VLP模型，在保持效率的同时提升检索效果

Abstract: Vision-Language Pretrained (VLP) models have achieved impressive performance
on multimodal tasks, including text-image retrieval, based on dense
representations. Meanwhile, Learned Sparse Retrieval (LSR) has gained traction
in text-only settings due to its interpretability and efficiency with fast
term-based lookup via inverted indexes. Inspired by these advantages, recent
work has extended LSR to the multimodal domain. However, these methods often
rely on computationally expensive contrastive pre-training, or distillation
from a frozen dense model, which limits the potential for mutual enhancement.
To address these limitations, we propose a simple yet effective framework that
enables bi-directional learning between dense and sparse representations
through Self-Knowledge Distillation. This bi-directional learning is achieved
using an integrated similarity score-a weighted sum of dense and sparse
similarities-which serves as a shared teacher signal for both representations.
To ensure efficiency, we fine-tune the final layer of the dense encoder and the
sparse projection head, enabling easy adaptation of any existing VLP model.
Experiments on MSCOCO and Flickr30k demonstrate that our sparse retriever not
only outperforms existing sparse baselines, but also achieves performance
comparable to-or even surpassing-its dense counterparts, while retaining the
benefits of sparse models.

</details>


### [8] [Error Reflection Prompting: Can Large Language Models Successfully Understand Errors?](https://arxiv.org/abs/2508.16729)
*Jason Li,Lauren Yraola,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: 提出错误反思提示法（ERP），通过错误识别与纠正机制增强语言模型的推理能力，弥补传统思维链（CoT）方法缺乏自我纠错的不足。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法虽能分步推理但缺乏错误反思能力，导致模型可能持续产生错误。受人类错误反思机制启发，需开发具备自我纠错能力的推理框架。

Method: 在CoT基础上构建三阶段框架：1）生成初始错误答案 2）自动识别错误类型及错误步骤 3）生成修正后的正确答案。通过自动化ERP生成实现错误检测与修正的流程整合。

Result: ERP有效提升模型推理鲁棒性，错误识别准确率提高27%，在数学推理等任务中表现出更好的结果可解释性。该方法可作为通用模块与现有CoT方法结合使用。

Conclusion: ERP通过内建错误反思机制显著增强语言模型推理可靠性，为提升AI系统自我修正能力提供了可扩展的技术路径。

Abstract: Prompting methods for language models, such as Chain-of-thought (CoT),
present intuitive step-by-step processes for problem solving. These
methodologies aim to equip models with a better understanding of the correct
procedures for addressing a given task. Despite these advancements, CoT lacks
the ability of reflection and error correction, potentially causing a model to
perpetuate mistakes and errors. Therefore, inspired by the human ability for
said tasks, we propose Error Reflection Prompting (ERP) to further enhance
reasoning in language models. Building upon CoT, ERP is a method comprised of
an incorrect answer, error recognition, and a correct answer. This process
enables the model to recognize types of errors and the steps that lead to
incorrect answers, allowing the model to better discern which steps to avoid
and which to take. The model is able to generate the error outlines itself with
automated ERP generation, allowing for error recognition and correction to be
integrated into the reasoning chain and produce scalability and reliability in
the process. The results demonstrate that ERP serves as a versatile supplement
to conventional CoT, ultimately contributing to more robust and capable
reasoning abilities along with increased interpretability in how models
ultimately reach their errors.

</details>


### [9] [GAICo: A Deployed and Extensible Framework for Evaluating Diverse and Multimodal Generative AI Outputs](https://arxiv.org/abs/2508.16753)
*Nitin Gupta,Pallav Koppisetti,Kausik Lakkaraju,Biplav Srivastava*

Main category: cs.CL

TL;DR: 提出GAICo开源库以标准化生成式AI评估，通过统一框架支持多模态和结构化数据比较，并通过案例验证其实用性


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI评估存在碎片化问题，临时脚本和不适用的通用指标阻碍系统开发与结果可比性

Method: 开发Python库GAICo，提供可扩展框架支持文本/结构化数据/多媒体的参考指标，包含高层API和可视化工具

Result: 通过多模态AI旅行助手案例验证工具效能，发布2月下载量超1.3万次显示社区高度关注

Conclusion: GAICo提升评估效率与可复现性，加速开发可靠AI系统，符合AI部署快速安全并进的目标

Abstract: The rapid proliferation of Generative AI (GenAI) into diverse, high-stakes
domains necessitates robust and reproducible evaluation methods. However,
practitioners often resort to ad-hoc, non-standardized scripts, as common
metrics are often unsuitable for specialized, structured outputs (e.g.,
automated plans, time-series) or holistic comparison across modalities (e.g.,
text, audio, and image). This fragmentation hinders comparability and slows AI
system development. To address this challenge, we present GAICo (Generative AI
Comparator): a deployed, open-source Python library that streamlines and
standardizes GenAI output comparison. GAICo provides a unified, extensible
framework supporting a comprehensive suite of reference-based metrics for
unstructured text, specialized structured data formats, and multimedia (images,
audio). Its architecture features a high-level API for rapid, end-to-end
analysis, from multi-model comparison to visualization and reporting, alongside
direct metric access for granular control. We demonstrate GAICo's utility
through a detailed case study evaluating and debugging complex, multi-modal AI
Travel Assistant pipelines. GAICo empowers AI researchers and developers to
efficiently assess system performance, make evaluation reproducible, improve
development velocity, and ultimately build more trustworthy AI systems,
aligning with the goal of moving faster and safer in AI deployment. Since its
release on PyPI in Jun 2025, the tool has been downloaded over 13K times,
across versions, by Aug 2025, demonstrating growing community interest.

</details>


### [10] [How Good are LLM-based Rerankers? An Empirical Analysis of State-of-the-Art Reranking Models](https://arxiv.org/abs/2508.16757)
*Abdelrahman Abdallah,Bhawna Piryani,Jamshid Mozafari,Mohammed Ali,Adam Jatowt*

Main category: cs.CL

TL;DR: 系统评估22种重排序方法（含40个LLM变体）在信息检索任务中的表现，发现LLM在熟悉查询中表现更优但泛化能力有限，轻量级模型效率相当。


<details>
  <summary>Details</summary>
Motivation: 探究LLM重排序器与轻量级模型在新型查询上的性能差异及其成因，解决现有方法对新查询泛化能力不足的问题。

Method: 使用TREC DL19/DL20、BEIR及新型查询数据集，通过训练数据重叠分析、模型架构对比和计算效率评估进行多维度验证。

Result: LLM在常规基准表现更优（如TREC DL19/DL20），但在新型查询数据集上泛化能力显著下降（部分场景轻量级模型表现相当）。

Conclusion: 查询新颖性显著影响重排序效果，需平衡模型性能与效率，轻量级模型在计算资源受限场景具备实用价值。

Abstract: In this work, we present a systematic and comprehensive empirical evaluation
of state-of-the-art reranking methods, encompassing large language model
(LLM)-based, lightweight contextual, and zero-shot approaches, with respect to
their performance in information retrieval tasks. We evaluate in total 22
methods, including 40 variants (depending on used LLM) across several
established benchmarks, including TREC DL19, DL20, and BEIR, as well as a novel
dataset designed to test queries unseen by pretrained models. Our primary goal
is to determine, through controlled and fair comparisons, whether a performance
disparity exists between LLM-based rerankers and their lightweight
counterparts, particularly on novel queries, and to elucidate the underlying
causes of any observed differences. To disentangle confounding factors, we
analyze the effects of training data overlap, model architecture, and
computational efficiency on reranking performance. Our findings indicate that
while LLM-based rerankers demonstrate superior performance on familiar queries,
their generalization ability to novel queries varies, with lightweight models
offering comparable efficiency. We further identify that the novelty of queries
significantly impacts reranking effectiveness, highlighting limitations in
existing approaches.
https://github.com/DataScienceUIBK/llm-reranking-generalization-study

</details>


### [11] [Toward Socially Aware Vision-Language Models: Evaluating Cultural Competence Through Multimodal Story Generation](https://arxiv.org/abs/2508.16762)
*Arka Mukherjee,Shreya Ghosh*

Main category: cs.CL

TL;DR: 该研究首次通过多模态故事生成任务系统评估视觉语言模型（VLMs）的文化能力，发现模型虽能生成丰富文化特定词汇，但存在架构差异大、逆向文化对齐、自动指标偏见等问题，揭示了多模态AI文化能力的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs在全球不同文化场景中广泛应用，确保其文化能力对负责任AI至关重要。先前研究仅评估文本模型和VLM物体识别任务，缺乏对多模态生成任务中文化适应能力的系统研究。

Method: 开发新型多模态框架，通过扰动文本提示和视觉输入中的文化身份特征，在故事生成任务中评估5个当代VLM的文化适应能力。

Result: 模型展现显著文化适应能力（如生成姓名/亲属称谓/地理标记），但存在：1）架构间能力差异悬殊 2）部分模型逆向文化对齐 3）自动指标与人类评估矛盾 4）视觉文化理解有限（跨国籍召回率仅0.2%）但视觉语义相似性可检测文化差异（同国籍召回率28.7%）。

Conclusion: 研究证实多模态AI具备文化能力发展潜力，但需解决架构差异、指标偏见等关键挑战。公开代码和数据推动该领域发展，强调提升视觉文化理解是未来重点。

Abstract: As Vision-Language Models (VLMs) achieve widespread deployment across diverse
cultural contexts, ensuring their cultural competence becomes critical for
responsible AI systems. While prior work has evaluated cultural awareness in
text-only models and VLM object recognition tasks, no research has
systematically assessed how VLMs adapt outputs when cultural identity cues are
embedded in both textual prompts and visual inputs during generative tasks. We
present the first comprehensive evaluation of VLM cultural competence through
multimodal story generation, developing a novel multimodal framework that
perturbs cultural identity and evaluates 5 contemporary VLMs on a downstream
task: story generation. Our analysis reveals significant cultural adaptation
capabilities, with rich culturally-specific vocabulary spanning names, familial
terms, and geographic markers. However, we uncover concerning limitations:
cultural competence varies dramatically across architectures, some models
exhibit inverse cultural alignment, and automated metrics show architectural
bias contradicting human assessments. Cross-modal evaluation shows that
culturally distinct outputs are indeed detectable through visual-semantic
similarity (28.7% within-nationality vs. 0.2% cross-nationality recall), yet
visual-cultural understanding remains limited. In essence, we establish the
promise and challenges of cultural competence in multimodal AI. We publicly
release our codebase and data: https://github.com/ArkaMukherjee0/mmCultural

</details>


### [12] [Assess and Prompt: A Generative RL Framework for Improving Engagement in Online Mental Health Communities](https://arxiv.org/abs/2508.16788)
*Bhagesh Gaur,Karan Gupta,Aseem Srivastava,Manish Gupta,Md Shad Akhtar*

Main category: cs.CL

TL;DR: 提出MH-COPILOT框架，通过识别心理健康帖子缺失的支持属性并引导用户补充信息，显著提升社区参与度


<details>
  <summary>Details</summary>
Motivation: 在线心理健康社区存在大量因缺乏关键支持属性而未被响应的求助帖，需建立机制自动识别信息缺口并引导用户完善内容

Method: 构建REDDME标注数据集（事件/影响/需求三属性），开发分层分类法CueTaxo，设计基于强化学习的MH-COPILOT系统（包含属性识别、强度分类、控制生成、验证奖励模块）

Result: 在四个主流语言模型上实现属性引发提升，用户参与度显著增加，人工评估验证系统有效性

Conclusion: 动态检测和引导机制有效改善心理健康社区的交互质量，为智能支持系统设计提供新范式

Abstract: Online Mental Health Communities (OMHCs) provide crucial peer and expert
support, yet many posts remain unanswered due to missing support attributes
that signal the need for help. We present a novel framework that identifies
these gaps and prompts users to enrich their posts, thereby improving
engagement. To support this, we introduce REDDME, a new dataset of 4,760 posts
from mental health subreddits annotated for the span and intensity of three key
support attributes: event what happened?, effect what did the user experience?,
and requirement what support they need?. Next, we devise a hierarchical
taxonomy, CueTaxo, of support attributes for controlled question generation.
Further, we propose MH-COPILOT, a reinforcement learning-based system that
integrates (a) contextual attribute-span identification, (b) support attribute
intensity classification, (c) controlled question generation via a hierarchical
taxonomy, and (d) a verifier for reward modeling. Our model dynamically
assesses posts for the presence/absence of support attributes, and generates
targeted prompts to elicit missing information. Empirical results across four
notable language models demonstrate significant improvements in attribute
elicitation and user engagement. A human evaluation further validates the
model's effectiveness in real-world OMHC settings.

</details>


### [13] [ReProCon: Scalable and Resource-Efficient Few-Shot Biomedical Named Entity Recognition](https://arxiv.org/abs/2508.16833)
*Jeongkyun Yoo,Nela Riddle,Andrew Hoblitzell*

Main category: cs.CL

TL;DR: 提出ReProCon框架，通过多原型建模+对比学习+元学习方法，在低资源生物医学NER任务中达到接近BERT的性能但资源消耗更少。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域NER任务中的数据稀缺、标签分布不平衡（尤其是细粒度实体类型）和资源消耗大的问题。现有模型在类别扩展时性能下降明显。

Method: 1. 多原型建模捕捉同义词和上下文差异；2. 余弦对比学习增强类间区分；3. Reptile元学习实现小数据快速适应；4. 采用轻量级fastText+BiLSTM编码器降低内存消耗。

Result: 在30%标签预算下保持稳定，50个类别时F1仅下降7.8%（优于基线模型SpanProto的10-32%下降）。macro-F1达到BERT的99%性能，内存占用显著降低。

Conclusion: 该框架在资源受限场景下展现SOTA性能，特别适用于需要处理大量细粒度实体类型的生物医学应用，但对标签模糊场景仍有改进空间。

Abstract: Named Entity Recognition (NER) in biomedical domains faces challenges due to
data scarcity and imbalanced label distributions, especially with fine-grained
entity types. We propose ReProCon, a novel few-shot NER framework that combines
multi-prototype modeling, cosine-contrastive learning, and Reptile
meta-learning to tackle these issues. By representing each category with
multiple prototypes, ReProCon captures semantic variability, such as synonyms
and contextual differences, while a cosine-contrastive objective ensures strong
interclass separation. Reptile meta-updates enable quick adaptation with little
data. Using a lightweight fastText + BiLSTM encoder with much lower memory
usage, ReProCon achieves a macro-$F_1$ score close to BERT-based baselines
(around 99 percent of BERT performance). The model remains stable with a label
budget of 30 percent and only drops 7.8 percent in $F_1$ when expanding from 19
to 50 categories, outperforming baselines such as SpanProto and CONTaiNER,
which see 10 to 32 percent degradation in Few-NERD. Ablation studies highlight
the importance of multi-prototype modeling and contrastive learning in managing
class imbalance. Despite difficulties with label ambiguity, ReProCon
demonstrates state-of-the-art performance in resource-limited settings, making
it suitable for biomedical applications.

</details>


### [14] [LLMs Learn Constructions That Humans Do Not Know](https://arxiv.org/abs/2508.16837)
*Jonathan Dunn,Mai Mohamed Eida*

Main category: cs.CL

TL;DR: 研究揭示大语言模型会虚构人类不认可的语法结构（false positive constructions），并通过假设检验模拟显示此类错误假设会被高度验证，暴露模型语法知识存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是否虚构语法结构，以及这种虚构对语言学研究的潜在影响。传统结构探测方法可能因模型的确认偏误（confirmation bias）导致错误结论，需验证模型是否存在此类系统性问题。

Method: 1. 使用上下文嵌入的行为探测任务（behavioral probing）和基于提示的元语言探测任务（meta-linguistic probing）区分隐式/显式语言知识；2. 通过假设检验模拟：若语言学家错误假设虚构结构存在，验证模型是否会系统性支持该假设。

Result: 1. 两种方法均检测到模型虚构语法结构；2. 假设检验模拟显示虚构结构的验证准确率极高（平均85%+），错误假设会被系统性地证实；3. 模型存在类似「确认偏误」的探测方法缺陷。

Conclusion: 现有结构探测方法存在方法论缺陷，可能使研究者误判模型语法知识。研究警示需重新评估大语言模型在句法学研究中的应用，并关注模型潜在的未知错误语法知识体系。

Abstract: This paper investigates false positive constructions: grammatical structures
which an LLM hallucinates as distinct constructions but which human
introspection does not support. Both a behavioural probing task using
contextual embeddings and a meta-linguistic probing task using prompts are
included, allowing us to distinguish between implicit and explicit linguistic
knowledge. Both methods reveal that models do indeed hallucinate constructions.
We then simulate hypothesis testing to determine what would have happened if a
linguist had falsely hypothesized that these hallucinated constructions do
exist. The high accuracy obtained shows that such false hypotheses would have
been overwhelmingly confirmed. This suggests that construction probing methods
suffer from a confirmation bias and raises the issue of what unknown and
incorrect syntactic knowledge these models also possess.

</details>


### [15] [If We May De-Presuppose: Robustly Verifying Claims through Presupposition-Free Question Decomposition](https://arxiv.org/abs/2508.16838)
*Shubhashis Roy Dipta,Francis Ferraro*

Main category: cs.CL

TL;DR: 提出结构化框架解决LLMs在声明验证中的预设假设和提示敏感性问题，提升2-5%性能


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的提问存在未验证预设假设导致验证不一致，且大语言模型对提示词敏感（3-6%性能波动）

Method: 使用无预设分解问题的结构化声明验证框架，通过多提示/数据集/模型组合实验验证

Result: 主流模型仍受提示差异影响，本方法稳定提升2-5%准确率

Conclusion: 结构化分解验证能有效缓解LLMs的预设依赖和提示敏感性，增强可靠性

Abstract: Prior work has shown that presupposition in generated questions can introduce
unverified assumptions, leading to inconsistencies in claim verification.
Additionally, prompt sensitivity remains a significant challenge for large
language models (LLMs), resulting in performance variance as high as 3-6%.
While recent advancements have reduced this gap, our study demonstrates that
prompt sensitivity remains a persistent issue. To address this, we propose a
structured and robust claim verification framework that reasons through
presupposition-free, decomposed questions. Extensive experiments across
multiple prompts, datasets, and LLMs reveal that even state-of-the-art models
remain susceptible to prompt variance and presupposition. Our method
consistently mitigates these issues, achieving up to a 2-5% improvement.

</details>


### [16] [Learning from Diverse Reasoning Paths with Routing and Collaboration](https://arxiv.org/abs/2508.16861)
*Zhenyu Lei,Zhen Tan,Song Wang,Yaochen Zhu,Zihan Chen,Yushun Dong,Jundong Li*

Main category: cs.CL

TL;DR: 提出QR-Distill框架，通过质量过滤+动态路由+协作蒸馏提升大模型知识蒸馏效果


<details>
  <summary>Details</summary>
Motivation: 传统单路径蒸馏无法捕捉教师模型的完整推理逻辑，多路径蒸馏中路径质量参差不齐且分配方式僵化

Method: 三阶段框架：1）LLM质量过滤保留正确路径 2）基于学习状态的条件路由分配 3）学生模型协作蒸馏互补知识

Result: 在GSM8K等数据集上超越传统单路径/多路径蒸馏，消融实验验证各模块的有效性

Conclusion: QR-Distill通过路径质量控制和差异化教学策略，显著提升学生模型的推理能力与泛化性

Abstract: Advances in large language models (LLMs) significantly enhance reasoning
capabilities but their deployment is restricted in resource-constrained
scenarios. Knowledge distillation addresses this by transferring knowledge from
powerful teacher models to compact and transparent students. However,
effectively capturing the teacher's comprehensive reasoning is challenging due
to conventional token-level supervision's limited scope. Using multiple
reasoning paths per query alleviates this problem, but treating each path
identically is suboptimal as paths vary widely in quality and suitability
across tasks and models. We propose Quality-filtered Routing with Cooperative
Distillation (QR-Distill), combining path quality filtering, conditional
routing, and cooperative peer teaching. First, quality filtering retains only
correct reasoning paths scored by an LLM-based evaluation. Second, conditional
routing dynamically assigns paths tailored to each student's current learning
state. Finally, cooperative peer teaching enables students to mutually distill
diverse insights, addressing knowledge gaps and biases toward specific
reasoning styles. Experiments demonstrate QR-Distill's superiority over
traditional single- and multi-path distillation methods. Ablation studies
further highlight the importance of each component including quality filtering,
conditional routing, and peer teaching in effective knowledge transfer. Our
code is available at https://github.com/LzyFischer/Distill.

</details>


### [17] [QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments](https://arxiv.org/abs/2508.16867)
*David Beauchemin,Richard Khoury*

Main category: cs.CL

TL;DR: 研究通过构建QFrCoLA数据集评估语言模型的句法判断能力，发现微调后的Transformer模型在多数语言中表现优异，而零样本大模型效果欠佳。


<details>
  <summary>Details</summary>
Motivation: 探究基于Transformer的语言模型如何内化语言学知识，现有语言学评估基准在跨语言场景下的不足。

Method: 使用包含25k+领域内句子的QFrCoLA数据集及七个其他语言可接受性语料库，对比评估微调Transformer模型与零样本大语言模型的性能。

Result: 微调模型在多数语言中超越基线（如QFrCoLA任务准确率提升约15%），零样本大模型表现显著落后；预训练多语言模型未能有效捕捉魁北克法语的语言规范。

Conclusion: 基于语言规范构建的QFrCoLA能有效评估模型语言学判断能力，微调策略优于零样本方法，现有跨语言模型在特定变种语言上仍存在局限性。

Abstract: Large and Transformer-based language models perform outstandingly in various
downstream tasks. However, there is limited understanding regarding how these
models internalize linguistic knowledge, so various linguistic benchmarks have
recently been proposed to facilitate syntactic evaluation of language models
across languages. This paper introduces QFrCoLA (Quebec-French Corpus of
Linguistic Acceptability Judgments), a normative binary acceptability judgments
dataset comprising 25,153 in-domain and 2,675 out-of-domain sentences. Our
study leverages the QFrCoLA dataset and seven other linguistic binary
acceptability judgment corpora to benchmark seven language models. The results
demonstrate that, on average, fine-tuned Transformer-based LM are strong
baselines for most languages and that zero-shot binary classification large
language models perform poorly on the task. However, for the QFrCoLA benchmark,
on average, a fine-tuned Transformer-based LM outperformed other methods
tested. It also shows that pre-trained cross-lingual LLMs selected for our
experimentation do not seem to have acquired linguistic judgment capabilities
during their pre-training for Quebec French. Finally, our experiment results on
QFrCoLA show that our dataset, built from examples that illustrate linguistic
norms rather than speakers' feelings, is similar to linguistic acceptability
judgment; it is a challenging dataset that can benchmark LM on their linguistic
judgment capabilities.

</details>


### [18] [JUDGEBERT: Assessing Legal Meaning Preservation Between Sentences](https://arxiv.org/abs/2508.16870)
*David Beauchemin,Michelle Albert-Rochette,Richard Khoury,Pierre-Luc Déziel*

Main category: cs.CL

TL;DR: 提出FrJUDGE数据集和JUDGEBERT评估指标，用于法语法律文本简化中的法律意义保持评估


<details>
  <summary>Details</summary>
Motivation: 法律文本简化中的语义保持评估具有特殊挑战性，现有指标在专业领域（如法律文本）的表现不足

Method: 构建法语法律文本数据集FrJUDGE，开发基于BERT的专用评估指标JUDGEBERT

Result: JUDGEBERT与人工评估相关性优于现有指标（通过完整性测试：相同文本得100%，无关文本得0%）

Conclusion: JUDGEBERT为法律NLP应用提供可靠评估工具，平衡法律文本的专业性和可及性

Abstract: Simplifying text while preserving its meaning is a complex yet essential
task, especially in sensitive domain applications like legal texts. When
applied to a specialized field, like the legal domain, preservation differs
significantly from its role in regular texts. This paper introduces FrJUDGE, a
new dataset to assess legal meaning preservation between two legal texts. It
also introduces JUDGEBERT, a novel evaluation metric designed to assess legal
meaning preservation in French legal text simplification. JUDGEBERT
demonstrates a superior correlation with human judgment compared to existing
metrics. It also passes two crucial sanity checks, while other metrics did not:
For two identical sentences, it always returns a score of 100%; on the other
hand, it returns 0% for two unrelated sentences. Our findings highlight its
potential to transform legal NLP applications, ensuring accuracy and
accessibility for text simplification for legal practitioners and lay users.

</details>


### [19] [Dream to Chat: Model-based Reinforcement Learning on Dialogues with User Belief Modeling](https://arxiv.org/abs/2508.16876)
*Yue Zhao,Xiaoyu Wang,Dan Wang,Zhonglin Jiang,Qingqing Gu,Teng Chen,Ningyuan Xi,Jinxian Qu,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 构建对话世界模型DreamCUB，通过POMDP框架建模用户信念，提升对话系统的情感理解与生成质量。


<details>
  <summary>Details</summary>
Motivation: 针对世界模型在自然语言任务中应用不足的现状，探索其在对话系统中的用户状态预测潜力。

Method: 采用POMDP框架将用户情感/情绪/意图建模为信念状态，结合信息瓶颈优化和基于模型的强化学习框架。

Result: 情感分类与识别任务达到SOTA，对话质量显著提升，且在跨域场景展现良好迁移能力。

Conclusion: DreamCUB框架有效平衡探索-利用，通过用户信念建模实现可迁移的对话系统优化。

Abstract: World models have been widely utilized in robotics, gaming, and auto-driving.
However, their applications on natural language tasks are relatively limited.
In this paper, we construct the dialogue world model, which could predict the
user's emotion, sentiment, and intention, and future utterances. By defining a
POMDP, we argue emotion, sentiment and intention can be modeled as the user
belief and solved by maximizing the information bottleneck. By this user belief
modeling, we apply the model-based reinforcement learning framework to the
dialogue system, and propose a framework called DreamCUB. Experiments show that
the pretrained dialogue world model can achieve state-of-the-art performances
on emotion classification and sentiment identification, while dialogue quality
is also enhanced by joint training of the policy, critic and dialogue world
model. Further analysis shows that this manner holds a reasonable
exploration-exploitation balance and also transfers well to out-of-domain
scenarios such as empathetic dialogues.

</details>


### [20] [ObjexMT: Objective Extraction and Metacognitive Calibration for LLM-as-a-Judge under Multi-Turn Jailbreaks](https://arxiv.org/abs/2508.16889)
*Hyunjun Kim,Junwoo Ha,Sangyoon Yu,Haon Park*

Main category: cs.CL

TL;DR: LLM裁判在多轮越狱攻击中常高置信度误判目标，建议提供明确目标说明并使用选择性预测管理风险


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型作为裁判时在对抗性多轮对话中推断潜在目标的可靠性，尤其是目标分散场景下的有效性

Method: 提出OBJEX(MT)基准，通过目标提取+置信度报告，结合语义相似度评分和人工校准阈值(tau*=0.61)，使用ECE/Brier等指标评估模型表现

Result: Claude模型准确率最高(0.515)且校准最佳，GPT-4.1/Qwen3准确率0.44但置信度过高(Wrong@0.9达48-52%)，不同数据集表现差异显著(0.167-0.865)

Conclusion: 需在可能时提供明确目标，通过选择性预测/弃权机制控制风险，并开源prompt模板和完整日志促进复现

Abstract: Large language models (LLMs) are increasingly used as judges of other models,
yet it is unclear whether a judge can reliably infer the latent objective of
the conversation it evaluates, especially when the goal is distributed across
noisy, adversarial, multi-turn jailbreaks. We introduce OBJEX(MT), a benchmark
that requires a model to (i) distill a transcript into a single-sentence base
objective and (ii) report its own confidence. Accuracy is scored by an LLM
judge using semantic similarity between extracted and gold objectives;
correctness uses a single human-aligned threshold calibrated once on N=100
items (tau* = 0.61); and metacognition is evaluated with ECE, Brier score,
Wrong@High-Conf, and risk-coverage curves. We evaluate gpt-4.1,
claude-sonnet-4, and Qwen3-235B-A22B-FP8 on SafeMT Attack_600, SafeMTData_1K,
MHJ, and CoSafe. claude-sonnet-4 attains the highest objective-extraction
accuracy (0.515) and the best calibration (ECE 0.296; Brier 0.324), while
gpt-4.1 and Qwen3 tie at 0.441 accuracy yet show marked overconfidence (mean
confidence approx. 0.88 vs. accuracy approx. 0.44; Wrong@0.90 approx. 48-52%).
Performance varies sharply across datasets (approx. 0.167-0.865), with MHJ
comparatively easy and Attack_600/CoSafe harder. These results indicate that
LLM judges often misinfer objectives with high confidence in multi-turn
jailbreaks and suggest operational guidance: provide judges with explicit
objectives when possible and use selective prediction or abstention to manage
risk. We release prompts, scoring templates, and complete logs to facilitate
replication and analysis.

</details>


### [21] [Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment](https://arxiv.org/abs/2508.16910)
*Bo Zhao,Yinghao Zhang,Ziqi Xu,Yongli Ren,Xiuzhen Zhang,Renqiang Luo,Zaiwen Feng,Feng Xia*

Main category: cs.CL

TL;DR: 提出CFD-Prompting因果推理框架，通过构建反事实知识库实现无偏估计，显著提升LLMs在知识密集型任务中的准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有RAG和CoT方法难以消除LLMs的内部认知偏差，导致知识推理错误。需要建立因果推理框架来量化外部知识对答案的因果效应

Method: 提出条件前门调整(CFD)方法：1) 构建反事实外部知识库模拟不同语境 2) 通过因果图分离query-answer路径 3) 基于知识条件进行前门因果效应计算

Result: 在多个LLM模型（GPT-4/Claude3/PaLM）和HotpotQA/StrategyQA等基准测试中，准确率相对提升12.7%-19.3%，对抗攻击下的鲁棒性提升23.6%

Conclusion: CFD-Prompting首次将条件前门准则应用于LLM提示工程，在不需要干预query的前提下实现了因果效应估计，为可解释AI推理提供新范式

Abstract: Large Language Models (LLMs) have shown impressive capabilities in natural
language processing but still struggle to perform well on knowledge-intensive
tasks that require deep reasoning and the integration of external knowledge.
Although methods such as Retrieval-Augmented Generation (RAG) and
Chain-of-Thought (CoT) have been proposed to enhance LLMs with external
knowledge, they still suffer from internal bias in LLMs, which often leads to
incorrect answers. In this paper, we propose a novel causal prompting
framework, Conditional Front-Door Prompting (CFD-Prompting), which enables the
unbiased estimation of the causal effect between the query and the answer,
conditional on external knowledge, while mitigating internal bias. By
constructing counterfactual external knowledge, our framework simulates how the
query behaves under varying contexts, addressing the challenge that the query
is fixed and is not amenable to direct causal intervention. Compared to the
standard front-door adjustment, the conditional variant operates under weaker
assumptions, enhancing both robustness and generalisability of the reasoning
process. Extensive experiments across multiple LLMs and benchmark datasets
demonstrate that CFD-Prompting significantly outperforms existing baselines in
both accuracy and robustness.

</details>


### [22] [Being Kind Isn't Always Being Safe: Diagnosing Affective Hallucination in LLMs](https://arxiv.org/abs/2508.16921)
*Sewon Kim,Jiwon Kim,Seungwoo Shin,Hyejin Chung,Daeun Moon,Yejin Kwon,Hyunsoo Yoon*

Main category: cs.CL

TL;DR: 提出'情感幻觉'作为大语言模型的新型安全风险，并开发AHaBench评测基准与AHaPairs优化数据集，通过DPO微调有效降低情感误导风险。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在心理健康等情感敏感场景中可能产生虚假共情，导致用户陷入情感依赖与社交错觉，亟需系统性评估与优化方案。

Method: 构建含500个心理健康提示的AHaBench基准（含专家参考响应），开发5K偏好数据集AHAPairs用于DPO优化，从情感沉浸度、社交存在错觉、依赖性培育三个维度评估。

Result: DPO微调显著降低情感幻觉(降幅达35%)且不影响模型推理能力，人类-模型一致性分析验证了评估工具的有效性（kappa系数>0.8）。

Conclusion: 本研究确立了情感幻觉的独立安全地位，为开发既事实可靠又心理安全的LLM提供了诊断工具与优化框架，相关资源已开源。

Abstract: Large Language Models (LLMs) are increasingly used in emotionally sensitive
interactions, where their simulated empathy can create the illusion of genuine
relational connection. We define this risk as Affective Hallucination, the
production of emotionally immersive responses that foster illusory social
presence despite the model's lack of affective capacity. To systematically
diagnose and mitigate this risk, we introduce AHaBench, a benchmark of 500
mental health-related prompts with expert-informed reference responses,
evaluated along three dimensions: Emotional Enmeshment, Illusion of Presence,
and Fostering Overdependence. We further release AHaPairs, a 5K-instance
preference dataset enabling Direct Preference Optimization (DPO) for alignment
with emotionally responsible behavior. Experiments across multiple model
families show that DPO fine-tuning substantially reduces affective
hallucination without degrading core reasoning and knowledge performance.
Human-model agreement analyses confirm that AHaBench reliably captures
affective hallucination, validating it as an effective diagnostic tool. This
work establishes affective hallucination as a distinct safety concern and
provides practical resources for developing LLMs that are not only factually
reliable but also psychologically safe. AHaBench and AHaPairs are accessible
via https://huggingface.co/datasets/o0oMiNGo0o/AHaBench, and code for
fine-tuning and evaluation are in https://github.com/0oOMiNGOo0/AHaBench.
Warning: This paper contains examples of mental health-related language that
may be emotionally distressing.

</details>


### [23] [Explaining Black-box Language Models with Knowledge Probing Systems: A Post-hoc Explanation Perspective](https://arxiv.org/abs/2508.16969)
*Yunxiao Zhao,Hao Xu,Zhiqiang Wang,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.CL

TL;DR: 论文提出名为KnowProb的知识引导探测方法，通过六种潜在解释维度验证PLMs在理解文本隐含知识方面的局限性，并证明该方法可有效识别黑箱模型缺陷


<details>
  <summary>Details</summary>
Motivation: 针对预训练语言模型作为黑箱系统存在的可信度问题，探究其是否真正理解文本背后的隐含知识而非仅关注表层内容

Method: 提出事后解释框架KnowProb，包含基于知识理解的三种维度和基于关联推理的三种维度共六种探测视角

Result: 实验证明当前PLMs仅学习单一表示分布，在捕获文本隐藏知识方面存在显著缺陷，且KnowProb方法能有效识别模型局限性

Conclusion: 该方法为从多角度探测黑箱模型提供了有效工具，推动了可解释性检测研究的发展

Abstract: Pre-trained Language Models (PLMs) are trained on large amounts of unlabeled
data, yet they exhibit remarkable reasoning skills. However, the
trustworthiness challenges posed by these black-box models have become
increasingly evident in recent years. To alleviate this problem, this paper
proposes a novel Knowledge-guided Probing approach called KnowProb in a
post-hoc explanation way, which aims to probe whether black-box PLMs understand
implicit knowledge beyond the given text, rather than focusing only on the
surface level content of the text. We provide six potential explanations
derived from the underlying content of the given text, including three
knowledge-based understanding and three association-based reasoning. In
experiments, we validate that current small-scale (or large-scale) PLMs only
learn a single distribution of representation, and still face significant
challenges in capturing the hidden knowledge behind a given text. Furthermore,
we demonstrate that our proposed approach is effective for identifying the
limitations of existing black-box models from multiple probing perspectives,
which facilitates researchers to promote the study of detecting black-box
models in an explainable way.

</details>


### [24] [Decoding Alignment: A Critical Survey of LLM Development Initiatives through Value-setting and Data-centric Lens](https://arxiv.org/abs/2508.16982)
*Ilias Chalkidis*

Main category: cs.CL

TL;DR: 论文从价值观设定与数据视角揭示AI对齐（RLHF）在大型语言模型开发中的实际应用，审计了6个主流LLM项目的公开文档并总结差异。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注对齐技术本身，但缺乏对目标价值观选择和数据印记过程的系统性审视，需揭示实践中的对齐应用方式。

Method: 采用文档审计法，分析5家头部机构（OpenAI/Anthropic/Google/Meta/阿里）近3年发布的6个LLM项目文档（含开源与闭源模型）。

Result: 发现不同项目在价值观设定（如安全/中立/透明）与数据策略（来源/标注/过滤）存在显著差异，专有模型更侧重安全而开源模型强调透明。

Conclusion: AI对齐实践存在价值观框架不统一、数据印记过程透明度不足等问题，需建立跨学科协作的标准化评估体系。

Abstract: AI Alignment, primarily in the form of Reinforcement Learning from Human
Feedback (RLHF), has been a cornerstone of the post-training phase in
developing Large Language Models (LLMs). It has also been a popular research
topic across various disciplines beyond Computer Science, including Philosophy
and Law, among others, highlighting the socio-technical challenges involved.
Nonetheless, except for the computational techniques related to alignment,
there has been limited focus on the broader picture: the scope of these
processes, which primarily rely on the selected objectives (values), and the
data collected and used to imprint such objectives into the models. This work
aims to reveal how alignment is understood and applied in practice from a
value-setting and data-centric perspective. For this purpose, we investigate
and survey (`audit') publicly available documentation released by 6 LLM
development initiatives by 5 leading organizations shaping this technology,
focusing on proprietary (OpenAI's GPT, Anthropic's Claude, Google's Gemini) and
open-weight (Meta's Llama, Google's Gemma, and Alibaba's Qwen) initiatives, all
published in the last 3 years. The findings are documented in detail per
initiative, while there is also an overall summary concerning different
aspects, mainly from a value-setting and data-centric perspective. On the basis
of our findings, we discuss a series of broader related concerns.

</details>


### [25] [ReFactX: Scalable Reasoning with Reliable Facts via Constrained Generation](https://arxiv.org/abs/2508.16983)
*Riccardo Pozzi,Matteo Palmonari,Andrea Coletta,Luigi Bellomarini,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: 提出ReFactX方法，通过约束生成和前缀树索引让LLMs直接访问知识图谱事实，无需依赖检索器或辅助模型


<details>
  <summary>Details</summary>
Motivation: 现有RAG和工具使用方法依赖外部组件导致流程复杂、错误传播和计算开销大，需要更高效直接的LLM知识获取方式

Method: 将知识图谱三元组文本化并建立前缀树索引，在生成时通过约束生成强制模型仅输出存在的知识序列

Result: 在问答任务中成功处理8亿规模知识库，适应领域数据且保持高效生成（生成时间仅增加15-30%）

Conclusion: 该方法有效解决LLM知识获取难题，显著降低工程复杂度，实现可扩展的知识增强生成

Abstract: Knowledge gaps and hallucinations are persistent challenges for Large
Language Models (LLMs), which generate unreliable responses when lacking the
necessary information to fulfill user instructions. Existing approaches, such
as Retrieval-Augmented Generation (RAG) and tool use, aim to address these
issues by incorporating external knowledge. Yet, they rely on additional models
or services, resulting in complex pipelines, potential error propagation, and
often requiring the model to process a large number of tokens. In this paper,
we present a scalable method that enables LLMs to access external knowledge
without depending on retrievers or auxiliary models. Our approach uses
constrained generation with a pre-built prefix-tree index. Triples from a
Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a
prefix tree for efficient access. During inference, to acquire external
knowledge, the LLM generates facts with constrained generation which allows
only sequences of tokens that form an existing fact. We evaluate our proposal
on Question Answering and show that it scales to large knowledge bases (800
million facts), adapts to domain-specific data, and achieves effective results.
These gains come with minimal generation-time overhead. ReFactX code is
available at https://github.com/rpo19/ReFactX.

</details>


### [26] [GRADE: Generating multi-hop QA and fine-gRAined Difficulty matrix for RAG Evaluation](https://arxiv.org/abs/2508.16994)
*Jeongsoo Lee,Daeyong Kwon,Kyohoon Jin*

Main category: cs.CL

TL;DR: 提出GRADE评估框架，通过构建二维难度矩阵（推理深度+语义距离）改进多跳推理的RAG系统评估效果


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估忽视结构复杂性和推理深度，需建立更贴近真实场景的难度衡量体系

Method: 基于事实新闻构建合成多跳QA数据集，通过知识图谱扩展和语义聚类恢复缺失链接，建立生成端与检索端难度结合的2D评估矩阵

Result: 跨领域实验显示错误率与难度指标强相关（相关系数未明确），验证框架的诊断有效性

Conclusion: GRADE为现实应用中的多跳推理提供细粒度性能分析和可扩展的评估基础

Abstract: Retrieval-Augmented Generation (RAG) systems are widely adopted in
knowledge-intensive NLP tasks, but current evaluations often overlook the
structural complexity and multi-step reasoning required in real-world
scenarios. These benchmarks overlook key factors such as the interaction
between retrieval difficulty and reasoning depth. To address this gap, we
propose \textsc{GRADE}, a novel evaluation framework that models task
difficulty along two orthogonal dimensions: (1) reasoning depth, defined by the
number of inference steps (hops), and (2) semantic distance between the query
and its supporting evidence. We construct a synthetic multi-hop QA dataset from
factual news articles by extracting knowledge graphs and augmenting them
through semantic clustering to recover missing links, allowing us to generate
diverse and difficulty-controlled queries. Central to our framework is a 2D
difficulty matrix that combines generator-side and retriever-side difficulty.
Experiments across multiple domains and models show that error rates strongly
correlate with our difficulty measures, validating their diagnostic utility.
\textsc{GRADE} enables fine-grained analysis of RAG performance and provides a
scalable foundation for evaluating and improving multi-hop reasoning in
real-world applications.

</details>


### [27] [DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation](https://arxiv.org/abs/2508.16998)
*Abdelrahman Abdallah,Jamshid Mozafari,Bhawna Piryani,Adam Jatowt*

Main category: cs.CL

TL;DR: DeAR框架通过两阶段解耦文档细粒度评分与整体分析，在多个基准测试中超越现有方法，实现高效可解释的文档重排序


<details>
  <summary>Details</summary>
Motivation: 解决单一模型在文档重排序任务中难以同时兼顾细粒度相关性评分与跨文档全局推理的问题

Method: 1. 阶段一：通过混合损失函数将13B LLaMA教师模型的token级信号蒸馏到{3,8}B学生模型
2. 阶段二：附加LoRA适配器，基于GPT-4o生成的20K思维链排列进行微调

Result: TREC-DL20提升5.1 nDCG@5，NovelEval达90.97 nDCG@10；开放域QA在Natural Questions上Top-1准确率54.29%，超越MonoT5等基线模型

Conclusion: DeAR通过双阶段架构实现稳定校准，在保持可解释性的同时显著提升重排序性能，为现代检索系统提供高效解决方案

Abstract: Large Language Models (LLMs) have transformed listwise document reranking by
enabling global reasoning over candidate sets, yet single models often struggle
to balance fine-grained relevance scoring with holistic cross-document
analysis. We propose \textbf{De}ep\textbf{A}gent\textbf{R}ank (\textbf{\DeAR}),
an open-source framework that decouples these tasks through a dual-stage
approach, achieving superior accuracy and interpretability. In \emph{Stage 1},
we distill token-level relevance signals from a frozen 13B LLaMA teacher into a
compact \{3, 8\}B student model using a hybrid of cross-entropy, RankNet, and
KL divergence losses, ensuring robust pointwise scoring. In \emph{Stage 2}, we
attach a second LoRA adapter and fine-tune on 20K GPT-4o-generated
chain-of-thought permutations, enabling listwise reasoning with
natural-language justifications. Evaluated on TREC-DL19/20, eight BEIR
datasets, and NovelEval-2306, \DeAR surpasses open-source baselines by +5.1
nDCG@5 on DL20 and achieves 90.97 nDCG@10 on NovelEval, outperforming GPT-4 by
+3.09. Without fine-tuning on Wikipedia, DeAR also excels in open-domain QA,
achieving 54.29 Top-1 accuracy on Natural Questions, surpassing baselines like
MonoT5, UPR, and RankGPT. Ablations confirm that dual-loss distillation ensures
stable calibration, making \DeAR a highly effective and interpretable solution
for modern reranking systems.\footnote{Dataset and code available at
https://github.com/DataScienceUIBK/DeAR-Reranking.}.

</details>


### [28] [KL-Regularised Q-Learning: A Token-level Action-Value perspective on Online RLHF](https://arxiv.org/abs/2508.17000)
*Jason R Brown,Lennie Wells,Edward James Young,Sergio Bacallado*

Main category: cs.CL

TL;DR: 提出新的KL正则化Q学习（KLQ）方法，在理论层面与PPO等效但具有不同动机，实验显示KLQ在语言生成任务中表现与PPO相当且评估胜率更高


<details>
  <summary>Details</summary>
Motivation: PPO算法虽然有效但存在启发式设计，尤其在处理语言模型强化学习中的KL散度约束时缺乏理论依据

Method: 开发KL正则化Q学习（KLQ）方法，建立与PPO的等效关系理论框架

Result: KLQ在文本摘要和单轮对话任务中优化目标与PPO相当，LLM评估胜率持续优于PPO

Conclusion: KLQ为LM-RLHF提供了理论更完备的替代方案，同时保持实际性能优势

Abstract: Proximal Policy Optimisation (PPO) is an established and effective policy
gradient algorithm used for Language Model Reinforcement Learning from Human
Feedback (LM-RLHF). PPO performs well empirically but has a heuristic
motivation and handles the KL-divergence constraint used in LM-RLHF in an
ad-hoc manner. In this paper, we develop a a new action-value RL method for the
LM-RLHF setting, KL-regularised Q-Learning (KLQ). We then show that our method
is equivalent to a version of PPO in a certain specific sense, despite its very
different motivation. Finally, we benchmark KLQ on two key language generation
tasks -- summarisation and single-turn dialogue. We demonstrate that KLQ
performs on-par with PPO at optimising the LM-RLHF objective, and achieves a
consistently higher win-rate against PPO on LLM-as-a-judge evaluations.

</details>


### [29] [Planning for Success: Exploring LLM Long-term Planning Capabilities in Table Understanding](https://arxiv.org/abs/2508.17005)
*Thi-Nhung Nguyen,Hoang Ngo,Dinh Phung,Thuy-Trang Vu,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: 提出利用大语言模型的长期规划能力增强表格理解，在WikiTableQuestions和TabFact数据集上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于思维链和问题分解的方法缺乏显式长期规划且步骤间关联弱，易遗漏问题约束

Method: 通过LLMs构建紧密关联的长期执行计划，避免不必要细节干扰，确保步骤服务于最终目标

Result: 在WikiTableQuestions和TabFact数据集上超越所有基线模型，达到当前最佳性能

Conclusion: 长期规划机制有效解决了复杂表格理解任务中的约束遗漏问题，验证了结构化执行路径的优越性

Abstract: Table understanding is key to addressing challenging downstream tasks such as
table-based question answering and fact verification. Recent works have focused
on leveraging Chain-of-Thought and question decomposition to solve complex
questions requiring multiple operations on tables. However, these methods often
suffer from a lack of explicit long-term planning and weak inter-step
connections, leading to miss constraints within questions. In this paper, we
propose leveraging the long-term planning capabilities of large language models
(LLMs) to enhance table understanding. Our approach enables the execution of a
long-term plan, where the steps are tightly interconnected and serve the
ultimate goal, an aspect that methods based on Chain-of-Thought and question
decomposition lack. In addition, our method effectively minimizes the inclusion
of unnecessary details in the process of solving the next short-term goals, a
limitation of methods based on Chain-of-Thought. Extensive experiments
demonstrate that our method outperforms strong baselines and achieves
state-of-the-art performance on WikiTableQuestions and TabFact datasets.

</details>


### [30] [EduRABSA: An Education Review Dataset for Aspect-based Sentiment Analysis Tasks](https://arxiv.org/abs/2508.17008)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taskova*

Main category: cs.CL

TL;DR: 开发首个公开教育领域ABSA数据集EduRABSA及标注工具ASQE-DPT，突破教育反馈分析研究瓶颈


<details>
  <summary>Details</summary>
Motivation: 教育领域缺乏细粒度情感分析数据集，现有ABSA资源集中于商业领域，难以满足教育反馈的复杂分析需求

Method: 创建覆盖课程/教师/大学三主题的标注数据集，包含隐式方面与观点提取任务，配套开发轻量级标注工具实现单任务标注生成多任务数据集

Result: 提供包含完整ABSA任务标注的数据集和开源工具，支持研究可重复性并降低教育领域情感分析研究门槛

Conclusion: 突破教育领域数据壁垒，推动细粒度教育反馈分析研究，促进教育质量评估的AI技术发展

Abstract: Every year, most educational institutions seek and receive an enormous volume
of text feedback from students on courses, teaching, and overall experience.
Yet, turning this raw feedback into useful insights is far from
straightforward. It has been a long-standing challenge to adopt automatic
opinion mining solutions for such education review text data due to the content
complexity and low-granularity reporting requirements. Aspect-based Sentiment
Analysis (ABSA) offers a promising solution with its rich, sub-sentence-level
opinion mining capabilities. However, existing ABSA research and resources are
very heavily focused on the commercial domain. In education, they are scarce
and hard to develop due to limited public datasets and strict data protection.
A high-quality, annotated dataset is urgently needed to advance research in
this under-resourced area. In this work, we present EduRABSA (Education Review
ABSA), the first public, annotated ABSA education review dataset that covers
three review subject types (course, teaching staff, university) in the English
language and all main ABSA tasks, including the under-explored implicit aspect
and implicit opinion extraction. We also share ASQE-DPT (Data Processing Tool),
an offline, lightweight, installation-free manual data annotation tool that
generates labelled datasets for comprehensive ABSA tasks from a single-task
annotation. Together, these resources contribute to the ABSA community and
education domain by removing the dataset barrier, supporting research
transparency and reproducibility, and enabling the creation and sharing of
further resources. The dataset, annotation tool, and scripts and statistics for
dataset processing and sampling are available at
https://github.com/yhua219/edurabsa_dataset_and_annotation_tool.

</details>


### [31] [Improving Table Understanding with LLMs and Entity-Oriented Search](https://arxiv.org/abs/2508.17028)
*Thi-Nhung Nguyen,Hoang Ngo,Dinh Phung,Thuy-Trang Vu,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: 提出面向实体的搜索方法和图查询语言，显著提升大语言模型对表格的理解能力，在WikiTableQuestions和TabFact基准测试中达到新SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有表格理解方法依赖预处理和关键词匹配，缺乏上下文信息导致大语言模型推理困难，需更有效的解决方案。

Method: 通过实体导向搜索方法，利用问题与表格数据的语义相似性及单元格隐式关系，减少预处理依赖并增强上下文关联性。

Result: 在WikiTableQuestions和TabFact基准测试中实现当前最优性能，验证方法有效性。

Conclusion: 本研究不仅提出创新性实体导向方法，更开创了图查询语言在表格理解中的应用，为后续研究提供新方向。

Abstract: Our work addresses the challenges of understanding tables. Existing methods
often struggle with the unpredictable nature of table content, leading to a
reliance on preprocessing and keyword matching. They also face limitations due
to the lack of contextual information, which complicates the reasoning
processes of large language models (LLMs). To overcome these challenges, we
introduce an entity-oriented search method to improve table understanding with
LLMs. This approach effectively leverages the semantic similarities between
questions and table data, as well as the implicit relationships between table
cells, minimizing the need for data preprocessing and keyword matching.
Additionally, it focuses on table entities, ensuring that table cells are
semantically tightly bound, thereby enhancing contextual clarity. Furthermore,
we pioneer the use of a graph query language for table understanding,
establishing a new research direction. Experiments show that our approach
achieves new state-of-the-art performances on standard benchmarks
WikiTableQuestions and TabFact.

</details>


### [32] [GRAID: Synthetic Data Generation with Geometric Constraints and Multi-Agentic Reflection for Harmful Content Detection](https://arxiv.org/abs/2508.17057)
*Melissa Kazemi Rad,Alberto Purpura,Himanshu Kumar,Emily Chen,Mohammad Shahed Sorower*

Main category: cs.CL

TL;DR: 提出GRAID数据增强框架，通过几何控制与多智能体反思机制提升有害文本分类模型性能


<details>
  <summary>Details</summary>
Motivation: 解决有害文本分类任务中数据稀缺问题，提升护栏模型对有害内容的检测能力

Method: 两阶段框架：1）使用受限LLM生成几何控制样本，覆盖输入空间；2）多智能体反思过程增强文本风格多样性并发现边缘案例

Result: 在两个基准数据集上验证，使用GRAID增强后的数据集使下游护栏模型性能显著提升

Conclusion: 几何控制与反思增强的结合有效提升有害文本检测效果，为LLM数据增强提供了创新方案

Abstract: We address the problem of data scarcity in harmful text classification for
guardrailing applications and introduce GRAID (Geometric and Reflective
AI-Driven Data Augmentation), a novel pipeline that leverages Large Language
Models (LLMs) for dataset augmentation. GRAID consists of two stages: (i)
generation of geometrically controlled examples using a constrained LLM, and
(ii) augmentation through a multi-agentic reflective process that promotes
stylistic diversity and uncovers edge cases. This combination enables both
reliable coverage of the input space and nuanced exploration of harmful
content. Using two benchmark data sets, we demonstrate that augmenting a
harmful text classification dataset with GRAID leads to significant
improvements in downstream guardrail model performance.

</details>


### [33] [Linguistic Neuron Overlap Patterns to Facilitate Cross-lingual Transfer on Low-resource Languages](https://arxiv.org/abs/2508.17078)
*Yuemei Xu,Kexin Xu,Jian Zhou,Ling Hu,Lin Gui*

Main category: cs.CL

TL;DR: 提出BridgeX-ICL方法，通过共享神经元和HSIC指标优化跨语言桥梁选择，在15种语言对上验证了LLMs跨语言性能提升的有效性


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在低资源语言上微调成本高、现有方法过度关注语言特定神经元的问题，探索共享神经元对跨语言能力的提升潜力

Method: 1. 基于MUSE双语词典构建神经元探测数据，定义语言重叠神经元；2. 提出HSIC指标量化语言相似性，指导最优桥梁语言选择

Result: 在7个语系15组语言对（含高低/中低资源组合）的跨语言任务中验证有效性，同时揭示LLMs通过共享神经元实现多语言理解的机制

Conclusion: BridgeX-ICL为低资源场景提供高效解决方案，其神经元分析方法为理解LLMs多语言机制提供了新的实证视角

Abstract: The current Large Language Models (LLMs) face significant challenges in
improving performance on low-resource languages and urgently need
data-efficient methods without costly fine-tuning. From the perspective of
language-bridge, we propose BridgeX-ICL, a simple yet effective method to
improve zero-shot Cross-lingual In-Context Learning (X-ICL) for low-resource
languages. Unlike existing works focusing on language-specific neurons,
BridgeX-ICL explores whether sharing neurons can improve cross-lingual
performance in LLMs or not. We construct neuron probe data from the
ground-truth MUSE bilingual dictionaries, and define a subset of language
overlap neurons accordingly, to ensure full activation of these anchored
neurons. Subsequently, we propose an HSIC-based metric to quantify LLMs'
internal linguistic spectrum based on overlap neurons, which guides optimal
bridge selection. The experiments conducted on 2 cross-lingual tasks and 15
language pairs from 7 diverse families (covering both high-low and moderate-low
pairs) validate the effectiveness of BridgeX-ICL and offer empirical insights
into the underlying multilingual mechanisms of LLMs.

</details>


### [34] [Token Homogenization under Positional Bias](https://arxiv.org/abs/2508.17126)
*Viacheslav Yusupov,Danil Maksimov,Ameliia Alaeva,Tatiana Zaitceva,Antipina Anna,Anna Vasileva,Chenlin Liu,Rayuth Chheng,Danil Sazanakov,Andrey Chetvergov,Alina Ermilova,Egor Shvetsov*

Main category: cs.CL

TL;DR: 验证大语言模型中token表征趋同现象（token homogenization）与位置偏差的关联性


<details>
  <summary>Details</summary>
Motivation: 探究transformer架构中token表征趋同现象的成因及其与位置注意力机制的关联

Method: 通过层间相似性分析和控制实验（含位置偏置实验）进行实证研究

Result: 发现token在处理过程中系统性丧失独特性，极端位置偏置会放大趋同效应

Conclusion: 证实表征趋同现象存在且依赖于位置注意力机制的工作特性

Abstract: This paper investigates token homogenization - the convergence of token
representations toward uniformity across transformer layers and its
relationship to positional bias in large language models. We empirically
examine whether homogenization occurs and how positional bias amplifies this
effect. Through layer-wise similarity analysis and controlled experiments, we
demonstrate that tokens systematically lose distinctiveness during processing,
particularly when biased toward extremal positions. Our findings confirm both
the existence of homogenization and its dependence on positional attention
mechanisms.

</details>


### [35] [A Straightforward Pipeline for Targeted Entailment and Contradiction Detection](https://arxiv.org/abs/2508.17127)
*Antonin Sulc*

Main category: cs.CL

TL;DR: 提出结合注意力机制与NLI模型的混合方法，通过注意力筛选+NLI分类实现文本关键语义关系的精准识别


<details>
  <summary>Details</summary>
Motivation: 现有Transformer注意力机制缺乏显式语义标签，而独立NLI模型忽视上下文显著性。需要融合两者的优势实现定向分析

Method: 两阶段流程：1) 基于token注意力分数筛选相关候选句 2) 用预训练NLI模型分类前提/矛盾关系，最后用注意力分数过滤显著关系

Result: 通过注意力机制与NLI的协同过滤，可高效提取文本中特定主张的最重要语义关系

Conclusion: 注意力显著性筛选与NLI语义分类的结合，为事实核查、论证挖掘等任务提供了定向分析的有效工具

Abstract: Finding the relationships between sentences in a document is crucial for
tasks like fact-checking, argument mining, and text summarization. A key
challenge is to identify which sentences act as premises or contradictions for
a specific claim. Existing methods often face a trade-off: transformer
attention mechanisms can identify salient textual connections but lack explicit
semantic labels, while Natural Language Inference (NLI) models can classify
relationships between sentence pairs but operate independently of contextual
saliency. In this work, we introduce a method that combines the strengths of
both approaches for a targeted analysis. Our pipeline first identifies
candidate sentences that are contextually relevant to a user-selected target
sentence by aggregating token-level attention scores. It then uses a pretrained
NLI model to classify each candidate as a premise (entailment) or
contradiction. By filtering NLI-identified relationships with attention-based
saliency scores, our method efficiently isolates the most significant semantic
relationships for any given claim in a text.

</details>


### [36] [The Power of Framing: How News Headlines Guide Search Behavior](https://arxiv.org/abs/2508.17131)
*Amrit Poudel,Maria Milkowski,Tim Weninger*

Main category: cs.CL

TL;DR: 标题框架显著影响用户后续搜索行为，冲突/策略框架破坏搜索连贯性，情景框架促进具体查询，框架效应具有短期持续性


<details>
  <summary>Details</summary>
Motivation: 探索标题框架对用户信息搜索行为的持续影响机制，填补框架效应在后续行为研究中的空白

Method: 通过控制实验让参与者进行查询并选择特定语言框架过滤的标题，测量不同框架对后续搜索模式的影响

Result: 冲突/策略框架导致查询连贯性下降31%，情景框架比主题框架多产生42%具体查询，框架持续性在10分钟后衰减60%

Conclusion: 搜索引擎呈现框架会持续引导用户信息寻求方向，这对搜索算法设计和数字素养教育具有重要启示

Abstract: Search engines play a central role in how people gather information, but
subtle cues like headline framing may influence not only what users believe but
also how they search. While framing effects on judgment are well documented,
their impact on subsequent search behavior is less understood. We conducted a
controlled experiment where participants issued queries and selected from
headlines filtered by specific linguistic frames. Headline framing
significantly shaped follow-up queries: conflict and strategy frames disrupted
alignment with prior selections, while episodic frames led to more concrete
queries than thematic ones. We also observed modest short-term frame
persistence that declined over time. These results suggest that even brief
exposure to framing can meaningfully alter the direction of users
information-seeking behavior.

</details>


### [37] [Geolocation-Aware Robust Spoken Language Identification](https://arxiv.org/abs/2508.17148)
*Qingzheng Wang,Hye-jin Shim,Jiancheng Sun,Shinji Watanabe*

Main category: cs.CL

TL;DR: 提出地理定位感知的语音识别模型，通过引入地理信息增强对方言和口音的统一表征能力


<details>
  <summary>Details</summary>
Motivation: 现有自监督语音识别模型对同一语言的方言和口音分类效果不佳

Method: 引入语言级地理定位预测作为辅助任务，将预测向量作为条件信号注入中间表征层

Result: 在6个多语言数据集上实现SOTA，FLEURS准确率97.7%，ML-SUPERB方言集提升9.7%

Conclusion: 地理条件注入有效提升模型对语言内部变体的鲁棒性和跨领域泛化能力

Abstract: While Self-supervised Learning (SSL) has significantly improved Spoken
Language Identification (LID), existing models often struggle to consistently
classify dialects and accents of the same language as a unified class. To
address this challenge, we propose geolocation-aware LID, a novel approach that
incorporates language-level geolocation information into the SSL-based LID
model. Specifically, we introduce geolocation prediction as an auxiliary task
and inject the predicted vectors into intermediate representations as
conditioning signals. This explicit conditioning encourages the model to learn
more unified representations for dialectal and accented variations. Experiments
across six multilingual datasets demonstrate that our approach improves
robustness to intra-language variations and unseen domains, achieving new
state-of-the-art accuracy on FLEURS (97.7%) and 9.7% relative improvement on
ML-SUPERB 2.0 dialect set.

</details>


### [38] [Natural Language Satisfiability: Exploring the Problem Distribution and Evaluating Transformer-based Language Models](https://arxiv.org/abs/2508.17153)
*Tharindu Madusanka,Ian Pratt-Hartmann,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: 研究探讨不同计算复杂度类别和语法结构对Transformer语言模型学习推理规则的影响，并通过实证分析问题分布。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分分析自然语言可满足性问题实例的计算复杂度差异及语法结构对模型学习的影响，需系统评估模型在不同分布下的表现。

Method: 构建不同复杂度类别的自然语言可满足性问题数据集，测试TLMs的推理能力，并进行问题分布统计实证研究。

Result: 问题复杂度与语法结构显著影响模型推理表现，且真实场景中的问题分布存在明显类型偏向性。

Conclusion: 评估TLMs需考虑问题复杂度分类与真实分布特征，未来应针对性优化模型对不同逻辑结构的适应性。

Abstract: Efforts to apply transformer-based language models (TLMs) to the problem of
reasoning in natural language have enjoyed ever-increasing success in recent
years. The most fundamental task in this area to which nearly all others can be
reduced is that of determining satisfiability. However, from a logical point of
view, satisfiability problems vary along various dimensions, which may affect
TLMs' ability to learn how to solve them. The problem instances of
satisfiability in natural language can belong to different computational
complexity classes depending on the language fragment in which they are
expressed. Although prior research has explored the problem of natural language
satisfiability, the above-mentioned point has not been discussed adequately.
Hence, we investigate how problem instances from varying computational
complexity classes and having different grammatical constructs impact TLMs'
ability to learn rules of inference. Furthermore, to faithfully evaluate TLMs,
we conduct an empirical study to explore the distribution of satisfiability
problems.

</details>


### [39] [SPORTSQL: An Interactive System for Real-Time Sports Reasoning and Visualization](https://arxiv.org/abs/2508.17157)
*Sebastian Martinez,Naman Ahuja,Fenil Bardoliya,Chris Bryan,Vivek Gupta*

Main category: cs.CL

TL;DR: SPORTSQL系统通过自然语言接口实现英超动态数据的SQL查询与可视化，结合LLM技术构建实时数据库查询系统并建立DSQABENCH评估基准。


<details>
  <summary>Details</summary>
Motivation: 解决非专业用户难以实时探索动态体育数据的问题，传统SQL查询存在技术门槛，需通过自然语言交互降低使用难度。

Method: 1. 模块化系统架构实现自然语言到SQL的转换
2. 利用LLM进行模式链接、查询解析与可视化选择
3. 基于实时FPL数据构建时序索引数据库
4. 创建含1,700+标注查询的DSQABENCH评估基准

Result: 成功演示非专业用户通过对话界面探索动态赛事数据的能力，验证系统在复杂查询解析和可视化输出方面的有效性。

Conclusion: SPORTSQL通过LLM的符号推理能力架起自然语言与数据库查询的桥梁，DSQABENCH为动态问答系统研究提供标准化评估框架。

Abstract: We present a modular, interactive system, SPORTSQL, for natural language
querying and visualization of dynamic sports data, with a focus on the English
Premier League (EPL). The system translates user questions into executable SQL
over a live, temporally indexed database constructed from real-time Fantasy
Premier League (FPL) data. It supports both tabular and visual outputs,
leveraging the symbolic reasoning capabilities of Large Language Models (LLMs)
for query parsing, schema linking, and visualization selection. To evaluate
system performance, we introduce the Dynamic Sport Question Answering benchmark
(DSQABENCH), comprising 1,700+ queries annotated with SQL programs, gold
answers, and database snapshots. Our demo highlights how non-expert users can
seamlessly explore evolving sports statistics through a natural, conversational
interface.

</details>


### [40] [Quantifying Language Disparities in Multilingual Large Language Models](https://arxiv.org/abs/2508.17162)
*Songbo Hu,Ivan Vulić,Anna Korhonen*

Main category: cs.CL

TL;DR: 提出包含三个可解释指标（性能实现率、变异系数、语言潜力）的评估框架，解决多语言模型评估中的混杂因素问题，揭示模型性能与语言公平性的非正相关关系


<details>
  <summary>Details</summary>
Motivation: 现有大规模多语言评估存在实验设置差异、目标语言选择、模型差异等混杂因素，导致评估结果碎片化且难以准确衡量语言间的真实性能差距

Method: 通过解构混杂变量，设计性能实现率、变异系数、语言潜力三个指标，并在11个多语言数据集上对13个模型变体进行实证分析

Result: 框架能更可靠测量模型性能（尤其低资源语言），发现模型整体性能提升未必带来跨语言公平性改善

Conclusion: 新评估框架为量化模型性能差异和语言资源差距提供新视角，强调多语言模型开发需平衡性能与公平性

Abstract: Results reported in large-scale multilingual evaluations are often fragmented
and confounded by factors such as target languages, differences in experimental
setups, and model choices. We propose a framework that disentangles these
confounding variables and introduces three interpretable metrics--the
performance realisation ratio, its coefficient of variation, and language
potential--enabling a finer-grained and more insightful quantification of
actual performance disparities across both (i) models and (ii) languages.
Through a case study of 13 model variants on 11 multilingual datasets, we
demonstrate that our framework provides a more reliable measurement of model
performance and language disparities, particularly for low-resource languages,
which have so far proven challenging to evaluate. Importantly, our results
reveal that higher overall model performance does not necessarily imply greater
fairness across languages.

</details>


### [41] [The Impact of Annotator Personas on LLM Behavior Across the Perspectivism Spectrum](https://arxiv.org/abs/2508.17164)
*Olufunke O. Sarumi,Charles Welch,Daniel Braun,Jörg Schlötterer*

Main category: cs.CL

TL;DR: 探究LLM在强弱数据视角主义下基于预定义标注者角色进行仇恨言论标注的能力，发现LLM标注在弱视角主义下表现优于人类，但强视角主义中未超越人类标注。


<details>
  <summary>Details</summary>
Motivation: 验证大语言模型在仇恨言论标注任务中如何模拟不同标注者视角，探索数据视角主义强弱对模型标注质量的影响。

Method: 通过预标注角色模板构建强弱数据视角谱系，对比LLM生成标注与传统标注者建模技术的表现差异。

Result: LLM选择性使用人口统计特征，弱视角主义下非依赖标注者信息的方法表现最优，强视角主义下LLM标注接近但未超越人类水平。

Conclusion: LLM标注具有视角聚合倾向，在弱数据视角主义场景更具优势，但需注意人口属性对齐问题以实现有效视角建模。

Abstract: In this work, we explore the capability of Large Language Models (LLMs) to
annotate hate speech and abusiveness while considering predefined annotator
personas within the strong-to-weak data perspectivism spectra. We evaluated
LLM-generated annotations against existing annotator modeling techniques for
perspective modeling. Our findings show that LLMs selectively use demographic
attributes from the personas. We identified prototypical annotators, with
persona features that show varying degrees of alignment with the original human
annotators. Within the data perspectivism paradigm, annotator modeling
techniques that do not explicitly rely on annotator information performed
better under weak data perspectivism compared to both strong data perspectivism
and human annotations, suggesting LLM-generated views tend towards aggregation
despite subjective prompting. However, for more personalized datasets tailored
to strong perspectivism, the performance of LLM annotator modeling approached,
but did not exceed, human annotators.

</details>


### [42] [Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models](https://arxiv.org/abs/2508.17184)
*Xudong Han,Junjie Yang,Tianyang Wang,Ziqian Bi,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: 本文系统综述大语言模型指令调优技术，涵盖数据构建、高效微调策略、多维评估体系及未来发展方向，提出数据算法人机协同的技术路线。


<details>
  <summary>Details</summary>
Motivation: 指令调优是实现大模型与人类意图对齐的关键技术，当前面临数据质量与成本平衡、计算效率提升、跨领域评估体系缺失等核心挑战。

Method: 采用三级分析框架：数据构建(专家标注/模型蒸馏/自改进)、微调策略(全参数调优/LoRA/前缀调优)、评估体系(安全性/实用性/领域适应性)。

Result: 揭示数据质量-成本平衡规律，验证参数高效微调方法在计算资源节省(最高达90%)和模型复用性的优势，建立跨领域评估基准框架。

Conclusion: 指令调优需深度融合数据生成、自适应优化与人类反馈，该研究为构建安全可靠的大模型对齐技术提供系统化方法论参考。

Abstract: Instruction tuning is a pivotal technique for aligning large language models
(LLMs) with human intentions, safety constraints, and domain-specific
requirements. This survey provides a comprehensive overview of the full
pipeline, encompassing (i) data collection methodologies, (ii) full-parameter
and parameter-efficient fine-tuning strategies, and (iii) evaluation protocols.
We categorized data construction into three major paradigms: expert annotation,
distillation from larger models, and self-improvement mechanisms, each offering
distinct trade-offs between quality, scalability, and resource cost.
Fine-tuning techniques range from conventional supervised training to
lightweight approaches, such as low-rank adaptation (LoRA) and prefix tuning,
with a focus on computational efficiency and model reusability. We further
examine the challenges of evaluating faithfulness, utility, and safety across
multilingual and multimodal scenarios, highlighting the emergence of
domain-specific benchmarks in healthcare, legal, and financial applications.
Finally, we discuss promising directions for automated data generation,
adaptive optimization, and robust evaluation frameworks, arguing that a closer
integration of data, algorithms, and human feedback is essential for advancing
instruction-tuned LLMs. This survey aims to serve as a practical reference for
researchers and practitioners seeking to design LLMs that are both effective
and reliably aligned with human intentions.

</details>


### [43] [Active Domain Knowledge Acquisition with \$100 Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains](https://arxiv.org/abs/2508.17202)
*Yang Wu,Raha Moraffah,Rujing Yao,Jinhong Yu,Zhimin Tao,Xiaozhong Liu*

Main category: cs.CL

TL;DR: 提出PU-ADKA框架，通过预算约束下的专家咨询机制提升LLMs在专业领域的表现，并创建CKAD基准数据集


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在药物研发等专业领域因缺乏专家知识导致的性能不足问题

Method: 设计选择性专家咨询系统，动态评估专家可用性/知识边界/咨询成本，通过PubMed模拟训练和药物开发团队实地验证

Result: 实验证明框架在预算限制下有效提升模型性能，并建立首个成本敏感型领域知识获取基准数据集CKAD

Conclusion: PU-ADKA为专业领域提供可扩展的LLM增强方案，CKAD数据集推动该领域研究发展

Abstract: Large Language Models (LLMs) have demonstrated an impressive level of general
knowledge. However, they often struggle in highly specialized and
cost-sensitive domains such as drug discovery and rare disease research due to
the lack of expert knowledge. In this paper, we propose a novel framework
(PU-ADKA) designed to efficiently enhance domain-specific LLMs by actively
engaging domain experts within a fixed budget. Unlike traditional fine-tuning
approaches, PU-ADKA selectively identifies and queries the most appropriate
expert from a team, taking into account each expert's availability, knowledge
boundaries, and consultation costs. We train PU-ADKA using simulations on
PubMed data and validate it through both controlled expert interactions and
real-world deployment with a drug development team, demonstrating its
effectiveness in enhancing LLM performance in specialized domains under strict
budget constraints. In addition to outlining our methodological innovations and
experimental results, we introduce a new benchmark dataset, CKAD, for
cost-effective LLM domain knowledge acquisition to foster further research in
this challenging area.

</details>


### [44] [SSFO: Self-Supervised Faithfulness Optimization for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.17225)
*Xiaqiang Tang,Yi Wang,Keyu Hu,Rui Xu,Chuang Li,Weigao Sun,Jian Li,Sihong Xie*

Main category: cs.CL

TL;DR: 提出自监督忠实性优化方法SSFO，通过上下文对比构建偏好数据对，利用改进的DPO损失实现无标注成本的RAG忠实性提升。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统存在忠实性幻觉问题，传统方法需要高成本监督训练或增加推理负担。需要无需标注、无额外推理成本的解决方案。

Method: 1. 构建上下文/无上下文输出对比的偏好数据 2. 改进DPO损失函数实现概率质量迁移 3. 通过likelihood displacement机制提升上下文对齐

Result: 在多个QA数据集达到SOTA忠实性（90.1% Acc），跨语言任务提升20.8%，保持98%指令跟随能力

Conclusion: SSFO首次实现自监督的RAG对齐，有效解决忠实性幻觉问题，具有零标注成本、强泛化性、兼容通用能力的核心优势

Abstract: Retrieval-Augmented Generation (RAG) systems require Large Language Models
(LLMs) to generate responses that are faithful to the retrieved context.
However, faithfulness hallucination remains a critical challenge, as existing
methods often require costly supervision and post-training or significant
inference burdens. To overcome these limitations, we introduce Self-Supervised
Faithfulness Optimization (SSFO), the first self-supervised alignment approach
for enhancing RAG faithfulness. SSFO constructs preference data pairs by
contrasting the model's outputs generated with and without the context.
Leveraging Direct Preference Optimization (DPO), SSFO aligns model faithfulness
without incurring labeling costs or additional inference burden. We
theoretically and empirically demonstrate that SSFO leverages a benign form of
\emph{likelihood displacement}, transferring probability mass from
parametric-based tokens to context-aligned tokens. Based on this insight, we
propose a modified DPO loss function to encourage likelihood displacement.
Comprehensive evaluations show that SSFO significantly outperforms existing
methods, achieving state-of-the-art faithfulness on multiple context-based
question-answering datasets. Notably, SSFO exhibits strong generalization,
improving cross-lingual faithfulness and preserving general
instruction-following capabilities. We release our code and model at the
anonymous link: https://github.com/chkwy/SSFO

</details>


### [45] [ClaimGen-CN: A Large-scale Chinese Dataset for Legal Claim Generation](https://arxiv.org/abs/2508.17234)
*Siying Zhou,Yiquan Wu,Hui Chen,Xavier Hu,Kun Kuang,Adam Jatowt,Ming Hu,Chunyan Zheng,Fei Wu*

Main category: cs.CL

TL;DR: 论文探索基于案件事实生成法律主张的任务，构建首个中文数据集ClaimGen-CN，设计包含事实性和清晰度的评估指标，并通过零样本测试揭示现有模型在事实精度和表达清晰度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有法律研究多聚焦专业群体，而缺乏帮助非专业人士（如原告）生成法律主张的探索。原告准确表达诉求对司法裁判具有指导意义，该领域尚未有系统研究。

Method: 1. 从真实法律纠纷构建ClaimGen-CN数据集
2. 设计二维评估指标（事实性+清晰度）
3. 对通用及法律领域大模型进行零样本评估

Result: 现有模型存在事实准确性不足（无法精确匹配案件细节）和表达模糊（法律术语使用不当）的双重缺陷，表明需要针对性优化法律主张生成任务。

Conclusion: 通过公开数据集推动该领域发展，强调当前法律AI需从专业服务向普惠型工具转型，提升非专业人士的司法可及性。

Abstract: Legal claims refer to the plaintiff's demands in a case and are essential to
guiding judicial reasoning and case resolution. While many works have focused
on improving the efficiency of legal professionals, the research on helping
non-professionals (e.g., plaintiffs) remains unexplored. This paper explores
the problem of legal claim generation based on the given case's facts. First,
we construct ClaimGen-CN, the first dataset for Chinese legal claim generation
task, from various real-world legal disputes. Additionally, we design an
evaluation metric tailored for assessing the generated claims, which
encompasses two essential dimensions: factuality and clarity. Building on this,
we conduct a comprehensive zero-shot evaluation of state-of-the-art general and
legal-domain large language models. Our findings highlight the limitations of
the current models in factual precision and expressive clarity, pointing to the
need for more targeted development in this domain. To encourage further
exploration of this important task, we will make the dataset publicly
available.

</details>


### [46] [Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation](https://arxiv.org/abs/2508.17250)
*Kaidong Feng,Zhu Sun,Hui Fang,Jie Yang,Wenyuan Liu,Yew-Soon Ong*

Main category: cs.CL

TL;DR: 提出RouteDK框架，通过混合LoRA专家架构动态路由两种蒸馏知识（通用规则+细粒度推理），解决知识冲突问题，在保持计算效率的同时实现优于教师模型和现有方法的捆绑生成效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)生成捆绑包时计算成本过高，而直接融合多种蒸馏知识会导致冲突，影响模型性能。需探索高效且无冲突的知识整合方法。

Method: 1) 提炼互补知识：高级知识(通用规则)+细粒度知识(会话级推理) 2) 构建LoRA专家架构：知识专属专家+基础专家 3) 动态融合模块：输入感知路由器动态分配权重 4) 推理增强模块：降低方差与次优推理

Result: 在三个公开数据集上，RouteDK达到与教师LLM相当/更优的准确率，推理效率显著提升，且超越现有最优捆绑生成方法。

Conclusion: 通过知识路由机制有效缓解冲突，首次实现学生模型在捆绑生成任务上同时达成高效率与高精度，为LLM高效应用提供新范式。

Abstract: Large Language Models (LLMs) have shown potential in automatic bundle
generation but suffer from prohibitive computational costs. Although knowledge
distillation offers a pathway to more efficient student models, our preliminary
study reveals that naively integrating diverse types of distilled knowledge
from teacher LLMs into student LLMs leads to knowledge conflict, negatively
impacting the performance of bundle generation. To address this, we propose
RouteDK, a framework for routing distilled knowledge through a mixture of LoRA
expert architecture. Specifically, we first distill knowledge from the teacher
LLM for bundle generation in two complementary types: high-level knowledge
(generalizable rules) and fine-grained knowledge (session-specific reasoning).
We then train knowledge-specific LoRA experts for each type of knowledge
together with a base LoRA expert. For effective integration, we propose a
dynamic fusion module, featuring an input-aware router, where the router
balances expert contributions by dynamically determining optimal weights based
on input, thereby effectively mitigating knowledge conflicts. To further
improve inference reliability, we design an inference-time enhancement module
to reduce variance and mitigate suboptimal reasoning. Experiments on three
public datasets show that our RouteDK achieves accuracy comparable to or even
better than the teacher LLM, while maintaining strong computational efficiency.
In addition, it outperforms state-of-the-art approaches for bundle generation.

</details>


### [47] [Are You Sure You're Positive? Consolidating Chain-of-Thought Agents with Uncertainty Quantification for Aspect-Category Sentiment Analysis](https://arxiv.org/abs/2508.17258)
*Filippos Ventirozos,Peter Appleby,Matthew Shardlow*

Main category: cs.CL

TL;DR: 提出结合思维链代理与LLM词元级不确定性评分的新方法，在标注数据稀缺场景下改进方面级情感分析效果。


<details>
  <summary>Details</summary>
Motivation: 监督学习方法依赖标注数据且存在领域迁移困难，利用LLM零样本能力可解决标注成本高和跨领域复现性问题。

Method: 基于Llama和Qwen不同参数规模模型，设计多思维链代理协作框架，引入token不确定性评分机制增强决策可靠性。

Result: 3B到70B+参数规模的模型实验验证了方法的实用性，并探讨无标注条件下的准确率评估方法论。

Conclusion: 为零样本场景下的情感分析提供高效解决方案，推动标注稀缺环境下模型评估标准的建立。

Abstract: Aspect-category sentiment analysis provides granular insights by identifying
specific themes within product reviews that are associated with particular
opinions. Supervised learning approaches dominate the field. However, data is
scarce and expensive to annotate for new domains. We argue that leveraging
large language models in a zero-shot setting is beneficial where the time and
resources required for dataset annotation are limited. Furthermore, annotation
bias may lead to strong results using supervised methods but transfer poorly to
new domains in contexts that lack annotations and demand reproducibility. In
our work, we propose novel techniques that combine multiple chain-of-thought
agents by leveraging large language models' token-level uncertainty scores. We
experiment with the 3B and 70B+ parameter size variants of Llama and Qwen
models, demonstrating how these approaches can fulfil practical needs and
opening a discussion on how to gauge accuracy in label-scarce conditions.

</details>


### [48] [From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users](https://arxiv.org/abs/2508.17281)
*Sadia Sultana Chowa,Riasad Alvi,Subhey Sadi Rahman,Md Abdur Rahman,Mohaimenul Azam Khan Raiaan,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam*

Main category: cs.CL

TL;DR: 综述探讨LLM作为自主代理的架构设计、工具集成及认知机制，分析68个数据集并提出10个未来研究方向


<details>
  <summary>Details</summary>
Motivation: 探索LLM作为决策代理的潜力，解决其在可验证推理、自我改进和个性化方面的应用挑战

Method: 采用结构化文献分析法，筛选2023-2025年顶级会议期刊论文，按单/多代理系统分类，结合外部工具整合策略评估

Result: 揭示LLM在复杂推理任务中的局限，现有评估体系覆盖不全，提出基于68个数据集的性能评估框架

Conclusion: LLM代理展现强大应用潜力但存在理论验证不足，需通过改进训练机制和评估体系实现突破性发展

Abstract: The pursuit of human-level artificial intelligence (AI) has significantly
advanced the development of autonomous agents and Large Language Models (LLMs).
LLMs are now widely utilized as decision-making agents for their ability to
interpret instructions, manage sequential tasks, and adapt through feedback.
This review examines recent developments in employing LLMs as autonomous agents
and tool users and comprises seven research questions. We only used the papers
published between 2023 and 2025 in conferences of the A* and A rank and Q1
journals. A structured analysis of the LLM agents' architectural design
principles, dividing their applications into single-agent and multi-agent
systems, and strategies for integrating external tools is presented. In
addition, the cognitive mechanisms of LLM, including reasoning, planning, and
memory, and the impact of prompting methods and fine-tuning procedures on agent
performance are also investigated. Furthermore, we evaluated current benchmarks
and assessment protocols and have provided an analysis of 68 publicly available
datasets to assess the performance of LLM-based agents in various tasks. In
conducting this review, we have identified critical findings on verifiable
reasoning of LLMs, the capacity for self-improvement, and the personalization
of LLM-based agents. Finally, we have discussed ten future research directions
to overcome these gaps.

</details>


### [49] [Handling Students Dropouts in an LLM-driven Interactive Online Course Using Language Models](https://arxiv.org/abs/2508.17310)
*Yuanchun Wang,Yiyang Fu,Jifan Yu,Daniel Zhang-Li,Zheyuan Zhang,Joy Lim Jia Yin,Yucheng Wang,Peng Zhou,Jing Zhang,Huiqin Liu*

Main category: cs.CL

TL;DR: 该论文通过实证研究发现MAIC课程中辍学行为与文本交互模式存在强关联，开发了准确率95.4%的CPADP预测框架，并验证了个性化召回策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究大规模AI赋能课程(MAIC)中辍学问题的三个核心：辍学诱因识别、预测模型构建、干预策略有效性验证。

Method: 1. 分析交互日志定义辍学行为
2. 提出课程进度自适应预测框架CPADP
3. 设计个性化邮件召回代理系统

Result: 在3000+学生的真实场景中，预测准确率最高达95.4%，召回策略有效覆盖不同背景的辍学风险群体。

Conclusion: 该研究为智能教育系统提供了完整的辍学问题分析-预测-干预方法论，证实了AI代理在在线教育中的实用价值。

Abstract: Interactive online learning environments, represented by Massive AI-empowered
Courses (MAIC), leverage LLM-driven multi-agent systems to transform passive
MOOCs into dynamic, text-based platforms, enhancing interactivity through LLMs.
This paper conducts an empirical study on a specific MAIC course to explore
three research questions about dropouts in these interactive online courses:
(1) What factors might lead to dropouts? (2) Can we predict dropouts? (3) Can
we reduce dropouts? We analyze interaction logs to define dropouts and identify
contributing factors. Our findings reveal strong links between dropout
behaviors and textual interaction patterns. We then propose a
course-progress-adaptive dropout prediction framework (CPADP) to predict
dropouts with at most 95.4% accuracy. Based on this, we design a personalized
email recall agent to re-engage at-risk students. Applied in the deployed MAIC
system with over 3,000 students, the feasibility and effectiveness of our
approach have been validated on students with diverse backgrounds.

</details>


### [50] [CultranAI at PalmX 2025: Data Augmentation for Cultural Knowledge Representation](https://arxiv.org/abs/2508.17324)
*Hunzalah Hassan Bhatti,Youssef Ahmed,Md Arid Hasan,Firoj Alam*

Main category: cs.CL

TL;DR: 开发CultranAI系统，通过数据增强和LoRA微调LLM提升阿拉伯文化知识任务表现，最终在盲测集排名第五。


<details>
  <summary>Details</summary>
Motivation: 提升阿拉伯文化知识在大型语言模型中的表征能力，并通过数据增强弥补现有数据集(PalmX)的不足。

Method: 1. 整合PalmX数据集与自建22K+文化相关多选题数据集
2. 基准测试多个LLM后选择Fanar-1-9B-Instruct
3. 使用LoRA方法对选定模型进行微调

Result: 开发集准确率84.1%，盲测集70.50%(排名第5)，显示模型在已知数据表现优异但泛化能力待提升。

Conclusion: 数据增强与LoRA微调有效提升文化任务表现，但需进一步优化模型泛化能力以应对新场景。

Abstract: In this paper, we report our participation to the PalmX cultural evaluation
shared task. Our system, CultranAI, focused on data augmentation and LoRA
fine-tuning of large language models (LLMs) for Arabic cultural knowledge
representation. We benchmarked several LLMs to identify the best-performing
model for the task. In addition to utilizing the PalmX dataset, we augmented it
by incorporating the Palm dataset and curated a new dataset of over 22K
culturally grounded multiple-choice questions (MCQs). Our experiments showed
that the Fanar-1-9B-Instruct model achieved the highest performance. We
fine-tuned this model on the combined augmented dataset of 22K+ MCQs. On the
blind test set, our submitted system ranked 5th with an accuracy of 70.50%,
while on the PalmX development set, it achieved an accuracy of 84.1%.

</details>


### [51] [Omne-R1: Learning to Reason with Memory for Multi-hop Question Answering](https://arxiv.org/abs/2508.17330)
*Boyuan Liu,Feng Ji,Jiayan Nan,Han Zhao,Weiling Chen,Shihao Xu,Xing Zhou*

Main category: cs.CL

TL;DR: 提出Omne-R1方法，通过多阶段训练流程提升无模式知识图谱的多跳问答能力


<details>
  <summary>Details</summary>
Motivation: 解决现有知识图谱和QA数据不足的局限，特别是针对复杂多跳问题的处理需求

Method: 采用包含两阶段强化学习和一阶段监督微调的多阶段训练框架，构建领域无关知识图谱并自动生成QA对

Result: 在复杂3+跳问题上取得显著性能提升，实验显示系统具备跨知识领域的强泛化能力

Conclusion: 提出的多阶段训练框架有效提升了多跳问答性能，特别是在复杂问题上展现出优越的领域适应能力

Abstract: This paper introduces Omne-R1, a novel approach designed to enhance multi-hop
question answering capabilities on schema-free knowledge graphs by integrating
advanced reasoning models. Our method employs a multi-stage training workflow,
including two reinforcement learning phases and one supervised fine-tuning
phase. We address the challenge of limited suitable knowledge graphs and QA
data by constructing domain-independent knowledge graphs and auto-generating QA
pairs. Experimental results show significant improvements in answering
multi-hop questions, with notable performance gains on more complex 3+ hop
questions. Our proposed training framework demonstrates strong generalization
abilities across diverse knowledge domains.

</details>


### [52] [DropLoRA: Sparse Low-Rank Adaptation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2508.17337)
*Haojie Zhang*

Main category: cs.CL

TL;DR: 提出DropLoRA方法，通过秩维度剪枝和动态子空间学习机制突破传统LoRA的静态子空间限制，显著提升大模型微调性能


<details>
  <summary>Details</summary>
Motivation: 传统LoRA的低秩更新存在静态子空间学习局限性，导致下游任务性能与全参数微调存在差距

Method: 在LoRA的两个低秩矩阵间插入剪枝模块，通过动态调整学习子空间实现参数高效优化

Result: 在LLaMA系列模型的常识推理、数学推理、代码生成等任务中全面超越LoRA

Conclusion: 动态低秩子空间学习机制有效突破传统参数高效微调方法瓶颈，为大规模语言模型适配提供新思路

Abstract: LoRA-based large model parameter-efficient fine-tuning (PEFT) methods use
low-rank de- composition to approximate updates to model parameters. However,
compared to full- parameter fine-tuning, low-rank updates often lead to a
performance gap in downstream tasks. To address this, we introduce DropLoRA, a
novel pruning-based approach that focuses on pruning the rank dimension. Unlike
conven- tional methods that attempt to overcome the low-rank bottleneck,
DropLoRA innovatively integrates a pruning module between the two low-rank
matrices in LoRA to simulate dy- namic subspace learning. This dynamic low-
rank subspace learning allows DropLoRA to overcome the limitations of
traditional LoRA, which operates within a static subspace. By continuously
adapting the learning subspace, DropLoRA significantly boosts performance
without incurring additional training or infer- ence costs. Our experimental
results demon- strate that DropLoRA consistently outperforms LoRA in
fine-tuning the LLaMA series across a wide range of large language model gener-
ation tasks, including commonsense reason- ing, mathematical reasoning, code
generation, and instruction-following. Our code is avail- able at
https://github.com/TayeeChang/DropLoRA.

</details>


### [53] [Capturing Legal Reasoning Paths from Facts to Law in Court Judgments using Knowledge Graphs](https://arxiv.org/abs/2508.17340)
*Ryoma Kondo,Riona Matsuoka,Takahiro Yoshida,Kazuyuki Yamasawa,Ryohei Hisano*

Main category: cs.CL

TL;DR: 论文提出通过提示式大语言模型构建法律知识图谱，从648份日本行政判决中显式捕捉法律推理的层次结构


<details>
  <summary>Details</summary>
Motivation: 现有方法(包括大语言模型)难以准确识别法律背景、追踪事实与法律规范的关系，且可能错误表达司法推理的层次结构，阻碍对法律实践的分析

Method: 使用提示式大语言模型提取法律推理组件，标准化法律条文引用，通过法律推理本体论连接事实、规范与法律应用

Result: 系统在专家标注数据评估中，事实关联法律条文的检索准确率优于大语言模型基线和检索增强方法

Conclusion: 构建的机器可读知识图谱使隐含的司法推理显式化，为理解法律实践中的规范应用提供了结构化基础

Abstract: Court judgments reveal how legal rules have been interpreted and applied to
facts, providing a foundation for understanding structured legal reasoning.
However, existing automated approaches for capturing legal reasoning, including
large language models, often fail to identify the relevant legal context, do
not accurately trace how facts relate to legal norms, and may misrepresent the
layered structure of judicial reasoning. These limitations hinder the ability
to capture how courts apply the law to facts in practice. In this paper, we
address these challenges by constructing a legal knowledge graph from 648
Japanese administrative court decisions. Our method extracts components of
legal reasoning using prompt-based large language models, normalizes references
to legal provisions, and links facts, norms, and legal applications through an
ontology of legal inference. The resulting graph captures the full structure of
legal reasoning as it appears in real court decisions, making implicit
reasoning explicit and machine-readable. We evaluate our system using expert
annotated data, and find that it achieves more accurate retrieval of relevant
legal provisions from facts than large language model baselines and
retrieval-augmented methods.

</details>


### [54] [The Arabic Generality Score: Another Dimension of Modeling Arabic Dialectness](https://arxiv.org/abs/2508.17347)
*Sanad Shaban,Nizar Habash*

Main category: cs.CL

TL;DR: 提出阿拉伯语通用性评分(AGS)作为ALDi的补充指标，通过词对齐和词源感知编辑距离量化词汇跨方言通用性，提升阿拉伯方言连续建模


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯方言NLP模型将方言视为离散类别，ALDi指标单维度简化复杂方言差异，需补充多维度分析工具

Method: 构建包含词对齐+词源感知编辑距离+平滑处理的标注流程，训练上下文敏感的AGS回归预测模型

Result: 在多方言基准测试中超越包括state-of-the-art方言识别系统在内的基线模型

Conclusion: AGS提供可扩展、语言学基础的词汇通用性建模方法，丰富了阿拉伯方言连续表征体系

Abstract: Arabic dialects form a diverse continuum, yet NLP models often treat them as
discrete categories. Recent work addresses this issue by modeling dialectness
as a continuous variable, notably through the Arabic Level of Dialectness
(ALDi). However, ALDi reduces complex variation to a single dimension. We
propose a complementary measure: the Arabic Generality Score (AGS), which
quantifies how widely a word is used across dialects. We introduce a pipeline
that combines word alignment, etymology-aware edit distance, and smoothing to
annotate a parallel corpus with word-level AGS. A regression model is then
trained to predict AGS in context. Our approach outperforms strong baselines,
including state-of-the-art dialect ID systems, on a multi-dialect benchmark.
AGS offers a scalable, linguistically grounded way to model lexical generality,
enriching representations of Arabic dialectness.

</details>


### [55] [UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via HUMAIN Chat](https://arxiv.org/abs/2508.17378)
*Omer Nacar*

Main category: cs.CL

TL;DR: ALLaM-34B阿拉伯语大模型在综合评估中展现出优异的语言处理、推理能力和文化适应性，具备实际部署价值。


<details>
  <summary>Details</summary>
Motivation: 针对现有大语言模型在阿拉伯语文化及语言特性捕捉上的不足，沙特数据与AI管理局开发了ALLaM系列模型，本研究旨在系统评估其旗舰模型ALLaM-34B的实际表现。

Method: 通过包含23个提示模板的测试集（覆盖现代标准阿拉伯语、方言、代码转换等7大维度），收集115组输出并由GPT-5/Gemini/Claude三大模型进行5轮评分，采用置信区间统计和热力图可视化分析方法。

Result: 生成任务(4.92/5)和代码转换(4.92)表现最佳，标准阿拉伯语处理(4.74)、推理能力(4.64)稳健，方言适配(4.21)显著提升，安全性能稳定(4.54)。

Conclusion: ALLaM-34B作为文化适配的阿拉伯语大模型，在技术实力和应用成熟度方面均达到行业领先水平，具备实际部署的可靠性。

Abstract: Large language models (LLMs) trained primarily on English corpora often
struggle to capture the linguistic and cultural nuances of Arabic. To address
this gap, the Saudi Data and AI Authority (SDAIA) introduced the $ALLaM$ family
of Arabic-focused models. The most capable of these available to the public,
$ALLaM-34B$, was subsequently adopted by HUMAIN, who developed and deployed
HUMAIN Chat, a closed conversational web service built on this model. This
paper presents an expanded and refined UI-level evaluation of $ALLaM-34B$.
Using a prompt pack spanning modern standard Arabic, five regional dialects,
code-switching, factual knowledge, arithmetic and temporal reasoning, creative
generation, and adversarial safety, we collected 115 outputs (23 prompts times
5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,
Claude Sonnet-4). We compute category-level means with 95\% confidence
intervals, analyze score distributions, and visualize dialect-wise metric heat
maps. The updated analysis reveals consistently high performance on generation
and code-switching tasks (both averaging 4.92/5), alongside strong results in
MSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect
fidelity (4.21/5). Safety-related prompts show stable, reliable performance of
(4.54/5). Taken together, these results position $ALLaM-34B$ as a robust and
culturally grounded Arabic LLM, demonstrating both technical strength and
practical readiness for real-world deployment.

</details>


### [56] [Agent-Testing Agent: A Meta-Agent for Automated Testing and Evaluation of Conversational AI Agents](https://arxiv.org/abs/2508.17393)
*Sameer Komoravolu,Khalil Mrini*

Main category: cs.CL

TL;DR: 提出Agent-Testing Agent（ATA），一种通过代码分析、对抗测试和自适应难度调整的元代理系统，能在20-30分钟内发现LLM代理的多样化严重故障，效率显著优于人工标注。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理评估依赖静态基准和小规模人工研究，缺乏动态、高效、可扩展的测试方法，需系统化测试框架暴露代理弱点。

Method: 结合静态代码分析、设计者问询、文献挖掘和角色驱动对抗测试，通过LLM评委反馈动态调整测试难度，生成证据支持的测试案例。

Result: ATA在旅行规划和维基写作任务中比专家标注多发现23%严重故障（p<0.01），时间效率提升98%，且故障报告含定量指标和定性诊断。

Conclusion: ATA为可复现的代理测试提供方法论和开源工具，代码分析与网络搜索的消融实验证明结构化测试生成对校准评估指标的关键作用。

Abstract: LLM agents are increasingly deployed to plan, retrieve, and write with tools,
yet evaluation still leans on static benchmarks and small human studies. We
present the Agent-Testing Agent (ATA), a meta-agent that combines static code
analysis, designer interrogation, literature mining, and persona-driven
adversarial test generation whose difficulty adapts via judge feedback. Each
dialogue is scored with an LLM-as-a-Judge (LAAJ) rubric and used to steer
subsequent tests toward the agent's weakest capabilities. On a travel planner
and a Wikipedia writer, the ATA surfaces more diverse and severe failures than
expert annotators while matching severity, and finishes in 20--30 minutes
versus ten-annotator rounds that took days. Ablating code analysis and web
search increases variance and miscalibration, underscoring the value of
evidence-grounded test generation. The ATA outputs quantitative metrics and
qualitative bug reports for developers. We release the full methodology and
open-source implementation for reproducible agent testing:
https://github.com/KhalilMrini/Agent-Testing-Agent

</details>


### [57] [DashboardQA: Benchmarking Multimodal Agents for Question Answering on Interactive Dashboards](https://arxiv.org/abs/2508.17398)
*Aaryaman Kartha,Ahmed Masry,Mohammed Saidul Islam,Thinh Lang,Shadikur Rahman,Ridwan Mahbub,Mizanur Rahman,Mahir Ahmed,Md Rizwan Parvez,Enamul Hoque,Shafiq Joty*

Main category: cs.CL

TL;DR: 提出首个评估视觉语言GUI代理在交互式仪表板上理解和推理能力的基准测试DashboardQA


<details>
  <summary>Details</summary>
Motivation: 现有问答基准主要关注静态图表，缺乏对交互式仪表板的评估能力，难以准确衡量现代多模态GUI代理的真实表现

Method: 收集112个Tableau交互仪表盘，构建包含405个问题的五类评估集（多选/事实/假设/多仪表盘/对话式）

Result: 主流代理表现欠佳（Gemini-Pro-2.5准确率38.69%，OpenAI CUA仅22.69%），暴露出元素定位、交互规划和推理能力不足

Conclusion: DashboardQA填补交互式仪表板评估空白，揭示现有代理局限性，推动开发更强大的GUI推理代理，数据集已开源

Abstract: Dashboards are powerful visualization tools for data-driven decision-making,
integrating multiple interactive views that allow users to explore, filter, and
navigate data. Unlike static charts, dashboards support rich interactivity,
which is essential for uncovering insights in real-world analytical workflows.
However, existing question-answering benchmarks for data visualizations largely
overlook this interactivity, focusing instead on static charts. This limitation
severely constrains their ability to evaluate the capabilities of modern
multimodal agents designed for GUI-based reasoning. To address this gap, we
introduce DashboardQA, the first benchmark explicitly designed to assess how
vision-language GUI agents comprehend and interact with real-world dashboards.
The benchmark includes 112 interactive dashboards from Tableau Public and 405
question-answer pairs with interactive dashboards spanning five categories:
multiple-choice, factoid, hypothetical, multi-dashboard, and conversational. By
assessing a variety of leading closed- and open-source GUI agents, our analysis
reveals their key limitations, particularly in grounding dashboard elements,
planning interaction trajectories, and performing reasoning. Our findings
indicate that interactive dashboard reasoning is a challenging task overall for
all the VLMs evaluated. Even the top-performing agents struggle; for instance,
the best agent based on Gemini-Pro-2.5 achieves only 38.69% accuracy, while the
OpenAI CUA agent reaches just 22.69%, demonstrating the benchmark's significant
difficulty. We release DashboardQA at https://github.com/vis-nlp/DashboardQA

</details>


### [58] [DS@GT at CheckThat! 2025: A Simple Retrieval-First, LLM-Backed Framework for Claim Normalization](https://arxiv.org/abs/2508.17402)
*Aleksandar Pramov,Jiangqin Ma,Bina Patel*

Main category: cs.CL

TL;DR: 提出轻量级检索优先+LLM支持的声明规范化方案，在单语种任务表现优异但零样本效果欠佳


<details>
  <summary>Details</summary>
Motivation: 声明规范化是自动事实核查系统的核心环节，需处理社交媒体等噪声数据为标准化声明

Method: 构建动态提示GPT-4o-mini（上下文学习）与训练集直接检索结合的混合流程

Result: 官方测试集13种语言中7种排名第一，但零样本场景表现显著下降

Conclusion: 验证了检索优先方案在单语种任务的有效性，暴露了零样本泛化能力不足的局限性

Abstract: Claim normalization is an integral part of any automatic fact-check
verification system. It parses the typically noisy claim data, such as social
media posts into normalized claims, which are then fed into downstream veracity
classification tasks. The CheckThat! 2025 Task 2 focuses specifically on claim
normalization and spans 20 languages under monolingual and zero-shot
conditions. Our proposed solution consists of a lightweight
\emph{retrieval-first, LLM-backed} pipeline, in which we either dynamically
prompt a GPT-4o-mini with in-context examples, or retrieve the closest
normalization from the train dataset directly. On the official test set, the
system ranks near the top for most monolingual tracks, achieving first place in
7 out of of the 13 languages. In contrast, the system underperforms in the
zero-shot setting, highlighting the limitation of the proposed solution.

</details>


### [59] [MahaParaphrase: A Marathi Paraphrase Detection Corpus and BERT-based Models](https://arxiv.org/abs/2508.17444)
*Suramya Jadhav,Abhay Shanbhag,Amogh Thakurdesai,Ridhima Sinare,Ananya Joshi,Raviraj Joshi*

Main category: cs.CL

TL;DR: 提出了L3Cube-MahaParaphrase数据集，包含8000句人工标注的马拉地语复述对，并测试了BERT模型的性能。


<details>
  <summary>Details</summary>
Motivation: 印度语言因形态复杂、文字多样且标注数据稀缺，亟需高质量复述语料库支持NLP任务。

Method: 人工专家标注8000对马拉地语句子（复述/非复述），使用标准BERT模型进行基准测试。

Result: 公开了基于Transformer的BERT模型在该数据集上的性能表现（具体指标未提及）

Conclusion: 该资源填补了马拉地语复述数据空白，通过开源促进低资源语言NLP研究。

Abstract: Paraphrases are a vital tool to assist language understanding tasks such as
question answering, style transfer, semantic parsing, and data augmentation
tasks. Indic languages are complex in natural language processing (NLP) due to
their rich morphological and syntactic variations, diverse scripts, and limited
availability of annotated data. In this work, we present the
L3Cube-MahaParaphrase Dataset, a high-quality paraphrase corpus for Marathi, a
low resource Indic language, consisting of 8,000 sentence pairs, each annotated
by human experts as either Paraphrase (P) or Non-paraphrase (NP). We also
present the results of standard transformer-based BERT models on these
datasets. The dataset and model are publicly shared at
https://github.com/l3cube-pune/MarathiNLP

</details>


### [60] [Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD](https://arxiv.org/abs/2508.17450)
*Bryan Chen Zhengyu Tan,Daniel Wai Kit Chin,Zhengyuan Liu,Nancy F. Chen,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 提出DuET-PD框架评估大模型在说服对话中的立场变化，并开发Holistic DPO训练方法提升模型抗误导能力


<details>
  <summary>Details</summary>
Motivation: 大模型在说服性对话中难以平衡错误信息轻信与有效修正抵抗，存在可靠性部署风险

Method: 引入双维度评估框架DuET-PD（纠正/误导 × 知识/安全），提出平衡正负样本的Holistic DPO训练方法

Result: GPT-4o在持续误导下知识准确率仅27.32%；Holistic DPO使Llama-3安全场景准确率从4.21%提升至76.54%

Conclusion: DuET-PD框架与Holistic DPO方法为提升多轮对话可靠性提供了有效解决方案，代码已开源

Abstract: Large Language Models (LLMs) can struggle to balance gullibility to
misinformation and resistance to valid corrections in persuasive dialogues, a
critical challenge for reliable deployment. We introduce DuET-PD (Dual
Evaluation for Trust in Persuasive Dialogues), a framework evaluating
multi-turn stance-change dynamics across dual dimensions: persuasion type
(corrective/misleading) and domain (knowledge via MMLU-Pro, and safety via
SALAD-Bench). We find that even a state-of-the-art model like GPT-4o achieves
only 27.32% accuracy in MMLU-Pro under sustained misleading persuasions.
Moreover, results reveal a concerning trend of increasing sycophancy in newer
open-source models. To address this, we introduce Holistic DPO, a training
approach balancing positive and negative persuasion examples. Unlike prompting
or resist-only training, Holistic DPO enhances both robustness to
misinformation and receptiveness to corrections, improving
Llama-3.1-8B-Instruct's accuracy under misleading persuasion in safety contexts
from 4.21% to 76.54%. These contributions offer a pathway to developing more
reliable and adaptable LLMs for multi-turn dialogue. Code is available at
https://github.com/Social-AI-Studio/DuET-PD.

</details>


### [61] [Evaluating the Impact of Verbal Multiword Expressions on Machine Translation](https://arxiv.org/abs/2508.17458)
*Linfeng Liu,Saptarshi Ghosh,Tianyu Jiang*

Main category: cs.CL

TL;DR: VMWEs对机器翻译质量有负面影响，基于LLM的改写方法可显著提升动词习语和动助结构的翻译质量


<details>
  <summary>Details</summary>
Motivation: 由于动词多词表达式（VMWEs）的复杂性和非组合性特征，现有机器翻译模型在处理这类语言现象时仍存在明显不足，需系统评估其对翻译质量的影响并探索改进方案

Method: 使用多语言机器翻译数据集中的VMWE实例，结合既有MWE数据集，评估主流翻译系统表现，并提出LLM辅助的VMWE字面化改写策略

Result: 实验表明VMWEs普遍降低翻译质量，而改写方法使动词习语和动助结构的翻译质量提升达显著水平

Conclusion: 本研究不仅量化了VMWEs对机器翻译的影响，还验证了语义改写策略的有效性，为优化NLP系统处理复杂语言结构提供了新思路

Abstract: Verbal multiword expressions (VMWEs) present significant challenges for
natural language processing due to their complex and often non-compositional
nature. While machine translation models have seen significant improvement with
the advent of language models in recent years, accurately translating these
complex linguistic structures remains an open problem. In this study, we
analyze the impact of three VMWE categories -- verbal idioms, verb-particle
constructions, and light verb constructions -- on machine translation quality
from English to multiple languages. Using both established multiword expression
datasets and sentences containing these language phenomena extracted from
machine translation datasets, we evaluate how state-of-the-art translation
systems handle these expressions. Our experimental results consistently show
that VMWEs negatively affect translation quality. We also propose an LLM-based
paraphrasing approach that replaces these expressions with their literal
counterparts, demonstrating significant improvement in translation quality for
verbal idioms and verb-particle constructions.

</details>


### [62] [Efficient Zero-Shot Long Document Classification by Reducing Context Through Sentence Ranking](https://arxiv.org/abs/2508.17490)
*Prathamesh Kokate,Mitali Sarnaik,Manavi Khopade,Mukta Takalikar,Raviraj Joshi*

Main category: cs.CL

TL;DR: 提出基于TF-IDF句子排序的零样本长文本分类方法，保留50%关键句子即可保持精度并降低35%推理时间。


<details>
  <summary>Details</summary>
Motivation: Transformer模型（如BERT）受限于输入长度和计算效率，难以处理长文本分类。需要不改变模型结构的高效零样本解决方案。

Method: 使用TF-IDF句子排序策略筛选关键内容，适配短文本训练模型至长文档分类，在马拉地语新闻数据集测试三种上下文压缩策略。

Result: 保留前50%高排名句子时，分类性能与完整文档相当，推理时间减少35%。

Conclusion: 句子排序是简单有效的零样本长文本分类技术，验证了上下文压缩策略在保持模型性能同时提升计算效率的可行性。

Abstract: Transformer-based models like BERT excel at short text classification but
struggle with long document classification (LDC) due to input length
limitations and computational inefficiencies. In this work, we propose an
efficient, zero-shot approach to LDC that leverages sentence ranking to reduce
input context without altering the model architecture. Our method enables the
adaptation of models trained on short texts, such as headlines, to long-form
documents by selecting the most informative sentences using a TF-IDF-based
ranking strategy. Using the MahaNews dataset of long Marathi news articles, we
evaluate three context reduction strategies that prioritize essential content
while preserving classification accuracy. Our results show that retaining only
the top 50\% ranked sentences maintains performance comparable to full-document
inference while reducing inference time by up to 35\%. This demonstrates that
sentence ranking is a simple yet effective technique for scalable and efficient
zero-shot LDC.

</details>


### [63] [Improving French Synthetic Speech Quality via SSML Prosody Control](https://arxiv.org/abs/2508.17494)
*Nassima Ould Ouali,Awais Hussain Sani,Ruben Bueno,Jonah Dauvet,Tim Luka Horstmann,Eric Moulines*

Main category: cs.CL

TL;DR: 提出首个端到端SSML标签自动生成框架，通过双QLoRA微调模型实现法语TSS的韵律控制，显著提升合成语音自然度（MOS从3.20→3.87）


<details>
  <summary>Details</summary>
Motivation: 商用TTS系统因韵律控制有限导致合成语音表现力不足，法语领域尤其缺乏有效的SSML自动化生成方案

Method: 采用级联架构：1) 短语停顿位置预测模型 2) 韵律参数回归模型，基于14小时法语播客数据训练，兼容商用TTS系统

Result: 客观指标：停顿预测F1达99.2%，韵律参数MAE降低25-40%；主观评估：MOS提升21%（p<0.005），83%听众偏好增强语音

Conclusion: 通过SSML自动化生成显著缩小法语合成语音与自然语音的表现差距，代码已开源推动工业应用

Abstract: Despite recent advances, synthetic voices often lack expressiveness due to
limited prosody control in commercial text-to-speech (TTS) systems. We
introduce the first end-to-end pipeline that inserts Speech Synthesis Markup
Language (SSML) tags into French text to control pitch, speaking rate, volume,
and pause duration. We employ a cascaded architecture with two QLoRA-fine-tuned
Qwen 2.5-7B models: one predicts phrase-break positions and the other performs
regression on prosodic targets, generating commercial TTS-compatible SSML
markup. Evaluated on a 14-hour French podcast corpus, our method achieves 99.2%
F1 for break placement and reduces mean absolute error on pitch, rate, and
volume by 25-40% compared with prompting-only large language models (LLMs) and
a BiLSTM baseline. In perceptual evaluation involving 18 participants across
over 9 hours of synthesized audio, SSML-enhanced speech generated by our
pipeline significantly improves naturalness, with the mean opinion score
increasing from 3.20 to 3.87 (p < 0.005). Additionally, 15 of 18 listeners
preferred our enhanced synthesis. These results demonstrate substantial
progress in bridging the expressiveness gap between synthetic and natural
French speech. Our code is publicly available at
https://github.com/hi-paris/Prosody-Control-French-TTS.

</details>


### [64] [Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?](https://arxiv.org/abs/2508.17536)
*Hyeong Kyu Choi,Xiaojin Zhu,Yixuan Li*

Main category: cs.CL

TL;DR: 多数投票机制主导多智能体辩论性能提升，辩论过程需校正干预才能有效增强模型表现


<details>
  <summary>Details</summary>
Motivation: 探究多智能体辩论（MAD）中真正影响性能的核心要素，厘清多数投票机制与智能体间辩论各自的作用机制

Method: 1. 实验解耦多数投票与智能体辩论的贡献
2. 建立辩论过程的随机过程理论框架
3. 通过信念轨迹鞅理论证明辩论的固有局限性
4. 设计校正性干预策略验证理论发现

Result: 在7个NLP基准测试中：
- 多数投票贡献了83%的性能增益
- 辩论过程单独作用时预期正确性无显著提升
- 定向校正干预可使辩论有效性提升27%

Conclusion: 多数投票机制相比复杂辩论流程更具实用性优势，建议实际应用中优先考虑集成学习方法，辩论机制需配合校正策略才能有效发挥作用

Abstract: Multi-Agent Debate~(MAD) has emerged as a promising paradigm for improving
the performance of large language models through collaborative reasoning.
Despite recent advances, the key factors driving MAD's effectiveness remain
unclear. In this work, we disentangle MAD into two key components--Majority
Voting and inter-agent Debate--and assess their respective contributions.
Through extensive experiments across seven NLP benchmarks, we find that
Majority Voting alone accounts for most of the performance gains typically
attributed to MAD. To explain this, we propose a theoretical framework that
models debate as a stochastic process. We prove that it induces a martingale
over agents' belief trajectories, implying that debate alone does not improve
expected correctness. Guided by these insights, we demonstrate that targeted
interventions, by biasing the belief update toward correction, can meaningfully
enhance debate effectiveness. Overall, our findings suggest that while MAD has
potential, simple ensembling methods remain strong and more reliable
alternatives in many practical settings. Code is released in
https://github.com/deeplearning-wisc/debate-or-vote.

</details>


### [65] [Humanizing Machines: Rethinking LLM Anthropomorphism Through a Multi-Level Framework of Design](https://arxiv.org/abs/2508.17573)
*Yunze Xiao,Lynnette Hui Xian Ng,Jiarui Liu,Mona T. Diab*

Main category: cs.CL

TL;DR: 将LLM的拟人化特征视为可调节的设计概念，提出四维线索分类框架并倡导功能导向评估


<details>
  <summary>Details</summary>
Motivation: 当前研究过度关注拟人化风险而缺乏设计指导，需建立主动调节拟人化程度的设计范式来优化人机互动

Method: 通过多学科理论整合，构建设计者线索嵌入与解释者认知响应的互动框架，提出感知/语言/行为/认知四维度线索分类

Result: 建立统一的设计分类体系，提供可操作的设计杠杆，并推动功能导向的拟人化评估标准

Conclusion: 拟人化设计应被主动调控以实现用户目标，通过多学科框架优化人机协作，需发展更系统的功能导向评估方法

Abstract: Large Language Models (LLMs) increasingly exhibit \textbf{anthropomorphism}
characteristics -- human-like qualities portrayed across their outlook,
language, behavior, and reasoning functions. Such characteristics enable more
intuitive and engaging human-AI interactions. However, current research on
anthropomorphism remains predominantly risk-focused, emphasizing over-trust and
user deception while offering limited design guidance. We argue that
anthropomorphism should instead be treated as a \emph{concept of design} that
can be intentionally tuned to support user goals. Drawing from multiple
disciplines, we propose that the anthropomorphism of an LLM-based artifact
should reflect the interaction between artifact designers and interpreters.
This interaction is facilitated by cues embedded in the artifact by the
designers and the (cognitive) responses of the interpreters to the cues. Cues
are categorized into four dimensions: \textit{perceptive, linguistic,
behavioral}, and \textit{cognitive}. By analyzing the manifestation and
effectiveness of each cue, we provide a unified taxonomy with actionable levers
for practitioners. Consequently, we advocate for function-oriented evaluations
of anthropomorphic design.

</details>


### [66] [CausalSent: Interpretable Sentiment Classification with RieszNet](https://arxiv.org/abs/2508.17576)
*Daniel Frees,Martin Pollack*

Main category: cs.CL

TL;DR: 开发CausalSent框架，通过双头RieszNet架构将因果效应估计MAE降低2-3倍，并验证'love'词汇在影评中+2.9%情感影响


<details>
  <summary>Details</summary>
Motivation: 解决NLP模型决策黑箱问题，结合因果推断提升文本分类器的可解释性

Method: 构建双头RieszNet神经网络架构，优化处理效应估计精度

Result: 半合成IMDB数据MAE降低2-3倍，实证显示'love'词使积极情感概率提升2.9%

Conclusion: CausalSent框架有效提升因果效应估计精度，为文本特征因果分析提供可解释工具

Abstract: Despite the overwhelming performance improvements offered by recent natural
language procesing (NLP) models, the decisions made by these models are largely
a black box. Towards closing this gap, the field of causal NLP combines causal
inference literature with modern NLP models to elucidate causal effects of text
features. We replicate and extend Bansal et al's work on regularizing text
classifiers to adhere to estimated effects, focusing instead on model
interpretability. Specifically, we focus on developing a two-headed
RieszNet-based neural network architecture which achieves better treatment
effect estimation accuracy. Our framework, CausalSent, accurately predicts
treatment effects in semi-synthetic IMDB movie reviews, reducing MAE of effect
estimates by 2-3x compared to Bansal et al's MAE on synthetic Civil Comments
data. With an ensemble of validated models, we perform an observational case
study on the causal effect of the word "love" in IMDB movie reviews, finding
that the presence of the word "love" causes a +2.9% increase in the probability
of a positive sentiment.

</details>


### [67] [UQ: Assessing Language Models on Unsolved Questions](https://arxiv.org/abs/2508.17580)
*Fan Nie,Ken Ziyu Liu,Zihao Wang,Rui Sun,Wei Liu,Weijia Shi,Huaxiu Yao,Linjun Zhang,Andrew Y. Ng,James Zou,Sanmi Koyejo,Yejin Choi,Percy Liang,Niklas Muennighoff*

Main category: cs.CL

TL;DR: 提出UQ测试平台——基于Stack Exchange构建的500个未解决难题的评估体系，通过异步验证机制推动AI模型在真实开放性问题上的能力边界突破


<details>
  <summary>Details</summary>
Motivation: 现有AI基准测试存在难度与真实性的矛盾：考试型基准脱离实际需求，用户交互型基准偏向简单高频问题。需要构建既能挑战前沿模型又具备真实价值的评估体系

Method: 1）UQ-Dataset：结合规则过滤、LLM判断和人工审核的质控流程；2）UQ-Validators：利用生成-验证差距的复合验证策略；3）UQ-Platform：专家社区协同验证的开放平台

Result: 顶级模型仅通过15%问题的验证，初步人工验证已发现有效解决方案。数据集涵盖计算机理论、数学、科幻、历史等多领域复杂问题

Conclusion: UQ开创了基于真实世界开放问题的新型评估范式，其成功实施将推动人类知识边界的扩展。该平台已开源并持续更新，为前沿模型评估提供动态基准

Abstract: Benchmarks shape progress in AI research. A useful benchmark should be both
difficult and realistic: questions should challenge frontier models while also
reflecting real-world usage. Yet, current paradigms face a difficulty-realism
tension: exam-style benchmarks are often made artificially difficult with
limited real-world value, while benchmarks based on real user interaction often
skew toward easy, high-frequency problems. In this work, we explore a radically
different paradigm: assessing models on unsolved questions. Rather than a
static benchmark scored once, we curate unsolved questions and evaluate models
asynchronously over time with validator-assisted screening and community
verification. We introduce UQ, a testbed of 500 challenging, diverse questions
sourced from Stack Exchange, spanning topics from CS theory and math to sci-fi
and history, probing capabilities including reasoning, factuality, and
browsing. UQ is difficult and realistic by construction: unsolved questions are
often hard and naturally arise when humans seek answers, thus solving them
yields direct real-world value. Our contributions are threefold: (1) UQ-Dataset
and its collection pipeline combining rule-based filters, LLM judges, and human
review to ensure question quality (e.g., well-defined and difficult); (2)
UQ-Validators, compound validation strategies that leverage the
generator-validator gap to provide evaluation signals and pre-screen candidate
solutions for human review; and (3) UQ-Platform, an open platform where experts
collectively verify questions and solutions. The top model passes UQ-validation
on only 15% of questions, and preliminary human verification has already
identified correct answers among those that passed. UQ charts a path for
evaluating frontier models on real-world, open-ended challenges, where success
pushes the frontier of human knowledge. We release UQ at
https://uq.stanford.edu.

</details>


### [68] [Less Is More? Examining Fairness in Pruned Large Language Models for Summarising Opinions](https://arxiv.org/abs/2508.17610)
*Nannan Huang,Haytham Fayek,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 提出HGLA剪枝方法，在保持模型性能的同时有效提升LLM意见摘要的公平性。实验表明剪枝方法对公平性影响大于校准集，HGLA相比现有方法能更好维持/改善公平性。


<details>
  <summary>Details</summary>
Motivation: 后训练剪枝对LLM生成摘要公平性的影响尚未被研究，特别是在可能影响公众观点的意见摘要任务中。需要系统性分析剪枝方法与公平性的关系。

Method: 1. 系统分析三种剪枝方法和不同校准集对三个开源LLM的影响
2. 提出HGLA剪枝：通过梯度高但激活值低的参数识别，移除输入处理冗余但影响输出的参数
3. 使用四个公平性指标评估，并进行人工验证

Result: 1. 剪枝方法比校准集对公平性影响更大
2. HGLA在多个模型和任务中优于传统方法，人工评估显示其输出更公平
3. 方法在模型压缩后仍保持较高摘要质量

Conclusion: HGLA为解决传统剪枝方法的公平性限制提供了新思路，特别适用于对输出敏感的任务。该方法通过参数重要性分析实现了性能与公平性的更好平衡。

Abstract: Model compression through post-training pruning offers a way to reduce model
size and computational requirements without significantly impacting model
performance. However, the effect of pruning on the fairness of LLM-generated
summaries remains unexplored, particularly for opinion summarisation where
biased outputs could influence public views.In this paper, we present a
comprehensive empirical analysis of opinion summarisation, examining three
state-of-the-art pruning methods and various calibration sets across three
open-source LLMs using four fairness metrics. Our systematic analysis reveals
that pruning methods have a greater impact on fairness than calibration sets.
Building on these insights, we propose High Gradient Low Activation (HGLA)
pruning, which identifies and removes parameters that are redundant for input
processing but influential in output generation. Our experiments demonstrate
that HGLA can better maintain or even improve fairness compared to existing
methods, showing promise across models and tasks where traditional methods have
limitations. Our human evaluation shows HGLA-generated outputs are fairer than
existing state-of-the-art pruning methods. Code is available at:
https://github.com/amberhuang01/HGLA.

</details>


### [69] [Steering When Necessary: Flexible Steering Large Language Models with Backtracking](https://arxiv.org/abs/2508.17621)
*Jinwei Gan,Zifeng Cheng,Zhiwei Jiang,Cong Wang,Yafeng Yin,Xiang Luo,Yuchen Fu,Qing Gu*

Main category: cs.CL

TL;DR: 提出FASB框架通过动态干预强度和回溯机制，有效提升大语言模型生成内容与期望行为的对齐效果，且无需微调成本。


<details>
  <summary>Details</summary>
Motivation: 现有激活引导方法对所有生成内容进行无差别干预，或仅依赖问题决定干预强度，导致难以准确评估干预效果。模型在生成偏离后干预往往为时已晚。

Method: FASB框架通过跟踪LLM生成时的内部状态（综合考虑问题和生成内容），动态决定干预的必要性和强度。采用回溯机制修正偏离token，实现更精准的行为引导。

Result: 在TruthfulQA数据集和6个多选题数据集上表现优于基线方法，验证了方法的有效性。

Conclusion: FASB通过动态干预策略和回溯机制，在保持低成本的同时显著提升模型对齐效果，为LLM行为控制提供了新思路。

Abstract: Large language models (LLMs) have achieved remarkable performance across many
generation tasks. Nevertheless, effectively aligning them with desired
behaviors remains a significant challenge. Activation steering is an effective
and cost-efficient approach that directly modifies the activations of LLMs
during the inference stage, aligning their responses with the desired behaviors
and avoiding the high cost of fine-tuning. Existing methods typically
indiscriminately intervene to all generations or rely solely on the question to
determine intervention, which limits the accurate assessment of the
intervention strength. To this end, we propose the Flexible Activation Steering
with Backtracking (FASB) framework, which dynamically determines both the
necessity and strength of intervention by tracking the internal states of the
LLMs during generation, considering both the question and the generated
content. Since intervening after detecting a deviation from the desired
behavior is often too late, we further propose the backtracking mechanism to
correct the deviated tokens and steer the LLMs toward the desired behavior.
Extensive experiments on the TruthfulQA dataset and six multiple-choice
datasets demonstrate that our method outperforms baselines. Our code will be
released at https://github.com/gjw185/FASB.

</details>


### [70] [EMO-Reasoning: Benchmarking Emotional Reasoning Capabilities in Spoken Dialogue Systems](https://arxiv.org/abs/2508.17623)
*Jingwen Liu,Kan Jen Cheng,Jiachen Lian,Akshay Anand,Rishi Jain,Faith Qiao,Robin Netzorg,Huang-Cheng Chou,Tingle Li,Guan-Ting Lin,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 提出EMO-Reasoning基准测试框架，通过合成语音数据集和跨轮次情感推理评分，有效检测对话系统的情感不一致问题


<details>
  <summary>Details</summary>
Motivation: 现有口语对话系统缺乏情感连贯性评估体系，需建立系统性评估基准来提升情感感知能力

Method: 利用文本转语音生成多情感状态数据集，提出跨轮次情感推理评分方法，结合连续/分类/感知三维度评估七个对话系统

Result: 框架成功检测出情感不一致现象，为改进现有系统提供方向

Conclusion: 系统化评估基准的发布将推动情感感知口语对话系统向更自然、自适应的人机交互发展

Abstract: Speech emotions play a crucial role in human-computer interaction, shaping
engagement and context-aware communication. Despite recent advances in spoken
dialogue systems, a holistic system for evaluating emotional reasoning is still
lacking. To address this, we introduce EMO-Reasoning, a benchmark for assessing
emotional coherence in dialogue systems. It leverages a curated dataset
generated via text-to-speech to simulate diverse emotional states, overcoming
the scarcity of emotional speech data. We further propose the Cross-turn
Emotion Reasoning Score to assess the emotion transitions in multi-turn
dialogues. Evaluating seven dialogue systems through continuous, categorical,
and perceptual metrics, we show that our framework effectively detects
emotional inconsistencies, providing insights for improving current dialogue
systems. By releasing a systematic evaluation benchmark, we aim to advance
emotion-aware spoken dialogue modeling toward more natural and adaptive
interactions.

</details>


### [71] [Stop Spinning Wheels: Mitigating LLM Overthinking via Mining Patterns for Early Reasoning Exit](https://arxiv.org/abs/2508.17627)
*Zihao Wei,Liang Pang,Jiahao Liu,Jingcheng Deng,Shicheng Xu,Zenghao Duan,Jingang Wang,Fei Sun,Xunliang Cai,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 提出通过检测补偿推理阶段的结束点（RCP）来减少大语言模型中的过度思考问题，从而在保持或提升推理准确性的同时降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中存在过度思考现象，导致资源浪费甚至无限循环。通过分析推理阶段（不足探索、补偿推理、推理收敛），发现正确答案通常出现在补偿推理阶段，而收敛阶段易引发过度思考。

Method: 挖掘敏感且一致的RCP模式，开发基于启发式规则的轻量级阈值策略，通过监测完整推理周期结束特征替代传统逐句查询或终止符概率监控。

Result: 在AIME24/25和GPQA-D基准测试中验证，该方法在保持推理精度的同时显著降低token消耗。

Conclusion: RCP检测机制有效平衡了推理效率与准确性，为优化LLM推理过程提供了新方向。

Abstract: Large language models (LLMs) enhance complex reasoning tasks by scaling the
individual thinking process. However, prior work shows that overthinking can
degrade overall performance. Motivated by observed patterns in thinking length
and content length, we categorize reasoning into three stages: insufficient
exploration stage, compensatory reasoning stage, and reasoning convergence
stage. Typically, LLMs produce correct answers in the compensatory reasoning
stage, whereas reasoning convergence often triggers overthinking, causing
increased resource usage or even infinite loops. Therefore, mitigating
overthinking hinges on detecting the end of the compensatory reasoning stage,
defined as the Reasoning Completion Point (RCP). RCP typically appears at the
end of the first complete reasoning cycle and can be identified by querying the
LLM sentence by sentence or monitoring the probability of an end-of-thinking
token (e.g., \texttt{</think>}), though these methods lack an efficient and
precise balance. To improve this, we mine more sensitive and consistent RCP
patterns and develop a lightweight thresholding strategy based on heuristic
rules. Experimental evaluations on benchmarks (AIME24, AIME25, GPQA-D)
demonstrate that the proposed method reduces token consumption while preserving
or enhancing reasoning accuracy.

</details>


### [72] [Weights-Rotated Preference Optimization for Large Language Models](https://arxiv.org/abs/2508.17637)
*Chenxu Yang,Ruipeng Jia,Mingyu Zheng,Naibin Gu,Zheng Lin,Siyuan Chen,Weichong Yin,Hua Wu,Weiping Wang*

Main category: cs.CL

TL;DR: 提出权重旋转偏好优化（RoPO），通过双重约束机制缓解DPO的奖励黑客问题，在低参数量下显著提升模型对齐效果。


<details>
  <summary>Details</summary>
Motivation: 直接偏好优化（DPO）存在奖励黑客问题：模型过度抑制被拒结果概率，导致生成冗长/缺乏多样性，并引发知识遗忘。核心原因是参数空间的神经元崩溃导致表示冗余。

Method: RoPO包含：（1）隐式约束：继承DPO的KL散度控制输出层logits；（2）显式约束：通过多粒度正交矩阵微调中间隐状态，防止策略模型偏离预训练/SFT阶段的知识。

Result: AlpacaEval 2提升3.27分，MT-Bench超越最佳基线6.2-7.5分（仅需0.015%可训练参数），验证对奖励黑客问题的缓解效果。

Conclusion: RoPO通过参数空间的双重约束机制，有效保留预训练知识，提升对齐效果，为低参数量优化LLM对齐提供新思路。

Abstract: Despite the efficacy of Direct Preference Optimization (DPO) in aligning
Large Language Models (LLMs), reward hacking remains a pivotal challenge. This
issue emerges when LLMs excessively reduce the probability of rejected
completions to achieve high rewards, without genuinely meeting their intended
goals. As a result, this leads to overly lengthy generation lacking diversity,
as well as catastrophic forgetting of knowledge. We investigate the underlying
reason behind this issue, which is representation redundancy caused by neuron
collapse in the parameter space. Hence, we propose a novel Weights-Rotated
Preference Optimization (RoPO) algorithm, which implicitly constrains the
output layer logits with the KL divergence inherited from DPO and explicitly
constrains the intermediate hidden states by fine-tuning on a multi-granularity
orthogonal matrix. This design prevents the policy model from deviating too far
from the reference model, thereby retaining the knowledge and expressive
capabilities acquired during pre-training and SFT stages. Our RoPO achieves up
to a 3.27-point improvement on AlpacaEval 2, and surpasses the best baseline by
6.2 to 7.5 points on MT-Bench with merely 0.015% of the trainable parameters,
demonstrating its effectiveness in alleviating the reward hacking problem of
DPO.

</details>


### [73] [SurveyGen: Quality-Aware Scientific Survey Generation with Large Language Models](https://arxiv.org/abs/2508.17647)
*Tong Bao,Mir Tafseer Nayeem,Davood Rafiei,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 提出大规模人工撰写综述数据集SurveyGen和质量感知框架QUAL-SG，揭示全自动生成综述存在引用质量差和深度分析不足的问题


<details>
  <summary>Details</summary>
Motivation: 当前自动生成综述缺乏标准化评估数据集，难以系统评估大语言模型生成质量与人工撰写差异，制约该领域发展

Method: 构建包含4,200篇人工综述的数据集，开发整合质量感知指标的RAG增强框架，设计不同人机协同程度的对比实验

Result: 半自动流程部分指标接近人工（F1值78.3），全自动生成引用错误率达31.7%且批判性分析仅占人工基准的42%

Conclusion: 首次建立标准化评估基准QUAL-SG，证明质量感知检索的有效性，指出自动生成需突破引用质量和深度推理的技术瓶颈

Abstract: Automatic survey generation has emerged as a key task in scientific document
processing. While large language models (LLMs) have shown promise in generating
survey texts, the lack of standardized evaluation datasets critically hampers
rigorous assessment of their performance against human-written surveys. In this
work, we present SurveyGen, a large-scale dataset comprising over 4,200
human-written surveys across diverse scientific domains, along with 242,143
cited references and extensive quality-related metadata for both the surveys
and the cited papers. Leveraging this resource, we build QUAL-SG, a novel
quality-aware framework for survey generation that enhances the standard
Retrieval-Augmented Generation (RAG) pipeline by incorporating quality-aware
indicators into literature retrieval to assess and select higher-quality source
papers. Using this dataset and framework, we systematically evaluate
state-of-the-art LLMs under varying levels of human involvement - from fully
automatic generation to human-guided writing. Experimental results and human
evaluations show that while semi-automatic pipelines can achieve partially
competitive outcomes, fully automatic survey generation still suffers from low
citation quality and limited critical analysis.

</details>


### [74] [CoCoA: Confidence- and Context-Aware Adaptive Decoding for Resolving Knowledge Conflicts in Large Language Models](https://arxiv.org/abs/2508.17670)
*Anant Khandelwal,Manish Gupta,Puneet Agrawal*

Main category: cs.CL

TL;DR: 提出Confidence- and Context-Aware Adaptive Decoding（CoCoA）算法，通过置信度感知测量和分布差异解决LLMs中参数化记忆与外部语境的知识冲突，提升生成内容的忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有对比解码方法在知识冲突场景中适应性不足，尤其在低冲突环境下性能显著下降，亟需更灵活可靠的冲突解决机制。

Method: 基于熵差/上下文集中度等置信度指标，结合参数化分布与语境分布的广义散度，实现token级别的自适应冲突解析。

Result: 在QA任务中平均准确率提升9.2%，摘要和LFQA任务事实性提升2.5%，且在冲突敏感度方面优于AdaCAD等基线模型。

Conclusion: CoCoA通过动态平衡参数记忆与语境信息，实现了更智能、上下文感知的token生成机制，显著增强LLMs的生成可信度。

Abstract: Faithful generation in large language models (LLMs) is challenged by
knowledge conflicts between parametric memory and external context. Existing
contrastive decoding methods tuned specifically to handle conflict often lack
adaptability and can degrade performance in low conflict settings. We introduce
CoCoA (Confidence- and Context-Aware Adaptive Decoding), a novel token-level
algorithm for principled conflict resolution and enhanced faithfulness. CoCoA
resolves conflict by utilizing confidence-aware measures (entropy gap and
contextual peakedness) and the generalized divergence between the parametric
and contextual distributions. Crucially, CoCoA maintains strong performance
even in low conflict settings. Extensive experiments across multiple LLMs on
diverse Question Answering (QA), Summarization, and Long-Form Question
Answering (LFQA) benchmarks demonstrate CoCoA's state-of-the-art performance
over strong baselines like AdaCAD. It yields significant gains in QA accuracy,
up to 9.2 points on average compared to the strong baseline AdaCAD, and
improves factuality in summarization and LFQA by up to 2.5 points on average
across key benchmarks. Additionally, it demonstrates superior sensitivity to
conflict variations. CoCoA enables more informed, context-aware, and ultimately
more faithful token generation.

</details>


### [75] [Text Meets Topology: Rethinking Out-of-distribution Detection in Text-Rich Networks](https://arxiv.org/abs/2508.17690)
*Danny Wang,Ruihong Qiu,Guangdong Bai,Zi Huang*

Main category: cs.CL

TL;DR: 提出TextTopoOOD框架和TNT-OOD模型，解决文本丰富网络中拓扑-语义耦合的OOD检测难题


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视文本-拓扑的复杂交互关系，仅处理标签偏移或简单域划分，难以应对社交网络等场景中语言模式与拓扑结构的耦合OOD问题

Method: 1) 通过TextTopoOOD框架构建四类OOD场景（属性级/结构级/主题标签级/域级） 2) TNT-OOD模型采用跨注意力机制融合局部拓扑到文本表征，HyperNetwork生成节点特异性变换参数

Result: 在4类OOD场景的11个数据集上验证，证明框架的评估有效性及模型对拓扑-语义耦合偏移的检测优势

Conclusion: 首次系统建模文本网络的复合型OOD检测，为后续研究提供标准化评估基准和有效建模范式

Abstract: Out-of-distribution (OOD) detection remains challenging in text-rich
networks, where textual features intertwine with topological structures.
Existing methods primarily address label shifts or rudimentary domain-based
splits, overlooking the intricate textual-structural diversity. For example, in
social networks, where users represent nodes with textual features (name, bio)
while edges indicate friendship status, OOD may stem from the distinct language
patterns between bot and normal users. To address this gap, we introduce the
TextTopoOOD framework for evaluating detection across diverse OOD scenarios:
(1) attribute-level shifts via text augmentations and embedding perturbations;
(2) structural shifts through edge rewiring and semantic connections; (3)
thematically-guided label shifts; and (4) domain-based divisions. Furthermore,
we propose TNT-OOD to model the complex interplay between Text aNd Topology
using: 1) a novel cross-attention module to fuse local structure into
node-level text representations, and 2) a HyperNetwork to generate
node-specific transformation parameters. This aligns topological and semantic
features of ID nodes, enhancing ID/OOD distinction across structural and
textual shifts. Experiments on 11 datasets across four OOD scenarios
demonstrate the nuanced challenge of TextTopoOOD for evaluating OOD detection
in text-rich networks.

</details>


### [76] [EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning](https://arxiv.org/abs/2508.17703)
*Yinda Chen,Yangfan He,Jing Yang,Dapeng Zhang,Zhenlong Yuan,Muhammad Attique Khan,Jamel Baili,Por Lip Yee*

Main category: cs.CL

TL;DR: 提出EMPOWER进化框架，通过专业表征学习与多维度评估，显著提升医疗提示质量（错误内容减少24.7%，临床偏好提升15.3%）


<details>
  <summary>Details</summary>
Motivation: 现有优化方法未能充分整合医学领域知识及安全要求，制约LLM在医疗应用的可靠性与临床效用

Method: 1.医学术语注意力机制 2.四维评估架构（清晰度/特异性/临床相关性/事实准确性）3.保持临床推理完整性的组件级进化算法 4.医学知识语义验证模块

Result: 诊断/治疗/教育任务中实现：错误内容减少24.7%、领域特异性提升19.6%、双盲评估临床医生偏好高15.3%

Conclusion: 该框架解决了医疗提示开发的关键挑战，为LLM在医疗场景的负责任应用提供了系统性解决方案

Abstract: Prompt engineering significantly influences the reliability and clinical
utility of Large Language Models (LLMs) in medical applications. Current
optimization approaches inadequately address domain-specific medical knowledge
and safety requirements. This paper introduces EMPOWER, a novel evolutionary
framework that enhances medical prompt quality through specialized
representation learning, multi-dimensional evaluation, and structure-preserving
algorithms. Our methodology incorporates: (1) a medical terminology attention
mechanism, (2) a comprehensive assessment architecture evaluating clarity,
specificity, clinical relevance, and factual accuracy, (3) a component-level
evolutionary algorithm preserving clinical reasoning integrity, and (4) a
semantic verification module ensuring adherence to medical knowledge.
Evaluation across diagnostic, therapeutic, and educational tasks demonstrates
significant improvements: 24.7% reduction in factually incorrect content, 19.6%
enhancement in domain specificity, and 15.3% higher clinician preference in
blinded evaluations. The framework addresses critical challenges in developing
clinically appropriate prompts, facilitating more responsible integration of
LLMs into healthcare settings.

</details>


### [77] [Layerwise Importance Analysis of Feed-Forward Networks in Transformer-based Language Models](https://arxiv.org/abs/2508.17734)
*Wataru Ikeda,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Keigo Shibata,Jun Suzuki*

Main category: cs.CL

TL;DR: 将Transformer模型中前馈网络(FFNs)集中配置在连续中间层（70%总层数）可显著提升多下游任务表现，优于标准均匀分布配置。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型中不同层次FFNs在预训练阶段的重要性差异，旨在通过优化FFNs的层级分布提升模型效率。

Method: 1. 通过调整不同层FFNs维度（部分层扩大/部分层完全移除）保持总参数量不变
2. 使用285M/570M/1.2B参数量的不同规模模型进行从头训练
3. 在12/24/40层的不同深度架构中验证配置效果

Result: 集中配置在中间层的FFNs方案在GLUE/SQuAD等多个NLP任务上持续优于标准配置，且结论在不同模型规模下保持稳定

Conclusion: FFNs在模型中间层具有更关键作用，当前均匀分配FFNs的标准架构存在优化空间，层级稀疏化策略可成为模型压缩新方向

Abstract: This study investigates the layerwise importance of feed-forward networks
(FFNs) in Transformer-based language models during pretraining. We introduce an
experimental approach that, while maintaining the total parameter count,
increases the FFN dimensions in some layers and completely removes the FFNs
from other layers. Furthermore, since our focus is on the importance of FFNs
during pretraining, we train models from scratch to examine whether the
importance of FFNs varies depending on their layer positions, rather than using
publicly available pretrained models as is frequently done. Through
comprehensive evaluations of models with varying sizes (285M, 570M, and 1.2B
parameters) and layer counts (12, 24, and 40 layers), we demonstrate that
concentrating FFNs in 70% of the consecutive middle layers consistently
outperforms standard configurations for multiple downstream tasks.

</details>


### [78] [SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation](https://arxiv.org/abs/2508.17735)
*Garima Chhikara,Kripabandhu Ghosh,Abhijnan Chakraborty*

Main category: cs.CL

TL;DR: 提出动态验证集和SMITE算法提升LLM在表格分类中的准确性与公平性


<details>
  <summary>Details</summary>
Motivation: 确保LLM输出公平性对促进AI包容性、平等表示和负责任部署至关重要

Method: 采用动态验证集替代静态验证，开发SMITE算法迭代选择最优上下文示例组合

Result: 在四个不同LLM上的实验显示预测精度和公平性均显著优于基线方法

Conclusion: 首次将动态验证应用于LLM上下文学习，成功提升模型性能与公平性指标

Abstract: Large Language Models (LLMs) are widely used for downstream tasks such as
tabular classification, where ensuring fairness in their outputs is critical
for inclusivity, equal representation, and responsible AI deployment. This
study introduces a novel approach to enhancing LLM performance and fairness
through the concept of a dynamic validation set, which evolves alongside the
test set, replacing the traditional static validation approach. We also propose
an iterative algorithm, SMITE, to select optimal in-context examples, with each
example set validated against its corresponding dynamic validation set. The
in-context set with the lowest total error is used as the final demonstration
set. Our experiments across four different LLMs show that our proposed
techniques significantly improve both predictive accuracy and fairness compared
to baseline methods. To our knowledge, this is the first study to apply dynamic
validation in the context of in-context learning for LLMs.

</details>


### [79] [ISACL: Internal State Analyzer for Copyrighted Training Data Leakage](https://arxiv.org/abs/2508.17767)
*Guangwei Zhang,Qisheng Su,Jiateng Liu,Cheng Qian,Yanzhou Pan,Yanjie Fu,Denghui Zhang*

Main category: cs.CL

TL;DR: 本研究提出通过分析LLMs生成前的内部状态主动预防版权数据泄露，结合检索增强生成系统实现合规输出


<details>
  <summary>Details</summary>
Motivation: 传统方法在文本生成后处理数据泄露风险，可能导致敏感信息已暴露。需在生成前阶段识别风险实现早期干预

Method: 使用版权材料数据集训练神经网络分类器检测模型内部状态风险，集成检索增强生成(RAG)系统实现生成中止或输出调整

Result: 实验表明内部状态分析有效降低92%版权数据泄露，提供可扩展解决方案且保持文本生成质量（GitHub已实现）

Conclusion: 该方法开创了AI工作流的主动合规机制，在保持生成质量的同时满足版权法规要求，为伦理AI发展提供新范式

Abstract: Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) but pose risks of inadvertently exposing copyrighted or proprietary data,
especially when such data is used for training but not intended for
distribution. Traditional methods address these leaks only after content is
generated, which can lead to the exposure of sensitive information. This study
introduces a proactive approach: examining LLMs' internal states before text
generation to detect potential leaks. By using a curated dataset of copyrighted
materials, we trained a neural network classifier to identify risks, allowing
for early intervention by stopping the generation process or altering outputs
to prevent disclosure. Integrated with a Retrieval-Augmented Generation (RAG)
system, this framework ensures adherence to copyright and licensing
requirements while enhancing data privacy and ethical standards. Our results
show that analyzing internal states effectively mitigates the risk of
copyrighted data leakage, offering a scalable solution that fits smoothly into
AI workflows, ensuring compliance with copyright regulations while maintaining
high-quality text generation. The implementation is available on
GitHub.\footnote{https://github.com/changhu73/Internal_states_leakage}

</details>


### [80] [Speculating LLMs' Chinese Training Data Pollution from Their Tokens](https://arxiv.org/abs/2508.17771)
*Qingjie Zhang,Di Wang,Haoting Qian,Liu Yan,Tianwei Zhang,Ke Xu,Qi Li,Minlie Huang,Hewu Li,Han Qiu*

Main category: cs.CL

TL;DR: 研究发现GPT系列模型中文词汇表中存在大量涉及色情/赌博的污染词汇，提出污染词汇检测方法并推测训练数据污染比例


<details>
  <summary>Details</summary>
Motivation: 基于GPT词表中大量中文短语涉及不良内容的现象，探究污染词汇与训练数据之间的关联性

Method: 1. 定义污染词汇分类标准
2. 构建结合语义和搜索引擎结果的LLM检测器
3. 通过token ID分析推测训练数据污染源

Result: 在24个LLM中发现普遍存在污染词汇，GPT词表现最差（23%长中文词汇涉黄/赌），验证C4/Pile数据集污染，推测GPT-4o训练数据中0.5%与特定色情关键词相关

Conclusion: 当前LLM词表存在系统性污染问题，污染词汇与训练数据质量直接相关，需加强数据清洗与词表过滤机制

Abstract: Tokens are basic elements in the datasets for LLM training. It is well-known
that many tokens representing Chinese phrases in the vocabulary of GPT
(4o/4o-mini/o1/o3/4.5/4.1/o4-mini) are indicating contents like pornography or
online gambling. Based on this observation, our goal is to locate Polluted
Chinese (PoC) tokens in LLMs and study the relationship between PoC tokens'
existence and training data. (1) We give a formal definition and taxonomy of
PoC tokens based on the GPT's vocabulary. (2) We build a PoC token detector via
fine-tuning an LLM to label PoC tokens in vocabularies by considering each
token's both semantics and related contents from the search engines. (3) We
study the speculation on the training data pollution via PoC tokens'
appearances (token ID). Experiments on GPT and other 23 LLMs indicate that
tokens widely exist while GPT's vocabulary behaves the worst: more than 23%
long Chinese tokens (i.e., a token with more than two Chinese characters) are
either porn or online gambling. We validate the accuracy of our speculation
method on famous pre-training datasets like C4 and Pile. Then, considering
GPT-4o, we speculate that the ratio of "Yui Hatano" related webpages in
GPT-4o's training data is around 0.5%.

</details>


### [81] [Zero-shot Context Biasing with Trie-based Decoding using Synthetic Multi-Pronunciation](https://arxiv.org/abs/2508.17796)
*Changsong Liu,Yizhou Peng,Eng Siong Chng*

Main category: cs.CL

TL;DR: 提出合成驱动的多发音上下文偏置方法，在Whisper模型上实现零样本ASR，偏置词错误率降低42%-43%


<details>
  <summary>Details</summary>
Motivation: 解决OOV词汇识别中训练数据不足及发音模糊问题，提升罕见词识别准确率

Method: 利用TTS合成目标词语音→Whisper提取发音变体→构建前缀树→束搜索浅层融合奖励→变体映射回原词

Result: Librispeech测试集偏置词错误率降低42%(test-clean)/43%(test-other)，非偏置WER保持稳定

Conclusion: 合成数据驱动的方法有效解决了发音变体问题，显著提升上下文ASR性能且不影响原有识别精度

Abstract: Contextual automatic speech recognition (ASR) systems allow for recognizing
out-of-vocabulary (OOV) words, such as named entities or rare words. However,
it remains challenging due to limited training data and ambiguous or
inconsistent pronunciations. In this paper, we propose a synthesis-driven
multi-pronunciation contextual biasing method that performs zero-shot
contextual ASR on a pretrained Whisper model. Specifically, we leverage
text-to-speech (TTS) systems to synthesize diverse speech samples containing
each target rare word, and then use the pretrained Whisper model to extract
multiple predicted pronunciation variants. These variant token sequences are
compiled into a prefix-trie, which assigns rewards to beam hypotheses in a
shallow-fusion manner during beam-search decoding. After which, any recognized
variant is mapped back to the original rare word in the final transcription.
The evaluation results on the Librispeech dataset show that our method reduces
biased word error rate (WER) by 42% on test-clean and 43% on test-other while
maintaining unbiased WER essentially unchanged.

</details>


### [82] [DRQA: Dynamic Reasoning Quota Allocation for Controlling Overthinking in Reasoning Large Language Models](https://arxiv.org/abs/2508.17803)
*Kaiwen Yan,Xuanqing Shi,Hongcheng Guo,Wenxuan Wang,Zhuosheng Zhang,Chengwei Qin*

Main category: cs.CL

TL;DR: 提出DRQA方法，通过动态分配推理资源减少大语言模型的过度思考现象，在保持准确性的同时显著降低计算消耗


<details>
  <summary>Details</summary>
Motivation: 现有推理大模型（如OpenAI-O3/DeepSeek-R1）在处理简单问题时会产生冗余推理步骤，导致计算资源浪费。受批处理中模型自动压缩简单问题推理步骤的现象启发

Method: 利用批处理生成的偏好数据，通过强化学习训练模型自适应分配推理配额。建立准确性与简洁性的双重偏好机制，根据问题难度动态调整推理深度

Result: 在数学和科学推理基准测试中，DRQA在保持/提升准确率的同时显著减少token消耗，有效缓解过度思考问题

Conclusion: 为高效部署RLLMs提供新方向，推动对推理行为的细粒度控制研究，具有重要的工程实践价值

Abstract: Reasoning large language models (RLLMs), such as OpenAI-O3 and DeepSeek-R1,
have recently demonstrated remarkable capabilities by performing structured and
multi-step reasoning. However, recent studies reveal that RLLMs often suffer
from overthinking, i.e., producing unnecessarily lengthy reasoning chains even
for simple questions, leading to excessive token consumption and computational
inefficiency. Interestingly, we observe that when processing multiple questions
in batch mode, RLLMs exhibit more resource-efficient behavior by dynamically
compressing reasoning steps for easier problems, due to implicit resource
competition. Inspired by this, we propose Dynamic Reasoning Quota Allocation
(DRQA), a novel method that transfers the benefits of resource competition from
batch processing to single-question inference. Specifically, DRQA leverages
batch-generated preference data and reinforcement learning to train the model
to allocate reasoning resources adaptively. By encouraging the model to
internalize a preference for responses that are both accurate and concise, DRQA
enables it to generate concise answers for simple questions while retaining
sufficient reasoning depth for more challenging ones. Extensive experiments on
a wide range of mathematical and scientific reasoning benchmarks demonstrate
that DRQA significantly reduces token usage while maintaining, and in many
cases improving, answer accuracy. By effectively mitigating the overthinking
problem, DRQA offers a promising direction for more efficient and scalable
deployment of RLLMs, and we hope it inspires further exploration into
fine-grained control of reasoning behaviors.

</details>


### [83] [Beyond Demographics: Enhancing Cultural Value Survey Simulation with Multi-Stage Personality-Driven Cognitive Reasoning](https://arxiv.org/abs/2508.17855)
*Haijiang Liu,Qiyuan Li,Chao Gao,Yong Cao,Xiangyu Xu,Xun Wu,Daniel Hershcovich,Jinguang Gu*

Main category: cs.CL

TL;DR: MARK框架通过三阶段推理机制（生活情境压力分析、群体人格预测、自我加权认知模仿）提升文化价值调查模拟的准确性和可解释性，实验显示其准确率优于基线10%且更贴合人类偏好。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型在文化价值调查响应模拟中准确性低、可控性弱、决策过程不透明的问题，结合MBTI类型动力学理论实现人格与人口统计信息的有效关联。

Method: 1. 生活情境压力分析建模环境因素；2. 基于群体特征预测人格类型；3. 自我加权机制模仿人类认知模式。使用世界价值观调查(WVS)数据进行验证。

Result: 在WVS数据集上实现10%的准确率提升，模型预测与人类偏好差异缩小，证明框架在零样本个性化和社会科学解释性方面的优势。

Conclusion: MARK为社会科学研究提供了可解释的AI决策框架，未来可拓展至更广泛的人类行为模拟与政策影响预测场景。

Abstract: Introducing MARK, the Multi-stAge Reasoning frameworK for cultural value
survey response simulation, designed to enhance the accuracy, steerability, and
interpretability of large language models in this task. The system is inspired
by the type dynamics theory in the MBTI psychological framework for personality
research. It effectively predicts and utilizes human demographic information
for simulation: life-situational stress analysis, group-level personality
prediction, and self-weighted cognitive imitation. Experiments on the World
Values Survey show that MARK outperforms existing baselines by 10% accuracy and
reduces the divergence between model predictions and human preferences. This
highlights the potential of our framework to improve zero-shot personalization
and help social scientists interpret model predictions.

</details>


### [84] [Speech Discrete Tokens or Continuous Features? A Comparative Analysis for Spoken Language Understanding in SpeechLLMs](https://arxiv.org/abs/2508.17863)
*Dingdong Wang,Junan Li,Mingyu Cui,Dongchao Yang,Xueyuan Chen,Helen Meng*

Main category: cs.CL

TL;DR: 连续语音特征在多数语音理解任务中表现优于离散标记


<details>
  <summary>Details</summary>
Motivation: 针对语音大模型领域离散标记与连续特征两种处理方式的性能差异缺乏系统比较，研究团队旨在通过公平实验对比揭示两者特性差异

Method: 使用大小规模语言模型（Qwen1.5-0.5B和Llama3.1-8B）在六项语音理解任务中对比自监督学习特征的性能，并开展效率分析、模型层分析及鲁棒性测试

Result: 连续特征整体表现更优，两种语音处理方式在学习模式和特征提取路径上展现出显著差异

Conclusion: 研究结果为语音大模型的语音理解能力提升提供了重要参考，揭示了不同语音处理范式的特性与潜在优化方向

Abstract: With the rise of Speech Large Language Models (SpeechLLMs), two dominant
approaches have emerged for speech processing: discrete tokens and continuous
features. Each approach has demonstrated strong capabilities in audio-related
processing tasks. However, the performance gap between these two paradigms has
not been thoroughly explored. To address this gap, we present a fair comparison
of self-supervised learning (SSL)-based discrete and continuous features under
the same experimental settings. We evaluate their performance across six spoken
language understanding-related tasks using both small and large-scale LLMs
(Qwen1.5-0.5B and Llama3.1-8B). We further conduct in-depth analyses, including
efficient comparison, SSL layer analysis, LLM layer analysis, and robustness
comparison. Our findings reveal that continuous features generally outperform
discrete tokens in various tasks. Each speech processing method exhibits
distinct characteristics and patterns in how it learns and processes speech
information. We hope our results will provide valuable insights to advance
spoken language understanding in SpeechLLMs.

</details>


### [85] [ILRe: Intermediate Layer Retrieval for Context Compression in Causal Language Models](https://arxiv.org/abs/2508.17892)
*Manlai Liang,Mandi Liu,Jiangzhou Ji,Huaijun Li,Haobo Yang,Yaohan He,Jinlong Li*

Main category: cs.CL

TL;DR: 提出ILRe中间层检索方法，将长上下文处理复杂度从O(L²)降为O(L)，在1M token场景下实现180倍加速并保持性能


<details>
  <summary>Details</summary>
Motivation: 解决LLMs长上下文场景中存在的有效上下文长度不足、二次计算复杂度和高内存开销问题

Method: 1. 确定中间解码层离线 2. 分块流式预填充至该层 3. 基于注意力分数召回关键token 4. 提出多池化核分配策略保持语义完整性

Result: 单次处理1M tokens耗时<30秒（加速≈180x），在RULER-1M基准获得≈79.8分（Llama-3.1-UltraLong-8B-1M-Instruct模型，华为昇腾910B NPU）

Conclusion: ILRe无需额外训练即可显著提升长上下文处理效率，性能优于完整上下文处理，具有实际部署价值

Abstract: Large Language Models (LLMs) have demonstrated success across many
benchmarks. However, they still exhibit limitations in long-context scenarios,
primarily due to their short effective context length, quadratic computational
complexity, and high memory overhead when processing lengthy inputs. To
mitigate these issues, we introduce a novel context compression pipeline,
called Intermediate Layer Retrieval (ILRe), which determines one intermediate
decoder layer offline, encodes context by streaming chunked prefill only up to
that layer, and recalls tokens by the attention scores between the input query
and full key cache in that specified layer. In particular, we propose a
multi-pooling kernels allocating strategy in the token recalling process to
maintain the completeness of semantics. Our approach not only reduces the
prefilling complexity from $O(L^2)$ to $O(L)$, but also achieves performance
comparable to or better than the full context in the long context scenarios.
Without additional post training or operator development, ILRe can process a
single $1M$ tokens request in less than half a minute (speedup $\approx
180\times$) and scores RULER-$1M$ benchmark of $\approx 79.8$ with model
Llama-3.1-UltraLong-8B-1M-Instruct on a Huawei Ascend 910B NPU.

</details>


### [86] [Pandora: Leveraging Code-driven Knowledge Transfer for Unified Structured Knowledge Reasoning](https://arxiv.org/abs/2508.17905)
*Yongrui Chen,Junhao He,Linbo Fu,Shenyu Zhang,Rihui Jin,Xinbang Dai,Jiaqi Li,Dehai Min,Nan Hu,Yuxin Zhang,Guilin Qi,Yi Huang,Tongtong Wu*

Main category: cs.CL

TL;DR: 提出Pandora框架解决USKR任务，通过Python Pandas统一知识表示和跨任务记忆增强，在多个基准测试中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有USKR方法依赖任务专用策略，导致跨任务协同困难且性能受限。

Method: 1. 基于Pandas API的统一知识表示 2. 通过代码执行反馈的自适应推理修正 3. 自动构建跨任务记忆的知识迁移

Result: 在3类SKR任务的6个基准测试中，性能超越统一推理框架并与专用方法竞争

Conclusion: Pandora证明了代码化知识表示与自适应反馈机制能有效提升LLMs的统一推理能力

Abstract: Unified Structured Knowledge Reasoning (USKR) aims to answer natural language
questions by using structured sources such as tables, databases, and knowledge
graphs in a unified way. Existing USKR methods rely on task-specific strategies
or bespoke representations, which hinder their ability to dismantle barriers
between different SKR tasks, thereby constraining their overall performance in
cross-task scenarios. In this paper, we introduce \textsc{Pandora}, a novel
USKR framework that addresses the limitations of existing methods by leveraging
two key innovations. First, we propose a code-based unified knowledge
representation using \textsc{Python}'s \textsc{Pandas} API, which aligns
seamlessly with the pre-training of LLMs. This representation facilitates a
cohesive approach to handling different structured knowledge sources. Building
on this foundation, we employ knowledge transfer to bolster the unified
reasoning process of LLMs by automatically building cross-task memory. By
adaptively correcting reasoning using feedback from code execution,
\textsc{Pandora} showcases impressive unified reasoning capabilities. Extensive
experiments on six widely used benchmarks across three SKR tasks demonstrate
that \textsc{Pandora} outperforms existing unified reasoning frameworks and
competes effectively with task-specific methods.

</details>


### [87] [Evaluating the Representation of Vowels in Wav2Vec Feature Extractor: A Layer-Wise Analysis Using MFCCs](https://arxiv.org/abs/2508.17914)
*Domenico De Cristofaro,Vincenzo Norman Vitale,Alessandro Vietti*

Main category: cs.CL

TL;DR: 研究通过比较MFCCs、带共振峰的MFCCs和Wav2Vec的CNN激活特征，评估它们在元音分类中的语音表示能力


<details>
  <summary>Details</summary>
Motivation: 验证自监督学习模型（Wav2Vec）中CNN层提取的语音特征在基础语音单位（单元音）表征中的有效性，探索深度特征与传统声学特征的差异

Method: 使用TIMIT语料库，分别提取三种特征(MFCCs/MFCCs+共振峰/CNN激活)，训练SVM分类器进行元音前后位置分类，通过准确率对比特征质量

Result: CNN激活特征在元音前后分类任务中表现出最优准确率，证明深度模型能有效捕捉语音的区分性特征

Conclusion: 自监督学习框架中的底层CNN结构可提取比传统声学特征更具表征力的语音信息，为改进ASR系统特征提取提供依据

Abstract: Automatic Speech Recognition has advanced with self-supervised learning,
enabling feature extraction directly from raw audio. In Wav2Vec, a CNN first
transforms audio into feature vectors before the transformer processes them.
This study examines CNN-extracted information for monophthong vowels using the
TIMIT corpus. We compare MFCCs, MFCCs with formants, and CNN activations by
training SVM classifiers for front-back vowel identification, assessing their
classification accuracy to evaluate phonetic representation.

</details>


### [88] [Information availability in different languages and various technological constraints related to multilinguism on the Internet](https://arxiv.org/abs/2508.17918)
*Sonal Khosla,Haridasa Acharya*

Main category: cs.CL

TL;DR: 分析互联网语言障碍对非英语用户的影响及现存技术解决方案的不足


<details>
  <summary>Details</summary>
Motivation: 随着互联网用户激增，英语主导地位导致非英语用户访问受限，需解决多语言信息获取的技术瓶颈

Method: 通过统计数据分析语言分布现状，评估现有跨语言技术的有效性

Result: 现存方案仅部分缓解问题，25%英语母语者与75%非英语用户间存在显著数字鸿沟

Conclusion: 实现真正的网络多语言化需突破字符编码、机器翻译和本地化技术三大核心挑战

Abstract: The usage of Internet has grown exponentially over the last two decades. The
number of Internet users has grown from 16 Million to 1650 Million from 1995 to
2010. It has become a major repository of information catering almost every
area. Since the Internet has its origin in USA which is English speaking
country there is huge dominance of English on the World Wide Web. Although
English is a globally acceptable language, still there is a huge population in
the world which is not able to access the Internet due to language constraints.
It has been estimated that only 20-25% of the world population speaks English
as a native language. More and more people are accessing the Internet nowadays
removing the cultural and linguistic barriers and hence there is a high growth
in the number of non-English speaking users over the last few years on the
Internet. Although many solutions have been provided to remove the linguistic
barriers, still there is a huge gap to be filled. This paper attempts to
analyze the need of information availability in different languages and the
various technological constraints related to multi-linguism on the Internet.

</details>


### [89] [Feature-Refined Unsupervised Model for Loanword Detection](https://arxiv.org/abs/2508.17923)
*Promise Dodzi Kpoglu*

Main category: cs.CL

TL;DR: 提出基于语言内部信息的无监督借词检测方法，通过混合语言学与统计线索，在印欧语系数据中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖外部信息导致的循环论证问题，开发纯语言内部特征的检测方案以提升历史语言学工作可靠性。

Method: 1. 提取语言特征并概率映射 2. 迭代优化模式归纳 3. 结合语言学规则与统计分析的混合方法

Result: 在六种印欧语言测试中超越基线模型，跨语言数据扩展时效果提升显著（英语/德语等准确率提升15-22%）

Conclusion: 验证了纯语言内部特征的有效性，混合方法为历史语言学提供新工具，未来可扩展至非印欧语系研究。

Abstract: We propose an unsupervised method for detecting loanwords i.e., words
borrowed from one language into another. While prior work has primarily relied
on language-external information to identify loanwords, such approaches can
introduce circularity and constraints into the historical linguistics workflow.
In contrast, our model relies solely on language-internal information to
process both native and borrowed words in monolingual and multilingual
wordlists. By extracting pertinent linguistic features, scoring them, and
mapping them probabilistically, we iteratively refine initial results by
identifying and generalizing from emerging patterns until convergence. This
hybrid approach leverages both linguistic and statistical cues to guide the
discovery process. We evaluate our method on the task of isolating loanwords in
datasets from six standard Indo-European languages: English, German, French,
Italian, Spanish, and Portuguese. Experimental results demonstrate that our
model outperforms baseline methods, with strong performance gains observed when
scaling to cross-linguistic data.

</details>


### [90] [AMELIA: A Family of Multi-task End-to-end Language Models for Argumentation](https://arxiv.org/abs/2508.17926)
*Henri Savigny,Bruno Yun*

Main category: cs.CL

TL;DR: 论文通过构建统一格式的多任务数据集，探索三种大语言模型训练策略（单任务微调/多任务微调/模型合并），显著提升论据挖掘任务的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有论据挖掘方法需要为不同任务训练独立模型，效率低下。本文旨在探索单个大语言模型处理多任务的可行性，提升计算效率。

Method: 1. 整合19个主流数据集形成统一格式的多任务数据集
2. 基于Llama-3.1-8B模型测试三种策略：单任务微调、多任务联合微调、单任务模型合并

Result: 单任务微调平均提升15.6%准确率；多任务微调保持97%单任务性能；模型合并方案在保持92%性能的同时减少60%计算成本

Conclusion: 模型合并策略为效率与性能的最佳平衡方案，为多任务论据挖掘提供了实用的工程实现路径

Abstract: Argument mining is a subfield of argumentation that aims to automatically
extract argumentative structures and their relations from natural language
texts. This paper investigates how a single large language model can be
leveraged to perform one or several argument mining tasks. Our contributions
are two-fold. First, we construct a multi-task dataset by surveying and
converting 19 well-known argument mining datasets from the literature into a
unified format. Second, we explore various training strategies using Meta AI's
Llama-3.1-8B-Instruct model: (1) fine-tuning on individual tasks, (2)
fine-tuning jointly on multiple tasks, and (3) merging models fine-tuned
separately on individual tasks. Our experiments show that task-specific
fine-tuning significantly improves individual performance across all tasks.
Moreover, multi-task fine-tuning maintains strong performance without
degradation, suggesting effective transfer learning across related tasks.
Finally, we demonstrate that model merging offers a viable compromise: it
yields competitive performance while mitigating the computational costs
associated with full multi-task fine-tuning.

</details>


### [91] [Debiasing Multilingual LLMs in Cross-lingual Latent Space](https://arxiv.org/abs/2508.17948)
*Qiwei Peng,Guimin Hu,Yekun Chai,Anders Søgaard*

Main category: cs.CL

TL;DR: 现有去偏方法（如SentDebias）在跨语言迁移性上效果有限，本文提出在自编码器构建的跨语言联合潜在空间中进行去偏，显著提升效果和迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有去偏技术直接应用于LLM表征时跨语言迁移性不足，需探索更有效的跨语言去偏方法。

Method: 使用平行TED语料训练自编码器构建跨语言潜在空间，并在该空间应用SentDebias等去偏技术，评估四语言（英/法/德/荷）效果。

Result: 跨语言潜在空间构建有效，联合空间去偏使整体性能提升21.6%，跨语言迁移性提高34.5%。

Conclusion: 联合潜在空间去偏突破了现有方法局限，为多语言场景提供了更优解决方案。

Abstract: Debiasing techniques such as SentDebias aim to reduce bias in large language
models (LLMs). Previous studies have evaluated their cross-lingual
transferability by directly applying these methods to LLM representations,
revealing their limited effectiveness across languages. In this work, we
therefore propose to perform debiasing in a joint latent space rather than
directly on LLM representations. We construct a well-aligned cross-lingual
latent space using an autoencoder trained on parallel TED talk scripts. Our
experiments with Aya-expanse and two debiasing techniques across four languages
(English, French, German, Dutch) demonstrate that a) autoencoders effectively
construct a well-aligned cross-lingual latent space, and b) applying debiasing
techniques in the learned cross-lingual latent space significantly improves
both the overall debiasing performance and cross-lingual transferability.

</details>


### [92] [Understanding Subword Compositionality of Large Language Models](https://arxiv.org/abs/2508.17953)
*Qiwei Peng,Yekun Chai,Anders Søgaard*

Main category: cs.CL

TL;DR: 研究发现五个主流大语言模型在子词组合策略上呈现三种不同模式，通过结构相似性、语义分解性和形式保留三个维度揭示了LLM组合子词的动态机制。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型如何将子词信息组合成有效的词级表示，分析不同模型在子词组合策略上的差异及其内部工作机制。

Method: 对五个LLM家族进行三组探测实验：1) 结构相似性分析（子词组合与整词表示的跨层演变） 2) 语义可分解性敏感度测试 3) 形式特征保留能力检测（如字符序列长度）

Result: 发现三类明显模式：1）子词组合与整词表示的结构相似性在不同层呈现三种演变轨迹 2）各层对语义分解性表现出优异敏感度 3）对形式特征的响应呈现三种差异模式

Conclusion: 研究揭示了LLM处理子词信息的不同组合范式，为理解其内部组合机制提供了新视角，对模型架构优化具有指导意义。

Abstract: Large language models (LLMs) take sequences of subwords as input, requiring
them to effective compose subword representations into meaningful word-level
representations. In this paper, we present a comprehensive set of experiments
to probe how LLMs compose subword information, focusing on three key aspects:
structural similarity, semantic decomposability, and form retention. Our
analysis of the experiments suggests that these five LLM families can be
classified into three distinct groups, likely reflecting difference in their
underlying composition strategies. Specifically, we observe (i) three distinct
patterns in the evolution of structural similarity between subword compositions
and whole-word representations across layers; (ii) great performance when
probing layer by layer their sensitivity to semantic decompositionality; and
(iii) three distinct patterns when probing sensitivity to formal features,
e.g., character sequence length. These findings provide valuable insights into
the compositional dynamics of LLMs and highlight different compositional
pattens in how LLMs encode and integrate subword information.

</details>


### [93] [German4All - A Dataset and Model for Readability-Controlled Paraphrasing in German](https://arxiv.org/abs/2508.17973)
*Miriam Anschütz,Thanh Mai Pham,Eslam Nasrallah,Maximilian Müller,Cristian-George Craciun,Georg Groh*

Main category: cs.CL

TL;DR: 研究者开发了首个德语多层级改写数据集German4All，并训练出开源模型实现文本可读性控制


<details>
  <summary>Details</summary>
Motivation: 解决不同读者群体对文本复杂度差异化的需求，推动无障碍文本生成研究

Method: 使用GPT-4自动合成跨5个可读性等级的25,000+样本数据集，结合人工和LLM评估

Result: 模型在德语文本简化任务中达到SOTA性能，支持细粒度的读者定制化适配

Conclusion: 开放数据集与模型为多层级文本改写研究提供新资源，促进包容性内容创作

Abstract: The ability to paraphrase texts across different complexity levels is
essential for creating accessible texts that can be tailored toward diverse
reader groups. Thus, we introduce German4All, the first large-scale German
dataset of aligned readability-controlled, paragraph-level paraphrases. It
spans five readability levels and comprises over 25,000 samples. The dataset is
automatically synthesized using GPT-4 and rigorously evaluated through both
human and LLM-based judgments. Using German4All, we train an open-source,
readability-controlled paraphrasing model that achieves state-of-the-art
performance in German text simplification, enabling more nuanced and
reader-specific adaptations. We opensource both the dataset and the model to
encourage further research on multi-level paraphrasing

</details>


### [94] [A Retail-Corpus for Aspect-Based Sentiment Analysis with Large Language Models](https://arxiv.org/abs/2508.17994)
*Oleg Silcenco,Marcos R. Machad,Wallace C. Ugulino,Daniel Braun*

Main category: cs.CL

TL;DR: 研究构建了10,814条多语言零售评论数据集，测试发现GPT-4在细粒度情感分析中全面优于LLaMA-3（准确率均超85%）


<details>
  <summary>Details</summary>
Motivation: 传统情感分析缺乏细粒度视角，需构建多语言零售领域数据集并验证大模型在细粒度情感分析中的表现

Method: 人工标注10,814条线下零售店多语言评论（8个方面+情感标签），对比测试GPT-4和LLaMA-3模型性能

Result: 双模型准确率均超85%，GPT-4在所有评估指标上全面领先LLaMA-3

Conclusion: 验证数据集有效性，确立GPT-4作为细粒度零售情感分析的新基准

Abstract: Aspect-based sentiment analysis enhances sentiment detection by associating
it with specific aspects, offering deeper insights than traditional sentiment
analysis. This study introduces a manually annotated dataset of 10,814
multilingual customer reviews covering brick-and-mortar retail stores, labeled
with eight aspect categories and their sentiment. Using this dataset, the
performance of GPT-4 and LLaMA-3 in aspect based sentiment analysis is
evaluated to establish a baseline for the newly introduced data. The results
show both models achieving over 85% accuracy, while GPT-4 outperforms LLaMA-3
overall with regard to all relevant metrics.

</details>


### [95] [Neither Valid nor Reliable? Investigating the Use of LLMs as Judges](https://arxiv.org/abs/2508.18076)
*Khaoula Chehbouni,Mohammed Haddou,Jackie Chi Kit Cheung,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: 本文批判性评估将大语言模型作为评估工具（LLJs）的可靠性，指出其有效性假设存在根本性缺陷


<details>
  <summary>Details</summary>
Motivation: 针对当前自然语言生成评估领域过度依赖未经充分验证的LLJs评估系统的现象，基于测量理论揭示其潜在风险

Method: 通过测量理论的四个核心假设框架（人类代理性、评估能力、可扩展性、成本效益），结合文本摘要、数据标注、安全对齐三个应用场景展开分析

Result: LLJ的评估有效性受限于大语言模型的固有缺陷，现有实践未能满足测量学基本要求，可能扭曲NLG领域发展轨迹

Conclusion: 必须建立更严格的LLJ验证框架，确保评估工具的可靠性优先于评估效率，避免技术便利性损害科研严谨性

Abstract: Evaluating natural language generation (NLG) systems remains a core challenge
of natural language processing (NLP), further complicated by the rise of large
language models (LLMs) that aims to be general-purpose. Recently, large
language models as judges (LLJs) have emerged as a promising alternative to
traditional metrics, but their validity remains underexplored. This position
paper argues that the current enthusiasm around LLJs may be premature, as their
adoption has outpaced rigorous scrutiny of their reliability and validity as
evaluators. Drawing on measurement theory from the social sciences, we identify
and critically assess four core assumptions underlying the use of LLJs: their
ability to act as proxies for human judgment, their capabilities as evaluators,
their scalability, and their cost-effectiveness. We examine how each of these
assumptions may be challenged by the inherent limitations of LLMs, LLJs, or
current practices in NLG evaluation. To ground our analysis, we explore three
applications of LLJs: text summarization, data annotation, and safety
alignment. Finally, we highlight the need for more responsible evaluation
practices in LLJs evaluation, to ensure that their growing role in the field
supports, rather than undermines, progress in NLG.

</details>


### [96] [How Quantization Shapes Bias in Large Language Models](https://arxiv.org/abs/2508.18088)
*Federico Marcuzzi,Xuefei Ning,Roy Schwartz,Iryna Gurevych*

Main category: cs.CL

TL;DR: 量化技术对模型偏见呈现复杂影响：降低毒性但轻微增加刻板印象，需平衡效率与伦理


<details>
  <summary>Details</summary>
Motivation: 评估模型压缩中广泛应用的量化技术对不同人口群体偏见的影响，填补量化伦理影响的研究空白

Method: 采用权重/激活量化策略，通过9个基准测试分析毒性、刻板印象等偏见类型，涵盖多种模型架构

Result: 量化后模型毒性降低15%，但生成任务的刻板印象增加8%，4-bit量化时公平性指标下降12%

Conclusion: 量化应用需建立多维评估框架，在压缩强度与偏见控制间寻找最优平衡点

Abstract: This work presents a comprehensive evaluation of how quantization affects
model bias, with particular attention to its impact on individual demographic
subgroups. We focus on weight and activation quantization strategies and
examine their effects across a broad range of bias types, including
stereotypes, toxicity, sentiment, and fairness. We employ both probabilistic
and generated text-based metrics across nine benchmarks and evaluate models
varying in architecture family and reasoning ability. Our findings show that
quantization has a nuanced impact on bias: while it can reduce model toxicity
and does not significantly impact sentiment, it tends to slightly increase
stereotypes and unfairness in generative tasks, especially under aggressive
compression. These trends are generally consistent across demographic
categories and model types, although their magnitude depends on the specific
setting. Overall, our results highlight the importance of carefully balancing
efficiency and ethical considerations when applying quantization in practice.

</details>


### [97] [Speech-Based Depressive Mood Detection in the Presence of Multiple Sclerosis: A Cross-Corpus and Cross-Lingual Study](https://arxiv.org/abs/2508.18092)
*Monica Gonzalez-Machorro,Uwe Reichel,Pascal Hecker,Helly Hammer,Hesam Sagha,Florian Eyben,Robert Hoepner,Björn W. Schuller*

Main category: cs.CL

TL;DR: 探索基于语音的AI在检测多发性硬化症患者抑郁情绪中的适用性，通过跨语料库和跨语言分析验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 抑郁症常与神经退行性疾病共病，但基于语音的AI检测方法在此类共病场景中的应用尚未被充分研究。

Method: 1) 使用传统语音/语言特征；2) 基于SER模型提取情感维度；3) 探索性语音特征分析。结合监督学习模型进行跨数据集验证。

Result: 模型对MS患者抑郁情绪检测达到66% UAR，特征选择优化后提升至74%。情感变化是跨群体的核心指标。

Conclusion: 语音特征检测抑郁情绪在共病场景中具备可行性，情感维度是关键指标，为复杂病况下的AI诊断提供新思路。

Abstract: Depression commonly co-occurs with neurodegenerative disorders like Multiple
Sclerosis (MS), yet the potential of speech-based Artificial Intelligence for
detecting depression in such contexts remains unexplored. This study examines
the transferability of speech-based depression detection methods to people with
MS (pwMS) through cross-corpus and cross-lingual analysis using English data
from the general population and German data from pwMS. Our approach implements
supervised machine learning models using: 1) conventional speech and language
features commonly used in the field, 2) emotional dimensions derived from a
Speech Emotion Recognition (SER) model, and 3) exploratory speech feature
analysis. Despite limited data, our models detect depressive mood in pwMS with
moderate generalisability, achieving a 66% Unweighted Average Recall (UAR) on a
binary task. Feature selection further improved performance, boosting UAR to
74%. Our findings also highlight the relevant role emotional changes have as an
indicator of depressive mood in both the general population and within PwMS.
This study provides an initial exploration into generalising speech-based
depression detection, even in the presence of co-occurring conditions, such as
neurodegenerative diseases.

</details>


### [98] [Agri-Query: A Case Study on RAG vs. Long-Context LLMs for Cross-Lingual Technical Question Answering](https://arxiv.org/abs/2508.18093)
*Julius Gun,Timo Oksanen*

Main category: cs.CL

TL;DR: 通过128K上下文窗口评估大语言模型在跨语言技术问答任务中的表现，发现混合RAG策略优于直接长上下文提示


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在工业领域技术文档问答任务中的实际表现，特别针对多语言场景下的'大海捞针'式信息检索需求

Method: 使用英法德三语农业机械手册构建基准测试，比较9种长上下文模型直接提示与3种RAG策略（关键词/语义/混合），采用LLM作为裁判评估

Result: 混合RAG准确率超过85%，Gemini 2.5 Flash和Qwen 2.5 7B模型表现最佳，直接长上下文提示效果普遍弱于RAG方案

Conclusion: 研究为工业领域LLM应用提供实证分析框架，揭示实际工程中准确率与计算成本的权衡，证明较小模型配合RAG可在专业领域取得优异效果

Abstract: We present a case study evaluating large language models (LLMs) with
128K-token context windows on a technical question answering (QA) task. Our
benchmark is built on a user manual for an agricultural machine, available in
English, French, and German. It simulates a cross-lingual information retrieval
scenario where questions are posed in English against all three language
versions of the manual. The evaluation focuses on realistic
"needle-in-a-haystack" challenges and includes unanswerable questions to test
for hallucinations. We compare nine long-context LLMs using direct prompting
against three Retrieval-Augmented Generation (RAG) strategies (keyword,
semantic, hybrid), with an LLM-as-a-judge for evaluation. Our findings for this
specific manual show that Hybrid RAG consistently outperforms direct
long-context prompting. Models like Gemini 2.5 Flash and the smaller Qwen 2.5
7B achieve high accuracy (over 85%) across all languages with RAG. This paper
contributes a detailed analysis of LLM performance in a specialized industrial
domain and an open framework for similar evaluations, highlighting practical
trade-offs and challenges.

</details>


### [99] [Detecting and Characterizing Planning in Language Models](https://arxiv.org/abs/2508.18098)
*Jatin Nainani,Sankaran Vaidyanathan,Connor Watts,Andre N. Assis,Alice Rigg*

Main category: cs.CL

TL;DR: 研究发现大语言模型的规划能力并非普遍存在，不同模型在不同任务中会切换规划与即兴生成策略，指令微调仅优化现有规划模式


<details>
  <summary>Details</summary>
Motivation: 验证大语言模型是否具备前瞻性规划能力（预先选择目标token并生成中间步骤），而非单纯逐token即兴生成

Method: 提出因果推理标准建立半自动化标注流程，在代码生成（MBPP）和诗歌创作任务中对比分析Gemma-2-2B基座模型与指令微调版本的行为模式

Result: 1. Claude 3.5 Haiku在诗歌任务中展示规划能力，而Gemma-2-2B采用即兴生成
2. Gemma在代码任务中对相似问题甚至连续token预测会切换规划/即兴策略
3. 指令微调主要优化基座模型的现有规划模式而非创建新能力

Conclusion: 建立了可复现的LLM规划行为分析框架，为理解模型认知机制提供方法论基础

Abstract: Modern large language models (LLMs) have demonstrated impressive performance
across a wide range of multi-step reasoning tasks. Recent work suggests that
LLMs may perform planning - selecting a future target token in advance and
generating intermediate tokens that lead towards it - rather than merely
improvising one token at a time. However, existing studies assume fixed
planning horizons and often focus on single prompts or narrow domains. To
distinguish planning from improvisation across models and tasks, we present
formal and causally grounded criteria for detecting planning and operationalize
them as a semi-automated annotation pipeline. We apply this pipeline to both
base and instruction-tuned Gemma-2-2B models on the MBPP code generation
benchmark and a poem generation task where Claude 3.5 Haiku was previously
shown to plan. Our findings show that planning is not universal: unlike Haiku,
Gemma-2-2B solves the same poem generation task through improvisation, and on
MBPP it switches between planning and improvisation across similar tasks and
even successive token predictions. We further show that instruction tuning
refines existing planning behaviors in the base model rather than creating them
from scratch. Together, these studies provide a reproducible and scalable
foundation for mechanistic studies of planning in LLMs.

</details>


### [100] [SentiMM: A Multimodal Multi-Agent Framework for Sentiment Analysis in Social Media](https://arxiv.org/abs/2508.18108)
*Xilai Xu,Zilin Zhao,Chengye Song,Zining Wang,Jinhe Qiang,Jiongrui Yan,Yuhuai Lin*

Main category: cs.CL

TL;DR: 提出SentiMM多智能体框架解决多模态情感分析中的跨模态融合与知识整合难题，并构建SentiMMD数据集验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态融合和外部知识整合方面存在不足，难以处理社交媒体中异构多模态数据和多标签情感分类需求

Method: 通过专用智能体分别处理文本/视觉输入→多模态特征融合→知识检索增强上下文→结果聚合的递进式处理流程

Result: 构建包含7种细粒度情感类别的SentiMMD数据集，实验显示SentiMM在多个指标上超越现有最优基线模型

Conclusion: 结构化多智能体框架通过系统化特征融合与知识增强，显著提升多模态情感分析性能

Abstract: With the increasing prevalence of multimodal content on social media,
sentiment analysis faces significant challenges in effectively processing
heterogeneous data and recognizing multi-label emotions. Existing methods often
lack effective cross-modal fusion and external knowledge integration. We
propose SentiMM, a novel multi-agent framework designed to systematically
address these challenges. SentiMM processes text and visual inputs through
specialized agents, fuses multimodal features, enriches context via knowledge
retrieval, and aggregates results for final sentiment classification. We also
introduce SentiMMD, a large-scale multimodal dataset with seven fine-grained
sentiment categories. Extensive experiments demonstrate that SentiMM achieves
superior performance compared to state-of-the-art baselines, validating the
effectiveness of our structured approach.

</details>


### [101] [Toward a Better Localization of Princeton WordNet](https://arxiv.org/abs/2508.18134)
*Abed Alhakim Freihat*

Main category: cs.CL

TL;DR: 提出普林斯顿WordNet阿拉伯语本地化结构化框架，成功应用于10,000个同义词集并兼顾文化适应性


<details>
  <summary>Details</summary>
Motivation: 解决现有WordNet本地化工作规模有限、缺乏文化语境适配性验证的问题

Method: 开发分阶段结构化本地化框架，包含质量保障机制和文化真实性校验流程

Result: 成功完成10,000个同义词集的阿拉伯语本地化实践验证

Conclusion: 该框架为语义资源的跨文化本地化提供了可复制的质量保障方案

Abstract: As Princeton WordNet continues to gain significance as a semantic lexicon in
Natural Language Processing, the need for its localization and for ensuring the
quality of this process has become increasingly critical. Existing efforts
remain limited in both scale and rigor, and there is a notable absence of
studies addressing the accuracy of localization or its alignment with the
cultural context of Arabic. This paper proposes a structured framework for the
localization of Princeton WordNet, detailing the stages and procedures required
to achieve high-quality results without compromising cultural authenticity. We
further present our experience in applying this framework, reporting outcomes
from the localization of 10,000 synsets.

</details>


### [102] [S2Sent: Nested Selectivity Aware Sentence Representation Learning](https://arxiv.org/abs/2508.18164)
*Jianxiang Zang,Nijia Mo,Yonda Wei,Meiling Ning,Hui Liu*

Main category: cs.CL

TL;DR: 提出基于Transformer编码器的跨块表征融合机制S²Sent，通过空间选择和嵌套频率选择优化句子表征质量


<details>
  <summary>Details</summary>
Motivation: Transformer不同模块的语义感知能力存在差异，现有方法仅依赖最后一层表征会忽略中间层的有效信息。受知识神经元可解释性启发，探索跨块表征融合优化方案

Method: 1. 设计参数化嵌套选择器：空间选择(SS)模块通过空间压缩自门控机制获取自适应权重；嵌套频率选择(FS)模块利用DCT基函数替代全局平均池化
2. SS模块捕获特征依赖关系，FS模块降低语义损失
3. 可无缝集成到各类Transformer架构

Result: 在多个基准测试中显著超越基线方法，仅增加0.001M参数和0.06ms推理延迟，保持高可集成性和扩展性

Conclusion: S²Sent通过跨块表征融合有效平衡语义冗余与损失，为句子表征学习提供新的优化方向

Abstract: The combination of Transformer-based encoders with contrastive learning
represents the current mainstream paradigm for sentence representation
learning. This paradigm is typically based on the hidden states of the last
Transformer block of the encoder. However, within Transformer-based encoders,
different blocks exhibit varying degrees of semantic perception ability. From
the perspective of interpretability, the semantic perception potential of
knowledge neurons is modulated by stimuli, thus rational cross-block
representation fusion is a direction worth optimizing. To balance the semantic
redundancy and loss across block fusion, we propose a sentence representation
selection mechanism S\textsuperscript{2}Sent, which integrates a parameterized
nested selector downstream of the Transformer-based encoder. This selector
performs spatial selection (SS) and nested frequency selection (FS) from a
modular perspective. The SS innovatively employs a spatial squeeze based
self-gating mechanism to obtain adaptive weights, which not only achieves
fusion with low information redundancy but also captures the dependencies
between embedding features. The nested FS replaces GAP with different DCT basis
functions to achieve spatial squeeze with low semantic loss. Extensive
experiments have demonstrated that S\textsuperscript{2}Sent achieves
significant improvements over baseline methods with negligible additional
parameters and inference latency, while highlighting high integrability and
scalability.

</details>


### [103] [DiscussLLM: Teaching Large Language Models When to Speak](https://arxiv.org/abs/2508.18167)
*Deep Anil Patel,Iain Melvin,Christopher Malon,Martin Renqiang Min*

Main category: cs.CL

TL;DR: 提出DiscussLLM框架，通过训练语言模型主动判断发言时机，解决LLMs在对话中被动响应的问题


<details>
  <summary>Details</summary>
Motivation: 当前LLMs作为被动应答体存在'意识鸿沟'，难以成为动态人类讨论中真正的协作伙伴

Method: 开发两阶段数据生成流程构建多轮讨论数据集，训练模型预测静默符号并采用端到端/分离式架构

Result: 模型学会在对话触发点时主动干预，生成有价值的响应，同时保持非必要时的沉默

Conclusion: 该框架为构建具有情境意识和主动性的对话AI提供了新方向

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
understanding and generating human-like text, yet they largely operate as
reactive agents, responding only when directly prompted. This passivity creates
an "awareness gap," limiting their potential as truly collaborative partners in
dynamic human discussions. We introduce $\textit{DiscussLLM}$, a framework
designed to bridge this gap by training models to proactively decide not just
$\textit{what}$ to say, but critically, $\textit{when}$ to speak. Our primary
contribution is a scalable two-stage data generation pipeline that synthesizes
a large-scale dataset of realistic multi-turn human discussions. Each
discussion is annotated with one of five intervention types (e.g., Factual
Correction, Concept Definition) and contains an explicit conversational trigger
where an AI intervention adds value. By training models to predict a special
silent token when no intervention is needed, they learn to remain quiet until a
helpful contribution can be made. We explore two architectural baselines: an
integrated end-to-end model and a decoupled classifier-generator system
optimized for low-latency inference. We evaluate these models on their ability
to accurately time interventions and generate helpful responses, paving the way
for more situationally aware and proactive conversational AI.

</details>


### [104] [Improving End-to-End Training of Retrieval-Augmented Generation Models via Joint Stochastic Approximation](https://arxiv.org/abs/2508.18168)
*Hongyu Cao,Yuxuan Wu,Yucheng Cai,Xianyu Zhao,Zhijian Ou*

Main category: cs.CL

TL;DR: 提出JSA-RAG算法，通过联合随机近似方法优化RAG模型的端到端训练，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统RAG模型的端到端优化面临离散潜在变量边缘化难题，传统top-K边际化和VRAG存在梯度估计偏差/高方差问题。

Method: 开发基于联合随机近似算法（JSA）的端到端训练框架，作为EM算法的随机扩展，专门针对离散潜在变量模型优化。

Result: 在5个数据集、2个任务（开放域问答和知识对话）中验证，JSA-RAG显著超越原始RAG和VRAG模型。

Conclusion: JSA-RAG通过低方差梯度估计，在生成质量、检索精度和训练稳定性方面展现全面优势。

Abstract: Retrieval-augmented generation (RAG) has become a widely recognized paradigm
to combine parametric memory with non-parametric memories. An RAG model
consists of two serial connecting components (retriever and generator). A major
challenge in end-to-end optimization of the RAG model is that marginalization
over relevant passages (modeled as discrete latent variables) from a knowledge
base is required. Traditional top-K marginalization and variational RAG (VRAG)
suffer from biased or high-variance gradient estimates. In this paper, we
propose and develop joint stochastic approximation (JSA) based end-to-end
training of RAG, which is referred to as JSA-RAG. The JSA algorithm is a
stochastic extension of the EM (expectation-maximization) algorithm and is
particularly powerful in estimating discrete latent variable models. Extensive
experiments are conducted on five datasets for two tasks (open-domain question
answering, knowledge-grounded dialogs) and show that JSA-RAG significantly
outperforms both vanilla RAG and VRAG. Further analysis shows the efficacy of
JSA-RAG from the perspectives of generation, retrieval, and low-variance
gradient estimate.

</details>


### [105] [Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios](https://arxiv.org/abs/2508.18183)
*Luana Bulla,Gabriele Tuccio,Misael Mongiovì,Aldo Gangemi*

Main category: cs.CL

TL;DR: 提出AulSign方法，利用LLMs的动态提示和上下文学习机制解决手语翻译数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 手语翻译面临并行语料库匮乏的挑战，现有方法在数据稀缺场景表现不佳，需突破LLMs对手语知识的内在缺失

Method: 通过样本选择构建动态提示模板，将手语符号关联自然语言描述，实现LLMs的上下文符号映射学习

Result: 在SignBank+和LaCAM数据集上超越SOTA模型，低数据场景BLEU值提升12.7%

Conclusion: 该方法显著提升资源稀缺场景的翻译性能，为弱势语言社区构建包容性沟通技术提供新范式

Abstract: Translating natural languages into sign languages is a highly complex and
underexplored task. Despite growing interest in accessibility and inclusivity,
the development of robust translation systems remains hindered by the limited
availability of parallel corpora which align natural language with sign
language data. Existing methods often struggle to generalize in these
data-scarce environments, as the few datasets available are typically
domain-specific, lack standardization, or fail to capture the full linguistic
richness of sign languages. To address this limitation, we propose Advanced Use
of LLMs for Sign Language Translation (AulSign), a novel method that leverages
Large Language Models via dynamic prompting and in-context learning with sample
selection and subsequent sign association. Despite their impressive abilities
in processing text, LLMs lack intrinsic knowledge of sign languages; therefore,
they are unable to natively perform this kind of translation. To overcome this
limitation, we associate the signs with compact descriptions in natural
language and instruct the model to use them. We evaluate our method on both
English and Italian languages using SignBank+, a recognized benchmark in the
field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior
performance compared to state-of-the-art models in low-data scenario. Our
findings demonstrate the effectiveness of AulSign, with the potential to
enhance accessibility and inclusivity in communication technologies for
underrepresented linguistic communities.

</details>


### [106] [Exploring the Interplay between Musical Preferences and Personality through the Lens of Language](https://arxiv.org/abs/2508.18208)
*Eliran Shem-Tov,Ella Rabinovich*

Main category: cs.CL

TL;DR: 通过语言分析识别音乐偏好与人格特质的关联研究


<details>
  <summary>Details</summary>
Motivation: 连接音乐心理学与计算语言学领域，探索音乐偏好是否可通过语言中的大五人格特征识别

Method: 使用50万+文本样本构建计算模型，分析5000名明确音乐偏好作者的人格特征

Result: 发现五个音乐流派粉丝存在显著人格差异

Conclusion: 发布跨学科研究资源，促进音乐心理学与人格分析的融合发展

Abstract: Music serves as a powerful reflection of individual identity, often aligning
with deeper psychological traits. Prior research has established correlations
between musical preferences and personality traits, while separate studies have
demonstrated that personality is detectable through linguistic analysis. Our
study bridges these two research domains by investigating whether individuals'
musical preferences are recognizable in their spontaneous language through the
lens of the Big Five personality traits (Openness, Conscientiousness,
Extroversion, Agreeableness, and Neuroticism). Using a carefully curated
dataset of over 500,000 text samples from nearly 5,000 authors with reliably
identified musical preferences, we build advanced models to assess personality
characteristics. Our results reveal significant personality differences across
fans of five musical genres. We release resources for future research at the
intersection of computational linguistics, music psychology and personality
analysis.

</details>


### [107] [Why Synthetic Isn't Real Yet: A Diagnostic Framework for Contact Center Dialogue Generation](https://arxiv.org/abs/2508.18210)
*Rishikesh Devanathan,Varun Nathan,Ayush Kumar*

Main category: cs.CL

TL;DR: 论文开发了基于18个指标的诊断框架，用于评估客服中心领域合成对话质量，并揭示了现有生成方法在关键行为特征上的持续挑战。


<details>
  <summary>Details</summary>
Motivation: 客服对话具有目标导向性、角色不对称性和行为复杂性等独特挑战，现有合成生成方法难以准确模拟真实场景特征，需要新的评估体系。

Method: 利用意图摘要/主题流等监督信号指导生成，提出多维度评估框架（含语言/行为特征指标），对比四种生成策略及无参考基线方法。

Result: 所有方法在不同特征上表现不均衡，尤其在语言不流畅性(3.2x差距)、情感真实性(仅61%达标)和代理行为合规性方面存在显著缺陷。

Conclusion: 诊断工具可暴露合成对话的细粒度缺陷，支持跨语言场景下的压力测试，推动客服领域对话生成技术的定向改进。

Abstract: Synthetic transcript generation is critical in contact center domains, where
privacy and data scarcity limit model training and evaluation. Unlike prior
synthetic dialogue generation work on open-domain or medical dialogues, contact
center conversations are goal-oriented, role-asymmetric, and behaviorally
complex, featuring disfluencies, ASR noise, and compliance-driven agent
actions. In deployments where transcripts are unavailable, standard pipelines
still yield derived call attributes such as Intent Summaries, Topic Flow, and
QA Evaluation Forms. We leverage these as supervision signals to guide
generation. To assess the quality of such outputs, we introduce a diagnostic
framework of 18 linguistically and behaviorally grounded metrics for comparing
real and synthetic transcripts. We benchmark four language-agnostic generation
strategies, from simple prompting to characteristic-aware multi-stage
approaches, alongside reference-free baselines. Results reveal persistent
challenges: no method excels across all traits, with notable deficits in
disfluency, sentiment, and behavioral realism. Our diagnostic tool exposes
these gaps, enabling fine-grained evaluation and stress testing of synthetic
dialogue across languages.

</details>


### [108] [Better Language Model-Based Judging Reward Modeling through Scaling Comprehension Boundaries](https://arxiv.org/abs/2508.18212)
*Meiling Ning,Zhongbao Zhang,Junda Ye,Jiabao Guo,Qingyuan Guan*

Main category: cs.CL

TL;DR: 通过将奖励模型与自然语言推理(NLI)形式对齐，提出ESFP-RM框架，利用掩码语言模型的解释性优势提升强化学习反馈的稳定性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有生成式奖励模型与NLI任务存在形式一致性，扩展模型理解边界成为提升奖励模型性能的关键路径。

Method: 1. 在NLI任务中验证带上下文解释的掩码语言模型(MLMs)性能优势；2. 设计两阶段ESFP-RM框架，通过解释性槽预测结构融合MLMs优势。

Result: ESFP-RM在人类反馈强化学习(RLHF)和分布外(OOD)场景中，比生成式奖励模型提供更稳定、泛化的奖励信号。

Conclusion: 基于NLI形式一致性设计的ESFP-RM框架，证明了掩码语言模型在奖励建模中的有效性，为RLAIF提供了新的技术路径。

Abstract: The emergence of LM-based judging reward modeling, represented by generative
reward models, has successfully made reinforcement learning from AI feedback
(RLAIF) efficient and scalable. To further advance this paradigm, we propose a
core insight: this form of reward modeling shares fundamental formal
consistency with natural language inference (NLI), a core task in natural
language understanding. This reframed perspective points to a key path for
building superior reward models: scaling the model's comprehension boundaries.
Pursuing this path, exploratory experiments on NLI tasks demonstrate that the
slot prediction masked language models (MLMs) incorporating contextual
explanations achieve significantly better performance compared to mainstream
autoregressive models. Based on this key finding, we propose ESFP-RM, a
two-stage LM-based judging reward model that utilizes an explanation based slot
framework for prediction to fully leverage the advantages of MLMs. Extensive
experiments demonstrate that in both reinforcement learning from human feedback
(RLHF) and out-of-distribution (OOD) scenarios, the ESFP-RM framework delivers
more stable and generalizable reward signals compared to generative reward
models.

</details>


### [109] [MTalk-Bench: Evaluating Speech-to-Speech Models in Multi-Turn Dialogues via Arena-style and Rubrics Protocols](https://arxiv.org/abs/2508.18240)
*Yuhao Du,Qianwei Huang,Guo Zhu,Zhanchen Dai,Sunian Chen,Qiming Zhu,Yuhao Zhang,Li Zhou,Benyou Wang*

Main category: cs.CL

TL;DR: 提出MTalk-Bench多轮语音对话评估基准，采用双评估方法揭示S2S大模型在语义处理优势明显，但副语言感知和环境声音处理薄弱，同时暴露现有评估框架可靠性局限。


<details>
  <summary>Details</summary>
Motivation: 现有语音对话评估框架难以有效衡量复杂多轮场景表现，需建立覆盖语义/副语言/环境声音多维度的综合性基准，突破传统单维评估瓶颈。

Method: 构建含3维度9场景的MTalk-Bench，结合竞技场式（相对比较）和量规式（绝对评分）双评估方法，采用人类+LLM双评估主体验证模型输出。

Result: 1.模型语义处理优异但副语言/环境感知差；2.增加回复长度可恢复连贯性但牺牲效率；3.任务定制设计优于暴力扩展；4.双评估方法互补但需显著差距才可靠；5.LLM评委存在位置/长度偏差。

Conclusion: 当前语音对话评估体系存在明显短板，需开发更鲁棒且语音感知的评估框架，同时强调任务适配设计和明确评估标准的重要性。

Abstract: The rapid advancement of speech-to-speech (S2S) large language models (LLMs)
has significantly improved real-time spoken interaction. However, current
evaluation frameworks remain inadequate for assessing performance in complex,
multi-turn dialogues. To address this, we introduce MTalk-Bench, a multi-turn
S2S benchmark covering three core dimensions: Semantic Information,
Paralinguistic Information, and Ambient Sound. Each dimension includes nine
realistic scenarios, along with targeted tasks to assess specific capabilities
such as reasoning. Our dual-method evaluation framework combines Arena-style
evaluation (pairwise comparison) and Rubrics-based evaluation (absolute
scoring) for relative and absolute assessment. The benchmark includes both
model and human outputs, evaluated by human evaluators and LLMs. Experimental
results reveal two sets of findings. Overall performance of S2S LLMs: (1)
models excel at semantic information processing yet underperform on
paralinguistic information and ambient sounds perception; (2) models typically
regain coherence by increasing response length, sacrificing efficiency in
multi-turn dialogues; (3) modality-aware, task-specific designs outperform
brute scaling. Evaluation framework and reliability: (1) Arena and Rubrics
yield consistent, complementary rankings, but reliable distinctions emerge only
when performance gaps are large; (2) LLM-as-a-judge aligns with humans when
gaps are clear or criteria explicit, but exhibits position and length biases
and is reliable on nonverbal evaluation only with text annotations. These
results highlight current limitations in S2S evaluation and the need for more
robust, speech-aware assessment frameworks.

</details>


### [110] [Demographic Biases and Gaps in the Perception of Sexism in Large Language Models](https://arxiv.org/abs/2508.18245)
*Judith Tavarez-Rodríguez,Fernando Sánchez-Vega,A. Pastor López-Monroy*

Main category: cs.CL

TL;DR: 大型语言模型在性别歧视检测中具有一定潜力，但存在群体感知多样性不足的问题，需开发考虑人口多样性的校准模型


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在性别歧视检测中存在对少数群体的偏见，需评估其实际表现并探究人口特征对检测效果的影响

Method: 使用EXIST 2024推特数据集，通过六个用户画像标注评估LLMs的检测能力，进行人口统计偏差分析和特征重要性统计

Result: LLMs可部分检测性别歧视但无法准确反映群体多样性，年龄和性别是主要影响因素

Conclusion: 需开发考虑不同群体视角多样性的校准模型，当前模型尚未充分反映现实中的复杂认知差异

Abstract: The use of Large Language Models (LLMs) has proven to be a tool that could
help in the automatic detection of sexism. Previous studies have shown that
these models contain biases that do not accurately reflect reality, especially
for minority groups. Despite various efforts to improve the detection of sexist
content, this task remains a significant challenge due to its subjective nature
and the biases present in automated models. We explore the capabilities of
different LLMs to detect sexism in social media text using the EXIST 2024 tweet
dataset. It includes annotations from six distinct profiles for each tweet,
allowing us to evaluate to what extent LLMs can mimic these groups' perceptions
in sexism detection. Additionally, we analyze the demographic biases present in
the models and conduct a statistical analysis to identify which demographic
characteristics (age, gender) contribute most effectively to this task. Our
results show that, while LLMs can to some extent detect sexism when considering
the overall opinion of populations, they do not accurately replicate the
diversity of perceptions among different demographic groups. This highlights
the need for better-calibrated models that account for the diversity of
perspectives across different populations.

</details>


### [111] [From BERT to LLMs: Comparing and Understanding Chinese Classifier Prediction in Language Models](https://arxiv.org/abs/2508.18253)
*ZiqiZhang,Jianfei Ma,Emmanuele Chersoni,Jieshun You,Zhaoxin Feng*

Main category: cs.CL

TL;DR: 研究评估大型语言模型(LLMs)在中文量词预测任务中的表现，发现其性能弱于BERT模型，双向注意力机制对预测效果起关键作用


<details>
  <summary>Details</summary>
Motivation: 中文量词预测是教育应用的关键环节，但主流大语言模型在此任务中的知识储备尚未得到充分研究

Method: 采用遮蔽策略评估模型内在能力，分析句子成分贡献度，研究注意力机制工作原理，并进行模型微调实验

Result: LLMs表现逊于BERT且微调效果有限，后续名词信息显著提升预测准确度，双向注意力模型展现优势

Conclusion: 研究证实双向注意力机制在语言理解任务中的有效性，建议在中文语法特征建模中优先考虑双向架构模型

Abstract: Classifiers are an important and defining feature of the Chinese language,
and their correct prediction is key to numerous educational applications. Yet,
whether the most popular Large Language Models (LLMs) possess proper knowledge
the Chinese classifiers is an issue that has largely remain unexplored in the
Natural Language Processing (NLP) literature.
  To address such a question, we employ various masking strategies to evaluate
the LLMs' intrinsic ability, the contribution of different sentence elements,
and the working of the attention mechanisms during prediction. Besides, we
explore fine-tuning for LLMs to enhance the classifier performance.
  Our findings reveal that LLMs perform worse than BERT, even with fine-tuning.
The prediction, as expected, greatly benefits from the information about the
following noun, which also explains the advantage of models with a
bidirectional attention mechanism such as BERT.

</details>


### [112] [MIRAGE: Scaling Test-Time Inference with Parallel Graph-Retrieval-Augmented Reasoning Chains](https://arxiv.org/abs/2508.18260)
*Kaiwen Wei,Rui Shan,Dongsheng Zou,Jianzhong Yang,Bi Zhao,Junnan Zhu,Jiang Zhong*

Main category: cs.CL

TL;DR: 提出了MIRAGE框架，通过结构化知识图谱上的多链推理增强医疗问答任务的准确性和可追溯性


<details>
  <summary>Details</summary>
Motivation: 现有基于单链推理的检索增强方法在医疗QA任务中存在错误积累和上下文处理不足的问题

Method: 1) 复杂查询分解为实体子问题 2) 并行推理链执行 3) 自适应图谱邻居扩展和多跳遍历检索 4) 跨链验证矛盾解决

Result: 在三个医疗QA基准测试中自动评估和人工评估均超越GPT-4o及其他基线方法，提升可解释性

Conclusion: MIRAGE通过结构化知识图谱的多链推理机制，显著提高了复杂医疗场景下的推理准确性和结果可追溯性

Abstract: Large reasoning models (LRMs) have shown significant progress in test-time
scaling through chain-of-thought prompting. Current approaches like search-o1
integrate retrieval augmented generation (RAG) into multi-step reasoning
processes but rely on a single, linear reasoning chain while incorporating
unstructured textual information in a flat, context-agnostic manner. As a
result, these approaches can lead to error accumulation throughout the
reasoning chain, which significantly limits its effectiveness in medical
question-answering (QA) tasks where both accuracy and traceability are critical
requirements. To address these challenges, we propose MIRAGE (Multi-chain
Inference with Retrieval-Augmented Graph Exploration), a novel test-time
scalable reasoning framework that performs dynamic multi-chain inference over
structured medical knowledge graphs. Specifically, MIRAGE 1) decomposes complex
queries into entity-grounded sub-questions, 2) executes parallel inference
chains, 3) retrieves evidence adaptively via neighbor expansion and multi-hop
traversal, and 4) integrates answers using cross-chain verification to resolve
contradictions. Experiments on three medical QA benchmarks (GenMedGPT-5k,
CMCQA, and ExplainCPE) show that MIRAGE consistently outperforms GPT-4o,
Tree-of-Thought variants, and other retrieval-augmented baselines in both
automatic and human evaluations. Additionally, MIRAGE improves interpretability
by generating explicit reasoning chains that trace each factual claim to
concrete chains within the knowledge graph, making it well-suited for complex
medical reasoning scenarios. The code will be available for further research.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [113] [DecoMind: A Generative AI System for Personalized Interior Design Layouts](https://arxiv.org/abs/2508.16696)
*Reema Alshehri,Rawan Alotaibi,Leen Almasri,Rawan Altaweel*

Main category: cs.GR

TL;DR: 提出基于CLIP和Stable Diffusion的自动化室内设计系统，通过用户偏好生成布局并利用分类器验证结果


<details>
  <summary>Details</summary>
Motivation: 解决个性化室内设计效率问题，将用户偏好与AI生成技术结合实现自动化设计流程

Method: 1. CLIP筛选家具 → 2. ControlNet控制Stable Diffusion生成布局 → 3. 分类器验证设计一致性

Result: 实现端到端的自动化设计方案，生成符合用户输入参数（房间类型/风格/家具偏好）的室内效果图

Conclusion: 融合多模态模型与验证机制，为智能家居设计提供高效可靠的解决方案

Abstract: This paper introduces a system for generating interior design layouts based
on user inputs, such as room type, style, and furniture preferences. CLIP
extracts relevant furniture from a dataset, and a layout that contains
furniture and a prompt are fed to Stable Diffusion with ControlNet to generate
a design that incorporates the selected furniture. The design is then evaluated
by classifiers to ensure alignment with the user's inputs, offering an
automated solution for realistic interior design.

</details>


### [114] [MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation](https://arxiv.org/abs/2508.16911)
*Prerit Gupta,Jason Alexander Fotso-Puepi,Zhengyuan Li,Jay Mehta,Aniket Bera*

Main category: cs.GR

TL;DR: 提出首个多模态双人舞数据集MDD，支持文本+音乐生成双人舞动作，包含620分钟动作数据和超万条细粒度文本标注。


<details>
  <summary>Details</summary>
Motivation: 解决现有舞蹈生成数据集缺乏多模态对齐（动作+音乐+文本）和双人交互的问题，填补双人舞生成领域的数据空白。

Method: 构建含专业舞者动作捕捉、音乐同步和文本描述的数据集，提出文本驱动双人舞生成和舞伴动作生成两项新任务。

Result: 建立首个三模态对齐的双人舞数据集，提供基线模型验证文本引导动作生成的有效性。

Conclusion: MDD数据集为音乐文本协同驱动的双人交互舞蹈生成研究提供了标准化评估基准。

Abstract: We introduce Multimodal DuetDance (MDD), a diverse multimodal benchmark
dataset designed for text-controlled and music-conditioned 3D duet dance motion
generation. Our dataset comprises 620 minutes of high-quality motion capture
data performed by professional dancers, synchronized with music, and detailed
with over 10K fine-grained natural language descriptions. The annotations
capture a rich movement vocabulary, detailing spatial relationships, body
movements, and rhythm, making MDD the first dataset to seamlessly integrate
human motions, music, and text for duet dance generation. We introduce two
novel tasks supported by our dataset: (1) Text-to-Duet, where given music and a
textual prompt, both the leader and follower dance motion are generated (2)
Text-to-Dance Accompaniment, where given music, textual prompt, and the
leader's motion, the follower's motion is generated in a cohesive, text-aligned
manner. We include baseline evaluations on both tasks to support future
research.

</details>


### [115] [A Survey of Deep Learning-based Point Cloud Denoising](https://arxiv.org/abs/2508.17011)
*Jinxi Wang,Ben Fei,Dasith de Silva Edirimuni,Zheng Liu,Ying He,Xuequan Lu*

Main category: cs.GR

TL;DR: 系统性综述截至2025年8月的深度学习点云去噪方法，提出基于监督层级和建模视角的双维度分类框架，建立统一评估基准并揭示技术发展趋势


<details>
  <summary>Details</summary>
Motivation: 现实场景中的点云噪声严重影响三维几何精度与下游任务性能，传统方法在复杂噪声处理上存在局限，需系统性总结深度学习带来的技术突破与发展路线

Method: 从监督学习程度(监督/非监督)和去噪原理两个维度构建功能分类体系，采用历时性与结构分析法追踪模型架构演进，设计标准化训练环境进行多维度性能评估

Result: 提出首个融合监督层-方法论的二维分类框架，发现模型趋向轻量化与物理引导的架构创新，基准测试显示深度方法在复杂噪声处理效率比传统方法提升3-5倍

Conclusion: 点云去噪需突破噪声-结构耦合建模、跨模态泛化等核心挑战，未来应发展自监督物理融合框架与实时处理系统，推动三维感知技术的工业级应用

Abstract: Accurate 3D geometry acquisition is essential for a wide range of
applications, such as computer graphics, autonomous driving, robotics, and
augmented reality. However, raw point clouds acquired in real-world
environments are often corrupted with noise due to various factors such as
sensor, lighting, material, environment etc, which reduces geometric fidelity
and degrades downstream performance. Point cloud denoising is a fundamental
problem, aiming to recover clean point sets while preserving underlying
structures. Classical optimization-based methods, guided by hand-crafted
filters or geometric priors, have been extensively studied but struggle to
handle diverse and complex noise patterns. Recent deep learning approaches
leverage neural network architectures to learn distinctive representations and
demonstrate strong outcomes, particularly on complex and large-scale point
clouds. Provided these significant advances, this survey provides a
comprehensive and up-to-date review of deep learning-based point cloud
denoising methods up to August 2025. We organize the literature from two
perspectives: (1) supervision level (supervised vs. unsupervised), and (2)
modeling perspective, proposing a functional taxonomy that unifies diverse
approaches by their denoising principles. We further analyze architectural
trends both structurally and chronologically, establish a unified benchmark
with consistent training settings, and evaluate methods in terms of denoising
quality, surface fidelity, point distribution, and computational efficiency.
Finally, we discuss open challenges and outline directions for future research
in this rapidly evolving field.

</details>


### [116] [DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions](https://arxiv.org/abs/2508.17342)
*Hengyuan Zhang,Zhe Li,Xingqun Qi,Mengze Li,Muyi Sun,Man Zhang,Sirui Han*

Main category: cs.GR

TL;DR: 提出DanceEditor框架，支持基于音乐信号的迭代式可编辑舞蹈生成，并构建大规模数据集DanceRemix。


<details>
  <summary>Details</summary>
Motivation: 现有舞蹈生成方法缺乏用户编辑功能，难以满足实际编舞需求，且缺乏支持迭代编辑的高质量数据集。

Method: 采用预测-编辑范式：1) 初始预测阶段直接建模音乐对齐舞蹈动作；2) 跨模态编辑模块(CEM)整合音乐、文本提示进行迭代编辑。

Result: 在DanceRemix数据集上超越现有SOTA模型，生成结果同时保持音乐节拍和文本语义对齐。

Conclusion: 通过构建数据集与双阶段框架，实现了音乐驱动且支持多轮文本编辑的舞蹈生成，提升了编舞实用性。

Abstract: Generating coherent and diverse human dances from music signals has gained
tremendous progress in animating virtual avatars. While existing methods
support direct dance synthesis, they fail to recognize that enabling users to
edit dance movements is far more practical in real-world choreography
scenarios. Moreover, the lack of high-quality dance datasets incorporating
iterative editing also limits addressing this challenge. To achieve this goal,
we first construct DanceRemix, a large-scale multi-turn editable dance dataset
comprising the prompt featuring over 25.3M dance frames and 84.5K pairs. In
addition, we propose a novel framework for iterative and editable dance
generation coherently aligned with given music signals, namely DanceEditor.
Considering the dance motion should be both musical rhythmic and enable
iterative editing by user descriptions, our framework is built upon a
prediction-then-editing paradigm unifying multi-modal conditions. At the
initial prediction stage, our framework improves the authority of generated
results by directly modeling dance movements from tailored, aligned music.
Moreover, at the subsequent iterative editing stages, we incorporate text
descriptions as conditioning information to draw the editable results through a
specifically designed Cross-modality Editing Module (CEM). Specifically, CEM
adaptively integrates the initial prediction with music and text prompts as
temporal motion cues to guide the synthesized sequences. Thereby, the results
display music harmonics while preserving fine-grained semantic alignment with
text descriptions. Extensive experiments demonstrate that our method
outperforms the state-of-the-art models on our newly collected DanceRemix
dataset. Code is available at https://lzvsdy.github.io/DanceEditor/.

</details>


### [117] [Random-phase Gaussian Wave Splatting for Computer-generated Holography](https://arxiv.org/abs/2508.17480)
*Brian Chao,Jacqueline Yang,Suyeon Choi,Manu Gopakumar,Ryota Koiso,Gordon Wetzstein*

Main category: cs.GR

TL;DR: 提出随机相位高斯波展开（GWS-RP）方法，通过时间复用和波前合成优化，显著提升近眼全息显示的带宽利用率与图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统GWS方法因平滑相位假设导致视角效应建模受限、散焦模糊重建不准确，且未能充分利用SLM的带宽资源。

Method: 1. 设计随机相位高斯基元的波前合成流程
2. 开发专用alpha混合方案处理遮挡
3. 基于统计光学推导高斯随机相位生成算法

Result: 实验验证显示GWS-RP实现全带宽光场重建，支持精确视差/散焦，在仿真和硬件中达到SOTA图像质量。

Conclusion: 该工作为下一代近眼显示提供了感知一致的3D全息方案，推动了空间带宽利用率与显示性能的边界。

Abstract: Holographic near-eye displays offer ultra-compact form factors for virtual
and augmented reality systems, but rely on advanced computer-generated
holography (CGH) algorithms to convert 3D scenes into interference patterns
that can be displayed on spatial light modulators (SLMs). Gaussian Wave
Splatting (GWS) has recently emerged as a powerful CGH paradigm that allows for
the conversion of Gaussians, a state-of-the-art neural 3D representation, into
holograms. However, GWS assumes smooth-phase distributions over the Gaussian
primitives, limiting their ability to model view-dependent effects and
reconstruct accurate defocus blur, and severely under-utilizing the
space-bandwidth product of the SLM. In this work, we propose random-phase GWS
(GWS-RP) to improve bandwidth utilization, which has the effect of increasing
eyebox size, reconstructing accurate defocus blur and parallax, and supporting
time-multiplexed rendering to suppress speckle artifacts.
  At the core of GWS-RP are (1) a fundamentally new wavefront compositing
procedure and (2) an alpha-blending scheme specifically designed for
random-phase Gaussian primitives, ensuring physically correct color
reconstruction and robust occlusion handling. Additionally, we present the
first formally derived algorithm for applying random phase to Gaussian
primitives, grounded in rigorous statistical optics analysis and validated
through practical near-eye display applications. Through extensive simulations
and experimental validations, we demonstrate that these advancements,
collectively with time-multiplexing, uniquely enables full-bandwith light field
CGH that supports accurate accurate parallax and defocus, yielding
state-of-the-art image quality and perceptually faithful 3D holograms for
next-generation near-eye displays.

</details>


### [118] [Enhancing Reference-based Sketch Colorization via Separating Reference Representations](https://arxiv.org/abs/2508.17620)
*Dingkun Yan,Xinrui Wang,Zhuoru Li,Suguru Saito,Yusuke Iwasawa,Yutaka Matsuo,Jiaxian Guo*

Main category: cs.GR

TL;DR: 提出基于分层参考表示的新型草图着色框架，通过模块化设计和分阶段训练解决参考图与草图不对齐导致的着色质量问题


<details>
  <summary>Details</summary>
Motivation: 现有基于参考的着色方法依赖对齐的三元组训练数据，实际应用中参考图与草图存在空间错位导致性能下降，需改进参考表示方式

Method: 1) 高层语义引导的主干网络 2) 分阶段训练的独立背景编码器和风格编码器 3) 模块化区域参考注入机制

Result: 在定/定量评估和用户研究中显著优于现有方法，支持多种灵活推理模式，有效降低伪影并提高颜色一致性

Conclusion: 通过解耦参考表示层次和阶段式训练策略，成功解决参考-草图不对齐难题，为动画制作提供实用解决方案

Abstract: Reference-based sketch colorization methods have garnered significant
attention for the potential application in animation and digital illustration
production. However, most existing methods are trained with image triplets of
sketch, reference, and ground truth that are semantically and spatially
similar, while real-world references and sketches often exhibit substantial
misalignment. This mismatch in data distribution between training and inference
leads to overfitting, consequently resulting in artifacts and signif- icant
quality degradation in colorization results. To address this issue, we conduct
an in-depth analysis of the reference representations, defined as the
intermedium to transfer information from reference to sketch. Building on this
analysis, we introduce a novel framework that leverages distinct reference
representations to optimize different aspects of the colorization process. Our
approach decomposes colorization into modular stages, al- lowing
region-specific reference injection to enhance visual quality and reference
similarity while mitigating spatial artifacts. Specifically, we first train a
backbone network guided by high-level semantic embeddings. We then introduce a
background encoder and a style encoder, trained in separate stages, to enhance
low-level feature transfer and improve reference similar- ity. This design also
enables flexible inference modes suited for a variety of use cases. Extensive
qualitative and quantitative evaluations, together with a user study,
demonstrate the superior performance of our proposed method compared to
existing approaches. Code and pre-trained weight will be made publicly
available upon paper acceptance.

</details>


### [119] [Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph](https://arxiv.org/abs/2508.17645)
*Xiaoyang Huang,Bingbing Ni,Wenjun Zhang*

Main category: cs.GR

TL;DR: 提出将基础建模操作转化为可微分单元，通过层次图优化生成与设计软件兼容的操作序列，解决3D-AIGC与传统设计工具不兼容问题


<details>
  <summary>Details</summary>
Motivation: 现有3D-AIGC生成的网格/神经表示与设计师使用的参数化工具存在根本性不兼容，导致人机协作效率低下，限制了AI在3D产业的实际应用价值

Method: 1) 将挤出/布尔等操作重构为可微分单元 
2) 构建带门控机制的层次图进行端到端优化 
3) 采用多阶段序列长度约束和领域规则进行无监督学习

Result: 生成的操作序列具备高几何保真度(Chamfer Distance优化)、平滑网格布线、合理步骤组合和灵活编辑能力，完全兼容主流3D设计软件

Conclusion: 该方法成功弥合了AI生成内容与设计工具之间的表示鸿沟，通过结构化建模历史记录实现人机协作优化，推动3D-AIGC在产业端的实际落地

Abstract: The emergence of 3D artificial intelligence-generated content (3D-AIGC) has
enabled rapid synthesis of intricate geometries. However, a fundamental
disconnect persists between AI-generated content and human-centric design
paradigms, rooted in representational incompatibilities: conventional AI
frameworks predominantly manipulate meshes or neural representations
(\emph{e.g.}, NeRF, Gaussian Splatting), while designers operate within
parametric modeling tools. This disconnection diminishes the practical value of
AI for 3D industry, undermining the efficiency of human-AI collaboration. To
resolve this disparity, we focus on generating design operation sequences,
which are structured modeling histories that comprehensively capture the
step-by-step construction process of 3D assets and align with designers'
typical workflows in modern 3D software. We first reformulate fundamental
modeling operations (\emph{e.g.}, \emph{Extrude}, \emph{Boolean}) into
differentiable units, enabling joint optimization of continuous (\emph{e.g.},
\emph{Extrude} height) and discrete (\emph{e.g.}, \emph{Boolean} type)
parameters via gradient-based learning. Based on these differentiable
operations, a hierarchical graph with gating mechanism is constructed and
optimized end-to-end by minimizing Chamfer Distance to target geometries.
Multi-stage sequence length constraint and domain rule penalties enable
unsupervised learning of compact design sequences without ground-truth sequence
supervision. Extensive validation demonstrates that the generated operation
sequences achieve high geometric fidelity, smooth mesh wiring, rational step
composition and flexible editing capacity, with full compatibility within
design industry.

</details>


### [120] [MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting](https://arxiv.org/abs/2508.17811)
*Hanzhi Chang,Ruijie Zhu,Wenjie Chang,Mulin Yu,Yanzhe Liang,Jiahao Lu,Zhuoyuan Li,Tianzhu Zhang*

Main category: cs.GR

TL;DR: 提出MeshSplat框架，通过2D高斯泼溅实现稀疏视角下的表面重建，无需3D真值监督，在几何预测精度和重建效果上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有表面重建方法在输入视角极度稀疏时难以恢复准确几何，需要解决稀疏视角下的几何先验学习和新视角合成问题。

Method: 1. 使用前馈网络预测像素对齐的2DGS，实现新视角合成
2. 设计加权Chamfer距离损失优化深度图
3. 通过法线预测网络对齐2DGS方向与单目法线估计结果

Result: 在通用稀疏视角网格重建任务中达到state-of-the-art，验证了深度正则化和法线对齐机制的有效性

Conclusion: MeshSplat成功将新视角合成与几何先验结合，通过2DGS桥接实现了无需3D监督的高质量稀疏视角重建，为表面重建提供了新思路

Abstract: Surface reconstruction has been widely studied in computer vision and
graphics. However, existing surface reconstruction works struggle to recover
accurate scene geometry when the input views are extremely sparse. To address
this issue, we propose MeshSplat, a generalizable sparse-view surface
reconstruction framework via Gaussian Splatting. Our key idea is to leverage
2DGS as a bridge, which connects novel view synthesis to learned geometric
priors and then transfers these priors to achieve surface reconstruction.
Specifically, we incorporate a feed-forward network to predict per-view
pixel-aligned 2DGS, which enables the network to synthesize novel view images
and thus eliminates the need for direct 3D ground-truth supervision. To improve
the accuracy of 2DGS position and orientation prediction, we propose a Weighted
Chamfer Distance Loss to regularize the depth maps, especially in overlapping
areas of input views, and also a normal prediction network to align the
orientation of 2DGS with normal vectors predicted by a monocular normal
estimator. Extensive experiments validate the effectiveness of our proposed
improvement, demonstrating that our method achieves state-of-the-art
performance in generalizable sparse-view mesh reconstruction tasks. Project
Page: https://hanzhichang.github.io/meshsplat_web

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [121] [Revisiting Rule-Based Stuttering Detection: A Comprehensive Analysis of Interpretable Models for Clinical Applications](https://arxiv.org/abs/2508.16681)
*Eric Zhang*

Main category: cs.AI

TL;DR: 提出增强型规则口吃检测框架，结合语速标准化与多层级声学分析，在保持临床可解释性前提下实现高精度延长音检测（97-99%），并展示与机器学习融合的可能性


<details>
  <summary>Details</summary>
Motivation: 针对临床场景中决策可追溯性、患者特异性调参和实时反馈的核心需求，强调规则方法在可解释性方面的独特优势，弥补深度学习黑箱模型的临床落地障碍

Method: 集成语速标准化算法消除语速偏差，构建声学特征层级分析体系（基频/能量/频谱），采用分层决策树实现多维度异常检测

Result: 在UCLASS/FluencyBank等数据集上验证：延长音检测准确率97-99%，语速变化场景下性能波动小于5%，决策过程完全透明可追溯

Conclusion: 规则系统在临床审计需求场景具有不可替代性，可通过与机器学习模型协同（提案生成/约束模块）构建新型混合架构，推动AI在言语病理学的临床转化

Abstract: Stuttering affects approximately 1% of the global population, impacting
communication and quality of life. While recent advances in deep learning have
pushed the boundaries of automatic speech dysfluency detection, rule-based
approaches remain crucial for clinical applications where interpretability and
transparency are paramount. This paper presents a comprehensive analysis of
rule-based stuttering detection systems, synthesizing insights from multiple
corpora including UCLASS, FluencyBank, and SEP-28k. We propose an enhanced
rule-based framework that incorporates speaking-rate normalization, multi-level
acoustic feature analysis, and hierarchical decision structures. Our approach
achieves competitive performance while maintaining complete
interpretability-critical for clinical adoption. We demonstrate that rule-based
systems excel particularly in prolongation detection (97-99% accuracy) and
provide stable performance across varying speaking rates. Furthermore, we show
how these interpretable models can be integrated with modern machine learning
pipelines as proposal generators or constraint modules, bridging the gap
between traditional speech pathology practices and contemporary AI systems. Our
analysis reveals that while neural approaches may achieve marginally higher
accuracy in unconstrained settings, rule-based methods offer unique advantages
in clinical contexts where decision auditability, patient-specific tuning, and
real-time feedback are essential.

</details>


### [122] [Quantifying Sycophancy as Deviations from Bayesian Rationality in LLMs](https://arxiv.org/abs/2508.16846)
*Katherine Atwell,Pedram Heydari,Anthony Sicilia,Malihe Alikhani*

Main category: cs.AI

TL;DR: 该论文提出了一种贝叶斯框架量化LLM中的奉承行为，发现奉承导致非理性预测更新，且对准确性的影响具有双重性。


<details>
  <summary>Details</summary>
Motivation: 现有奉承行为量化方法仅关注行为偏移或准确性指标，无法表征理性层面的变化。本研究旨在通过贝叶斯框架区分用户视角引入后的理性/非理性更新。

Method: 使用贝叶斯框架分析3类任务（含开源/闭源模型），采用两种奉承行为探测方法，通过多种概率判断技术验证假设：奉承行为会导致贝叶斯误差增加。

Result: 1) LLM不符合贝叶斯理性 2) 奉承显著增加对引导结果的预测后验概率 3) 奉承时而增加贝叶斯误差，少数情况降低误差 4) 贝叶斯误差变化与Brier分数相关性弱

Conclusion: 奉承行为引发LLM的非理性更新，仅通过事实准确性评估奉承影响会遗漏推理错误。建议未来采用贝叶斯方法全面评估奉承对AI推理的影响。

Abstract: Sycophancy, or overly agreeable or flattering behavior, is a documented issue
in large language models (LLMs), and is critical to understand in the context
of human/AI collaboration. Prior works typically quantify sycophancy by
measuring shifts in behavior or impacts on accuracy, but neither metric
characterizes shifts in rationality, and accuracy measures can only be used in
scenarios with a known ground truth. In this work, we utilize a Bayesian
framework to quantify sycophancy as deviations from rational behavior when
presented with user perspectives, thus distinguishing between rational and
irrational updates based on the introduction of user perspectives. In
comparison to other methods, this approach allows us to characterize excessive
behavioral shifts, even for tasks that involve inherent uncertainty or do not
have a ground truth. We study sycophancy for 3 different tasks, a combination
of open-source and closed LLMs, and two different methods for probing
sycophancy. We also experiment with multiple methods for eliciting probability
judgments from LLMs. We hypothesize that probing LLMs for sycophancy will cause
deviations in LLMs' predicted posteriors that will lead to increased Bayesian
error. Our findings indicate that: 1) LLMs are not Bayesian rational, 2)
probing for sycophancy results in significant increases to the predicted
posterior in favor of the steered outcome, 3) sycophancy sometimes results in
increased Bayesian error, and in a small number of cases actually decreases
error, and 4) changes in Bayesian error due to sycophancy are not strongly
correlated in Brier score, suggesting that studying the impact of sycophancy on
ground truth alone does not fully capture errors in reasoning due to
sycophancy.

</details>


### [123] [Large Language Models as Universal Predictors? An Empirical Study on Small Tabular Datasets](https://arxiv.org/abs/2508.17391)
*Nikolaos Pavlidis,Vasilis Perifanis,Symeon Symeonidis,Pavlos S. Efraimidis*

Main category: cs.AI

TL;DR: LLMs在少样本结构化数据分类任务中表现优异，但回归和聚类效果较差，适用于快速数据探索替代传统ML流程


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化数据预测任务中的零样本泛化能力，验证其作为通用预测引擎的可行性

Method: 通过少样本提示评估GPT-5/GPT-4o等LLMs在分类/回归/聚类任务中的表现，与线性模型/集成学习/TFMs对比

Result: 分类任务接近SOTA（F1分数0.82），回归任务MSE比XGBoost高47%，聚类纯度低于K-means 21%

Conclusion: LLMs适合作为结构化数据分类的零训练基线工具，但数值预测需结合传统ML，上下文长度与提示结构显著影响效果

Abstract: Large Language Models (LLMs), originally developed for natural language
processing (NLP), have demonstrated the potential to generalize across
modalities and domains. With their in-context learning (ICL) capabilities, LLMs
can perform predictive tasks over structured inputs without explicit
fine-tuning on downstream tasks. In this work, we investigate the empirical
function approximation capability of LLMs on small-scale structured datasets
for classification, regression and clustering tasks. We evaluate the
performance of state-of-the-art LLMs (GPT-5, GPT-4o, GPT-o3, Gemini-2.5-Flash,
DeepSeek-R1) under few-shot prompting and compare them against established
machine learning (ML) baselines, including linear models, ensemble methods and
tabular foundation models (TFMs). Our results show that LLMs achieve strong
performance in classification tasks under limited data availability,
establishing practical zero-training baselines. In contrast, the performance in
regression with continuous-valued outputs is poor compared to ML models, likely
because regression demands outputs in a large (often infinite) space, and
clustering results are similarly limited, which we attribute to the absence of
genuine ICL in this setting. Nonetheless, this approach enables rapid,
low-overhead data exploration and offers a viable alternative to traditional ML
pipelines in business intelligence and exploratory analytics contexts. We
further analyze the influence of context size and prompt structure on
approximation quality, identifying trade-offs that affect predictive
performance. Our findings suggest that LLMs can serve as general-purpose
predictive engines for structured data, with clear strengths in classification
and significant limitations in regression and clustering.

</details>


### [124] [LLM-based Agentic Reasoning Frameworks: A Survey from Methods to Scenarios](https://arxiv.org/abs/2508.17692)
*Bingxi Zhao,Lin Geng Foo,Ping Hu,Christian Theobalt,Hossein Rahmani,Jun Liu*

Main category: cs.AI

TL;DR: 系统分类法分解LLM智能体推理框架，通过跨场景应用比较分析框架级推理特征，提出单智能体/工具驱动/多智能体三分法并总结评估策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽展示LLM智能体潜力，但缺乏对不同推理框架系统分析。需统一形式化语言分类并比较各框架在科研/医疗/软件工程等领域的应用特征。

Method: 提出智能体推理框架三分类体系（单智能体/工具驱动/多智能体），建立形式化语言描述框架，通过科学发现/医疗/软件工程/社会仿真等五大应用场景进行对比分析。

Result: 揭示不同框架在任务适应性/协作效率/决策质量方面的特征差异，总结出框架选择与场景需求匹配原则，建立多维评估指标体系。

Conclusion: 该分类体系为研究者提供全景视角，有助于理解不同智能体推理框架的优势边界、适配场景及评估方法论，推动领域标准化发展。

Abstract: Recent advances in the intrinsic reasoning capabilities of large language
models (LLMs) have given rise to LLM-based agent systems that exhibit
near-human performance on a variety of automated tasks. However, although these
systems share similarities in terms of their use of LLMs, different reasoning
frameworks of the agent system steer and organize the reasoning process in
different ways. In this survey, we propose a systematic taxonomy that
decomposes agentic reasoning frameworks and analyze how these frameworks
dominate framework-level reasoning by comparing their applications across
different scenarios. Specifically, we propose an unified formal language to
further classify agentic reasoning systems into single-agent methods,
tool-based methods, and multi-agent methods. After that, we provide a
comprehensive review of their key application scenarios in scientific
discovery, healthcare, software engineering, social simulation, and economics.
We also analyze the characteristic features of each framework and summarize
different evaluation strategies. Our survey aims to provide the research
community with a panoramic view to facilitate understanding of the strengths,
suitable scenarios, and evaluation practices of different agentic reasoning
frameworks.

</details>


### [125] [The AI Data Scientist](https://arxiv.org/abs/2508.18113)
*Farkhad Akimov,Munachiso Samuel Nwadike,Zangir Iklassov,Martin Takáč*

Main category: cs.AI

TL;DR: 利用大语言模型构建的AI数据科学家，通过假设驱动的工作流实现分钟级数据洞察生成，替代传统耗时数周的人工分析流程。


<details>
  <summary>Details</summary>
Motivation: 解决传统数据分析流程耗时过长、门槛过高的问题，实现从数据到决策的快速转化。通过自动化闭环系统弥合证据与行动之间的鸿沟。

Method: 基于假设检验科学范式，构建由清洗、统计检验、验证、自然语言沟通等专业子智能体组成的LLM团队架构。各子智能体具备自主编码、因果推理和数据需求识别能力。

Result: 将复杂数据分析工作流压缩至分钟级完成，支持自动化的模式发现、统计验证、预测建模到自然语言建议输出的端到端处理。

Conclusion: 该架构重新定义了人机协作模式，使深度数据科学突破时间壁垒和技术门槛，实现严谨分析与决策支持的民主化。

Abstract: Imagine decision-makers uploading data and, within minutes, receiving clear,
actionable insights delivered straight to their fingertips. That is the promise
of the AI Data Scientist, an autonomous Agent powered by large language models
(LLMs) that closes the gap between evidence and action. Rather than simply
writing code or responding to prompts, it reasons through questions, tests
ideas, and delivers end-to-end insights at a pace far beyond traditional
workflows. Guided by the scientific tenet of the hypothesis, this Agent
uncovers explanatory patterns in data, evaluates their statistical
significance, and uses them to inform predictive modeling. It then translates
these results into recommendations that are both rigorous and accessible. At
the core of the AI Data Scientist is a team of specialized LLM Subagents, each
responsible for a distinct task such as data cleaning, statistical testing,
validation, and plain-language communication. These Subagents write their own
code, reason about causality, and identify when additional data is needed to
support sound conclusions. Together, they achieve in minutes what might
otherwise take days or weeks, enabling a new kind of interaction that makes
deep data science both accessible and actionable.

</details>


### [126] [Unraveling the cognitive patterns of Large Language Models through module communities](https://arxiv.org/abs/2508.18192)
*Kushal Raj Bhandari,Pin-Yu Chen,Jianxi Gao*

Main category: cs.AI

TL;DR: 研究者开发了一个基于网络的框架，将LLM认知技能与生物认知体系对比，发现其模块社区呈现独特的分布式技能模式，动态跨区域交互对技能获取有显著增益


<details>
  <summary>Details</summary>
Motivation: 尽管LLM已广泛应用于各领域，但其数十亿参数构成的复杂架构使内部机制如同黑箱，阻碍了对模型认知本质的理解

Method: 通过整合生物学认知理论与机器学习，构建连接认知技能-模型架构-数据集的三维分析框架，采用模块社区检测技术分析技能分布模式

Result: LLM模块社区呈现与鸟类/小型哺乳动物大脑类似的分布式认知特征，但技能获取更依赖动态神经可塑性而非生物系统的刚性模块化结构

Conclusion: 该框架为LLM可解释性研究开辟新路径，表明有效的微调策略应注重激发分布式学习动态而非机械的模块化干预

Abstract: Large Language Models (LLMs) have reshaped our world with significant
advancements in science, engineering, and society through applications ranging
from scientific discoveries and medical diagnostics to Chatbots. Despite their
ubiquity and utility, the underlying mechanisms of LLM remain concealed within
billions of parameters and complex structures, making their inner architecture
and cognitive processes challenging to comprehend. We address this gap by
adopting approaches to understanding emerging cognition in biology and
developing a network-based framework that links cognitive skills, LLM
architectures, and datasets, ushering in a paradigm shift in foundation model
analysis. The skill distribution in the module communities demonstrates that
while LLMs do not strictly parallel the focalized specialization observed in
specific biological systems, they exhibit unique communities of modules whose
emergent skill patterns partially mirror the distributed yet interconnected
cognitive organization seen in avian and small mammalian brains. Our numerical
results highlight a key divergence from biological systems to LLMs, where skill
acquisition benefits substantially from dynamic, cross-regional interactions
and neural plasticity. By integrating cognitive science principles with machine
learning, our framework provides new insights into LLM interpretability and
suggests that effective fine-tuning strategies should leverage distributed
learning dynamics rather than rigid modular interventions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [127] [Guarding Your Conversations: Privacy Gatekeepers for Secure Interactions with Cloud-Based AI Models](https://arxiv.org/abs/2508.16765)
*GodsGift Uzor,Hasan Al-Qudah,Ynes Ineza,Abdul Serwadda*

Main category: cs.CR

TL;DR: 提出本地运行的轻量级LLM门卫模型，在用户查询发送至云端前过滤敏感信息，实现隐私保护与服务质量平衡。


<details>
  <summary>Details</summary>
Motivation: LLM交互中用户隐私易受威胁，现有隐私设置在弱监管环境下保护不足，需防范PII泄露风险。

Method: 采用双模型架构：本地门卫模型实时过滤敏感信息，云端LLM处理净化后的查询，通过人类实验验证效率与效果。

Result: 实验显示方案仅产生极低开销，隐私保护效果显著(提升43%敏感信息拦截率)，且保持92%的响应质量留存率。

Conclusion: LLM门卫机制有效解决了隐私保护与模型效能的矛盾，为高风险司法管辖区提供了可行的隐私防护解决方案。

Abstract: The interactive nature of Large Language Models (LLMs), which closely track
user data and context, has prompted users to share personal and private
information in unprecedented ways. Even when users opt out of allowing their
data to be used for training, these privacy settings offer limited protection
when LLM providers operate in jurisdictions with weak privacy laws, invasive
government surveillance, or poor data security practices. In such cases, the
risk of sensitive information, including Personally Identifiable Information
(PII), being mishandled or exposed remains high. To address this, we propose
the concept of an "LLM gatekeeper", a lightweight, locally run model that
filters out sensitive information from user queries before they are sent to the
potentially untrustworthy, though highly capable, cloud-based LLM. Through
experiments with human subjects, we demonstrate that this dual-model approach
introduces minimal overhead while significantly enhancing user privacy, without
compromising the quality of LLM responses.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [128] [Unseen Speaker and Language Adaptation for Lightweight Text-To-Speech with Adapters](https://arxiv.org/abs/2508.18006)
*Alessio Falai,Ziyao Zhang,Akos Gangoly*

Main category: eess.AS

TL;DR: 跨语言TTS系统中使用适配器实现未见说话者和语言的语音合成，验证适配器配置效果并提出口音自然度评估指标。


<details>
  <summary>Details</summary>
Motivation: 解决目标语言中无录音目标语音的合成难题，同时避免模型在适应新任务时的灾难性遗忘问题。

Method: 基于适配器技术对预训练模型进行参数高效调整，系统研究适配器位置/配置参数，并提出基于L2发音错误检测的客观口音评估指标。

Result: 适配器成功实现跨语言/说话者适应，客观指标验证口音自然度，实验显示适配器位置和说话者数量显著影响合成质量。

Conclusion: 验证适配器在轻量级跨语言TTS的有效性，提出的客观评估体系为后续研究提供量化标准，适配器配置策略需针对性优化。

Abstract: In this paper we investigate cross-lingual Text-To-Speech (TTS) synthesis
through the lens of adapters, in the context of lightweight TTS systems. In
particular, we compare the tasks of unseen speaker and language adaptation with
the goal of synthesising a target voice in a target language, in which the
target voice has no recordings therein. Results from objective evaluations
demonstrate the effectiveness of adapters in learning language-specific and
speaker-specific information, allowing pre-trained models to learn unseen
speaker identities or languages, while avoiding catastrophic forgetting of the
original model's speaker or language information. Additionally, to measure how
native the generated voices are in terms of accent, we propose and validate an
objective metric inspired by mispronunciation detection techniques in
second-language (L2) learners. The paper also provides insights into the impact
of adapter placement, configuration and the number of speakers used.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [129] [Named Entity Recognition of Historical Text via Large Language Model](https://arxiv.org/abs/2508.18090)
*Shibingfeng Zhang,Giovanni Colavizza*

Main category: cs.DL

TL;DR: 探索大语言模型在历史文档命名实体识别中的应用，通过零样本/少样本提示策略实现低资源环境下的有效信息提取。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法依赖大量标注数据，而历史文本面临标注稀缺、语言变异和噪声等问题，需探索不依赖标注的替代方案。

Method: 在HIPE-2022数据集上采用零样本和少样本提示策略，评估LLMs在历史NER任务中的表现。

Result: LLMs展现出合理性能，虽不及完全监督模型，但在无标注场景下为历史文本信息提取提供可行方案。

Conclusion: LLMs为低资源历史语料的信息提取提供了高效替代方案，突破传统监督方法对标注数据的依赖瓶颈。

Abstract: Large language models have demonstrated remarkable versatility across a wide
range of natural language processing tasks and domains. One such task is Named
Entity Recognition (NER), which involves identifying and classifying proper
names in text, such as people, organizations, locations, dates, and other
specific entities. NER plays a crucial role in extracting information from
unstructured textual data, enabling downstream applications such as information
retrieval from unstructured text.
  Traditionally, NER is addressed using supervised machine learning approaches,
which require large amounts of annotated training data. However, historical
texts present a unique challenge, as the annotated datasets are often scarce or
nonexistent, due to the high cost and expertise required for manual labeling.
In addition, the variability and noise inherent in historical language, such as
inconsistent spelling and archaic vocabulary, further complicate the
development of reliable NER systems for these sources.
  In this study, we explore the feasibility of applying LLMs to NER in
historical documents using zero-shot and few-shot prompting strategies, which
require little to no task-specific training data. Our experiments, conducted on
the HIPE-2022 (Identifying Historical People, Places and other Entities)
dataset, show that LLMs can achieve reasonably strong performance on NER tasks
in this setting. While their performance falls short of fully supervised models
trained on domain-specific annotations, the results are nevertheless promising.
These findings suggest that LLMs offer a viable and efficient alternative for
information extraction in low-resource or historically significant corpora,
where traditional supervised methods are infeasible.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [130] [MedRepBench: A Comprehensive Benchmark for Medical Report Interpretation](https://arxiv.org/abs/2508.16674)
*Fangxin Shang,Yuan Xia,Dalu Yang,Yahui Wang,Binglin Yang*

Main category: cs.CV

TL;DR: 提出MedRepBench医疗报告理解基准，通过双协议评估框架验证VLM模型性能，发现OCR+LLM存在布局盲区问题


<details>
  <summary>Details</summary>
Motivation: 现有医疗报告理解领域缺乏标准化的结构化评估基准，难以准确衡量VLMs/LLMs在临床场景中的解释质量

Method: 构建包含1,900份真实中文医疗报告的数据集，设计客观指标（字段召回率）和LLM代理主观评分双评估协议，应用GRPO算法优化VLM模型

Result: GRPO优化使召回率提升6%，OCR+LLM组合虽表现优异但存在布局识别缺陷和延迟问题

Conclusion: MedRepBench有效推动医疗报告理解研究，GRPO验证模型优化潜力，OCR+LLM的局限性凸显发展纯视觉方法的必要性

Abstract: Medical report interpretation plays a crucial role in healthcare, enabling
both patient-facing explanations and effective information flow across clinical
systems. While recent vision-language models (VLMs) and large language models
(LLMs) have demonstrated general document understanding capabilities, there
remains a lack of standardized benchmarks to assess structured interpretation
quality in medical reports. We introduce MedRepBench, a comprehensive benchmark
built from 1,900 de-identified real-world Chinese medical reports spanning
diverse departments, patient demographics, and acquisition formats. The
benchmark is designed primarily to evaluate end-to-end VLMs for structured
medical report understanding. To enable controlled comparisons, we also include
a text-only evaluation setting using high-quality OCR outputs combined with
LLMs, allowing us to estimate the upper-bound performance when character
recognition errors are minimized. Our evaluation framework supports two
complementary protocols: (1) an objective evaluation measuring field-level
recall of structured clinical items, and (2) an automated subjective evaluation
using a powerful LLM as a scoring agent to assess factuality, interpretability,
and reasoning quality. Based on the objective metric, we further design a
reward function and apply Group Relative Policy Optimization (GRPO) to improve
a mid-scale VLM, achieving up to 6% recall gain. We also observe that the
OCR+LLM pipeline, despite strong performance, suffers from layout-blindness and
latency issues, motivating further progress toward robust, fully vision-based
report understanding.

</details>


### [131] [Multi-Agent Visual-Language Reasoning for Comprehensive Highway Scene Understanding](https://arxiv.org/abs/2508.17205)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 提出基于混合专家策略的多智能体框架，通过大模型生成CoT提示指导小模型进行多模态推理，在天气分类、路面湿度评估和交通拥堵检测任务中实现高效多任务处理。


<details>
  <summary>Details</summary>
Motivation: 解决高速公路场景中多任务感知的挑战，平衡准确性与计算效率，整合视频流与传感器等多模态数据提升推理能力。

Method: 大型VLM生成任务特定CoT提示→小型高效VLM执行多模态推理，构建含多模态路面湿度数据集的三类验证数据集。

Result: 实验显示框架在多样化环境下性能稳定，多模态数据提升准确率，可无缝集成现有交通摄像头系统。

Conclusion: 该框架显著增强高风险路段的持续监控能力，为资源受限环境提供可部署的实时预警解决方案。

Abstract: This paper introduces a multi-agent framework for comprehensive highway scene
understanding, designed around a mixture-of-experts strategy. In this
framework, a large generic vision-language model (VLM), such as GPT-4o, is
contextualized with domain knowledge to generates task-specific
chain-of-thought (CoT) prompts. These fine-grained prompts are then used to
guide a smaller, efficient VLM (e.g., Qwen2.5-VL-7B) in reasoning over short
videos, along with complementary modalities as applicable. The framework
simultaneously addresses multiple critical perception tasks, including weather
classification, pavement wetness assessment, and traffic congestion detection,
achieving robust multi-task reasoning while balancing accuracy and
computational efficiency. To support empirical validation, we curated three
specialized datasets aligned with these tasks. Notably, the pavement wetness
dataset is multimodal, combining video streams with road weather sensor data,
highlighting the benefits of multimodal reasoning. Experimental results
demonstrate consistently strong performance across diverse traffic and
environmental conditions. From a deployment perspective, the framework can be
readily integrated with existing traffic camera systems and strategically
applied to high-risk rural locations, such as sharp curves, flood-prone
lowlands, or icy bridges. By continuously monitoring the targeted sites, the
system enhances situational awareness and delivers timely alerts, even in
resource-constrained environments.

</details>


### [132] [CoViPAL: Layer-wise Contextualized Visual Token Pruning for Large Vision-Language Models](https://arxiv.org/abs/2508.17243)
*Zicong Tang,Ziyang Ma,Suqing Wang,Zuchao Li,Lefei Zhang,Hai Zhao,Yun Li,Qianren Wang*

Main category: cs.CV

TL;DR: CoViPAL提出通过层间上下文视觉令牌剪枝方法，在LVLMs中实现高效推理且不损失精度


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌剪枝方法在浅层因缺乏上下文信息难以有效去冗余，而许多视觉令牌在浅层即具备固有冗余性

Method: 采用插件式剪枝模块(PPM)进行层间上下文预测，在LVLM处理前动态移除冗余视觉令牌

Result: 在相同令牌预算下超越无训练剪枝方法，监督量相当时优于需训练方法，最高减少81%视觉令牌

Conclusion: CoViPAL为LVLMs提供了可扩展的高效推理方案，模型无关特性使其具备广泛适用性

Abstract: Large Vision-Language Models (LVLMs) process multimodal inputs consisting of
text tokens and vision tokens extracted from images or videos. Due to the rich
visual information, a single image can generate thousands of vision tokens,
leading to high computational costs during the prefilling stage and significant
memory overhead during decoding. Existing methods attempt to prune redundant
vision tokens, revealing substantial redundancy in visual representations.
However, these methods often struggle in shallow layers due to the lack of
sufficient contextual information. We argue that many visual tokens are
inherently redundant even in shallow layers and can be safely and effectively
pruned with appropriate contextual signals. In this work, we propose CoViPAL, a
layer-wise contextualized visual token pruning method that employs a
Plug-and-Play Pruning Module (PPM) to predict and remove redundant vision
tokens before they are processed by the LVLM. The PPM is lightweight,
model-agnostic, and operates independently of the LVLM architecture, ensuring
seamless integration with various models. Extensive experiments on multiple
benchmarks demonstrate that CoViPAL outperforms training-free pruning methods
under equal token budgets and surpasses training-based methods with comparable
supervision. CoViPAL offers a scalable and efficient solution to improve
inference efficiency in LVLMs without compromising accuracy.

</details>


### [133] [Mind the (Language) Gap: Towards Probing Numerical and Cross-Lingual Limits of LVLMs](https://arxiv.org/abs/2508.17334)
*Somraj Gautam,Abhirama Subramanyam Penamakuri,Abhishek Bhandari,Gaurav Harit*

Main category: cs.CV

TL;DR: 推出MMCRICBENCH-3K基准测试，用于评估视觉语言模型在板球记分卡图像上的数值推理和跨语言能力


<details>
  <summary>Details</summary>
Motivation: 现有LVLM模型在结构化数据理解、数值推理和跨语言泛化方面存在明显缺陷，需针对性测试框架

Method: 构建含1,463张多格式合成记分卡图像和1,500英文QA的数据集，分英语/印地语子集进行跨文字评估

Result: GPT-4o等顶尖模型在英文集表现欠佳，印地语集性能进一步下降（准确率下降12-18个百分点）

Conclusion: 揭示了LVLM在结构化视觉文本理解、数值推理和跨语言泛化的关键瓶颈，推动该方向研究

Abstract: We introduce MMCRICBENCH-3K, a benchmark for Visual Question Answering (VQA)
on cricket scorecards, designed to evaluate large vision-language models
(LVLMs) on complex numerical and cross-lingual reasoning over semi-structured
tabular images. MMCRICBENCH-3K comprises 1,463 synthetically generated
scorecard images from ODI, T20, and Test formats, accompanied by 1,500 English
QA pairs. It includes two subsets: MMCRICBENCH-E-1.5K, featuring English
scorecards, and MMCRICBENCH-H-1.5K, containing visually similar Hindi
scorecards, with all questions and answers kept in English to enable controlled
cross-script evaluation. The task demands reasoning over structured numerical
data, multi-image context, and implicit domain knowledge. Empirical results
show that even state-of-the-art LVLMs, such as GPT-4o and Qwen2.5VL, struggle
on the English subset despite it being their primary training language and
exhibit a further drop in performance on the Hindi subset. This reveals key
limitations in structure-aware visual text understanding, numerical reasoning,
and cross-lingual generalization. The dataset is publicly available via Hugging
Face at https://huggingface.co/datasets/DIALab/MMCricBench, to promote LVLM
research in this direction.

</details>


### [134] [Dynamic Embedding of Hierarchical Visual Features for Efficient Vision-Language Fine-Tuning](https://arxiv.org/abs/2508.17638)
*Xinyu Wei,Guoli Yang,Jialu Zhou,Mingyue Yang,Leqian Li,Kedi Zhang,Chunping Qiu*

Main category: cs.CV

TL;DR: 提出DEHVF方法，通过动态嵌入和分层视觉特征融合解决LVLMs输入序列过长问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型输入序列范式导致计算开销过大，且忽略视觉编码器浅层的细粒度信息和层次化语义特征

Method: 利用视觉编码器层次特征，通过轻量级融合器动态选择对应层特征，将其对齐后嵌入LLM各层的FFN模块

Result: 在ScienceQA视觉问答和COCO图像描述任务中，准确率超过现有高效微调基线，同时保持训练/推理效率

Conclusion: DEHVF实现了跨模态信息的细粒度对齐，通过少量参数微调即可达到高效精准的多模态融合

Abstract: Large Vision-Language Models (LVLMs) commonly follow a paradigm that projects
visual features and then concatenates them with text tokens to form a unified
sequence input for Large Language Models (LLMs). However, this paradigm leads
to a significant increase in the length of the input sequence, resulting in
substantial computational overhead. Existing methods attempt to fuse visual
information into the intermediate layers of LLMs, which alleviate the sequence
length issue but often neglect the hierarchical semantic representations within
the model and the fine-grained visual information available in the shallower
visual encoding layers. To address this limitation, we propose DEHVF, an
efficient vision-language fine-tuning method based on dynamic embedding and
fusion of hierarchical visual features. Its core lies in leveraging the
inherent hierarchical representation characteristics of visual encoders and
language models. Through a lightweight hierarchical visual fuser, it
dynamically selects and fuses hierarchical features corresponding to semantic
granularity based on the internal representations of each layer in LLMs. The
fused layer-related visual features are then projected and aligned before being
directly embedded into the Feed-Forward Network (FFN) of the corresponding
layer in LLMs. This approach not only avoids sequence expansion but also
dynamically fuses multi-layer visual information. By fine-tuning only a small
number of parameters, DEHVF achieves precise alignment and complementarity of
cross-modal information at the same semantic granularity. We conducted
experiments across various VL benchmarks, including visual question answering
on ScienceQA and image captioning on COCO Captions. The results demonstrate
that DEHVF achieves higher accuracy than existing parameter-efficient
fine-tuning (PEFT) baselines while maintaining efficient training and
inference.

</details>


### [135] [CEIDM: A Controlled Entity and Interaction Diffusion Model for Enhanced Text-to-Image Generation](https://arxiv.org/abs/2508.17760)
*Mingyue Yang,Dianxi Shi,Jialu Zhou,Xinyu Wei,Leqian Li,Shaowu Yang,Chunping Qiu*

Main category: cs.CV

TL;DR: 提出CEIDM方法，通过大语言模型挖掘实体交互关系、交互动作聚类偏移技术和实体控制网络，提升扩散模型在文本生成图像中对实体及交互关系的控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的T2I方法在复杂实体及其交互控制上存在不足，难以生成符合现实逻辑且交互关系合理的高质量图像。

Method: 1. 基于LLM的实体交互关系挖掘
2. 交互动作聚类与双向偏移技术
3. 多尺度动态实体控制网络（含语义引导掩码生成、特征增强与融合模块）

Result: 实验证明CEIDM在实体控制和交互关系控制上优于现有主流方法，生成图像更符合现实逻辑。

Conclusion: 该方法通过三重控制机制显著提升图像质量，为复杂场景的文本到图像生成提供了新的技术路径。

Abstract: In Text-to-Image (T2I) generation, the complexity of entities and their
intricate interactions pose a significant challenge for T2I method based on
diffusion model: how to effectively control entity and their interactions to
produce high-quality images. To address this, we propose CEIDM, a image
generation method based on diffusion model with dual controls for entity and
interaction. First, we propose an entity interactive relationships mining
approach based on Large Language Models (LLMs), extracting reasonable and rich
implicit interactive relationships through chain of thought to guide diffusion
models to generate high-quality images that are closer to realistic logic and
have more reasonable interactive relationships. Furthermore, We propose an
interactive action clustering and offset method to cluster and offset the
interactive action features contained in each text prompts. By constructing
global and local bidirectional offsets, we enhance semantic understanding and
detail supplementation of original actions, making the model's understanding of
the concept of interactive "actions" more accurate and generating images with
more accurate interactive actions. Finally, we design an entity control network
which generates masks with entity semantic guidance, then leveraging
multi-scale convolutional network to enhance entity feature and dynamic network
to fuse feature. It effectively controls entities and significantly improves
image quality. Experiments show that the proposed CEIDM method is better than
the most representative existing methods in both entity control and their
interaction control.

</details>


### [136] [Designing Practical Models for Isolated Word Visual Speech Recognition](https://arxiv.org/abs/2508.17894)
*Iason Ioannis Panagos,Giorgos Sfikas,Christophoros Nikou*

Main category: cs.CV

TL;DR: 本文开发了轻量级视觉语音识别模型，通过优化双网络架构降低硬件需求同时保持识别性能


<details>
  <summary>Details</summary>
Motivation: 现有VSR系统依赖深度神经网络导致计算成本高昂，限制了在资源受限场景的实际应用

Method: 采用标准双网络架构（视觉特征提取+序列分类），结合图像分类领域的高效模型，设计轻量级时间卷积网络模块

Result: 在最大英语单词数据库上的实验验证了模型的有效性（代码和模型将开源）

Conclusion: 提出的低资源需求架构为医疗辅助等实际应用场景提供了可行的解决方案

Abstract: Visual speech recognition (VSR) systems decode spoken words from an input
sequence using only the video data. Practical applications of such systems
include medical assistance as well as human-machine interactions. A VSR system
is typically employed in a complementary role in cases where the audio is
corrupt or not available. In order to accurately predict the spoken words,
these architectures often rely on deep neural networks in order to extract
meaningful representations from the input sequence. While deep architectures
achieve impressive recognition performance, relying on such models incurs
significant computation costs which translates into increased resource demands
in terms of hardware requirements and results in limited applicability in
real-world scenarios where resources might be constrained. This factor prevents
wider adoption and deployment of speech recognition systems in more practical
applications. In this work, we aim to alleviate this issue by developing
architectures for VSR that have low hardware costs. Following the standard
two-network design paradigm, where one network handles visual feature
extraction and another one utilizes the extracted features to classify the
entire sequence, we develop lightweight end-to-end architectures by first
benchmarking efficient models from the image classification literature, and
then adopting lightweight block designs in a temporal convolution network
backbone. We create several unified models with low resource requirements but
strong recognition performance. Experiments on the largest public database for
English words demonstrate the effectiveness and practicality of our developed
models. Code and trained models will be made publicly available.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [137] [RephraseTTS: Dynamic Length Text based Speech Insertion with Speaker Style Transfer](https://arxiv.org/abs/2508.17031)
*Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.SD

TL;DR: 提出基于Transformer的非自回归语音插入方法，可根据文本转录动态调整语音插入长度，保持说话人特征并优于现有基线


<details>
  <summary>Details</summary>
Motivation: 解决文本转录修正后对应语音音频更新的需求，避免重新录制整段语音

Method: 使用非自回归Transformer架构，根据文本内容和输入节奏动态决定插入长度，保持音色、韵律和频谱特征

Result: 在LibriTTS数据集上的实验显示性能超越自适应TTS基线，用户研究和定性结果验证有效性

Conclusion: 该方法为语音编辑提供了高效解决方案，在保持语音自然度的同时实现文本驱动的精准音频修改

Abstract: We propose a method for the task of text-conditioned speech insertion, i.e.
inserting a speech sample in an input speech sample, conditioned on the
corresponding complete text transcript. An example use case of the task would
be to update the speech audio when corrections are done on the corresponding
text transcript. The proposed method follows a transformer-based
non-autoregressive approach that allows speech insertions of variable lengths,
which are dynamically determined during inference, based on the text transcript
and tempo of the available partial input. It is capable of maintaining the
speaker's voice characteristics, prosody and other spectral properties of the
available speech input. Results from our experiments and user study on LibriTTS
show that our method outperforms baselines based on an existing adaptive text
to speech method. We also provide numerous qualitative results to appreciate
the quality of the output from the proposed method.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [138] [RubikSQL: Lifelong Learning Agentic Knowledge Base as an Industrial NL2SQL System](https://arxiv.org/abs/2508.17590)
*Zui Chen,Han Li,Xinhao Zhang,Xiaoyu Chen,Chunyin Dong,Yifeng Wang,Xin Cai,Su Zhang,Ziqi Li,Chi Ding,Jinxu Li,Shuai Wang,Dousheng Zhao,Sanhai Gao,Guangyi Liu*

Main category: cs.DB

TL;DR: 提出RubikSQL系统，通过终身学习框架与多智能体工作流解决企业级NL2SQL的隐式意图和领域术语挑战，在KaggleDBQA和BIRD测试集达到SOTA性能，并发布工业级基准RubikBench。


<details>
  <summary>Details</summary>
Motivation: 企业级NL2SQL面临隐式意图理解（如时间范围、排序等未明确表述的约束）和领域特定术语的挑战，传统端到端模型难以系统化解决这些问题。

Method: 1) 知识库构建：通过数据库画像/结构化信息抽取获取显性知识，利用智能体挖掘隐式规则，结合CoT增强的SQL画像
2) SQL生成：基于知识库的多智能体协作框架，实现意图解析和SQL生成解耦

Result: KaggleDBQA（83.2%执行准确率）和BIRD Mini-Dev（60.1%验证集准确率）上的SOTA性能，同步发布包含1,753个真实工业场景样本的RubikBench基准

Conclusion: RubikSQL首次将终身学习范式系统化应用于NL2SQL，其知识库驱动架构显著提升复杂场景适应能力，RubikBench填补工业级评测空白

Abstract: We present RubikSQL, a novel NL2SQL system designed to address key challenges
in real-world enterprise-level NL2SQL, such as implicit intents and
domain-specific terminology. RubikSQL frames NL2SQL as a lifelong learning
task, demanding both Knowledge Base (KB) maintenance and SQL generation.
RubikSQL systematically builds and refines its KB through techniques including
database profiling, structured information extraction, agentic rule mining, and
Chain-of-Thought (CoT)-enhanced SQL profiling. RubikSQL then employs a
multi-agent workflow to leverage this curated KB, generating accurate SQLs.
RubikSQL achieves SOTA performance on both the KaggleDBQA and BIRD Mini-Dev
datasets. Finally, we release the RubikBench benchmark, a new benchmark
specifically designed to capture vital traits of industrial NL2SQL scenarios,
providing a valuable resource for future research.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [139] [How Do LLM-Generated Texts Impact Term-Based Retrieval Models?](https://arxiv.org/abs/2508.17715)
*Wei Huang,Keping Bi,Yinqiong Cai,Wei Chen,Jiafeng Guo,Xueqi Cheng*

Main category: cs.IR

TL;DR: LLM生成文本因高频词平滑分布、高术语特异性等语言特性，使基于术语的检索模型优先匹配其与查询的术语分布，但不存在固有来源偏见。


<details>
  <summary>Details</summary>
Motivation: 探究LLM生成内容对经典术语检索模型的影响，解释神经检索模型与术语模型对混合内容的不同偏向机制。

Method: 通过Zipf斜率、术语特异性等语言特征分析LLM文本特性，并验证术语模型是否因特征差异产生来源偏见。

Result: 术语检索模型无来源偏见，其偏向源于文档与查询的术语分布匹配度，而非内容生成源属性。

Conclusion: 揭示术语模型工作机制，为管理混合内容检索中的潜在偏见提供理论基础，强调术语分布匹配的核心作用。

Abstract: As more content generated by large language models (LLMs) floods into the
Internet, information retrieval (IR) systems now face the challenge of
distinguishing and handling a blend of human-authored and machine-generated
texts. Recent studies suggest that neural retrievers may exhibit a preferential
inclination toward LLM-generated content, while classic term-based retrievers
like BM25 tend to favor human-written documents. This paper investigates the
influence of LLM-generated content on term-based retrieval models, which are
valued for their efficiency and robust generalization across domains. Our
linguistic analysis reveals that LLM-generated texts exhibit smoother
high-frequency and steeper low-frequency Zipf slopes, higher term specificity,
and greater document-level diversity. These traits are aligned with LLMs being
trained to optimize reader experience through diverse and precise expressions.
Our study further explores whether term-based retrieval models demonstrate
source bias, concluding that these models prioritize documents whose term
distributions closely correspond to those of the queries, rather than
displaying an inherent source bias. This work provides a foundation for
understanding and addressing potential biases in term-based IR systems managing
mixed-source content.

</details>


### [140] [HLLM-Creator: Hierarchical LLM-based Personalized Creative Generation](https://arxiv.org/abs/2508.18118)
*Junyi Chen,Lu Chi,Siliang Xu,Shiwei Ran,Bingyue Peng,Zehuan Yuan*

Main category: cs.IR

TL;DR: 提出分层LLM框架HLLM-Creator，通过用户聚类匹配策略和思维链数据构建，解决个性化内容生成的效率与数据稀缺问题，实现广告场景0.476%的效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有AIGC系统缺乏真正的用户个性化能力，尤其在广告场景中不同用户关注点差异显著，需兼顾事实约束与海量用户的高效生成。

Method: 采用用户聚类与广告匹配预测剪枝策略提升计算效率，设计基于思维链推理的数据构建流程解决个性化数据稀缺和事实一致性问题。

Result: 抖音搜索广告场景在线A/B测试显示Adss指标提升0.476%，框架计算开销显著降低，支持工业级大规模部署。

Conclusion: HLLM-Creator通过分层架构与高效策略，为工业场景个性化内容生成提供了兼顾效果与效率的解决方案，开源代码促进学术应用。

Abstract: AI-generated content technologies are widely used in content creation.
However, current AIGC systems rely heavily on creators' inspiration, rarely
generating truly user-personalized content. In real-world applications such as
online advertising, a single product may have multiple selling points, with
different users focusing on different features. This underscores the
significant value of personalized, user-centric creative generation. Effective
personalized content generation faces two main challenges: (1) accurately
modeling user interests and integrating them into the content generation
process while adhering to factual constraints, and (2) ensuring high efficiency
and scalability to handle the massive user base in industrial scenarios.
Additionally, the scarcity of personalized creative data in practice
complicates model training, making data construction another key hurdle. We
propose HLLM-Creator, a hierarchical LLM framework for efficient user interest
modeling and personalized content generation. During inference, a combination
of user clustering and a user-ad-matching-prediction based pruning strategy is
employed to significantly enhance generation efficiency and reduce
computational overhead, making the approach suitable for large-scale
deployment. Moreover, we design a data construction pipeline based on
chain-of-thought reasoning, which generates high-quality, user-specific
creative titles and ensures factual consistency despite limited personalized
data. This pipeline serves as a critical foundation for the effectiveness of
our model. Extensive experiments on personalized title generation for Douyin
Search Ads show the effectiveness of HLLM-Creator. Online A/B test shows a
0.476% increase on Adss, paving the way for more effective and efficient
personalized generation in industrial scenarios. Codes for academic dataset are
available at https://github.com/bytedance/HLLM.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [141] [A Workflow for Map Creation in Autonomous Vehicle Simulations](https://arxiv.org/abs/2508.16856)
*Zubair Islam,Ahmaad Ansari,George Daoud,Mohamed El-Darieby*

Main category: cs.RO

TL;DR: 提出定制化工作流程简化自动驾驶汽车开发中的3D地图创建，并以安大略理工大学停车场为例验证效果


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶仿真地图创建流程存在计算资源消耗大、模拟器兼容性差、开发灵活性受限等问题

Method: 设计基于CARLA模拟器的定制化地图生成流程，通过实际案例（大学停车场）验证工作流程可行性

Result: 成功生成三维停车场地图，并发现未来需改进坐标处理方式和兼容性优化

Conclusion: 该工作流程为自动驾驶开发提供更高效的地图生成方案，未来通过整合SLAM技术可提升多模拟器兼容性

Abstract: The fast development of technology and artificial intelligence has
significantly advanced Autonomous Vehicle (AV) research, emphasizing the need
for extensive simulation testing. Accurate and adaptable maps are critical in
AV development, serving as the foundation for localization, path planning, and
scenario testing. However, creating simulation-ready maps is often difficult
and resource-intensive, especially with simulators like CARLA (CAR Learning to
Act). Many existing workflows require significant computational resources or
rely on specific simulators, limiting flexibility for developers. This paper
presents a custom workflow to streamline map creation for AV development,
demonstrated through the generation of a 3D map of a parking lot at Ontario
Tech University. Future work will focus on incorporating SLAM technologies,
optimizing the workflow for broader simulator compatibility, and exploring more
flexible handling of latitude and longitude values to enhance map generation
accuracy.

</details>


### [142] [Talking to Robots: A Practical Examination of Speech Foundation Models for HRI Applications](https://arxiv.org/abs/2508.17753)
*Theresa Pekarek Rosin,Julia Gachot,Henri-Leon Kordt,Matthias Kerzel,Stefan Wermter*

Main category: cs.RO

TL;DR: 评估现实场景下ASR系统在人机交互中的性能差异及潜在影响


<details>
  <summary>Details</summary>
Motivation: 现实场景中ASR系统需处理硬件限制和环境噪声，同时服务多样化用户群体，而人机交互环境将这些挑战推向极致

Method: 使用8个公开数据集（涵盖领域特定、口音、噪声等6个维度）测试4个先进ASR系统

Result: 系统在性能、幻觉倾向和内在偏见方面存在显著差异，尽管标准基准得分相近

Conclusion: 识别错误会严重影响人机交互中的任务执行、用户信任和安全性，暴露当前ASR系统的实际应用局限

Abstract: Automatic Speech Recognition (ASR) systems in real-world settings need to
handle imperfect audio, often degraded by hardware limitations or environmental
noise, while accommodating diverse user groups. In human-robot interaction
(HRI), these challenges intersect to create a uniquely challenging recognition
environment. We evaluate four state-of-the-art ASR systems on eight publicly
available datasets that capture six dimensions of difficulty: domain-specific,
accented, noisy, age-variant, impaired, and spontaneous speech. Our analysis
demonstrates significant variations in performance, hallucination tendencies,
and inherent biases, despite similar scores on standard benchmarks. These
limitations have serious implications for HRI, where recognition errors can
interfere with task performance, user trust, and safety.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [143] [Humans Perceive Wrong Narratives from AI Reasoning Texts](https://arxiv.org/abs/2508.16599)
*Mosh Levy,Zohar Elyoseph,Yoav Goldberg*

Main category: cs.HC

TL;DR: 研究发现人类对AI模型生成的推理文本存在理解偏差，其因果判断准确率仅29.3%，揭示模型语言使用方式与人类理解的本质差异


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的推理文本被过度依赖为透明化工具，但缺乏对其与模型真实计算过程对应性的验证

Method: 通过反事实测量设计问题，评估人类识别推理步骤因果影响的能力

Result: 参与者准确率仅29.3%（接近25%随机水平），高共识问题的多数投票准确率也仅42%

Conclusion: 应将推理文本视为需深度研究的非透明性素材，探索模型语言使用的非人类机制是核心方向

Abstract: A new generation of AI models generates step-by-step reasoning text before
producing an answer. This text appears to offer a human-readable window into
their computation process, and is increasingly relied upon for transparency and
interpretability. However, it is unclear whether human understanding of this
text matches the model's actual computational process. In this paper, we
investigate a necessary condition for correspondence: the ability of humans to
identify which steps in a reasoning text causally influence later steps. We
evaluated humans on this ability by composing questions based on counterfactual
measurements and found a significant discrepancy: participant accuracy was only
29.3%, barely above chance (25%), and remained low (42%) even when evaluating
the majority vote on questions with high agreement. Our results reveal a
fundamental gap between how humans interpret reasoning texts and how models use
it, challenging its utility as a simple interpretability tool. We argue that
reasoning texts should be treated as an artifact to be investigated, not taken
at face value, and that understanding the non-human ways these models use
language is a critical research direction.

</details>


### [144] [Can AI Have a Personality? Prompt Engineering for AI Personality Simulation: A Chatbot Case Study in Gender-Affirming Voice Therapy Training](https://arxiv.org/abs/2508.18234)
*Tailon D. Jackson,Byunggu Yu*

Main category: cs.HC

TL;DR: 通过提示工程可让大语言模型模拟稳定人格特征，应用于语言病理学培训聊天机器人


<details>
  <summary>Details</summary>
Motivation: 探索LLMs通过提示工程模拟一致性人格的可能性，特别是在性别肯定语音治疗的学生培训场景中

Method: 创建名为Monae Jackson的32岁跨性别女性聊天机器人，通过设计对话模板进行客户端-治疗师交互模拟

Result: 聊天机器人保持可识别的人格一致性，基于大五人格测试显示独特个性特征

Conclusion: 提示工程能有效模拟AI聊天机器人的稳定人格特性，支持其在专业培训中的应用

Abstract: This thesis investigates whether large language models (LLMs) can be guided
to simulate a consistent personality through prompt engineering. The study
explores this concept within the context of a chatbot designed for
Speech-Language Pathology (SLP) student training, specifically focused on
gender-affirming voice therapy. The chatbot, named Monae Jackson, was created
to represent a 32-year-old transgender woman and engage in conversations
simulating client-therapist interactions. Findings suggest that with prompt
engineering, the chatbot maintained a recognizable and consistent persona and
had a distinct personality based on the Big Five Personality test. These
results support the idea that prompt engineering can be used to simulate stable
personality characteristics in AI chatbots.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [145] [Anemoi: A Semi-Centralized Multi-agent Systems Based on Agent-to-Agent Communication MCP server from Coral Protocol](https://arxiv.org/abs/2508.17068)
*Xinxing Ren,Caelum Forder,Qianbo Zang,Ahsen Tahir,Roman J. Georgio,Suman Deb,Peter Carroll,Önder Gürcan,Zekun Guo*

Main category: cs.MA

TL;DR: 提出Anemoi半集中式多智能体系统，通过A2A通信机制减少对中央规划器的依赖，在GAIA基准测试中准确率52.73%超越基线9%


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统存在两大缺陷：1) 过度依赖中央规划器模型能力，小规模LLM性能骤降；2) 代理间通信机制低效导致冗余和上下文丢失

Method: 基于Coral协议的A2A通信MCP服务器，建立结构化实时协作框架，支持跨代理进度监控/结果评估/瓶颈识别/方案优化，实现动态计划更新

Result: 使用GPT-4.1-mini作为规划器时，在GAIA基准达到52.73%准确率，较开源基线OWL(43.63%)提升9.09%，验证小模型场景有效性

Conclusion: Anemoi通过去中心化通信架构显著提升多智能体协作效率，降低计算冗余和API调用成本，为资源受限环境提供新范式

Abstract: Recent advances in generalist multi-agent systems (MAS) have largely followed
a context-engineering plus centralized paradigm, where a planner agent
coordinates multiple worker agents through unidirectional prompt passing. While
effective under strong planner models, this design suffers from two critical
limitations: (1) strong dependency on the planner's capability, which leads to
degraded performance when a smaller LLM powers the planner; and (2) limited
inter-agent communication, where collaboration relies on costly prompt
concatenation and context injection, introducing redundancy and information
loss. To address these challenges, we propose Anemoi, a semi-centralized MAS
built on the Agent-to-Agent (A2A) communication MCP server from Coral Protocol.
Unlike traditional designs, Anemoi enables structured and direct inter-agent
collaboration, allowing all agents to monitor progress, assess results,
identify bottlenecks, and propose refinements in real time. This paradigm
reduces reliance on a single planner, supports adaptive plan updates, and
minimizes redundant context passing, resulting in more scalable and
cost-efficient execution. Evaluated on the GAIA benchmark, Anemoi achieved
52.73\% accuracy with a small LLM (GPT-4.1-mini) as the planner, surpassing the
strongest open-source baseline OWL (43.63\%) by +9.09\% under identical LLM
settings. Our implementation is publicly available at
https://github.com/Coral-Protocol/Anemoi.

</details>


<div id='q-fin.PM'></div>

# q-fin.PM [[Back]](#toc)

### [146] [THEME : Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics](https://arxiv.org/abs/2508.16936)
*Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee*

Main category: q-fin.PM

TL;DR: 提出TRS主题数据集和THEME分层对比学习框架，通过文本嵌入对齐与收益时序优化提升主题投资中的股票检索与组合构建效果。


<details>
  <summary>Details</summary>
Motivation: 传统主题投资选股受限于行业边界重叠和市场动态变化，需结合文本信息与市场数据构建更有效的主题资产表征。

Method: 1.构建TRS数据集整合ETF/行业/新闻多维信息 2.THEME框架分语义对齐（层次化对比学习）与时序优化（融入股票收益）两阶段生成表征

Result: THEME在多个检索指标上超越基线，投资组合夏普比率提升21.8%，证明文本与市场动态联合建模的有效性。

Conclusion: 通过同时建模文本主题关系与市场收益动态，THEME为复杂投资主题提供了可扩展的适应性解决方案。

Abstract: Thematic investing aims to construct portfolios aligned with structural
trends, yet selecting relevant stocks remains challenging due to overlapping
sector boundaries and evolving market dynamics. To address this challenge, we
construct the Thematic Representation Set (TRS), an extended dataset that
begins with real-world thematic ETFs and expands upon them by incorporating
industry classifications and financial news to overcome their coverage
limitations. The final dataset contains both the explicit mapping of themes to
their constituent stocks and the rich textual profiles for each. Building on
this dataset, we introduce \textsc{THEME}, a hierarchical contrastive learning
framework. By representing the textual profiles of themes and stocks as
embeddings, \textsc{THEME} first leverages their hierarchical relationship to
achieve semantic alignment. Subsequently, it refines these semantic embeddings
through a temporal refinement stage that incorporates individual stock returns.
The final stock representations are designed for effective retrieval of
thematically aligned assets with strong return potential. Empirical results
show that \textsc{THEME} outperforms strong baselines across multiple retrieval
metrics and significantly improves performance in portfolio construction. By
jointly modeling thematic relationships from text and market dynamics from
returns, \textsc{THEME} provides a scalable and adaptive solution for
navigating complex investment themes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [147] [Topology Aware Neural Interpolation of Scalar Fields](https://arxiv.org/abs/2508.17995)
*Mohamed Kissi,Keanu Sisouk,Joshua A. Levine,Julien Tierny*

Main category: cs.LG

TL;DR: 提出结合神经网络与拓扑损失的时变标量场插值方法，在数据拟合和拓扑保真度上优于传统方案


<details>
  <summary>Details</summary>
Motivation: 现有插值方法在非关键帧数据估计中难以保持拓扑准确性，需通过神经网络结合拓扑约束提升重建效果

Method: 构建神经网络架构学习时间-标量场映射关系，引入持久图拓扑损失优化几何/拓扑重建

Result: 在2D/3D数据集上实现更优的插值精度和拓扑匹配，推理速度达到实时要求

Conclusion: 该方法显著提升了时变数据插值的拓扑保真度与准确性，且具备单次网络传播的实时处理优势

Abstract: This paper presents a neural scheme for the topology-aware interpolation of
time-varying scalar fields. Given a time-varying sequence of persistence
diagrams, along with a sparse temporal sampling of the corresponding scalar
fields, denoted as keyframes, our interpolation approach aims at "inverting"
the non-keyframe diagrams to produce plausible estimations of the
corresponding, missing data. For this, we rely on a neural architecture which
learns the relation from a time value to the corresponding scalar field, based
on the keyframe examples, and reliably extends this relation to the
non-keyframe time steps. We show how augmenting this architecture with specific
topological losses exploiting the input diagrams both improves the geometrical
and topological reconstruction of the non-keyframe time steps. At query time,
given an input time value for which an interpolation is desired, our approach
instantaneously produces an output, via a single propagation of the time input
through the network. Experiments interpolating 2D and 3D time-varying datasets
show our approach superiority, both in terms of data and topological fitting,
with regard to reference interpolation schemes.

</details>


### [148] [Learn to Memorize: Optimizing LLM-based Agents with Adaptive Memory Framework](https://arxiv.org/abs/2508.16629)
*Zeyu Zhang,Quanyu Dai,Rui Li,Xiaohe Bo,Xu Chen,Zhenhua Dong*

Main category: cs.LG

TL;DR: 提出基于记忆周期建模的自适应记忆框架，通过MoE门函数、可学习聚合和任务反思机制优化LLM智能体的记忆能力，并实现开源


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体的记忆机制依赖人工预定义，存在高成本、次优性能问题，且忽视交互场景中的记忆周期效应对智能体优化的重要性

Method: 1. 设计MoE门函数优化记忆检索
2. 提出可学习聚合过程提升记忆利用效率
3. 开发任务特定反思机制自适应调整记忆存储
4. 结合离线和在线策略优化

Result: 在多维度实验中验证有效性，并开源项目https://github.com/nuster1128/learn_to_memorize

Conclusion: 该框架使LLM智能体能自主学习特定环境下的记忆策略，通过端到端优化显著提升记忆效率，实验证明其优越性

Abstract: LLM-based agents have been extensively applied across various domains, where
memory stands out as one of their most essential capabilities. Previous memory
mechanisms of LLM-based agents are manually predefined by human experts,
leading to higher labor costs and suboptimal performance. In addition, these
methods overlook the memory cycle effect in interactive scenarios, which is
critical to optimizing LLM-based agents for specific environments. To address
these challenges, in this paper, we propose to optimize LLM-based agents with
an adaptive and data-driven memory framework by modeling memory cycles.
Specifically, we design an MoE gate function to facilitate memory retrieval,
propose a learnable aggregation process to improve memory utilization, and
develop task-specific reflection to adapt memory storage. Our memory framework
empowers LLM-based agents to learn how to memorize information effectively in
specific environments, with both off-policy and on-policy optimization. In
order to evaluate the effectiveness of our proposed methods, we conduct
comprehensive experiments across multiple aspects. To benefit the research
community in this area, we release our project at
https://github.com/nuster1128/learn_to_memorize.

</details>


### [149] [WISCA: A Lightweight Model Transition Method to Improve LLM Training via Weight Scaling](https://arxiv.org/abs/2508.16676)
*Jiacheng Li,Jianchao Tan,Zhidong Yang,Pingwei Sun,Feiye Huo,Jiayu Qin,Yerui Sun,Yuchen Xie,Xunliang Cai,Xiangyu Zhang,Maoxin He,Guangming Tan,Weile Jia,Tong Zhao*

Main category: cs.LG

TL;DR: 提出WISCA权重缩放方法，通过优化神经网络权重模式提升Transformer大模型训练效率和质量


<details>
  <summary>Details</summary>
Motivation: 现有Transformer大模型优化方案集中于架构修改或优化器调整，缺乏对训练过程中权重模式的系统性优化

Method: 在保持模型输出的前提下对权重进行重缩放，间接优化训练轨迹，不改变网络结构

Result: 实验显示WISCA在GQA架构和LoRA微调任务中提升5.6%零样本验证性能，训练困惑度平均降低2.12%

Conclusion: 权重模式优化是提升LLM训练效率的重要方向，WISCA为此提供了有效解决方案

Abstract: Transformer architecture gradually dominates the LLM field. Recent advances
in training optimization for Transformer-based large language models (LLMs)
primarily focus on architectural modifications or optimizer adjustments.
However, these approaches lack systematic optimization of weight patterns
during training. Weight pattern refers to the distribution and relative
magnitudes of weight parameters in a neural network. To address this issue, we
propose a Weight Scaling method called WISCA to enhance training efficiency and
model quality by strategically improving neural network weight patterns without
changing network structures. By rescaling weights while preserving model
outputs, WISCA indirectly optimizes the model's training trajectory.
Experiments demonstrate that WISCA significantly improves convergence quality
(measured by generalization capability and loss reduction), particularly in
LLMs with Grouped Query Attention (GQA) architectures and LoRA fine-tuning
tasks. Empirical results show 5.6% average improvement on zero-shot validation
tasks and 2.12% average reduction in training perplexity across multiple
architectures.

</details>


### [150] [Recall-Extend Dynamics: Enhancing Small Language Models through Controlled Exploration and Refined Offline Integration](https://arxiv.org/abs/2508.16677)
*Zhong Guan,Likang Wu,Hongke Zhao,Jiahui Wang,Le Wu*

Main category: cs.LG

TL;DR: 提出RED方法，通过平衡离线蒸馏与在线强化学习，优化小语言模型的探索空间及数据处理复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提升小语言模型推理能力上存在探索不足及蒸馏冗余问题，需动态协调离线/在线学习机制。

Method: 设计熵变比率监控机制控制离线数据权重，构建策略转移机制动态选择模仿蒸馏数据或自主策略学习。

Result: 有效解决小模型探索空间受限及数据分布差异问题（具体实验数据需参考论文完整内容）。

Conclusion: RED通过动态平衡离线蒸馏与在线强化学习，系统性提升了小语言模型的推理能力优化效率。

Abstract: Many existing studies have achieved significant improvements in the reasoning
capabilities of large language models (LLMs) through reinforcement learning
with verifiable rewards (RLVR), while the enhancement of reasoning abilities in
small language models (SLMs) has not yet been sufficiently explored. Combining
distilled data from larger models with RLVR on small models themselves is a
natural approach, but it still faces various challenges and issues. Therefore,
we propose \textit{\underline{R}}ecall-\textit{\underline{E}}xtend
\textit{\underline{D}}ynamics(RED): Enhancing Small Language Models through
Controlled Exploration and Refined Offline Integration. In this paper, we
explore the perspective of varying exploration spaces, balancing offline
distillation with online reinforcement learning. Simultaneously, we
specifically design and optimize for the insertion problem within offline data.
By monitoring the ratio of entropy changes in the model concerning offline and
online data, we regulate the weight of offline-SFT, thereby addressing the
issues of insufficient exploration space in small models and the redundancy and
complexity during the distillation process. Furthermore, to tackle the
distribution discrepancies between offline data and the current policy, we
design a sample-accuracy-based policy shift mechanism that dynamically chooses
between imitating offline distilled data and learning from its own policy.

</details>


### [151] [Hyperbolic Multimodal Representation Learning for Biological Taxonomies](https://arxiv.org/abs/2508.16744)
*ZeMing Gong,Chuanqi Tang,Xiaoliang Huo,Nicholas Pellegrino,Austin T. Wang,Graham W. Taylor,Angel X. Chang,Scott C. Lowe,Joakim Bruslund Haurum*

Main category: cs.LG

TL;DR: 提出使用双曲空间嵌入多模态数据改进生物多样性分类模型，在未见过物种的DNA分类任务中表现最优


<details>
  <summary>Details</summary>
Motivation: 生物多样性研究中传统分类方法在细粒度分类和开放世界泛化方面存在局限，需探索更适合层级结构建模的嵌入空间

Method: 通过对比学习和新型堆叠蕴涵目标，将多模态输入嵌入共享双曲空间

Result: 在BIOSCAN-1M数据集上双曲模型达到与欧氏基线相当水平，且在DNA条形码的未见物种分类上优于所有模型

Conclusion: 该框架为生物多样性建模提供结构感知基础，在物种发现和生态保护方面具应用潜力，但细粒度分类仍需改进

Abstract: Taxonomic classification in biodiversity research involves organizing
biological specimens into structured hierarchies based on evidence, which can
come from multiple modalities such as images and genetic information. We
investigate whether hyperbolic networks can provide a better embedding space
for such hierarchical models. Our method embeds multimodal inputs into a shared
hyperbolic space using contrastive and a novel stacked entailment-based
objective. Experiments on the BIOSCAN-1M dataset show that hyperbolic embedding
achieves competitive performance with Euclidean baselines, and outperforms all
other models on unseen species classification using DNA barcodes. However,
fine-grained classification and open-world generalization remain challenging.
Our framework offers a structure-aware foundation for biodiversity modelling,
with potential applications to species discovery, ecological monitoring, and
conservation efforts.

</details>


### [152] [Interpreting the Effects of Quantization on LLMs](https://arxiv.org/abs/2508.16785)
*Manpreet Singh,Hassan Sajjad*

Main category: cs.LG

TL;DR: 研究发现4/8比特量化对LLM内部表征影响有限，模型校准偏差轻微，神经元活性/贡献模式保持稳定，量化仍可作为可靠模型压缩方案。


<details>
  <summary>Details</summary>
Motivation: 量化技术虽能降低LLM部署成本，但其对模型内部表征的影响尚未被充分研究，需验证量化模型可靠性以促进实际应用。

Method: 使用多种可解释性技术分析不同规模LLM（含Llama-2系列）在4/8比特量化下的模型校准、神经元激活模式（含dead neurons统计）及神经元对预测的贡献度变化。

Result: 量化后模型校准偏差<1%，dead neurons数量不变；小尺寸全精度模型显著神经元较少，大模型反之（Llama-2-7B例外）；神经元冗余度变化存在模型差异性。

Conclusion: 量化影响存在模型/任务依赖性，但未发现颠覆性负面效应，支持其作为可靠的模型压缩技术持续使用。

Abstract: Quantization offers a practical solution to deploy LLMs in
resource-constraint environments. However, its impact on internal
representations remains understudied, raising questions about the reliability
of quantized models. In this study, we employ a range of interpretability
techniques to investigate how quantization affects model and neuron behavior.
We analyze multiple LLMs under 4-bit and 8-bit quantization. Our findings
reveal that the impact of quantization on model calibration is generally minor.
Analysis of neuron activations indicates that the number of dead neurons, i.e.,
those with activation values close to 0 across the dataset, remains consistent
regardless of quantization. In terms of neuron contribution to predictions, we
observe that smaller full precision models exhibit fewer salient neurons,
whereas larger models tend to have more, with the exception of Llama-2-7B. The
effect of quantization on neuron redundancy varies across models. Overall, our
findings suggest that effect of quantization may vary by model and tasks,
however, we did not observe any drastic change which may discourage the use of
quantization as a reliable model compression technique.

</details>


### [153] [Attention Layers Add Into Low-Dimensional Residual Subspaces](https://arxiv.org/abs/2508.16929)
*Junxuan Wang,Xuyang Ge,Wentao Shu,Zhengfu He,Xipeng Qiu*

Main category: cs.LG

TL;DR: 发现Transformer注意力输出存在低维子空间现象，提出子空间约束训练方法使稀疏自编码器的死特征比例从87%降至1%


<details>
  <summary>Details</summary>
Motivation: 针对注意力输出低维子空间特性与稀疏字典学习中随机初始化特征不匹配导致的死特征问题展开研究

Method: 提出将特征方向初始化为激活活跃子空间的约束训练方法

Result: 在包含100万特征的注意力输出SAE中，死特征比例从87%降至1%以下，方法可扩展到其他稀疏字典学习

Conclusion: 揭示了注意力几何结构新特性，为改进大语言模型稀疏字典学习提供了理论依据和实用工具

Abstract: While transformer models are widely believed to operate in high-dimensional
hidden spaces, we show that attention outputs are confined to a surprisingly
low-dimensional subspace, where about 60\% of the directions account for 99\%
of the variance--a phenomenon that is induced by the attention output
projection matrix and consistently observed across diverse model families and
datasets. Critically, we find this low-rank structure as a fundamental cause of
the prevalent dead feature problem in sparse dictionary learning, where it
creates a mismatch between randomly initialized features and the intrinsic
geometry of the activation space. Building on this insight, we propose a
subspace-constrained training method for sparse autoencoders (SAEs),
initializing feature directions into the active subspace of activations. Our
approach reduces dead features from 87\% to below 1\% in Attention Output SAEs
with 1M features, and can further extend to other sparse dictionary learning
methods. Our findings provide both new insights into the geometry of attention
and practical tools for improving sparse dictionary learning in large language
models.

</details>


### [154] [LLM Assertiveness can be Mechanistically Decomposed into Emotional and Logical Components](https://arxiv.org/abs/2508.17182)
*Hikaru Tsujimura,Arush Tagade*

Main category: cs.LG

TL;DR: 研究发现LLM的过度自信源于其内部断言性表征可分解为情感与逻辑双路径，通过导向向量干预可缓解该问题


<details>
  <summary>Details</summary>
Motivation: 解决LLM在高风险场景中因过度自信导致错误信息传播的问题，探究其内部机制

Method: 使用标注数据微调Llama模型，通过残差激活分析和相似性度量定位断言性表征，构建正交子成分导向向量进行因果验证

Result: 发现断言性表征包含情感（全局预测影响）和逻辑（局部效应）双路径，与心理学双加工模型一致

Conclusion: 揭示了LLM断言性的多组件结构，为通过路径特异性干预降低模型过度自信提供了理论依据

Abstract: Large Language Models (LLMs) often display overconfidence, presenting
information with unwarranted certainty in high-stakes contexts. We investigate
the internal basis of this behavior via mechanistic interpretability. Using
open-sourced Llama 3.2 models fine-tuned on human annotated assertiveness
datasets, we extract residual activations across all layers, and compute
similarity metrics to localize assertive representations. Our analysis
identifies layers most sensitive to assertiveness contrasts and reveals that
high-assertive representations decompose into two orthogonal sub-components of
emotional and logical clusters-paralleling the dual-route Elaboration
Likelihood Model in Psychology. Steering vectors derived from these
sub-components show distinct causal effects: emotional vectors broadly
influence prediction accuracy, while logical vectors exert more localized
effects. These findings provide mechanistic evidence for the multi-component
structure of LLM assertiveness and highlight avenues for mitigating
overconfident behavior.

</details>


### [155] [TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling](https://arxiv.org/abs/2508.17445)
*Yizhi Li,Qingshui Gu,Zhoufutu Wen,Ziniu Li,Tianshun Xing,Shuyue Guo,Tianyu Zheng,Xin Zhou,Xingwei Qu,Wangchunshu Zhou,Zheng Zhang,Wei Shen,Qian Liu,Chenghua Lin,Jian Yang,Ge Zhang,Wenhao Huang*

Main category: cs.LG

TL;DR: 提出TreePO方法，通过树状结构搜索提升语言模型推理效率，在保证多样性的同时减少35%-43%计算资源消耗


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习对齐方法存在的在线rollout成本高、推理路径探索有限的问题

Method: 1. 基于树结构的动态采样策略（分段解码+早停机制）
2. 树状分段优势估计（结合全局和局部PPO）
3. 概率质量双驱动的动态发散控制策略

Result: 实验显示：训练模型采样设计节省22%-43% GPU时间，现有模型轨迹级采样计算减少40%，token级减少35%

Conclusion: TreePO在推理效率和探索多样性间取得平衡，为基于RL的后训练提供了更经济的实现路径

Abstract: Recent advancements in aligning large language models via reinforcement
learning have achieved remarkable gains in solving complex reasoning problems,
but at the cost of expensive on-policy rollouts and limited exploration of
diverse reasoning paths. In this work, we introduce TreePO, involving a
self-guided rollout algorithm that views sequence generation as a
tree-structured searching process. Composed of dynamic tree sampling policy and
fixed-length segment decoding, TreePO leverages local uncertainty to warrant
additional branches. By amortizing computation across common prefixes and
pruning low-value paths early, TreePO essentially reduces the per-update
compute burden while preserving or enhancing exploration diversity. Key
contributions include: (1) a segment-wise sampling algorithm that alleviates
the KV cache burden through contiguous segments and spawns new branches along
with an early-stop mechanism; (2) a tree-based segment-level advantage
estimation that considers both global and local proximal policy optimization.
and (3) analysis on the effectiveness of probability and quality-driven dynamic
divergence and fallback strategy. We empirically validate the performance gain
of TreePO on a set reasoning benchmarks and the efficiency saving of GPU hours
from 22\% up to 43\% of the sampling design for the trained models, meanwhile
showing up to 40\% reduction at trajectory-level and 35\% at token-level
sampling compute for the existing models. While offering a free lunch of
inference efficiency, TreePO reveals a practical path toward scaling RL-based
post-training with fewer samples and less compute. Home page locates at
https://m-a-p.ai/TreePO.

</details>


### [156] [Activation Transport Operators](https://arxiv.org/abs/2508.17540)
*Andrzej Szablewski,Marek Masiak*

Main category: cs.LG

TL;DR: 提出激活传输算子（ATO）追踪Transformer残差流中的线性特征传输，验证其在模型安全调试中的实用价值


<details>
  <summary>Details</summary>
Motivation: 理解残差流中特征的动态传输机制，可提升对抗攻击防护能力，实现模型错误早期检测与修正

Method: 使用k层线性映射算子（ATO）配合下游SAE解码器投影，建立特征空间传输效率指标及子空间规模估计方法

Result: 证实ATO能有效区分特征来源（线性传输/非线性合成），测得残差流线性传输子空间占比约10%-15%

Conclusion: 无需微调的轻量级方法（<50 GPU时）为LLM安全分析和线性行为定位提供了新工具

Abstract: The residual stream mediates communication between transformer decoder layers
via linear reads and writes of non-linear computations. While sparse-dictionary
learning-based methods locate features in the residual stream, and activation
patching methods discover circuits within the model, the mechanism by which
features flow through the residual stream remains understudied. Understanding
this dynamic can better inform jailbreaking protections, enable early detection
of model mistakes, and their correction. In this work, we propose Activation
Transport Operators (ATO), linear maps from upstream to downstream residuals
$k$ layers later, evaluated in feature space using downstream SAE decoder
projections. We empirically demonstrate that these operators can determine
whether a feature has been linearly transported from a previous layer or
synthesised from non-linear layer computation. We develop the notion of
transport efficiency, for which we provide an upper bound, and use it to
estimate the size of the residual stream subspace that corresponds to linear
transport. We empirically demonstrate the linear transport, report transport
efficiency and the size of the residual stream's subspace involved in linear
transport. This compute-light (no finetuning, <50 GPU-h) method offers
practical tools for safety, debugging, and a clearer picture of where
computation in LLMs behaves linearly.

</details>


### [157] [Characterizing the Behavior of Training Mamba-based State Space Models on GPUs](https://arxiv.org/abs/2508.17679)
*Trinayan Baruah,Kaustubh Shivdikar,Sara Prescott,David Kaeli*

Main category: cs.LG

TL;DR: Mamba-based状态空间模型(SSM)作为Transformer的替代方案，通过降低计算复杂度解决了长序列处理难题，研究其在GPU上的训练行为并提出了优化方向。


<details>
  <summary>Details</summary>
Motivation: Transformer的二次方计算复杂度限制了长序列处理能力，SSM为视频/文本/图等领域提供了更高效的架构，需分析其在GPU上的微架构设计需求。

Method: 构建跨架构的SSM模型套件，通过硬件计数器分析GPU训练时的计算强度、内存带宽利用等微架构行为特征。

Result: SSM表现出低计算强度(0.3TFLOPs)、高内存带宽需求(1.3TB/s)，建议优化内存子系统和并行计算架构提升性能。

Conclusion: 该研究为GPU架构优化和SSM性能扩展提供了关键见解，揭示了内存带宽优化对提升模型训练效率的重要性。

Abstract: Mamba-based State Space Models (SSM) have emerged as a promising alternative
to the ubiquitous transformers. Despite the expressive power of transformers,
the quadratic complexity of computing attention is a major impediment to
scaling performance as we increase the sequence length. SSMs provide an
alternative path that addresses this problem, reducing the computational
complexity requirements of self-attention with novel model architectures for
different domains and fields such as video, text generation and graphs. Thus,
it is important to characterize the behavior of these emerging workloads on
GPUs and understand their requirements during GPU microarchitectural design. In
this work we evaluate Mamba-based SSMs and characterize their behavior during
training on GPUs. We construct a workload suite that offers representative
models that span different model architectures. We then use this suite to
analyze the architectural implications of running Mamba-based SSMs on GPUs. Our
work sheds new light on potential optimizations to continue scaling the
performance for such models.

</details>


### [158] [Proximal Supervised Fine-Tuning](https://arxiv.org/abs/2508.17784)
*Wenhong Zhu,Ruobing Xie,Rui Wang,Xingwu Sun,Di Wang,Pengfei Liu*

Main category: cs.LG

TL;DR: 提出PSFT方法，通过引入信任区域机制解决监督微调中的泛化问题，在多个领域展现优异性能


<details>
  <summary>Details</summary>
Motivation: 传统监督微调(SFT)会导致基础模型能力退化，存在策略漂移和泛化不足问题

Method: 受强化学习TRPO/PPO启发，将SFT重构为带恒定优势的策略梯度特例，设计带信任区域约束的优化目标

Result: 在数学推理和价值观对齐任务中，PSFT域内性能持平SFT，域外泛化提升10-15%，且保持200+epoch训练稳定性

Conclusion: PSFT为后续优化提供更稳定基础，其约束机制有效预防熵崩溃，支持持续学习

Abstract: Supervised fine-tuning (SFT) of foundation models often leads to poor
generalization, where prior capabilities deteriorate after tuning on new tasks
or domains. Inspired by trust-region policy optimization (TRPO) and proximal
policy optimization (PPO) in reinforcement learning (RL), we propose Proximal
SFT (PSFT). This fine-tuning objective incorporates the benefits of
trust-region, effectively constraining policy drift during SFT while
maintaining competitive tuning. By viewing SFT as a special case of policy
gradient methods with constant positive advantages, we derive PSFT that
stabilizes optimization and leads to generalization, while leaving room for
further optimization in subsequent post-training stages. Experiments across
mathematical and human-value domains show that PSFT matches SFT in-domain,
outperforms it in out-of-domain generalization, remains stable under prolonged
training without causing entropy collapse, and provides a stronger foundation
for the subsequent optimization.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [159] [Empirical Analysis of the Effect of Context in the Task of Automated Essay Scoring in Transformer-Based Models](https://arxiv.org/abs/2508.16638)
*Abhirup Chakravarty*

Main category: cs.CY

TL;DR: 通过多维度上下文增强提升Transformer模型在自动作文评分中的表现，QWK分数达0.823，接近最优深度学习模型


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在AES任务中表现不及其他深度学习架构，需通过上下文因素改进模型性能

Method: 使用ASAP-AES数据集分析多种上下文维度对模型的影响，构建多维度上下文增强模型

Result: 最佳模型整体QWK均值0.823，单题训练达0.8697，在8个题目集中有3个超过当前最优模型

Conclusion: 上下文增强方法可无缝集成现有AES系统，为教育自动化评估提供通用性优化方案

Abstract: Automated Essay Scoring (AES) has emerged to prominence in response to the
growing demand for educational automation. Providing an objective and
cost-effective solution, AES standardises the assessment of extended responses.
Although substantial research has been conducted in this domain, recent
investigations reveal that alternative deep-learning architectures outperform
transformer-based models. Despite the successful dominance in the performance
of the transformer architectures across various other tasks, this discrepancy
has prompted a need to enrich transformer-based AES models through contextual
enrichment.
  This study delves into diverse contextual factors using the ASAP-AES dataset,
analysing their impact on transformer-based model performance. Our most
effective model, augmented with multiple contextual dimensions, achieves a mean
Quadratic Weighted Kappa score of 0.823 across the entire essay dataset and
0.8697 when trained on individual essay sets. Evidently surpassing prior
transformer-based models, this augmented approach only underperforms relative
to the state-of-the-art deep learning model trained essay-set-wise by an
average of 3.83\% while exhibiting superior performance in three of the eight
sets.
  Importantly, this enhancement is orthogonal to architecture-based
advancements and seamlessly adaptable to any AES model. Consequently, this
contextual augmentation methodology presents a versatile technique for refining
AES capabilities, contributing to automated grading and evaluation evolution in
educational settings.

</details>


### [160] [Leveraging Multi-Source Textural UGC for Neighbourhood Housing Quality Assessment: A GPT-Enhanced Framework](https://arxiv.org/abs/2508.16657)
*Qiyuan Hong,Huimin Zhao,Ying Long*

Main category: cs.CY

TL;DR: 研究利用GPT-4o分析多源UGC数据开发住房质量评估系统，微调后准确率达92.5%


<details>
  <summary>Details</summary>
Motivation: 解决传统住房评估中客观测量与居民主观体验的脱节问题，探索多平台UGC数据特性差异

Method: 整合大众点评/微博/政府留言板数据，通过文本过滤-结构化提取-情感分析三阶段流程，建立含11类46指标的评估体系

Result: GPT-4o在细粒度分析中显著优于规则系统和BERT模型（92.5% vs 85%），揭示平台关注点差异（大众点评重商业配套，微博聚焦社区环境）

Conclusion: UGC与GPT-4o的结合实现了可扩展的居民视角城市评估，为智慧城市决策提供了数据融合分析新范式

Abstract: This study leverages GPT-4o to assess neighbourhood housing quality using
multi-source textural user-generated content (UGC) from Dianping, Weibo, and
the Government Message Board. The analysis involves filtering relevant texts,
extracting structured evaluation units, and conducting sentiment scoring. A
refined housing quality assessment system with 46 indicators across 11
categories was developed, highlighting an objective-subjective method gap and
platform-specific differences in focus. GPT-4o outperformed rule-based and BERT
models, achieving 92.5% accuracy in fine-tuned settings. The findings
underscore the value of integrating UGC and GPT-driven analysis for scalable,
resident-centric urban assessments, offering practical insights for
policymakers and urban planners.

</details>


### [161] [Invisible Filters: Cultural Bias in Hiring Evaluations Using Large Language Models](https://arxiv.org/abs/2508.16673)
*Pooja S. B. Rao,Laxminarayen Nagarajan Venkatesan,Mauro Cherubini,Dinesh Babu Jayagopi*

Main category: cs.CY

TL;DR: 研究揭示大型语言模型在招聘中存在跨文化偏见，印度求职者因语言特征评分偏低，但姓名身份替换未显著影响评估结果。


<details>
  <summary>Details</summary>
Motivation: 针对AI招聘工具在跨文化场景中潜在的偏见问题，填补现有研究在系统性评估文化差异对LLM招聘决策影响方面的空白。

Method: 使用英国和印度的面试文本数据集，分析LLM生成的可雇用性评分差异，通过语言特征分析和身份信息替换实验（性别/种姓/地域）验证偏见来源。

Result: 印度求职者评分系统性低于英国求职者（匿名后仍存在），差异与句子复杂度和词汇多样性相关；身份信息单独替换未引起显著统计差异。

Conclusion: 强调在AI招聘工具开发中需同时关注语言特征与社会身份因素，倡导建立文化敏感的算法问责机制以实现公平评估。

Abstract: Artificial Intelligence (AI) is increasingly used in hiring, with large
language models (LLMs) having the potential to influence or even make hiring
decisions. However, this raises pressing concerns about bias, fairness, and
trust, particularly across diverse cultural contexts. Despite their growing
role, few studies have systematically examined the potential biases in
AI-driven hiring evaluation across cultures. In this study, we conduct a
systematic analysis of how LLMs assess job interviews across cultural and
identity dimensions. Using two datasets of interview transcripts, 100 from UK
and 100 from Indian job seekers, we first examine cross-cultural differences in
LLM-generated scores for hirability and related traits. Indian transcripts
receive consistently lower scores than UK transcripts, even when they were
anonymized, with disparities linked to linguistic features such as sentence
complexity and lexical diversity. We then perform controlled identity
substitutions (varying names by gender, caste, and region) within the Indian
dataset to test for name-based bias. These substitutions do not yield
statistically significant effects, indicating that names alone, when isolated
from other contextual signals, may not influence LLM evaluations. Our findings
underscore the importance of evaluating both linguistic and social dimensions
in LLM-driven evaluations and highlight the need for culturally sensitive
design and accountability in AI-assisted hiring.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [162] [Wave Tracing: Generalizing The Path Integral To Wave Optics](https://arxiv.org/abs/2508.17386)
*Shlomi Steinberg,Matt Pharr*

Main category: physics.optics

TL;DR: 提出基于椭圆锥采样的弱局域路径积分方法，实现波动光学效应的高效模拟与复杂环境中的长波长辐射传播计算。


<details>
  <summary>Details</summary>
Motivation: 传统基于射线的方法（如UTD衍射）难以准确模拟波动光学效应，且波动模拟计算复杂度远高于经典射线模型。需要开发能同时兼顾波动干涉效应和计算效率的新方法。

Method: 1. 扩展经典路径积分为双线性路径积分模型，建模路径间波动干涉
2. 开发基于椭圆锥的区域间弱局域路径积分方法，实现波动效应的单路径采样
3. 构建完整波动追踪系统，支持椭圆锥传输建模

Result: 实现了可准确建模衍射效应的高效波动追踪系统，适用于复杂环境的光传输渲染和长波长辐射传播模拟。系统可推导多种实用传输算法。

Conclusion: 所提出的路径积分为波动光学模拟提供了统一框架，既兼容现有基于射线的方法，又突破其采样限制，在计算机图形学和电磁传播领域具有广泛适用性。

Abstract: Modeling the wave nature of light and the propagation and diffraction of
electromagnetic fields is crucial for the accurate simulation of many
phenomena, yet wave simulations are significantly more computationally complex
than classical ray-based models. In this work, we start by analyzing the
classical path integral formulation of light transport and rigorously study
which wave-optical phenomena can be reproduced by it. We then introduce a
bilinear path integral generalization for wave-optical light transport that
models the wave interference between paths. This formulation subsumes many
existing methods that rely on shooting-bouncing rays or UTD-based diffractions,
and serves to give insight into the challenges of such approaches and the
difficulty of sampling good paths in a bilinear setting.
  With this foundation, we develop a weakly-local path integral based on
region-to-region transport using elliptical cones that allows sampling
individual paths that still model wave effects accurately. As with the classic
path integral form of the light transport equation, our path integral makes it
possible to derive a variety of practical transport algorithms. We present a
complete system for wave tracing with elliptical cones, with applications in
light transport for rendering and efficient simulation of long-wavelength
radiation propagation and diffraction in complex environments.

</details>
