<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.GR](#cs.GR) [Total: 2]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.CV](#cs.CV) [Total: 9]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.SI](#cs.SI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 研究揭示多语言LLM中思维链推理的归因偏差：过度关注最后推理步骤、高资源语言受益明显、抗干扰能力薄弱。


<details>
  <summary>Details</summary>
Motivation: 评估思维链提示在不同语言场景下的解释可信度与逻辑一致性，验证其多语言鲁棒性。

Method: 采用ContextCite（步骤归因）和Inseq（标记归因）方法，基于Qwen2.5 1.5B-Instruct模型在MGSM基准进行测试。

Result: 1.错误推理过度依赖最后步骤
2.CoT仅提升拉丁语系准确率
3.干扰语句显著破坏模型稳定性

Conclusion: 思维链提示存在跨语言解释透明度缺陷，需开发更均衡的多语言推理框架。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出评估AI非语言解读能力的Motion2Mind框架，揭示现有系统在检测和解释上存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 现有心智理论基准局限于错误信念任务，忽视非语言交流的复杂心理状态解读需求

Method: 基于专家身体语言知识库构建精细标注视频数据集（222种线索+397种心理状态）

Result: 当前AI在非语言线索检测存在性能差距，解释呈现过度解读倾向

Conclusion: 需提升AI对非语言社交信号的理解能力，Motion2Mind成为关键评估工具

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出TOD-ProcBench基准，系统评估大语言模型在任务导向对话中遵循复杂流程指令的能力


<details>
  <summary>Details</summary>
Motivation: 现有TOD基准过度简化真实场景中的复杂指令约束，需建立更贴近实际的评估体系

Method: 基于ABCD数据集构建多层次条件-动作指令文档，设计指令违反检测、条件响应生成等三大评估任务，并考察多语言/格式影响

Result: 不同LLMs在复杂指令遵循表现差异显著，多语言场景和指令格式调整对合规性产生系统性影响

Conclusion: 填补复杂指令评估空白，为提升LLMs的流程理解能力提供新方向，基准数据集已开源

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: LIARS' BENCH测试平台揭示现有大语言模型谎言检测技术的系统性缺陷，并提供7万+多样化谎言样本用于技术改进


<details>
  <summary>Details</summary>
Motivation: 现有LLM谎言检测技术验证场景单一，无法覆盖模型可能生成的各种谎言类型

Method: 构建包含72,863个谎言样本的测试平台，覆盖4个开源模型和7个数据集，按欺骗动机和信念对象两个维度分类

Result: 现有黑白盒检测技术无法有效识别特定类型谎言（尤其是无法仅通过对话记录判断的场景）

Conclusion: 该测试平台为谎言检测技术的突破提供实用基准，揭示了现有方法的局限性

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: 提出LTLA方法，结合基础语言模型与固定替代模型，提升受控生成的效率与效果，解决现有方法在上下文感知和计算效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有HMM等替代模型上下文感知弱，导致查询质量下降；传统方法存在词汇遍历效率低、计算无法复用等问题，需开发高效解决方案。

Method: 使用基础模型编码前缀+固定替代模型计算精确后续概率，通过单次批处理HMM更新避免逐词遍历，固定解码器参数实现跨前缀计算复用。

Result: LTLA条件似然优于HMM，支持视觉语言模型上下文建模，在受控生成任务中提升约束满足度且保持流畅性，计算开销极小。

Conclusion: LTLA有效平衡效率与质量，为序列级约束的受控生成提供通用解决方案，适用于多模态场景，具备实际应用潜力。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: GPT-5辅助科学家在多个学科取得新突破（包括数学领域4个已验证新成果）


<details>
  <summary>Details</summary>
Motivation: 科学家对前沿AI能力认知不足，需展示AI在科研中的实际应用潜力

Method: 通过数学、物理、材料科学等跨学科案例研究，记录人机协作模式

Result: 验证了AI可加速科研进程（尤其在数学领域解决未解问题），但人类指导仍不可或缺

Conclusion: GPT-5当前贡献虽有限，但预示AI快速发展将深刻改变科研范式

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出基于集成学习的提示优化框架ELPO，通过投票机制和多样化搜索策略显著提升自动提示优化的准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法在复杂任务中存在性能瓶颈，单一模型/算法难以满足需求。手动提示工程效率低下制约LLMs实际应用

Method: 采用集成学习思想，设计投票机制结合共享生成策略，创新提出高效提示生成算法与多维度搜索方法

Result: 在ArSarcasm等数据集上F1分数提升7.6，全面超越现有SOTA提示优化方法

Conclusion: ELPO框架有效突破单策略限制，为自动提示优化领域提供了更强大的解决方案

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 提出SemanticCite系统，通过全文分析和AI模型验证引用准确性，实现高效的大规模文献校验


<details>
  <summary>Details</summary>
Motivation: 解决学术文献中日益严重的语义引用错误、AI生成虚假参考文献，以及传统引用格式无法定位具体证据段落的问题

Method: 结合多种检索方法和四分类系统（支持/部分支持/不支持/不确定），采用轻量级微调语言模型实现高效验证

Result: 构建含1000+多学科引用的标注数据集，开源验证框架，微调模型性能接近商业系统但计算成本显著降低

Conclusion: 该系统通过可扩展的引用验证、智能化同行评审和AI内容质控，为维护研究完整性提供开源解决方案

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出语义结构熵（SeSE）框架，通过结构信息视角量化大语言模型语义不确定性，显著提升幻觉检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法依赖概率分布或距离度量，忽略潜在语义结构信息，导致估计不精确。需从结构信息角度开发更可靠的UQ方法以减少幻觉。

Method: 1. 构建自适应稀疏有向语义图，捕捉方向性语义依赖并自动剪枝干扰连接
2. 通过层次抽象提取潜在结构信息，定义最优语义编码树的结构熵
3. 扩展SeSE至长文本生成场景，建模随机语义交互实现细粒度不确定性量化

Result: 在29个模型-数据集组合实验中，SeSE显著优于KLE等先进基线方法，包括监督学习方法

Conclusion: SeSE通过结构信息理论框架实现理论可解释的幻觉检测，为安全关键场景提供可靠的不确定性量化工具

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出无需训练的SDA框架，通过动态调整模型输出概率提升大语言模型与人类意图的对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法依赖昂贵重训练或大量监督，需在推理阶段实现高效且灵活的对齐方案

Method: 基于用户指令动态重分布概率分布，轻量级设计兼容不同模型，支持独立运行或与训练策略整合

Result: 在8个开源模型上实现3H维度显著提升：帮助性64.4%、诚实性30%、无害性11.5%

Conclusion: SDA框架有效提升多场景下的模型对齐能力，支持个性化偏好控制并展现跨模型泛化性

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 提出自我重写框架提升大型推理模型内部思维质量，通过选择性重写保持奖励信号并减少46%推理长度


<details>
  <summary>Details</summary>
Motivation: 现有强化学习奖励机制仅关注结果正确性，导致模型出现过度思考/思考不足/冗余推理等内部质量问题

Method: 设计选择性重写算法（仅重写模型持续正确的简单样本），通过批量并行生成实现约10%的额外开销

Result: 在准确率-长度权衡中提升0.6准确率同时缩短46%推理，LLM评估显示内部推理质量提升7.2分

Conclusion: 自我重写机制有效优化模型内部推理过程，在保持强化学习扩展性的同时显著提升推理效率和质量

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [13] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文提出三种新数据集（大规模潜在习语数据集+人工标注数据集）用于提升预训练语言模型对习语和比喻语言的识别能力


<details>
  <summary>Details</summary>
Motivation: 当前LLM在处理习语和比喻语言方面存在明显不足，现有的大规模语料库未能有效解决这一问题。研究旨在通过构建更优质的数据集缩小模型与人类语言理解能力的差距

Method: 1. 整合现有习语数据集生成综合习语列表
2. 从大规模语料库中提取上下文序列
3. 创建包含潜在表达式的大规模数据集和两个人工标注的确切表达式数据集
4. 基于这些数据集进行习语识别（检测）任务的基线模型评估

Result: 构建的三个数据集经过模型无关的兼容性处理后，成功应用于槽位标注和序列标注任务的模型训练与评估，验证了数据集的实用性

Conclusion: 新型数据集为提升LLM的比喻语言理解提供了有效解决方案，其多类别设计为开发新模型和方法奠定基础，强调高质量数据对突破NLP瓶颈的重要性

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [14] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 研究发现rationale的充分性指标存在局限，需结合token分类和注意力正则化方法系统分析其对模型性能的影响


<details>
  <summary>Details</summary>
Motivation: 现有sufficiency指标只能有限反映rationale信息对模型性能的影响，需通过建模范式揭示其与模型能力的关联

Method: 结合两种建模范式：1) 通过token分类识别rationale成分 2) 通过注意力正则化将rationale融入输入

Result: 发现高信息量rationale未必提升分类准确；sufficiency反映非rationalized上下文的干扰作用；融入rationale对跨领域分类效果存在任务/模型差异

Conclusion: rationale的复杂性表明需要开发能系统捕捉其信息特征的评估指标，现有sufficiency指标与token分类能力无直接关联

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [15] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 提出MinerU-HTML新型HTML提取框架，通过序列标注模型提升结构化元素保留能力，构建高质量AICC语料库并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有HTML提取工具（如Trafilatura）破坏文档结构且无法保留代码/公式等元素，影响大模型训练数据质量。

Method: 将内容提取转化为序列标注问题，使用0.6B参数模型进行语义分类，采用两阶段Markdown转换流程。基于Common Crawl构建7.3万亿token的AICC语料库。

Result: MainWebBench基准测试ROUGE-N F1达81.8%（Trafilatura仅63.6%），代码/公式保留率超90%。AICC训练模型在13个基准上准确率50.8%，优于对比组1.08pp。

Conclusion: HTML提取质量对模型能力有重大影响，MinerU-HTML框架及AICC语料库的发布填补了该领域技术空白。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [16] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 监督机器学习和深度学习模型能有效区分新闻质量，ModernBERT-large模型表现最佳（准确率87.44%，ROC-AUC 95.93%）


<details>
  <summary>Details</summary>
Motivation: 探索算法模型区分新闻质量的能力，以应对虚假/低质信息传播的社会需求

Method: 使用141万篇新闻构建数据集，通过专家评分划分质量等级，提取194个语言特征，测试3种机器学习分类器和3种深度学习模型

Result: 随机森林准确率73.55%，ModernBERT-large达87.44%准确率和95.93% ROC-AUC，不同模型性能随上下文长度变化

Conclusion: 传统CPU机器学习与深度学习均可有效区分新闻质量，深度学习方法在准确率和计算效率上展现优势

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [17] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench：针对可解释ESG问答系统的新基准，包含多主题领域问题及人工标注答案，揭示大模型在事实一致性、可追溯性等领域存在的核心挑战


<details>
  <summary>Details</summary>
Motivation: 解决ESG领域AI系统透明度和可问责性评估的空白，通过构建结构化基准推动可解释ESG问答系统的发展

Method: 构建包含多ESG主题领域问题、人工标注答案及证据支持的基准数据集，开发细粒度模型推理评估框架

Result: 发现主流大模型在事实一致性(35%错误率)、答案可追溯性(仅62%证据匹配)和领域对齐(41%偏离ESG语境)方面存在显著缺陷

Conclusion: ESGBench为开发透明可靠的ESG AI系统提供关键评估工具，将加速领域对齐、推理可解释性等方面的技术突破

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [18] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 通过电路发现技术揭示Transformer处理习语表达的机制，识别出关键注意力头(Idiom Heads)和增强接收现象，阐明模型在计算效率与鲁棒性间的平衡策略


<details>
  <summary>Details</summary>
Motivation: 探究Transformer模型如何处理非组合性语言结构(如习语)，现有研究缺乏对其内部计算机制的理解，因此开发新型电路分析技术进行系统性研究

Method: 1. 改进路径修补算法进行电路发现
2. 分析跨习语频繁激活的注意力头(Idiom Heads)
3. 研究早期处理形成的增强注意力模式(augmented reception)
4. 系统分析电路特征与模型工作机制

Result: 发现特定注意力头专门处理习语，早期处理增强词间注意力，揭示模型通过动态电路调整实现效率与鲁棒性的最佳平衡

Conclusion: 该研究为理解Transformer处理非组合语言提供新视角，其电路分析范式可扩展至更复杂语法结构的机制研究

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [19] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是面向扫描/数字商务文档的结构化数据提取模型，兼具SOTA性能和轻量化部署（6.6GiB，适配24GB显存A10 GPU，可处理125页长文档）。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限硬件环境下高效处理长篇幅商务文档的结构化信息提取需求。

Method: 采用优化的训练协议，平衡模型性能与计算资源消耗，实现轻量化部署。

Result: 模型在文档理解任务中展现出强劲性能，单卡可处理125页文档，适用于实际业务场景。

Conclusion: Arctic-Extract通过算法优化，在保持SOTA性能的同时显著降低部署门槛，为长文档处理提供了实用解决方案。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [20] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 提出了首个土耳其语检索综合基准TurkColBERT，验证后期交互模型在参数效率和性能上显著优于密集编码器


<details>
  <summary>Details</summary>
Motivation: 现有神经检索系统在土耳其语等形态复杂的小语种中缺乏系统评估，需探索参数高效的检索方案

Method: 采用两阶段适配流程：先在NLI/STS任务微调编码器，再通过PyLate训练转为ColBERT检索器，评估5个领域10个模型

Result: 1M参数的模型比600M模型小600倍保留71%性能；后期交互模型在特定领域提升13.8% mAP，索引速度提升3.33倍

Conclusion: 验证了后期交互模型的参数效率优势，但需解决数据集规模限制和翻译基准的潜在偏差问题

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 通过分析LLM激活模式预测文本体裁，使用浅层学习模型实现高准确率


<details>
  <summary>Details</summary>
Motivation: 解决LLM结构不可解释性和人工评估效率低的问题，确保模型安全部署

Method: 使用Mistral-7B模型和scikit-learn分类器，在两个数据集上进行文本体裁预测

Result: 分类器F1分数分别达到98%和71%，显著超越基线任务表现

Conclusion: 验证了通过浅层学习模型从LLM激活中推断文本体裁的可行性

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 传统ASR评估指标WER在临床场景中与错误临床影响相关性低，研究者提出基于LLM的优化评估框架达到人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 现有ASR评估指标（如词错率WER）无法反映转录错误对临床诊疗的实际风险，需建立安全评估体系确保患者安全。

Method: 通过临床专家标注建立黄金标准，采用GEPA优化LLM评估模型（Gemini-2.5-Pro），实现自动化安全风险评估。

Result: 优化后的模型准确率达90%，Cohen's κ=0.816，与人类专家评估高度一致。

Conclusion: 该研究为临床ASR评估提供了超越文本保真度的安全评估框架，实现了可扩展的临床对话安全性验证。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出无需标注数据的词义消歧方法，利用LLM作为消歧预言机


<details>
  <summary>Details</summary>
Motivation: 现有词义消歧方法依赖手工标注数据且仅支持粗粒度语义表示，无法适应复杂推理场景的细粒度消歧需求

Method: 将符号系统生成的候选含义转换为自然语言选项，通过LLM上下文选择最佳解释并反馈至符号系统

Result: 通过与人工标注黄金答案对比验证了方法的有效性

Conclusion: 该方法突破了传统数据标注限制，为复杂语义表示的自动化消歧提供了新思路

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 直接多模态嵌入检索显著优于传统文本摘要方法，在金融文档问答任务中实现13% mAP@5绝对提升


<details>
  <summary>Details</summary>
Motivation: 现有多模态RAG系统通过LLM摘要将图像转为文本会丢失关键视觉信息，影响检索和问答效果

Method: 对比两种多模态检索方法：基于LLM摘要的文本块检索 vs 原生存储图像的多模态嵌入检索，使用含40个QA对的金融数据集测试

Result: 直接多模态检索实现mAP@5提升13%（相对32%）、nDCG@5提升11%（相对20%），且答案准确性更高

Conclusion: 直接多模态嵌入保留视觉上下文，克服LLM摘要的信息损失问题，具有更强的实际应用价值

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 提出Nemotron Elastic框架，通过单一父模型嵌入多个子模型实现360倍成本压缩，子模型性能超越现有技术


<details>
  <summary>Details</summary>
Motivation: 传统大模型多尺度训练成本高昂，现有压缩方法仍需数百亿token训练。希望通过嵌套子模型架构实现零训练成本提取，优化推理模型部署效率

Method: 采用混合Mamba-Attention架构，结合端到端路由器和两阶段训练课程。创新包括分组感知SSM弹性化、异质MLP弹性化、标准化MSE层重要性评估，以及多预算知识蒸馏

Result: 在Nemotron Nano V2 12B模型上仅用110B token生成9B/6B子模型，成本降低360倍（相比从头训练）和7倍（相比SOTA压缩），各子模型准确率优于基准

Conclusion: 该框架实现恒定部署内存的多模型合一架构，突破传统压缩方法限制，为高效推理模型部署提供新范式

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [26] [SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments](https://arxiv.org/abs/2511.15908)
*William Baumgartner,Gizem Kayar-Ceylan*

Main category: cs.GR

TL;DR: 提出统一框架实现VR中刚体、可变形物体与流体的实时双向触觉交互，通过SPH方法和力反馈优化提升物理准确性


<details>
  <summary>Details</summary>
Motivation: 解决多物理系统实时交互中流体/刚体/软体精确力反馈的稳定性与计算效率难题

Method: 结合平滑粒子流体动力学(SPH)、双向力耦合与反馈平滑技术，整合流体-刚体-软体动力学于统一平台

Result: 成功实现流体搅拌、软组织操作等VR场景，验证系统可提供符合流体-结构行为的稳定触觉反馈

Conclusion: 该框架通过统一多物理模拟推进了沉浸式教育应用的触觉交互技术发展

Abstract: Haptic feedback enhances immersion in virtual environments by allowing users to physically interact with simulated objects. Supporting accurate force responses in multiphysics systems is challenging because physically based simulation of fluid, rigid, and deformable materials is computationally demanding, especially when interaction must occur in real time. We present a unified framework for real-time, bidirectional haptic interaction with rigid bodies, deformable objects, and Lagrangian fluids in virtual reality (VR). Our approach integrates Smoothed Particle Hydrodynamics (SPH) with two-way force coupling and feedback smoothing to maintain stability and produce physically meaningful tactile responses. This enables users to manipulate objects immersed in fluid and feel reaction forces consistent with fluid-structure behavior. We demonstrate the capabilities of our framework through interactive VR scenarios involving fluid stirring, soft tissue manipulation, and rigid-body interaction. The proposed system advances haptic-enabled multiphysics simulation by unifying fluid, soft-body, and rigid-body dynamics into a single platform suitable for immersive educational applications.

</details>


### [27] [Controllable Layer Decomposition for Reversible Multi-Layer Image Generation](https://arxiv.org/abs/2511.16249)
*Zihao Liu,Zunnan Xu,Shi Shu,Jun Zhou,Ruicheng Zhang,Zhenchao Tang,Xiu Li*

Main category: cs.GR

TL;DR: 提出可控层分解方法CLD，通过LD-DiT和MLCA模块实现精准的多图层分离与控制，实验证明其优于现有方法并具备实际设计工具兼容性。


<details>
  <summary>Details</summary>
Motivation: 现有设计流程中图层合成后无法逆向编辑，传统图像分层方法存在可控性和精度不足的问题。

Method: 1. LD-DiT模块解耦图像元素至独立层；2. MLCA模块通过多图层条件适配实现精准条件生成；3. 构建新评估基准与指标。

Result: CLD在分解质量和可控性上全面超越现有方法，分离图层可直接在PowerPoint等工具中编辑。

Conclusion: CLD解决了设计工作流中图层不可逆编辑的痛点，其工业化兼容性展现了实际应用价值。

Abstract: This work presents Controllable Layer Decomposition (CLD), a method for achieving fine-grained and controllable multi-layer separation of raster images. In practical workflows, designers typically generate and edit each RGBA layer independently before compositing them into a final raster image. However, this process is irreversible: once composited, layer-level editing is no longer possible. Existing methods commonly rely on image matting and inpainting, but remain limited in controllability and segmentation precision. To address these challenges, we propose two key modules: LayerDecompose-DiT (LD-DiT), which decouples image elements into distinct layers and enables fine-grained control; and Multi-Layer Conditional Adapter (MLCA), which injects target image information into multi-layer tokens to achieve precise conditional generation. To enable a comprehensive evaluation, we build a new benchmark and introduce tailored evaluation metrics. Experimental results show that CLD consistently outperforms existing methods in both decomposition quality and controllability. Furthermore, the separated layers produced by CLD can be directly manipulated in commonly used design tools such as PowerPoint, highlighting its practical value and applicability in real-world creative workflows.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [28] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: 提出首个基于离散音频编解码单元的表征学习框架Codec2Vec，在保持性能的同时实现16.5倍存储压缩和2.3倍训练加速


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，解决现有连续输入模型的存储开销大、训练效率低、隐私风险问题

Method: 使用纯离散编解码单元构建表征框架，结合遮蔽预测技术和多种训练目标推导策略进行模型训练

Result: 在SUPERB基准上达到与连续输入模型相当的竞争力，存储需求降低16.5倍，训练时间减少2.3倍

Conclusion: Codec2Vec验证了离散表征在语音处理中的有效性，为资源受限场景提供高效解决方案，展示了编解码单元在语音表征学习中的新可能

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [29] [QueryGym: A Toolkit for Reproducible LLM-Based Query Reformulation](https://arxiv.org/abs/2511.15996)
*Amin Bigdeli,Radin Hamidi Rad,Mert Incesu,Negar Arabzadeh,Charles L. A. Clarke,Ebrahim Bagheri*

Main category: cs.IR

TL;DR: QueryGym是一个轻量级、可扩展的Python工具包，用于支持基于大语言模型（LLM）的查询重构，提供统一框架实现方法对比和实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有LLM查询重构方法缺乏统一工具包，导致公平比较、快速实验和可靠部署困难。

Method: 1) Python API支持多样化LLM方法 2) 检索无关接口整合后端 3) 带版本控制的提示管理系统 4) 内置BEIR/MS MARCO基准支持 5) 完全开源可扩展实现

Result: 开发了集成多种功能的开源工具包，支持研究人员进行查询重构方法实验与部署。

Conclusion: 该工具包通过标准化框架促进LLM查询重构领域的研究复现、方法比较和实际应用部署。

Abstract: We present QueryGym, a lightweight, extensible Python toolkit that supports large language model (LLM)-based query reformulation. This is an important tool development since recent work on llm-based query reformulation has shown notable increase in retrieval effectiveness. However, while different authors have sporadically shared the implementation of their methods, there is no unified toolkit that provides a consistent implementation of such methods, which hinders fair comparison, rapid experimentation, consistent benchmarking and reliable deployment. QueryGym addresses this gap by providing a unified framework for implementing, executing, and comparing llm-based reformulation methods. The toolkit offers: (1) a Python API for applying diverse LLM-based methods, (2) a retrieval-agnostic interface supporting integration with backends such as Pyserini and PyTerrier, (3) a centralized prompt management system with versioning and metadata tracking, (4) built-in support for benchmarks like BEIR and MS MARCO, and (5) a completely open-source extensible implementation available to all researchers. QueryGym is publicly available at https://github.com/radinhamidi/QueryGym.

</details>


### [30] [Music Recommendation with Large Language Models: Challenges, Opportunities, and Evaluation](https://arxiv.org/abs/2511.16478)
*Elena V. Epure,Yashar Deldjoo,Bruno Sguerra,Markus Schedl,Manuel Moussallam*

Main category: cs.IR

TL;DR: LLM驱动的音乐推荐系统需要重构评估体系，传统准确性指标失效，需整合自然语言处理评估方法并建立多维度评估框架。


<details>
  <summary>Details</summary>
Motivation: 传统音乐推荐系统依赖信息检索范式，无法评估推荐本质质量。LLM的生成特性颠覆传统排名机制，带来新挑战（幻觉/知识断层/不确定性）与机遇（自然交互/模型即评估者）。

Method: 1. 分析LLM对音乐用户建模、内容建模和自然语言推荐的革新 2. 借鉴NLP领域评估方法论 3. 提出基于提示词工程的成功-风险双维度评估框架

Result: 构建跨学科评估视角，明确LLM在音乐推荐中需监控的12个核心指标（如情境理解/文化敏感度）和8类风险（如版权模糊/认知偏差）

Conclusion: 为MRS社区提供融合教育学视角的评估范式转型路径，强调需建立动态评估协议以适应LLM的非确定性特征

Abstract: Music Recommender Systems (MRS) have long relied on an information-retrieval framing, where progress is measured mainly through accuracy on retrieval-oriented subtasks. While effective, this reductionist paradigm struggles to address the deeper question of what makes a good recommendation, and attempts to broaden evaluation, through user studies or fairness analyses, have had limited impact. The emergence of Large Language Models (LLMs) disrupts this framework: LLMs are generative rather than ranking-based, making standard accuracy metrics questionable. They also introduce challenges such as hallucinations, knowledge cutoffs, non-determinism, and opaque training data, rendering traditional train/test protocols difficult to interpret. At the same time, LLMs create new opportunities, enabling natural-language interaction and even allowing models to act as evaluators.
  This work argues that the shift toward LLM-driven MRS requires rethinking evaluation. We first review how LLMs reshape user modeling, item modeling, and natural-language recommendation in music. We then examine evaluation practices from NLP, highlighting methodologies and open challenges relevant to MRS. Finally, we synthesize insights-focusing on how LLM prompting applies to MRS, to outline a structured set of success and risk dimensions. Our goal is to provide the MRS community with an updated, pedagogical, and cross-disciplinary perspective on evaluation.

</details>


### [31] [The Oracle and The Prism: A Decoupled and Efficient Framework for Generative Recommendation Explanation](https://arxiv.org/abs/2511.16543)
*Jiaheng Zhang,Daqiang Zhang*

Main category: cs.IR

TL;DR: 提出解耦框架Prism，通过分离推荐排序与解释生成阶段，结合知识蒸馏技术，在保持高效的同时提升可解释推荐质量。


<details>
  <summary>Details</summary>
Motivation: 解决端到端可解释推荐模型中性能与效率的权衡问题，避免联合优化导致的次优结果。

Method: 1. 用大参数教师模型(FLAN-T5-XXL)生成解释知识
2. 训练轻量学生模型(BART-Base)专门合成个性化解释
3. 两阶段完全解耦架构避免目标冲突

Result: 140M参数的Prism模型：
- 人类评估忠实度/个性化超越11B教师模型
- 推理速度提升24倍
- 内存消耗降低10倍

Conclusion: 解耦架构+定向蒸馏为高质量可解释推荐提供了高效解决方案，证明小模型通过专业化分工可超越大模型综合表现。

Abstract: The integration of Large Language Models (LLMs) into explainable recommendation systems often leads to a performance-efficiency trade-off in end-to-end architectures, where joint optimization of ranking and explanation can result in suboptimal compromises. To resolve this, we propose Prism, a novel decoupled framework that rigorously separates the recommendation process into a dedicated ranking stage and an explanation generation stage.
  Inspired by knowledge distillation, Prism leverages a powerful teacher LLM (e.g., FLAN-T5-XXL) as an Oracle to produce high-fidelity explanatory knowledge. A compact, fine-tuned student model (e.g., BART-Base), the Prism, then specializes in synthesizing this knowledge into personalized explanations. This decomposition ensures that each component is optimized for its specific objective, eliminating inherent conflicts in coupled models.
  Extensive experiments on benchmark datasets demonstrate that our 140M-parameter Prism model significantly outperforms its 11B-parameter teacher in human evaluations of faithfulness and personalization, while achieving a 24 times speedup and a 10 times reduction in memory consumption during inference. These results validate that decoupling, coupled with targeted distillation, provides an efficient and effective pathway to high-quality explainable recommendation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [32] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 提出模拟多智能体系统中不合作行为的框架，揭示其对系统稳定性的破坏性影响


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对不合作行为的系统分类，且多智能体系统对异常行为的脆弱性尚未充分研究

Method: 1. 基于博弈论构建不合作行为分类体系
2. 开发动态生成不合作行为的多阶段模拟流程
3. 通过资源管理场景验证框架有效性

Result: 合作智能体保持100%生存率（12轮）与0%资源过载，任何不合作行为可在1-7轮内导致系统崩溃，框架生成准确率达96.7%

Conclusion: 不合作行为显著降低系统稳定性，凸显设计弹性多智能体系统的必要性，需开发新的异常检测与容错机制

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization](https://arxiv.org/abs/2511.15915)
*Genghan Zhang,Shaowei Zhu,Anjiang Wei,Zhenyu Song,Allen Nie,Zhen Jia,Nandita Vijaykumar,Yida Wang,Kunle Olukotun*

Main category: cs.LG

TL;DR: 自主优化AI加速器内核的自改进LLM系统AccelOpt，在性能与成本效益上实现突破


<details>
  <summary>Details</summary>
Motivation: 解决新兴AI加速器内核优化依赖专家知识的问题，实现无需硬件专家参与的自动化优化

Method: 通过迭代生成优化方案+优化记忆库积累经验，构建NKIBench真实场景测试基准

Result: Trainium加速器峰值吞吐量提升12%（1代49%→61%，2代45%→59%），成本效益达Claude Sonnet的26倍

Conclusion: AccelOpt展现出自进化优化能力，为AI加速器提供高性价比的自动化内核优化方案

Abstract: We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\%$ to $61\%$ on Trainium 1 and from $45\%$ to $59\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\times$ cheaper.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [34] [PSM: Prompt Sensitivity Minimization via LLM-Guided Black-Box Optimization](https://arxiv.org/abs/2511.16209)
*Huseein Jawad,Nicolas Brunel*

Main category: cs.CR

TL;DR: 论文提出通过shield appending框架对LLM系统提示进行文本加固，将提示防护形式化为效用约束优化问题，在保持模型功能的前提下显著降低对抗攻击导致的提示泄漏风险。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制存在依赖启发式规则、计算开销大、无法适配黑盒API等问题，需要开发轻量且实用的防护方案应对系统提示的提取攻击。

Method: 使用LLM作为优化器搜索保护文本(SHIELD)，通过最小化对抗攻击的泄漏指标，同时约束语义保真度维持任务效用，形成黑盒优化框架。

Result: 实验证明优化的SHIELDs在多种提取攻击下显著降低提示泄漏率，且保持与基线模型输出语义相似度超过预定阈值。

Conclusion: 该研究为LLM安全领域提供了兼顾鲁棒性和实用性的防御范式，代码开源推动实际应用。

Abstract: System prompts are critical for guiding the behavior of Large Language Models (LLMs), yet they often contain proprietary logic or sensitive information, making them a prime target for extraction attacks. Adversarial queries can successfully elicit these hidden instructions, posing significant security and privacy risks. Existing defense mechanisms frequently rely on heuristics, incur substantial computational overhead, or are inapplicable to models accessed via black-box APIs. This paper introduces a novel framework for hardening system prompts through shield appending, a lightweight approach that adds a protective textual layer to the original prompt. Our core contribution is the formalization of prompt hardening as a utility-constrained optimization problem. We leverage an LLM-as-optimizer to search the space of possible SHIELDs, seeking to minimize a leakage metric derived from a suite of adversarial attacks, while simultaneously preserving task utility above a specified threshold, measured by semantic fidelity to baseline outputs. This black-box, optimization-driven methodology is lightweight and practical, requiring only API access to the target and optimizer LLMs. We demonstrate empirically that our optimized SHIELDs significantly reduce prompt leakage against a comprehensive set of extraction attacks, outperforming established baseline defenses without compromising the model's intended functionality. Our work presents a paradigm for developing robust, utility-aware defenses in the escalating landscape of LLM security. The code is made public on the following link: https://github.com/psm-defense/psm

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [35] [MiMo-Embodied: X-Embodied Foundation Model Technical Report](https://arxiv.org/abs/2511.16518)
*Xiaoshuai Hao,Lei Zhou,Zhijian Huang,Zhiwen Hou,Yingbo Tang,Lingfeng Zhang,Guang Li,Zheng Lu,Shuhuai Ren,Xianhui Meng,Yuchen Zhang,Jing Wu,Jinghui Lu,Chenxu Dang,Jiayi Guan,Jianhua Wu,Zhiyi Hou,Hanbing Li,Shumeng Xia,Mingliang Zhou,Yinan Zheng,Zihao Yue,Shuhao Gu,Hao Tian,Yuannan Shen,Jianwei Cui,Wen Zhang,Shaoqing Xu,Bing Wang,Haiyang Sun,Zeyu Zhu,Yuncheng Jiang,Zibin Guo,Chuhong Gong,Chaofan Zhang,Wenbo Ding,Kun Ma,Guang Chen,Rui Cai,Diyun Xiang,Heng Qu,Fuli Luo,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: 首个跨具身基础模型MiMo-Embodied在自动驾驶与具身AI领域同步实现SOTA，通过多阶段学习与数据构建实现领域正迁移


<details>
  <summary>Details</summary>
Motivation: 探索自动驾驶与具身AI的跨领域协同效应，验证多任务学习对领域互促的积极作用

Method: 多阶段训练框架 + 领域定制化数据构建 + CoT/RL联合微调策略

Result: 在29个基准测试中刷新记录（17项具身AI任务，12项自动驾驶任务），全面超越开源/闭源基线模型

Conclusion: 成功验证跨领域正迁移效应，开源模型架构与训练方法论为多模态具身智能研究提供新范式

Abstract: We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [36] [Clustered Error Correction with Grouped 4D Gaussian Splatting](https://arxiv.org/abs/2511.16112)
*Taeho Kang,Jaeyeon Park,Kyungjin Lee,Youngki Lee*

Main category: cs.CV

TL;DR: 提出CEM-4DGS方法，通过椭圆误差聚类和分组4D高斯溅射技术解决动态场景重建中的像素对应错误问题，显著提升渲染质量


<details>
  <summary>Details</summary>
Motivation: 现有4DGS方法在动态区域重建中存在像素对应模糊和致密化不足的问题，导致时间一致性差和渲染质量下降

Method: 1. 椭圆误差聚类与纠错溅射添加：通过跨视图颜色一致性指导错误分类与校正
2. 分组4D高斯溅射：建立溅射与动态对象间的稳定映射关系，采用背景投影和前景分割策略

Result: 在Technicolor光场数据集上PSNR提升0.39dB，Neural 3D Video等数据集显示时间一致性显著改善，达到SOTA感知渲染质量

Conclusion: 该方法通过创新性错误校正机制和分组策略，有效解决了动态对象对齐问题，可视化结果验证了溅射初始化策略的有效性

Abstract: Existing 4D Gaussian Splatting (4DGS) methods struggle to accurately reconstruct dynamic scenes, often failing to resolve ambiguous pixel correspondences and inadequate densification in dynamic regions. We address these issues by introducing a novel method composed of two key components: (1) Elliptical Error Clustering and Error Correcting Splat Addition that pinpoints dynamic areas to improve and initialize fitting splats, and (2) Grouped 4D Gaussian Splatting that improves consistency of mapping between splats and represented dynamic objects. Specifically, we classify rendering errors into missing-color and occlusion types, then apply targeted corrections via backprojection or foreground splitting guided by cross-view color consistency. Evaluations on Neural 3D Video and Technicolor datasets demonstrate that our approach significantly improves temporal consistency and achieves state-of-the-art perceptual rendering quality, improving 0.39dB of PSNR on the Technicolor Light Field dataset. Our visualization shows improved alignment between splats and dynamic objects, and the error correction method's capability to identify errors and properly initialize new splats. Our implementation details and source code are available at https://github.com/tho-kn/cem-4dgs.

</details>


### [37] [Layer-wise Noise Guided Selective Wavelet Reconstruction for Robust Medical Image Segmentation](https://arxiv.org/abs/2511.16162)
*Yuting Lu,Ziliang Wang,Weixin Xu,Wei Zhang,Yongqiang Zhao,Yang Yu,Xiaohong Zhang*

Main category: cs.CV

TL;DR: 提出LNG-SWR方法，通过层级噪声注入和选择性小波重建提升医学图像分割模型的抗扰动能力，兼容对抗训练且推理开销低。


<details>
  <summary>Details</summary>
Motivation: 对抗训练(AT)在提升模型鲁棒性时存在干净-鲁棒性权衡和高训练成本问题，难以满足医学影像部署的稳定性需求。

Method: 1. 多层级噪声注入学习频率偏置先验 2. 基于先验的选择性小波重建实现输入/特征频率适应，抑制噪声敏感频段并增强结构特征

Result: 在CT/超声数据上显著提升干净数据Dice/IoU(2-5%)，强攻击下性能下降减少50%以上，与AT结合时鲁棒性叠加提升

Conclusion: LNG-SWR为医学图像分割提供了简单、有效且工程友好的鲁棒性解决方案，适用于对抗训练和标准训练双场景

Abstract: Clinical deployment requires segmentation models to stay stable under distribution shifts and perturbations. The mainstream solution is adversarial training (AT) to improve robustness; however, AT often brings a clean--robustness trade-off and high training/tuning cost, which limits scalability and maintainability in medical imaging. We propose \emph{Layer-wise Noise-Guided Selective Wavelet Reconstruction (LNG-SWR)}. During training, we inject small, zero-mean noise at multiple layers to learn a frequency-bias prior that steers representations away from noise-sensitive directions. We then apply prior-guided selective wavelet reconstruction on the input/feature branch to achieve frequency adaptation: suppress noise-sensitive bands, enhance directional structures and shape cues, and stabilize boundary responses while maintaining spectral consistency. The framework is backbone-agnostic and adds low additional inference overhead. It can serve as a plug-in enhancement to AT and also improves robustness without AT. On CT and ultrasound datasets, under a unified protocol with PGD-$L_{\infty}/L_{2}$ and SSAH, LNG-SWR delivers consistent gains on clean Dice/IoU and significantly reduces the performance drop under strong attacks; combining LNG-SWR with AT yields additive gains. When combined with adversarial training, robustness improves further without sacrificing clean accuracy, indicating an engineering-friendly and scalable path to robust segmentation. These results indicate that LNG-SWR provides a simple, effective, and engineering-friendly path to robust medical image segmentation in both adversarial and standard training regimes.

</details>


### [38] [TetraSDF: Precise Mesh Extraction with Multi-resolution Tetrahedral Grid](https://arxiv.org/abs/2511.16273)
*Seonghun Oh,Youngjung Uh,Jin-Hwa Kim*

Main category: cs.CV

TL;DR: 提出TetraSDF框架，通过四面体位编码与ReLU MLP结合，实现神经符号距离函数(SDF)的精确网格提取，克服传统采样方法和CPWA方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有神经SDF网格提取方法存在离散化误差（采样法）和仅支持普通ReLU MLP（CPWA解析法）的局限性，无法精确匹配学习到的等值面。

Method: 1. 引入多分辨率四面体位编码器，其重心插值保持全局CPWA结构
2. 在编码器诱导的多面体复合体内追踪ReLU线性区域
3. 使用编码器度量导出的固定解析输入预处理器降低方向偏差并稳定训练

Result: 在多个基准测试中：
- SDF重建精度达到或超越现有基于网格的编码器
- 解析提取器生成高自洽网格（几何一致性误差降低54.2%）
- 保持实用运行效率（单场景<5分钟）和内存效率（<1.5GB）

Conclusion: TetraSDF首次实现编码神经SDF的精确解析网格提取，通过四面体分解与理论推导的预处理机制，在保持计算效率的同时忠实呈现学习到的等值面几何。

Abstract: Extracting meshes that exactly match the zero-level set of neural signed distance functions (SDFs) remains challenging. Sampling-based methods introduce discretization error, while continuous piecewise affine (CPWA) analytic approaches apply only to plain ReLU MLPs. We present TetraSDF, a precise analytic meshing framework for SDFs represented by a ReLU MLP composed with a multi-resolution tetrahedral positional encoder. The encoder's barycentric interpolation preserves global CPWA structure, enabling us to track ReLU linear regions within an encoder-induced polyhedral complex. A fixed analytic input preconditioner derived from the encoder's metric further reduces directional bias and stabilizes training. Across multiple benchmarks, TetraSDF matches or surpasses existing grid-based encoders in SDF reconstruction accuracy, and its analytic extractor produces highly self-consistent meshes that remain faithful to the learned isosurfaces, all with practical runtime and memory efficiency.

</details>


### [39] [Optimizing 3D Gaussian Splattering for Mobile GPUs](https://arxiv.org/abs/2511.16298)
*Md Musfiqur Rahman Sanim,Zhihao Shu,Bahram Afsharmanesh,AmirAli Mirian,Jiexiong Guan,Wei Niu,Bin Ren,Gagan Agrawal*

Main category: cs.CV

TL;DR: 提出Texture3dgs优化框架，通过2D纹理缓存优化和新型排序算法，实现移动端3D场景重建速度提升1.7倍、内存降低1.6倍。


<details>
  <summary>Details</summary>
Motivation: 利用3D高斯泼溅算法的高效特性，针对移动GPU的二维纹理缓存进行优化，解决移动端部署时的计算效率与内存瓶颈问题。

Method: 开发新型排序算法优化2D内存访问模式，改进变量布局设计，并辅以纹理缓存成本模型指导算法优化。

Result: 排序步骤加速4.1倍，整体重建速度提升1.7倍，内存占用减少1.6倍。

Conclusion: Texture3dgs有效解决了移动端3D重建效率问题，其纹理缓存优化策略为移动图形计算提供了新范式。

Abstract: Image-based 3D scene reconstruction, which transforms multi-view images into a structured 3D representation of the surrounding environment, is a common task across many modern applications. 3D Gaussian Splatting (3DGS) is a new paradigm to address this problem and offers considerable efficiency as compared to the previous methods. Motivated by this, and considering various benefits of mobile device deployment (data privacy, operating without internet connectivity, and potentially faster responses), this paper develops Texture3dgs, an optimized mapping of 3DGS for a mobile GPU. A critical challenge in this area turns out to be optimizing for the two-dimensional (2D) texture cache, which needs to be exploited for faster executions on mobile GPUs. As a sorting method dominates the computations in 3DGS on mobile platforms, the core of Texture3dgs is a novel sorting algorithm where the processing, data movement, and placement are highly optimized for 2D memory. The properties of this algorithm are analyzed in view of a cost model for the texture cache. In addition, we accelerate other steps of the 3DGS algorithm through improved variable layout design and other optimizations. End-to-end evaluation shows that Texture3dgs delivers up to 4.1$\times$ and 1.7$\times$ speedup for the sorting and overall 3D scene reconstruction, respectively -- while also reducing memory usage by up to 1.6$\times$ -- demonstrating the effectiveness of our design for efficient mobile 3D scene reconstruction.

</details>


### [40] [PartUV: Part-Based UV Unwrapping of 3D Meshes](https://arxiv.org/abs/2511.16659)
*Zhaoning Wang,Xinyue Wei,Ruoxi Shi,Xiaoshuai Zhang,Hao Su,Minghua Liu*

Main category: cs.CV

TL;DR: 提出PartUV——基于部件语义分解的UV展开方法，通过结合几何启发式策略，在保持低畸变的同时显著减少贴图数量


<details>
  <summary>Details</summary>
Motivation: 现有UV展开方法在处理AI生成的粗糙网格时，常产生碎片化贴图和不理想的接缝边界，导致视觉瑕疵并影响下游任务

Method: 基于PartField部件分解框架，采用自上而下的递归架构，融合语义部件分割与几何启发式策略（如动态阈值控制、非流形网格处理），结合参数化与打包算法并行优化

Result: 在人工建模、CAD、AI生成等四类数据集上验证：贴图数量减少28%、接缝长度缩短19%、保持可比较的畸变水平（0.034 vs 0.031），在挑战性网格上的成功率提升45%

Conclusion: PartUV实现了工业级鲁棒性，支持部件级多贴图打包等新应用，其并行化架构处理效率比传统方法提升3倍，项目页面提供完整实现

Abstract: UV unwrapping flattens 3D surfaces to 2D with minimal distortion, often requiring the complex surface to be decomposed into multiple charts. Although extensively studied, existing UV unwrapping methods frequently struggle with AI-generated meshes, which are typically noisy, bumpy, and poorly conditioned. These methods often produce highly fragmented charts and suboptimal boundaries, introducing artifacts and hindering downstream tasks. We introduce PartUV, a part-based UV unwrapping pipeline that generates significantly fewer, part-aligned charts while maintaining low distortion. Built on top of a recent learning-based part decomposition method PartField, PartUV combines high-level semantic part decomposition with novel geometric heuristics in a top-down recursive framework. It ensures each chart's distortion remains below a user-specified threshold while minimizing the total number of charts. The pipeline integrates and extends parameterization and packing algorithms, incorporates dedicated handling of non-manifold and degenerate meshes, and is extensively parallelized for efficiency. Evaluated across four diverse datasets, including man-made, CAD, AI-generated, and Common Shapes, PartUV outperforms existing tools and recent neural methods in chart count and seam length, achieves comparable distortion, exhibits high success rates on challenging meshes, and enables new applications like part-specific multi-tiles packing. Our project page is at https://www.zhaoningwang.com/PartUV.

</details>


### [41] [Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions](https://arxiv.org/abs/2511.16221)
*Caixin Kang,Yifei Huang,Liangyang Ouyang,Mingfang Zhang,Ruicong Liu,Yoichi Sato*

Main category: cs.CV

TL;DR: 研究揭示了当前多模态大语言模型在社交推理中的核心缺陷——无法有效识别复杂交互中的欺骗行为，提出新型评估框架MIDA和社会认知增强模块，实验表明其解决方案显著提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多模态大语言模型虽具备强大推理能力，但缺乏人类'察言观色'的核心社交智能，尤其在识别欺骗性交互方面存在严重缺陷，这对构建可信AI系统构成关键障碍。

Method: 提出多模态交互欺骗评估任务(MIDA)，构建含同步视频文本的验证数据集，测试12个先进模型并分析失败模式，设计社会思维链推理框架(SoCoT)和动态社会认知记忆模块(DSEM)。

Result: 基准测试显示GPT-4o等顶级模型平均准确率仅59%，新框架将性能提升21%，证实社会认知建模的有效性。失败模式分析揭示模型在多模态社交线索融合和他人心理建模方面存在系统性缺陷。

Conclusion: 该研究为开发具有人类水平社交推理能力的AI指明新方向，通过社会认知架构增强多模态理解，为解决'机器察言观色'难题提供了可行路径。

Abstract: Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.

</details>


### [42] [TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding](https://arxiv.org/abs/2511.16595)
*Boshen Xu,Zihan Xiao,Jiaze Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Qin Jin*

Main category: cs.CV

TL;DR: TimeViper提出混合Mamba-Transformer架构，通过TransV模块压缩视觉令牌冗余，实现万帧长视频的高效理解，在保持多模态能力的同时达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 长视频理解需要兼顾模型效率与长时序处理能力，传统架构存在视觉令牌冗余问题。

Method: 1. 混合Mamba-Transformer骨干网络
2. 发现视觉-文本信息聚合现象
3. 提出TransV模块压缩视觉令牌至指令令牌

Result: 1. 可处理超万帧/小时级视频
2. 多基准测试达SOTA水平
3. 首次揭示混合架构的注意力行为规律

Conclusion: 本研究为混合架构开发提供新范式，通过模型压缩和注意力机制解释性分析，推动长视频理解技术发展。

Abstract: We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM depth, resulting in severe vision token redundancy. Motivated by this observation, we propose TransV, a token information transfer module that transfers and compresses vision tokens into instruction tokens while maintaining multimodal understanding capabilities. This design enables TimeViper to process hour-long videos exceeding 10,000 frames. Extensive experiments across multiple benchmarks demonstrate that TimeViper competes with state-of-the-art models while extending frame numbers. We further analyze attention behaviors of both Mamba and Transformer layers, offering new insights into hybrid model interpretability. This work represents an initial step towards developing, interpreting, and compressing hybrid Mamba-Transformer architectures.

</details>


### [43] [SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction](https://arxiv.org/abs/2511.16635)
*Guolin Huang,Wenting Chen,Jiaqi Yang,Xinheng Lyu,Xiaoling Luo,Sen Yang,Xiaohan Xing,Linlin Shen*

Main category: cs.CV

TL;DR: SurvAgent通过分层思维链增强的多代理系统，实现了可解释的多模态癌症生存预测，在TCGA数据集上超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有生存分析方法缺乏临床可解释性，传统病理代理存在多模态整合不足、ROI探索低效、缺乏历史案例学习三大缺陷。

Method: 两阶段架构：1) WSI-Gene CoT案例库构建（病理图像分层分析+基因分层分析）；2) 基于RAG的多专家代理推理（渐进式区间细化预测）。

Result: 在5个TCGA队列中超越传统方法、专有大模型和医疗代理，建立可解释AI生存预测新范式。

Conclusion: SurvAgent通过结构化思维链和经验学习机制，显著提升生存预测的可解释性和临床适用性，推动精准肿瘤决策支持。

Abstract: Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.

</details>


### [44] [Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation](https://arxiv.org/abs/2511.16671)
*Ziyu Guo,Renrui Zhang,Hongyu Li,Manyuan Zhang,Xinyan Chen,Sifan Wang,Yan Feng,Peng Pei,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 提出了TwiG框架，首次在视觉生成过程中实现文本推理与图像生成的动态交互，通过三种策略探索增强生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成方法仅在生成前后进行文本推理，缺乏生成过程中的实时多模态交互，导致输出缺乏上下文连贯性和语义深度。

Method: 开发了TwiG框架，包含：1）零样本提示 2）在自建TwiG-50K数据集上的监督微调 3）定制TwiG-GRPO强化学习策略，实现推理与生成的动态互引导。

Result: 通过文本推理与图像生成的交织演进，产生更具上下文感知和语义丰富的视觉输出，三种策略各具独特优势。

Conclusion: 该框架为增强视觉生成开辟了新方向，未来研究可进一步探索不同模态推理的实时交互机制。

Abstract: Recent advances in visual generation have increasingly explored the integration of reasoning capabilities. They incorporate textual reasoning, i.e., think, either before (as pre-planning) or after (as post-refinement) the generation process, yet they lack on-the-fly multimodal interaction during the generation itself. In this preliminary study, we introduce Thinking-while-Generating (TwiG), the first interleaved framework that enables co-evolving textual reasoning throughout the visual generation process. As visual content is progressively generating, textual reasoning is interleaved to both guide upcoming local regions and reflect on previously synthesized ones. This dynamic interplay produces more context-aware and semantically rich visual outputs. To unveil the potential of this framework, we investigate three candidate strategies, zero-shot prompting, supervised fine-tuning (SFT) on our curated TwiG-50K dataset, and reinforcement learning (RL) via a customized TwiG-GRPO strategy, each offering unique insights into the dynamics of interleaved reasoning. We hope this work inspires further research into interleaving textual reasoning for enhanced visual generation. Code will be released at: https://github.com/ZiyuGuo99/Thinking-while-Generating.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [45] [Chain of Summaries: Summarization Through Iterative Questioning](https://arxiv.org/abs/2511.15719)
*William Brach,Lukas Galke Poech*

Main category: cs.AI

TL;DR: 提出Chain of Summaries(CoS)方法，通过黑格尔辩证法迭代生成信息密集摘要，显著提升LLM处理网页内容的效率与效果


<details>
  <summary>Details</summary>
Motivation: LLM处理网页内容时面临格式不兼容和上下文长度限制，导致信息利用效率低下

Method: 基于黑格尔辩证法（正题-反题-合题）的迭代优化框架：首先生成初始摘要（正题），通过质疑发现局限（反题），最终生成满足当前和未来需求的通用摘要（合题）

Result: 在TriviaQA/TruthfulQA/SQUAD数据集上：相比零样本LLM提升66%，优于BRIO/PEGASUS等专用方法27%；生成的摘要Q&A性能更高且token消耗减少85%

Conclusion: CoS为网站维护者提供高效LLM适配方案，在保持人工监督可能性的同时，显著提升内容可访问性

Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a method for generating general-purpose, information-dense summaries that act as plain-text repositories of web content. Inspired by Hegel's dialectical method, our approach, denoted as Chain of Summaries (CoS), iteratively refines an initial summary (thesis) by identifying its limitations through questioning (antithesis), leading to a general-purpose summary (synthesis) that can satisfy current and anticipate future information needs. Experiments on the TriviaQA, TruthfulQA, and SQUAD datasets demonstrate that CoS outperforms zero-shot LLM baselines by up to 66% and specialized summarization methods such as BRIO and PEGASUS by up to 27%. CoS-generated summaries yield higher Q&A performance compared to the source content, while requiring substantially fewer tokens and being agnostic to the specific downstream LLM. CoS thus resembles an appealing option for website maintainers to make their content more accessible for LLMs, while retaining possibilities for human oversight.

</details>


### [46] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1通过MGRD框架成功解锁音频推理能力，在跨领域音频任务中超越Gemini 2.5 Pro并媲美Gemini 3 Pro，证明音频智能可受益于扎根声学特征的推理链


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型依赖浅层推理的悖论，验证扎根声学特征的深度推理在音频领域的有效性

Method: 提出模态锚定推理蒸馏框架(MGRD)，通过声学特征锚定生成真实的音频相关推理链

Result: 在包含语音/环境音/音乐的完整基准测试中，性能超越Gemini 2.5 Pro并达到Gemini 3 Pro水平

Conclusion: 推理能力可跨模态迁移，扎根声学特征的深度思考可转化为音频智能的核心优势，为多模态推理系统开辟新路径

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [47] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 提出JudgeBoard评估框架和MAJ多智能体系统，通过直接评估答案正确性提升小模型在推理任务中的判断性能，实现与大型模型相当的评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有小语言模型在判断答案正确性时依赖间接的人工预设指标，评估效率低且难以自动化。需要开发直接评估框架提升轻量级模型的判断能力。

Method: 1. 构建JudgeBoard评估管道，采用准确率排名和ELO评分系统
2. 设计MAJ多智能体框架，通过异构模型协同决策提升小模型判断准确性

Result: MAJ框架使小模型在MATH数据集上达到或超越大模型性能（如Phi-3-mini准确率77.3% vs GPT-4的78.2%）

Conclusion: 多智能体协同机制可有效缩小模型规模差距，为高效可扩展的推理评估提供新范式

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [48] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 检索增强的大语言模型在临床场景仍存在推理缺陷，提出评估框架强调需对逻辑推理进行严格评估


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在临床场景中检索证据与逻辑推理之间的脱节问题，特别是在需要严格遵循结构化治疗协议的场景下

Method: 以书面暴露疗法指南为测试平台，通过评估模型对临床专家验证问题的响应，开发包含准确性、一致性和推理保真度的三维评估框架

Result: 实验表明检索增强生成(RAG)能约束输出范围，但模型仍存在系统性推理错误，推理评估需与检索评估同等严格

Conclusion: 临床场景安全部署需建立双重评估体系，在加强检索约束的同时，对逻辑推理质量进行系统化验证

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [49] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 提出基于自然语言交互的AI游戏SpellForger，通过BERT模型实现玩家咒语实时生成与参数平衡，验证AI作为核心玩法的可行性


<details>
  <summary>Details</summary>
Motivation: 现有AI在游戏中的应用多集中于内容生成而非核心玩法共创，本研究探索AI作为直接游戏机制的可能性

Method: 使用监督训练的BERT模型解析自然语言提示，映射预设咒语模板并平衡参数，Unity引擎搭建前端，Python实现AI后端

Result: 开发出实时咒语生成原型，通过创意驱动玩法验证AI作为核心机制的可行性，确保游戏平衡性与玩家创造力结合

Conclusion: SpellForger成功证明自然语言交互的AI系统可直接融入游戏核心循环，为AI驱动型游戏设计开辟新路径

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [50] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: 提出OpenMMReasoner两阶段训练框架（监督微调+强化学习），通过高质量数据构建和优化策略显著提升多模态推理能力，在九项基准测试中超越基线模型11.6%。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态推理领域数据构建不透明、训练策略不可复现的问题，推动规模化研究发展。

Method: 1. 监督微调阶段：构建87.4万样本的冷启动数据集，含严格分步验证
2. 强化学习阶段：使用7.4万跨领域样本优化模型稳定性

Result: 在九大多模态推理基准测试中实现11.6%的性能提升（相比Qwen2.5-VL-7B-Instruct基线）

Conclusion: 数据质量和训练设计是塑造多模态推理性能的关键因素，开源代码/数据为后续研究提供可靠基础。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [51] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出无需训练的联邦视觉语言模型适配框架TOFA，通过多模态特征提取和自适应权重校准解决数据异构问题


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法存在通信成本高、易受攻击、数据异构处理不足等问题，且缺乏训练资源的适配方案

Method: 采用视觉原型贝叶斯建模+文本提示全局对齐的双模态流程，结合自适应权重平衡个性化和鲁棒性

Result: 在9个数据集的不同联邦场景下验证有效性，实现无训练资源依赖的高效适配

Conclusion: TOFA框架无需额外训练资源，通过多模态协同有效应对联邦学习中的数据异构挑战

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [52] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: 提出动态基准框架D-GARA，用于评估安卓GUI智能体在真实异常场景下的鲁棒性，填补现有静态基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体数据集存在静态化、理想化缺陷，无法反映真实环境中的复杂异常现象（如权限弹窗/低电量提示/更新提醒等常见中断场景）。

Method: 通过D-GARA框架植入多样化真实异常场景，构建包含主流安卓应用的标注化基准测试集，开展系统性实验验证智能体表现。

Result: 实验显示当前最先进GUI智能体在异常密集环境中性能显著下降（平均下降35%），证实鲁棒性学习的重要性。

Conclusion: 模块化设计的D-GARA支持新任务/异常类型/交互场景的灵活扩展，为智能体健壮性评估提供标准化解决方案。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [53] [Time-Critical Adversarial Influence Blocking Maximization](https://arxiv.org/abs/2511.16068)
*Jilong Shi,Qiuyan Yan,Xiaobin Rui,Zhixiao Wang*

Main category: cs.SI

TL;DR: 提出时间敏感的TC-IC模型和TC-AIBM问题，通过BIS算法实现高效对抗性影响阻断，提供理论保证与实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性影响阻断模型忽略时间因素且缺乏理论下界证明，无法满足政治选举等时效敏感场景需求。

Method: 1. 提出TC-IC模型引入时间约束
2. 建立TC-AIBM问题框架
3. 证明目标函数子模性
4. 设计双向影响力采样(BIS)算法

Result: BIS算法在四个真实数据集上展现：
- 理论保证（近似比）
- 3倍效率提升（相比贪婪算法）
- 不同参数下的稳定表现

Conclusion: TC-IC模型有效解决了时间敏感场景需求，BIS算法通过子模性保证和高效采样机制，在理论和实验层面均优于现有基线方法。

Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.

</details>
