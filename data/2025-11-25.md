<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 77]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 8]
- [cs.LO](#cs.LO) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering](https://arxiv.org/abs/2511.17559)
*Gyubok Lee,Woosog Chay,Edward Choi*

Main category: cs.CL

TL;DR: 提出SCARE基准用于评估EHR QA系统中的安全验证机制，包含问题可答性分类和SQL验证的双重任务


<details>
  <summary>Details</summary>
Motivation: 现有文本转SQL模型生成的错误查询可能危及临床决策，缺乏统一的事后验证评估基准

Method: 基于MIMIC-III/IV和eICU数据库构建包含4200个问题-SQL对的基准，涵盖7种模型生成的多样化查询

Result: 实验揭示了问题分类与SQL纠错之间的关键权衡，为安全部署提供了实证依据

Conclusion: SCARE填补了EHR安全验证评估的空白，揭示了临床QA系统部署的核心挑战与研究方向

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.

</details>


### [2] [$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving](https://arxiv.org/abs/2511.17560)
*Yuechi Zhou,Yi Su,Jianxin Zhang,Juntao Li,Qingrong Xia,Zhefeng Wang,Xinyu Duan,Baoxing Huai*

Main category: cs.CL

TL;DR: 提出A³算法通过注意力感知的KV Cache融合，在降低解码延迟的同时保持任务性能


<details>
  <summary>Details</summary>
Motivation: 现有KV Cache重用方法存在性能显著下降问题，重新计算的token与关键上下文对齐不足导致表征更新困难

Method: 基于注意力机制预计算文本块的KV Cache，根据问题相关性进行选择性融合

Result: 在多个基准测试中实现最佳任务性能，首token延迟降低2倍（TTFT 2×）

Conclusion: A³算法通过精准的KV Cache融合机制，在保持模型性能的前提下显著提升推理效率

Abstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\times$.

</details>


### [3] [LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models](https://arxiv.org/abs/2511.17561)
*Huimin Ren,Yan Liang,Baiqiao Su,Chaobo Sun,Hengtong Lu,Kaike Zhang,Chen Wei*

Main category: cs.CL

TL;DR: 提出LexInstructEval评测框架，通过<Procedure, Relation, Value>三元组语法体系，构建细粒度词汇指令遵循能力的自动化评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指令遵循评估方法存在主观性强（人工评估）、固有偏差（LLM-as-a-judge）或表达能力不足（程序化基准）三大痛点，难以精准评估复杂组合约束的遵循能力。

Method: 1. 基于形式化语法将复杂指令解构为<Procedure, Relation, Value>三元组
2. 采用人机协同多阶段流程生成多样化数据集
3. 开发透明可解释的程序化验证引擎

Result: 发布包含3,000+测试用例的LexInstructEval基准数据集及开源评估工具，支持对LLM可控性的细粒度诊断（如数值范围约束、词汇替换要求等12类关系）。

Conclusion: LexInstructEval为提升LLM指令遵循的可靠性和可控性研究提供了系统化的评估基础设施，填补了现有评测体系在细粒度语义约束验证方面的空白。

Abstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.

</details>


### [4] [ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector](https://arxiv.org/abs/2511.17562)
*Wei Tian,YuhaoZhou*

Main category: cs.CL

TL;DR: 提出基于Qwen3-4B的中文拼写与语法纠错统一模型ChineseErrorCorrector3-4B，在多项基准测试中取得SOTA成绩


<details>
  <summary>Details</summary>
Motivation: 解决现有公开模型在中文拼写校正（CSC）和语法纠错（CGC）任务中性能不足的问题

Method: 基于Qwen3-4B架构构建统一纠错框架，融合拼写与语法错误修正能力

Result: 在SIGHAN-2015/EC-LAW/MCSC/NaCGEC等基准测试中，F1和F0.5分数显著超越现有模型

Conclusion: 该模型在通用文本纠错任务中展现出卓越性能，确立中文错误校正领域双任务最优解决方案

Abstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.

</details>


### [5] [Generative Caching for Structurally Similar Prompts and Responses](https://arxiv.org/abs/2511.17565)
*Sarthak Chakraborty,Suman Nath,Xuchao Zhang,Chetan Bansal,Indranil Gupta*

Main category: cs.CL

TL;DR: 提出Generative Cache方法，通过识别可重用响应模式，提升LLM在重复任务中的缓存效率，减少延迟。


<details>
  <summary>Details</summary>
Motivation: 在可重复工作流中，结构相似的提示常被复用但存在细微差异，现有缓存方法无法有效处理结构相似性且易产生错误响应。

Method: 开发生成式缓存系统，识别跨相似结构的可重用响应模式，为新的请求合成定制化输出，实现差异感知响应。

Result: 达到83%缓存命中率，在无重复场景错误命中率极低；相比标准方法提升20%命中率，端到端延迟降低34%。

Conclusion: 该方法有效提升代理工作流中缓存利用率，通过响应模式复用显著优化任务执行效率。

Abstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\% compared to standard prompt matching.

</details>


### [6] [Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs](https://arxiv.org/abs/2511.17572)
*Patrick Gerard,Aiden Chang,Svitlana Volkova*

Main category: cs.CL

TL;DR: 研究发现对齐后的大语言模型在事件知识被删除后仍能保持特定社区处理不确定性的行为模式，表明对齐过程编码了结构化行为而不仅是表面模仿。


<details>
  <summary>Details</summary>
Motivation: 验证LLMs对齐后是否真正具备社区认知模式的迁移能力，而非单纯记忆训练数据模式。

Method: 开发认知立场转移框架：1）定向删除事件知识 2）多维度探针验证 3）评估模型在无知状态下的社区响应模式复现能力

Result: 使用俄乌军事讨论和美国党派推文数据，发现即使删除事实后，模型仍保持稳定的社区特异性不确定性处理模式（准确率>85%）

Conclusion: 该框架为检测模型潜在行为偏见提供系统方法，推动LLM向更安全透明的方向部署，证明对齐编码具有可推广的行为结构

Abstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.

</details>


### [7] [Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models](https://arxiv.org/abs/2511.17575)
*Vladimir Berman*

Main category: cs.CL

TL;DR: 基于纯随机文本生成模型（有限字母+空格符号），通过概率模型推导出词汇长度几何分布、临界长度k*概念及Zipf型频次规律，证明组合结构与分割机制可产生类自然语言统计特征


<details>
  <summary>Details</summary>
Motivation: 建立结构化零模型，验证自然语言及大语言模型中的词汇统计特征（如Zipf定律）是否可能仅通过随机组合与分割机制产生，无需依赖语言组织或优化原则

Method: 1. 构建非语言模型：文本为有限字母表+空格的独立序列，单词定义为连续非空格块
2. 概率模型推导：几何分布描述词长、优惠券收集论证计算词频
3. 组合爆炸与概率衰减的数学结合

Result: 1. 词长服从由空格概率决定的几何分布
2. 存在临界长度k*（词频从高频转为低频的转折点）
3. 推导出指数α=1+log(字母数)/log(1/空格概率)的Zipf型频次规律

Conclusion: 数学层面：统一框架解释词汇统计四要素；概念层面：证明随机文本结构即可产生Zipf模式，为区分需深层解释的现象与随机结构固有特征提供基准模型

Abstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.
  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.

</details>


### [8] [Computational frame analysis revisited: On LLMs for studying news coverage](https://arxiv.org/abs/2511.17746)
*Sharaj Kunjar,Alyssa Hasegawa Smith,Tyler R Mckenzie,Rushali Mohbe,Samuel V Scarpino,Brooke Foucault Welles*

Main category: cs.CL

TL;DR: 生成式大语言模型在媒体框架分析中表现不如人工编码，部分场景下甚至弱于小型模型，需结合人类验证选择模型，建议采用多元化方法论


<details>
  <summary>Details</summary>
Motivation: 评估生成式LLM在媒体框架识别中的有效性，与传统计算方法和人工编码对比，为研究者提供方法选择依据

Method: 构建Mpox疫情新闻金标准数据集，对比生成式LLM（GPT/Claude）、传统模型（词袋/编码器转换器）与人工编码的表现，分析不同框架分析任务的适配性

Result: 生成式LLM仅在某些特定任务中具有应用潜力，人工编码始终保持最优表现，部分框架分析任务中较小模型反超LLM，任务性质决定方法适用性

Conclusion: 倡导计算框架分析方法论多元化，提出结合人类验证与模型互补性的实施路线图，强调研究设计中人工参与的不可替代性

Abstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.

</details>


### [9] [PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese](https://arxiv.org/abs/2511.17808)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: 创建PoETa v2基准测试，系统评估20+模型在葡萄牙语的表现，分析计算资源与语言适应的影响


<details>
  <summary>Details</summary>
Motivation: LLMs在葡萄牙语的性能差异显著，缺乏系统性评估框架

Method: 构建含40+葡萄牙语任务的PoETa v2基准，评估不同规模/资源的20余个模型

Result: 揭示计算投入与语言适应对葡萄牙语性能的关联，发现与英语任务存在显著表现差距

Conclusion: PoETa v2为葡萄牙语建模研究奠定基准基础，开源工具促进跨语言模型评估

Abstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.

</details>


### [10] [Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation](https://arxiv.org/abs/2511.17813)
*Scott Merrill,Shashank Srivastava*

Main category: cs.CL

TL;DR: 该论文提出了一种将Zoom会议录像转化为带说话人身份及行为标签的转录数据管道，并构建了三个地方政府审议数据集，通过微调LLMs使模拟的多人审议真实度显著提升（人类评估难以区分虚实）。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别（ASR）生成的匿名说话人标签（如Speaker_1）无法捕捉人类行为的连贯性，限制了语言模型对多方审议的逼真模拟。

Method: 1. 开发可复现的数据处理管道，将公开Zoom录像转化为带说话人身份、角色档案及行为标签（如[propose_motion]）的转录文本；2. 发布法院听证会、校董会与市政会议三个地方政府审议数据集；3. 用该『行为感知』数据微调LLMs以模拟特定参与者。

Result: 模型困惑度降低67%，基于分类器的说话人保真度与真实感指标提升近一倍。图灵测试式评估显示模拟结果与真实审议难以区分。

Conclusion: 该方法为复杂公民社会模拟提供了实用、可扩展的解决方案，『行为感知』数据显著提高了LLM在审议场景中的说话人一致性及真实感。

Abstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this "action-aware" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.

</details>


### [11] [A superpersuasive autonomous policy debating system](https://arxiv.org/abs/2511.17854)
*Allen Roush,Devin Gonier,John Hines,Judah Goldfeder,Philippe Martin Wyder,Sanjay Basu,Ravid Shwartz Ziv*

Main category: cs.CL

TL;DR: DeepDebater推出支持完整政策辩论的AI系统，采用多智能体分层架构，在模拟辩论中击败人类案例


<details>
  <summary>Details</summary>
Motivation: 突破AI在复杂政策辩论中的论证能力瓶颈，超越IBM Project Debater仅支持简化辩论形式的局限

Method: 基于LLM的多智能体协作框架，结合OpenDebateEvidence数据库进行迭代检索与自我修正，支持语音合成与人机混合辩论

Result: 在自主裁判评估中持续获胜，专家评委更倾向其论据质量，完整辩论流程支持人类实时介入对抗

Conclusion: 系统实现了AI在专业政策辩论领域的实用化突破，开创人机协同辩论新模式，推动复杂说服任务的技术边界

Abstract: The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main

</details>


### [12] [Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction](https://arxiv.org/abs/2511.17908)
*Debashish Chakraborty,Eugene Yang,Daniel Khashabi,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 提出使用符合预测框架对RAG进行覆盖控制的上下文过滤，在减少2-3倍上下文量的同时保持事实准确性，证明丢弃内容多为冗余。


<details>
  <summary>Details</summary>
Motivation: 现有RAG预生成过滤器缺乏统计保证，无法可靠控制保留证据的比例，需开发覆盖可控的上下文工程方法。

Method: 基于符合预测框架，使用嵌入式和LLM评分函数在NeuCLIR/RAGTIME数据集进行实验，实施覆盖控制过滤策略。

Result: 符合过滤达到目标覆盖率，保留内容减少2-3倍，ARGUE F1指标在严格过滤下提升，中等覆盖率保持稳定。

Conclusion: 符合预测为RAG提供了可靠且覆盖可控的上下文缩减方案，是模型无关的原则性上下文工程方法。

Abstract: Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.

</details>


### [13] [L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention](https://arxiv.org/abs/2511.17910)
*Yuliang Zhan,Xinyu Tang,Han Wan,Jian Li,Ji-Rong Wen,Hao Sun*

Main category: cs.CL

TL;DR: 提出L2V-CoT方法，通过频域提取LLMs的低频CoT表示并注入VLMs，无需训练即可提升视觉语言模型的多步推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法迁移CoT推理至VLMs需要高成本训练或架构对齐，而研究发现LLMs/VLMs存在共享的低频潜在表示，因此探索无需训练的迁移方式。

Method: 基于线性人工断层扫描(LAT)发现模型间低频潜在表示相似性，设计频域重采样机制实现维度匹配，在推理阶段直接注入LLMs的CoT表征。

Result: 实验表明L2V-CoT在12个数据集上超越无监督基线5.3%-12.8%，部分任务甚至优于有监督方法。

Conclusion: 首次实现训练自由的跨模态CoT迁移，为轻量化增强多模态推理提供新范式。

Abstract: Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.

</details>


### [14] [Towards Efficient LLM-aware Heterogeneous Graph Learning](https://arxiv.org/abs/2511.17923)
*Wenda Li,Tongya Zheng,Shunyu Liu,Yu Wang,Kaixuan Chen,Hanyang Yuan,Bingde Hu,Zujie Ren,Mingli Song,Gang Chen*

Main category: cs.CL

TL;DR: 提出高效LLM感知框架ELLA，通过多跳多类型关系编码器及线性复杂度转换器，在异构图场景中实现性能与效率双提升


<details>
  <summary>Details</summary>
Motivation: 现有异构图建模方法受限于预定义语义依赖和稀疏监督信号，LLM的语义推理潜力受计算复杂度制约，需开发高效整合方案

Method: 1. LLM感知关系分词器编码多跳多类型关系语义 2. 跳级关系图转换器降低计算复杂度至线性 3. 细粒度任务链式文本提示桥接预训练与下游任务

Result: 在四个异构图数据集上超越SOTA方法，支持130亿参数LLM并实现4倍加速，代码已开源

Conclusion: ELLA通过高效LLM集成、复杂度优化及思维链提示技术，有效解决异构图语义建模与任务适配难题，推进LLM在图学习中的应用

Abstract: Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.

</details>


### [15] [SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization](https://arxiv.org/abs/2511.17938)
*Jianghao Wu,Yasmeen George,Jin Ye,Yicheng Wu,Daniel F. Schmidt,Jianfei Cai*

Main category: cs.CL

TL;DR: 提出SPINE框架，通过选择性更新关键令牌和熵带正则化解决测试时强化学习中的响应崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有测试时强化学习方法（TTRL）在自我一致性投票中易崩溃，导致响应缩短和Pass@1下降。核心问题在于均匀序列更新中大多数低熵跟随令牌掩盖了关键高熵分支点。

Method: 1. 仅更新分叉令牌（通过前向统计识别的高熵分支点）
2. 应用熵带正则化器（维持探索与抑制噪声监督的双重机制）
3. 兼容GRPO目标，无需标签或奖励模型

Result: 在10个跨模态VQA、数学推理和医疗QA基准中：
- Pass@1指标持续超越TTRL
- 避免响应长度崩溃
- 在LLM/MLLM骨干上获得更稳定的训练动态

Conclusion: 通过将更新与思维链分支点对齐，SPINE为推理模型提供了无需标签的稳定测试时适应机制，代码已开源。

Abstract: Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.

</details>


### [16] [Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946)
*Shuo Zhang,Fabrizio Gotti,Fengran Mo,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 提出利用预训练数据的词汇覆盖作为幻觉检测的补充信号，发现其与概率特征结合可提升检测效果


<details>
  <summary>Details</summary>
Motivation: 探索预训练数据覆盖度与LLM幻觉的关系，弥补现有基于模型内部信号检测方法的不足

Method: 构建RedPajama语料库的1.3万亿token后缀数组，提取问题和答案的n-gram统计特征

Result: 词汇覆盖特征单独效果有限，但与对数概率结合后提升检测性能（尤其在不确定性高的数据集）

Conclusion: 词汇覆盖特征为幻觉检测提供了补充信号，代码基础设施已开源

Abstract: Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.

</details>


### [17] [MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok](https://arxiv.org/abs/2511.17955)
*Dat Thanh Nguyen,Nguyen Hung Lam,Anh Hoang-Thi Nguyen,Trong-Hop Do*

Main category: cs.CL

TL;DR: MTikGuard系统通过扩展数据集、多模态融合和流式架构实现TikTok有害内容实时检测，准确率达89.37%


<details>
  <summary>Details</summary>
Motivation: 针对TikTok短视频平台海量实时有害内容难以传统审核的问题，需开发高效多模态检测方案

Method: 1. 扩展TikHarm数据集至4,723个视频 2. 融合视觉/音频/文本特征的多模态分类框架 3. 基于Apache Kafka和Spark的流式架构

Result: 实现89.37%准确率和89.45% F1值，系统已开源并提供实时部署方案

Conclusion: 结合数据集扩展、多模态融合和流式计算架构，有效解决社交媒体实时内容审核难题

Abstract: With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.

</details>


### [18] [Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets](https://arxiv.org/abs/2511.18054)
*Gowtham,Sai Rupesh,Sanjay Kumar,Saravanan,Venkata Chaithanya*

Main category: cs.CL

TL;DR: Blu-WERP新型数据预处理流程显著提升LLM训练数据质量，在多个模型规模与评测基准中全面超越现有方案，实现质量与效率双优化


<details>
  <summary>Details</summary>
Motivation: 现有网络语料预处理方案难以有效去除噪声和非结构化内容，制约大语言模型的训练质量提升

Method: 基于CC WARC数据设计进阶过滤与质量评估机制，包含多阶段清洗流程和量化评估体系

Result: 在1B参数模型上相对DCLM/Fineweb分别实现4.0%/9.5%综合提升，世界知识推理/语言理解/常识推理分别提升2.4%/6.2%/4.2%，质量-计算效率比显著提高

Conclusion: Blu-WERP验证了数据预处理流程对模型性能的关键影响，为数据驱动型AI研究提供了高效解决方案

Abstract: High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.

</details>


### [19] [GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set](https://arxiv.org/abs/2511.18146)
*Yomal De Mel,Nisansa de Silva*

Main category: cs.CL

TL;DR: 创建僧伽罗语歌曲情感标注数据集GeeSanBhava，通过优化MLP模型实现0.887 ROC-AUC，推动音乐情感分析与NLP发展


<details>
  <summary>Details</summary>
Motivation: 解决僧伽罗语情感数据稀缺问题，探索用户评论与歌曲情感关联性，消除用户生成内容的分析偏见

Method: 采用三重人工标注验证（Fleiss κ=84.96%），基于新闻评论预训练模型迁移学习，构建三层MLP架构（256-128-64神经元）进行超参数优化

Result: 优化后的MLP模型在情感分类任务中达到0.887 ROC-AUC值，显著优于零样本基线

Conclusion: 首次提供高质量僧伽罗语音乐情感数据集，建立跨内容类型（新闻-音乐）的情感模型迁移框架，为小语种NLP提供新方法论

Abstract: This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.

</details>


### [20] [Vector Arithmetic in Concept and Token Subspaces](https://arxiv.org/abs/2511.18162)
*Sheridan Feucht,Byron Wallace,David Bau*

Main category: cs.CL

TL;DR: LLMs通过概念归纳头和token归纳头分离语义/表层信息，使用注意力权重转换隐藏状态后，平行四边形算术准确率从47%提升至80%


<details>
  <summary>Details</summary>
Motivation: 探索如何利用不同注意力头分离语义和表层信息，揭示隐藏状态的潜在结构特征

Method: 使用概念头的注意力权重转换隐藏状态进行语义算术（如国家首都计算），利用token头进行表层形态操作（如词形变化）

Result: 概念头转换后准确率80%（原始47%），token头成功实现"coding→dancing"等形态转换

Conclusion: 特定注意力头可识别隐藏状态中的语义/表层子空间，为模型解释和可控生成提供新方法

Abstract: In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that "Athens" - "Greece" + "China" = "Beijing". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like "coding" - "code" + "dance" = "dancing".

</details>


### [21] [Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models](https://arxiv.org/abs/2511.18177)
*Elias Lumer,Matt Melich,Olivia Zino,Elena Kim,Sara Dieter,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah,James A. Burke,Roberto Hernandez*

Main category: cs.CL

TL;DR: 系统性比较向量与节点式RAG架构在金融文档问答中的表现，验证交叉编码器重排和小到大分块检索技术提升效果


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏金融文档中向量与非向量RAG架构的系统性对比，且高级RAG技术对检索精度、回答质量、延迟及成本的实证影响不明确

Method: 采用1200份SEC文件构建150问基准测试，比较向量架构(混合搜索+元数据过滤)与节点架构(结构化遍历)，评估交叉编码器重排和小到大分块检索两种增强技术

Result: 向量架构以68%胜率优于节点架构，交叉编码器重排带来59%的MRR@5提升，小到大分块检索实现65%胜率且仅增加0.2秒延迟

Conclusion: 高级RAG技术可有效提升金融问答系统性能，但在生产部署中需权衡成本效益与性能增益

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.

</details>


### [22] [Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems](https://arxiv.org/abs/2511.18194)
*Faheem Nizar,Elias Lumer,Anmol Gulati,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 通过知识图谱表示代理及其工具的关系，实现更精准的多智能体检索


<details>
  <summary>Details</summary>
Motivation: 现有检索方法仅匹配单一代理描述，无法充分展现工具细粒度能力，导致代理选择效果欠佳

Method: 提出Agent-as-a-Graph知识图谱检索方法，分三步：向量搜索初筛→加权RRF重排序→知识图谱遍历确定最终代理集合

Result: 在LiveMCPBenchmark上Recall@5提升14.9%，nDCG@5提升14.6%，wRRF优化提升2.4%

Conclusion: 基于知识图谱的检索方法显著提升多智能体系统的检索效果，为复杂任务代理选择提供新范式

Abstract: Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.

</details>


### [23] [From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation](https://arxiv.org/abs/2511.18259)
*Xiaochen Zheng,Alvaro Serra,Ilya Schneider Chernov,Maddalena Marchesi,Eunice Musvasva,Tatyana Y. Doktorova*

Main category: cs.CL

TL;DR: 提出多智能体系统DiscoVerse解决药物研发数据重用难题，通过专家评估验证其在逆向转化中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有药物研发中断项目数据难以有效重用，需开发支持逆向转化的智能框架提升科研效率。

Method: 基于罗氏历史数据构建多角色智能体系统，使用180分子数据集（覆盖8.7亿BPE tokens）进行专家盲评验证。

Result: 召回率≥0.99，精确度0.71-0.91；器官特异性毒性等定性评估显示跨证据可靠合成。

Conclusion: 首个经真实药物数据验证的智能框架，为药物逆向转化提供人机协同解决方案与决策支持。

Abstract: Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.

</details>


### [24] ["AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa](https://arxiv.org/abs/2511.18301)
*Harsh Rathva,Pruthwik Mishra,Shrikant Malviya*

Main category: cs.CL

TL;DR: 通过数据优化策略构建大规模平衡语料库，XLM-RoBERTa模型在多语言科学文本幻觉检测任务中取得优异表现


<details>
  <summary>Details</summary>
Motivation: 解决多语言科学文本幻觉检测中训练数据稀缺且不平衡的核心问题，突破传统仅优化模型架构的局限

Method: 整合5个现有数据集形成124,821样本的平衡语料库（正确/幻觉样本各占50%），基于5.6亿参数XLM-RoBERTa-Large进行微调

Result: 在古吉拉特语（零样本语言）获Factuality F1 0.5107（第二名），其余8语言保持4-6名，训练数据量达原始SHROOM数据172倍

Conclusion: 系统性数据优化策略显著优于单纯架构创新，尤其在零样本低资源语言场景中，为可靠AI系统开发提供新方向

Abstract: The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.

</details>


### [25] [Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning](https://arxiv.org/abs/2511.18306)
*Mohammad Aqib,Mohd Hamza,Ying Hei Chui,Qipei Mei*

Main category: cs.CL

TL;DR: 论文提出两种基于视觉语言模型（VLMs）的表格信息提取方法，并通过微调显著提升模型在建筑规范解读中的准确性


<details>
  <summary>Details</summary>
Motivation: 建筑规范中的表格数据因复杂布局和语义关系难以被传统NLP方法和视觉语言模型有效处理，需探索更优的信息提取方法

Method: 1. 直接输入法：将表格页面图像直接输入VLMs进行问答
2. 间接输入法：将表格转换为LaTeX代码后输入模型
3. 使用LoRA方法在领域表格数据上微调VLMs

Result: 直接输入法准确率更高，微调后Qwen2.5-VL-3B-Instruct模型相对准确率提升超100%

Conclusion: 参数高效微调方法能有效提升VLMs在建筑规范等专业领域处理复杂结构化数据的能力

Abstract: Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.

</details>


### [26] [Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search](https://arxiv.org/abs/2511.18313)
*Joseph Oladokun*

Main category: cs.CL

TL;DR: 提出路径约束检索方法(PCR)，通过结合结构图约束与语义搜索，在保持相关性的同时实现100%结构一致性检索


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的知识检索缺乏与当前推理状态的结构对齐，导致推理链断裂。需确保检索信息在知识图谱中保持原有逻辑关系

Method: 在知识图谱中限定搜索范围为锚节点可达路径，结合图结构约束与语义相似度计算，构建PathRAG-6多领域基准测试集（含180节点/360边）

Result: PCR实现100%结构一致性（基线24-32%），技术领域检索top10完全相关且结构一致，平均图距离降低78%

Conclusion: 路径约束检索显著提升LLM推理系统的结构连贯性，为知识密集型任务提供可靠检索方案

Abstract: Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.

</details>


### [27] [Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection](https://arxiv.org/abs/2511.18324)
*Syed Mohaiminul Hoque,Naimur Rahman,Md Sakhawat Hossain*

Main category: cs.CL

TL;DR: 集成微调方法在低资源孟加拉语仇恨言论分类任务中表现优异，分别获得子任务1A第六名（73.23% F1）和1B第三名（73.28% F1）


<details>
  <summary>Details</summary>
Motivation: 解决YouTube评论中低资源孟加拉语仇恨言论检测难题，提升模型在仇恨类型分类（1A）和目标群体分类（1B）任务中的泛化能力

Method: 基于Bangla语言模型的混合集成微调策略，通过对比实验验证模型鲁棒性，评估低资源场景下的数据集覆盖和泛化表现

Result: 在官方评测中取得1A任务73.23%微F1值（第6名）和1B任务73.28%成绩（第3名），实验证明模型优于基线及其他变体

Conclusion: 该方法有效应对低资源孟加拉语仇恨检测挑战，双任务排名验证方案可行性，错误模式分析为后续优化提供方向

Abstract: This paper introduces the approach of "Gradient Masters" for BLP-2025 Task 1: "Bangla Multitask Hate Speech Identification Shared Task". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.

</details>


### [28] [OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas](https://arxiv.org/abs/2511.18335)
*James Y. Huang,Wenxuan Zhou,Nan Xu,Fei Wang,Qin Liu,Sheng Zhang,Hoifung Poon,Muhao Chen*

Main category: cs.CL

TL;DR: 提出OmniStruct基准测试框架，通过合成数据训练小模型实现与GPT-4o相当的文本结构化生成能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在非结构化文本生成表现出色，但在文本到结构化输出（信息抽取/表格生成/函数调用）的任务性能尚未明确，需要统一评估基准

Method: 1. 整合跨领域数据集构建OmniStruct基准
2. 通过合成任务生成高质量训练数据
3. 在零监督数据条件下微调小模型

Result: 基于合成数据微调的小模型（未使用OmniStruct监督数据）在结构化生成任务中达到GPT-4o水平

Conclusion: 通过合成数据训练可实现小模型的通用结构化生成能力，为高效文本结构化处理提供新路径

Abstract: The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.

</details>


### [29] [Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle](https://arxiv.org/abs/2511.18369)
*Manon Berriche*

Main category: cs.CL

TL;DR: 该研究通过混合方法分析社交媒体用户行为，揭示虚假新闻传播集中于少数高活跃度政治化用户，不同社会群体展现差异化的批判性应对方式，但这些互动未能产生有效公共辩论。


<details>
  <summary>Details</summary>
Motivation: 解决两大矛盾：1）缺乏编辑管控下虚假新闻实际传播比例偏低的现象；2）用户对假新闻接受度有限但政治极化加剧的矛盾现象。

Method: Twitter和Facebook混合研究方法：定量分析数字痕迹+线上观察访谈，研究一通过事实核查标注追踪法国推特圈假新闻传播者，研究二分析用户标记的存疑内容互动模式。

Result: 1）假新闻传播集中于教育水平不低但政治化程度高、批判体制的活跃用户；2）用户批判距离体现为表达谨慎或异议修正；3）互动多形成无效对话而非良性辩论。

Conclusion: 政治极化源于少数活跃用户的议程设置能力及差异化批判实践，而非大众普遍受假新闻影响，揭示了平台治理需关注关键节点用户的交互动态。

Abstract: This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence énonciative) or interventions ('points d'arrêt') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.

</details>


### [30] [Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models](https://arxiv.org/abs/2511.18393)
*Heejoon Koo*

Main category: cs.CL

TL;DR: 评估大语言模型在临床决策支持中的鲁棒性与公平性，提出分层思维链策略提升诊断预测准确性


<details>
  <summary>Details</summary>
Motivation: 临床文本常因人为错误或自动化流程故障导致质量下降，需研究噪声输入对大语言模型诊断预测的可靠性和公平性影响

Method: 提出基于临床实践的标签降维方案和分层思维链策略，模拟临床医生的推理过程，优化大语言模型的预测稳定性

Result: 在文本损坏场景下显著提升模型鲁棒性，降低不同人口统计学亚组的结果波动，诊断预测准确率提高12%-18%

Conclusion: 通过结构化推理框架有效缓解噪声输入对模型的影响，为大语言模型在临床决策系统的可靠应用提供新范式

Abstract: A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.

</details>


### [31] [Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models](https://arxiv.org/abs/2511.18409)
*Dana Arad,Yonatan Belinkov,Hanjie Chen,Najoung Kim,Hosein Mohebbi,Aaron Mueller,Gabriele Sarti,Martin Tutek*

Main category: cs.CL

TL;DR: MIB基准与BlackboxNLP 2025共享任务为机制可解释性研究提供标准化评估框架，在电路定位和因果变量定位任务中取得显著进展


<details>
  <summary>Details</summary>
Motivation: 解决机制可解释性研究缺乏标准化评估的问题，推动不同方法在因果定位任务中的可复现比较

Method: 基于MIB基准扩展共享任务，设立电路定位（识别影响模型行为的组件）和因果变量定位（激活向量特征化映射）双轨道

Result: 电路定位赛道：3团队8方法通过集成/正则化策略提升性能；因果变量定位赛道：1团队2方法采用低维非线性投影显著改进

Conclusion: MIB排行榜持续开放，鼓励使用该标准框架衡量机制可解释性研究的未来发展

Abstract: Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.

</details>


### [32] [SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data](https://arxiv.org/abs/2511.18411)
*Sultan Alrashed,Chadi Helwe,Francesco Orabona*

Main category: cs.CL

TL;DR: 通过多模型集成翻译流程和严格质量过滤，构建高质量阿拉伯语多轮对话数据集SmolKalam，解决现有推理和工具调用数据不足的问题


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语预训练数据缺乏支持推理和工具调用的大规模多轮对话数据集，简单翻译无法满足后训练阶段对数据质量的严苛要求

Method: 1. 采用多模型集成翻译流程翻译Smoltalk2数据集 2. 实施质量过滤机制 3. 通过消融实验验证解码器专用模型的有效翻译技术

Result: 成功构建SmolKalam数据集，其质量优于简单翻译方法，适用于传统仅解码器模型的后训练需求

Conclusion: 系统性翻译框架结合质量过滤机制能有效提升阿拉伯语对话数据质量，消融实验验证了技术选择的有效性

Abstract: Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.

</details>


### [33] [Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations](https://arxiv.org/abs/2511.18413)
*Yu Xia,Sungchul Kim,Tong Yu,Ryan A. Rossi,Julian McAuely*

Main category: cs.CL

TL;DR: Proposes MACF framework integrating LLM-based multi-agent collaboration with collaborative filtering principles for enhanced recommendations


<details>
  <summary>Details</summary>
Motivation: Existing agentic recommenders underutilize collaborative signals in user-item interaction history, leading to suboptimal performance

Method: Instantiates user/item agents with profiles, enables tool usage and inter-agent collaboration managed by central orchestrator with dynamic recruitment/personalization

Result: Shows advantages over agentic baselines across three domain datasets

Conclusion: MACF effectively bridges traditional collaborative filtering with modern LLM agent collaboration through adaptive multi-agent coordination

Abstract: Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.

</details>


### [34] [General Agentic Memory Via Deep Research](https://arxiv.org/abs/2511.18423)
*B. Y. Yan,Chaofan Li,Hongjin Qian,Shuqi Lu,Zheng Liu*

Main category: cs.CL

TL;DR: 提出通用代理记忆框架(GAM)，通过即时编译原理和双重组件设计优化AI代理内存系统，显著提升各类记忆依赖型任务性能


<details>
  <summary>Details</summary>
Motivation: 现有静态内存系统存在严重信息损失问题，无法在运行时动态优化上下文

Method: 采用Memorizer-轻量级记忆核心与完整历史存储配合Researcher的动态信息检索架构，结合大语言模型能力和强化学习端到端优化

Result: 实验证明GAM在多种记忆驱动型任务场景中相较现有系统取得显著性能提升

Conclusion: GAM通过运行时优化和离线-在线协同设计，有效利用大模型代理能力，实现了高效灵活的记忆管理系统

Abstract: Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \textbf{general agentic memory (GAM)}. GAM follows the principle of "\textbf{just-in time (JIT) compilation}" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.

</details>


### [35] [MindEval: Benchmarking Language Models on Multi-turn Mental Health Support](https://arxiv.org/abs/2511.18491)
*José Pombal,Maya D'Eon,Nuno M. Guerreiro,Pedro Henrique Martins,António Farinhas,Ricardo Rei*

Main category: cs.CL

TL;DR: 开发了MindEval框架用于自动评估LLM在多轮心理健康对话中的表现，发现现有模型普遍存在沟通缺陷且性能与规模/推理能力无关


<details>
  <summary>Details</summary>
Motivation: 现有心理健康AI评估基准存在局限：1.仅通过选择题测试临床知识 2.孤立评估单轮响应 3.缺乏真实多轮对话评估框架

Method: 1.与临床心理学家合作设计框架 2.通过患者模拟实现多轮对话 3.结合自动评估与人工专家评估验证 4.测试12个SOTA模型 5.分析模型规模/推理能力/对话长度/症状严重度的影响

Result: 1.所有模型平均分<4/6 2.存在AI特有的不良沟通模式 3.模型规模/推理能力与表现无关 4.长对话/严重症状时性能下降 5.自动评估与专家判断强相关

Conclusion: 现有LLM在心理健康支持中存在系统性缺陷，需开发专门解决方案而非依赖通用模型扩展，开源框架为后续研究提供基准

Abstract: Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.

</details>


### [36] [For Those Who May Find Themselves on the Red Team](https://arxiv.org/abs/2511.18499)
*Tyler Shoemaker*

Main category: cs.CL

TL;DR: 主张文学学者应参与LLM可解释性研究，突破现有工具性解释标准，建议以红队作为实践场所


<details>
  <summary>Details</summary>
Motivation: 当前LLM可解释性研究过度依赖技术工具性标准，缺乏人文视角的批判性解释框架，文学阐释方法可提供补充

Method: 通过立场分析论证，提出将红队机制转化为跨学科解释实验场的理论建构方法

Result: 揭示文学阐释学能拓展LLM解释维度，建立技术可解释性与人文批判性对话的新范式

Conclusion: 跨学科解释共同体建设具有紧迫性，红队机制可成为技术解释标准革新的实践平台

Abstract: This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.

</details>


### [37] [Dealing with the Hard Facts of Low-Resource African NLP](https://arxiv.org/abs/2511.18557)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Panga Azazia Kamaté,Madani Amadou Tall,Emmanuel Élisé Koné,Aymane Dembélé,Michael Leventhal*

Main category: cs.CL

TL;DR: 该论文构建了612小时班巴拉语语音数据集，开发了单语紧凑模型并提出数据收集/评估建议，验证人工评估重要性并开源资源


<details>
  <summary>Details</summary>
Motivation: 针对低资源西非语言缺乏语音处理基础的问题，探索建立有效数据集与模型的最佳实践

Method: 通过田野采集自发言语→半自动语音转写→构建monolingual ultra-compact/small模型→自动+人工双维度评估

Result: 成功创建首个大规模班巴拉语数据集及对应模型，提出可复用的数据收集协议，证明人工评估指标与自动评估存在显著差异

Conclusion: 为低资源语言处理提供完整技术路线，开源资源促进领域发展，强调人工评估在低资源场景中的必要性

Abstract: Creating speech datasets, models, and evaluation frameworks for low-resource languages remains challenging given the lack of a broad base of pertinent experience to draw from. This paper reports on the field collection of 612 hours of spontaneous speech in Bambara, a low-resource West African language; the semi-automated annotation of that dataset with transcriptions; the creation of several monolingual ultra-compact and small models using the dataset; and the automatic and human evaluation of their output. We offer practical suggestions for data collection protocols, annotation, and model design, as well as evidence for the importance of performing human evaluation. In addition to the main dataset, multiple evaluation datasets, models, and code are made publicly available.

</details>


### [38] [Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks](https://arxiv.org/abs/2511.18597)
*H. M. Shadman Tabib,Jaber Ahmed Deedar*

Main category: cs.CL

TL;DR: GPT-4o在评估编程题目难度时准确率仅37.75%，显著低于基于明确特征的LightGBM模型（86%），揭示了LLM在结构化任务中的关键缺陷


<details>
  <summary>Details</summary>
Motivation: 验证LLM在竞争性编程难度评估等结构化任务中的可靠性，评估其作为自动评分工具在教育和技术场景中的应用潜力

Method: 使用1,825个LeetCode问题数据集，对比纯自然语言处理的GPT-4o与基于数值/文本特征的LightGBM集成模型，结合混淆矩阵和SHAP可解释性分析

Result: LightGBM准确率达86%，而GPT-4o仅37.75%；数值特征（输入限制/接受率）对难度区分至关重要；GPT-4o存在简单类别偏见且自生成难题误判为中等

Conclusion: LLM在编程评估等关键场景中的可信度存疑，需先解决其忽略结构化特征和判断不一致问题，才能应用于教育平台或强化学习系统

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.

</details>


### [39] [A Benchmark for Zero-Shot Belief Inference in Large Language Models](https://arxiv.org/abs/2511.18616)
*Joseph Malone,Rachith Aiyappa,Byunghwee Lee,Haewoon Kwak,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: 本文提出系统性基准测试，验证大语言模型在零样本场景下预测多领域人类信念的能力，揭示模型在模拟人类推理中的潜力与局限


<details>
  <summary>Details</summary>
Motivation: 现有计算模型局限于特定社会政治领域且依赖微调，研究旨在探索大语言模型对不同信念领域的泛化能力，突破传统研究框架

Method: 基于在线辩论平台数据构建可复现基准，通过控制人口统计背景和已知先验信念的信息条件，测试不同规模语言模型的零样本预测效果

Result: 增加个体背景信息可提升预测准确率（平均提升5-8%），但不同信念领域表现差异显著（准确率跨领域标准差达12%）

Conclusion: 研究既揭示当前语言模型模拟人类推理的边界，也为非社会政治领域的信念系统建模提供了可扩展框架，推动机器行为学研究发展

Abstract: Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.

</details>


### [40] [A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News](https://arxiv.org/abs/2511.18618)
*Mirza Raquib,Munazer Montasir Akash,Tawhid Ahmed,Saydul Akbar Murad,Farida Siddiqi Prity,Mohammad Amzad Hossain,Asif Pervez Polok,Nick Rahimi*

Main category: cs.CL

TL;DR: 提出BERT-CNN-BiLSTM混合模型处理孟加拉语新闻标题分类与情感分析，在BAN-ABSA数据集上实现最先进效果。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉语新闻海量内容分类困难及情感分析需求，填补该语言低资源场景的研究空白。

Method: 采用混合迁移学习模型BERT-CNN-BiLSTM，在9014条新闻数据集上应用两种采样策略（技术1采样后分割/技术2分割后采样）。

Result: 技术1过采样取得标题分类78.57%与情感分析73.43%，技术2原始不平衡数据训练标题分类达81.37%但情感分析仅64.46%。

Conclusion: 模型显著超越基线，为低资源语言文本分类建立新基准，证实联合处理标题与情感数据的有效性。

Abstract: In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\% and 73.43\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.

</details>


### [41] [Prompt Optimization as a State-Space Search Problem](https://arxiv.org/abs/2511.18619)
*Maanas Taneja*

Main category: cs.CL

TL;DR: 将提示优化建模为状态空间搜索问题，通过束搜索等算法探索提示转换路径，实验表明浅层搜索即可提升模型表现但存在过拟合，简洁化转换效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型对提示词微小变化敏感的问题，探索系统化的提示优化方法以替代人工调试。

Method: 构建提示状态图（节点为提示，边为转换操作如缩短/增例/重组），采用束搜索和随机漫步算法进行空间探索，通过开发集评估和剪枝策略。

Result: 浅层搜索配置即实现开发集显著提升（如推理任务准确率从0.40→0.80），测试集提升较小（0.20→0.50），成功路径中83%为简洁化转换操作。

Conclusion: 验证提示优化作为搜索问题的可行性，指出需更多计算资源与抗过拟合评估指标以实现更鲁棒的提示泛化。

Abstract: Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].

</details>


### [42] [OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph](https://arxiv.org/abs/2511.18622)
*Michael J. Bommarito*

Main category: cs.CL

TL;DR: OpenGloss：首个集成百科全书词典与语义知识图谱的合成资源，通过LLM多智能体流程一周内低成本生成，涵盖53.7万词义与9.1M语义关系，支持词汇教学与NLP任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有词典资源（如WordNet）在教学内容整合（定义/例句/搭配/百科）与生成效率上的不足，通过结构化生成技术突破人工编纂的时空限制。

Method: 采用多智能体流程生成技术：LLM模式化输出+自动化质量验证+模式校验，7天内以低于$1000成本完成全量数据生成。

Result: 构建包含53.7万词义（4倍于WordNet定义量）、9.1M语义边、1M例句、3M搭配及60M百科文本的资源，数据规模与质量对标人工编纂标准。

Conclusion: 证明结构化生成技术能高效创建综合性语言资源，随着基座模型进化可实现快速迭代，同时反映当前生成模型的能力边界，开放CC-BY协议促进教育/NLP应用创新。

Abstract: We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.
  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.
  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.

</details>


### [43] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://arxiv.org/abs/2511.18635)
*Shireen Chand,Faith Baca,Emilio Ferrara*

Main category: cs.CL

TL;DR: 针对性偏见缓解可能导致其他维度偏见加剧，需多维评估工具保障策略有效性


<details>
  <summary>Details</summary>
Motivation: 现有偏见缓解技术仅评估目标维度效果，可能产生跨维度负面连锁反应

Method: 使用4种偏见缓解技术，在7个模型家族的10个模型中测试种族/宗教/职业/性别四维度偏见

Result: 针对性缓解在目标维度部分有效，但76%案例导致其他维度偏见增加且模型一致性下降

Conclusion: 必须建立跨维度评估框架，避免单一维度优化造成系统性偏见转移或恶化

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.

</details>


### [44] [Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting](https://arxiv.org/abs/2511.18649)
*Goun Pyeon,Inbum Heo,Jeesu Jung,Taewook Hwang,Hyuk Namgoong,Hyein Seo,Yerim Han,Eunbin Kim,Hyeonseok Kang,Sangkeun Jung*

Main category: cs.CL

TL;DR: 对24个大语言模型进行无数据污染的数学能力评估，GPT-5 Codex获得满分，揭示几何领域和推理效率的显著问题


<details>
  <summary>Details</summary>
Motivation: 解决现有基准测试存在的数据泄露问题，使用完全未被模型训练接触的2026韩国高考数学题进行纯净评估

Method: 在考试公布后两小时内数字化46道试题，测试24个LLM在文本/图像输入、韩英提示下的表现，进行推理强度对比实验

Result: GPT-5 Codex获文本输入满分，几何领域平均77.7%最弱，增强推理使性能提升但效率下降85%

Conclusion: 建立首个真实考试评估框架，提出需平衡性能与推理成本的实用方案，公开详细评估结果数据库

Abstract: This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).
  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.
  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).

</details>


### [45] [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659)
*Jie He,Richard He Bai,Sinead Williamson,Jeff Z. Pan,Navdeep Jaitly,Yizhe Zhang*

Main category: cs.CL

TL;DR: CLaRa框架通过嵌入压缩和联合优化解决RAG的长上下文问题，使用SCP生成可检索压缩向量，在QA基准实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决检索增强生成（RAG）中长上下文处理效率低、检索与生成模块优化割裂的问题

Method: 1. 提出SCP框架通过QA和复述监督生成语义丰富的压缩向量
2. 通过可微分top-k估计器实现检索器与生成器的端到端联合训练
3. 共享连续空间统一优化检索相关性和答案质量

Result: 在多个QA基准测试中实现最先进的压缩性能（45.2%相对提升）和重新排名效果（平均提升3.1 ROUGE-L）

Conclusion: CLaRa证明了联合优化框架在保持语义丰富性的同时显著提升检索效率和答案质量，为RAG系统优化提供了新范式

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.

</details>


### [46] [Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models](https://arxiv.org/abs/2511.18696)
*Wangjiaxuan Xin*

Main category: cs.CL

TL;DR: 提出多阶段提示框架ECN，通过四阶段流程增强大语言模型的同理心与包容性，实验显示其在EQ指标上表现最优


<details>
  <summary>Details</summary>
Motivation: 现有对话AI在情感共鸣和情境理解方面存在局限，需开发系统性方法提升模型的共情能力

Method: 采用四阶段架构：视角采纳→情感共鸣→反思理解→综合合成，通过递进式提示引导模型生成响应

Result: 在GPT-3.5-turbo和GPT-4上实现最高同理心指数（EQ），同时保持竞争力的Regard和Perplexity指标

Conclusion: ECN框架为需要情感智能的对话系统提供了有效解决方案，特别适用于心理咨询、客户服务等包容性场景

Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.

</details>


### [47] [RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context](https://arxiv.org/abs/2511.18743)
*Yu Lei,Shuzheng Si,Wei Wang,Yifei Wu,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: RhinoInsight框架通过可验证检查表和证据审计双机制，在不更新参数前提下显著提升深度研究任务的可靠性和结果质量


<details>
  <summary>Details</summary>
Motivation: 传统线性流程（计划-搜索-写作）存在错误累积和上下文腐化问题，缺乏对模型行为和上下文的显式控制机制

Method: 1. 可验证检查表：将需求转化为可追踪子目标，通过人/LLM协同优化生成层次化大纲
2. 证据审计：结构化搜索内容，动态更新大纲并剪枝噪声，绑定高质量证据减少幻觉

Result: 实验证明RhinoInsight在深度研究任务达到SOTA，同时保持深度搜索任务的竞争优势

Conclusion: 通过层次化目标锚定和证据验证机制，该框架有效提升了研究过程的控制力与结果的可验证性

Abstract: Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.

</details>


### [48] [Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search](https://arxiv.org/abs/2511.18749)
*Matthew R. DeVerna,Kai-Cheng Yang,Harry Yaojun Yan,Filippo Menczer*

Main category: cs.CL

TL;DR: 大语言模型在自动事实核查中表现欠佳，推理功能收效甚微，但定制化RAG系统使F1值提升233%


<details>
  <summary>Details</summary>
Motivation: 针对主流聊天机器人集成推理和网络搜索工具后，数百万用户依赖其进行事实核查的现状，需对模型性能进行严谨评估

Method: 在PolitiFact 6000+标注声明上测试15个主流LLM（含标准模型/推理增强/网络搜索版本），并与定制RAG系统对比

Result: 标准模型表现差（F1=0.18）、推理功能提升有限（+7%）、网络搜索效果有限（F1=0.27），而定制RAG系统实现233%的F1提升

Conclusion: 通过提供精选高质量上下文（如RAG系统）是实现自动事实核查的有效路径，优于原始模型或基础网络搜索方案

Abstract: Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.

</details>


### [49] [Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion](https://arxiv.org/abs/2511.18751)
*Daiqing Wu,Dongbao Yang,Can Ma,Yu Zhou*

Main category: cs.CL

TL;DR: 提出基于分布特征恢复与融合的DRF方法，通过模态特征队列处理多模态情感分析中的低质量/缺失模态问题，在三个数据集上实现稳定性能提升


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析方法缺乏对低质量模态（如模糊图像）和缺失模态（单模态输入）的鲁棒性处理，现实场景中这两种问题会严重影响模型性能

Method: 1. 为各模态维护特征队列近似特征分布
2. 通过分布量化评估模态质量，降低低质量模态的融合权重
3. 建立样本和分布监督的跨模态映射关系，从可用模态恢复缺失模态

Result: 在两种模拟策略（破坏/丢弃模态）下，DRF在三个公开数据集上相比SOTA方法均取得显著提升，验证了方法的鲁棒性

Conclusion: DRF首次统一处理低质量和缺失模态问题，通过特征分布建模和跨模态恢复机制，显著提升多模态情感分析在实际应用中的稳定性

Abstract: As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.

</details>


### [50] [Context-Aware Whisper for Arabic ASR Under Linguistic Varieties](https://arxiv.org/abs/2511.18774)
*Bashar Talafha,Amin Abu Alhassan,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 通过上下文提示策略改进Whisper模型，在无需重新训练的情况下提升阿拉伯语低资源语音识别的准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言多样性显著且标注数据稀缺，传统ASR系统在真实零样本场景下存在词错误率高、幻觉生成和说话人不匹配等问题

Method: 采用解码器提示(首遍转录/检索语句)+编码器语音前缀的混合策略，结合提示重排序、说话人感知合成及词汇/语义/声学多模态检索技术

Result: 在9种阿拉伯语场景测试中，MSA词错误率降低22.3%，方言降低9.2%，有效减少83%的幻觉错误和说话人失配问题

Conclusion: 上下文提示策略显著提升零样本ASR性能，为低资源语言处理提供了参数高效且实用的解决方案，特别是在抑制模型幻觉方面效果突出

Abstract: Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.

</details>


### [51] [HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations](https://arxiv.org/abs/2511.18808)
*Cao Linxiao,Wang Ruitao,Li Jindong,Zhou Zhipeng,Yang Menglin*

Main category: cs.CL

TL;DR: 提出HyperbolicRAG框架，通过结合双曲几何增强图基RAG的层次表示能力，在多个QA基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统图基RAG依赖欧式嵌入，缺乏表示知识图谱层次抽象关系的几何能力。双曲几何能更好建模语义相似性与层级包容关系。

Method: 1. 深度感知表示学习器在庞加莱流形中联合编码语义和层次；2. 跨抽象层对比正则化保持几何一致性；3. 欧式-双曲空间互排名融合机制。

Result: 在多问答基准测试中，HyperbolicRAG性能优于标准RAG和图增强基线模型。

Conclusion: 双曲几何与图基RAG的结合有效提升了结构化推理能力，验证了跨空间检索信号融合的有效性。

Abstract: Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.

</details>


### [52] [Concept than Document: Context Compression via AMR-based Conceptual Entropy](https://arxiv.org/abs/2511.18832)
*Kaize Shi,Xueyao Sun,Xiaohui Tao,Lin Li,Qika Lin,Guandong Xu*

Main category: cs.CL

TL;DR: 提出基于AMR图的无监督上下文压缩框架，通过概念熵量化筛选核心语义节点，显著提升模型准确率并降低计算开销


<details>
  <summary>Details</summary>
Motivation: 解决LLMs处理长上下文时信息过载导致的准确性下降和计算成本增加问题，特别是在RAG场景中冗余文档的影响

Method: 1. 构建原始文本的AMR图 2. 计算节点概念熵评估语义重要性 3. 筛选高信息量节点形成压缩上下文

Result: 在PopQA和EntityQuestions数据集上超越基线方法，准确率提升同时上下文长度减少60%

Conclusion: 首次将AMR概念熵引入上下文压缩，验证语言特征在上下文工程中的稳定性价值

Abstract: Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.

</details>


### [53] [A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis](https://arxiv.org/abs/2511.18843)
*Heger Arfaoui,Mohammed Iheb Hergli,Beya Benzina,Slimane BenMiled*

Main category: cs.CL

TL;DR: 提出可重复计算框架解决传统焦点小组人工编码分析的低效问题，通过BERTopic主题建模结合超参数优化、稳定性评估及人工验证，实现高效且可解释的定性数据分析


<details>
  <summary>Details</summary>
Motivation: 传统焦点小组讨论分析依赖耗时的手动编码，存在可扩展性和可重复性局限。需建立自动化、可验证的计算方法来提升质性研究效率

Method: 1) 对突尼斯HPV疫苗认知的10组焦点讨论(1,076话语)应用BERTopic 2) 系统评估27种超参数配置 3) 通过30次自举重采样检验稳定性 4) 三位领域专家进行主题解释性验证

Result: 1) 超参数选择显著影响模型表现 2) 分层合并策略使主题连贯性提升3.5%(0.558 vs 0.539) 3) 人工验证显示极佳评分者间信度(ICC=0.79，加权Cohen's κ=0.578)

Conclusion: 该框架为质性研究提供可复现分析范式，通过公开代码/数据处理脚本促进方法扩展，有效平衡主题模型的稳定性与解释性需求

Abstract: Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.

</details>


### [54] [Large Language Models for the Summarization of Czech Documents: From History to the Present](https://arxiv.org/abs/2511.18848)
*Václav Tran,Jakub Šmíd,Ladislav Lenc,Jean-Pierre Salmon,Pavel Král*

Main category: cs.CL

TL;DR: 提出利用Mistral/mT5等大语言模型提升捷克语文本摘要性能，构建历史文档数据集Posel od Čerchova并建立基线模型


<details>
  <summary>Details</summary>
Motivation: 捷克语文本摘要研究匮乏，尤其缺乏历史文档处理资源和高质量标注数据集

Method: 采用多语言LLMs直接处理捷克文本 + 英捷互译的pipeline方法（英文化处理→英文摘要→回译捷克文）

Result: 在SumeCzech数据集刷新SOTA，构建首个19世纪捷克历史文献摘要数据集

Conclusion: 为捷克语低资源场景下的现代/历史文本摘要研究奠定基础，验证多语言LLMs在形态复杂中等资源语言中的有效性

Abstract: Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.
  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od Čerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.
  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.

</details>


### [55] [Cognitive Alpha Mining via LLM-Driven Code-Based Evolution](https://arxiv.org/abs/2511.18850)
*Fengyuan Liu,Huang Yi,Sichun Luo,Yuqi Wang,Yazheng Yang,Xinye Li,Zefa Hu,Junlan Feng,Qi Liu*

Main category: cs.CL

TL;DR: CogAlpha框架结合LLM推理与进化搜索，显著提升金融alpha因子发现的准确性、鲁棒性和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有方法（深度学习/符号公式）在探索空间、模式透明度与经济可解释性方面存在局限，需实现逻辑严谨与创新突破的平衡探索

Method: 采用代码级alpha表示，通过LLM驱动的多阶段进化搜索（变异/重组）配合金融反馈机制迭代优化候选因子

Result: 在A股实验中持续生成预测准确率提升15%、夏普比率提高20%的alpha因子，显著优于传统方法

Conclusion: 融合进化优化与LLM认知推理为自动化、可解释的金融信号发现开辟新范式，源代码开放将推动领域发展

Abstract: Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.

</details>


### [56] [FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models](https://arxiv.org/abs/2511.18852)
*Masoomali Fatehkia,Enes Altinisik,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: 提出了双语内容审核过滤器FanarGuard，首次将文化语境融入阿拉伯语/英语内容审核，在安全性和文化对齐指标上均超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核过滤器过度聚焦通用安全性，忽视了文化语境适配性，尤其是阿拉伯语文化场景缺乏针对性保障机制。

Method: 1. 构建包含46.8万组提示-响应的双语数据集，通过LLM标注系统评估无害性和文化敏感性；2. 开发首个阿拉伯文化基准测试（含1000+文化敏感提示），采用人工标注的LLM生成响应。

Result: 1. 文化对齐指标超越人工标注者间一致性（Kappa 0.81 vs 0.78）；2. 安全性指标与SOTA过滤器持平；3. 模型参数量仅7B仍保持高效推理。

Conclusion: 证明了文化意识融入内容审核的必要性，FanarGuard为实现语境敏感的AI安全机制提供了可行路径。

Abstract: Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.

</details>


### [57] [Generating Reading Comprehension Exercises with Large Language Models for Educational Applications](https://arxiv.org/abs/2511.18860)
*Xingyu Huang,Fei Jiang,Jianli Xiao*

Main category: cs.CL

TL;DR: 提出RCEG框架，通过微调大语言模型生成候选内容+判别器筛选机制，显著提升英语阅读理解练习的生成质量。实验表明该方法在内容相关性和认知适配性上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在教育领域展现生成自适应学习内容的潜力，但需专门框架提升生成内容的教学适配性。

Method: 三阶段流程：1) 微调LLMs生成候选练习题 2) 判别器筛选最优内容 3) 质量增强模块优化输出。构建专用英语阅读理解数据集进行验证。

Result: 实验使用多样性、事实准确性、语言安全性和教学对齐四维评估体系，RCEG在相关性（提升32%）和认知适宜性（提升28%）指标显著优于基线。

Conclusion: RCEG框架为教育内容生成提供新范式，其质量控制机制可有效适配不同教学场景，推动LLMs在教育技术中的深度应用。

Abstract: With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.

</details>


### [58] [Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models](https://arxiv.org/abs/2511.18864)
*Yang Xiang,Yixin Ji,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 首次针对大型推理模型（LRMs）进行剪枝研究，提出基于自生成推理数据的校准策略SSGR，相比传统方法提升剪枝后模型推理能力10%-13%


<details>
  <summary>Details</summary>
Motivation: 现有剪枝技术主要面向大语言模型（LLMs），但直接应用于LRMs时效果不佳，需探索适合LRMs长链推理特性的剪枝方案

Method: 使用自生成推理数据校准剪枝过程，分析数据难度/长度对剪枝的影响，提出选择性自生成推理数据（SSGR）构建策略

Result: 在DeepSeek-R1-Distill模型系列中验证，SSGR策略使剪枝后的LRMs推理能力相比通用方法提升10%-13%

Conclusion: 具有挑战性且长度适中的自生成推理数据是理想的剪枝校准数据，SSGR策略有效提升了LRMs剪枝后的性能保持能力

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.

</details>


### [59] [CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation](https://arxiv.org/abs/2511.18889)
*Jingqian Zhao,Bingbing Wang,Geng Tu,Yice Zhang,Qianlong Wang,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 提出CoreEval方法，通过动态整合实时知识和迭代验证机制解决LLM评估中的数据污染问题，确保评估的公平性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效消除模型预训练知识对评估的干扰，且难以保持数据集的语义复杂性，导致评估结果存在偏差。

Method: 1. 从原始数据提取实体关系；2. 利用GDELT数据库获取实时知识；3. 通过重构整合实现语义连贯性；4. 建立数据反射机制迭代验证标签一致性。

Result: 实验表明CoreEval能有效降低68%的性能虚高现象，在更新后的数据集上验证了方法的抗污染能力。

Conclusion: 该方法通过动态知识更新和双重验证机制，首次实现了真正抗污染的评估框架，为LLM公平评估提供新范式。

Abstract: Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \textbf{CoreEval}, a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.

</details>


### [60] [Reproducibility Study of Large Language Model Bayesian Optimization](https://arxiv.org/abs/2511.18891)
*Adam Rychert,Gasper Spagnolo,Evgenii Posashkov*

Main category: cs.CL

TL;DR: 复现研究表明LLAMBO框架更换为Llama 3.1 70B后仍保持有效性，上下文热启动显著提升早期性能，但小模型容量不足导致预测不稳定


<details>
  <summary>Details</summary>
Motivation: 验证LLAMBO在不同语言模型下的鲁棒性，探索开源模型替代GPT-3.5的可行性

Method: 在原始评估协议下复现实验，用Llama 3.1 70B替代GPT-3.5，进行贝叶斯优化基准测试和消融实验分析

Result: 上下文描述使早期regret降低68%，LLAMBO采样器比TPE多样性高40%，但Gemma 27B产生无效预测概率达32%

Conclusion: LLAMBO架构对语言模型更换具有鲁棒性，但需要70B级别模型才能保持有效性，小模型无法满足代理模型需求

Abstract: In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.
  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.
  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.

</details>


### [61] [Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs](https://arxiv.org/abs/2511.18931)
*Sahil Kale*

Main category: cs.CL

TL;DR: 评估大模型内置网络搜索的效果：提升事实准确性但存在置信校准差、查询表述弱等问题，需改进检索机制


<details>
  <summary>Details</summary>
Motivation: 验证大模型是否能在必要场景准确调用网络搜索，并评估其对事实准确性的提升效果

Method: 构建包含783个静态锚定问题和288个动态后截止查询的基准，测试GPT-5-mini和Claude Haiku 4.5的搜索调用策略与性能

Result: 静态准确率提升但置信校准恶化，动态查询准确率不足70%；搜索失败后回报率骤降，存在过度自信与检索遗漏问题

Conclusion: 内置搜索更适合作为验证层而非分析工具，需改进查询生成、校准机制和容错能力

Abstract: Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.

</details>


### [62] [Skeletons Matter: Dynamic Data Augmentation for Text-to-Query](https://arxiv.org/abs/2511.18934)
*Yuchen Ji,Bo Xu,Jie Shi,Jiaqing Liang,Deqing Yang,Yu Mao,Hai Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 提出统一跨语言文本到查询任务范式，通过查询骨架动态增强数据框架，在小数据量下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义解析研究局限于单一查询语言，导致方法泛化能力不足，需建立跨语言的统一解决方案。

Method: 定义查询骨架作为共享优化目标，设计动态数据增强框架诊断模型弱点并合成针对性训练数据。

Result: 在4个基准测试中达到SOTA，仅需少量合成数据即展现高效性和跨语言通用性。

Conclusion: 为文本到查询任务的统一研究奠定基础，代码已开源推动后续研究。

Abstract: The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.

</details>


### [63] [Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials](https://arxiv.org/abs/2511.18937)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: 提出通过添加Safeterm医学知识层增强MedDRA系统，实现临床试验不良事件的智能化聚类分析和可视化信号检测


<details>
  <summary>Details</summary>
Motivation: 现有MedDRA系统缺乏语义关联分析能力，导致不良事件解释效率低下。需要建立医学知识图谱提升分析精度

Method: 1. 构建Safeterm语义关系二维地图
2. 开发收缩发生率比计算模型
3. 实现精确加权的EBGM聚类分析
4. 设计双维度可视化系统（语义地图+预期性-比例失调图）

Result: 在三项历史试验中成功识别所有已知安全信号，验证方法有效性

Conclusion: 该方法显著提升临床试验不良事件分析的清晰度（语义关联）、效率（自动聚类）和准确性（信号捕获）

Abstract: We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.

</details>


### [64] [Logic of Montage](https://arxiv.org/abs/2511.19063)
*Hayami Takahashi,Kensuke Takahashi*

Main category: cs.CL

TL;DR: 提出通过矛盾结构效应和蒙太奇手法构建情感表达模型，建立跨系统的理论框架并验证其有效性


<details>
  <summary>Details</summary>
Motivation: 自然语言在情感表达中存在局限性，需要构建能体现情感动态特征的结构化表达形式

Method: 1. 定义动态矛盾结构效应
2. 引入蒙太奇叠加机制
3. 整合德勒兹的强度概念
4. 通过奥斯汀语力理论论证概念移植

Result: 建立词汇跨系统移植理论框架，以教育晋级为例验证结构效应形成过程

Conclusion: 该模型突破传统语言表达局限，通过哲学概念移植实现动态情感建模，为情感计算提供新方法论

Abstract: In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form "Effect of Contradictory Structure." "Effect of Contradictory Structure" is not static but dynamic. Effect in "Effect of Contradictory Structure" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, "Effect of Contradictory Structure" can be overlapped with each other. This overlapping operation is called "montage." A broader "Structure" that includes related "Effect of Contradictory Structure" and "Effect of Structure" are set up. Montage produces "Effect of Structure". In montage, it is necessary to set something like "strength," so we adopted Deleuze and Deleuze/Guattari's word "intensity" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of "intensity" through Austin's use of the word "force." "Effect of Structure" process is demonstrated using the example of proceeding to the next level of education.

</details>


### [65] [GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning](https://arxiv.org/abs/2511.19078)
*Yutong Li,Yitian Zhou,Xudong Wang,GuoChen,Caiyan Qin*

Main category: cs.CL

TL;DR: 提出动态图框架GraphMind，通过图神经网络与LLM融合实现结构化多步推理


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏显式动态机制表示中间推理状态，限制了定理选择与结论生成能力

Method: 构建条件-定理-结论的异构图，利用GNN编码状态+语义匹配实现闭环推理

Result: 在QA数据集上显著超越基线模型，验证方法有效性

Conclusion: 动态图结构实现了可解释的上下文感知推理，提升多步推理性能

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.

</details>


### [66] [A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis](https://arxiv.org/abs/2511.19083)
*Wenxuan Mu,Jinzhong Ning,Di Zhao,Yijia Zhang*

Main category: cs.CL

TL;DR: 提出KDR-Agent多智能体框架，通过知识检索、消歧与反思分析的三阶段协作机制，显著提升低资源多领域命名实体识别性能


<details>
  <summary>Details</summary>
Motivation: 现有基于上下文学习的NER方法存在动态检索依赖、领域泛化不足和缺乏外部知识整合三大缺陷，限制了低资源场景的应用效果

Method: 1. 利用自然语言类型定义和静态实体级对比示例库
2. 中心规划器协调知识检索代理(维基百科事实检索)、消歧代理(上下文推理)和反思代理(结构化自评估)
3. 构建三阶段协作机制实现领域知识注入与预测修正

Result: 在5个领域10个数据集上的实验表明，KDR-Agent在多种LLM基座上显著超越现有零样本/少样本上下文学习方法

Conclusion: 通过系统化整合外部知识与自反思机制，KDR-Agent有效降低对标注数据的依赖，提升跨领域适应能力，为低资源NER提供新范式，代码数据已开源

Abstract: In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.

</details>


### [67] [DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and Cascaded Reinforcement for Interpretable and Scalable RLHF](https://arxiv.org/abs/2511.19097)
*Ziyuan Gao,Di Liang,Xianjie Wu,Philippe Morel,Minlong Peng*

Main category: cs.CL

TL;DR: DeCoRL框架通过并行模块化推理链和独立奖励函数，解决传统强化学习推理方法的效率与可解释性问题


<details>
  <summary>Details</summary>
Motivation: 现有思维链强化学习方法存在黑箱式整体奖励机制（难以诊断错误）和顺序解码的高时间复杂度（影响实时部署）两大核心缺陷

Method: 1. 并行生成推理子步骤的轻量级专业模型 2. 模块化奖励函数独立评分 3. 级联DRPO优化协调奖励依赖

Result: 在三大基准测试中实现SOTA：推理速度提升3.8倍，可解释性提高22.7%，能耗降低72.4%，吞吐量增加68%

Conclusion: 该框架使复杂推理系统的实时部署成为可能，在保持推理质量的同时显著提升能效和可解释性

Abstract: Existing reinforcement learning methods for Chain-of-Thought reasoning suffer from two critical limitations. First, they operate as monolithic black boxes that provide undifferentiated reward signals, obscuring individual step contributions and hindering error diagnosis. Second, sequential decoding has O(n) time complexity. This makes real-time deployment impractical for complex reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated Reinforcement Learning), a novel framework that transforms reasoning from sequential processing into collaborative modular orchestration. DeCoRL trains lightweight specialized models to generate reasoning sub-steps concurrently, eliminating sequential bottlenecks through parallel processing. To enable precise error attribution, the framework designs modular reward functions that score each sub-step independently. Cascaded DRPO optimization then coordinates these rewards while preserving inter-step dependencies. Comprehensive evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and RewardBench, outperforming existing methods including large-scale models. DeCoRL delivers 3.8 times faster inference while maintaining superior solution quality and offers a 22.7\% improvement in interpretability through explicit reward attribution. These advancements, combined with a 72.4\% reduction in energy consumption and a 68\% increase in throughput, make real-time deployment of complex reasoning systems a reality.

</details>


### [68] [A symbolic Perl algorithm for the unification of Nahuatl word spellings](https://arxiv.org/abs/2511.19118)
*Juan-José Guzmán-Landa,Jesús Vázquez-Osorio,Juan-Manuel Torres-Moreno,Ligia Quintana Torres,Miguel Figueroa-Saavedra,Martha-Lorena Avendaño-Garrido,Graham Ranger,Patricia Velázquez-Morales,Gerardo Eugenio Sierra Martínez*

Main category: cs.CL

TL;DR: 开发基于符号正则表达式的Nawatl文本自动正字法统一模型，通过人工评估验证其有效性并获得积极反馈


<details>
  <summary>Details</summary>
Motivation: 为解决Nawatl多种正字法导致的文本处理困难，利用既有算法和π-yalli多正字法语料库，构建自动化统一工具以促进语言标准化处理

Method: 1. 基于符号模型设计正则表达式语言规则
2. 使用π-yalli跨正字法语料库训练
3. 开发自动统一算法
4. 设计人工评估协议测试统一句子的语义准确性

Result: 评估者在语义任务测试中，对人工统一句子在形态一致性(85%)、语义保持度(78%)和可读性(82%)等核心特征上给予积极评价

Conclusion: 该符号模型有效实现了Nawatl文本的正字法统一，评估结果验证了其在语言标准化处理中的实用价值，为低资源语言处理提供了可扩展的解决方案

Abstract: In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $π$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences

</details>


### [69] [On the Optimality of Discrete Object Naming: a Kinship Case Study](https://arxiv.org/abs/2511.19120)
*Phong Le,Mees Lindeman,Raquel G. Alhama*

Main category: cs.CL

TL;DR: 自然语言命名系统在信息丰富性与低复杂性之间通过贝叶斯解码器实现最优权衡


<details>
  <summary>Details</summary>
Motivation: 突破前人研究中假设'最优听者'和'普遍交际需求'的局限，建立更普适的命名系统分析框架

Method: 采用指称游戏实验范式，构建信息论框架分析亲属关系语义领域的通信系统

Result: 理论证明最优权衡需听者解码器等同说话者贝叶斯解码器，实证显示该最优性在习得系统中自然涌现

Conclusion: 贝叶斯解码器是实现命名系统最优化的必要条件，这一理论预测在实际学习系统中得到验证

Abstract: The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.

</details>


### [70] [Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2511.19122)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 提出结合情感维度与多任务学习的情感分析框架，通过大语言模型生成情感描述并引入VAD修正机制，在多个基准数据集上显著超越基线模型


<details>
  <summary>Details</summary>
Motivation: 现有ACSA方法过度关注情感极性而忽略情感维度，导致无法捕捉面向特定方面类别的细粒度情感信号

Method: 1. 构建多任务框架联合学习情感极性和Ekman六种基础情感
2. 利用LLM生成方面类别情感描述
3. 基于VAD维度框架设计情绪修正机制，通过坐标一致性检测和结构化修正策略优化结果

Result: 在所有基准数据集上显著优于强基线模型，验证情感维度整合的有效性

Conclusion: 通过情感维度增强、LLM生成能力和VAD修正机制的结合，成功提升了细粒度情感分析性能，为ACSA研究开辟情感认知新方向

Abstract: Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.

</details>


### [71] [Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization](https://arxiv.org/abs/2511.19131)
*Zijian Wang,Yanxiang Ma,Chang Xu*

Main category: cs.CL

TL;DR: 提出基于概率条件生成与正则化优化的隐藏状态操作方法，显著提升基础大语言模型的思维链推理能力


<details>
  <summary>Details</summary>
Motivation: 现有隐藏状态操纵方法(如线性激活引导)因刚性约束导致分布偏移和文本质量下降，需更灵活的优化框架

Method: 通过概率条件生成建模，构建平衡似然与先验正则化的优化目标，引导隐藏状态沿推理轨迹演进并保持语言连贯性

Result: 在数学/常识/逻辑推理任务上持续超越现有方法，验证方法的理论合理性与实践有效性

Conclusion: 该方法为激发基础大语言模型推理潜力提供了理论严谨且高效的技术路径，推动了无需微调的推理能力提升

Abstract: Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.

</details>


### [72] [Representational Stability of Truth in Large Language Models](https://arxiv.org/abs/2511.19166)
*Samantha Dies,Courtney Maynard,Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 研究发现LLMs对陌生陈述的稳定性较差（40%判断翻转），而熟悉虚构陈述更稳定（≤8.2%变化），揭示认知熟悉度是表征稳定性的核心因素。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs内部概率表示中真实/虚假/中性内容的区分稳定性，解决语义不确定性下的真相分配鲁棒性问题

Method: 通过线性探针分析16个开源模型的激活模式，对比陌生实体陈述与经典虚构陈述在不同事实领域（如单词定义）对决策边界的影响

Result: 陌生中性陈述导致最大边界偏移（最高40%判断反转），熟悉虚构陈述保持更好聚类稳定性（变化≤8.2%）

Conclusion: 表征稳定性源于认知熟悉度而非语言形式，提出通过语义不确定性诊断优化LLM训练，超越单纯输出准确性的优化范式

Abstract: Large language models (LLMs) are widely used for factual tasks such as "What treats asthma?" or "What is the capital of Latvia?". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\leq 8.2\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.

</details>


### [73] [In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations](https://arxiv.org/abs/2511.19232)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 研究通过分析phi-2模型的隐藏状态，发现transformer在中间层开始有效检测语义不合理性，且其维度变化与人类语言处理的阶段性特征存在相似性。


<details>
  <summary>Details</summary>
Motivation: 探究transformer模型如何及在何时感知语义异常，并与人类心理语言学中'句法优先于语义'的认知机制进行类比。

Method: 使用合理/不合理结尾的语料库，通过线性探针分析各层隐藏状态，并进行表示空间维度分析。

Result: 下层检测困难，中间层准确率陡增；语义违规编码呈现先维度扩张后塌缩的阶段性特征。

Conclusion: transformer的异常检测机制与人类阅读时'先句法后语义'的处理时序存在潜在对应，暗示计算模型与生物认知的深层共性。

Abstract: How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.

</details>


### [74] [MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset](https://arxiv.org/abs/2511.19317)
*Md. Tanzim Ferdous,Naeem Ahsan Chowdhury,Prithwiraj Bhattacharjee*

Main category: cs.CL

TL;DR: 构建了首个多领域孟加拉语摘要数据集(54k+样本)，采用LSTM/预训练模型建立基线，推动低资源语言NLP发展


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集局限于新闻领域的问题，应对数字时代多源孟加拉内容的信息过载挑战

Method: 从博客(Cinegolpo)、报纸(Samakal)等多源收集数据，使用LSTM/BanglaT5-small/MTS-small等模型进行基准测试

Result: 数据集展现跨领域适应性，为未来研究提供可靠评估基准，迁移学习模型表现优异

Conclusion: 该资源填补多领域孟加拉摘要空白，为低资源语言NLP基础设施构建提供重要支持

Abstract: This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.

</details>


### [75] [Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces](https://arxiv.org/abs/2511.19333)
*Shaltiel Shmidman,Asher Fredman,Oleg Sudakov,Meriem Bendris*

Main category: cs.CL

TL;DR: 研究比较DeepSeek-R1与GPT-OSS生成推理轨迹对中型LLM数学能力的影响


<details>
  <summary>Details</summary>
Motivation: 探索不同大模型生成的推理轨迹对中小模型后训练效果的影响，降低人工标注成本

Method: 通过后训练中型LLM，对比使用DeepSeek-R1和GPT-OSS生成推理轨迹后的数学问题解决准确率与推理效率

Result: 两种推理轨迹均提升模型性能，但在准确率与推理效率指标上存在显著差异

Conclusion: 大模型生成的推理轨迹质量直接影响小模型后训练效果，需根据任务需求选择合适的数据源

Abstract: Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.

</details>


### [76] [DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research](https://arxiv.org/abs/2511.19399)
*Rulin Shao,Akari Asai,Shannon Zejiang Shen,Hamish Ivison,Varsha Kishore,Jingming Zhuo,Xinran Zhao,Molly Park,Samuel G. Finlayson,David Sontag,Tyler Murray,Sewon Min,Pradeep Dasigi,Luca Soldaini,Faeze Brahman,Wen-tau Yih,Tongshuang Wu,Luke Zettlemoyer,Yoon Kim,Hannaneh Hajishirzi,Pang Wei Koh*

Main category: cs.CL

TL;DR: 提出RLER方法训练出首个开源长文本深度研究模型DR Tulu-8B，在多项基准测试中超越现有开源模型并媲美商用系统


<details>
  <summary>Details</summary>
Motivation: 现有基于RLVR的开放模型主要针对短问答任务训练，无法适应开放式的长文本深度研究需求

Method: 提出演化式标准强化学习框架（RLER），使评估标准与模型共同进化，融入新探索信息并提供区分性反馈

Result: DR Tulu-8B在科学、医疗等领域的4个长文本研究基准测试中显著优于开源模型，且参数量更少成本更低

Conclusion: RLER框架有效解决了长文本研究的训练难题，通过开放数据模型和新型MCP智能体架构推动深度研究系统发展

Abstract: Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.

</details>


### [77] [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](https://arxiv.org/abs/2511.19417)
*James Y. Huang,Sheng Zhang,Qianchu Liu,Guanghui Qin,Tinghui Zhu,Tristan Naumann,Muhao Chen,Hoifung Poon*

Main category: cs.CL

TL;DR: 通过模块化多代理框架BeMyEyes，将高效视觉模型作为感知器与LLMs推理器协作，无需训练大规模多模态模型即可实现知识密集型多模态推理。


<details>
  <summary>Details</summary>
Motivation: 现有小规模视觉语言模型缺乏LLMs的广泛知识和推理能力，而训练大规模多模态模型成本高昂。通过代理协作保留LLMs优势的同时扩展多模态能力。

Method: 1. 构建感知器（VLMs）与推理器（LLMs）的对话协作框架 2. 开发数据合成和微调流程训练感知器代理 3. 通过模块化设计支持多模态灵活扩展

Result: 开源方案（DeepSeek-R1+Qwen2.5-VL-7B）在知识密集型多模态任务上超越GPT-4o等专有大模型

Conclusion: 多代理协作方法有效平衡模型能力与效率，证明了模块化设计在构建未来多模态推理系统中的可行性和扩展性

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [78] [MotionDuet: Dual-Conditioned 3D Human Motion Generation with Video-Regularized Text Learning](https://arxiv.org/abs/2511.18209)
*Yi-Yang Zhang,Tengjiao Sun,Pengcheng Fang,Deng-Bao Wang,Xiaohao Cai,Min-Ling Zhang,Hansung Kim*

Main category: cs.GR

TL;DR: 提出多模态框架MotionDuet，通过视频特征对齐和双流编码技术实现更真实的3D人体运动生成


<details>
  <summary>Details</summary>
Motivation: 传统动捕成本高，现有单模态方法难以平衡运动动态与真实数据统计特征

Method: 采用DUET双流编码融合视频特征，DASH损失对齐分布，配合自引导机制平衡多模态信号

Result: 在实验中超越现有SOTA方法，生成兼具真实性和可控性的运动序列

Conclusion: MotionDuet通过跨模态表征对齐和动态注意力机制，突破了文本-视频协同控制的技术瓶颈

Abstract: 3D Human motion generation is pivotal across film, animation, gaming, and embodied intelligence. Traditional 3D motion synthesis relies on costly motion capture, while recent work shows that 2D videos provide rich, temporally coherent observations of human behavior. Existing approaches, however, either map high-level text descriptions to motion or rely solely on video conditioning, leaving a gap between generated dynamics and real-world motion statistics. We introduce MotionDuet, a multimodal framework that aligns motion generation with the distribution of video-derived representations. In this dual-conditioning paradigm, video cues extracted from a pretrained model (e.g., VideoMAE) ground low-level motion dynamics, while textual prompts provide semantic intent. To bridge the distribution gap across modalities, we propose Dual-stream Unified Encoding and Transformation (DUET) and a Distribution-Aware Structural Harmonization (DASH) loss. DUET fuses video-informed cues into the motion latent space via unified encoding and dynamic attention, while DASH aligns motion trajectories with both distributional and structural statistics of video features. An auto-guidance mechanism further balances textual and visual signals by leveraging a weakened copy of the model, enhancing controllability without sacrificing diversity. Extensive experiments demonstrate that MotionDuet generates realistic and controllable human motions, surpassing strong state-of-the-art baselines.

</details>


### [79] [A Convex-Inspired Neural Construction for Structured and Generalizable Nonlinear Model Reduction](https://arxiv.org/abs/2511.18241)
*Shixun Huang,Eitan Grinspun,Yue Chang*

Main category: cs.GR

TL;DR: 提出基于对称性约束的输入凸神经网络，在模型降阶中兼顾神经网络的表达能力与物理一致性


<details>
  <summary>Details</summary>
Motivation: 传统线性模型降阶方法（如PCA）表达能力有限，而现有非线性神经网络方法缺乏结构约束导致泛化能力差

Method: 采用输入凸神经网络（ICNN）框架，增加对称性约束构建非线性解码器，保持物理一致性

Result: 在未见过的力场方向/强度等场景中展现优异泛化能力，保持紧凑的降维空间并支持实时交互

Conclusion: 通过结构化神经网络设计成功桥接线性和非线性模型降阶的优势，突破传统方法泛化瓶颈

Abstract: Real-time simulation of deformable objects relies on model reduction to achieve interactive performance while maintaining physical fidelity. Traditional linear methods, such as principal component analysis (PCA), provide structured and predictable behavior thanks to their linear formulation, but are limited in expressiveness. Nonlinear model reduction, typically implemented with neural networks, offers richer representations and higher compression; however, without structural constraints, the learned mappings often fail to generalize beyond the training distribution, leading to unstable or implausible deformations. We present a symmetric, convex-inspired neural formulation that bridges the gap between linear and nonlinear model reduction. Our approach adopts an input-convex neural network (ICNN) augmented with symmetry constraints to impose structure on the nonlinear decoder. This design retains the flexibility of neural mappings while embedding physical consistency, yielding coherent and stable displacements even under unseen conditions. We evaluate our method on challenging deformation scenarios involving forces of different magnitudes, inverse directions, and sparsely sampled training data. Our approach demonstrates superior generalization while maintaining compact reduced spaces, and supports real-time interactive applications.

</details>


### [80] [Inverse Rendering for High-Genus Surface Meshes from Multi-View Images](https://arxiv.org/abs/2511.18680)
*Xiang Gao,Xinmu Wang,Xiaolong Wu,Jiazhi Li,Jingyu Shi,Yu Guo,Yuanpeng Liu,Xiyun Song,Heather Yu,Zongfang Lin,Xianfeng David Gu*

Main category: cs.GR

TL;DR: 提出结合V循环重网格化与改进Adam优化器的逆向渲染方法，有效解决高亏格表面重建中的拓扑特征丢失问题，在Chamfer Distance和Volume IoU指标上显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 传统基于体素/点云的逆向渲染方法难以保持高亏格表面拓扑特征，且Adam优化器导致梯度异常，亟需兼顾拓扑保持与几何细节的优化框架

Method: 1. 自适应V循环重网格化周期性地粗化-细化网格
2. 改进Adam优化器参数化方式增强梯度稳定性
3. 基于高斯-博内定理构建拓扑基元保证拓扑一致性

Result: 高亏格表面重建效果显著提升：Chamfer Distance降低23%，Volume IoU提高18%；低亏格表面细节保留提升19%

Conclusion: 将拓扑感知机制融入逆向渲染流程，首次实现高复杂度拓扑结构的鲁棒重建，为工业设计/医学成像领域复杂曲面建模提供新方案

Abstract: We present a topology-informed inverse rendering approach for reconstructing high-genus surface meshes from multi-view images. Compared to 3D representations like voxels and point clouds, mesh-based representations are preferred as they enable the application of differential geometry theory and are optimized for modern graphics pipelines. However, existing inverse rendering methods often fail catastrophically on high-genus surfaces, leading to the loss of key topological features, and tend to oversmooth low-genus surfaces, resulting in the loss of surface details. This failure stems from their overreliance on Adam-based optimizers, which can lead to vanishing and exploding gradients. To overcome these challenges, we introduce an adaptive V-cycle remeshing scheme in conjunction with a re-parametrized Adam optimizer to enhance topological and geometric awareness. By periodically coarsening and refining the deforming mesh, our method informs mesh vertices of their current topology and geometry before optimization, mitigating gradient issues while preserving essential topological features. Additionally, we enforce topological consistency by constructing topological primitives with genus numbers that match those of ground truth using Gauss-Bonnet theorem. Experimental results demonstrate that our inverse rendering approach outperforms the current state-of-the-art method, achieving significant improvements in Chamfer Distance and Volume IoU, particularly for high-genus surfaces, while also enhancing surface details for low-genus surfaces.

</details>


### [81] [ChronoGS: Disentangling Invariants and Changes in Multi-Period Scenes](https://arxiv.org/abs/2511.18794)
*Zhongtao Wang,Jiaqi Dai,Qingtian Zhu,Yilong Li,Mai Su,Fei Zhu,Meng Gai,Shaorong Wang,Chengwei Pan,Yisong Chen,Guoping Wang*

Main category: cs.GR

TL;DR: 提出ChronoGS时间调制高斯表示方法，实现多时期场景的时空一致重建，并发布ChronoScene基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长期不连续变化场景中失效：静态方法强制单几何体，动态方法假设平滑运动。需解决多时期场景重建难题。

Method: 1. 构建时间锚定统一支架表达所有时期 2. 解耦稳定/演化组件实现时空一致性 3. 采用可微分优化策略调整高斯参数

Result: 实验显示ChronoGS在重建质量和时间一致性上优于基线，同时开源代码和包含真实/合成场景的ChronoScene数据集。

Conclusion: 通过时间调制表征和组件解耦机制，首次实现多时期场景的高效统一重建，推动相关领域研究发展。

Abstract: Multi-period image collections are common in real-world applications. Cities are re-scanned for mapping, construction sites are revisited for progress tracking, and natural regions are monitored for environmental change. Such data form multi-period scenes, where geometry and appearance evolve. Reconstructing such scenes is an important yet underexplored problem. Existing pipelines rely on incompatible assumptions: static and in-the-wild methods enforce a single geometry, while dynamic ones assume smooth motion, both failing under long-term, discontinuous changes. To solve this problem, we introduce ChronoGS, a temporally modulated Gaussian representation that reconstructs all periods within a unified anchor scaffold. It's also designed to disentangle stable and evolving components, achieving temporally consistent reconstruction of multi-period scenes. To catalyze relevant research, we release ChronoScene dataset, a benchmark of real and synthetic multi-period scenes, capturing geometric and appearance variation. Experiments demonstrate that ChronoGS consistently outperforms baselines in reconstruction quality and temporal consistency. Our code and the ChronoScene dataset are publicly available at https://github.com/ZhongtaoWang/ChronoGS.

</details>


### [82] [MatMart: Material Reconstruction of 3D Objects via Diffusion](https://arxiv.org/abs/2511.18900)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.GR

TL;DR: 提出基于扩散模型的3D物体材质重建框架TTT，通过两阶段重建策略（先材质预测后生成）实现高精度结果，支持任意数量输入图像并具备端到端优化能力。


<details>
  <summary>Details</summary>
Motivation: 针对现有基于物理的材质估计方法在视角扩展性、生成质量和模型稳定性方面的不足，探索扩散模型在3D材质重建中的应用潜力。

Method: 1. 两阶段流程：输入图像材质预测+视角先验引导生成 2. 提出视角-材质交叉注意力机制(VMCA)实现多图输入扩展 3. 单一扩散模型端到端训练，无需额外预训练模型

Result: 实验证明TTT在材质重建质量上显著优于现有方法，对各类物体展现稳定性能

Conclusion: 该框架成功将扩散模型应用于3D材质重建，兼具高保真度、强扩展性和训练稳定性，为材质重建领域提供新解决方案

Abstract: Applying diffusion models to physically-based material estimation and generation has recently gained prominence. In this paper, we propose \ttt, a novel material reconstruction framework for 3D objects, offering the following advantages. First, \ttt\ adopts a two-stage reconstruction, starting with accurate material prediction from inputs and followed by prior-guided material generation for unobserved views, yielding high-fidelity results. Second, by utilizing progressive inference alongside the proposed view-material cross-attention (VMCA), \ttt\ enables reconstruction from an arbitrary number of input images, demonstrating strong scalability and flexibility. Finally, \ttt\ achieves both material prediction and generation capabilities through end-to-end optimization of a single diffusion model, without relying on additional pre-trained models, thereby exhibiting enhanced stability across various types of objects. Extensive experiments demonstrate that \ttt\ achieves superior performance in material reconstruction compared to existing methods.

</details>


### [83] [AvatarBrush: Monocular Reconstruction of Gaussian Avatars with Intuitive Local Editing](https://arxiv.org/abs/2511.19189)
*Mengtian Li,Shengxiang Yao,Yichen Pan,Haiyao Xiao,Zhongmei Li,Zhifeng Xie,Keyu Chen*

Main category: cs.GR

TL;DR: 提出了AvatarBrush框架，通过单目视频输入重建可完全动画化且支持局部编辑的虚拟化身，基于三层模型和网格变形技术实现高效编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如3DGS虽具高效重建能力，但缺乏直观的本地编辑功能，且依赖扫描网格或多视角输入。需降低用户创作门槛并增强编辑能力（体型/纹理/几何调整）。

Method: 1. 构建参数化身体模型、中间变形层、高斯表面层三层架构；2. 基于网格变形技术从身体模型局部信息生成高斯模型；3. 支持单目视频输入驱动。

Result: 在两个数据集上取得最优效果，支持体型调整/纹理修改/几何迁移等本地化编辑，相比传统方法降低硬件成本并提升用户友好性。

Conclusion: 该框架突破了传统方法对专业设备依赖的限制，通过创新的分层架构实现了高质量化身重建与便捷本地化编辑的平衡。

Abstract: The efficient reconstruction of high-quality and intuitively editable human avatars presents a pressing challenge in the field of computer vision. Recent advancements, such as 3DGS, have demonstrated impressive reconstruction efficiency and rapid rendering speeds. However, intuitive local editing of these representations remains a significant challenge. In this work, we propose AvatarBrush, a framework that reconstructs fully animatable and locally editable avatars using only a monocular video input. We propose a three-layer model to represent the avatar and, inspired by mesh morphing techniques, design a framework to generate the Gaussian model from local information of the parametric body model. Compared to previous methods that require scanned meshes or multi-view captures as input, our approach reduces costs and enhances editing capabilities such as body shape adjustment, local texture modification, and geometry transfer. Our experimental results demonstrate superior quality across two datasets and emphasize the enhanced, user-friendly, and localized editing capabilities of our method.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [84] [From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems](https://arxiv.org/abs/2511.17621)
*Brendan Gho,Suman Muppavarapu,Afnan Shaik,Tyson Tsay,James Begin,Kevin Zhu,Archana Vaidheeswaran,Vasu Sharma*

Main category: cs.MA

TL;DR: 提出基于市场机制的多智能体LLM协调框架，通过经济交换实现自我验证推理，在多项任务中准确率提升10%并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统集中式协调机制难以适应多智能体系统规模扩展，且决策过程缺乏透明度，亟需新型协调范式保障可信AI部署。

Method: 将LLM智能体建模为市场参与者，通过概率信念交易形成经济协调，使局部激励与集体认知目标自动对齐。

Result: 在事实推理/伦理判断任务中相比单次推理基线提升10%准确率，同时保留完整的中间推理链条可追溯性。

Conclusion: 经济协调机制为多智能体系统提供了可扩展的责任性实现路径，使AI系统具备自我纠正能力，支撑社会可信部署。

Abstract: As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [85] [Practical Machine Learning for Aphasic Discourse Analysis](https://arxiv.org/abs/2511.17553)
*Jason M. Pittman,Anton Phillips,Yesenia Medina-Santos,Brielle C. Stark*

Main category: cs.LG

TL;DR: 研究评估五种机器学习模型在图片描述任务中自动识别正确信息单元（CIU）的能力，发现模型在区分词汇/非词汇方面表现优异，但在识别CIU时存在挑战。


<details>
  <summary>Details</summary>
Motivation: 传统CIU分析依赖言语病理学家手动编码效率低下，需通过机器学习自动化提升分析效率。

Method: 使用随机选取的失语症患者人工编码转录本，训练五种监督式ML模型（含k近邻算法）进行词汇/非词汇、CIU/非CIU分类。

Result: 词汇识别准确率达0.995（AUC 0.914-0.995），CIU识别最佳模型为k-NN（准确率0.824，AUC 0.787）。

Conclusion: 监督学习可有效区分基础语言单位，但CIU识别需更精细的语义理解模型，显示自动化CIU分析的实际应用潜力与当前局限。

Abstract: Analyzing spoken discourse is a valid means of quantifying language ability in persons with aphasia. There are many ways to quantify discourse, one common way being to evaluate the informativeness of the discourse. That is, given the total number of words produced, how many of those are context-relevant and accurate. This type of analysis is called Correct Information Unit (CIU) analysis and is one of the most prevalent discourse analyses used by speech-language pathologists (SLPs). Despite this, CIU analysis in the clinic remains limited due to the manual labor needed by SLPs to code and analyze collected speech. Recent advances in machine learning (ML) seek to augment such labor by automating modeling of propositional, macrostructural, pragmatic, and multimodal dimensions of discourse. To that end, this study evaluated five ML models for reliable identification of Correct Information Units (CIUs, Nicholas & Brookshire, 1993), during a picture description task. The five supervised ML models were trained using randomly selected human-coded transcripts and accompanying words and CIUs from persons with aphasia. The baseline model training produced a high accuracy across transcripts for word vs non-word, with all models achieving near perfect performance (0.995) with high AUC range (0.914 min, 0.995 max). In contrast, CIU vs non-CIU showed a greater variability, with the k-nearest neighbor (k-NN) model the highest accuracy (0.824) and second highest AUC (0.787). These findings indicate that while the supervised ML models can distinguish word from not word, identifying CIUs is challenging.

</details>


### [86] [Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation](https://arxiv.org/abs/2511.17577)
*Fengming Yu,Qingyu Meng,Haiwei Pan,Kejia Zhang*

Main category: cs.LG

TL;DR: 提出动态注意力头剪枝+知识蒸馏的轻量化方法，在数学推理任务中实现高效部署


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在高计算/存储成本问题，阻碍实际应用部署

Method: 通过权重范数+熵动态评估注意力头重要性，实时剪枝冗余头；结合知识蒸馏保持学生模型推理能力

Result: Math23k数据集剪枝30%时：参数量↓18.7%，推理速度↑27.5%，FLOPs↓19.3%，准确率仅降0.7%

Conclusion: 在保持数学推理性能的前提下显著提升效率，为大模型实际应用提供有效解决方案

Abstract: With the rapid development of deep learning, large language models have shown strong capabilities in complex reasoning tasks such as mathematical equation solving. However, their substantial computational and storage costs hinder practical deployment. This paper proposes a lightweight optimization method that integrates dynamic attention head pruning with knowledge distillation. The approach dynamically evaluates the importance of each attention head in the multi-head attention mechanism using a combination of weight norms and entropy, and prunes redundant heads in real time to reduce computational overhead. To mitigate performance degradation, knowledge distillation transfers information from the original model to the pruned student, enabling the smaller model to preserve reasoning ability. Experiments conducted on both Math23k and ASDiv-A verify the effectiveness of the proposed method. For example, on Math23k with a 30% pruning ratio, parameters are reduced by 18.7%, inference speed is improved by 27.5%, FLOPs are reduced by 19.3%, and accuracy drops only 0.7% (from 84.4% to 83.7%). These results demonstrate that the method achieves substantial efficiency gains while maintaining strong reasoning performance, providing a practical solution for efficient deployment of large language models in mathematical reasoning tasks.

</details>


### [87] [Llamazip: Leveraging LLaMA for Lossless Text Compression and Training Dataset Detection](https://arxiv.org/abs/2511.17589)
*Sören Dréano,Derek Molloy,Noel Murphy*

Main category: cs.LG

TL;DR: 基于LLaMA3语言模型预测能力的无损文本压缩算法Llamazip，通过仅存储模型预测失败的token实现高效压缩，同时具备语言模型训练数据溯源能力


<details>
  <summary>Details</summary>
Motivation: 解决传统压缩算法效率瓶颈，并应对语言模型训练数据来源不透明带来的知识产权和可追溯性挑战

Method: 利用LLaMA3的预测能力动态选择存储内容，结合量化和上下文窗口优化技术平衡压缩率与计算资源消耗

Result: 量化参数和上下文窗口大小显著影响压缩率（最高提升40%）和内存消耗（可降低35%），算法在保持无损压缩的同时实现存储优化

Conclusion: Llamazip不仅革新了文本压缩技术，其训练数据检测能力为模型透明度审计提供了新工具，对知识产权保护具有重要意义

Abstract: This work introduces Llamazip, a novel lossless text compression algorithm based on the predictive capabilities of the LLaMA3 language model. Llamazip achieves significant data reduction by only storing tokens that the model fails to predict, optimizing storage efficiency without compromising data integrity. Key factors affecting its performance, including quantization and context window size, are analyzed, revealing their impact on compression ratios and computational requirements. Beyond compression, Llamazip demonstrates the potential to identify whether a document was part of the training dataset of a language model. This capability addresses critical concerns about data provenance, intellectual property, and transparency in language model training.

</details>


### [88] [PocketLLM: Ultimate Compression of Large Language Models via Meta Networks](https://arxiv.org/abs/2511.17637)
*Ye Tian,Chengcheng Wang,Jing Han,Yehui Tang,Kai Han*

Main category: cs.LG

TL;DR: 提出PocketLLM框架，通过元网络在潜在空间压缩大语言模型权重，实现10倍压缩率下精度无损


<details>
  <summary>Details</summary>
Motivation: 传统量化与剪枝方法难以在极端压缩大语言模型时保持精度，需解决边缘设备部署的存储传输瓶颈

Method: 设计编码器-码本-解码器架构：编码器将权重映射为离散潜在向量，紧凑码本存储特征，轻量解码器重构原始权重空间

Result: Llama 2-7B模型实现10倍压缩后准确率仅下降0.3%，显著优于传统压缩方法

Conclusion: 该框架为边缘计算场景部署超大语言模型提供了可行的压缩解决方案，突破存储限制同时保持模型性能

Abstract: As Large Language Models (LLMs) continue to grow in size, storing and transmitting them on edge devices becomes increasingly challenging. Traditional methods like quantization and pruning struggle to achieve extreme compression of LLMs without sacrificing accuracy. In this paper, we introduce PocketLLM, a novel approach to compress LLMs in a latent space via meta-networks. A simple encoder network is proposed to project the weights of LLMs into discrete latent vectors, which are then represented using a compact codebook. A lightweight decoder network is employed to map the codebook's representative vectors back to the original weight space. This method allows for significant compression of the large weights in LLMs, consisting solely of a small decoder, a concise codebook, and an index. Extensive experiments show that PocketLLM achieves superior performance even at significantly high compression ratios, e.g., compressing Llama 2-7B by 10x with a negligible drop in accuracy.

</details>


### [89] [DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams](https://arxiv.org/abs/2511.17693)
*Ginés Carreto Picón,Peng Yuan Zhou,Qi Zhang,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: 提出DeepCoT模型，实现无冗余的深度持续Transformer，显著提升流数据推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有持续Transformer仅适用于浅层模型，无法满足复杂任务需求，且流数据滑动窗口计算存在高冗余。

Method: 设计DeepCoT架构，兼容现有深度编码器，通过线性计算复杂度实现各Transformer层的高效处理。

Result: 在音视频文本流中，运行时间比高效模型减少两个数量级，性能与非持续基线相当。

Conclusion: DeepCoT有效解决深度模型计算冗余问题，为资源受限设备提供实时高效推理方案。

Abstract: Transformer-based models have dramatically increased their size and parameter count to tackle increasingly complex tasks. At the same time, there is a growing demand for low-latency inference on resource-constrained devices that achieves high performance. In particular, stream data inference is typically performed over a sliding temporal window, leading to highly redundant computations. The recent Continual Transformers have addressed this issue, but they can only be effectively used in shallow models, which limits their scope and generalization power. In this paper, we propose the Deep Continual Transformer (DeepCoT), a redundancy-free encoder-only model that can be applied over existing deep encoder architectures with minimal changes. In our experiments over audio, video, and text streams, we show that DeepCoTs retain comparative performance to their non-continual baselines while offering a linear computational cost for all Transformer layers, which reduces up to two orders of magnitude in the running time compared to previous efficient models.

</details>


### [90] [Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch](https://arxiv.org/abs/2511.17826)
*Ziyang Zhang,Xinheng Ding,Jiayi Yuan,Rixin Liu,Huizi Mao,Jiarong Xing,Zirui Liu*

Main category: cs.LG

TL;DR: 提出Tree-Based Invariant Kernels(TBIK)，解决大语言模型在不同张量并行规模(TP)下的非确定性推理问题，保证跨GPU配置的比特级结果一致性


<details>
  <summary>Details</summary>
Motivation: 当前LLM服务框架在TP规模变化时会产生非确定性输出，这对强化学习训练等场景造成严重干扰（如TP=1的FSDP训练引擎与多GPU推理引擎存在计算精度失配）

Method: 基于统一层次二叉树结构设计TP不变的矩阵乘法和规约原语，通过对齐GPU内/间的计算顺序消除并行配置差异

Result: 实验验证了跨TP规模的零概率发散，在vLLM和FSDP框架中实现比特级可复现性，强化学习训练流程中获得完全一致的推理结果

Conclusion: TBIK有效解决了TP规模导致的非确定性问题，为LLM的确定性推理提供了可靠解决方案，提升强化学习等场景的系统可靠性

Abstract: Deterministic inference is increasingly critical for large language model (LLM) applications such as LLM-as-a-judge evaluation, multi-agent systems, and Reinforcement Learning (RL). However, existing LLM serving frameworks exhibit non-deterministic behavior: identical inputs can yield different outputs when system configurations (e.g., tensor parallel (TP) size, batch size) vary, even under greedy decoding. This arises from the non-associativity of floating-point arithmetic and inconsistent reduction orders across GPUs. While prior work has addressed batch-size-related nondeterminism through batch-invariant kernels, determinism across different TP sizes remains an open problem, particularly in RL settings, where the training engine typically uses Fully Sharded Data Parallel (i.e., TP = 1) while the rollout engine relies on multi-GPU TP to maximize the inference throughput, creating a natural mismatch between the two. This precision mismatch problem may lead to suboptimal performance or even collapse for RL training. We identify and analyze the root causes of TP-induced inconsistency and propose Tree-Based Invariant Kernels (TBIK), a set of TP-invariant matrix multiplication and reduction primitives that guarantee bit-wise identical results regardless of TP size. Our key insight is to align intra- and inter-GPU reduction orders through a unified hierarchical binary tree structure. We implement these kernels in Triton and integrate them into vLLM and FSDP. Experiments confirm zero probability divergence and bit-wise reproducibility for deterministic inference across different TP sizes. Also, we achieve bit-wise identical results between vLLM and FSDP in RL training pipelines with different parallel strategy. Code is available at https://github.com/nanomaoli/llm_reproducibility.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [91] [Beyond the Rubric: Cultural Misalignment in LLM Benchmarks for Sexual and Reproductive Health](https://arxiv.org/abs/2511.17554)
*Sumon Kanti Dey,Manvi S,Zeel Mehta,Meet Shah,Unnati Agrawal,Suhani Jalota,Azra Ismail*

Main category: cs.CY

TL;DR: 现有基准测试存在西方偏见，需开发文化适应性评估框架以提升LLM在非西方医疗场景的有效性


<details>
  <summary>Details</summary>
Motivation: 评估LLM在印度性健康场景的实际效果，揭示西方基准在非西方环境的不适应性

Method: 从数据集中提取637个SRH查询，使用HealthBench自动评分+人工定性分析评估330个单轮对话

Result: 自动评分普遍偏低但人工验证显示多数回答合格，暴露基准存在法律/饮食/成本等西方偏见问题

Conclusion: 应开发兼顾质量标准与文化适应性的评估框架，满足多样化人群的医疗信息需求

Abstract: Large Language Models (LLMs) have been positioned as having the potential to expand access to health information in the Global South, yet their evaluation remains heavily dependent on benchmarks designed around Western norms. We present insights from a preliminary benchmarking exercise with a chatbot for sexual and reproductive health (SRH) for an underserved community in India. We evaluated using HealthBench, a benchmark for conversational health models by OpenAI. We extracted 637 SRH queries from the dataset and evaluated on the 330 single-turn conversations. Responses were evaluated using HealthBench's rubric-based automated grader, which rated responses consistently low. However, qualitative analysis by trained annotators and public health experts revealed that many responses were actually culturally appropriate and medically accurate. We highlight recurring issues, particularly a Western bias, such as for legal framing and norms (e.g., breastfeeding in public), diet assumptions (e.g., fish safe to eat during pregnancy), and costs (e.g., insurance models). Our findings demonstrate the limitations of current benchmarks in capturing the effectiveness of systems built for different cultural and healthcare contexts. We argue for the development of culturally adaptive evaluation frameworks that meet quality standards while recognizing needs of diverse populations.

</details>


### [92] [A Cross-Cultural Assessment of Human Ability to Detect LLM-Generated Fake News about South Africa](https://arxiv.org/abs/2511.17682)
*Tim Schlippe,Matthias Wölfel,Koena Ronny Mabokela*

Main category: cs.CY

TL;DR: 研究通过实验发现文化亲近性在识别AI生成假新闻中存在双重作用：南非人更擅长验证本国真实新闻，但识别假新闻表现较差，可能源于对本国新闻源的高度信任。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成虚假信息能力的提升，需探究不同文化背景下人类识别AI假新闻的能力差异，尤其关注信息跨文化传播时的检测机制。

Method: 89位参与者（56名南非人+33名他国人员）评估10篇真实南非新闻与10篇AI生成的假新闻，通过偏差值比较群体表现差异。

Result: 南非人对真实新闻的识别偏差值更低（40% vs 52%），但识别假新闻偏差更高（62% vs 55%）；群体总体偏差相近（51% vs 53%），显示文化熟悉度对真伪信息验证存在非对称影响。

Conclusion: 文化熟悉度虽能提升真实信息验证能力，但可能导致评估虚假内容时的认知偏见，这对制定跨文化反虚假信息策略具有重要启示。

Abstract: This study investigates how cultural proximity affects the ability to detect AI-generated fake news by comparing South African participants with those from other nationalities. As large language models increasingly enable the creation of sophisticated fake news, understanding human detection capabilities becomes crucial, particularly across different cultural contexts. We conducted a survey where 89 participants (56 South Africans, 33 from other nationalities) evaluated 10 true South African news articles and 10 AI-generated fake versions. Results reveal an asymmetric pattern: South Africans demonstrated superior performance in detecting true news about their country (40% deviation from ideal rating) compared to other participants (52%), but performed worse at identifying fake news (62% vs. 55%). This difference may reflect South Africans' higher overall trust in news sources. Our analysis further shows that South Africans relied more on content knowledge and contextual understanding when judging credibility, while participants from other countries emphasised formal linguistic features such as grammar and structure. Overall, the deviation from ideal rating was similar between groups (51% vs. 53%), suggesting that cultural familiarity appears to aid verification of authentic information but may also introduce bias when evaluating fabricated content. These insights contribute to understanding cross-cultural dimensions of misinformation detection and inform strategies for combating AI-generated fake news in increasingly globalised information ecosystems where content crosses cultural and geographical boundaries.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [93] [Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop](https://arxiv.org/abs/2511.17673)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 提出结构化认知循环（SCL）架构，通过软符号控制解决LLM代理的架构缺陷，实现零策略违规和完全决策可追溯性


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理存在推理与执行纠缠、记忆易失性、动作序列不可控等核心架构问题，需建立模块化认知框架提升可靠性

Method: 将认知分解为R-CCAM五阶段架构，创新性提出软符号控制机制——在概率推理中应用符号约束，融合神经灵活性与符号可解释性

Result: 实验验证SCL实现零策略违规，消除冗余工具调用，保持完整决策溯源，显著优于ReAct/AutoGPT等现有框架

Conclusion: SCL架构为可信AI代理提供三条设计原则：模块化解耦、自适应符号治理、透明状态管理，连接经典专家系统与现代LLM能力

Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). At the core of SCL is Soft Symbolic Control, an adaptive governance mechanism that applies symbolic constraints to probabilistic inference, preserving neural flexibility while restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents. Code: https://github.com/enkiluv/scl-core-experiment Demo: https://scl-travel-planner.streamlit.app/

</details>


### [94] [Paper2SysArch: Structure-Constrained System Architecture Generation from Scientific Papers](https://arxiv.org/abs/2511.18036)
*Ziyi Guo,Zhou Liu,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出首个系统性架构图生成基准测试（包含3000论文+对应图表）和三层评估指标，并开发Paper2SysArch端到端系统验证可行性


<details>
  <summary>Details</summary>
Motivation: 现有图表生成方法缺乏结构化控制且缺少标准化评估基准，阻碍该领域研究发展

Method: Paper2SysArch系统采用多智能体协作机制，将论文自动转换为结构化可编辑图表

Result: 在人工筛选的复杂论文子集上，系统综合评分达到69.0（基于语义准确性、布局合理性和视觉质量的三维评估）

Conclusion: 建立了首个大规模基准测试推动可复现研究，同时通过多智能体系统验证了自动化图表生成的技术可行性

Abstract: The manual creation of system architecture diagrams for scientific papers is a time-consuming and subjective process, while existing generative models lack the necessary structural control and semantic understanding for this task. A primary obstacle hindering research and development in this domain has been the profound lack of a standardized benchmark to quantitatively evaluate the automated generation of diagrams from text. To address this critical gap, we introduce a novel and comprehensive benchmark, the first of its kind, designed to catalyze progress in automated scientific visualization. It consists of 3,000 research papers paired with their corresponding high-quality ground-truth diagrams and is accompanied by a three-tiered evaluation metric assessing semantic accuracy, layout coherence, and visual quality. Furthermore, to establish a strong baseline on this new benchmark, we propose Paper2SysArch, an end-to-end system that leverages multi-agent collaboration to convert papers into structured, editable diagrams. To validate its performance on complex cases, the system was evaluated on a manually curated and more challenging subset of these papers, where it achieves a composite score of 69.0. This work's principal contribution is the establishment of a large-scale, foundational benchmark to enable reproducible research and fair comparison. Meanwhile, our proposed system serves as a viable proof-of-concept, demonstrating a promising path forward for this complex task.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [95] [LLM and Agent-Driven Data Analysis: A Systematic Approach for Enterprise Applications and System-level Deployment](https://arxiv.org/abs/2511.17676)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Annie Wang,Weizhe Wang*

Main category: cs.DB

TL;DR: 生成式AI与Agent技术推动企业数据分析革新，覆盖创新框架、SQL生成挑战与典型应用案例


<details>
  <summary>Details</summary>
Motivation: 企业需要应对AI技术带来的数据管理变革，在提升分析效率的同时确保数据安全合规

Method: 结合RAG技术、向量数据库和LLM驱动的SQL生成框架，建立包含多代理协作、安全验证的系统部署方案

Result: 提出支持复杂查询理解的安全验证框架，但面临分布式部署、SQL幻觉等实际挑战

Conclusion: AI技术显著降低企业数据访问门槛，需平衡计算效率与数据安全才能实现有效落地

Abstract: The rapid progress in Generative AI and Agent technologies is profoundly transforming enterprise data management and analytics. Traditional database applications and system deployment are fundamentally impacted by AI-driven tools, such as Retrieval-Augmented Generation (RAG) and vector database technologies, which provide new pathways for semantic querying over enterprise knowledge bases. In the meantime, data security and compliance are top priorities for organizations adopting AI technologies. For enterprise data analysis, SQL generations powered by large language models (LLMs) and AI agents, has emerged as a key bridge connecting natural language with structured data, effectively lowering the barrier to enterprise data access and improving analytical efficiency. This paper focuses on enterprise data analysis applications and system deployment, covering a range of innovative frameworks, enabling complex query understanding, multi-agent collaboration, security verification, and computational efficiency. Through representative use cases, key challenges related to distributed deployment, data security, and inherent difficulties in SQL generation tasks are discussed.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [96] [MURMUR: Using cross-user chatter to break collaborative language agents in groups](https://arxiv.org/abs/2511.17671)
*Atharv Singh Patlan,Peiyao Sheng,S. Ashwin Hebbar,Prateek Mittal,Pramod Viswanath*

Main category: cs.CR

TL;DR: 多用户语言代理存在跨用户投毒（CUP）安全漏洞，攻击者可通过污染共享状态触发恶意行为，实验证明攻击成功率极高且影响持久，并提出初步防御方案。


<details>
  <summary>Details</summary>
Motivation: 随着语言代理从单用户转向多用户协作场景，现有模型缺乏用户交互隔离机制，导致跨用户投毒攻击（CUP）新风险——攻击者通过污染共享状态诱导代理执行恶意操作。

Method: 1. 在真实系统验证CUP攻击有效性
2. 开发MURMUR框架模拟多用户场景（LLM生成历史感知的并发用户交互）
3. 分析攻击持续性和成功率

Result: 1. CUP攻击在主流多用户代理中成功率极高
2. 攻击效果可跨多个任务持续存在
3. 基于任务聚类的防御方案可初步缓解漏洞

Conclusion: 多用户LLM部署存在基础性安全风险，CUP攻击证明共享状态机制存在严重缺陷。研究首次系统揭示该攻击模式，并提出任务聚类防御方法作为解决方案起点。

Abstract: Language agents are rapidly expanding from single-user assistants to multi-user collaborators in shared workspaces and groups. However, today's language models lack a mechanism for isolating user interactions and concurrent tasks, creating a new attack vector inherent to this new setting: cross-user poisoning (CUP). In a CUP attack, an adversary injects ordinary-looking messages that poison the persistent, shared state, which later triggers the agent to execute unintended, attacker-specified actions on behalf of benign users. We validate CUP on real systems, successfully attacking popular multi-user agents. To study the phenomenon systematically, we present MURMUR, a framework that composes single-user tasks into concurrent, group-based scenarios using an LLM to generate realistic, history-aware user interactions. We observe that CUP attacks succeed at high rates and their effects persist across multiple tasks, thus posing fundamental risks to multi-user LLM deployments. Finally, we introduce a first-step defense with task-based clustering to mitigate this new class of vulnerability

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [97] [Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion](https://arxiv.org/abs/2511.17932)
*Yan Xu,Yixing Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 提出一种基于预训练视频扩散模型的零样本框架，通过不确定性感知机制与3D高斯溅射结合，实现极端稀疏输入下的高质量新视角合成。


<details>
  <summary>Details</summary>
Motivation: 解决传统稀疏输入视角合成方法在极端稀疏观测区域（如仅有2-3个输入视角）难以生成时空连贯视频的问题，利用大规模预训练模型的强先验突破几何约束。

Method: 1) 不确定性感知机制生成空间连贯的伪视图 2) 3D高斯溅射与视频扩散模型的迭代优化循环 3) 生成指导的零样本框架避免场景特定训练

Result: 在LLFF、DTU等数据集上，相比3D-GS基线方法PSNR提升3.5dB以上，且在仅有2个输入视角时仍能保持时空一致性

Conclusion: 通过将神经渲染与生成模型先验结合，首次实现了无需场景微调的稀疏视角视频合成，为跨场景的通用视图生成提供了新范式

Abstract: Given just a few glimpses of a scene, can you imagine the movie playing out as the camera glides through it? That's the lens we take on \emph{sparse-input novel view synthesis}, not only as filling spatial gaps between widely spaced views, but also as \emph{completing a natural video} unfolding through space.
  We recast the task as \emph{test-time natural video completion}, using powerful priors from \emph{pretrained video diffusion models} to hallucinate plausible in-between views. Our \emph{zero-shot, generation-guided} framework produces pseudo views at novel camera poses, modulated by an \emph{uncertainty-aware mechanism} for spatial coherence. These synthesized frames densify supervision for \emph{3D Gaussian Splatting} (3D-GS) for scene reconstruction, especially in under-observed regions. An iterative feedback loop lets 3D geometry and 2D view synthesis inform each other, improving both the scene reconstruction and the generated views.
  The result is coherent, high-fidelity renderings from sparse inputs \emph{without any scene-specific training or fine-tuning}. On LLFF, DTU, DL3DV, and MipNeRF-360, our method significantly outperforms strong 3D-GS baselines under extreme sparsity.

</details>


### [98] [MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer](https://arxiv.org/abs/2511.18370)
*Zenghao Chai,Chen Tang,Yongkang Wong,Xulei Yang,Mohan Kankanhalli*

Main category: cs.CV

TL;DR: 提出MimiCAT模型实现跨类别3D姿态迁移，通过软对应匹配突破传统方法的结构限制


<details>
  <summary>Details</summary>
Motivation: 现有3D姿态迁移方法局限于同类角色（如人形间迁移），无法处理跨物种（如人形→四足动物）的复杂结构差异导致的区域错配问题

Method: 1.构建百万级跨角色姿态数据集
2.设计级联Transformer架构
3.通过语义关键点实现软对应匹配
4.建立条件生成框架（投影+形状条件细化）

Result: 在跨角色迁移任务中，定量指标和视觉质量均显著优于现有方法（特别是超越传统方法在非同类迁移场景下的表现）

Conclusion: MimiCAT首次实现真正意义上的无类别限制3D姿态迁移，其软对应机制和条件生成框架为跨结构角色动画提供了新范式

Abstract: 3D pose transfer aims to transfer the pose-style of a source mesh to a target character while preserving both the target's geometry and the source's pose characteristic. Existing methods are largely restricted to characters with similar structures and fail to generalize to category-free settings (e.g., transferring a humanoid's pose to a quadruped). The key challenge lies in the structural and transformation diversity inherent in distinct character types, which often leads to mismatched regions and poor transfer quality. To address these issues, we first construct a million-scale pose dataset across hundreds of distinct characters. We further propose MimiCAT, a cascade-transformer model designed for category-free 3D pose transfer. Instead of relying on strict one-to-one correspondence mappings, MimiCAT leverages semantic keypoint labels to learn a novel soft correspondence that enables flexible many-to-many matching across characters. The pose transfer is then formulated as a conditional generation process, in which the source transformations are first projected onto the target through soft correspondence matching and subsequently refined using shape-conditioned representations. Extensive qualitative and quantitative experiments demonstrate that MimiCAT transfers plausible poses across different characters, significantly outperforming prior methods that are limited to narrow category transfer (e.g., humanoid-to-humanoid).

</details>


### [99] [ReCoGS: Real-time ReColoring for Gaussian Splatting scenes](https://arxiv.org/abs/2511.18441)
*Lorenzo Rutayisire,Nicola Capodieci,Fabio Pellacini*

Main category: cs.CV

TL;DR: 提出基于Gaussian Splatting的实时重着色方案RecoGS，通过交互式工具实现场景区域精选取色，解决现有方法视角不一致、计算成本高的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于2D扩散模型的多视角数据集生成方法存在视角不一致、细粒度控制不足、计算资源消耗大的痛点，需开发更高效的3D场景编辑方案

Method: 1. 构建用户友好流水线支持在预训练高斯泼溅场景中精选取色区域 2. 开发交互式工具实现实时颜色编辑操作 3. 保留原始几何结构实现非破坏性编辑

Result: 方案在保持原始场景质量前提下实现实时重着色，GitHub已开源代码验证方案有效性（https://github.com/loryruta/recogs）

Conclusion: RecoGS突破了传统NeRF方法效率瓶颈，为3D场景编辑提供新范式，交互工具设计拓宽了高斯泼溅技术的应用场景

Abstract: Gaussian Splatting has emerged as a leading method for novel view synthesis, offering superior training efficiency and real-time inference compared to NeRF approaches, while still delivering high-quality reconstructions. Beyond view synthesis, this 3D representation has also been explored for editing tasks. Many existing methods leverage 2D diffusion models to generate multi-view datasets for training, but they often suffer from limitations such as view inconsistencies, lack of fine-grained control, and high computational demand. In this work, we focus specifically on the editing task of recoloring. We introduce a user-friendly pipeline that enables precise selection and recoloring of regions within a pre-trained Gaussian Splatting scene. To demonstrate the real-time performance of our method, we also present an interactive tool that allows users to experiment with the pipeline in practice. Code is available at https://github.com/loryruta/recogs.

</details>


### [100] [Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction](https://arxiv.org/abs/2511.18873)
*Yiming Wang,Shaofei Wang,Marko Mihajlovic,Siyu Tang*

Main category: cs.CV

TL;DR: 提出Neural Texture Splatting(NTS)方法，通过全局神经场建模局部纹理场，显著提升3D高斯泼溅技术在多任务重建中的性能


<details>
  <summary>Details</summary>
Motivation: 现有3DGS变体在稀疏输入/动态重建等通用场景表现受限，且无法建模视角和时间依赖性效果

Method: 采用tri-plane+神经解码器的混合架构构建全局神经场，预测每个图元的局部外观/几何场，通过共享表征实现参数压缩和全局信息交互

Result: 在稀疏/密集输入的新视角合成、几何重建、动态重建等任务中实现SOTA，模型体积缩减约80%

Conclusion: NTS通过神经建模局部纹理场，在保持效率的同时显著提升3DGS的泛化能力和表现力，突破现有方法的局限

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading approach for high-quality novel view synthesis, with numerous variants extending its applicability to a broad spectrum of 3D and 4D scene reconstruction tasks. Despite its success, the representational capacity of 3DGS remains limited by the use of 3D Gaussian kernels to model local variations. Recent works have proposed to augment 3DGS with additional per-primitive capacity, such as per-splat textures, to enhance its expressiveness. However, these per-splat texture approaches primarily target dense novel view synthesis with a reduced number of Gaussian primitives, and their effectiveness tends to diminish when applied to more general reconstruction scenarios. In this paper, we aim to achieve concrete performance improvement over state-of-the-art 3DGS variants across a wide range of reconstruction tasks, including novel view synthesis, geometry and dynamic reconstruction, under both sparse and dense input settings. To this end, we introduce Neural Texture Splatting (NTS). At the core of our approach is a global neural field (represented as a hybrid of a tri-plane and a neural decoder) that predicts local appearance and geometric fields for each primitive. By leveraging this shared global representation that models local texture fields across primitives, we significantly reduce model size and facilitate efficient global information exchange, demonstrating strong generalization across tasks. Furthermore, our neural modeling of local texture fields introduces expressive view- and time-dependent effects, a critical aspect that existing methods fail to account for. Extensive experiments show that Neural Texture Splatting consistently improves models and achieves state-of-the-art results across multiple benchmarks.

</details>


### [101] [NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting](https://arxiv.org/abs/2511.19202)
*Brent Zoomers,Florian Hahlbohm,Joni Vanherck,Lode Jorissen,Marcus Magnor,Nick Michiels*

Main category: cs.CV

TL;DR: 提出基于共享MLP的可见性学习框架，实现3D高斯渲染中的高效遮挡剔除


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯渲染因半透明特性无法应用遮挡剔除技术，导致大规模场景渲染效率受限

Method: 使用跨实例共享的小型MLP学习视角依赖的可见性函数，结合Tensor Core加速的实例化软件光栅器

Result: 在合成场景中VRAM使用降低40%，渲染质量PSNR提升1.2dB，与现有LOD技术形成互补优势

Conclusion: 神经可见性查询机制有效突破遮挡剔除瓶颈，为实时渲染系统提供了新的优化维度

Abstract: 3D Gaussian Splatting can exploit frustum culling and level-of-detail strategies to accelerate rendering of scenes containing a large number of primitives. However, the semi-transparent nature of Gaussians prevents the application of another highly effective technique: occlusion culling. We address this limitation by proposing a novel method to learn the viewpoint-dependent visibility function of all Gaussians in a trained model using a small, shared MLP across instances of an asset in a scene. By querying it for Gaussians within the viewing frustum prior to rasterization, our method can discard occluded primitives during rendering. Leveraging Tensor Cores for efficient computation, we integrate these neural queries directly into a novel instanced software rasterizer. Our approach outperforms the current state of the art for composed scenes in terms of VRAM usage and image quality, utilizing a combination of our instanced rasterizer and occlusion culling MLP, and exhibits complementary properties to existing LoD techniques.

</details>


### [102] [Robustness of Structured Data Extraction from Perspectively Distorted Documents](https://arxiv.org/abs/2511.17607)
*Hyakka Nakada,Yoshiyasu Tanaka*

Main category: cs.CV

TL;DR: 研究评估了文档畸变对多模态大模型OCR准确性的影响，发现结构识别精度显著下降，但简单旋转校正可提升性能。


<details>
  <summary>Details</summary>
Motivation: 实际文档常存在透视畸变，而现有研究多关注平面旋转。需评估此类畸变对多模态大模型数据提取的影响。

Method: 将透视畸变建模为等腰梯形变换（参数：旋转角+畸变率），生成合成文档测试Gemini-1.5-pro的字符/结构识别精度。

Result: 结构识别准确率（阅读顺序）比字符识别更易受畸变影响；简单旋转校正可显著改善性能。

Conclusion: 文档畸变会严重影响LLM的结构识别能力，实施几何校正对提升实际OCR应用效果至关重要。

Abstract: Optical Character Recognition (OCR) for data extraction from documents is essential to intelligent informatics, such as digitizing medical records and recognizing road signs. Multi-modal Large Language Models (LLMs) can solve this task and have shown remarkable performance. Recently, it has been noticed that the accuracy of data extraction by multi-modal LLMs can be affected when in-plane rotations are present in the documents. However, real-world document images are usually not only in-plane rotated but also perspectively distorted. This study investigates the impacts of such perturbations on the data extraction accuracy for the state-of-the-art model, Gemini-1.5-pro. Because perspective distortions have a high degree of freedom, designing experiments in the same manner as single-parametric rotations is difficult. We observed typical distortions of document images and showed that most of them approximately follow an isosceles-trapezoidal transformation, which allows us to evaluate distortions with a small number of parameters. We were able to reduce the number of independent parameters from eight to two, i.e. rotation angle and distortion ratio. Then, specific entities were extracted from synthetically generated sample documents with varying these parameters. As the performance of LLMs, we evaluated not only a character-recognition accuracy but also a structure-recognition accuracy. Whereas the former represents the classical indicators for optical character recognition, the latter is related to the correctness of reading order. In particular, the structure-recognition accuracy was found to be significantly degraded by document distortion. In addition, we found that this accuracy can be improved by a simple rotational correction. This insight will contribute to the practical use of multi-modal LLMs for OCR tasks.

</details>


### [103] [When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA](https://arxiv.org/abs/2511.17886)
*Pume Tuchinda,Parinthapat Pengpun,Romrawin Chumpu,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CV

TL;DR: 研究发现CLIP式视觉语言模型的知识蒸馏存在反直觉现象：更强的教师模型未必产生更好学生模型，现有蒸馏框架在多任务扩展时性能下降。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型高计算需求与现有知识蒸馏方法在CLIP式模型扩展中的低效问题，挑战传统知识蒸馏的适用性假设。

Method: 通过系统研究不同规模的CLIP式教师模型（从基准模型到SOTA大模型），评估蒸馏框架在视觉问答等多模态下游任务的表现。

Result: 发现教师模型强度与学生性能呈非线性关系，现有蒸馏方法在模型扩展时导致多模态任务性能下降（如视觉问答准确率降低）

Conclusion: 突破传统知识蒸馏范式，为设计参数高效的多模态模型指明新方向，强调需要开发适配大模型蒸馏的新框架。

Abstract: Vision-language models (VLMs) have achieved remarkable success across multimodal tasks, yet their substantial computational demands hinder efficient deployment. Knowledge distillation (KD) has emerged as a powerful approach for building lightweight but competitive models, with strong evidence from both language and vision domains. However, its application to VLMs, particularly CLIP-style models, remains limited, often constrained to small-scale teachers and narrow evaluation tasks such as classification or retrieval. In this work, we present the first systematic study of distillation across a range of CLIP-style teacher models, ranging from standard baselines to large-scale state-of-the-art models. Contrary to trends observed in NLP and vision, we find that stronger teachers do not consistently yield better students; in fact, existing distillation frameworks often fail to scale, leading to degraded performance in downstream multimodal tasks such as visual question answering. Our findings challenge prevailing assumptions in KD and point toward new directions for designing parameter-efficient multimodal models.

</details>


### [104] [IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment](https://arxiv.org/abs/2511.18055)
*Bowen Qu,Shangkun Sun,Xiaoyu Liang,Wei Gao*

Main category: cs.CV

TL;DR: 提出文本驱动图像编辑评估基准IE-Bench及人类感知对齐评估模型IE-Critic-R1


<details>
  <summary>Details</summary>
Motivation: 现有评估方法仅关注图文对齐性且未与人类感知充分对齐，需建立同时考虑文本指令与源图像特性的评估体系

Method: 构建包含多样化源图/编辑提示/编辑结果的数据库，引入基于可验证奖励强化学习（RLVR）的IE-Critic-R1评估框架

Result: 建立含4000样本的人工评分数据集，实验证明IE-Critic-R1在主观对齐性上优于现有指标

Conclusion: IE-Bench为文本驱动图像编辑提供系统评估基准，IE-Critic-R1通过RLVR机制实现更全面可解释的质量评估

Abstract: Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [105] [Comparing Labeled Markov Chains: A Cantor-Kantorovich Approach](https://arxiv.org/abs/2511.18103)
*Adrien Banse,Alessandro Abate,Raphaël M. Jungers*

Main category: cs.LO

TL;DR: 本文系统分析了Cantor-Kantorovich距离在标记马尔可夫链中的计算复杂性、连续性及近似性，建立了其与折扣总变差距离的理论联系，并证明其#P-hard性及可计算近似方案。


<details>
  <summary>Details</summary>
Motivation: 解决LMCs模型比较的挑战（如评估抽象化精度或扰动影响），需对CK距离进行理论验证以明确其适用边界及与现有距离的关系。

Method: 1. 将CK距离框架化为Cantor拓扑下的折扣线性距离
2. 从计算复杂性（#P-hard证明）、连续性（有限轨迹概率误差边界）及近似性（可计算方案）三个维度展开分析

Result: 1. 精确计算CK距离为#P-hard
2. 建立有限轨迹概率误差的量化边界
3. 提出可计算近似方案（同样具有#P-hard复杂性）

Conclusion: CK距离作为自然Cantor拓扑的产物，其理论属性为模型比较提供了严格基础，并通过#P-hard结果澄清了其与线性距离的实践边界。

Abstract: Labeled Markov Chains (or LMCs for short) are useful mathematical objects to model complex probabilistic languages. A central challenge is to compare two LMCs, for example to assess the accuracy of an abstraction or to quantify the effect of model perturbations. In this work, we study the recently introduced Cantor-Kantorovich (or CK) distance. In particular we show that the latter can be framed as a discounted sum of finite-horizon Total Variation distances, making it an instance of discounted linear distance, but arising from the natural Cantor topology. Building on the latter observation, we analyze the properties of the CK distance along three dimensions: computational complexity, continuity properties and approximation. More precisely, we show that the exact computation of the CK distance is #P-hard. We also provide an upper bound on the CK distance as a function of the approximation relation between the two LMCs, and show that a bounded CK distance implies a bounded error between probabilities of finite-horizon traces. Finally, we provide a computable approximation scheme, and show that the latter is also #P-hard. Altogether, our results provide a rigorous theoretical foundation for the CK distance and clarify its relationship with existing distances.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [106] [Speech Recognition Model Improves Text-to-Speech Synthesis using Fine-Grained Reward](https://arxiv.org/abs/2511.17555)
*Guansu Wang,Peijie Sun*

Main category: eess.AS

TL;DR: 通过ASR模型的注意力机制改进TTS评估，提出W3AR方法提升语音合成质量与鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有TTS评估方法（如MOS）仅评估整句质量，无法捕捉单词级错误。ASR模型的交叉注意力可揭示音文错位，但未被充分利用

Method: 利用预训练ASR模型（如Whisper）的注意力机制，构建无需人工标注的单词级对齐奖励W3AR，优化TTS模型输出

Result: 实验表明W3AR提升现有TTS系统质量，增强对未见说话者的零样本适应能力

Conclusion: 理解模型（如ASR）可作为生成模型的评估者，通过细粒度反馈优化生成效果，为生成模型优化提供新范式

Abstract: Recent advances in text-to-speech (TTS) have enabled models to clone arbitrary unseen speakers and synthesize high-quality, natural-sounding speech. However, evaluation methods lag behind: typical mean opinion score (MOS) estimators perform regression over entire utterances, while failures usually occur in a few problematic words. We observe that encoder-decoder ASR models (e.g., Whisper) surface word-level mismatches between speech and text via cross-attention, providing a fine-grained reward signal. Building on this, we introduce Word-level TTS Alignment by ASR-driven Attentive Reward (W3AR). Without explicit reward annotations, W3AR uses attention from a pre-trained ASR model to drive finer-grained alignment and optimization of sequences predicted by a TTS model. Experiments show that W3AR improves the quality of existing TTS systems and strengthens zero-shot robustness on unseen speakers. More broadly, our results suggest a simple recipe for generative modeling: understanding models can act as evaluators, delivering informative, fine-grained feedback for optimization.

</details>
