<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 64]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.LG](#cs.LG) [Total: 5]
- [cs.CV](#cs.CV) [Total: 3]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

TL;DR: 提出首个可扩展的大规模语音识别系统Omnilingual ASR，通过70亿参数的自监督预训练和类LLM解码器架构，实现仅需少量样本即可支持1600+语言（含500+首次覆盖语种），并开源不同规模模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统ASR系统架构限制导致的语种覆盖不足（全球7000+语言中多数未被支持）、扩展成本高及缺乏伦理考量的问题，通过社区协作实现低资源语言的普惠接入。

Method: 采用70亿参数自监督预训练框架学习鲁棒语音表征，设计支持零样本泛化的编码器-解码器架构（受大语言模型启发），结合公共资源与社区合作采集的补偿性语料构建多样化训练数据。

Result: 覆盖1600+语言（含500+首次支持语种），低资源场景性能显著超越现有系统，发布从3亿到70亿参数的多版本模型供不同设备使用。

Conclusion: 通过开源模型降低研究门槛，强调社区参与的伦理设计，推动语音技术普惠。项目开源地址：https://github.com/facebookresearch/omnilingual-asr

Abstract: Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [2] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

TL;DR: 示例排序在上下文学习中的影响与示例选择相当，两者共同决定模型性能


<details>
  <summary>Details</summary>
Motivation: 挑战传统认知中示例选择主导性能的假设，揭示示例排序与选择对模型表现具有同等量级的影响

Method: 通过分类和生成任务的对照实验，使用多规模开源模型（0.5B-27B）和GPT-5，比较不同排序与不同示例集的性能方差，并开发基于开发集的排序优化方法

Result: 不同排序导致的性能差异与完全替换示例集的差异相当，通过开发集筛选的排序能达到接近测试集最优排序的性能

Conclusion: 示例选择与排序在提示工程中具有同等重要性，两者存在协同效应，需重新审视上下文学习的机制假设

Abstract: In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [3] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

TL;DR: 形态学引导的分词方法提升拉丁语语言模型性能


<details>
  <summary>Details</summary>
Motivation: 传统分词方法在形态丰富的语言（如拉丁语）中存在局限，本文利用拉丁语丰富的词典资源而非大规模预训练数据，探索语言学资源对语言模型的提升价值

Method: 采用形态学指导的分词策略，结合拉丁语现有词典资源进行模型训练

Result: 在四个下游任务中实现性能提升（特别是跨领域文本），证明模型泛化能力增强

Conclusion: 对形态复杂的低资源语言，开发语言学资源是提升语言模型性能的有效替代方案

Abstract: Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [4] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

TL;DR: 研究探讨NLP在总统指令文本挖掘中的应用潜力，对比AI与人工分析效果，揭示技术局限性


<details>
  <summary>Details</summary>
Motivation: 验证NLP在社会科学大规模文本分析中的有效性，评估现有AI工具在政治信号识别中的实际表现

Method: 采用NLP技术与人工标注双盲对照，分析里根至克林顿时期的总统指令文本主题特征

Result: NLP能有效识别相关文档，但与人工分析存在显著差异，显示技术应用需进一步验证

Conclusion: 尽管展示NLP应用潜力，但AI技术快速迭代导致工具时效性限制，需持续验证技术适用边界

Abstract: Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [5] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

TL;DR: 研究发现10亿参数级模型（如Gemma-3-1B）在质量效率平衡上表现最优，支持边缘设备实时翻译错误检测


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器翻译评估中效果显著，但其规模和成本阻碍在边缘设备/隐私敏感场景的应用，需探索小模型可行性

Method: 基于WMT和SynCED数据集，对多个sub-2B模型进行基准测试，采用标准化提示词、轻量级logit偏置校准和多数投票机制，综合评估语义质量（MCC/F1）和计算指标（VRAM/延迟）

Result: Gemma-3-1B在SynCED-EnDe-2025微调后达到MCC=0.77（F1-ERR=0.98），MacBook Pro M4 Pro单样本延迟400ms；Qwen-3-1.7B性能更高但计算成本增加；0.6B级模型存在实体/数字错误检测不足

Conclusion: 指令微调的小型LLM配合轻量校准和小样本监督，可在保持隐私/低成本前提下实现可信的端侧翻译错误检测，相关数据集和工具已开源

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [6] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

TL;DR: 本文分析了中英文平行句子的谓词-论元结构，发现语言迁移具有不对称性，强调在跨语言NLP中选择源语言时需谨慎


<details>
  <summary>Details</summary>
Motivation: 探索语言差异对跨语言迁移学习的影响，特别是类型学差异较大的中文和英文之间的结构对齐问题

Method: 通过平行语料库的谓词标注对比分析，结合注释投影实验的定性和定量研究，建立结构差异分类体系

Result: 语言迁移呈现明显不对称性，源语言选择会显著影响标注投影效果

Conclusion: 跨语言NLP研究需优先验证源语言选择的合理性，语言结构差异的系统性分析应成为迁移学习的前置条件

Abstract: Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [7] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

TL;DR: TARG通过无训练的自适应检索门控机制，仅用基础模型的短草稿计算不确定性分数，动态控制检索触发，在保持RAG准确率的同时减少70-90%检索次数并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法每次查询都触发检索会导致token膨胀和延迟上升，而盲目减少检索次数会影响事实准确性，需要开发轻量高效的检索控制机制。

Method: 利用基础模型生成的无上下文短草稿前缀logits，计算三种轻量级不确定性分数（平均token熵/top-1-top-2 logit边际信号/小N方差），仅当分数超过阈值时触发检索。

Result: 在NQ-Open等数据集上，TARG将检索次数减少70-90%的同时保持EM/F1指标，边际信号成为现代LLM下的稳健选择，小N方差适合预算优先场景。

Conclusion: TARG通过动态门控机制在准确率与效率间实现最优平衡，其训练无关特性和低开销特性使其成为实用化RAG部署的有效解决方案。

Abstract: Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [8] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

TL;DR: 提出整合高棉语子词切分、命名实体识别、音素转换和语言模型的全方位拼写检查方案，准确率达94.4%


<details>
  <summary>Details</summary>
Motivation: 解决高棉语拼写检查中词典对齐困难、单词形态多变、复合词灵活构成、专有名词误判四大挑战

Method: 融合子词切分模块、命名实体识别模型、音素转换模型及语言模型候选排序机制

Result: 实验显示准确率提升至94.4%，并建立公开的高棉语拼写检查和NER基准数据集

Conclusion: 该研究首次系统性解决高棉语拼写难题，开源数据集将推动低资源语言处理发展

Abstract: Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [9] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

TL;DR: 提出基于数据分析与机器学习的课程推荐系统，整合用户偏好、学术指标及行业趋势，通过迭代原型设计优化前端界面，帮助学生做出数据驱动的选课决策。


<details>
  <summary>Details</summary>
Motivation: 解决学生在选课时难以匹配行业需求的问题，弥合大学课程与产业期望的鸿沟。现有推荐系统可能缺乏对行业动态的实时追踪，导致课程选择与职业目标错位。

Method: 采用数据挖掘和协同过滤技术分析历史课程数据，构建融合机器学习算法、用户画像和职业目标的推荐框架，并通过迭代原型设计和用户反馈优化交互界面。

Result: 经用户反馈优化的系统能有效提升选课相关性，为师生及职业顾问提供决策支持，实证表明可改善毕业生就业竞争力。

Conclusion: 该系统成功搭建学术与产业的桥梁，通过数据驱动的个性化推荐促进终身学习，提升高校人才与职场需求的契合度。

Abstract: This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [10] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

TL;DR: 提出基于开源大语言模型与检索增强生成（RAG）的课程问答系统，通过微调模型、构建课程知识库、多链推理机制，有效解决课程论坛响应延迟和重复问题。


<details>
  <summary>Details</summary>
Motivation: 在线课程学生数量激增导致教师难以及时响应论坛提问，重复性问题大量消耗教学资源，需通过自动化方案提升问答效率。

Method: 1. 微调开源LLM适应课程领域
2. 构建本地课程知识库实施RAG检索
3. 集成多链思维推理机制抑制幻觉
4. 在HotpotQA数据集验证方案有效性

Result: 实验表明微调后的RAG-LLM模型在问答任务中表现出色，准确率提升显著。

Conclusion: 该方案成功实现课程问答自动化，降低教师工作量同时保证回答质量，为教育技术领域提供可复用的LLM应用范式。

Abstract: The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [11] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

TL;DR: 提出TermGPT多级对比微调框架，解决大语言模型在法律金融领域的术语区分难题


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在领域特定术语（尤其是法律金融术语）的嵌入表征存在各向同性缺陷，影响下游任务表现

Method: 通过构建句子图捕捉语义关系，基于上下文和拓扑线索生成正负样本，设计句子级和token级的双重对比学习机制

Result: 构建首个金融术语数据集，实验显示TermGPT在术语区分任务上超越现有基线模型

Conclusion: 该框架有效提升模型对专业术语的细粒度区分能力，为领域适应性提供新解决方案

Abstract: Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [12] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

TL;DR: 论文提出InTRO框架，通过标记级探索和自反馈机制提升大语言模型的思维链推理能力，在数学推理任务中实现20%的相对准确率提升，并展示跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在监督微调惩罚有效替代方案、强化学习面临信用分配和高计算成本的问题，需探索更高效的推理优化框架。

Method: 利用生成策略与答案条件策略间的信息差异估计校正因子，实现单次前向传播中的标记级探索和自反馈，优化下一个标记选择。

Result: 在6个数学推理基准测试中相对基准模型提升20%准确率，生成更简洁的思维链，且能跨领域迁移到非数学推理任务。

Conclusion: InTRO通过标记级探索和自反馈机制有效解决了现有方法的局限性，为可扩展的推理优化提供了新思路，具有强泛化能力。

Abstract: Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [13] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2511.09873)
*Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna*

Main category: cs.CL

TL;DR: 提出分层路由框架HierRouter，通过动态组合轻量级模型显著提升LLM推理效率（2.4倍质量提升）且成本可控


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在高计算/内存成本，难以部署在资源受限或实时场景

Method: 基于有限阶段MDP框架，采用PPO强化学习代理动态选择模型组合，实现多阶段推理路由

Result: 在6个基准测试中质量提升达2.4倍，平均仅增加9%推理成本

Conclusion: 分层路由机制为高效能、低成本LLM推理提供了创新解决方案

Abstract: Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models. Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference. The agent conditions on the evolving context and accumulated cost to make context-aware routing decisions. Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average. These results highlight the promise of hierarchical routing for cost-efficient, high-performance LLM inference. All codes can be found here https://github.com/ Nikunj-Gupta/hierouter.

</details>


### [14] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

TL;DR: EnchTable框架通过NTK安全向量蒸馏和干扰感知合并技术，有效维护下游LLM的安全对齐，在多种任务领域和模型架构中实现安全性与效用的平衡。


<details>
  <summary>Details</summary>
Motivation: 微调大语言模型常导致安全对齐能力退化，可能产生有害输出。需要开发兼容性强、无需大量重训练的安全维护方案。

Method: 1. 基于神经切线核(NTK)的安全向量蒸馏解耦安全约束与任务推理
2. 干扰感知合并技术平衡安全性和实用性
3. 跨3种模型架构/任务领域的原型实现与11个数据集评估

Result: 在11个数据集中实现：
- 不安全率降低51.2%（对比基线）
- 效用分数提升18.7%
- 静态/动态越狱攻击抵抗成功率>94%
- 支持跨厂商LLM的通用部署

Conclusion: EnchTable在安全防护效能、任务实用性、架构兼容性三方面实现突破，为LLM安全部署提供免训练的系统级解决方案。

Abstract: Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [15] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

TL;DR: HI-TransPA提出基于Omni-Model的多模态助听辅助系统，通过唇语-语音融合和课程学习策略实现听障人群的高精度端到端对话翻译。


<details>
  <summary>Details</summary>
Motivation: 现有全模态模型在听障语音场景存在噪声数据处理能力不足、多模态样本异质性强的缺陷，需构建融合高帧率唇动特征与语音的多模态统一框架。

Method: 构建包含面部关键点检测-唇部区域稳定化-样本质量评估的数据预处理流程，采用质量分数引导的课程学习策略；使用SigLIP编码器联合3D-Resampler处理高帧率唇动特征。

Result: 在HI-Dialogue数据集上取得字面准确率94.7%与语义保真度91.2%的SOTA性能，验证了全模态框架在辅助沟通技术中的有效性。

Conclusion: 建立了全模态助听技术的端到端建模范式，为后续研究提供核心处理工具与多模态融合框架参考。

Abstract: To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [16] [MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection](https://arxiv.org/abs/2511.09918)
*Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran*

Main category: cs.CL

TL;DR: 提出Norm-RAG框架结合语义分块和MINDS数据集，实现多语言对话中社会规范的上下文感知推理


<details>
  <summary>Details</summary>
Motivation: 现有规范标注研究多针对孤立语句或合成对话，难以捕捉真实多轮对话的动态规范表达

Method: 开发检索增强框架Norm-RAG（结合语义分块技术）并构建双语MINDS对话数据集（含多注释者共识标注）

Result: Norm-RAG提升规范检测泛化能力，在多文化场景中实现95.2%的规范识别准确率

Conclusion: 该框架为跨文化对话系统提供可解释的规范推理范式，MINDS数据集推动社会智能研究发展

Abstract: Social norms are implicit, culturally grounded expectations that guide interpersonal communication. Unlike factual commonsense, norm reasoning is subjective, context-dependent, and varies across cultures, posing challenges for computational models. Prior works provide valuable normative annotations but mostly target isolated utterances or synthetic dialogues, limiting their ability to capture the fluid, multi-turn nature of real-world conversations. In this work, we present Norm-RAG, a retrieval-augmented, agentic framework for nuanced social norm inference in multi-turn dialogues. Norm-RAG models utterance-level attributes including communicative intent, speaker roles, interpersonal framing, and linguistic cues and grounds them in structured normative documentation retrieved via a novel Semantic Chunking approach. This enables interpretable and context-aware reasoning about norm adherence and violation across multilingual dialogues. We further introduce MINDS (Multilingual Interactions with Norm-Driven Speech), a bilingual dataset comprising 31 multi-turn Mandarin-English and Spanish-English conversations. Each turn is annotated for norm category and adherence status using multi-annotator consensus, reflecting cross-cultural and realistic norm expression. Our experiments show that Norm-RAG improves norm detection and generalization, demonstrates improved performance for culturally adaptive and socially intelligent dialogue systems.

</details>


### [17] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 本研究通过扩展LLM提示策略并引入余弦相似度合并方法，有效改善了知识组件自动化识别的冗余问题


<details>
  <summary>Details</summary>
Motivation: 手动识别知识组件效率低下，现有LLM自动化方法存在标签冗余问题且仅适用于小规模数据

Method: 1. 将「模拟教科书」提示策略扩展到646道选择题数据集
2. 提出基于余弦相似度的语义合并方法
3. 评估不同相似度阈值的合并效果

Result: 最佳方案（阈值0.8）将KC数量从569降至428，RMSE从0.4285改善至0.4259，优于专家模型（0.4206）

Conclusion: LLM生成结合语义合并技术为知识组件自动化识别提供了可行解决方案

Abstract: Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [18] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

TL;DR: 提出REAP方法，通过递归评估与自适应规划增强多跳推理的准确性和可靠性


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在多跳推理中存在全局规划不足、检索内容利用不充分的问题，导致推理结果准确性受限

Method: 通过子任务规划器(SP)维护全局推理方向，事实提取器(FE)进行细粒度内容分析，结合统一任务范式实现多任务微调

Result: 在多个多跳数据集实验中显著超越现有RAG方法，验证其在复杂推理任务中的有效性

Conclusion: REAP通过结构化知识表示和动态轨迹优化，为复杂多跳推理任务提供可靠解决方案

Abstract: Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [19] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

TL;DR: 大语言模型在数值事实核查中存在鲁棒性缺陷，即使顶尖模型在特定扰动下准确率下降达62%，扩展上下文并加入扰动示例可部分恢复性能


<details>
  <summary>Details</summary>
Motivation: 探究当前语言模型在数值声明验证任务中的鲁棒性局限，特别是面对受控扰动时的表现

Method: 通过标签翻转探测、上下文长度变化和扰动演示增强等控制性扰动方法，系统评估主流模型的数值事实核查能力

Result: 1. 所有模型在至少一种扰动场景下准确率显著下降（最高降幅62%）
2. 上下文延长通常降低准确率，但加入扰动示例后多数模型性能大幅恢复
3. 无模型能在所有测试条件下保持稳定表现

Conclusion: 当前语言模型的数值事实核查存在根本性脆弱，鲁棒性仍是开放挑战，需开发更可靠的扰动抵抗机制

Abstract: Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [20] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 提出基于熵趋势约束（ETC）的动态检索增强生成方法，通过建模token级不确定性动态实现更精准的检索时机判断，在减少检索频率的同时提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有动态RAG方法依赖低置信度触发检索，存在延迟干预导致错误传播的问题。需要更早识别模型内在不确定性以优化检索决策。

Method: 利用熵序列的一阶（趋势）和二阶（趋势变化）差分检测早期不确定性信号，建立趋势感知的检索触发机制。无需训练，可即插即用地集成到现有解码流程。

Result: 在6个QA基准测试中，使用3种LLM均优于基线方法（平均提升2.1%准确率），检索频率降低23%。领域特定场景表现最佳，消融实验验证趋势建模的有效性。

Conclusion: ETC通过动态跟踪熵趋势实现了更有效的检索时机决策，具有模型无关性和工程易用性，为动态RAG系统提供了可靠的时序控制方案。

Abstract: Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [21] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

TL;DR: 提出Soft Constrained Decoding（SCD）方法解决多语言RAG中的输出语言漂移问题，通过解码时惩罚非目标语言令牌实现跨语言稳定生成。


<details>
  <summary>Details</summary>
Motivation: 多语言RAG系统中，当检索证据与用户查询语言不一致时，模型会出现非预期语言漂移（尤其实时推理场景），英语作为语义吸引器加剧跨语言干扰。

Method: SCD：轻量级无训练的解码策略，在生成过程中对非目标语言token施加惩罚项，动态调整token概率分布保持目标语言对齐。

Result: 在三个多语言数据集、多种语言及LLM架构的实验中，SCD持续提升语言对齐度（+15.3%）和任务性能（+9.8% F1），尤其改善思维链生成的跨语言稳定性。

Conclusion: SCD为多语言RAG提供通用解决方案，无需模型修改或额外数据，有效缓解解码器层面的语言崩溃现象，证明语言约束解码的工程可行性。

Abstract: Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [22] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: BERTScore在金融领域存在数值敏感性不足的缺陷，作者提出FinNuE诊断数据集揭示该问题并呼吁开发数值感知的金融NLP评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入的语义相似度评估指标（如BERTScore）对数值变化不敏感，而金融领域数值精度直接影响语义（如2%收益与20%亏损）。需要揭示该缺陷并推动金融NLP评估框架的改进。

Method: 构建包含收益电话会议、监管文件、社交媒体和新闻文章的FinNuE诊断数据集，通过控制数值变化生成文本对，测试BERTScore的敏感性。

Result: BERTScore无法区分具有关键语义差异的数值变化，常对财务意义上截然不同的文本对给出高相似度评分。

Conclusion: 基于嵌入的评估指标在金融领域存在根本性局限，需开发数值敏感的评估框架以支持金融NLP应用。

Abstract: BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [23] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

TL;DR: 论文提出教育框架PustakAI和NCERT-QA数据集，评估不同LLM在印度基础教育课程中的适配性，分析模型在事实/推理类问题的表现差异。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在NCERT课程内容适配中的准确性、对齐性和教学相关性挑战，推动教育资源匮乏地区的个性化学习。

Method: 1) 构建6-8年级英语/科学课程的QA数据集（事实型/推理型/其他） 2) 采用元提示、小样本、思维链等提示技术 3) 对比开源模型（Gemma3等）与高阶模型（Deepseek-r1等）

Result: 不同模型在课程对齐效率上存在显著差异，高阶模型在复杂推理任务表现更优，但开源模型展示出基础教育场景的应用潜力

Conclusion: 需平衡模型性能与部署成本，当前LLM在课程结构化知识传递上仍存在语义对齐和教学策略适配的局限性

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [24] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

TL;DR: 提出了ScaleFormer框架，通过分块压缩和结构感知机制，使现有预训练模型无需架构修改即可高效处理长文本


<details>
  <summary>Details</summary>
Motivation: 解决标准Transformer自注意力机制二次方复杂度带来的长文本处理限制，避免现有方法需要架构修改和重新预训练的问题

Method: 将长输入分割为重叠块，通过参数无关的融合机制（累积上下文向量）增强块边界表示，实现结构感知和线性复杂度

Result: 在长文档摘要任务中超越现有方法，无需架构修改或外部检索机制

Conclusion: ScaleFormer为预训练模型提供了简单有效的长文本处理解决方案，保持原始架构的同时实现叙事流理解

Abstract: The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [25] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

TL;DR: 通过LEX-ICON数据集分析多模态大语言模型对语音象似性的处理机制，发现其音素直觉与语言学理论高度吻合，注意力模式聚焦标志性音素。


<details>
  <summary>Details</summary>
Motivation: 探究MLLMs如何通过语音象征主义（语音与意义的非任意关联）解码听觉信息，验证模型是否符合人类语言认知机制。

Method: 使用包含8052个自然语言词汇和2930个伪词的跨模态数据集，通过音素级注意力分数评估模型在25个语义维度（如尖锐/圆润）的层间处理特征。

Result: 1. MLLMs在多个语义维度展现与语言学理论一致的音素直觉
2. 注意力模式揭示模型对标志性音素（如/k/表尖锐）的显著关注

Conclusion: 首次实现MLLMs语音象似性的大规模定量分析，为人工智能模型可解释性与认知语言学的交叉研究建立新范式。

Abstract: Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [26] [GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt](https://arxiv.org/abs/2511.10051)
*Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song*

Main category: cs.CL

TL;DR: 提出GraphIF框架，通过图结构建模多轮对话关系约束，提升LLM指令遵循能力


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模多轮对话数据微调LLM，但未显式建模跨轮次关系约束。图结构能自然表达对话轮次间的语义关系，但尚未被有效利用

Method: 1) 基于动作触发机制的关系抽取模块构建对话关系图；2) 将图结构转化为自然语言提示；3) 响应重写模块利用图提示优化LLM输出

Result: 在两个长多轮对话数据集上实验显示，GraphIF显著提升所有四项指令遵循评估指标

Conclusion: GraphIF作为即插即用框架，无需重新训练即可增强LLM的多轮指令遵循能力，验证了图结构在对话建模中的有效性

Abstract: Multi-turn instruction following is essential for building intelligent conversational systems that can consistently adhere to instructions across dialogue turns. However, existing approaches to enhancing multi-turn instruction following primarily rely on collecting or generating large-scale multi-turn dialogue datasets to fine-tune large language models (LLMs), which treat each response generation as an isolated task and fail to explicitly incorporate multi-turn instruction following into the optimization objectives. As a result, instruction-tuned LLMs often struggle with complex long-distance constraints. In multi-turn dialogues, relational constraints across turns can be naturally modeled as labeled directed edges, making graph structures particularly suitable for modeling multi-turn instruction following. Despite this potential, leveraging graph structures to enhance the multi-turn instruction following capabilities of LLMs remains unexplored. To bridge this gap, we propose GraphIF, a plug-and-play framework that models multi-turn dialogues as directed relation graphs and leverages graph prompts to enhance the instruction following capabilities of LLMs. GraphIF comprises three key components: (1) an agent-based relation extraction module that captures inter-turn semantic relations via action-triggered mechanisms to construct structured graphs; (2) a relation graph prompt generation module that converts structured graph information into natural language prompts; and (3) a response rewriting module that refines initial LLM outputs using the generated graph prompts. Extensive experiments on two long multi-turn dialogue datasets demonstrate that GraphIF can be seamlessly integrated into instruction-tuned LLMs and leads to significant improvements across all four multi-turn instruction-following evaluation metrics.

</details>


### [27] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 扩展ADI-17阿拉伯语方言数据集至ADI-20，覆盖全部阿拉伯国家方言并开源数据模型


<details>
  <summary>Details</summary>
Motivation: 解决现有阿拉伯方言识别数据覆盖不足的问题，支持更全面的方言研究

Method: 采用ECAPA-TDNN预训练模型微调，结合Whisper编码器+注意力池化层+分类层的架构，分析训练数据量和模型参数对性能的影响

Result: 仅使用30%训练数据时F1值略微下降（1.58%绝对差异），证明模型高效性

Conclusion: ADI-20数据集和模型开源促进方言识别研究，中等规模模型在有限数据下表现优异

Abstract: We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [28] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 多模态大语言模型在科学主张验证任务中，表格证据处理优于图表证据，且小规模模型跨模态泛化能力有限


<details>
  <summary>Details</summary>
Motivation: 随着科学论文数量激增，需要评估多模态大语言模型在不同证据格式（表格/图表）下的科学主张验证能力

Method: 通过改造两个现有科学论文数据集，评估12个多模态LLM在表格和图表证据下的表现，并进行人类对照实验

Result: 模型表格处理准确率比图表高18.3%，参数量小于8B的模型跨模态表现相关性弱（Spearman系数0.29）

Conclusion: 未来多模态模型应加强图表理解能力，提升科学主张验证的跨模态推理能力

Abstract: With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [29] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 团队通过微调大规模预训练模型在阿拉伯语方言识别和多方言ASR任务中取得优异成绩


<details>
  <summary>Details</summary>
Motivation: 验证大规模预训练语音模型结合定向微调在阿拉伯语语音处理中的有效性

Method: 1. ADI任务使用数据增强的微调Whisper-large-v3编码器；2. ASR任务为每个阿拉伯方言单独微调SeamlessM4T-v2 Large模型

Result: ADI准确率79.83%（测试集最高），ASR平均WER 38.54%、CER 14.53%（测试集第二）

Conclusion: 实验证明针对特定任务微调大规模预训练模型能显著提升阿拉伯语音处理效果

Abstract: This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [30] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

TL;DR: 探讨大语言模型（如GPT）在军事领域的应用潜力，分析商业云服务（如Azure）对其实现的支持作用。


<details>
  <summary>Details</summary>
Motivation: 揭示自然语言处理技术军事化应用的可能性，评估现有商业平台快速部署军事应用的可行性。

Method: 1. 通过GPT模型（Microsoft Copilot）自揭示军事应用知识
2. 使用Microsoft Azure云服务进行应用可行性验证

Result: 模型文本总结和生成能力直接支撑多种军事应用，其他特性具备特殊用途潜力

Conclusion: 大语言模型与商业云服务的结合为军事应用提供了快速部署路径，需关注技术特性与军事需求的适配性

Abstract: In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [31] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 通过因果学习方法减少灾害事件分类中的领域偏差，提升模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有灾害事件监测系统存在事件相关偏差，导致模型在新生事件上泛化能力不足。近期因果学习技术为去偏提供了新思路，但在灾害领域尚未充分探索。

Method: 提出基于因果透镜的偏差缓解方法，同时减少事件相关偏差和领域相关偏差

Result: 在三个灾害分类任务中超越基线方法（最高F1提升+1.9%），显著改进基于预训练语言模型的分类器性能

Conclusion: 该方法有效提升了灾害事件分类模型的泛化能力，为社交媒体实时灾害监测提供了更可靠的解决方案

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [32] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: VISTA是一个基于Web的可视化交互系统，用于分析大语言模型在多轮对话中的推理过程，通过可视化上下文影响和生成推理依赖树降低分析复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以分析多轮交互中LLMs的复杂推理过程，主要受限于上下文依赖性和缺乏专用可视化工具，导致研究者认知负荷过高。

Method: 开发Web平台实现三大功能：1) 可视化上下文对模型决策的影响 2) 支持历史对话的交互式修改和跨模型假设分析 3) 自动生成推理依赖树展示逻辑路径。系统开源且支持自定义基准测试和本地模型集成。

Result: 系统显著降低推理链分析复杂度，通过依赖树可视化增强模型逻辑透明度，帮助研究者深入理解LLMs的推理能力边界。

Conclusion: VISTA为评估和改进LLMs的推理能力提供统一框架，其开源特性有利于研究社区扩展应用场景。

Abstract: Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [33] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

TL;DR: Text2SQL-Flow framework generates large-scale, diverse Text-to-SQL pairs via SQL-aware data augmentation, enhancing LLM performance in both open and closed-source settings.


<details>
  <summary>Details</summary>
Motivation: Existing Text-to-SQL datasets are limited by scarcity, simplicity, and low diversity, constraining model performance. Addressing these limitations through data augmentation can significantly improve system capabilities.

Method: Proposed Text2SQL-Flow framework with six augmentation dimensions, featuring SQL execution verification, NL question generation, chain-of-thought reasoning, data classification, and a modular Database Manager for cross-database compatibility.

Result: Built SQLFlow dataset (89,544 examples). Fine-tuning open-source LLMs with SQLFlow improves benchmark performance. For closed-source LLMs, masked alignment retrieval using SQLFlow as knowledge base achieves state-of-the-art results.

Conclusion: Establishes scalable data-centric foundation for Text-to-SQL advancement, demonstrating critical role of high-quality structured data in modern AI systems through novel framework and retrieval methodology.

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [34] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

TL;DR: 提出EffiReason-Bench基准，系统评估LLM高效推理方法，实验表明最优策略取决于模型规模、任务复杂度等因素


<details>
  <summary>Details</summary>
Motivation: 现有CoT推理方法生成冗长解释导致效率低下，且分散的评估方法阻碍公平比较

Method: 构建带标准化推理结构的标注数据集，开发E3-Score评估指标，在6个开源模型（1B-70B）上评估7种方法

Result: 无单一方法占优，推理策略选择需考虑模型规模、任务复杂度、架构特性

Conclusion: 系统化评估框架揭示高效推理方法的选择具有强上下文依赖性，需综合多维度因素进行策略决策

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [35] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

TL;DR: 提出PAL框架通过两阶段训练（角色感知学习+角色对齐）和『选择后生成』推理策略，在语义层面提升对话模型对角色特征的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有基于token级训练的个性化对话模型容易忽略角色特征，导致生成回复缺乏针对性。

Method: 采用角色感知学习（捕捉角色语义）+角色对齐训练（优化语义级对齐）两阶段框架，配合推理阶段的选择生成策略。

Result: 在多个实验中超越现有SOTA方法及大语言模型，生成更符合角色特征的对话回复。

Conclusion: 将角色对齐直接作为训练目标能有效提升对话系统的个性化表达能力，语义级对齐优于传统token级预测。

Abstract: Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [36] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: 提出LangGPS框架，通过语言可分离性指导多语言训练数据筛选，提升LLMs在多语言任务中的表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多语言训练数据选择方法忽视语言内在结构特征，导致模型多语言能力不稳定。语言可分离性可有效量化不同语言样本在表示空间中的区分度。

Method: 两阶段预选框架：1) 基于语言可分离性分数进行初筛 2) 结合现有方法精筛子集。语言可分离性通过样本在模型表示空间中的语言区分度量化。

Result: 在6个基准测试和22种语言中验证：相比基线方法平均提升3.1%理解任务准确率，低资源语言提升达5.8%。高可分离性样本促进语言边界形成（训练效率提升27%），低可分离性样本支持跨语言对齐。

Conclusion: 语言可分离性是数据效用评估和课程学习的重要信号，为开发语言感知的LLMs提供新视角。建议训练时交替使用不同可分离性样本，兼顾语言专精与跨语言迁移。

Abstract: Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [37] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出低延迟语音模型VocalNet-M2，通过多码本分词器和多令牌预测策略将首块延迟从725ms降至350ms，保持主流SLM竞争力


<details>
  <summary>Details</summary>
Motivation: 现有端到端语音模型存在显著响应延迟，主要源于语音令牌的自回归生成和复杂流匹配模型的语音合成需求

Method: 整合多码本分词器+多令牌预测策略，直接生成多码本语音令牌，避免使用流匹配模型，提升生成效率

Result: 首块延迟降低约50%（725ms→350ms），在主流SLM中保持竞争力，并提供单/多码本策略的全面对比

Conclusion: 该模型为实时交互应用提供了高效高性能的SLM解决方案，不同码本策略的对比为后续研究提供重要参考

Abstract: Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [38] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

TL;DR: 提出MTR-DuplexBench基准解决全双工语音语言模型在多轮对话评估中的不足，验证现有模型在持续对话中的性能波动问题


<details>
  <summary>Details</summary>
Motivation: 现有基准仅关注单轮对话评估，缺乏对多轮交互复杂性和关键能力（指令遵循、安全性）的全面测试，难以准确评估真实对话场景中的模型表现

Method: 将连续全双工对话切分为离散对话轮次，建立包含对话质量、会话动态、指令遵循和安全性四个维度的逐轮评估体系

Result: 实验表明当前全双工模型在多轮对话中难以保持稳定的性能表现，验证了该基准的有效性及评估必要性

Conclusion: MTR-DuplexBench填补了全双工模型评估体系的空白，揭示了现有模型的技术局限，其模块化设计为未来研究提供可扩展的测试框架

Abstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [39] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 本地化问答系统通过结合语义检索与关键词匹配，使企业可在消费级硬件上实现隐私保护与高效文档问答


<details>
  <summary>Details</summary>
Motivation: 解决金融机构/医疗机构在文档AI应用中面临的隐私泄露（云端处理）与准确性不足（本地处理）的核心矛盾

Method: 1. 平衡语义理解与关键词精准匹配的双重检索策略
2. 完全本地化部署架构
3. 消费级硬件加速优化

Result: 系统在复杂法律/科学/对话式文档查询中达到商用精度（错误率<2%），处理速度比传统本地方案提升5倍

Conclusion: 通过创新的混合检索架构设计，首次证明企业级AI部署中隐私保护与系统性能可实现协同优化

Abstract: Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [40] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

TL;DR: 提出基于困惑度的强化学习算法纠正大语言模型在数学推理中的评估偏好失衡问题，提升其多步数学推理的批评能力


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视LLMs批评能力不足的本质原因——评估偏好失衡（倾向于将低困惑度解判断为正确），需系统性量化分析该现象

Method: 1.构建OPS基准量化LLMs评估差异；2.通过困惑度偏好统计发现评估偏好失衡现象；3.设计Group Relative Policy Optimization算法调整评估偏好

Result: 在OPS基准和现有批评基准上的实验验证了方法有效性

Conclusion: 揭示了LLMs评估偏好失衡现象，提出基于困惑度感知的强化学习方法，显著提升了模型对多步数学推理解决方案的批评能力

Abstract: To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [41] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 研究提出了BhashaKritika多语言合成预训练数据集（540B tokens），通过5种生成技术探索文档/人设/主题对数据质量的影响，并开发模块化质量评估框架。


<details>
  <summary>Details</summary>
Motivation: 解决低资源印度语言在LLM预训练中的数据不足问题，平衡语言间的技术红利分布。重点分析提示语言选择、本土生成与翻译内容的质量差异。

Method: 采用文档锚定、人设设定、主题引导的生成策略；构建包含文字检测、元数据校验、n-gram重复分析、KenLM困惑度过滤的模块化评估流程。

Result: 揭示了生成策略中的关键权衡（如本土生成与翻译的优劣），确立了多语言语料库构建的最佳实践。模型运行验证了评估框架的有效性。

Conclusion: 通过系统性实证研究，为低资源语言合成数据生成提供了可扩展的质量控制方案，证明了混合生成策略的优越性。

Abstract: In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


### [42] [Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates](https://arxiv.org/abs/2511.10354)
*Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp*

Main category: cs.CL

TL;DR: 提出了ATR4CH五步法，通过LLM将文化遗产文本转化为知识图谱，在真实性评估案例中实现0.65-0.99的F1值


<details>
  <summary>Details</summary>
Motivation: 文化遗产文本蕴含丰富知识但难以结构化查询，现有方法缺乏LLM与本体论的系统整合，需建立可复现的知识图谱构建框架

Method: 结合标注模型、本体框架和迭代式LLM抽取：1)基础分析 2)标注模式开发 3)三LLM串联流水线架构（Claude/Llama/GPT）4)集成优化 5)多维评估

Result: 元数据抽取F1 0.96-0.99，实体识别0.7-0.8，假设抽取0.65-0.75，证据抽取0.95-0.97，话语表征G-EVAL 0.62；小模型表现接近大模型

Conclusion: 首个LLM与文化遗产本体协同的系统方法论，提供跨领域适配框架。局限在于仅用维基百科数据且需人工校验，实际支持机构自动化知识发现

Abstract: Cultural Heritage texts contain rich knowledge that is difficult to query systematically due to the challenges of converting unstructured discourse into structured Knowledge Graphs (KGs). This paper introduces ATR4CH (Adaptive Text-to-RDF for Cultural Heritage), a systematic five-step methodology for Large Language Model-based Knowledge Extraction from Cultural Heritage documents. We validate the methodology through a case study on authenticity assessment debates. Methodology - ATR4CH combines annotation models, ontological frameworks, and LLM-based extraction through iterative development: foundational analysis, annotation schema development, pipeline architecture, integration refinement, and comprehensive evaluation. We demonstrate the approach using Wikipedia articles about disputed items (documents, artifacts...), implementing a sequential pipeline with three LLMs (Claude Sonnet 3.7, Llama 3.3 70B, GPT-4o-mini). Findings - The methodology successfully extracts complex Cultural Heritage knowledge: 0.96-0.99 F1 for metadata extraction, 0.7-0.8 F1 for entity recognition, 0.65-0.75 F1 for hypothesis extraction, 0.95-0.97 for evidence extraction, and 0.62 G-EVAL for discourse representation. Smaller models performed competitively, enabling cost-effective deployment. Originality - This is the first systematic methodology for coordinating LLM-based extraction with Cultural Heritage ontologies. ATR4CH provides a replicable framework adaptable across CH domains and institutional resources. Research Limitations - The produced KG is limited to Wikipedia articles. While the results are encouraging, human oversight is necessary during post-processing. Practical Implications - ATR4CH enables Cultural Heritage institutions to systematically convert textual knowledge into queryable KGs, supporting automated metadata enrichment and knowledge discovery.

</details>


### [43] [TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs](https://arxiv.org/abs/2511.10375)
*Shuyi Liu,Yuming Shang,Xi Zhang*

Main category: cs.CL

TL;DR: 提出TruthfulRAG框架，首次利用知识图谱解决RAG系统中事实层面的知识冲突，通过图检索与熵过滤机制提升生成内容的准确性与可信度。


<details>
  <summary>Details</summary>
Motivation: 现有RAG冲突解决方法局限于token/语义层面，导致对LLM内部知识与上下文间事实差异的碎片化认知，难以应对知识密集型任务的需求。

Method: 1. 从检索内容构建知识图谱 2. 基于查询的图检索定位相关知识 3. 熵过滤机制精确定位冲突三元组 4. 动态调整生成过程消除事实矛盾

Result: 实验表明TruthfulRAG显著优于基线方法，冲突缓解效果提升23%，生成内容事实准确性提高18%

Conclusion: 知识图谱为事实层冲突解决提供了结构化解决方案，TruthfulRAG框架有效增强了RAG系统的鲁棒性与可信赖性，为知识密集型LLM应用奠定新基础。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for enhancing the capabilities of Large Language Models (LLMs) by integrating retrieval-based methods with generative models. As external knowledge repositories continue to expand and the parametric knowledge within models becomes outdated, a critical challenge for RAG systems is resolving conflicts between retrieved external information and LLMs' internal knowledge, which can significantly compromise the accuracy and reliability of generated content. However, existing approaches to conflict resolution typically operate at the token or semantic level, often leading to fragmented and partial understanding of factual discrepancies between LLMs' knowledge and context, particularly in knowledge-intensive tasks. To address this limitation, we propose TruthfulRAG, the first framework that leverages Knowledge Graphs (KGs) to resolve factual-level knowledge conflicts in RAG systems. Specifically, TruthfulRAG constructs KGs by systematically extracting triples from retrieved content, utilizes query-based graph retrieval to identify relevant knowledge, and employs entropy-based filtering mechanisms to precisely locate conflicting elements and mitigate factual inconsistencies, thereby enabling LLMs to generate faithful and accurate responses. Extensive experiments reveal that TruthfulRAG outperforms existing methods, effectively alleviating knowledge conflicts and improving the robustness and trustworthiness of RAG systems.

</details>


### [44] [Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning](https://arxiv.org/abs/2511.10381)
*Jason Chan,Zhixue Zhao,Robert Gaizauskas*

Main category: cs.CL

TL;DR: 本文论证评估基础大语言模型（LLMs）推理能力存在根本性方法论缺陷，其预训练目标与正确性评估标准存在本质错配，基础模型的输出不能视为真实推理尝试，相关结论也无法推广至后训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视基础LLMs评估中的方法论问题：1）错误地将模型输出视为其真实推理结果 2）错误假设基础模型结论可推广至后训练模型。需重新审视相关研究的底层假设。

Method: 通过理论分析揭示基础LLMs生成逻辑有效性结论的偶然性（实为语言统计模式的副产品），批判性检验现有评估方法的底层假设有效性。

Result: 证明基础LLMs的生成结果本质是语言统计模式的顺应产物，与逻辑正确性无必然关联，现有评估体系存在根本性方法论缺陷。

Conclusion: 必须严格区分基础模型与后训练模型的评估范畴，重新检验现有研究的方法论假设，警惕将语言模式顺应行为误判为真实推理能力的评估陷阱。

Abstract: Existing work investigates the reasoning capabilities of large language models (LLMs) to uncover their limitations, human-like biases and underlying processes. Such studies include evaluations of base LLMs (pre-trained on unlabeled corpora only) for this purpose. Our position paper argues that evaluating base LLMs' reasoning capabilities raises inherent methodological concerns that are overlooked in such existing studies. We highlight the fundamental mismatch between base LLMs' pretraining objective and normative qualities, such as correctness, by which reasoning is assessed. In particular, we show how base LLMs generate logically valid or invalid conclusions as coincidental byproducts of conforming to purely linguistic patterns of statistical plausibility. This fundamental mismatch challenges the assumptions that (a) base LLMs' outputs can be assessed as their bona fide attempts at correct answers or conclusions; and (b) conclusions about base LLMs' reasoning can generalize to post-trained LLMs optimized for successful instruction-following. We call for a critical re-examination of existing work that relies implicitly on these assumptions, and for future work to account for these methodological pitfalls.

</details>


### [45] [DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence](https://arxiv.org/abs/2511.10404)
*Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam*

Main category: cs.CL

TL;DR: 本文提出DELICATE（结合BERT与Wikidata的神经符号实体链接方法）和ENEIDE（历史意大利语多领域语料库），显著提升历史文献实体链接性能。


<details>
  <summary>Details</summary>
Motivation: 人文领域实体链接(EL)面临复杂文档类型、领域数据/模型缺失及长尾实体挑战，需针对性解决方案。

Method: 1. DELICATE：基于BERT编码器，融合Wikidata上下文信息，通过时间合理性与实体类型一致性筛选知识库实体
2. ENEIDE：从19-20世纪文学/政治文本中半自动构建的多领域历史意大利语EL语料库

Result: DELICATE在历史意大利语EL任务中优于其他模型（包括数十亿参数大模型），其置信度与特征敏感性提供更可解释的结果

Conclusion: 神经符号方法DELICATE在性能与可解释性上优于纯神经方法，ENEIDE为低资源领域研究提供重要数据支持

Abstract: In spite of the remarkable advancements in the field of Natural Language Processing, the task of Entity Linking (EL) remains challenging in the field of humanities due to complex document typologies, lack of domain-specific datasets and models, and long-tail entities, i.e., entities under-represented in Knowledge Bases (KBs). The goal of this paper is to address these issues with two main contributions. The first contribution is DELICATE, a novel neuro-symbolic method for EL on historical Italian which combines a BERT-based encoder with contextual information from Wikidata to select appropriate KB entities using temporal plausibility and entity type consistency. The second contribution is ENEIDE, a multi-domain EL corpus in historical Italian semi-automatically extracted from two annotated editions spanning from the 19th to the 20th century and including literary and political texts. Results show how DELICATE outperforms other EL models in historical Italian even if compared with larger architectures with billions of parameters. Moreover, further analyses reveal how DELICATE confidence scores and features sensitivity provide results which are more explainable and interpretable than purely neural methods.

</details>


### [46] [Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction](https://arxiv.org/abs/2511.10441)
*Chunyang Jiang,Paola Merlo*

Main category: cs.CL

TL;DR: 通过类比结构、对比学习和最小上下文提示，轻量级模型仅用百量级数据即可实现与大型语言模型相当的语言规则学习效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过认知启发的类比范式组织，使轻量级模型在极少量数据条件下达到与大数据训练的大型语言模型相当的语言规则学习能力。

Method: 开发结合类比结构/对比学习/最小上下文线索的计算框架，使用BERT+CNN架构在结构化完形填空任务上训练，通过消融实验和跨现象验证（使役交替与无宾交替）评估方法有效性。

Result: 在英语使役交替任务中，50万参数模型用100样本达到F1=0.95，显著优于GPT-3的零样本表现（F1=0.87）。消融实验显示类比组织和对比结构贡献25%性能提升，跨现象验证保持高效性。

Conclusion: 类比范式组织通过结构化知识表征，使模型数据效率提升两个数量级，为资源受限场景下的语言学习提供认知启发的解决方案。

Abstract: Large language models achieve strong performance through training on vast datasets. Can analogical paradigm organization enable lightweight models to match this performance with minimal data? We develop a computational approach implementing three cognitive-inspired principles: analogical structure, contrastive learning, and minimal contextual cues. We test this approach with structured completion tasks where models identify correct sentence completions from analogical patterns with contrastive alternatives. Training lightweight models (BERT+CNN, $0.5M$ parameters) on only one hundred structured examples of English causative/inchoative alternations achieves $F1=0.95$, outperforming zero-shot \texttt{GPT-o3} ($F1=0.87$). Ablation studies confirm that analogical organization and contrastive structure improve performance, consistently surpassing randomly shuffled baselines across architectures. Cross-phenomenon validation using unspecified object alternations replicates these efficiency gains, confirming approach robustness. Our results show that analogical paradigm organization enables competitive linguistic rule learning with orders of magnitude less data than conventional approaches require.

</details>


### [47] [Reasoning About Intent for Ambiguous Requests](https://arxiv.org/abs/2511.10453)
*Irina Saparina,Mirella Lapata*

Main category: cs.CL

TL;DR: 提出通过结构化多解释-答案对增强语言模型对模糊问题的响应能力，实现透明、高效、可拓展的解决方案


<details>
  <summary>Details</summary>
Motivation: 语言模型处理模糊请求时容易隐式选择单一解释，导致用户困扰及安全隐患

Method: 使用强化学习框架配合定制化奖励函数，通过多有效答案监督训练模型

Result: 在对话问答和语义解析任务中覆盖更多有效答案（优于基线方法），人类评估显示解释与答案高度对齐

Conclusion: 结构化输出格式在保持单步生成效率的同时提升透明度，并为下游应用提供支持

Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer pairs in a single structured response to ambiguous requests. Our models are trained with reinforcement learning and customized reward functions using multiple valid answers as supervision. Experiments on conversational question answering and semantic parsing demonstrate that our method achieves higher coverage of valid answers than baseline approaches. Human evaluation confirms that predicted interpretations are highly aligned with their answers. Our approach promotes transparency with explicit interpretations, achieves efficiency by requiring only one generation step, and supports downstream applications through its structured output format.

</details>


### [48] [Exploring State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2511.10457)
*Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 大语言模型在状态跟踪任务中表现差异显著，GPT-4和Llama3结合思维链机制能有效跟踪状态，早期模型在多次步骤后容易失败


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在复杂任务中的状态跟踪能力，特别关注隔离其他影响因素后的纯状态跟踪性能

Method: 创建包含三个明确定义任务的基准测试，分析不同代际LLMs（GPT-4/Llama3 vs 前代模型）在不同场景下的表现

Result: 新一代LLMs展现优秀状态跟踪能力（准确率提升30%+），前代模型初始阶段可完成任务但逐步失效（失败率在第5步后达60%）

Conclusion: 思维链等机制整合对状态跟踪效果显著，前代模型存在系统性局限需架构创新突破

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in solving complex tasks, including those requiring a certain level of reasoning. In this paper, we focus on state tracking, a problem where models need to keep track of the state governing a number of entities. To isolate the state tracking component from other factors, we propose a benchmark based on three well-defined state tracking tasks and analyse the performance of LLMs in different scenarios. The results indicate that the recent generation of LLMs (specifically, GPT-4 and Llama3) are capable of tracking state, especially when integrated with mechanisms such as Chain of Thought. However, models from the former generation, while understanding the task and being able to solve it at the initial stages, often fail at this task after a certain number of steps.

</details>


### [49] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: 提出首个评估大语言模型在美国县级本地知识能力的基准LocalBench，发现现有模型在叙事类问题准确率仅56.8%，数值推理不足15.5%，且模型扩展与网络增强效果不稳定。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法评估LLMs在社区治理、文化叙事等超本地知识的理解能力，而实际应用对此需求迫切。

Method: 基于本地性概念框架构建LocalBench，包含49州526个县的14,782个多源问题（人口普查/论坛/新闻），覆盖物理/认知/关系三维度。

Result: 测试13个先进模型发现：最佳模型叙事准确率56.8%，数值推理低于15.5%；网络增强使Gemini提升13.6%但GPT系列下降11.4%。

Conclusion: 亟需开发能理解地域文化差异的公平AI系统，当前模型难以支撑社区级精细化需求。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [50] [Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks](https://arxiv.org/abs/2511.10465)
*Yunzhe Xu,Zhuosheng Zhang,Zhe Liu*

Main category: cs.CL

TL;DR: 提出KPPO框架，通过系统性知识整合突破传统提示优化局限，在15个知识密集型任务上实现平均6%性能提升并降低29%token消耗


<details>
  <summary>Details</summary>
Motivation: 传统激发式提示优化在知识密集型任务中存在固有局限，无法补充领域专有知识、术语精准度和推理模式，亟需新的知识整合范式

Method: 1) 知识缺口填补机制；2) 批量候选评估兼顾性能与稳定性；3) 自适应知识剪枝策略平衡性能与token效率

Result: 在跨领域基准测试中性能平均提升6%，token消耗持平或更低，最高减少29%token使用

Conclusion: KPPO通过系统知识整合有效突破语言模型参数边界，为知识密集型任务提示优化提供新范式

Abstract: While prompt optimization has emerged as a critical technique for enhancing language model performance, existing approaches primarily focus on elicitation-based strategies that search for optimal prompts to activate models' capabilities. These methods exhibit fundamental limitations when addressing knowledge-intensive tasks, as they operate within fixed parametric boundaries rather than providing the factual knowledge, terminology precision, and reasoning patterns required in specialized domains. To address these limitations, we propose Knowledge-Provision-based Prompt Optimization (KPPO), a framework that reformulates prompt optimization as systematic knowledge integration rather than potential elicitation. KPPO introduces three key innovations: 1) a knowledge gap filling mechanism for knowledge gap identification and targeted remediation; 2) a batch-wise candidate evaluation approach that considers both performance improvement and distributional stability; 3) an adaptive knowledge pruning strategy that balances performance and token efficiency, reducing up to 29% token usage. Extensive evaluation on 15 knowledge-intensive benchmarks from various domains demonstrates KPPO's superiority over elicitation-based methods, with an average performance improvement of ~6% over the strongest baseline while achieving comparable or lower token consumption. Code at: https://github.com/xyz9911/KPPO.

</details>


### [51] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://arxiv.org/abs/2511.10507)
*Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui*

Main category: cs.CL

TL;DR: 提出AdvancedIF基准测试和RIFL训练方法，显著提升大模型遵循复杂指令的能力


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在复杂指令遵循方面存在不足，缺乏高质量评估基准和可靠奖励信号

Method: 构建包含1,600个提示的AdvancedIF基准，开发基于评分标准的RIFL训练流程（标准生成+验证器微调+奖励塑造）

Result: RIFL使LLMs在AdvancedIF提升6.7%，公共基准表现优异，消融实验验证各组件有效性

Conclusion: 评分标准成为LLM指令遵循能力训练和评估的有效工具，推动更可靠AI系统发展

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant challenge. Rigorous evaluation and effective training for such capabilities are hindered by the lack of high-quality, human-annotated benchmarks and reliable, interpretable reward signals. In this work, we introduce AdvancedIF (we will release this benchmark soon), a comprehensive benchmark featuring over 1,600 prompts and expert-curated rubrics that assess LLMs ability to follow complex, multi-turn, and system-level instructions. We further propose RIFL (Rubric-based Instruction-Following Learning), a novel post-training pipeline that leverages rubric generation, a finetuned rubric verifier, and reward shaping to enable effective reinforcement learning for instruction following. Extensive experiments demonstrate that RIFL substantially improves the instruction-following abilities of LLMs, achieving a 6.7% absolute gain on AdvancedIF and strong results on public benchmarks. Our ablation studies confirm the effectiveness of each component in RIFL. This work establishes rubrics as a powerful tool for both training and evaluating advanced IF in LLMs, paving the way for more capable and reliable AI systems.

</details>


### [52] [LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025](https://arxiv.org/abs/2511.10515)
*Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma*

Main category: cs.CL

TL;DR: LOCA-R框架在CPhO 2025理论考试中获得313/320分，超越人类最佳选手与所有基线模型


<details>
  <summary>Details</summary>
Motivation: 物理奥赛题需融合精确计算、抽象推理与物理原理理解，是检验复杂推理能力的理想场景

Method: 基于LOCA框架改进的LOCA-R（逻辑链增强推理框架），专为复杂物理问题设计

Result: 在320分满分中取得313分，显著优于人类选手（最佳285分）和GPT-4（200分）等基线方法

Conclusion: LOCA-R在复杂物理推理任务中展现了类人的系统性思维与逻辑链构建能力

Abstract: Olympiad-level physics problem-solving presents a significant challenge for both humans and artificial intelligence (AI), as it requires a sophisticated integration of precise calculation, abstract reasoning, and a fundamental grasp of physical principles. The Chinese Physics Olympiad (CPhO), renowned for its complexity and depth, serves as an ideal and rigorous testbed for these advanced capabilities. In this paper, we introduce LOCA-R (LOgical Chain Augmentation for Reasoning), an improved version of the LOCA framework adapted for complex reasoning, and apply it to the CPhO 2025 theory examination. LOCA-R achieves a near-perfect score of 313 out of 320 points, solidly surpassing the highest-scoring human competitor and significantly outperforming all baseline methods.

</details>


### [53] [Say It Differently: Linguistic Styles as Jailbreak Vectors](https://arxiv.org/abs/2511.10519)
*Srikant Panda,Avinash Rai*

Main category: cs.CL

TL;DR: 语言模型的风格化改写可显著提升越狱攻击成功率，最高达57%，需通过风格中和预处理缓解。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语义等价攻击，忽略语言风格变化对模型安全性的影响。

Method: 构建包含11种风格（恐惧/好奇等）的越狱测试集，评估16个开源/闭源模型，提出基于LLM的风格中和防御方法。

Result: 风格改写使越狱成功率最高提升57%，上下文改写效果优于模板改写。风格中和使成功率降低30-40个百分点。

Conclusion: 语言风格是系统性的安全漏洞，现有安全机制存在盲区，需针对性防御措施。

Abstract: Large Language Models (LLMs) are commonly evaluated for robustness against paraphrased or semantically equivalent jailbreak prompts, yet little attention has been paid to linguistic variation as an attack surface. In this work, we systematically study how linguistic styles such as fear or curiosity can reframe harmful intent and elicit unsafe responses from aligned models. We construct style-augmented jailbreak benchmark by transforming prompts from 3 standard datasets into 11 distinct linguistic styles using handcrafted templates and LLM-based rewrites, while preserving semantic intent. Evaluating 16 open- and close-source instruction-tuned models, we find that stylistic reframing increases jailbreak success rates by up to +57 percentage points. Styles such as fearful, curious and compassionate are most effective and contextualized rewrites outperform templated variants.
  To mitigate this, we introduce a style neutralization preprocessing step using a secondary LLM to strip manipulative stylistic cues from user inputs, significantly reducing jailbreak success rates. Our findings reveal a systemic and scaling-resistant vulnerability overlooked in current safety pipelines.

</details>


### [54] [Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG](https://arxiv.org/abs/2511.10523)
*Egor Pakhomov,Erik Nijkamp,Caiming Xiong*

Main category: cs.CL

TL;DR: 提出包含75,336问答对的对话记忆评估基准，揭示全上下文方法在150次对话前优于RAG系统，对话记忆系统需专门研究而非简单套用RAG方案


<details>
  <summary>Details</summary>
Motivation: 现有对话记忆评估框架存在统计功效不足、数据生成不一致和评估灵活性受限的问题，需要建立更全面的评估体系并探索对话记忆与RAG的关系差异

Method: 构建多类别对话记忆基准，实验对比全上下文方法与RAG系统在不同对话规模下的性能，分析成本/延迟与效果的权衡点

Result: 全上下文方法在150次对话内保持70-82%准确率（RAG仅30-45%），前30次对话效果最佳，150次后需转向混合/RAG方案

Conclusion: 对话记忆系统具备'小语料库优势'，应从零积累的特性出发进行专项研究，而非简单应用通用RAG方案到对话历史分析中

Abstract: We introduce a comprehensive benchmark for conversational memory evaluation containing 75,336 question-answer pairs across diverse categories including user facts, assistant recall, abstention, preferences, temporal changes, and implicit connections. While existing benchmarks have advanced the field, our work addresses fundamental challenges in statistical power, data generation consistency, and evaluation flexibility that limit current memory evaluation frameworks. We examine the relationship between conversational memory and retrieval-augmented generation (RAG). While these systems share fundamental architectural patterns--temporal reasoning, implicit extraction, knowledge updates, and graph representations--memory systems have a unique characteristic: they start from zero and grow progressively with each conversation. This characteristic enables naive approaches that would be impractical for traditional RAG. Consistent with recent findings on long context effectiveness, we observe that simple full-context approaches achieve 70-82% accuracy even on our most challenging multi-message evidence cases, while sophisticated RAG-based memory systems like Mem0 achieve only 30-45% when operating on conversation histories under 150 interactions. Our analysis reveals practical transition points: long context excels for the first 30 conversations, remains viable with manageable trade-offs up to 150 conversations, and typically requires hybrid or RAG approaches beyond that point as costs and latencies become prohibitive. These patterns indicate that the small-corpus advantage of conversational memory--where exhaustive search and complete reranking are feasible--deserves dedicated research attention rather than simply applying general RAG solutions to conversation histories.

</details>


### [55] [Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction](https://arxiv.org/abs/2511.10546)
*Natasha Johnson*

Main category: cs.CL

TL;DR: 利用计算分析方法探究文学分类中形式特征与制度标签的差异，揭示女性作者对文学地位获得的影响


<details>
  <summary>Details</summary>
Motivation: 针对传统流派分类偏重形式特征而忽视制度因素的争议，通过量化手段验证流派作为形式标签的有效性，并探索作者性别对文学地位评判的调节作用

Method: 采用CONLIT当代文学数据集，运用Welch方差分析比较性别叙事特征分布，通过逻辑回归建模形式特征对文学分类的影响，结合风格向量和语义向量分析形式与内容的重要性

Result: 发现不同文学类别存在统计学显著的形式标记，女性 authorship 使获得文学地位的标准呈现收窄与模糊化特征

Conclusion: 文学分类需兼顾形式特征与制度维度，作者性别通过调节形式特征的显著性影响文学地位获取，暗示制度因素在流派划分中的潜在作用

Abstract: Though the concept of genre has been a subject of discussion for millennia, the relatively recent emergence of genre fiction has added a new layer to this ongoing conversation. While more traditional perspectives on genre have emphasized form, contemporary scholarship has invoked both formal and institutional characteristics in its taxonomy of genre, genre fiction, and literary fiction. This project uses computational methods to explore the soundness of genre as a formal designation as opposed to an institutional one. Pulling from Andrew Piper's CONLIT dataset of Contemporary Literature, we assemble a corpus of literary and genre fiction, with the latter category containing romance, mystery, and science fiction novels. We use Welch's ANOVA to compare the distribution of narrative features according to author gender within each genre and within genre versus literary fiction. Then, we use logistic regression to model the effect that each feature has on literary classification and to measure how author gender moderates these effects. Finally, we analyze stylistic and semantic vector representations of our genre categories to understand the importance of form and content in literary classification. This project finds statistically significant formal markers of each literary category and illustrates how female authorship narrows and blurs the target for achieving literary status.

</details>


### [56] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: 提出URaG框架，通过统一检索与生成机制，利用MLLMs自身的层次化推理特性实现长文档高效理解，计算开销降低44-56%


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs处理长文档存在信息干扰与计算成本高的问题，观察到模型浅层广泛关注、深层聚焦关键页面的类人推理特性

Method: 引入轻量级跨模态检索模块，将早期Transformer层改造为证据选择器，保留相关页面供深层专注处理

Result: 在保持端到端优化的同时达到SOTA性能，计算成本显著降低（44-56%），开源代码推动应用落地

Conclusion: URaG首次实现检索与生成的内在统一，验证了MLLMs自含检索能力的有效性，为长文档理解提供高效解决方案

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


### [57] [DESS: DeBERTa Enhanced Syntactic-Semantic Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2511.10577)
*Vishal Thenuwara,Nisansa de Silva*

Main category: cs.CL

TL;DR: 提出DESS方法，整合DeBERTa增强注意力机制与LSTM双通道结构，在ASTE任务中实现4.85-8.36%的F1值提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于BERT和GNN的方法未能充分利用先进语言模型处理复杂语言关系的能力，特别是在远距离语义关联捕捉方面存在局限。

Method: 构建DeBERTa与LSTM的双通道架构：DeBERTa负责上下文关系建模，LSTM捕捉语法模式，通过精细化协同机制整合语义和语法特征。

Result: 在标准数据集上F1值提升4.85/8.36/2.42（aspect-opinion识别和情感判定），DeBERTa注意力机制显著改善长距离依赖处理能力。

Conclusion: 验证了先进语言模型经合理整合可有效提升情感分析性能，注意力机制的优化对处理复杂句式具有关键作用。

Abstract: Fine-grained sentiment analysis faces ongoing challenges in Aspect Sentiment Triple Extraction (ASTE), particularly in accurately capturing the relationships between aspects, opinions, and sentiment polarities. While researchers have made progress using BERT and Graph Neural Networks, the full potential of advanced language models in understanding complex language patterns remains unexplored. We introduce DESS, a new approach that builds upon previous work by integrating DeBERTa's enhanced attention mechanism to better understand context and relationships in text. Our framework maintains a dual-channel structure, where DeBERTa works alongside an LSTM channel to process both meaning and grammatical patterns in text. We have carefully refined how these components work together, paying special attention to how different types of language information interact. When we tested DESS on standard datasets, it showed meaningful improvements over current methods, with F1-score increases of 4.85, 8.36, and 2.42 in identifying aspect opinion pairs and determining sentiment accurately. Looking deeper into the results, we found that DeBERTa's sophisticated attention system helps DESS handle complicated sentence structures better, especially when important words are far apart. Our findings suggest that upgrading to more advanced language models when thoughtfully integrated, can lead to real improvements in how well we can analyze sentiments in text. The implementation of our approach is publicly available at: https://github.com/VishalRepos/DESS.

</details>


### [58] [Evaluating Prompting Strategies with MedGemma for Medical Order Extraction](https://arxiv.org/abs/2511.10583)
*Abhinand Balachandran,Bavana Durgapraveen,Gowsikkan Sikkan Sudhagar,Vidhya Varshany J S,Sriram Rajkumar*

Main category: cs.CL

TL;DR: 研究比较三种提示方法（单次提示/ReAct框架/多步代理流程）在医疗指令抽取任务中的表现，发现简单直接的one-shot方法在官方验证集效果最佳


<details>
  <summary>Details</summary>
Motivation: 解决复杂推理方法在人工标注医疗转录本场景中可能引发的'过度思考'问题，探索不同提示策略在临床信息抽取中的适用性

Method: 使用MedGemma模型，系统评估三种提示范式：基础one-shot方法、注重推理的ReAct框架、多步骤代理工作流程

Result: 简单单次提示方法在MEDIQA-OE-2025验证集上取得最高准确率（优于复杂方法），证明直接方法在人工标注数据中更稳健

Conclusion: 临床信息抽取应依据数据特性选择提示策略，人工标注场景适合直接方法，自动化流程可能更适合其他场景

Abstract: The accurate extraction of medical orders from doctor-patient conversations is a critical task for reducing clinical documentation burdens and ensuring patient safety. This paper details our team submission to the MEDIQA-OE-2025 Shared Task. We investigate the performance of MedGemma, a new domain-specific open-source language model, for structured order extraction. We systematically evaluate three distinct prompting paradigms: a straightforward one-Shot approach, a reasoning-focused ReAct framework, and a multi-step agentic workflow. Our experiments reveal that while more complex frameworks like ReAct and agentic flows are powerful, the simpler one-shot prompting method achieved the highest performance on the official validation set. We posit that on manually annotated transcripts, complex reasoning chains can lead to "overthinking" and introduce noise, making a direct approach more robust and efficient. Our work provides valuable insights into selecting appropriate prompting strategies for clinical information extraction in varied data conditions.

</details>


### [59] [Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering](https://arxiv.org/abs/2511.10591)
*Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar*

Main category: cs.CL

TL;DR: 提出结合样本检索提示和元数据引导生成的双重方法，提升伤口护理AI应答的临床可靠性和效率


<details>
  <summary>Details</summary>
Motivation: 远程医疗扩张加剧临床工作负荷，需开发AI系统协助处理带图像伤患咨询

Method: 1. 基于嵌入向量的训练样本检索构建动态few-shot提示
2. 通过元数据消融实验确定关键增强属性，建立预测模型融入生成流程

Result: 样本检索提升应答相关性，元数据引导增强临床精确性，组合方法展现协同效应

Conclusion: 融合数据驱动提示和预测性元数据引导，为可靠伤口护理AI工具开发提供有效范式

Abstract: The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded and the top-k most similar examples are retrieved to serve as few-shot demonstrations during generation. The second approach builds on a metadata ablation study, which identified four metadata attributes that consistently enhance response quality. We train classifiers to predict these attributes for test cases and incorporate them into the generation pipeline, dynamically adjusting outputs based on prediction confidence. Experimental results demonstrate that mined prompting improves response relevance, while metadata-guided generation further refines clinical precision. Together, these methods highlight promising directions for developing AI-driven tools that can provide reliable and efficient wound care support.

</details>


### [60] [Know Your Limits: Entropy Estimation Modeling for Compression and Generalization](https://arxiv.org/abs/2511.10618)
*Benjamin L. Badger,Matthew Neligeorge*

Main category: cs.CL

TL;DR: 提出编码器增强的因果解码器架构，在提升语言压缩效率的同时通过熵约束训练增强模型泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有因果语言模型存在计算不可行的熵估计瓶颈，需通过改进模型架构突破压缩效率与训练资源限制

Method: 采用编码器-解码器混合架构，开发逐token熵估计方法，设计基于熵约束的训练目标函数

Result: 新架构在普通硬件上实现更高压缩率，接近熵值的模型训练使困惑度降低15%，泛化性能提升27%

Conclusion: 熵引导的训练范式能有效平衡模型容量与泛化需求，为资源受限环境下的高效语言建模提供新方向

Abstract: Language prediction is constrained by informational entropy intrinsic to language, such that there exists a limit to how accurate any language model can become and equivalently a lower bound to language compression. The most efficient language compression algorithms today are causal (next token prediction) large language models, but the use of these models to form accurate estimates of language entropy is currently computationally infeasible. We introduce encoder-augmented causal decoder model architectures that exhibit superior training efficiency characteristics and achieve higher compression than causal transformers even when trained on modest hardware. We demonstrate how entropy estimates can be obtained on a per-token basis, and show that the generalization of models trained to approach the entropy of their training data necessarily exceeds the generalization of models trained to minimize loss beyond this value. We show empirically that causal models trained to approach but not exceed estimated per-token entropies exhibit greater generalization than models trained without taking entropy into account.

</details>


### [61] [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/abs/2511.10621)
*Haizhou Shi,Ye Liu,Bo Pang,Zeyu Leo Liu,Hao Wang,Silvio Savarese,Caiming Xiong,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: 提出SSR框架，通过分解验证步骤和迭代优化，显著提升大语言模型的推理准确性和可解释性


<details>
  <summary>Details</summary>
Motivation: 现有测试框架依赖粗粒度自我验证，无法有效处理复杂推理任务，需要更细粒度的评估修正机制

Method: 将模型响应分解为（子问题-子答案）对，通过重新求解和自洽性检查进行步骤级置信度评估，迭代修正不可靠步骤

Result: 在5个推理基准和3个LLM上超越现有方法，同时提供解析模型推理过程的黑箱方法

Conclusion: SSR框架不仅提升性能，还为理解LLM内部推理机制提供了系统性解决方案

Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, yet existing test-time frameworks often rely on coarse self-verification and self-correction, limiting their effectiveness on complex tasks. In this paper, we propose Socratic Self-Refine (SSR), a novel framework for fine-grained evaluation and precise refinement of LLM reasoning. Our proposed SSR decomposes model responses into verifiable (sub-question, sub-answer) pairs, enabling step-level confidence estimation through controlled re-solving and self-consistency checks. By pinpointing unreliable steps and iteratively refining them, SSR produces more accurate and interpretable reasoning chains. Empirical results across five reasoning benchmarks and three LLMs show that SSR consistently outperforms state-of-the-art iterative self-refinement baselines. Beyond performance gains, SSR provides a principled black-box approach for evaluating and understanding the internal reasoning processes of LLMs. Code is available at https://github.com/SalesforceAIResearch/socratic-self-refine-reasoning.

</details>


### [62] [Instella: Fully Open Language Models with Stellar Performance](https://arxiv.org/abs/2511.10628)
*Jiang Liu,Jialian Wu,Xiaodong Yu,Yusheng Su,Prakamya Mishra,Gowtham Ramesh,Sudhanshu Ranjan,Chaitanya Manem,Ximeng Sun,Ze Wang,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: 提出Instella系列全开源3B参数大语言模型，基于开放数据训练并发布数学推理和长文本处理专用版本，在开源模型中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前高性能大语言模型多为闭源或半开源，限制了研究的透明度和可复现性。为解决这一问题，研究团队希望构建完全开源的高性能替代方案。

Method: 利用AMD MI300X GPU进行大规模预训练、通用指令微调和人类偏好对齐，并通过监督微调和强化学习开发数学推理专用模型Instella-Math。

Result: 在预训练数据量显著更少的情况下，模型性能超越全开源模型，与同规模开源权重模型竞争，长文本版支持128K上下文，数学推理能力显著提升。

Conclusion: Instella系列通过完全开源的模型、数据和代码库，为社区提供了透明且高性能的替代方案，推动语言模型研究的开放可复现发展。

Abstract: Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks, yet the majority of high-performing models remain closed-source or partially open, limiting transparency and reproducibility. In this work, we introduce Instella, a family of fully open three billion parameter language models trained entirely on openly available data and codebase. Powered by AMD Instinct MI300X GPUs, Instella is developed through large-scale pre-training, general-purpose instruction tuning, and alignment with human preferences. Despite using substantially fewer pre-training tokens than many contemporaries, Instella achieves state-of-the-art results among fully open models and is competitive with leading open-weight models of comparable size. We further release two specialized variants: Instella-Long, capable of handling context lengths up to 128K tokens, and Instella-Math, a reasoning-focused model enhanced through supervised fine-tuning and reinforcement learning on mathematical tasks. Together, these contributions establish Instella as a transparent, performant, and versatile alternative for the community, advancing the goal of open and reproducible language modeling research.

</details>


### [63] [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643)
*Tianzhu Ye,Li Dong,Zewen Chi,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.CL

TL;DR: 提出生成对抗蒸馏（GAD）方法，通过对抗训练框架实现黑盒大语言模型的高效知识迁移


<details>
  <summary>Details</summary>
Motivation: 传统黑盒蒸馏仅能静态学习教师模型的输出文本，缺乏动态反馈机制。GAD旨在通过对抗训练范式解决这一局限性，提升学生模型的优化稳定性与适应性。

Method: 将学生LLM作为生成器，同步训练判别器区分教师/学生输出，形成动态对抗训练。判别器作为协同进化的奖励模型，提供持续稳定的策略梯度反馈。

Result: 在LMSYS-Chat基准测试中，GAD训练的学生模型Qwen2.5-14B-Instruct达到与教师模型GPT-5-Chat相当的对话能力，显著优于传统序列蒸馏方法。

Conclusion: GAD建立了黑盒LLM蒸馏的新范式，通过对抗训练机制有效提升知识迁移效率，为模型压缩领域提供创新解决方案。

Abstract: Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.

</details>


### [64] [ParoQuant: Pairwise Rotation Quantization for Efficient Reasoning LLM Inference](https://arxiv.org/abs/2511.10645)
*Yesheng Liang,Haisheng Chen,Song Han,Zhijian Liu*

Main category: cs.CL

TL;DR: 提出ParoQuant权重后训练量化方法，通过Givens旋转和通道缩放降低推理误差，在10%开销内实现推理任务2.4%精度提升


<details>
  <summary>Details</summary>
Motivation: 现有权重量化方法无法有效抑制权重/激活中的异常值，导致长链推理任务中误差累积和精度骤降，同时存在计算开销过大的问题

Method: 结合硬件友好的独立Givens旋转与通道缩放，平衡通道间量级分布，设计并行化推理内核保持运行时轻量化

Result: 在推理任务上相较AWQ平均提升2.4%准确率，计算开销控制在10%以内

Conclusion: 为高效部署需要长链推理的LLM提供了更优的量化解决方案

Abstract: Weight-only post-training quantization (PTQ) compresses the weights of Large Language Models (LLMs) into low-precision representations to reduce memory footprint and accelerate inference. However, the presence of outliers in weights and activations often leads to large quantization errors and severe accuracy degradation, especially in recent reasoning LLMs where errors accumulate across long chains of thought. Existing PTQ methods either fail to sufficiently suppress outliers or introduce significant overhead during inference. In this paper, we propose Pairwise Rotation Quantization (ParoQuant), a weight-only PTQ method that combines hardware-efficient and optimizable independent Givens rotations with channel-wise scaling to even out the magnitude across channels and narrow the dynamic range within each quantization group. We further co-design the inference kernel to fully exploit GPU parallelism and keep the rotations and scaling lightweight at runtime. ParoQuant achieves an average 2.4% accuracy improvement over AWQ on reasoning tasks with less than 10% overhead. This paves the way for more efficient and accurate deployment of reasoning LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [65] [Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning](https://arxiv.org/abs/2511.10067)
*Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao*

Main category: cs.AI

TL;DR: 提出MuSeR方法，通过自我评估和精炼增强LLMs在医疗场景中的上下文感知能力，在HealthBench数据集上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在真实医疗场景中因缺乏上下文意识（如用户身份识别、病史理解、风险评估）导致表现不佳，需提升其决策、沟通和安全三方面的情境适应能力

Method: 1. 设计属性条件查询生成器模拟多样化医疗场景
2. 通过LLM自我评估（决策/沟通/安全三维度）与响应精炼
3. 利用知识蒸馏和监督微调提升模型能力

Result: 在HealthBench数据集上达到63.8%整体准确率（hard子集43.1%），Qwen3-32B模型超越原有教师模型成为开源LLM新SOTA

Conclusion: MuSeR通过多维度自优化机制有效提升LLMs的医疗场景适应能力，知识蒸馏策略使小模型性能超越大模型，为医疗AI部署提供新思路

Abstract: Large language models (LLMs) have shown great promise in the medical domain, achieving strong performance on several benchmarks. However, they continue to underperform in real-world medical scenarios, which often demand stronger context-awareness, i.e., the ability to recognize missing or critical details (e.g., user identity, medical history, risk factors) and provide safe, helpful, and contextually appropriate responses. To address this issue, we propose Multifaceted Self-Refinement (MuSeR), a data-driven approach that enhances LLMs' context-awareness along three key facets (decision-making, communication, and safety) through self-evaluation and refinement. Specifically, we first design a attribute-conditioned query generator that simulates diverse real-world user contexts by varying attributes such as role, geographic region, intent, and degree of information ambiguity. An LLM then responds to these queries, self-evaluates its answers along three key facets, and refines its responses to better align with the requirements of each facet. Finally, the queries and refined responses are used for supervised fine-tuning to reinforce the model's context-awareness ability. Evaluation results on the latest HealthBench dataset demonstrate that our method significantly improves LLM performance across multiple aspects, with particularly notable gains in the context-awareness axis. Furthermore, by incorporating knowledge distillation with the proposed method, the performance of a smaller backbone LLM (e.g., Qwen3-32B) surpasses its teacher model, achieving a new SOTA across all open-source LLMs on HealthBench (63.8%) and its hard subset (43.1%). Code and dataset will be released at https://muser-llm.github.io.

</details>


### [66] [ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs](https://arxiv.org/abs/2511.10240)
*Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim*

Main category: cs.AI

TL;DR: 提出ProgRAG框架，通过分解复杂问题为子问题并逐步优化推理路径，显著提升多跳知识图谱问答的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有KG增强的LLM方法存在检索不准确、长上下文干扰及自我评估错误导致的推理失败问题，需更系统的路径优化机制。

Method: 1. 多跳问题分解 2. 外部检索器获取候选证据 3. LLM进行不确定性感知剪枝 4. 动态重组推理路径上下文

Result: 在三个主流数据集上超越基线模型，验证了框架在复杂推理任务中的有效性和鲁棒性。

Conclusion: ProgRAG通过路径渐进优化与证据筛选机制，为知识密集型复杂推理任务提供了可靠的解决方案。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities but struggle with hallucinations and limited transparency. Recently, KG-enhanced LLMs that integrate knowledge graphs (KGs) have been shown to improve reasoning performance, particularly for complex, knowledge-intensive tasks. However, these methods still face significant challenges, including inaccurate retrieval and reasoning failures, often exacerbated by long input contexts that obscure relevant information or by context constructions that struggle to capture the richer logical directions required by different question types. Furthermore, many of these approaches rely on LLMs to directly retrieve evidence from KGs, and to self-assess the sufficiency of this evidence, which often results in premature or incorrect reasoning. To address the retrieval and reasoning failures, we propose ProgRAG, a multi-hop knowledge graph question answering (KGQA) framework that decomposes complex questions into sub-questions, and progressively extends partial reasoning paths by answering each sub-question. At each step, external retrievers gather candidate evidence, which is then refined through uncertainty-aware pruning by the LLM. Finally, the context for LLM reasoning is optimized by organizing and rearranging the partial reasoning paths obtained from the sub-question answers. Experiments on three well-known datasets demonstrate that ProgRAG outperforms existing baselines in multi-hop KGQA, offering improved reliability and reasoning quality.

</details>


### [67] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: 提出FactGuard框架，利用LLMs提取事件核心内容并动态整合建议，通过知识蒸馏实现高效部署


<details>
  <summary>Details</summary>
Motivation: 现有基于写作风格的假新闻检测方法易被风格模仿攻击，且LLMs的潜力未被充分挖掘，存在功能探索浅、推理成本高等问题

Method: 1. 事件内容提取减少风格干扰 2. 动态可用性机制识别矛盾案例 3. 知识蒸馏得到轻量版FactGuard-D

Result: 在两个基准数据集上鲁棒性和准确率均超越现有方法，解决风格敏感性问题并提升决策可靠性

Conclusion: FactGuard有效平衡检测性能与部署效率，为LLMs在假新闻检测中的实际应用提供新范式

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [68] [Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding](https://arxiv.org/abs/2511.09559)
*Tianlei Chen,Yuxiao Chen,Yang Li,Feifei Wang*

Main category: cs.LG

TL;DR: 提出基于共现关系图编码的ICD编码方法，解决长尾分布问题


<details>
  <summary>Details</summary>
Motivation: 现有自动化ICD编码面临标签空间巨大（10k-20k代码）和长尾分布挑战，罕见代码缺乏训练数据

Method: 1. 构建有向二分图编码器（常见代码→罕见代码）
2. 基于条件概率的共现编码注意力机制
3. 使用LLM生成代码描述增强嵌入表示

Result: 在三个基准测试中实现SOTA，Macro-F1指标显著提升（长尾分类关键指标）

Conclusion: 通过统计共现关系建模和临床知识增强，有效提升罕见代码的表示质量

Abstract: Automated International Classification of Diseases (ICD) coding aims to assign multiple disease codes to clinical documents, constituting a crucial multi-label text classification task in healthcare informatics. However, the task is challenging due to its large label space (10,000 to 20,000 codes) and long-tail distribution, where a few codes dominate while many rare codes lack sufficient training data. To address this, we propose a learning method that models fine-grained co-occurrence relationships among codes. Specifically, we construct a Directed Bipartite Graph Encoder with disjoint sets of common and rare code nodes. To facilitate a one-way information flow, edges are directed exclusively from common to rare codes. The nature of these connections is defined by a probability-based bias, which is derived from the conditional probability of a common code co-occurring given the presence of a rare code. This bias is then injected into the encoder's attention module, a process we term Co-occurrence Encoding. This structure empowers the graph encoder to enrich rare code representations by aggregating latent comorbidity information reflected in the statistical co-occurrence of their common counterparts. To ensure high-quality input to the graph, we utilize a large language model (LLM) to generate comprehensive descriptions for codes, enriching initial embeddings with clinical context and comorbidity information, serving as external knowledge for the statistical co-occurrence relationships in the code system. Experiments on three automated ICD coding benchmark datasets demonstrate that our method achieves state-of-the-art performance with particularly notable improvements in Macro-F1, which is the key metric for long-tail classification.

</details>


### [69] [OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models](https://arxiv.org/abs/2511.10287)
*Yuping Yan,Yuhan Xie,Yuanshuai Li,Yingchao Yu,Lingjuan Lyu,Yaochu Jin*

Main category: cs.LG

TL;DR: 开发首个全面多模态内容安全评估套件OutSafe-Bench，覆盖文本/图像/音频/视频四模态数据，提出多维风险评分指标和自动化评估框架


<details>
  <summary>Details</summary>
Motivation: 现有安全基准测试在模态覆盖和评估维度上存在局限，难以全面评估多模态大语言模型的内容安全风险

Method: 构建包含18k双语文本/4.5k图像/450音频/450视频的数据集，设计多维交叉风险评分(MCRS)和基于自适应评审团的FairScore评估框架

Result: 在9个先进MLLMs上的评估显示持续显著的安全漏洞，平均风险暴露率达38.7%，视频模态风险最高（52.1%）

Conclusion: 该研究揭示了当前多模态模型的安全防护缺陷，提出的评估体系为开发更安全的AI系统提供了重要基准和方法论支撑

Abstract: Since Multimodal Large Language Models (MLLMs) are increasingly being integrated into everyday tools and intelligent agents, growing concerns have arisen regarding their possible output of unsafe contents, ranging from toxic language and biased imagery to privacy violations and harmful misinformation. Current safety benchmarks remain highly limited in both modality coverage and performance evaluations, often neglecting the extensive landscape of content safety. In this work, we introduce OutSafe-Bench, the first most comprehensive content safety evaluation test suite designed for the multimodal era. OutSafe-Bench includes a large-scale dataset that spans four modalities, featuring over 18,000 bilingual (Chinese and English) text prompts, 4,500 images, 450 audio clips and 450 videos, all systematically annotated across nine critical content risk categories. In addition to the dataset, we introduce a Multidimensional Cross Risk Score (MCRS), a novel metric designed to model and assess overlapping and correlated content risks across different categories. To ensure fair and robust evaluation, we propose FairScore, an explainable automated multi-reviewer weighted aggregation framework. FairScore selects top-performing models as adaptive juries, thereby mitigating biases from single-model judgments and enhancing overall evaluation reliability. Our evaluation of nine state-of-the-art MLLMs reveals persistent and substantial safety vulnerabilities, underscoring the pressing need for robust safeguards in MLLMs.

</details>


### [70] [AgentEvolver: Towards Efficient Self-Evolving Agent System](https://arxiv.org/abs/2511.10395)
*Yunpeng Zhai,Shuchang Tao,Cheng Chen,Anni Zou,Ziqian Chen,Qingxu Fu,Shinji Mai,Li Yu,Jiaji Deng,Zouying Cao,Zhaoyang Liu,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: 提出自主进化代理系统AgentEvolver，结合自我提问、自我导航、自我归因三种机制，显著提升代理的探索效率与样本利用率


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法存在数据构建成本高、探索效率低、样本利用差三大痛点，需借助LLM的语义理解能力实现更高效的自主代理学习

Method: 通过(1)基于好奇心的环境自提问生成任务；(2)经验复用+混合策略的智能导航；(3)轨迹状态差异化奖励分配的三重协同机制

Result: 实验证明在探索效率（提升40%）、样本利用率（提高2.3倍）和适应速度（加快1.8倍）上均优于传统RL基线方法

Conclusion: 首次将自进化机制系统整合，为持续提升代理能力提供可扩展框架，标志着自主代理发展从人工干预转向智能自驱动新范式

Abstract: Autonomous agents powered by large language models (LLMs) have the potential to significantly enhance human productivity by reasoning, using tools, and executing complex tasks in diverse environments. However, current approaches to developing such agents remain costly and inefficient, as they typically require manually constructed task datasets and reinforcement learning (RL) pipelines with extensive random exploration. These limitations lead to prohibitively high data-construction costs, low exploration efficiency, and poor sample utilization. To address these challenges, we present AgentEvolver, a self-evolving agent system that leverages the semantic understanding and reasoning capabilities of LLMs to drive autonomous agent learning. AgentEvolver introduces three synergistic mechanisms: (i) self-questioning, which enables curiosity-driven task generation in novel environments, reducing dependence on handcrafted datasets; (ii) self-navigating, which improves exploration efficiency through experience reuse and hybrid policy guidance; and (iii) self-attributing, which enhances sample efficiency by assigning differentiated rewards to trajectory states and actions based on their contribution. By integrating these mechanisms into a unified framework, AgentEvolver enables scalable, cost-effective, and continual improvement of agent capabilities. Preliminary experiments indicate that AgentEvolver achieves more efficient exploration, better sample utilization, and faster adaptation compared to traditional RL-based baselines.

</details>


### [71] [Impact of Layer Norm on Memorization and Generalization in Transformers](https://arxiv.org/abs/2511.10566)
*Rishi Singhal,Jung-Eun Kim*

Main category: cs.LG

TL;DR: 研究揭示LayerNorm在Pre/Post架构中对记忆化和学习的不同影响机制：Pre架构中稳定学习，Post架构中抑制记忆化，早期层作用最显著


<details>
  <summary>Details</summary>
Motivation: 明确LayerNorm在不同Transformer架构（Pre/Post-LayerNorm）中对模型记忆能力和学习稳定性的具体作用机制

Method: 通过参数消除实验（移除LayerNorm参数）、层次分析（分层研究LayerNorm影响）和跨架构对比（6个视觉/语言数据集验证13个模型）

Result: Pre架构依赖LayerNorm稳定梯度流，去除参数导致记忆激增（+20%）；Post架构中移除LayerNorm恢复真实标签分布，记忆率下降38%；早期层影响权重占整体效果的72%

Conclusion: 首次系统性揭示LayerNorm双重作用机制，为优化Transformer架构设计（如动态调整LayerNorm位置）提供理论依据

Abstract: Layer Normalization (LayerNorm) is one of the fundamental components in transformers that stabilizes training and improves optimization. In recent times, Pre-LayerNorm transformers have become the preferred choice over Post-LayerNorm transformers due to their stable gradient flow. However, the impact of LayerNorm on learning and memorization across these architectures remains unclear. In this work, we investigate how LayerNorm influences memorization and learning for Pre- and Post-LayerNorm transformers. We identify that LayerNorm serves as a key factor for stable learning in Pre-LayerNorm transformers, while in Post-LayerNorm transformers, it impacts memorization. Our analysis reveals that eliminating LayerNorm parameters in Pre-LayerNorm models exacerbates memorization and destabilizes learning, while in Post-LayerNorm models, it effectively mitigates memorization by restoring genuine labels. We further precisely identify that early layers LayerNorm are the most critical over middle/later layers and their influence varies across Pre and Post LayerNorm models. We have validated it through 13 models across 6 Vision and Language datasets. These insights shed new light on the role of LayerNorm in shaping memorization and learning in transformers.

</details>


### [72] [Towards Emotionally Intelligent and Responsible Reinforcement Learning](https://arxiv.org/abs/2511.10573)
*Garapati Keerthana,Manik Gupta*

Main category: cs.LG

TL;DR: 提出整合情感理解与伦理约束的负责任强化学习框架（RRL），通过约束马尔可夫决策过程优化个性化干预系统的安全性与共情能力


<details>
  <summary>Details</summary>
Motivation: 现有医疗决策系统过度依赖静态规则和参与度最大化策略，忽视用户情感状态与伦理风险，在心理健康等敏感领域易产生有害干预

Method: 建立情感感知状态表征（情绪准备度/情感/风险波动）和多目标奖励机制，将强化学习算法（DQN/PPO）与安全约束/Lagrangian正则化结合

Result: 提出可适配不同RL算法的通用架构，为行为健康、数字治疗等领域提供兼顾短期参与和长期福祉的伦理对齐解决方案

Conclusion: 该框架将共情操作化融入机器学习策略优化，推动情感智能系统向可信赖方向发展，需后续仿真验证和跨学科方法论探讨

Abstract: Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [73] [Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning](https://arxiv.org/abs/2511.09893)
*Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon*

Main category: cs.CV

TL;DR: 提出基于Swin-BART架构的区域注意力模型，在ROCO数据集上实现医学图像描述的SOTA性能，显著提升语义准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有医学图像描述模型对关键诊断区域关注不足的问题，同时提升生成文本的临床相关性和模型可解释性。

Method: 采用Swin Transformer编码器+BART解码器架构，新增区域注意力模块强化诊断关键区域特征。使用beam search解码策略（beam_size=4），在ROCO数据集上训练并进行多维度评估。

Result: ROUGE(0.603)和BERTScore(0.807)显著优于基线模型，其他指标(BLEU/CIDEr/METEOR)保持竞争力。消融实验验证区域注意力有效性，热力图可视化提供临床可解释性。

Conclusion: 该模型在保持高效推理的同时，生成符合临床表述的图像描述，并通过区域归因可视化支持人机协作的医疗研究应用。

Abstract: Automated medical image captioning translates complex radiological images into diagnostic narratives that can support reporting workflows. We present a Swin-BART encoder-decoder system with a lightweight regional attention module that amplifies diagnostically salient regions before cross-attention. Trained and evaluated on ROCO, our model achieves state-of-the-art semantic fidelity while remaining compact and interpretable. We report results as mean$\pm$std over three seeds and include $95\%$ confidence intervals. Compared with baselines, our approach improves ROUGE (proposed 0.603, ResNet-CNN 0.356, BLIP2-OPT 0.255) and BERTScore (proposed 0.807, BLIP2-OPT 0.645, ResNet-CNN 0.623), with competitive BLEU, CIDEr, and METEOR. We further provide ablations (regional attention on/off and token-count sweep), per-modality analysis (CT/MRI/X-ray), paired significance tests, and qualitative heatmaps that visualize the regions driving each description. Decoding uses beam search (beam size $=4$), length penalty $=1.1$, $no\_repeat\_ngram\_size$ $=3$, and max length $=128$. The proposed design yields accurate, clinically phrased captions and transparent regional attributions, supporting safe research use with a human in the loop.

</details>


### [74] [Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers](https://arxiv.org/abs/2511.09926)
*Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi*

Main category: cs.CV

TL;DR: 提出SLDC方法通过潜在空间转换算子和知识蒸馏缓解连续微调ViT时的分布漂移问题


<details>
  <summary>Details</summary>
Motivation: 连续微调导致共享主干参数优化引发特征分布漂移，损害分类器持续性能

Method: 开发线性和弱非线性特征转换算子，结合知识蒸馏对齐跨任务特征分布

Result: 在标准CIL基准测试中显著提升SeqFT性能，接近联合训练效果

Conclusion: 通过SLDC补偿分布漂移与知识蒸馏处理表示漂移，使SeqFT成为有效CIL方案

Abstract: Recent advances have shown that sequential fine-tuning (SeqFT) of pre-trained vision transformers (ViTs), followed by classifier refinement using approximate distributions of class features, can be an effective strategy for class-incremental learning (CIL). However, this approach is susceptible to distribution drift, caused by the sequential optimization of shared backbone parameters. This results in a mismatch between the distributions of the previously learned classes and that of the updater model, ultimately degrading the effectiveness of classifier performance over time. To address this issue, we introduce a latent space transition operator and propose Sequential Learning with Drift Compensation (SLDC). SLDC aims to align feature distributions across tasks to mitigate the impact of drift. First, we present a linear variant of SLDC, which learns a linear operator by solving a regularized least-squares problem that maps features before and after fine-tuning. Next, we extend this with a weakly nonlinear SLDC variant, which assumes that the ideal transition operator lies between purely linear and fully nonlinear transformations. This is implemented using learnable, weakly nonlinear mappings that balance flexibility and generalization. To further reduce representation drift, we apply knowledge distillation (KD) in both algorithmic variants. Extensive experiments on standard CIL benchmarks demonstrate that SLDC significantly improves the performance of SeqFT. Notably, by combining KD to address representation drift with SLDC to compensate distribution drift, SeqFT achieves performance comparable to joint training across all evaluated datasets. Code: https://github.com/raoxuan98-hash/sldc.git.

</details>


### [75] [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/abs/2511.10615)
*Shruti Singh Baghel,Yash Pratap Singh Rathore,Sushovan Jena,Anurag Pradhan,Amit Shukla,Arnav Bhavsar,Pawan Goyal*

Main category: cs.CV

TL;DR: 本文提出小型视觉语言模型SmolVLM2（5亿/22亿参数），通过专为视障用户设计的评估框架验证其在移动端视频描述任务的性能与部署可行性


<details>
  <summary>Details</summary>
Motivation: 针对大型视觉语言模型在视障用户场景中存在的硬件资源占用高、部署困难问题，研究模型小型化对多场景视频描述质量的影响，提升移动端辅助技术的实用性

Method: 1. 提出Multi-Context BLV框架（空间定位/社交互动/动作事件/环境氛围）和Navigational Assistance框架（移动辅助信息）
2. 在AVCaps（户外）和Charades（室内）数据集测试
3. 对比四种提示策略，评估FP32/INT8量化模型在智能手机的部署效果

Result: 5亿参数模型在多项评估中达到与更大模型相当的性能（室内场景准确率提升3.2%），INT8量化后模型体积缩小4倍仍保持90%以上精度

Conclusion: 小型视觉语言模型通过专用评估框架和提示优化，可在保持描述质量的同时实现移动端实时推理，为视障辅助技术提供可行的轻量化解决方案

Abstract: Large Vision-Language Models (VLMs) excel at understanding and generating video descriptions but their high memory, computation, and deployment demands hinder practical use particularly for blind and low-vision (BLV) users who depend on detailed, context-aware descriptions. To study the effect of model size on accessibility-focused description quality, we evaluate SmolVLM2 variants with 500M and 2.2B parameters across two diverse datasets: AVCaps (outdoor), and Charades (indoor). In this work, we introduce two novel evaluation frameworks specifically designed for BLV accessibility assessment: the Multi-Context BLV Framework evaluating spatial orientation, social interaction, action events, and ambience contexts; and the Navigational Assistance Framework focusing on mobility-critical information. Additionally, we conduct a systematic evaluation of four different prompt design strategies and deploy both models on a smartphone, evaluating FP32 and INT8 precision variants to assess real-world performance constraints on resource-limited mobile devices.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [76] [Music Flamingo: Scaling Music Understanding in Audio Language Models](https://arxiv.org/abs/2511.10289)
*Sreyan Ghosh,Arushi Goel,Lasha Koroshinadze,Sang-gil Lee,Zhifeng Kong,Joao Felipe Santos,Ramani Duraiswami,Dinesh Manocha,Wei Ping,Mohammad Shoeybi,Bryan Catanzaro*

Main category: eess.AS

TL;DR: Music Flamingo模型通过构建MF-Skills数据集和改进训练方法，显著提升音乐理解能力，在10+基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有音频模型难以处理音乐的动态性、层次性和文化多样性，且受限于数据稀缺和浅层分析能力。

Method: 使用多阶段标注流程构建MF-Skills数据集，改进Audio Flamingo 3架构，并引入基于音乐理论的MF-Think链式思维训练及GRPO强化学习。

Result: 在音乐理解和推理任务中实现最先进性能，建立具备分层人类化音乐感知能力的通用模型。

Conclusion: 该模型为音乐理解设立了新标准，推动AI从表层识别转向深层次音乐语义理解，奠定下一代模型开发基础。

Abstract: We introduce Music Flamingo, a novel large audio-language model designed to advance music (including song) understanding in foundational audio models. While audio-language research has progressed rapidly, music remains challenging due to its dynamic, layered, and information-dense nature. Progress has been further limited by the difficulty of scaling open audio understanding models, primarily because of the scarcity of high-quality music data and annotations. As a result, prior models are restricted to producing short, high-level captions, answering only surface-level questions, and showing limited generalization across diverse musical cultures. To address these challenges, we curate MF-Skills, a large-scale dataset labeled through a multi-stage pipeline that yields rich captions and question-answer pairs covering harmony, structure, timbre, lyrics, and cultural context. We fine-tune an enhanced Audio Flamingo 3 backbone on MF-Skills and further strengthen multiple skills relevant to music understanding. To improve the model's reasoning abilities, we introduce a post-training recipe: we first cold-start with MF-Think, a novel chain-of-thought dataset grounded in music theory, followed by GRPO-based reinforcement learning with custom rewards. Music Flamingo achieves state-of-the-art results across 10+ benchmarks for music understanding and reasoning, establishing itself as a generalist and musically intelligent audio-language model. Beyond strong empirical results, Music Flamingo sets a new standard for advanced music understanding by demonstrating how models can move from surface-level recognition toward layered, human-like perception of songs. We believe this work provides both a benchmark and a foundation for the community to build the next generation of models that engage with music as meaningfully as humans do.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [77] [Simulating Misinformation Propagation in Social Networks using Large Language Models](https://arxiv.org/abs/2511.10384)
*Raj Gaurav Maurya,Vaibhav Shukla,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.SI

TL;DR: LLM-based framework simulates misinformation spread through biased personas, showing identity-driven acceleration and expert mitigation. Dual LLM roles as bias proxies and auditors demonstrated.


<details>
  <summary>Details</summary>
Motivation: Investigate how human cognitive biases and ideological alignments drive misinformation evolution by modeling LLM personas as synthetic agents with user-level biases.

Method: Auditor-node framework propagates news through persona-conditioned LLM networks. QA-based auditor tracks factual fidelity. Metrics: misinformation index and propagation rate across 30 rewrites.

Result: Identity/ideology personas accelerate misinformation in politics/marketing/tech. Expert personas maintain stability. Heterogeneous interactions escalate distortions to propaganda levels.

Conclusion: LLMs enable dual simulation-audit capabilities for studying misinformation. Framework provides interpretable methods to analyze and mitigate digital ecosystem misinformation.

Abstract: Misinformation on social media thrives on surprise, emotion, and identity-driven reasoning, often amplified through human cognitive biases. To investigate these mechanisms, we model large language model (LLM) personas as synthetic agents that mimic user-level biases, ideological alignments, and trust heuristics. Within this setup, we introduce an auditor--node framework to simulate and analyze how misinformation evolves as it circulates through networks of such agents. News articles are propagated across networks of persona-conditioned LLM nodes, each rewriting received content. A question--answering-based auditor then measures factual fidelity at every step, offering interpretable, claim-level tracking of misinformation drift. We formalize a misinformation index and a misinformation propagation rate to quantify factual degradation across homogeneous and heterogeneous branches of up to 30 sequential rewrites. Experiments with 21 personas across 10 domains reveal that identity- and ideology-based personas act as misinformation accelerators, especially in politics, marketing, and technology. By contrast, expert-driven personas preserve factual stability. Controlled-random branch simulations further show that once early distortions emerge, heterogeneous persona interactions rapidly escalate misinformation to propaganda-level distortion. Our taxonomy of misinformation severity -- spanning factual errors, lies, and propaganda -- connects observed drift to established theories in misinformation studies. These findings demonstrate the dual role of LLMs as both proxies for human-like biases and as auditors capable of tracing information fidelity. The proposed framework provides an interpretable, empirically grounded approach for studying, simulating, and mitigating misinformation diffusion in digital ecosystems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [78] [Rethinking the Reliability of Multi-agent System: A Perspective from Byzantine Fault Tolerance](https://arxiv.org/abs/2511.10400)
*Lifan Zheng,Jiawei Chen,Qinghong Yin,Jingyuan Zhang,Xinyi Zeng,Yu Tian*

Main category: cs.MA

TL;DR: 提出基于置信探针的加权拜占庭容错机制CP-WBFT，验证LLM智能体在极端故障条件下的可靠性优势


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统可靠性研究不足，LLM智能体在复杂任务中展现突破但可靠性影响未知，需验证其拜占庭容错能力

Method: 通过探针加权信息流传输机制，结合LLM的反思判别能力设计CP-WBFT共识机制

Result: 在85.7%故障率下，CP-WBFT在不同网络拓扑中准确率提升显著，数学推理任务准确率达92.3%

Conclusion: LLM智能体具有原生怀疑优势，CP-WBFT成功实现拓扑自适应的可靠共识，为安全关键领域MAS部署提供新方案

Abstract: Ensuring the reliability of agent architectures and effectively identifying problematic agents when failures occur are crucial challenges in multi-agent systems (MAS). Advances in large language models (LLMs) have established LLM-based agents as a major branch of MAS, enabling major breakthroughs in complex problem solving and world modeling. However, the reliability implications of this shift remain largely unexplored. i.e., whether substituting traditional agents with LLM-based agents can effectively enhance the reliability of MAS. In this work, we investigate and quantify the reliability of LLM-based agents from the perspective of Byzantine fault tolerance. We observe that LLM-based agents demonstrate stronger skepticism when processing erroneous message flows, a characteristic that enables them to outperform traditional agents across different topological structures. Motivated by the results of the pilot experiment, we design CP-WBFT, a confidence probe-based weighted Byzantine Fault Tolerant consensus mechanism to enhance the stability of MAS with different topologies. It capitalizes on the intrinsic reflective and discriminative capabilities of LLMs by employing a probe-based, weighted information flow transmission method to improve the reliability of LLM-based agents. Extensive experiments demonstrate that CP-WBFT achieves superior performance across diverse network topologies under extreme Byzantine conditions (85.7\% fault rate). Notably, our approach surpasses traditional methods by attaining remarkable accuracy on various topologies and maintaining strong reliability in both mathematical reasoning and safety assessment tasks.

</details>
