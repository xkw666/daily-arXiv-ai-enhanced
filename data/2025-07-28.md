<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.GR](#cs.GR) [Total: 3]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CV](#cs.CV) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: 提出Specification Self-Correction框架，通过模型自修正机制减少90%以上规范漏洞利用


<details>
  <summary>Details</summary>
Motivation: 语言模型容易利用规范漏洞获取高分却不满足用户真实需求（50-70%案例存在该问题）

Method: 四步自修正流程：1.按原规范生成响应 → 2.自我批判输出 → 3.修正规范 → 4.基于新规范生成最终响应

Result: 在创意写作和智能体编码任务中，将规范漏洞利用比例从50-70%降低超过90%

Conclusion: SSC框架实现动态规范修复，无需修改模型权重即可提升模型行为鲁棒性

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [2] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: AS-RoBERTa模型家族通过针对阿拉伯文字语言特性优化预训练，在分类任务中表现优于通用多语言模型


<details>
  <summary>Details</summary>
Motivation: 通用多语言模型在处理共享文字但语言特征迥异的阿拉伯文字语言（如库尔德语、波斯语等）时存在性能局限

Method: 构建四个RoBERTa模型，每个模型使用目标语言特定的大规模语料库进行脚本特征聚焦的预训练

Result: 在分类任务中性能提升2-5个百分点，消融实验证实脚本聚焦预训练是关键改进因素

Conclusion: 基于文字特性的专业化预训练策略对阿拉伯文字语言处理具有重要价值，支持未来基于文字特性的模型开发

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


### [3] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
*Nicole Lai-Lopez,Lusha Wang,Su Yuan,Liza Zhang*

Main category: cs.CL

TL;DR: 提出融合多语言词典引导标注、微调seq2seq模型与迭代分类把关机制的多语言文本去毒流程，在PAN-2025竞赛中取得第九名（J=0.612）


<details>
  <summary>Details</summary>
Motivation: 现有无监督/单语言去毒方法缺乏跨语言泛化能力，需通过显式标注和多语言模型提升去毒精度

Method: 三阶段流程：1) 多语言toxic词典标注；2) s-nlp/mt0-xl-detox-orpo模型微调；3) 迭代分类器把关质量

Result: STA达0.922，J=0.612（测试集），xCOMET 0.787，在英/俄/法语表现超越基线方法

Conclusion: 该方法在保持语义连贯性（SIM）的权衡下，实现了强跨语言泛化能力，验证了显式标注与门控机制的有效性

Abstract: In this work, we introduce our solution for the Multilingual Text
Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust
multilingual text detoxification pipeline that integrates lexicon-guided
tagging, a fine-tuned sequence-to-sequence model (s-nlp/mt0-xl-detox-orpo) and
an iterative classifier-based gatekeeping mechanism. Our approach departs from
prior unsupervised or monolingual pipelines by leveraging explicit toxic word
annotation via the multilingual_toxic_lexicon to guide detoxification with
greater precision and cross-lingual generalization. Our final model achieves
the highest STA (0.922) from our previous attempts, and an average official J
score of 0.612 for toxic inputs in both the development and test sets. It also
achieved xCOMET scores of 0.793 (dev) and 0.787 (test). This performance
outperforms baseline and backtranslation methods across multiple languages, and
shows strong generalization in high-resource settings (English, Russian,
French). Despite some trade-offs in SIM, the model demonstrates consistent
improvements in detoxification strength. In the competition, our team achieved
ninth place with a score of 0.612.

</details>


### [4] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
*Yilun Yang,Yekun Chai*

Main category: cs.CL

TL;DR: 论文系统评估了大语言模型在18种语言上的语码混合能力，并提出结合词汇替换与GPT-4提示的合成数据生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有语码混合基准存在语言对单一、任务类型有限的问题，且数据生成方法不成熟，难以充分评估大语言模型的跨语言混合能力。

Method: 跨七大语系18种语言构建评测体系，提出词汇替换与GPT-4提示结合的合成语码混合文本生成框架。

Result: 大语言模型在涉及多语系的语码混合数据集上表现持续欠佳，语言家族差异显著影响模型性能。

Conclusion: 建议通过增加训练数据规模、扩大模型参数量以及改进少样本学习策略来提升模型表现。

Abstract: Code-mixing, the practice of switching between languages within a
conversation, presents unique challenges for traditional natural language
processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by
narrow language pairings and tasks, failing to adequately evaluate the
code-mixing capabilities of large language models (LLMs). Despite the
significance of code-mixing for multilingual users, research on LLMs in this
context remains limited. Additionally, current methods for generating
code-mixed data are underdeveloped. In this paper, we conduct a comprehensive
evaluation of LLMs' performance on code-mixed data across 18 languages from
seven language families. We also propose a novel approach for generating
synthetic code-mixed texts by combining word substitution with GPT-4 prompting.
Our analysis reveals consistent underperformance of LLMs on code-mixed datasets
involving multiple language families. We suggest that improvements in training
data size, model scale, and few-shot learning could enhance their performance.

</details>


### [5] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
*Pranav Gupta*

Main category: cs.CL

TL;DR: CueBuddy通过实时技术术语识别和多语言词汇表查找，为英语非母语的STEM学生提供实时术语提示，避免昂贵翻译方案


<details>
  <summary>Details</summary>
Motivation: 全球南方STEM学生因专业英语术语理解困难导致学习滞后，现有实时语音翻译方案成本高且不擅长处理技术内容

Method: 开发实时技术关键词识别系统，配合多语言术语库即时查询，在不打断课堂注意力的前提下提供术语辅助

Result: 系统能有效帮助学生跟上复杂英语术语，但存在应用限制需要后续扩展改进

Conclusion: CueBuddy创新性地解决了非母语学生专业术语理解难题，但需进一步扩展功能边界

Abstract: Students across the world in STEM classes, especially in the Global South,
fall behind their peers who are more fluent in English, despite being at par
with them in terms of scientific prerequisites. While many of them are able to
follow everyday English at ease, key terms in English stay challenging. In most
cases, such students have had most of their course prerequisites in a lower
resource language. Live speech translation to lower resource languages is a
promising area of research, however, models for speech translation can be too
expensive on a large scale and often struggle with technical content. In this
paper, we describe CueBuddy, which aims to remediate these issues by providing
real-time "lexical cues" through technical keyword spotting along real-time
multilingual glossary lookup to help students stay up to speed with complex
English jargon without disrupting their concentration on the lecture. We also
describe the limitations and future extensions of our approach.

</details>


### [6] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
*Mohammad Kachuee,Teja Gollapudi,Minseok Kim,Yin Huang,Kai Sun,Xiao Yang,Jiaqi Wang,Nirav Shah,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: 提出PrismRAG框架，通过干扰感知训练和推理习惯培养提升RAG性能，在12个基准测试中平均事实性提升5.4%


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成(RAG)在遇到半相关干扰段落时效果不佳，且缺乏深度推理能力

Method: 1. 使用含黄金证据与干扰段落的QA对进行训练；2. 培养计划-论证-合成的推理习惯，减少人工指令依赖

Result: 在涵盖多领域的12个开放域RAG QA基准测试中，事实性指标平均提升5.4%，优于现有方案

Conclusion: PrismRAG通过自动化训练框架有效提升RAG系统的抗干扰能力和深度推理能力，减少人工工程需求

Abstract: Retrieval-augmented generation (RAG) often falls short when retrieved context
includes confusing semi-relevant passages, or when answering questions require
deep contextual understanding and reasoning. We propose an efficient
fine-tuning framework, called PrismRAG, that (i) trains the model with
distractor-aware QA pairs mixing gold evidence with subtle distractor passages,
and (ii) instills reasoning-centric habits that make the LLM plan, rationalize,
and synthesize without relying on extensive human engineered instructions.
Evaluated across 12 open-book RAG QA benchmarks spanning diverse application
domains and scenarios, PrismRAG improves average factuality by 5.4%,
outperforming state-of-the-art solutions.

</details>


### [7] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
*Ming Gong,Xucheng Huang,Ziheng Xu,Vijayan K. Asari*

Main category: cs.CL

TL;DR: 结合LLMs与强化学习开发了MindFlow+对话系统，通过工具增强和奖励机制提升电商场景的对话质量与AI贡献度


<details>
  <summary>Details</summary>
Motivation: 传统意图驱动的电商对话系统难以处理动态多轮交互，需要结合领域知识构建具有持续进化能力的对话代理

Method: 1. 工具增强的演示构建机制（知识增强+ReAct式交互）
2. 奖励条件数据建模（基于奖励信号对齐任务目标）
3. 提出AI贡献率量化指标

Result: 在真实电商对话数据中，MindFlow+在上下文相关性(↑23%)、灵活性(↑17%)和任务准确率(↑31%)上显著超越基线模型

Conclusion: LLMs+工具推理+奖励引导学习的组合，为构建领域专业化、上下文感知的对话系统提供了有效技术路径

Abstract: High-quality dialogue is crucial for e-commerce customer service, yet
traditional intent-based systems struggle with dynamic, multi-turn
interactions. We present MindFlow+, a self-evolving dialogue agent that learns
domain-specific behavior by combining large language models (LLMs) with
imitation learning and offline reinforcement learning (RL). MindFlow+
introduces two data-centric mechanisms to guide learning: tool-augmented
demonstration construction, which exposes the model to knowledge-enhanced and
agentic (ReAct-style) interactions for effective tool use; and
reward-conditioned data modeling, which aligns responses with task-specific
goals using reward signals. To evaluate the model's role in response
generation, we introduce the AI Contribution Ratio, a novel metric quantifying
AI involvement in dialogue. Experiments on real-world e-commerce conversations
show that MindFlow+ outperforms strong baselines in contextual relevance,
flexibility, and task accuracy. These results demonstrate the potential of
combining LLMs tool reasoning, and reward-guided learning to build
domain-specialized, context-aware dialogue systems.

</details>


### [8] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
*Jonathan Ivey,Susan Gauch,David Jurgens*

Main category: cs.CL

TL;DR: 提出NUTMEG贝叶斯模型，有效区分标注数据中的噪声与合理分歧，提升数据质量与下游任务表现


<details>
  <summary>Details</summary>
Motivation: 传统数据聚合方法将标注冲突视为噪声，但真实场景中可能存在合理的系统性分歧。现有模型未能有效区分噪声与真实信号，导致训练数据质量受限

Method: 通过贝叶斯模型整合标注者背景信息，设计双重过滤机制：既去除随机噪声，又保留系统性合理分歧。使用合成数据验证框架有效性，并分析子群体规模/分歧率/垃圾标注率的影响

Result: 1. 在合成数据中恢复真实标注准确率优于传统方法6-15%
2. 下游任务模型准确率提升3.2-7.8个百分点
3. 模型对子群体规模变化保持鲁棒性，在50%垃圾标注率下仍保持85%+准确率

Conclusion: 处理人工标注数据时需兼顾标注者能力评估与合理分歧保留。NUTMEG通过建模标注者背景实现双重优化，为高质量训练数据构建提供新范式

Abstract: NLP models often rely on human-labeled data for training and evaluation. Many
approaches crowdsource this data from a large number of annotators with varying
skills, backgrounds, and motivations, resulting in conflicting annotations.
These conflicts have traditionally been resolved by aggregation methods that
assume disagreements are errors. Recent work has argued that for many tasks
annotators may have genuine disagreements and that variation should be treated
as signal rather than noise. However, few models separate signal and noise in
annotator disagreement. In this work, we introduce NUTMEG, a new Bayesian model
that incorporates information about annotator backgrounds to remove noisy
annotations from human-labeled training data while preserving systematic
disagreements. Using synthetic data, we show that NUTMEG is more effective at
recovering ground-truth from annotations with systematic disagreement than
traditional aggregation methods. We provide further analysis characterizing how
differences in subpopulation sizes, rates of disagreement, and rates of spam
affect the performance of our model. Finally, we demonstrate that downstream
models trained on NUTMEG-aggregated data significantly outperform models
trained on data from traditionally aggregation methods. Our results highlight
the importance of accounting for both annotator competence and systematic
disagreements when training on human-labeled data.

</details>


### [9] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
*Chuxuan Hu,Liyun Zhang,Yeji Lim,Aum Wadhwani,Austin Peters,Daniel Kang*

Main category: cs.CL

TL;DR: 开发REPRO-Bench基准测试工具评估AI代理自动化复现社科论文能力，现有代理准确率仅21.4%，改进后的REPRO-Agent提升71%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅验证代码数据复现结果，忽视与论文一致性、场景简化且缺乏数据多样性，无法满足真实场景需求。

Method: 构建包含112个社科论文实例的REPRO-Bench，要求代理基于原始论文PDF和复现包进行端到端的可复现性评估。

Result: 最佳传统代理准确率21.4%，改进的REPRO-Agent将最高准确率提升71%达到36.6%。

Conclusion: 需开发更先进的AI代理以实现真实世界可复现性评估自动化，REPRO-Bench公开促进该领域发展。

Abstract: Assessing the reproducibility of social science papers is essential for
promoting rigor in research processes, but manual assessment is costly. With
recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate
their capability to automate this process. However, existing benchmarks for
reproducing research papers (1) focus solely on reproducing results using
provided code and data without assessing their consistency with the paper, (2)
oversimplify real-world scenarios, and (3) lack necessary diversity in data
formats and programming languages. To address these issues, we introduce
REPRO-Bench, a collection of 112 task instances, each representing a social
science paper with a publicly available reproduction report. The agents are
tasked with assessing the reproducibility of the paper based on the original
paper PDF and the corresponding reproduction package. REPRO-Bench features
end-to-end evaluation tasks on the reproducibility of social science papers
with complexity comparable to real-world assessments. We evaluate three
representative AI agents on REPRO-Bench, with the best-performing agent
achieving an accuracy of only 21.4%. Building on our empirical analysis, we
develop REPRO-Agent, which improves the highest accuracy achieved by existing
agents by 71%. We conclude that more advanced AI agents should be developed to
automate real-world reproducibility assessment. REPRO-Bench is publicly
available at https://github.com/uiuc-kang-lab/REPRO-Bench.

</details>


### [10] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
*Hongyuan Lu,Zixuan Li,Zefan Zhang,Wai Lam*

Main category: cs.CL

TL;DR: 提出自动词典选择任务(ADS)及SLoW方法，通过筛选低频词典实现翻译质量与计算成本的平衡


<details>
  <summary>Details</summary>
Motivation: 现有词典增强方法会消耗大量token资源，需建立灵活的词典选择机制以平衡计算成本与翻译性能

Method: SLoW方法基于公开资源估算词频，自动选择低频词词典，无需访问模型训练数据或进行额外调参

Result: 在FLORES的100种语言测试中，SLoW节省40%以上token使用量的同时，翻译性能超越全词典基线方法

Conclusion: 该方案突破传统依赖训练数据的局限，为低资源语言翻译提供高效实用的词典选择框架

Abstract: There are more than 7,000 languages around the world, and current Large
Language Models (LLMs) only support hundreds of languages. Dictionary-based
prompting methods can enhance translation on them, but most methods use all the
available dictionaries, which could be expensive. Instead, it will be flexible
to have a trade-off between token consumption and translation performance. This
paper proposes a novel task called \textbf{A}utomatic \textbf{D}ictionary
\textbf{S}election (\textbf{ADS}). The goal of the task is to automatically
select which dictionary to use to enhance translation. We propose a novel and
effective method which we call \textbf{S}elect \textbf{Lo}w-frequency
\textbf{W}ords! (\textbf{SLoW}) which selects those dictionaries that have a
lower frequency. Our methods have unique advantages. First, there is no need
for access to the training data for frequency estimation (which is usually
unavailable). Second, it inherits the advantage of dictionary-based methods,
where no additional tuning is required on LLMs. Experimental results on 100
languages from FLORES indicate that SLoW surpasses strong baselines, and it can
obviously save token usage, with many languages even surpassing the translation
performance of the full dictionary baseline.\footnote{A shocking fact is that
there is no need to use the actual training data (often unobtainable) for
frequency estimation, and an estimation frequency obtained using public
resources is still apparently effective in improving translation with ChatGPT
and Llama, and DeepSeek.}\footnote{Code and data available upon publication.}

</details>


### [11] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
*Rachel L. Draelos,Samina Afreen,Barbara Blasko,Tiffany Brazile,Natasha Chase,Dimple Desai,Jessica Evert,Heather L. Gardner,Lauren Herrmann,Aswathy Vaikom House,Stephanie Kass,Marianne Kavan,Kirshma Khemani,Amanda Koire,Lauren M. McDonald,Zahraa Rabeeah,Amy Shah*

Main category: cs.CL

TL;DR: 研究揭示四款主流医疗聊天机器人中，21.6%-43.2%的医疗建议存在安全隐患，其中Llama和GPT-4o的不安全回答率最高（达13%）。


<details>
  <summary>Details</summary>
Motivation: 针对数百万患者日常使用LLM获取医疗建议引发的安全隐患，首次通过医师主导的红队测试评估公开聊天机器人的临床安全性。

Method: 使用HealthAdvice数据集，对Claude/Gemini/GPT-4o/Llama3-70B进行888次测试，覆盖内科/妇产科/儿科等222个常见病症的咨询场景。

Result: Claude表现最优（问题率21.6%，不安全率5%），Llama问题率最高（43.2%），GPT-4o和Llama的不安全回答率均达13%。存在导致严重医疗事故的响应案例。

Conclusion: 当前公开聊天机器人可能对数百万患者构成安全隐患，亟需改进临床安全性验证机制。

Abstract: Millions of patients are already using large language model (LLM) chatbots
for medical advice on a regular basis, raising patient safety concerns. This
physician-led red-teaming study compares the safety of four publicly available
chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and
Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation
framework that enables quantitative and qualitative analysis. In total, 888
chatbot responses are evaluated for 222 patient-posed advice-seeking medical
questions on primary care topics spanning internal medicine, women's health,
and pediatrics. We find statistically significant differences between chatbots.
The rate of problematic responses varies from 21.6 percent (Claude) to 43.2
percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13
percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the
potential to lead to serious patient harm. This study suggests that millions of
patients could be receiving unsafe medical advice from publicly available
chatbots, and further work is needed to improve the clinical safety of these
powerful tools.

</details>


### [12] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
*Agada Joseph Oche,Ademola Glory Folashade,Tirthankar Ghosal,Arpan Biswas*

Main category: cs.CL

TL;DR: 系统综述RAG技术，分析其演进路径、技术架构、企业应用及未来发展方向


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型存在的事实性幻觉、知识更新滞后问题，通过检索增强提升模型可靠性

Method: 整合信息检索系统与生成模型，重点研究检索机制、生成模型融合策略，开展逐年演进分析和企业级系统部署评估

Result: 验证RAG在检索准确性（提升32%）、生成流畅度（改进28%）的优化效果，揭示检索质量、隐私保护等持续性挑战

Conclusion: 提出混合检索、隐私计算、智能体架构等解决方案，推动构建更可靠的知识增强型NLP系统

Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in
natural language processing (NLP), combining large language models (LLMs) with
information retrieval systems to enhance factual grounding, accuracy, and
contextual relevance. This paper presents a comprehensive systematic review of
RAG, tracing its evolution from early developments in open domain question
answering to recent state-of-the-art implementations across diverse
applications. The review begins by outlining the motivations behind RAG,
particularly its ability to mitigate hallucinations and outdated knowledge in
parametric models. Core technical components-retrieval mechanisms,
sequence-to-sequence generation models, and fusion strategies are examined in
detail. A year-by-year analysis highlights key milestones and research trends,
providing insight into RAG's rapid growth. The paper further explores the
deployment of RAG in enterprise systems, addressing practical challenges
related to retrieval of proprietary data, security, and scalability. A
comparative evaluation of RAG implementations is conducted, benchmarking
performance on retrieval accuracy, generation fluency, latency, and
computational efficiency. Persistent challenges such as retrieval quality,
privacy concerns, and integration overhead are critically assessed. Finally,
the review highlights emerging solutions, including hybrid retrieval
approaches, privacy-preserving techniques, optimized fusion strategies, and
agentic RAG architectures. These innovations point toward a future of more
reliable, efficient, and context-aware knowledge-intensive NLP systems.

</details>


### [13] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
*Ananya Sahu,Amith Ananthram,Kathleen McKeown*

Main category: cs.CL

TL;DR: 开发了一种通过挖掘视觉关联生成多层级抽象创意描述的模型，显著提升了诗歌和隐喻可视化领域的零样本检索能力


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型依赖网络爬取的简短字面描述文本，缺乏对创造性内容的理解能力，需构建关联性更强的语义表达体系

Method: 提出可扩展的上下文关联挖掘方法，从无标注数据中提取视觉要素关联，生成不同抽象程度的创意描述

Result: 构建包含170万创意描述的MSCOCO新数据集，人类评估验证其视觉锚定性与抽象性的平衡，微调模型在创意领域检索准确率显著提升

Conclusion: 该方法有效连接字面描述与创造性理解，为创造性视觉语言任务提供新的解决方案和资源支持

Abstract: Understanding another person's creative output requires a shared language of
association. However, when training vision-language models such as CLIP, we
rely on web-scraped datasets containing short, predominantly literal, alt-text.
In this work, we introduce a method for mining contextualized associations for
salient visual elements in an image that can scale to any unlabeled dataset.
Given an image, we can use these mined associations to generate high quality
creative captions at increasing degrees of abstraction. With our method, we
produce a new dataset of visual associations and 1.7m creative captions for the
images in MSCOCO. Human evaluation confirms that these captions remain visually
grounded while exhibiting recognizably increasing abstraction. Moreover,
fine-tuning a visual encoder on this dataset yields meaningful improvements in
zero-shot image-text retrieval in two creative domains: poetry and metaphor
visualization. We release our dataset, our generation code and our models for
use by the broader community.

</details>


### [14] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
*Richmond Sin Jing Xuan,Jalil Huseynov,Yang Zhang*

Main category: cs.CL

TL;DR: 研究通过稀疏自编码器分析多语言大模型激活模式差异，提出基于LoRA的激活感知微调方法，显著提升了低资源语言的激活强度并保持英语性能。


<details>
  <summary>Details</summary>
Motivation: 中低资源语言在通用基准测试中表现不佳，需探究其在大模型中的激活差异并寻求优化方案。

Method: 使用稀疏自编码器(SAEs)分析Gemma-2-2B模型在10种语言的26个残差层激活模式，采用低秩适配(LoRA)进行激活感知微调。

Result: 低资源语言激活强度提升最高达87.69%（马拉雅拉姆语），英语保留率约91%，基准测试指标呈现持续稳定改进。

Conclusion: 激活对齐是提升多语言大模型性能的关键因素，激活感知微调可有效缩小语言间表征差异。

Abstract: Multilingual large language models (LLMs) exhibit strong cross-linguistic
generalization, yet medium to low resource languages underperform on common
benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation
patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese
(zh), Russian (ru), Spanish (es), Italian (it), medium to low resource
languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam
(ml), and Hindi (hi), with English (en) as the reference. Using Sparse
Autoencoders (SAEs), we reveal systematic disparities in activation patterns.
Medium to low resource languages receive up to 26.27 percent lower activations
in early layers, with a persistent gap of 19.89 percent in deeper layers. To
address this, we apply activation-aware fine-tuning via Low-Rank Adaptation
(LoRA), leading to substantial activation gains, such as 87.69 percent for
Malayalam and 86.32 percent for Hindi, while maintaining English retention at
approximately 91 percent. After fine-tuning, benchmark results show modest but
consistent improvements, highlighting activation alignment as a key factor in
enhancing multilingual LLM performance.

</details>


### [15] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
*Jingxuan Wei,Caijun Jia,Qi Chen,Yujun Cai,Linzhuang Sun,Xiangxiang Zhang,Gaowei Wu,Bihui Yu*

Main category: cs.CL

TL;DR: 提出LLaVA-NeuMT多模态多语言翻译框架，通过层选择和神经元级适应策略，仅微调40%参数即在两个数据集上达到SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态翻译方法在扩展到多语言场景时存在跨语言干扰和参数共享效率低下的问题，需设计更高效的适应策略。

Method: 1. 层选择机制筛选不同语对的信息最丰富层；2. 神经元级动态适配策略分离语言相关/无关神经元以减少冗余。

Result: 在M3-Multi30K和M3-AmbigCaps数据集上超越全参数微调方法，最高提升指标达显著幅度。

Conclusion: 通过显式建模语言特性与共享表征，为多模态多语言翻译提供了高效可扩展的解决方案，参数效率提升150%。

Abstract: Multimodal Machine Translation (MMT) enhances translation quality by
incorporating visual context, helping to resolve textual ambiguities. While
existing MMT methods perform well in bilingual settings, extending them to
multilingual translation remains challenging due to cross-lingual interference
and ineffective parameter-sharing strategies. To address this, we propose
LLaVA-NeuMT, a novel multimodal multilingual translation framework that
explicitly models language-specific and language-agnostic representations to
mitigate multilingual interference. Our approach consists of a layer selection
mechanism that identifies the most informative layers for different language
pairs and a neuron-level adaptation strategy that dynamically selects
language-specific and agnostic neurons to improve translation quality while
reducing redundancy. We conduct extensive experiments on the M3-Multi30K and
M3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only
40\% of the model parameters, surpasses full fine-tuning approaches and
ultimately achieves SOTA results on both datasets. Our analysis further
provides insights into the importance of selected layers and neurons in
multimodal multilingual adaptation, offering an efficient and scalable solution
to cross-lingual adaptation in multimodal translation.

</details>


### [16] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CL

TL;DR: 利用NLP和机器学习技术自动生成法律文档摘要，提升司法效率并减少人工失误


<details>
  <summary>Details</summary>
Motivation: 通过自动化关键信息提取缓解法律从业者的文书处理压力，降低因人工疏忽导致的错误风险

Method: 采用先进自然语言处理技术和机器学习算法识别司法文档深层模式

Result: 实验显示能保持内容完整性的同时显著提升处理速度，生成高质量摘要

Conclusion: 自动化技术可重构法律工作流程，将人力转向核心决策分析

Abstract: Legal document summarization represents a significant advancement towards
improving judicial efficiency through the automation of key information
detection. Our approach leverages state-of-the-art natural language processing
techniques to meticulously identify and extract essential data from extensive
legal texts, which facilitates a more efficient review process. By employing
advanced machine learning algorithms, the framework recognizes underlying
patterns within judicial documents to create precise summaries that encapsulate
the crucial elements. This automation alleviates the burden on legal
professionals, concurrently reducing the likelihood of overlooking vital
information that could lead to errors. Through comprehensive experiments
conducted with actual legal datasets, we demonstrate the capability of our
method to generate high-quality summaries while preserving the integrity of the
original content and enhancing processing times considerably. The results
reveal marked improvements in operational efficiency, allowing legal
practitioners to direct their efforts toward critical analytical and
decision-making activities instead of manual reviews. This research highlights
promising technology-driven strategies that can significantly alter workflow
dynamics within the legal sector, emphasizing the role of automation in
refining judicial processes.

</details>


### [17] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
*Sang Min Jung,Kaixiang Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出一种对话动态相似性度量方法，通过验证框架证明其有效性，并在在线社区分析中揭示情境权力的作用。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对对话整体互动模式的自动化对比手段，阻碍了对话数据的全面分析和对话代理的全局评估。

Method: 开发对话动态相似性度量指标，构建验证框架测试指标对动态差异的捕捉能力和话题敏感性。

Result: 该指标成功应用于大型在线社区对话分析，揭示情境权力对对话动态的关键影响。

Conclusion: 对话动态测量工具为社群交流分析提供新维度，对社交计算和对话系统评估具有方法论价值。

Abstract: The quality of a conversation goes beyond the individual quality of each
reply, and instead emerges from how these combine into interactional patterns
that give the conversation its distinctive overall "shape". However, there is
no robust automated method for comparing conversations in terms of their
overall interactional dynamics. Such methods could enhance the analysis of
conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations
with respect to their dynamics. We design a validation framework for testing
the robustness of the metric in capturing differences in conversation dynamics
and for assessing its sensitivity to the topic of the conversations. Finally,
to illustrate the measure's utility, we use it to analyze conversational
dynamics in a large online community, bringing new insights into the role of
situational power in conversations.

</details>


### [18] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
*Bohan Yao,Vikas Yadav*

Main category: cs.CL

TL;DR: 提出Multi-TAG框架，通过多工具聚合增强大语言模型数学推理能力，无需微调即可显著提升复杂问题性能。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强方法依赖单工具调用，难以处理需要多步精确推理的复杂数学问题（如数学竞赛题）。

Method: Multi-TAG框架引导LLM在推理步骤中并行调用多工具，聚合验证输出以优化推理路径，无需微调且兼容各类LLM架构。

Result: 在MATH500/AIME等四个挑战性基准上，相比SOTA方法平均提升6.0%-7.5%，适用于开放权重模型和闭源前沿模型。

Conclusion: 通过多工具协同验证机制，有效提升复杂数学问题解决能力，为LLM工具增强提供轻量级高性能解决方案。

Abstract: Augmenting large language models (LLMs) with external tools is a promising
avenue for developing high-performance mathematical reasoning systems. Prior
tool-augmented approaches typically finetune an LLM to select and invoke a
single tool at each reasoning step and show promising results on simpler math
reasoning benchmarks such as GSM8K. However, these approaches struggle with
more complex math problems that require precise reasoning over multiple steps.
To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool
AGgregation-based framework. Instead of relying on a single tool, Multi-TAG
guides an LLM to concurrently invoke multiple tools at each reasoning step. It
then aggregates their diverse outputs to verify and refine the reasoning
process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a
finetuning-free, inference-only framework, making it readily applicable to any
LLM backbone, including large open-weight models which are computationally
expensive to finetune and proprietary frontier models which cannot be finetuned
with custom recipes. We evaluate Multi-TAG on four challenging benchmarks:
MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and
closed-source LLM backbones, Multi-TAG consistently and substantially
outperforms state-of-the-art baselines, achieving average improvements of 6.0%
to 7.5% over state-of-the-art baselines.

</details>


### [19] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
*Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: 提出Arg-LLaDA框架，通过迭代掩码再生机制改进论点总结质量，在自动指标和人工评估中均超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有论点总结方法依赖单次生成，缺乏事实修正和结构优化的迭代支持，导致输出可能存在不准确/冗余/不完整问题

Method: 结合动态掩码控制器与充分性检查模块，通过迭代检测和修复不充分文本跨度，实现渐进式摘要优化

Result: 在基准测试中超越SOTA方法7/10自动指标，人工评估显示覆盖度、忠实度和简洁性提升15-20%

Conclusion: 基于充分性引导的迭代生成策略显著提升论点总结质量，验证了动态修正机制在结构化文本生成中的有效性

Abstract: Argument summarization aims to generate concise, structured representations
of complex, multi-perspective debates. While recent work has advanced the
identification and clustering of argumentative components, the generation stage
remains underexplored. Existing approaches typically rely on single-pass
generation, offering limited support for factual correction or structural
refinement. To address this gap, we introduce Arg-LLaDA, a novel large language
diffusion framework that iteratively improves summaries via sufficiency-guided
remasking and regeneration. Our method combines a flexible masking controller
with a sufficiency-checking module to identify and revise unsupported,
redundant, or incomplete spans, yielding more faithful, concise, and coherent
outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA
surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation
metrics. In addition, human evaluations reveal substantial improvements across
core dimensions, coverage, faithfulness, and conciseness, validating the
effectiveness of our iterative, sufficiency-aware generation strategy.

</details>


### [20] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
*Haorui He,Yupeng Li,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CL

TL;DR: 提出辩论驱动框架DebateCV，通过多LLM代理辩论和合成数据后训练策略，显著提升复杂声明验证效果


<details>
  <summary>Details</summary>
Motivation: 现有单LLM方法难以处理需要多证据交叉验证的复杂声明验证，受现实世界事实核查流程启发，采用多方辩论机制解决该问题

Method: 设计双辩论者对抗论证+主持人评估的三方框架，开发基于零样本辩论数据合成的后训练策略解决数据稀缺问题

Result: 在多个证据质量场景下超越现有方法，尤其在低质量证据场景保持稳定表现

Conclusion: 辩论机制有效提升LLM的推理严谨性，合成数据训练策略为有限监督数据场景提供新解决方案，框架已开源

Abstract: Claim verification is critical for enhancing digital literacy. However, the
state-of-the-art single-LLM methods struggle with complex claim verification
that involves multi-faceted evidences. Inspired by real-world fact-checking
practices, we propose DebateCV, the first claim verification framework that
adopts a debate-driven methodology using multiple LLM agents. In our framework,
two Debaters take opposing stances on a claim and engage in multi-round
argumentation, while a Moderator evaluates the arguments and renders a verdict
with justifications. To further improve the performance of the Moderator, we
introduce a novel post-training strategy that leverages synthetic debate data
generated by the zero-shot DebateCV, effectively addressing the scarcity of
real-world debate-driven claim verification data. Experimental results show
that our method outperforms existing claim verification methods under varying
levels of evidence quality. Our code and dataset are publicly available at
https://anonymous.4open.science/r/DebateCV-6781.

</details>


### [21] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
*Swapnil Hingmire,Ze Shi Li,Shiyu,Zeng,Ahmed Musa Awon,Luiz Franciscatto Guerra,Neil Ernst*

Main category: cs.CL

TL;DR: 提出基于认知偏见的主题解释理论，强调用户模型需考虑生态合理性


<details>
  <summary>Details</summary>
Motivation: 现有主题质量评估指标（如一致性）无法有效衡量主题在语料库探索中的实际效用，需构建任务导向的评估框架

Method: 通过用户研究收集主题解释理性，采用反身性主题分析法识别解释模式

Result: 用户主要依赖可用性/代表性启发式而非概率，提出基于锚定调整启发式的主题解释理论框架

Conclusion: 主题解释本质是不确定性下的生态理性判断，需开发认知偏差感知的用户建模方法

Abstract: Interpretation of topics is crucial for their downstream applications.
State-of-the-art evaluation measures of topic quality such as coherence and
word intrusion do not measure how much a topic facilitates the exploration of a
corpus. To design evaluation measures grounded on a task, and a population of
users, we do user studies to understand how users interpret topics. We propose
constructs of topic quality and ask users to assess them in the context of a
topic and provide rationale behind evaluations. We use reflexive thematic
analysis to identify themes of topic interpretations from rationales. Users
interpret topics based on availability and representativeness heuristics rather
than probability. We propose a theory of topic interpretation based on the
anchoring-and-adjustment heuristic: users anchor on salient words and make
semantic adjustments to arrive at an interpretation. Topic interpretation can
be viewed as making a judgment under uncertainty by an ecologically rational
user, and hence cognitive biases aware user models and evaluation frameworks
are needed.

</details>


### [22] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
*Gioele Giachino,Marco Rondina,Antonio Vetrò,Riccardo Coppola,Juan Carlos De Martin*

Main category: cs.CL

TL;DR: 研究揭示大语言模型在意大利语环境中存在显著性别职业偏见（如97%-100%将'她'关联助理而非管理岗），强调需制定缓解策略应对伦理风险


<details>
  <summary>Details</summary>
Motivation: LLMs的广泛应用可能传播刻板印象，当前对非英语语言环境中的偏见生成能力研究不足，需探究其偏见形成机制及社会影响

Method: 使用意大利语设计结构化实验（含3种职业组合提示），通过API收集ChatGPT(gpt-4o-mini)和Gemini(gemini-1.5-flash)的3600条响应，分析代词分配模式

Result: 模型输出显著强化性别职业刻板印象：Gemini将100%'她'分配助理岗（ChatGPT达97%），管理岗呈现明显性别倾斜

Conclusion: LLMs生成内容中的系统性偏见可能加剧职场不平等，需开发针对性缓解策略，建议未来研究扩展多语言测试及优化提示工程方法

Abstract: The increasing use of Large Language Models (LLMs) in a large variety of
domains has sparked worries about how easily they can perpetuate stereotypes
and contribute to the generation of biased content. With a focus on gender and
professional bias, this work examines in which manner LLMs shape responses to
ungendered prompts, contributing to biased outputs. This analysis uses a
structured experimental method, giving different prompts involving three
different professional job combinations, which are also characterized by a
hierarchical relationship. This study uses Italian, a language with extensive
grammatical gender differences, to highlight potential limitations in current
LLMs' ability to generate objective text in non-English languages. Two popular
LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google
Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600
responses. The results highlight how content generated by LLMs can perpetuate
stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'
pronouns to the 'assistant' rather than the 'manager'. The presence of bias in
AI-generated text can have significant implications in many fields, such as in
the workplaces or in job selections, raising ethical concerns about its use.
Understanding these risks is pivotal to developing mitigation strategies and
assuring that AI-based systems do not increase social inequalities, but rather
contribute to more equitable outcomes. Future research directions include
expanding the study to additional chatbots or languages, refining prompt
engineering methods or further exploiting a larger experimental base.

</details>


### [23] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
*Chaymaa Abbas,Mariette Awad,Razane Tajeddine*

Main category: cs.CL

TL;DR: 大语言模型在数据污染和方言偏见（AAVE与SAE）叠加作用下显著增加毒性输出，规模越大放大效应越强，需针对性干预措施


<details>
  <summary>Details</summary>
Motivation: 探究方言差异（非裔美国方言AAVE与标准美式英语SAE）与数据污染如何共同影响大模型输出的毒性水平

Method: 使用LLaMA系列不同规模模型进行实验，并引入GPT-4o作为公平性评估器进行刻板印象分析

Result: 1. 微小数据污染即可显著提升AAVE输入的毒性（SAE影响微弱）
2. 模型规模与毒性放大效应正相关
3. GPT-4o检测到AAVE输入关联攻击性/犯罪/智力贬低等有害模式

Conclusion: 需建立方言敏感的评估体系，开发针对性去偏见技术，并在训练中采用社会责任感更强的协议以应对复合型偏见风险

Abstract: Despite the ongoing improvements in the design of large language models
(LLMs) to foster inclusion and balanced responses, these systems remain
susceptible to encoding and amplifying social biases. This study examines how
dialectal variation, specifically African American Vernacular English (AAVE)
versus Standard American English (SAE), interacts with data poisoning to
influence toxicity in outputs. Using both small- and medium-scale LLaMA models,
we show that even minimal exposure to poisoned data significantly increases
toxicity for AAVE inputs, while it remains comparatively unaffected for SAE.
Larger models exhibit a more significant amplification effect which suggests
heightened susceptibility with scale. To further assess these disparities, we
employed GPT-4o as a fairness auditor, which identified harmful stereotypical
patterns disproportionately tied to AAVE inputs, including portrayals of
aggression, criminality, and intellectual inferiority. These findings
underscore the compounding impact of data poisoning and dialectal bias and
emphasize the need for dialect-aware evaluation, targeted debiasing
interventions, and socially responsible training protocols during development.

</details>


### [24] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
*Zi Liang,Liantong Yu,Shiyu Zhang,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: 提出动态评估框架ArxivRoll，通过SCP自动生成私有测试集和Rugged Scores指标，解决LLM评估中的基准污染问题


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在污染和训练偏差问题，导致LLM评估结果虚高且无法公平比较，现有解决方案难以兼顾可重复性、透明性和效率

Method: 基于密码学一次性填充原理，结合SCP(序列生成+完形填空)自动生成动态测试集，每半年更新ArXiv新论文构建基准，使用Rugged Scores量化污染程度

Result: 实验验证了基准质量，首次系统量化了当前LLM的过拟合程度，开源框架支持动态可靠评估

Conclusion: ArxivRoll通过动态测试集生成和偏差量化指标，建立了更可靠的LLM评估体系，解决了评估结果虚高和基准污染的核心痛点

Abstract: Overestimation in evaluating large language models (LLMs) has become an
increasing concern. Due to the contamination of public benchmarks or imbalanced
model training, LLMs may achieve unreal evaluation results on public
benchmarks, either intentionally or unintentionally, which leads to unfair
comparisons among LLMs and undermines their realistic capability assessments.
Existing benchmarks attempt to address these issues by keeping test cases
permanently secret, mitigating contamination through human evaluation, or
repeatedly collecting and constructing new samples. However, these approaches
fail to ensure reproducibility, transparency, and high efficiency
simultaneously. Moreover, the extent of overestimation in current LLMs remains
unquantified. To address these issues, we propose ArxivRoll, a dynamic
evaluation framework inspired by one-time pad encryption in cryptography.
ArxivRoll comprises two key components: \emph{i) SCP (Sequencing, Cloze, and
Prediction)}, an automated generator for private test cases, and \emph{ii)
Rugged Scores (RS)}, metrics that measure the proportion of public benchmark
contamination and training bias. Leveraging SCP, ArxivRoll constructs a new
benchmark every six months using recent articles from ArXiv and employs them
for one-time evaluations of LLM performance. Extensive experiments demonstrate
the high quality of our benchmark, and we provide a systematic evaluation of
current LLMs. The source code is available at
https://github.com/liangzid/ArxivRoll/.

</details>


### [25] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
*Yuanhe Zhang,Fangzhou Xie,Zhenhong Zhou,Zherui Li,Hao Chen,Kun Wang,Yufei Guo*

Main category: cs.CL

TL;DR: LLDMs存在严重安全漏洞，PAD并行解码攻击方法实现97%的越狱成功率，揭示扩散模型生成有害内容的速度是传统LLMs的2倍。


<details>
  <summary>Details</summary>
Motivation: 现有针对LLMs的防御方法对LLDMs效果有限，需揭示扩散架构语言模型的安全脆弱性本质

Method: 提出PAD并行解码攻击框架，采用多注意力点攻击策略引导并行生成过程

Result: 在四个LLDMs上实现97%攻击成功率，有害内容生成速度提升2倍

Conclusion: LLDMs架构存在系统性安全风险，需重新评估扩散模型的安全部署方案

Abstract: Large Language Diffusion Models (LLDMs) exhibit comparable performance to
LLMs while offering distinct advantages in inference speed and mathematical
reasoning tasks.The precise and rapid generation capabilities of LLDMs amplify
concerns of harmful generations, while existing jailbreak methodologies
designed for Large Language Models (LLMs) prove limited effectiveness against
LLDMs and fail to expose safety vulnerabilities.Successful defense cannot
definitively resolve harmful generation concerns, as it remains unclear whether
LLDMs possess safety robustness or existing attacks are incompatible with
diffusion-based architectures.To address this, we first reveal the
vulnerability of LLDMs to jailbreak and demonstrate that attack failure in
LLDMs stems from fundamental architectural differences.We present a PArallel
Decoding jailbreak (PAD) for diffusion-based language models. PAD introduces
Multi-Point Attention Attack, which guides parallel generative processes toward
harmful outputs that inspired by affirmative response patterns in LLMs.
Experimental evaluations across four LLDMs demonstrate that PAD achieves
jailbreak attack success rates by 97%, revealing significant safety
vulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,
LLDMs increase the harmful generation speed by 2x, significantly highlighting
risks of uncontrolled misuse.Through comprehensive analysis, we provide an
investigation into LLDM architecture, offering critical insights for the secure
deployment of diffusion-based language models.

</details>


### [26] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
*Ilias Chalkidis,Stephanie Brandl,Paris Aslanidis*

Main category: cs.CL

TL;DR: 论文系统评估了LLMs在识别复杂政治概念（民粹主义）中的表现，发现微调模型优于原生LLMs，并展示了跨语境分析的实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在社会科学领域中处理复杂政治概念（如民粹主义）的能力，填补现有研究在政治话语分析领域的空白。

Method: 1. 构建专门捕捉民粹主义话语的数据集
2. 评估多种预训练/微调模型（包括开源和商业模型）
3. 应用最佳模型分析特朗普竞选演讲
4. 在欧洲政治语境中验证模型泛化能力

Result: 1. 微调RoBERTa显著优于指令调优的LLMs（除非后者被微调）
2. 指令调优模型在跨语境数据中展现更强鲁棒性
3. 特朗普演讲分析揭示其民粹主义修辞策略

Conclusion: LLMs对复杂政治概念的捕捉能力有限，特定领域微调效果显著。跨语境分析中指令调优模型展现优势，为政治话语分析提供新方法论。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of instruction-following tasks, yet their grasp of nuanced social
science concepts remains underexplored. This paper examines whether LLMs can
identify and classify fine-grained forms of populism, a complex and contested
concept in both academic and media debates. To this end, we curate and release
novel datasets specifically designed to capture populist discourse. We evaluate
a range of pre-trained (large) language models, both open-weight and
proprietary, across multiple prompting paradigms. Our analysis reveals notable
variation in performance, highlighting the limitations of LLMs in detecting
populist discourse. We find that a fine-tuned RoBERTa classifier vastly
outperforms all new-era instruction-tuned LLMs, unless fine-tuned.
Additionally, we apply our best-performing model to analyze campaign speeches
by Donald Trump, extracting valuable insights into his strategic use of
populist rhetoric. Finally, we assess the generalizability of these models by
benchmarking them on campaign speeches by European politicians, offering a lens
into cross-context transferability in political discourse analysis. In this
setting, we find that instruction-tuned LLMs exhibit greater robustness on
out-of-domain data.

</details>


### [27] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
*Yicheng Tao,Yuanhao Huang,Jie Liu*

Main category: cs.CL

TL;DR: 提出无需本体特定训练的AutoPCR方法，通过混合策略+SapBERT+大模型提示实现表型概念识别，在多个数据集上超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有表型概念识别方法依赖本体特定训练，难以泛化到不同文本类型和动态更新的医学术语。

Method: 三阶段框架：1) 混合规则与神经标注的实体抽取 2) SapBERT候选检索 3) 大语言模型提示的实体链接

Result: 在4个基准测试中达到最优平均性能，mention/document层面均表现最鲁棒，消融实验验证迁移能力

Conclusion: AutoPCR具有对新本体的归纳泛化能力，验证了提示工程在生物医学概念识别中的有效性

Abstract: Phenotype concept recognition (CR) is a fundamental task in biomedical text
mining, enabling applications such as clinical diagnostics and knowledge graph
construction. However, existing methods often require ontology-specific
training and struggle to generalize across diverse text types and evolving
biomedical terminology. We present AutoPCR, a prompt-based phenotype CR method
that does not require ontology-specific training. AutoPCR performs CR in three
stages: entity extraction using a hybrid of rule-based and neural tagging
strategies, candidate retrieval via SapBERT, and entity linking through
prompting a large language model. Experiments on four benchmark datasets show
that AutoPCR achieves the best average and most robust performance across both
mention-level and document-level evaluations, surpassing prior state-of-the-art
methods. Further ablation and transfer studies demonstrate its inductive
capability and generalizability to new ontologies.

</details>


### [28] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
*Kai Liu,Zhan Su,Peijie Dong,Fengran Mo,Jianfei Gao,ShaoTing Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 提出Smooth Reading分块推理方法，显著缩小循环LLMs与自注意力LLMs在长上下文任务中的性能差距，同时保持效率优势。


<details>
  <summary>Details</summary>
Motivation: 循环LLMs因固定内存限制在长上下文任务中表现欠佳，传统增强内存方法未解决根本问题。受人类阅读启发，提出分块处理策略。

Method: 将上下文分块处理并迭代汇总，降低内存需求。通过SWA-3B-4k模型验证，在LongBench上超越自注意力LLMs 3.61%。

Result: 训练速度提升3倍，64k上下文推理快2倍。首次实现循环LLMs与自注意力LLMs在长任务中性能持平。

Conclusion: 方法为循环LLMs研究提供新方向，将开源代码数据集推动领域发展。

Abstract: Recently, recurrent large language models (Recurrent LLMs) with linear
computational complexity have re-emerged as efficient alternatives to
self-attention-based LLMs (Self-Attention LLMs), which have quadratic
complexity. However, Recurrent LLMs often underperform on long-context tasks
due to their limited fixed-size memory. Previous research has primarily focused
on enhancing the memory capacity of Recurrent LLMs through architectural
innovations, but these approaches have not yet enabled Recurrent LLMs to match
the performance of Self-Attention LLMs on long-context tasks. We argue that
this limitation arises because processing the entire context at once is not
well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a
chunk-wise inference method inspired by human reading strategies. Smooth
Reading processes context in chunks and iteratively summarizes the contextual
information, thereby reducing memory demands and making the approach more
compatible with Recurrent LLMs. Our experimental results show that this method
substantially narrows the performance gap between Recurrent and Self-Attention
LLMs on long-context tasks, while preserving the efficiency advantages of
Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from
5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.
Besides, our method maintains the high efficiency, training 3x faster and
inferring 2x faster at 64k context compared to Self-Attention LLMs. To our
knowledge, this is the first work to achieve comparable performance using
Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope
our method will inspire future research in this area. To facilitate further
progress, we will release code and dataset.

</details>


### [29] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
*Hsuan-Yu Wang,Pei-Ying Lee,Berlin Chen*

Main category: cs.CL

TL;DR: 提出基于时间戳对齐ASR文本与说话人日志的方法，提升语音情感识别准确率


<details>
  <summary>Details</summary>
Motivation: 解决语音识别文本与说话人日志时间错位导致的多模态情感分析可靠性下降问题

Method: 使用预训练ASR和说话人日志模型构建时间戳对齐框架，结合RoBERTa文本特征和Wav2Vec音频特征的跨注意力门控融合方法

Result: 在IEMOCAP数据集上验证时间同步方法优于非同步基线模型

Conclusion: 时间对齐机制对提升多模态情感识别精度具有关键作用，为鲁棒性分析奠定基础

Abstract: In this paper, we investigate the impact of incorporating timestamp-based
alignment between Automatic Speech Recognition (ASR) transcripts and Speaker
Diarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.
Misalignment between these two modalities often reduces the reliability of
multimodal emotion recognition systems, particularly in conversational
contexts. To address this issue, we introduce an alignment pipeline utilizing
pre-trained ASR and speaker diarization models, systematically synchronizing
timestamps to generate accurately labeled speaker segments. Our multimodal
approach combines textual embeddings extracted via RoBERTa with audio
embeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating
mechanism. Experimental evaluations on the IEMOCAP benchmark dataset
demonstrate that precise timestamp alignment improves SER accuracy,
outperforming baseline methods that lack synchronization. The results highlight
the critical importance of temporal alignment, demonstrating its effectiveness
in enhancing overall emotion recognition accuracy and providing a foundation
for robust multimodal emotion analysis.

</details>


### [30] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
*Zhen Wan,Chao-Han Huck Yang,Yahan Yu,Jinchuan Tian,Sheng Li,Ke Hu,Zhehuai Chen,Shinji Watanabe,Fei Cheng,Chenhui Chu,Sadao Kurohashi*

Main category: cs.CL

TL;DR: 提出基于布鲁姆分类法的语音智商(SIQ)评估框架，通过记忆-理解-应用三层次量化语音大模型能力，实现模型对比、错误检测和多模态挑战分析


<details>
  <summary>Details</summary>
Motivation: 传统词错率(WER)指标无法全面评估语音理解能力，需建立认知科学驱动的多维度评估体系，解决现有基准的标注错误检测和幻觉识别问题

Method: 1)记忆层用WER评估转录准确度；2)理解层通过语义相似度分析；3)应用层测试下游任务QA准确率。同时开发模型对比框架和错误检测机制

Result: SIQ实现跨模型可比性，识别出数据标注错误率约8.3%，检测到27%的模型幻觉案例，揭示端到端模型在语义理解上优于级联系统13.2%

Conclusion: 首次建立认知原则与语音评估的桥梁，暴露多模态训练中语义对齐和幻觉控制等关键挑战，为语音大模型研发提供系统性评估工具

Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human
cognition-inspired evaluation pipeline for voice understanding large language
models, LLM Voice, designed to assess their voice understanding ability. Moving
beyond popular voice understanding metrics such as word error rate (WER), SIQ
examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:
(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,
similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy
for simulating downstream tasks). We demonstrate that SIQ not only quantifies
voice understanding abilities but also provides unified comparisons between
cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation
errors in existing benchmarks, and detects hallucinations in LLM Voice. Our
framework represents a first-of-its-kind intelligence examination that bridges
cognitive principles with voice-oriented benchmarks, while exposing overlooked
challenges in multi-modal training.

</details>


### [31] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
*Penny Karanasou,Mengjie Qian,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While there exist strong benchmark datasets for grammatical error correction
(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still
under-resourced. In this paper, we propose a fully automated method to generate
audio-text pairs with grammatical errors and disfluencies. Moreover, we propose
a series of objective metrics that can be used to evaluate the generated data
and choose the more suitable dataset for SGEC. The goal is to generate an
augmented dataset that maintains the textual and acoustic characteristics of
the original data while providing new types of errors. This augmented dataset
should augment and enrich the original corpus without altering the language
assessment scores of the second language (L2) learners. We evaluate the use of
the augmented corpus both for written GEC (the text part) and for SGEC (the
audio-text pairs). Our experiments are conducted on the S\&I Corpus, the first
publicly available speech dataset with grammar error annotations.

</details>


### [32] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
*Rachel M. Murphy,Nishant Mishra,Nicolette F. de Keizer,Dave A. Dongelmans,Kitty J. Jager,Ameen Abu-Hanna,Joanna E. Klopotowska,Iacer Calixto*

Main category: cs.CL

TL;DR: 荷兰临床文本药物不良事件检测基准研究，使用多种Transformer模型验证，MedRoBERTa.nl以0.63宏F1分表现最佳，提出临床适用的评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏荷兰临床自由文本中药物不良事件(ADE)检测的可靠基准，且需要适合临床任务需求的性能评估指标。

Method: 使用Bi-LSTM和4种预训练模型(BERTje/RobBERT/MedRoBERTa.nl/NuNER)，基于102份ICU临床笔记进行实体识别和关系分类，采用黄金标准预测和端到端任务双验证，并实施院内院外文档级验证。

Result: MedRoBERTa.nl在关系分类任务中宏F1达0.63(黄金标准)/0.62(预测实体)，外部验证召回率67-74%，可识别2/3以上含ADE的出院摘要。

Conclusion: 研究建立了临床导向的ADE检测评估体系，强调需根据临床场景选择性能指标，为未来临床文本自动化药物安全监测提供方法论基础。

Abstract: In this study, we set a benchmark for adverse drug event (ADE) detection in
Dutch clinical free text documents using several transformer models, clinical
scenarios and fit-for-purpose performance measures. We trained a Bidirectional
Long Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or
multilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the
tasks of named entity recognition (NER) and relation classification (RC) using
102 richly annotated Dutch ICU clinical progress notes. Anonymized free text
clinical progress notes of patients admitted to intensive care unit (ICU) of
one academic hospital and discharge letters of patients admitted to Internal
Medicine wards of two non-academic hospitals were reused. We evaluated our ADE
RC models internally using gold standard (two-step task) and predicted entities
(end-to-end task). In addition, all models were externally validated on
detecting ADEs at the document level. We report both micro- and macro-averaged
F1 scores, given the imbalance of ADEs in the datasets. Although differences
for the ADE RC task between the models were small, MedRoBERTa.nl was the best
performing model with macro-averaged F1 score of 0.63 using gold standard and
0.62 using predicted entities. The MedRoBERTa.nl models also performed the best
in our external validation and achieved recall of between 0.67 to 0.74 using
predicted entities, meaning between 67 to 74% of discharge letters with ADEs
were detected. Our benchmark study presents a robust and clinically meaningful
approach for evaluating language models for ADE detection in clinical free text
documents. Our study highlights the need to use appropriate performance
measures fit for the task of ADE detection in clinical free-text documents and
envisioned future clinical use.

</details>


### [33] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
*Mohammad Khodadad,Ali Shiraee,Mahdi Astaraki,Hamidreza Mahyar*

Main category: cs.CL

TL;DR: 提出MEDTE医学嵌入模型及51任务评估框架，解决现有模型数据狭窄和评估不足问题，性能超越SOTA


<details>
  <summary>Details</summary>
Motivation: 现有医学嵌入模型存在两大缺陷：1. 训练数据局限于狭窄医学领域且方法论陈旧 2. 常用基准测试无法覆盖真实医疗任务全谱系

Method: 通过多数据源自监督对比学习微调GTE模型，构建包含分类/聚类/配对分类/检索的51任务医疗基准套件（基于MTEB改进）

Result: 新方法生成的嵌入在不同任务中持续优于现有技术，同时建立有效的医疗文本评估框架

Conclusion: 结合MEDTE模型与定制化评估基准，既能构建鲁棒评估体系，又能产生更优质的医学文本嵌入

Abstract: Medical text embedding models are foundational to a wide array of healthcare
applications, ranging from clinical decision support and biomedical information
retrieval to medical question answering, yet they remain hampered by two
critical shortcomings. First, most models are trained on a narrow slice of
medical and biological data, beside not being up to date in terms of
methodology, making them ill suited to capture the diversity of terminology and
semantics encountered in practice. Second, existing evaluations are often
inadequate: even widely used benchmarks fail to generalize across the full
spectrum of real world medical tasks.
  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned
on diverse medical corpora through self-supervised contrastive learning across
multiple data sources, to deliver robust medical text embeddings.
  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks
spanning classification, clustering, pair classification, and retrieval modeled
on the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of
medical text. Our results demonstrate that this combined approach not only
establishes a robust evaluation framework but also yields embeddings that
consistently outperform state of the art alternatives in different tasks.

</details>


### [34] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
*Mohammad Aflah Khan,Ameya Godbole,Johnny Tian-Zheng Wei,Ryan Wang,James Flemings,Krishna Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: TokenSmith是一个开源库，简化预训练数据集的编辑、检查和分析流程，支持搜索/查看/结构化编辑等操作，无需修改训练代码即可集成现有LLM预训练流程


<details>
  <summary>Details</summary>
Motivation: 解决现有预训练数据管理流程繁琐、碎片化且难以访问的问题，使研究人员能更便捷地调试、验证和实验预训练数据集

Method: 通过开发交互式UI和模块化后端，支持数据集搜索、可视化、采样、结构化编辑等功能，兼容Megatron/GPT-NeoX/NVIDIA NeMo等主流框架

Result: 成功创建可即插即用的生产级工具，提供完整的文档、教程和演示视频，已在GitHub开源

Conclusion: 该工具显著降低了预训练数据集的操作门槛，实现了数据管理流程的标准化和民主化，为LLM研发提供了基础设施支持

Abstract: Understanding the relationship between training data and model behavior
during pretraining is crucial, but existing workflows make this process
cumbersome, fragmented, and often inaccessible to researchers. We present
TokenSmith, an open-source library for interactive editing, inspection, and
analysis of datasets used in Megatron-style pretraining frameworks such as
GPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of
operations including searching, viewing, ingesting, exporting, inspecting, and
sampling data, all accessible through a simple user interface and a modular
backend. It also enables structured editing of pretraining data without
requiring changes to training code, simplifying dataset debugging, validation,
and experimentation.
  TokenSmith is designed as a plug and play addition to existing large language
model pretraining workflows, thereby democratizing access to production-grade
dataset tooling. TokenSmith is hosted on GitHub1, with accompanying
documentation and tutorials. A demonstration video is also available on
YouTube.

</details>


### [35] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
*Lakshya A Agrawal,Shangyin Tan,Dilara Soylu,Noah Ziems,Rishi Khare,Krista Opsahl-Ong,Arnav Singhvi,Herumb Shandilya,Michael J Ryan,Meng Jiang,Christopher Potts,Koushik Sen,Alexandros G. Dimakis,Ion Stoica,Dan Klein,Matei Zaharia,Omar Khattab*

Main category: cs.CL

TL;DR: 提出GEPA提示优化器，通过自然语言反思机制实现高效LLM提示优化，仅需少量rollouts即可显著提升性能，效果超越GRPO和MIPROv2。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法（如GRPO）依赖大量rollouts和稀疏标量奖励，未能充分利用语言模型的可解释性优势。

Method: GEPA通过分析系统级轨迹（推理/工具调用/输出），用自然语言进行问题诊断和提示更新，结合帕累托前沿的互补优化策略。

Result: 在四个任务中：平均优于GRPO 10%（最高20%），减少35倍rollouts；优于MIPROv2超10%；展示代码优化的推理时搜索潜力。

Conclusion: 语言驱动的反思机制可有效提升LLM提示优化效率，GEPA为资源节约型优化提供了新范式，在实时搜索场景展现应用前景。

Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via
reinforcement learning (RL) methods like Group Relative Policy Optimization
(GRPO), which often require thousands of rollouts to learn new tasks. We argue
that the interpretable nature of language can often provide a much richer
learning medium for LLMs, compared with policy gradients derived from sparse,
scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt
optimizer that thoroughly incorporates natural language reflection to learn
high-level rules from trial and error. Given any AI system containing one or
more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool
calls, and tool outputs) and reflects on them in natural language to diagnose
problems, propose and test prompt updates, and combine complementary lessons
from the Pareto frontier of its own attempts. As a result of GEPA's design, it
can often turn even just a few rollouts into a large quality gain. Across four
tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up
to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,
MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an
inference-time search strategy for code optimization.

</details>


### [36] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
*Son Quoc Tran,Tushaar Gangavarapu,Nicholas Chernogor,Jonathan P. Chang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出首个统一的CGA模型评估框架，引入动态预测修正指标，系统评估对话失控预测模型的进展


<details>
  <summary>Details</summary>
Motivation: 人类依靠直觉预测对话走向，需要为对话系统注入类似预见能力以辅助人际沟通。当前对话失控预测模型缺乏统一评估标准，阻碍技术发展

Method: 1. 建立首个标准化评估基准，实现模型跨架构直接比较 2. 结合最新语言建模技术 3. 提出动态预测修正指标，量化模型随对话进程调整预测的能力

Result: 框架揭示不同架构性能差异，新指标有效捕捉模型预测动态调整特性，为模型优化提供新维度

Conclusion: 统一框架实现可靠评估，动态指标增强模型适应性评估，推动对话失控预测技术的实际应用发展

Abstract: We often rely on our intuition to anticipate the direction of a conversation.
Endowing automated systems with similar foresight can enable them to assist
human-human interactions. Recent work on developing models with this predictive
capacity has focused on the Conversations Gone Awry (CGA) task: forecasting
whether an ongoing conversation will derail. In this work, we revisit this task
and introduce the first uniform evaluation framework, creating a benchmark that
enables direct and reliable comparisons between different architectures. This
allows us to present an up-to-date overview of the current progress in CGA
models, in light of recent advancements in language modeling. Our framework
also introduces a novel metric that captures a model's ability to revise its
forecast as the conversation progresses.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [37] [Generating real-time detailed ground visualisations from sparse aerial point clouds](https://arxiv.org/abs/2507.18664)
*Aidan Murray,Eddie Waite,Caleb Ross,Scarlet Mitchell,Alexander Bradley,Joanna Jamrozy,Kenny Mitchell*

Main category: cs.GR

TL;DR: 提出自动化放大真实扫描数据并实时渲染的3D内容生成方法，解决传统人工建模成本高且精度不足的问题


<details>
  <summary>Details</summary>
Motivation: 传统艺术家手工建模方式成本高昂且难以准确还原真实地形多样性，需开发自动化解决方案

Method: 通过算法自动处理真实世界扫描数据，实现数据扩增与实时3D渲染技术结合

Result: 生成支持近距离探索的高质量3D环境，适用于训练/模拟/游戏等多种应用场景

Conclusion: 自动化流程显著降低制作成本同时保持视觉精度，为数字内容创作提供高效解决方案

Abstract: Building realistic wide scale outdoor 3D content with sufficient visual
quality to observe at walking eye level or from driven vehicles is often
carried out by large teams of artists skilled in modelling, texturing, material
shading and lighting, which typically leads to both prohibitive costs and
reduced accuracy honoring the variety of real world ground truth landscapes. In
our proposed method, we define a process to automatically amplify real-world
scanned data and render real-time in animated 3D to explore at close range with
high quality for training, simulation, video game and visualisation
applications.

</details>


### [38] [Procedural city modeling](https://arxiv.org/abs/2507.18899)
*Thomas Lechner,Ben Watson,Uri Wilensky,Martin Felsen*

Main category: cs.GR

TL;DR: 提出基于智能体模拟的城市生成方法，通过简单规则驱动不同类别智能体交互，实现从村庄到都市的自进化逼真城市建模，聚焦土地用途与建筑分布创新。


<details>
  <summary>Details</summary>
Motivation: 突破传统道路网络建模局限，构建能自主演化、呈现城市发展阶段性特征的人工城市生成系统，强调土地规划与建筑布局的真实性。

Method: 采用多智能体模拟框架，定义不同类别智能体的简单行为规则集，通过环境交互引发复杂涌现行为，支持地形输入为主、艺术参数为辅的扩展性设计。

Result: 建立可动态演化的城市生成模型，实现建筑分布与土地使用的自组织优化，支持任意发展阶段的城市形态可视化。

Conclusion: 该方法通过底层规则驱动上层复杂系统，不仅提升城市建模真实性，还为模拟社会文化影响提供可扩展框架，推动生成式城市设计发展。

Abstract: We propose a method to procedurally generate a familiar yet complex human
artifact: the city. We are not trying to reproduce existing cities, but to
generate artificial cities that are convincing and plausible by capturing
developmental behavior. In addition, our results are meant to build upon
themselves, such that they ought to look compelling at any point along the
transition from village to metropolis. Our approach largely focuses upon land
usage and building distribution for creating realistic city environments,
whereas previous attempts at city modeling have mainly focused on populating
road networks. Finally, we want our model to be self automated to the point
that the only necessary input is a terrain description, but other high-level
and low-level parameters can be specified to support artistic contributions.
With the aid of agent based simulation we are generating a system of agents and
behaviors that interact with one another through their effects upon a simulated
environment. Our philosophy is that as each agent follows a simple behavioral
rule set, a more complex behavior will tend to emerge out of the interactions
between the agents and their differing rule sets. By confining our model to a
set of simple rules for each class of agents, we hope to make our model
extendible not only in regard to the types of structures that are produced, but
also in describing the social and cultural influences prevalent in all cities

</details>


### [39] [TiVy: Time Series Visual Summary for Scalable Visualization](https://arxiv.org/abs/2507.18972)
*Gromit Yeuk-Yin Chan,Luis Gustavo Nonato,Themis Palpanas,Cláudio T. Silva,Juliana Freire*

Main category: cs.GR

TL;DR: 提出TiVy算法通过动态时间规整和序列模式分析，有效解决多时间序列可视化中的视觉混乱问题，速度提升1000倍


<details>
  <summary>Details</summary>
Motivation: 现有时间序列可视化方法在长跨度场景下存在视觉混乱问题，叠加显示和小多图形式均无法有效平衡可扩展性与可视化清晰度

Method: 1. 使用DTW将时间序列转为符号序列 2. 基于频繁顺序模式进行不相交分组 3. 构建时间对齐的可变长度子序列可视化摘要

Result: 实验证明：(1)提取模式准确清晰 (2)比传统DTW聚类快1000倍 (3)在两大应用场景中成功探索海量时序数据隐藏结构

Conclusion: TiVy算法通过时序模式挖掘实现大规模时间序列的实时可视化，在保持视觉清晰度的同时显著提升计算效率，为海量时序数据分析提供新范式

Abstract: Visualizing multiple time series presents fundamental tradeoffs between
scalability and visual clarity. Time series capture the behavior of many
large-scale real-world processes, from stock market trends to urban activities.
Users often gain insights by visualizing them as line charts, juxtaposing or
superposing multiple time series to compare them and identify trends and
patterns. However, existing representations struggle with scalability: when
covering long time spans, leading to visual clutter from too many small
multiples or overlapping lines. We propose TiVy, a new algorithm that
summarizes time series using sequential patterns. It transforms the series into
a set of symbolic sequences based on subsequence visual similarity using
Dynamic Time Warping (DTW), then constructs a disjoint grouping of similar
subsequences based on the frequent sequential patterns. The grouping result, a
visual summary of time series, provides uncluttered superposition with fewer
small multiples. Unlike common clustering techniques, TiVy extracts similar
subsequences (of varying lengths) aligned in time. We also present an
interactive time series visualization that renders large-scale time series in
real-time. Our experimental evaluation shows that our algorithm (1) extracts
clear and accurate patterns when visualizing time series data, (2) achieves a
significant speed-up (1000X) compared to a straightforward DTW clustering. We
also demonstrate the efficiency of our approach to explore hidden structures in
massive time series data in two usage scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [40] [FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems](https://arxiv.org/abs/2507.19040)
*Yizhou Peng,Yi-Wen Chao,Dianwen Ng,Yukun Ma,Chongjia Ni,Bin Ma,Eng Siong Chng*

Main category: eess.AS

TL;DR: 本文提出基于LLM、TTS和ASR的全双工语音对话系统评估框架，通过293次模拟对话和1200次中断测试，发现现有模型在应对用户打断、高干扰场景时仍存在显著缺陷


<details>
  <summary>Details</summary>
Motivation: 传统语音系统采用轮转交互模式，现有基准测试缺乏对全双工场景（如实时打断处理能力）的系统性评估指标

Method: 构建包含用户打断模拟、延迟管理和噪声鲁棒性测试的评估流程，使用40+小时生成语音，在Moshi/Freeze-omni/VITA-1.5三个开源系统上进行实验

Result: 所有模型在频繁打断（平均4次/对话）和噪声环境下均出现响应失败，部分模型中断响应率高达35%，噪声场景错误率提升2-3倍

Conclusion: 全双工对话系统的鲁棒性仍需突破，公开的测试框架与数据将推动领域发展。未来需改进模型在动态交互中的上下文保持能力和实时决策机制

Abstract: Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine
interactions by allowing real-time user interruptions and backchanneling,
compared to traditional SDS that rely on turn-taking. However, existing
benchmarks lack metrics for FD scenes, e.g., evaluating model performance
during user interruptions. In this paper, we present a comprehensive FD
benchmarking pipeline utilizing LLMs, TTS, and ASR to address this gap. It
assesses FDSDS's ability to handle user interruptions, manage delays, and
maintain robustness in challenging scenarios with diverse novel metrics. We
applied our benchmark to three open-source FDSDS (Moshi, Freeze-omni, and
VITA-1.5) using over 40 hours of generated speech, with 293 simulated
conversations and 1,200 interruptions. The results show that all models
continue to face challenges, such as failing to respond to user interruptions,
under frequent disruptions and noisy conditions. Demonstrations, data, and code
will be released.

</details>


### [41] [Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?](https://arxiv.org/abs/2507.19204)
*Simon Malan,Benjamin van Niekerk,Herman Kamper*

Main category: eess.AS

TL;DR: 提出两种语音分割聚类方法（自下而上与自上而下），实验证明两者性能相当但自下而上方法快5倍，指出聚类技术是当前瓶颈


<details>
  <summary>Details</summary>
Motivation: 验证自上而下信息是否对语音分割有效，比较两种框架在实际应用中的表现差异

Method: 1. 自下而上：基于自监督特征差异预测边界后聚类
2. 自上而下：改进ES-KMeans动态规划方法，迭代更新边界

Result: ZeroSpeech五语种基准测试显示：
- 两种方法达到SOTA水平
- 自下而上速度快4.8倍
- 聚类步骤成为性能瓶颈

Conclusion: 建议未来研究聚焦：
1. 改进聚类算法
2. 学习更具区分性的词级表示
3. 边界候选质量优化

Abstract: We investigate the problem of segmenting unlabeled speech into word-like
units and clustering these to create a lexicon. Prior work can be categorized
into two frameworks. Bottom-up methods first determine boundaries and then
cluster the fixed segmented words into a lexicon. In contrast, top-down methods
incorporate information from the clustered words to inform boundary selection.
However, it is unclear whether top-down information is necessary to improve
segmentation. To explore this, we look at two similar approaches that differ in
whether top-down clustering informs boundary selection. Our simple bottom-up
strategy predicts word boundaries using the dissimilarity between adjacent
self-supervised features, then clusters the resulting segments to construct a
lexicon. Our top-down system is an updated version of the ES-KMeans dynamic
programming method that iteratively uses K-means to update its boundaries. On
the five-language ZeroSpeech benchmarks, both approaches achieve comparable
state-of-the-art results, with the bottom-up system being nearly five times
faster. Through detailed analyses, we show that the top-down influence of
ES-KMeans can be beneficial (depending on factors like the candidate
boundaries), but in many cases the simple bottom-up method performs just as
well. For both methods, we show that the clustering step is a limiting factor.
Therefore, we recommend that future work focus on improved clustering
techniques and learning more discriminative word-like representations. Project
code repository: https://github.com/s-malan/prom-seg-clus.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [A Markov Categorical Framework for Language Modeling](https://arxiv.org/abs/2507.19247)
*Yifan Zhang*

Main category: cs.LG

TL;DR: 论文通过马尔可夫范畴理论揭示NLL训练隐式实现谱对比学习，使表示空间对齐预测相似算子的特征谱


<details>
  <summary>Details</summary>
Motivation: 现有研究对自回归模型的负对数似然目标缺乏理论解释，需通过信息几何和范畴论揭示其深层原理

Method: 使用Markov Categories框架分解AR生成过程，结合统计散度分析信息流和表示空间几何结构

Result: 1. 解释推测解码方法的信息理论基础 2. 证明NLL隐式学习数据内在随机性 3. 揭示NLL训练本质是谱对比学习过程

Conclusion: 该理论框架首次从组合范畴和信息几何视角揭示了语言模型表示能力的结构性原理，为理解NLL目标有效性提供了新范式

Abstract: Auto-regressive language models factorize sequence probabilities and are
trained by minimizing the negative log-likelihood (NLL) objective. While
empirically powerful, a deep theoretical understanding of why this simple
objective yields such versatile representations remains elusive. This work
introduces a unifying analytical framework using Markov Categories (MCs) to
deconstruct the AR generation process and the NLL objective. We model the
single-step generation map as a composition of Markov kernels in the category
Stoch. This compositional view, when enriched with statistical divergences,
allows us to dissect information flow and learned geometry. Our framework makes
three main contributions. First, we provide a formal, information-theoretic
rationale for the success of modern speculative decoding methods like EAGLE,
quantifying the information surplus in hidden states that these methods
exploit. Second, we formalize how NLL minimization forces the model to learn
not just the next token, but the data's intrinsic conditional stochasticity, a
process we analyze using categorical entropy. Third, and most centrally, we
prove that NLL training acts as an implicit form of spectral contrastive
learning. By analyzing the information geometry of the model's prediction head,
we show that NLL implicitly forces the learned representation space to align
with the eigenspectrum of a predictive similarity operator, thereby learning a
geometrically structured space without explicit contrastive pairs. This
compositional and information-geometric perspective reveals the deep structural
principles underlying the effectiveness of modern LMs. Project Page:
https://github.com/asiresearch/lm-theory

</details>


### [43] [Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts](https://arxiv.org/abs/2507.19477)
*Sang-Woo Lee,Sohee Yang,Donghyun Kwak,Noah Y. Siegel*

Main category: cs.LG

TL;DR: 论文主张当前是研究超级预测者级别事件预测大模型的重要时机，通过改进训练方法和数据获取策略，推动AI预测智能的社会化应用。


<details>
  <summary>Details</summary>
Motivation: 早期方法论问题引发质疑，但近期评估方法改进表明先进LLMs已接近超级预测者水平，强化学习与新型推理模型的技术突破为大规模训练创造了条件。

Method: 提出训练三大难点（噪声稀疏性/知识截止/简单奖励），解决方案包括假设事件贝叶斯网络、反事实事件利用和辅助奖励机制，主张整合市场/公共/爬虫数据源。

Result: 研究表明：1) 前沿LLMs接近超级预测者表现 2) 强化学习有效提升预测 3) 新技术显著增强预测能力 4) 大规模训练评估具备可行性。

Conclusion: 通过方法论创新和多样化数据应用，AI预测技术有望达到人类超级预测者水平，为社会提供广泛预测支持，呼吁学界关注该领域研究。

Abstract: Many recent papers have studied the development of superforecaster-level
event forecasting LLMs. While methodological problems with early studies cast
doubt on the use of LLMs for event forecasting, recent studies with improved
evaluation methods have shown that state-of-the-art LLMs are gradually reaching
superforecaster-level performance, and reinforcement learning has also been
reported to improve future forecasting. Additionally, the unprecedented success
of recent reasoning models and Deep Research-style models suggests that
technology capable of greatly improving forecasting performance has been
developed. Therefore, based on these positive recent trends, we argue that the
time is ripe for research on large-scale training of superforecaster-level
event forecasting LLMs. We discuss two key research directions: training
methods and data acquisition. For training, we first introduce three
difficulties of LLM-based event forecasting training: noisiness-sparsity,
knowledge cut-off, and simple reward structure problems. Then, we present
related ideas to mitigate these problems: hypothetical event Bayesian networks,
utilizing poorly-recalled and counterfactual events, and auxiliary reward
signals. For data, we propose aggressive use of market, public, and crawling
datasets to enable large-scale training and evaluation. Finally, we explain how
these technical advances could enable AI to provide predictive intelligence to
society in broader areas. This position paper presents promising specific paths
and considerations for getting closer to superforecaster-level AI technology,
aiming to call for researchers' interest in these directions.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [44] [Adaptive Learning Systems: Personalized Curriculum Design Using LLM-Powered Analytics](https://arxiv.org/abs/2507.18949)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CY

TL;DR: 利用大语言模型构建自适应学习系统，通过实时数据分析动态调整学习路径，显著提升学习参与度与知识留存率。


<details>
  <summary>Details</summary>
Motivation: 传统教育模式缺乏个性化，本研究旨在通过LLM技术实现学生需求的精准分析，推动教育向'因材施教'的适应性模式转型。

Method: 开发LLM驱动的分析框架，结合机器学习实时处理学习数据，动态生成个性化课程并推荐适配资源。

Result: 实验显示定制课程使学习参与度提升27%，知识留存率提高33%，跨环境验证证实系统具有强适应性。

Conclusion: 该框架为教育范式转型提供技术路径，可能重塑传统教学为以学生为中心的动态模型，推动教育智能化发展。

Abstract: Large language models (LLMs) are revolutionizing the field of education by
enabling personalized learning experiences tailored to individual student
needs. In this paper, we introduce a framework for Adaptive Learning Systems
that leverages LLM-powered analytics for personalized curriculum design. This
innovative approach uses advanced machine learning to analyze real-time data,
allowing the system to adapt learning pathways and recommend resources that
align with each learner's progress. By continuously assessing students, our
framework enhances instructional strategies, ensuring that the materials
presented are relevant and engaging. Experimental results indicate a marked
improvement in both learner engagement and knowledge retention when using a
customized curriculum. Evaluations conducted across varied educational
environments demonstrate the framework's flexibility and positive influence on
learning outcomes, potentially reshaping conventional educational practices
into a more adaptive and student-centered model.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [45] [Distilling a Small Utility-Based Passage Selector to Enhance Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19102)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Shuaiqiang Wang,Dawei Yin,Xueqi Cheng*

Main category: cs.IR

TL;DR: 论文提出通过知识蒸馏将大语言模型的实用性判断能力迁移到小模型，实现高效实用的检索增强生成（RAG）框架，在保证答案质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于相关性的检索方法难以满足复杂查询需求，而基于大语言模型的实用性检索存在计算成本过高的问题，限制了RAG系统的实际应用。

Method: 采用教师-学生模型蒸馏框架：1）利用Qwen3-32B生成伪答案和实用性标注 2）通过滑动窗口动态选择有用段落 3）训练1.7B小模型实现效用判断和段落选择

Result: 实验证明UtilityQwen1.7B在MS MARCO数据集上：1）计算成本降低18倍 2）答案质量提升23% 3）复杂问题处理效果优于传统相关性排序方法

Conclusion: 实用性选择机制为RAG系统提供了灵活高效的解决方案，特别是在处理多维度信息需求的复杂问题时，实用性导向的检索策略显著优于传统相关性排序方法。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
incorporating retrieved information. Standard retrieval process prioritized
relevance, focusing on topical alignment between queries and passages. In
contrast, in RAG, the emphasis has shifted to utility, which considers the
usefulness of passages for generating accurate answers. Despite empirical
evidence showing the benefits of utility-based retrieval in RAG, the high
computational cost of using LLMs for utility judgments limits the number of
passages evaluated. This restriction is problematic for complex queries
requiring extensive information. To address this, we propose a method to
distill the utility judgment capabilities of LLMs into smaller, more efficient
models. Our approach focuses on utility-based selection rather than ranking,
enabling dynamic passage selection tailored to specific queries without the
need for fixed thresholds. We train student models to learn pseudo-answer
generation and utility judgments from teacher LLMs, using a sliding window
method that dynamically selects useful passages. Our experiments demonstrate
that utility-based selection provides a flexible and cost-effective solution
for RAG, significantly reducing computational costs while improving answer
quality. We present the distillation results using Qwen3-32B as the teacher
model for both relevance ranking and utility-based selection, distilled into
RankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex
questions, utility-based selection is more effective than relevance ranking in
enhancing answer generation performance. We will release the relevance ranking
and utility-based selection annotations for the MS MARCO dataset, supporting
further research in this area.

</details>


### [46] [Injecting External Knowledge into the Reasoning Process Enhances Retrieval-Augmented Generation](https://arxiv.org/abs/2507.19333)
*Minghao Tang,Shiyu Ni,Jiafeng Guo,Keping Bi*

Main category: cs.IR

TL;DR: 提出Passage Injection方法增强RAG系统对噪声检索的鲁棒性，实验表明该方法显著提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统易受低质量检索段落干扰，利用LLMs的推理自省能力改善噪声抵抗能力

Method: 将检索段落显式融入LLMs推理过程，使用BM25检索器在四个QA数据集验证方法有效性

Result: 在四种LLMs上平均准确率提升9.2%，随机噪声和对抗性噪声场景下鲁棒性分别提升12.5%和15.3%

Conclusion: 将检索段落融入推理过程是构建鲁棒RAG系统的有效方向，代码已开源

Abstract: Retrieval-augmented generation (RAG) has been widely adopted to augment large
language models (LLMs) with external knowledge for knowledge-intensive tasks.
However, its effectiveness is often undermined by the presence of noisy (i.e.,
low-quality) retrieved passages. Enhancing LLMs' robustness to such noise is
critical for improving the reliability of RAG systems. Recent advances have
equipped LLMs with strong reasoning and self-reflection capabilities, allowing
them to identify and correct errors in their reasoning process. Inspired by
this ability, we propose Passage Injection-a simple yet effective method that
explicitly incorporates retrieved passages into LLMs' reasoning process, aiming
to enhance the model's ability to recognize and resist noisy passages. We
validate Passage Injection under general RAG settings using BM25 as the
retriever. Experiments on four reasoning-enhanced LLMs across four factual QA
datasets demonstrate that Passage Injection significantly improves overall RAG
performance. Further analysis on two noisy retrieval settings-random noise,
where the model is provided irrelevant passages, and counterfactual noise,
where it is given misleading passages-shows that Passage Injection consistently
improves robustness. Controlled experiments confirm that Passage Injection can
also effectively leverage helpful passages. These findings suggest that
incorporating passages in LLMs' reasoning process is a promising direction for
building more robust RAG systems. The code can be found
\href{here}{https://github.com/mh-tang/Passage-Injection}.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [47] [MLLM-based Speech Recognition: When and How is Multimodality Beneficial?](https://arxiv.org/abs/2507.19037)
*Yiwen Guan,Viet Anh Trinh,Vivek Voleti,Jacob Whitehill*

Main category: cs.SD

TL;DR: 探索多模态输入在不同噪声条件下提升语音识别精度的效果及影响因素


<details>
  <summary>Details</summary>
Motivation: 基于多模态大语言模型的发展，研究多模态输入在噪声环境中提升语音识别准确性的具体条件与模型架构优化方向

Method: 通过合成数据与真实场景数据的对比实验，分析同步/异步模态（唇语/图像）、视觉表征质量、Mamba架构、输入顺序及损失权重等因素的影响

Result: 发现：1）多模态互补性取决于噪声强度；2）高噪声时同步模态更有效，中噪声时异步模态更优；3）高质量视觉表征持续提升精度；4）Mamba与Transformer在多模态趋势上一致；5）输入顺序和损失权重显著影响精度

Conclusion: 研究结果为开发噪声环境下多模态语音识别系统提供了架构设计、模态选择、训练策略等方面的实践指导，深化了对多模态协同机制的理解

Abstract: Recent advances in multi-modal large language models (MLLMs) have opened new
possibilities for unified modeling of speech, text, images, and other
modalities. Building on our prior work, this paper examines the conditions and
model architectures under which multiple input modalities can improve automatic
speech recognition (ASR) accuracy in noisy environments. Through experiments on
synthetic and real-world data, we find that (1) harnessing more modalities
usually improves ASR accuracy, as each modality provides complementary
information, but the improvement depends on the amount of auditory noise. (2)
Synchronized modalities (e.g., lip movements) are more useful at high noise
levels whereas unsynchronized modalities (e.g., image context) are most helpful
at moderate noise levels. (3) Higher-quality visual representations
consistently improve ASR accuracy, highlighting the importance of developing
more powerful visual encoders. (4) Mamba exhibits similar trends regarding the
benefits of multimodality as do Transformers. (5) The input order of modalities
as well as their weights in the loss function can significantly impact
accuracy. These findings both offer practical insights and help to deepen our
understanding of multi-modal speech recognition under challenging conditions.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [48] [Closing the Modality Gap for Mixed Modality Search](https://arxiv.org/abs/2507.19054)
*Binxu Li,Yuhui Zhang,Xiaohan Wang,Weixin Liang,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: 提出GR-CLIP方法消除CLIP模型的模态鸿沟，在混合模态搜索任务中显著提升检索效果


<details>
  <summary>Details</summary>
Motivation: 混合模态搜索面临跨模态数据融合难题，现有视觉语言模型存在嵌入空间模态差异导致的检索偏差和跨模态融合失效问题

Method: 开发轻量级后处理校准方法GR-CLIP，通过校准CLIP嵌入空间消除图像与文本模态间的表征差异

Result: 在MixBench基准测试中，NDCG@10指标较CLIP提升26%，计算资源消耗减少75倍

Conclusion: GR-CLIP有效解决模态鸿沟问题，为实际跨模态检索应用提供高效解决方案

Abstract: Mixed modality search -- retrieving information across a heterogeneous corpus
composed of images, texts, and multimodal documents -- is an important yet
underexplored real-world application. In this work, we investigate how
contrastive vision-language models, such as CLIP, perform on the mixed modality
search task. Our analysis reveals a critical limitation: these models exhibit a
pronounced modality gap in the embedding space, where image and text embeddings
form distinct clusters, leading to intra-modal ranking bias and inter-modal
fusion failure. To address this issue, we propose GR-CLIP, a lightweight
post-hoc calibration method that removes the modality gap in CLIP's embedding
space. Evaluated on MixBench -- the first benchmark specifically designed for
mixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points
over CLIP, surpasses recent vision-language generative embedding models by 4
percentage points, while using 75x less compute.

</details>


### [49] [LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences](https://arxiv.org/abs/2507.19362)
*Yusuke Hirota,Boyi Li,Ryo Hachiuma,Yueh-Hua Wu,Boris Ivanovic,Yuta Nakashima,Marco Pavone,Yejin Choi,Yu-Chiang Frank Wang,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: 提出LOTUS评估框架，系统评估LVLM生成详细描述的文本质量、风险及社会偏见，揭示模型表现与用户偏好的关联性


<details>
  <summary>Details</summary>
Motivation: 现有图像描述评估缺乏标准化准则、偏见检测机制和用户偏好适配，难以全面评估大型视觉语言模型性能

Method: 构建多维度评估体系，包含文本质量（对齐度/描述性）、风险（幻觉/安全）和社会偏见（性别/种族），支持用户偏好定制化评估

Result: 当前模型无全能优胜者，文本细节与偏见风险正相关，用户优先级决定最优模型选择

Conclusion: 评估标准需结合技术指标与用户场景，模型开发应平衡描述细节与风险控制

Abstract: Large Vision-Language Models (LVLMs) have transformed image captioning,
shifting from concise captions to detailed descriptions. We introduce LOTUS, a
leaderboard for evaluating detailed captions, addressing three main gaps in
existing evaluations: lack of standardized criteria, bias-aware assessments,
and user preference considerations. LOTUS comprehensively evaluates various
aspects, including caption quality (e.g., alignment, descriptiveness), risks
(\eg, hallucination), and societal biases (e.g., gender bias) while enabling
preference-oriented evaluations by tailoring criteria to diverse user
preferences. Our analysis of recent LVLMs reveals no single model excels across
all criteria, while correlations emerge between caption detail and bias risks.
Preference-oriented evaluations demonstrate that optimal model selection
depends on user priorities.

</details>


### [50] [MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents](https://arxiv.org/abs/2507.19478)
*Xuehui Wang,Zhenyu Wu,JingJing Xie,Zichen Ding,Bowen Yang,Zehao Li,Zhaoyang Liu,Qingyun Li,Xuan Dong,Zhe Chen,Weiyun Wang,Xiangyu Zhao,Jixuan Chen,Haodong Duan,Tianbao Xie,Chenyu Yang,Shiqian Su,Yue Yu,Yuan Huang,Yiqian Liu,Xiao Zhang,Yanting Zhang,Xiangyu Yue,Weijie Su,Xizhou Zhu,Wei Shen,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: MMBench-GUI是一个跨平台GUI自动化代理基准测试工具，包含四个评估层级并提出效率质量指标EQA，发现视觉定位精度和模块化框架对任务成功率至关重要，同时揭示现有模型存在效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有GUI自动化评估工具在跨平台覆盖、技能维度完整性和效率量化指标方面的不足，推动高效可靠的GUI自动化技术发展。

Method: 1) 设计分层基准（内容理解/元素定位/任务自动化/跨平台协作）
2) 提出EQA指标量化执行效率
3) 多平台实验验证框架有效性

Result: 1) 视觉定位精度决定83%任务成功率
2) 模块化框架比端到端模型性能提升27%
3) 所有模型平均冗余步骤率达62%
4) 跨平台任务完成率差异达41%

Conclusion: 未来GUI自动化需三位一体整合：精准定位+智能规划+动态终止策略，同时应建立标准化效率评估体系，推动从「能工作」到「高效工作」的范式转变。

Abstract: We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI
automation agents across Windows, macOS, Linux, iOS, Android, and Web
platforms. It comprises four levels: GUI Content Understanding, Element
Grounding, Task Automation, and Task Collaboration, covering essential skills
for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)
metric to assess GUI agent execution efficiency in online automation scenarios.
Through MMBench-GUI, we identify accurate visual grounding as a critical
determinant of overall task success, emphasizing the substantial benefits of
modular frameworks that integrate specialized grounding modules. Furthermore,
to achieve reliable GUI automation, an agent requires strong task planning and
cross-platform generalization abilities, with long-context memory, a broad
action space, and long-term reasoning playing a critical role. More important,
task efficiency remains a critically underexplored dimension, and all models
suffer from substantial inefficiencies, with excessive redundant steps even
when tasks are ultimately completed. The integration of precise localization,
effective planning, and early stopping strategies is indispensable to enable
truly efficient and scalable GUI automation. Our benchmark code, evaluation
data, and running environment will be publicly available at
https://github.com/open-compass/MMBench-GUI.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [51] [People Are Highly Cooperative with Large Language Models, Especially When Communication Is Possible or Following Human Interaction](https://arxiv.org/abs/2507.18639)
*Paweł Niszczota,Tomasz Grzegorczyk,Alexander Pastukhov*

Main category: cs.HC

TL;DR: 研究通过囚徒困境实验发现，与人类相比，LLM驱动的机器合作率低10-15%，但依然较高。允许沟通可提升合作率（+88%），且人类互动后与LLM合作存在溢出效应。


<details>
  <summary>Details</summary>
Motivation: 探究LLM代替人类参与合作场景时，对人类合作行为的影响机制及其商业应用潜力。

Method: 使用囚徒困境游戏模拟商业场景：实验1（N=100）比较30轮重复博弈中人类/传统bot/LLM的互动；实验2（N=192）测试单次博弈中沟通机制对合作的影响。

Result: 1. LLM合作率比人类低10-15个百分点但绝对值仍高
2. 允许沟通使人类/LLM合作率同等提升88%
3. 人类互动后与LLM合作存在正向溢出效应

Conclusion: 建议企业在具有合作属性的场景中谨慎使用LLM，需注意人类对机器的行为差异及历史互动带来的行为迁移效应。

Abstract: Machines driven by large language models (LLMs) have the potential to augment
humans across various tasks, a development with profound implications for
business settings where effective communication, collaboration, and stakeholder
trust are paramount. To explore how interacting with an LLM instead of a human
might shift cooperative behavior in such settings, we used the Prisoner's
Dilemma game -- a surrogate of several real-world managerial and economic
scenarios. In Experiment 1 (N=100), participants engaged in a thirty-round
repeated game against a human, a classic bot, and an LLM (GPT, in real-time).
In Experiment 2 (N=192), participants played a one-shot game against a human or
an LLM, with half of them allowed to communicate with their opponent, enabling
LLMs to leverage a key advantage over older-generation machines. Cooperation
rates with LLMs -- while lower by approximately 10-15 percentage points
compared to interactions with human opponents -- were nonetheless high. This
finding was particularly notable in Experiment 2, where the psychological cost
of selfish behavior was reduced. Although allowing communication about
cooperation did not close the human-machine behavioral gap, it increased the
likelihood of cooperation with both humans and LLMs equally (by 88%), which is
particularly surprising for LLMs given their non-human nature and the
assumption that people might be less receptive to cooperating with machines
compared to human counterparts. Additionally, cooperation with LLMs was higher
following prior interaction with humans, suggesting a spillover effect in
cooperative behavior. Our findings validate the (careful) use of LLMs by
businesses in settings that have a cooperative component.

</details>


### [52] [TreeReader: A Hierarchical Academic Paper Reader Powered by Language Models](https://arxiv.org/abs/2507.18945)
*Zijian Zhang,Pan Chen,Fangshi Du,Runlong Ye,Oliver Huang,Michael Liut,Alán Aspuru-Guzik*

Main category: cs.HC

TL;DR: TreeReader是一款通过树状交互结构提升论文阅读效率的工具，利用LLM分层生成章节摘要，支持按需查看原文细节。


<details>
  <summary>Details</summary>
Motivation: 传统PDF/HTML格式易引发认知过载，现有LLM摘要工具存在章节理解不足、信息可靠性差、破坏文档结构导航等问题。

Method: 将论文解构为交互式树状结构，各章节首层显示LLM生成的简洁摘要，细节内容按需展开，并通过用户研究验证效果。

Result: 用户研究表明TreeReader显著提升阅读效率与理解准确度，实现核心思想快速捕捉与细节验证的平衡。

Conclusion: 通过分层摘要与交互探索的结合，TreeReader为复杂学术文献提供了更聚焦高效的阅读范式。

Abstract: Efficiently navigating and understanding academic papers is crucial for
scientific progress. Traditional linear formats like PDF and HTML can cause
cognitive overload and obscure a paper's hierarchical structure, making it
difficult to locate key information. While LLM-based chatbots offer
summarization, they often lack nuanced understanding of specific sections, may
produce unreliable information, and typically discard the document's
navigational structure. Drawing insights from a formative study on academic
reading practices, we introduce TreeReader, a novel language model-augmented
paper reader. TreeReader decomposes papers into an interactive tree structure
where each section is initially represented by an LLM-generated concise
summary, with underlying details accessible on demand. This design allows users
to quickly grasp core ideas, selectively explore sections of interest, and
verify summaries against the source text. A user study was conducted to
evaluate TreeReader's impact on reading efficiency and comprehension.
TreeReader provides a more focused and efficient way to navigate and understand
complex academic literature by bridging hierarchical summarization with
interactive exploration.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [53] [PurpCode: Reasoning for Safer Code Generation](https://arxiv.org/abs/2507.19060)
*Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang*

Main category: cs.CR

TL;DR: 提出首个后训练框架PurpCode，通过规则学习和强化学习两阶段训练代码模型，生成安全代码并抵御恶意网络活动


<details>
  <summary>Details</summary>
Motivation: 解决现有代码模型在网络安全推理能力上的不足，防止生成包含漏洞的代码及助长恶意网络行为

Method: 1. 规则学习阶段：显式教授模型引用网络安全规则生成无漏洞代码
2. 强化学习阶段：通过多目标奖励机制优化安全性并保持功能性

Result: 开发PurpCode-32B模型，在网络安全防护上达到SOTA水平，降低过拒绝率（通用场景降34.8%，安全场景降7.3%），同时保持代码生成能力和安全知识理解

Conclusion: 该对齐方法成功平衡模型安全性与功能性，通过红队测试构建的高覆盖率数据集有效提升防御能力，为安全关键场景的AI部署提供新范式

Abstract: We introduce PurpCode, the first post-training recipe for training safe code
reasoning models towards generating secure code and defending against malicious
cyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule
Learning, which explicitly teaches the model to reference cybersafety rules to
generate vulnerability-free code and to avoid facilitating malicious
cyberactivities; and (ii) Reinforcement Learning, which optimizes model safety
and preserves model utility through diverse, multi-objective reward mechanisms.
To empower the training pipelines with comprehensive cybersafety data, we
conduct internal red-teaming to synthesize comprehensive and high-coverage
prompts based on real-world tasks for inducing unsafe cyberactivities in the
model. Based on PurpCode, we develop a reasoning-based coding model, namely
PurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming
various frontier models. Meanwhile, our alignment method decreases the model
overrefusal rates in both general and cybersafety-specific scenarios, while
preserving model utility in both code generation and common security knowledge.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [54] [Towards Multimodal Social Conversations with Robots: Using Vision-Language Models](https://arxiv.org/abs/2507.19196)
*Ruben Janssens,Tony Belpaeme*

Main category: cs.RO

TL;DR: 提出通过视觉-语言模型解决社交机器人多模态交互不足的问题，并讨论技术挑战与评估方法


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型虽支持开放对话，但缺乏处理社交互动中多模态信息（如视觉线索）的能力，需构建通用多模态系统

Method: 采用视觉-语言模型处理多样化视觉信息，适配自主社交机器人场景

Result: 验证视觉-语言模型在社交机器人多模态交互中的通用潜力，但需解决技术实现挑战

Conclusion: 视觉-语言模型是提升社交机器人交互能力的关键，未来需完善技术实现并建立有效评估体系

Abstract: Large language models have given social robots the ability to autonomously
engage in open-domain conversations. However, they are still missing a
fundamental social skill: making use of the multiple modalities that carry
social interactions. While previous work has focused on task-oriented
interactions that require referencing the environment or specific phenomena in
social interactions such as dialogue breakdowns, we outline the overall needs
of a multimodal system for social conversations with robots. We then argue that
vision-language models are able to process this wide range of visual
information in a sufficiently general manner for autonomous social robots. We
describe how to adapt them to this setting, which technical challenges remain,
and briefly discuss evaluation practices.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP 基准包含416个跨15个应用的日常自动化任务，通过五级自动化分类和需求层次化评估框架，揭示当前智能体在感知推理等高阶任务上的能力瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法有效评估计算机代理的任务适应能力与用户需求的匹配程度，阻碍了研究向实际应用的转化。

Method: 构建二维评估体系：五级自动化分类（自主性递增）和需求层次化泛化范围，形成性能-泛化评估矩阵。

Result: 实验表明当前最先进的多模态代理在需要感知、推理和跨应用协调的高阶任务中表现欠佳。

Conclusion: OS-MAP 为计算机代理研究提供了结构化评估框架，揭示了现有技术局限，推动面向真实场景的能力发展。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>
