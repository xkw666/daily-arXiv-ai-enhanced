<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CV](#cs.CV) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [StreetMath: Study of LLMs' Approximation Behaviors](https://arxiv.org/abs/2510.25776)
*Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong*

Main category: cs.CL

TL;DR: 研究通过StreetMath基准测试发现，大语言模型在近似数学推理中倾向于精确计算且消耗更多资源，与人类认知策略不同。


<details>
  <summary>Details</summary>
Motivation: 填补大语言模型在非自回归架构下非正式快速数学近似推理能力评估的空白

Method: 开发StreetMath基准测试，结合机制可解释性技术分析模型内部计算状态

Result: 模型在近似任务中仍尝试精确计算，且激活神经组件与精确计算存在显著分离

Conclusion: 大语言模型未表现出人类在街头数学场景中的认知吝啬特性，研究已开源

Abstract: There is a substantial body of literature examining the mathematical
reasoning capabilities of large language models (LLMs), particularly their
performance on precise arithmetic operations in autoregressive architectures.
However, their ability to perform approximate reasoning in informal, fast-paced
mathematical operations has received far less attention, especially among
non-autoregressive decoder models. Our work addresses this gap by introducing
StreetMath, a benchmark designed to evaluate models' approximation abilities
under real-world approximation scenarios. We conduct extensive evaluations
across different LLM architectures: Qwen3-4B-Instruct-2507,
Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, and
Mamba-GPT-3B. Furthermore, we apply mechanistic interpretability techniques to
probe their internal computational states. Our analysis reveals that LLMs
generally attempt to compute exact values or invoke external tools even in
tasks that call for approximation. Moreover, while models sometimes reach the
correct answer in early layers or steps, they still consume more tokens when
solving approximation tasks. Additional experiments indicate that exact and
approximate arithmetic operations rely on largely separate neural components.
Drawing upon research on cognitive psychology, we argue that LLMs do not
exhibit cognitive miserliness in the same way humans do in street math
settings. We open source our work https://github.com/ctseng777/StreetMath

</details>


### [2] [Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis](https://arxiv.org/abs/2510.25778)
*Pratik N. Kalamkar,Anupama G. Phakatkar*

Main category: cs.CL

TL;DR: 提出基于模糊逻辑和句法依赖解析的细粒度情感强度分类方法，改进现有忽略情感强度的词典分析法


<details>
  <summary>Details</summary>
Motivation: 现有基于词典的整体分析方法忽略情感强度分级（如非常强烈/弱等），无法满足细粒度实体排序需求

Method: 1. 结合副词/形容词/名词/动词等意见词 2. 模糊逻辑算法分类情感强度等级 3. 句法依赖解析提取方面词关联

Result: 实现五级情感强度分类（非常弱/弱/中等/强/非常强），通过方面相关意见词计算实体评分

Conclusion: 该方法能有效捕获评论中不同方面的情感强度差异，提升实体排序准确性

Abstract: Opinion mining, also called sentiment analysis, is the field of study that
analyzes people opinions, sentiments, evaluations, appraisals, attitudes, and
emotions towards entities such as products, services, organizations,
individuals, issues, events, topics, and their attributes. Holistic
lexicon-based approach does not consider the strength of each opinion, i.e.,
whether the opinion is very strongly negative (or positive), strongly negative
(or positive), moderate negative (or positive), very weakly negative (or
positive) and weakly negative (or positive). In this paper, we propose approach
to rank entities based on orientation and strength of the entity reviews and
user's queries by classifying them in granularity levels (i.e. very weak, weak,
moderate, very strong and strong) by combining opinion words (i.e. adverb,
adjective, noun and verb) that are related to aspect of interest of certain
product. We shall use fuzzy logic algorithmic approach in order to classify
opinion words into different category and syntactic dependency resolution to
find relations for desired aspect words. Opinion words related to certain
aspects of interest are considered to find the entity score for that aspect in
the review.

</details>


### [3] [LASTIST: LArge-Scale Target-Independent STance dataset](https://arxiv.org/abs/2510.25783)
*DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park*

Main category: cs.CL

TL;DR: 构建了大规模韩语目标独立立场检测数据集LASTIST，含56.3万标注语句，适用于多任务研究并公开数据集。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测研究集中于目标依赖任务且依赖英文数据，韩语等低资源语言缺乏相关数据集阻碍研究发展。

Method: 从韩国政党新闻稿收集563,299句标注数据，训练前沿深度学习模型，详细描述数据构建流程。

Result: 创建支持目标独立立场检测和历时演变分析的数据集，提供模型基准并开源数据。

Conclusion: LASTIST填补了韩语立场检测领域的数据空白，推动了低资源语言环境下多任务立场检测研究的发展。

Abstract: Stance detection has emerged as an area of research in the field of
artificial intelligence. However, most research is currently centered on the
target-dependent stance detection task, which is based on a person's stance in
favor of or against a specific target. Furthermore, most benchmark datasets are
based on English, making it difficult to develop models in low-resource
languages such as Korean, especially for an emerging field such as stance
detection. This study proposes the LArge-Scale Target-Independent STance
(LASTIST) dataset to fill this research gap. Collected from the press releases
of both parties on Korean political parties, the LASTIST dataset uses 563,299
labeled Korean sentences. We provide a detailed description of how we collected
and constructed the dataset and trained state-of-the-art deep learning and
stance detection models. Our LASTIST dataset is designed for various tasks in
stance detection, including target-independent stance detection and diachronic
evolution stance detection. We deploy our dataset on
https://anonymous.4open.science/r/LASTIST-3721/.

</details>


### [4] [zFLoRA: Zero-Latency Fused Low-Rank Adapters](https://arxiv.org/abs/2510.25784)
*Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee*

Main category: cs.CL

TL;DR: 提出零延迟融合低秩适配器zFLoRA，解决现有适配器在LLMs推理时的高计算开销问题，实验显示其在多个任务中表现优异且接近零延迟。


<details>
  <summary>Details</summary>
Motivation: 现有适配器参数虽少(不足基础模型1%)，但导致推理时计算量剧增(达基础模型2.5倍)，亟需优化计算效率。

Method: 通过融合低秩适配器技术，直接在基础模型参数中整合适配器功能，消除额外计算层。

Result: 在1B/3B/7B模型上验证，zFLoRA在18个常识推理/数学推理/摘要对话任务中优于LoRA和全微调，NPU/GPU平台延迟趋近于零。

Conclusion: zFLoRA成功解决适配器延迟问题，为实际部署提供高效解决方案，具有显著工程应用价值。

Abstract: Large language models (LLMs) are increasingly deployed with task-specific
adapters catering to multiple downstream applications. In such a scenario, the
additional compute associated with these apparently insignificant number of
adapter parameters (typically less than 1% of the base model) turns out to be
disproportionately significant during inference time (upto 2.5x times that of
the base model). In this paper, we propose a new zero-latency fused low-rank
adapter (zFLoRA) that introduces zero or negligible latency overhead on top of
the base model. Experimental results on LLMs of size 1B, 3B and 7B show that
zFLoRA compares favorably against the popular supervised fine-tuning benchmarks
including low-rank adapters (LoRA) as well as full fine-tuning (FFT).
Experiments are conducted on 18 different tasks across three different
categories namely commonsense reasoning, math reasoning and summary-dialogue.
Latency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA
H100) platforms show that the proposed zFLoRA adapters introduce zero to
negligible latency overhead.

</details>


### [5] [BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection](https://arxiv.org/abs/2510.25786)
*Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 提出三种改进方法（自举法、比率选择策略、整数线性规划）显著提升机制可解释性中电路发现的忠实度和性能


<details>
  <summary>Details</summary>
Motivation: 现有电路发现方法在性能与忠实度平衡、选择策略优化方面存在不足，需更可靠的机制解释方案

Method: 1. 自举法筛选稳定归因边 2. 比率选择策略平衡性能与忠实度 3. 整数线性规划替代贪婪选择

Result: 在MIB多个任务和模型上实现更高忠实度的电路发现，性能超越现有方法

Conclusion: 通过系统性方法改进，为神经网络机制可解释性研究提供了更可靠的电路发现框架

Abstract: One of the main challenges in mechanistic interpretability is circuit
discovery, determining which parts of a model perform a given task. We build on
the Mechanistic Interpretability Benchmark (MIB) and propose three key
improvements to circuit discovery. First, we use bootstrapping to identify
edges with consistent attribution scores. Second, we introduce a simple
ratio-based selection strategy to prioritize strong positive-scoring edges,
balancing performance and faithfulness. Third, we replace the standard greedy
selection with an integer linear programming formulation. Our methods yield
more faithful circuits and outperform prior approaches across multiple MIB
tasks and models. Our code is available at:
https://github.com/technion-cs-nlp/MIB-Shared-Task.

</details>


### [6] [LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection](https://arxiv.org/abs/2510.25799)
*Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier*

Main category: cs.CL

TL;DR: 提出LISTEN框架，利用LLM作为自然语言偏好预测器解决多目标决策问题，包含LISTEN-U和LISTEN-T两种算法。


<details>
  <summary>Details</summary>
Motivation: 传统多目标决策方法难以形式化复杂偏好，专家认知负担重，需自然语言驱动的轻量化方案。

Method: LISTEN-U通过LLM迭代优化参数化效用函数，LISTEN-T采用非参数锦标赛式选择方案。

Result: LISTEN-U在参数对齐场景表现优异，LISTEN-T鲁棒性更强，实验覆盖航班预订/购物/考试安排等场景。

Conclusion: 探索了自然语言直接引导复杂决策的新方向，通过降低偏好提取认知负担提升决策效率。

Abstract: Human experts often struggle to select the best option from a large set of
items with multiple competing objectives, a process bottlenecked by the
difficulty of formalizing complex, implicit preferences. To address this, we
introduce LISTEN, a framework that leverages a Large Language Model (LLM) as a
zero-shot preference oracle, guided only by an expert's high-level priorities
in natural language. To operate within LLM constraints like context windows and
inference costs, we propose two iterative algorithms: LISTEN-U, which uses the
LLM to refine a parametric utility function, and LISTEN-T, a non-parametric
method that performs tournament-style selections over small batches of
solutions. Evaluated on diverse tasks including flight booking, shopping, and
exam scheduling, our results show LISTEN-U excels when preferences are
parametrically aligned (a property we measure with a novel concordance metric),
while LISTEN-T offers more robust performance. This work explores a promising
direction for steering complex multi-objective decisions directly with natural
language, reducing the cognitive burden of traditional preference elicitation.

</details>


### [7] [Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data](https://arxiv.org/abs/2510.25804)
*Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong*

Main category: cs.CL

TL;DR: 提出LongFilter框架，通过对比长/短上下文预测差异筛选高质量长文本数据，显著提升模型长上下文能力


<details>
  <summary>Details</summary>
Motivation: 现有长文本数据大多缺乏有效长距离依赖，导致长上下文模型训练效率低下，需开发高效数据筛选方法

Method: 通过对比模型在长上下文（64K）与短上下文（8K）的预测差异计算信息增益，筛选依赖长程关系的样本

Result: LLaMA-3-8B扩展至64K后，在HELMET/LongBench/RULER等基准提升显著，证明数据筛选有效性

Conclusion: LongFilter通过上下文对比机制高效筛选训练数据，成功解决长文本训练低效问题，为模型长上下文扩展提供新范式

Abstract: Long-context language models unlock advanced capabilities in reasoning, code
generation, and document summarization by leveraging dependencies across
extended spans of text. However, a significant portion of readily available
long-text data lacks meaningful long-distance dependencies; most spans can be
predicted using only local context. Training on such data is inefficient,
making careful data selection crucial. Therefore, we introduce LongFilter, a
framework for curating training data tailored to long-context pretraining.
LongFilter measures the information gain provided by extended context by
contrasting model predictions under long-context versus short-context settings,
thereby identifying samples where long-range dependencies are essential.
Experiments with LLaMA-3-8B, extending its context length from 8K to 64K, show
that LongFilter efficiently selects high-quality data and yields substantial
improvements on benchmarks such as HELMET, LongBench, and RULER.

</details>


### [8] [Ideology-Based LLMs for Content Moderation](https://arxiv.org/abs/2510.25805)
*Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini*

Main category: cs.CL

TL;DR: 研究发现LLM在内容审核中采用不同人物设定会引发意识形态偏见，模型会强化同阵营观点一致性并加剧跨意识形态分歧


<details>
  <summary>Details</summary>
Motivation: 探讨人物设定对LLM有害内容分类一致性/公平性的影响，揭示AI系统在表面中立下可能隐含的偏见风险

Method: 通过跨架构模型比较（不同规模LLM）、多模态分析（文本/视觉）、政治倾向任务实验，结合一致性分析和群体差异测量

Result: 1. 人物设定显著改变模型对内容危害性的敏感阈值
2. 大模型更易与同意识形态人物达成共识（组内一致性提高14.2%）
3. 在政治任务中模型表现出防御本阵营观点、贬低对立阵营危害性的倾向

Conclusion: 人物设定可能使LLM输出携带隐蔽的意识形态偏向，警示需警惕以中立为名的AI系统实际强化党派立场

Abstract: Large language models (LLMs) are increasingly used in content moderation
systems, where ensuring fairness and neutrality is essential. In this study, we
examine how persona adoption influences the consistency and fairness of harmful
content classification across different LLM architectures, model sizes, and
content modalities (language vs. vision). At first glance, headline performance
metrics suggest that personas have little impact on overall classification
accuracy. However, a closer analysis reveals important behavioral shifts.
Personas with different ideological leanings display distinct propensities to
label content as harmful, showing that the lens through which a model "views"
input can subtly shape its judgments. Further agreement analyses highlight that
models, particularly larger ones, tend to align more closely with personas from
the same political ideology, strengthening within-ideology consistency while
widening divergence across ideological groups. To show this effect more
directly, we conducted an additional study on a politically targeted task,
which confirmed that personas not only behave more coherently within their own
ideology but also exhibit a tendency to defend their perspective while
downplaying harmfulness in opposing views. Together, these findings highlight
how persona conditioning can introduce subtle ideological biases into LLM
outputs, raising concerns about the use of AI systems that may reinforce
partisan perspectives under the guise of neutrality.

</details>


### [9] [Beyond Long Context: When Semantics Matter More than Tokens](https://arxiv.org/abs/2510.25816)
*Tarun Kumar Chawdhury,Jon D. Duke*

Main category: cs.CL

TL;DR: CLEAR方法通过实体感知检索机制，在临床自然语言处理中实现效率与精度的双重提升，尤其在处理长文本（65k+ token）时取得75%的胜率


<details>
  <summary>Details</summary>
Motivation: 传统向量数据库方法在处理FHIR DocumentReference中base64编码的临床文档时，难以捕捉细粒度的临床语义关系，且大上下文推理存在计算效率问题

Method: 开发临床问答评估平台，对比实体感知检索(CLEAR)、零样本大上下文推理和传统分块检索增强生成。使用12份真实临床文档（10k-65k tokens）进行验证

Result: CLEAR取得58.3%胜率（平均语义相似度0.878），token使用量比大上下文处理减少78%。在65k+超长文档上胜率达75%

Conclusion: 实体感知检索显著提升临床NLP系统的语义精度和计算效率，评估框架为临床QA系统提供了可复现的透明基准

Abstract: Electronic Health Records (EHR) store clinical documentation as base64
encoded attachments in FHIR DocumentReference resources, which makes semantic
question answering difficult. Traditional vector database methods often miss
nuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)
method, introduced by Lopez et al. 2025, uses entity aware retrieval and
achieved improved performance with an F1 score of 0.90 versus 0.86 for
embedding based retrieval, while using over 70 percent fewer tokens. We
developed a Clinical Notes QA Evaluation Platform to validate CLEAR against
zero shot large context inference and traditional chunk based retrieval
augmented generation. The platform was tested on 12 clinical notes ranging from
10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a
58.3 percent win rate, an average semantic similarity of 0.878, and used 78
percent fewer tokens than wide context processing. The largest performance
gains occurred on long notes, with a 75 percent win rate for documents
exceeding 65,000 tokens. These findings confirm that entity aware retrieval
improves both efficiency and accuracy in clinical natural language processing.
The evaluation framework provides a reusable and transparent benchmark for
assessing clinical question answering systems where semantic precision and
computational efficiency are critical.

</details>


### [10] [A Survey on Efficient Large Language Model Training: From Data-centric Perspectives](https://arxiv.org/abs/2510.25817)
*Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang*

Main category: cs.CL

TL;DR: 对LLM高效数据后训练方法的首个系统综述，提出覆盖数据选择/增强/生成/蒸馏/自进化生态等维度的分类框架，总结研究现状与未来方向。


<details>
  <summary>Details</summary>
Motivation: 当前LLM后训练面临数据标注成本高、规模边际效益递减等挑战，亟需建立数据高效利用的方法体系。

Method: 采用数据中心的系统综述方法，构建包含数据选择、质量增强、合成生成、蒸馏压缩、自进化生态的五维分类框架，分析各类代表性方法。

Result: 形成覆盖全生命周期的数据高效利用理论框架，揭示当前在合成数据质量、数据蒸馏效率、生态自演化机制等方面的研究空白。

Conclusion: 提出构建数据高效生态系统的未来方向，包括改进合成数据生成算法、开发轻量级蒸馏框架、建立数据自进化机制等突破路径。

Abstract: Post-training of Large Language Models (LLMs) is crucial for unlocking their
task generalization potential and domain-specific capabilities. However, the
current LLM post-training paradigm faces significant data challenges, including
the high costs of manual annotation and diminishing marginal returns on data
scales. Therefore, achieving data-efficient post-training has become a key
research question. In this paper, we present the first systematic survey of
data-efficient LLM post-training from a data-centric perspective. We propose a
taxonomy of data-efficient LLM post-training methods, covering data selection,
data quality enhancement, synthetic data generation, data distillation and
compression, and self-evolving data ecosystems. We summarize representative
approaches in each category and outline future research directions. By
examining the challenges in data-efficient LLM post-training, we highlight open
problems and propose potential research avenues. We hope our work inspires
further exploration into maximizing the potential of data utilization in
large-scale model training. Paper List:
https://github.com/luo-junyu/Awesome-Data-Efficient-LLM

</details>


### [11] [Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation](https://arxiv.org/abs/2510.25904)
*Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 研究通过实验证明，在FrameNet语义标注任务中，半自动标注模式在保持标注覆盖率的同时显著提升了框架多样性，而全自动模式除标注速度外各项指标均表现较差。


<details>
  <summary>Details</summary>
Motivation: 填补基于大语言模型的语义角色标注工具在语料库标注自动化效果评估方面的研究空白，特别是从NLP视角探讨其对标注数据集创建的影响。

Method: 采用三组对照实验（手动/全自动/半自动），比较不同设置下的标注时间、覆盖率和框架多样性指标。

Result: 半自动组框架多样性提升25%且覆盖率达手动组96%，全自动组除标注速度最快外，覆盖率仅为手动组68%且多样性最低。

Conclusion: 人机协同的半自动模式在语义标注任务中实现了效率与质量的平衡，为低资源语言处理中的标注资源创建提供了新思路。

Abstract: The use of LLM-based applications as a means to accelerate and/or substitute
human labor in the creation of language resources and dataset is a reality.
Nonetheless, despite the potential of such tools for linguistic research,
comprehensive evaluation of their performance and impact on the creation of
annotated datasets, especially under a perspectivized approach to NLP, is still
missing. This paper contributes to reduction of this gap by reporting on an
extensive evaluation of the (semi-)automatization of FrameNet-like semantic
annotation by the use of an LLM-based semantic role labeler. The methodology
employed compares annotation time, coverage and diversity in three experimental
settings: manual, automatic and semi-automatic annotation. Results show that
the hybrid, semi-automatic annotation setting leads to increased frame
diversity and similar annotation coverage, when compared to the human-only
setting, while the automatic setting performs considerably worse in all
metrics, except for annotation time.

</details>


### [12] [RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline](https://arxiv.org/abs/2510.25941)
*André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li*

Main category: cs.CL

TL;DR: 提出RECAP框架，通过反馈循环机制和越狱模块，显著提升大语言模型训练数据提取效果（ROUGE-L提升24%）


<details>
  <summary>Details</summary>
Motivation: 解决无法检测LLM训练数据时验证模型记忆内容的问题，尤其针对版权材料的潜在泄露风险

Method: 1. 反馈驱动循环：次级模型评估输出差异并生成修正提示
2. 越狱模块突破对齐限制
3. 基于30+书籍构建EchoTrace基准测试

Result: GPT-4.1的版权文本提取ROUGE-L从0.38提升至0.47，相对提升近24%

Conclusion: RECAP证明迭代优化策略对数据提取的有效性，为模型审计和版权保护提供新方案

Abstract: If we cannot inspect the training data of a large language model (LLM), how
can we ever know what it has seen? We believe the most compelling evidence
arises when the model itself freely reproduces the target content. As such, we
propose RECAP, an agentic pipeline designed to elicit and verify memorized
training data from LLM outputs. At the heart of RECAP is a feedback-driven
loop, where an initial extraction attempt is evaluated by a secondary language
model, which compares the output against a reference passage and identifies
discrepancies. These are then translated into minimal correction hints, which
are fed back into the target model to guide subsequent generations. In
addition, to address alignment-induced refusals, RECAP includes a jailbreaking
module that detects and overcomes such barriers. We evaluate RECAP on
EchoTrace, a new benchmark spanning over 30 full books, and the results show
that RECAP leads to substantial gains over single-iteration approaches. For
instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text
extraction improved from 0.38 to 0.47 - a nearly 24% increase.

</details>


### [13] [Revisiting Multilingual Data Mixtures in Language Model Pretraining](https://arxiv.org/abs/2510.25947)
*Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut*

Main category: cs.CL

TL;DR: 研究发现合理平衡多语言数据可提升模型性能且不造成权衡，挑战了多语言训练的常见假设


<details>
  <summary>Details</summary>
Motivation: 针对多语言预训练中语言覆盖与模型性能之间的潜在矛盾（多语言诅咒假说）进行系统性验证

Method: 通过训练1.1B/3B参数模型，使用25-400种语言构成的多样化多语料库进行实验对比

Result: 发现足够token保证下英语与多语言数据可兼容，英语枢纽作用跨语系有效，未观察到显著多语言诅咒现象

Conclusion: 合理配置的多语言数据能增强模型能力，对低资源语言处理具有实践指导意义

Abstract: The impact of different multilingual data mixtures in pretraining large
language models (LLMs) has been a topic of ongoing debate, often raising
concerns about potential trade-offs between language coverage and model
performance (i.e., the curse of multilinguality). In this work, we investigate
these assumptions by training 1.1B and 3B parameter LLMs on diverse
multilingual corpora, varying the number of languages from 25 to 400. Our study
challenges common beliefs surrounding multilingual training. First, we find
that combining English and multilingual data does not necessarily degrade the
in-language performance of either group, provided that languages have a
sufficient number of tokens included in the pretraining corpus. Second, we
observe that using English as a pivot language (i.e., a high-resource language
that serves as a catalyst for multilingual generalization) yields benefits
across language families, and contrary to expectations, selecting a pivot
language from within a specific family does not consistently improve
performance for languages within that family. Lastly, we do not observe a
significant "curse of multilinguality" as the number of training languages
increases in models at this scale. Our findings suggest that multilingual data,
when balanced appropriately, can enhance language model capabilities without
compromising performance, even in low-resource settings

</details>


### [14] [Semantic Label Drift in Cross-Cultural Translation](https://arxiv.org/abs/2510.25967)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 机器翻译中文化差异导致语义标签偏移，大语言模型的文化知识会加剧该现象，影响下游应用准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视机器翻译过程中文化差异对语义标签保存的影响，本文旨在揭示文化错位引发的标签偏移风险及其对实际应用的潜在危害。

Method: 通过对比实验（文化敏感领域 vs 中性领域），分析传统统计机器翻译与大语言模型在跨文化翻译中的标签保存效果，并验证语言文化相似度的影响。

Result: 1）所有机器翻译系统均导致文化敏感领域标签偏移 2）大语言模型的文化知识会放大偏移 3）语言间文化相似度是标签保存关键因素

Conclusion: 忽视文化因素会损害翻译的标签保真度，导致下游应用中的文化冲突。跨文化机器翻译需将文化对齐作为核心考量。

Abstract: Machine Translation (MT) is widely employed to address resource scarcity in
low-resource languages by generating synthetic data from high-resource
counterparts. While sentiment preservation in translation has long been
studied, a critical but underexplored factor is the role of cultural alignment
between source and target languages. In this paper, we hypothesize that
semantic labels are drifted or altered during MT due to cultural divergence.
Through a series of experiments across culturally sensitive and neutral
domains, we establish three key findings: (1) MT systems, including modern
Large Language Models (LLMs), induce label drift during translation,
particularly in culturally sensitive domains; (2) unlike earlier statistical MT
tools, LLMs encode cultural knowledge, and leveraging this knowledge can
amplify label drift; and (3) cultural similarity or dissimilarity between
source and target languages is a crucial determinant of label preservation. Our
findings highlight that neglecting cultural factors in MT not only undermines
label fidelity but also risks misinterpretation and cultural conflict in
downstream applications.

</details>


### [15] [SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation](https://arxiv.org/abs/2510.25975)
*Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal*

Main category: cs.CL

TL;DR: SymCode框架通过符号计算增强LLM数学推理，准确率提升13.6%


<details>
  <summary>Details</summary>
Motivation: 现有LLM在数学推理中缺乏确定性验证机制，生成结果不可靠

Method: 基于SymPy库将数学问题转化为可验证的代码生成任务

Result: 在MATH-500和OlympiadBench上显著优于基线，错误类型转为可调试的程序错误

Conclusion: 通过符号引擎实现确定性验证，是提升AI在形式领域可信度的重要进展

Abstract: Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.

</details>


### [16] [NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium](https://arxiv.org/abs/2510.25977)
*Dinghong Song,Jierui Xu,Weichu Yang,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 针对AWS Trainium AI加速器的架构特性，提出定制化矩阵乘法优化方案，显著提升LLM推理性能


<details>
  <summary>Details</summary>
Motivation: Trainium加速器的脉动阵列架构和特殊数据布局要求导致难以充分发挥硬件性能，现有方案存在数据搬移效率低、矩阵转置开销大等问题

Method: 基于内核融合策略与创新缓存技术，优化软件管理内存层次结构的数据流，最大化SRAM带宽利用率，消除矩阵转置操作

Result: 在9个数据集和4个LLM上的测试显示：矩阵乘法内核平均加速1.35倍（最高2.22倍），端到端LLM推理平均加速1.66倍（最高2.49倍）

Conclusion: 提出的定制化优化方法有效克服了Trainium架构限制，为LLM推理提供了当前最佳的性能解决方案，对降低AI计算成本具有重要意义

Abstract: AI accelerators, customized to AI workloads, provide cost-effective and
high-performance solutions for training and inference. Trainium, an AI
accelerator recently developed by Amazon Web Services (AWS), provides an
attractive option for LLM training and inference through its heterogeneous
architecture. However, leveraging Trainium architecture for high performance
can be challenging because of its systolic array architecture and special
requirement on data layout. In this paper, we design high-performance matrix
multiplication (matmul), a critical compute kernel, for LLM inference on
Trainium. We introduce a series of techniques customized to Trainium based on
kernel fusion and novel caching strategies to reduce data movement across the
software-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive
matrix transpose. Evaluating with nine datasets and four recent LLMs, we show
that our system largely outperforms the state-of-the-art matmul implemented by
AWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x
speedup (up to 2.22x), which translates to an average 1.66x speedup (up to
2.49x) for end-to-end LLM inference.

</details>


### [17] [AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache](https://arxiv.org/abs/2510.25979)
*Dinghong Song,Yuan Feng,Yiwei Wang,Shangye Chen,Cyril Guyot,Filip Blagojevic,Hyeran Jeon,Pengfei Su,Dong Li*

Main category: cs.CL

TL;DR: 提出AttnCache框架，通过缓存和重用相似注意力图加速LLM预填充阶段推理，在CPU/GPU上分别实现1.2x/1.6x端到端加速且精度损失可忽略


<details>
  <summary>Details</summary>
Motivation: LLM预填充阶段的自注意力计算存在二次复杂度瓶颈，影响分类/问答/推荐等非生成式任务的推理效率

Method: 基于注意力图跨层/头的相似性观察，建立注意力图记忆数据库，采用缓存和相似性检索技术复用历史计算结果

Result: CPU端到端加速1.2x（注意力2x），GPU端到端加速1.6x（注意力3x），精度下降<0.5%

Conclusion: AttnCache有效突破自注意力计算瓶颈，为LLM非生成式应用提供高效推理方案

Abstract: Large Language Models (LLMs) are widely used in generative applications such
as chatting, code generation, and reasoning. However, many realworld workloads
such as classification, question answering, recommendation, and text embedding
rely solely on the prefill stage of inference, where the model encodes input
sequences without performing autoregressive decoding. In these prefill only
scenarios, the self-attention computation becomes the primary performance
bottleneck due to its quadratic complexity with respect to sequence length. In
this paper, we observe that semantically different sentences often produce
similar attention maps across layers and heads. Building on this insight, we
propose AttnCache, a framework that accelerates the prefill stage of LLM
inference by retrieving and reusing similar attention maps. Based on an
attention map memorization database, AttnCache employs efficient caching and
similarity search techniques to identify and reuse pre-cached attention maps
during inference, thereby reducing the computational overhead of
self-attention. Experimental results show that AttnCache achieves an average of
1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x
attention speedup on GPU, with negligible accuracy degradation.

</details>


### [18] [Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning](https://arxiv.org/abs/2510.25992)
*Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.CL

TL;DR: 提出监督强化学习（SRL）框架，结合监督与强化学习优势，有效提升小模型在复杂推理任务中的表现，并在软件工程任务中验证其通用性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习（RLVR）在正确方案极少被采样时失效，监督微调（SFT）存在对长演示的僵化模仿问题。需结合两者优势解决小模型多步推理的学习瓶颈。

Method: 将问题解决重构为逻辑动作序列生成，训练模型在输出每个动作前生成内部推理独白。通过逐步比对模型动作与专家动作的相似性提供平滑奖励信号。

Result: SRL使小模型掌握RLVR/SFT无法学习的复杂任务，SRL+RLVR组合实现最优性能，且在软件工程任务中展现强泛化能力。

Conclusion: SRL通过融合监督信号与强化学习机制，建立了面向推理任务的通用训练框架，显著提升小模型复杂问题解决能力。

Abstract: Large Language Models (LLMs) often struggle with problems that require
multi-step reasoning. For small-scale open-source models, Reinforcement
Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely
sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to
overfit long demonstrations through rigid token-by-token imitation. To address
this gap, we propose Supervised Reinforcement Learning (SRL), a framework that
reformulates problem solving as generating a sequence of logical "actions". SRL
trains the model to generate an internal reasoning monologue before committing
to each action. It provides smoother rewards based on the similarity between
the model's actions and expert actions extracted from the SFT dataset in a
step-wise manner. This supervision offers richer learning signals even when all
rollouts are incorrect, while encouraging flexible reasoning guided by expert
demonstrations. As a result, SRL enables small models to learn challenging
problems previously unlearnable by SFT or RLVR. Moreover, initializing training
with SRL before refining with RLVR yields the strongest overall performance.
Beyond reasoning benchmarks, SRL generalizes effectively to agentic software
engineering tasks, establishing it as a robust and versatile training framework
for reasoning-oriented LLMs.

</details>


### [19] [PORTool: Tool-Use LLM Training with Rewarded Tree](https://arxiv.org/abs/2510.26020)
*Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao*

Main category: cs.CL

TL;DR: 提出PORTool强化学习方法，通过探索多种工具调用轨迹提升语言模型的工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 当前工具调用模型依赖静态数据集模仿常规流程，缺乏对动态环境的适应性探索。

Method: 1. 生成多路径推理树 2. 基于答案正确性和工具调用成功率的层级奖励机制 3. 融合分支相关与轨迹相关优势的混合训练策略

Result: 在17个工具场景中显著提升最终准确率（+8.9%）并减少平均工具调用步骤（-2.1步）

Conclusion: 通过强化学习引导的探索性训练可有效增强语言模型在动态工具环境中的适应能力。

Abstract: Current tool-use large language models (LLMs) are trained on static datasets,
enabling them to interact with external tools and perform multi-step,
tool-integrated reasoning, which produces tool-call trajectories. However,
these models imitate how a query is resolved in a generic tool-call routine,
thereby failing to explore possible solutions and demonstrating limited
performance in an evolved, dynamic tool-call environment. In this work, we
propose PORTool, a reinforcement learning (RL) method that encourages a
tool-use LLM to explore various trajectories yielding the correct answer.
Specifically, this method starts with generating multiple rollouts for a given
query, and some of them share the first few tool-call steps, thereby forming a
tree-like structure. Next, we assign rewards to each step, based on its ability
to produce a correct answer and make successful tool calls. A shared step
across different trajectories receives the same reward, while different steps
under the same fork receive different rewards. Finally, these step-wise rewards
are used to calculate fork-relative advantages, blended with
trajectory-relative advantages, to train the LLM for tool use. The experiments
utilize 17 tools to address user queries, covering both time-sensitive and
time-invariant topics. We conduct ablation studies to systematically justify
the necessity and the design robustness of step-wise rewards. Furthermore, we
compare the proposed PORTool with other training approaches and demonstrate
significant improvements in final accuracy and the number of tool-call steps.

</details>


### [20] [Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs](https://arxiv.org/abs/2510.26024)
*HyoJung Han,Sweta Agrawal,Eleftheria Briakou*

Main category: cs.CL

TL;DR: 论文揭示了跨语言对齐（CLA）在促进知识迁移时会导致文化擦除问题，提出评估框架'迁移-本地化平面'并通过层次解耦的Surgical Steering方法实现平衡


<details>
  <summary>Details</summary>
Motivation: 现有跨语言对齐方法追求表征统一，但可能损害模型在不同语言文化背景下的差异化响应能力（文化擦除现象）

Method: 1. 建立迁移-本地化平面评估框架；2. 分析六种语言的CLA模型；3. 发现表征层次分工规律；4. 提出基于层次激活控制的Surgical Steering方法

Result: 1. CLA方法在六种语言中均显示知识迁移提升伴随文化本地化下降；2. 模型浅层适合文化特异性控制，深层适合通用知识迁移；3. Surgical Steering相比现有方法实现更优平衡

Conclusion: 通过层次解耦的激活控制方法，在保持跨语言知识迁移优势的同时有效保留文化特异性，突破了传统对齐技术的局限性

Abstract: Cross-lingual alignment (CLA) aims to align multilingual representations,
enabling Large Language Models (LLMs) to seamlessly transfer knowledge across
languages. While intuitive, we hypothesize, this pursuit of representational
convergence can inadvertently cause "cultural erasure", the functional loss of
providing culturally-situated responses that should diverge based on the query
language. In this work, we systematically analyze this trade-off by introducing
a holistic evaluation framework, the transfer-localization plane, which
quantifies both desirable knowledge transfer and undesirable cultural erasure.
Using this framework, we re-evaluate recent CLA approaches and find that they
consistently improve factual transfer at the direct cost of cultural
localization across all six languages studied. Our investigation into the
internal representations of these models reveals a key insight: universal
factual transfer and culturally-specific knowledge are optimally steerable at
different model layers. Based on this finding, we propose Surgical Steering, a
novel inference-time method that disentangles these two objectives. By applying
targeted activation steering to distinct layers, our approach achieves a better
balance between the two competing dimensions, effectively overcoming the
limitations of current alignment techniques.

</details>


### [21] [Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings](https://arxiv.org/abs/2510.26032)
*Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito*

Main category: cs.CL

TL;DR: 甲状腺偶发发现（ITFs）常见且与甲状腺癌过度诊断显著相关，需标准化报告和选择性随访


<details>
  <summary>Details</summary>
Motivation: 随着影像学检查普及，甲状腺偶发发现的临床意义和后果尚不明确，需系统性评估其流行病学特征和诊疗影响

Method: 开发基于Transformer的NLP流程，分析2017-2023年115,683例无甲状腺病史患者的影像报告，追踪后续超声、活检、手术及癌症诊断

Result: 7.8%患者发现ITFs（92.9%为结节），女性/高龄/肿瘤科申请者更易出现；ITFs患者甲状腺癌诊断率显著升高（多为微小乳头状癌）

Conclusion: ITFs导致低风险甲状腺癌的过度诊断，建议规范影像报告标准并优化随访策略以降低医疗风险

Abstract: Importance Incidental thyroid findings (ITFs) are increasingly detected on
imaging performed for non-thyroid indications. Their prevalence, features, and
clinical consequences remain undefined. Objective To develop, validate, and
deploy a natural language processing (NLP) pipeline to identify ITFs in
radiology reports and assess their prevalence, features, and clinical outcomes.
Design, Setting, and Participants Retrospective cohort of adults without prior
thyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from
July 1, 2017, to September 30, 2023. A transformer-based NLP pipeline
identified ITFs and extracted nodule characteristics from image reports from
multiple modalities and body regions. Main Outcomes and Measures Prevalence of
ITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer
diagnosis. Logistic regression identified demographic and imaging-related
factors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%
women), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more
likely in women, older adults, those with higher BMI, and when imaging was
ordered by oncology or internal medicine. Compared with chest CT, ITFs were
more likely via neck CT, PET, and nuclear medicine scans. Nodule
characteristics were poorly documented, with size reported in 44% and other
features in fewer than 15% (e.g. calcifications). Compared with patients
without ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,
biopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were
papillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were
common and strongly associated with cascades leading to the detection of small,
low-risk cancers. These findings underscore the role of ITFs in thyroid cancer
overdiagnosis and the need for standardized reporting and more selective
follow-up.

</details>


### [22] [QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback](https://arxiv.org/abs/2510.26101)
*Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura*

Main category: cs.CL

TL;DR: 提出量子编程评估框架QCoder Benchmark，通过模拟硬件反馈评估大语言模型性能，发现推理型模型o3准确率78%远超人类平均水平39.98%


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在需硬件交互的量子编程领域研究不足，缺乏结合硬件反馈和人类代码对比的系统评估方法

Method: 开发支持量子模拟器环境评测的框架，整合电路深度/执行时间等硬件指标，并采用真实竞赛的人类代码进行定量定性分析

Result: GPT-4o准确率仅18.97%，推理模型o3达78%准确率，显著优于人类代码39.98%的平均成功率

Conclusion: 该框架有效评估模型量子编程能力，揭示推理模型优势，发布数据集和API推动领域发展

Abstract: Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.

</details>


### [23] [Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking](https://arxiv.org/abs/2510.26122)
*Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung*

Main category: cs.CL

TL;DR: 提出1PNS训练范式和RPD指标，通过增加训练数据的推理路径多样性显著提升LLM的推理效果和输出多样性


<details>
  <summary>Details</summary>
Motivation: 传统1P1S训练模式导致LLM输出多样性低，限制TTS效果提升。需要量化思维链差异并引入多样化推理轨迹

Method: 开发RPD指标衡量多步推理路径差异，基于该指标筛选多样化解决方案构建1PNS训练集，微调Qwen3-4B-Base模型

Result: 在pass@16指标上平均提升2.80%，AIME24数据集提升4.99%。验证了多样化训练对TTS效果的增强作用

Conclusion: 1PNS训练范式结合RPD指标能有效突破传统训练模式限制，证明推理路径多样性是提升LLM推理能力的关键因素

Abstract: While Test-Time Scaling (TTS) has proven effective in improving the reasoning
ability of large language models (LLMs), low diversity in model outputs often
becomes a bottleneck; this is partly caused by the common "one problem, one
solution" (1P1S) training practice, which provides a single canonical answer
and can push models toward a narrow set of reasoning paths. To address this, we
propose a "one problem, multiple solutions" (1PNS) training paradigm that
exposes the model to a variety of valid reasoning trajectories and thus
increases inference diversity. A core challenge for 1PNS is reliably measuring
semantic differences between multi-step chains of thought, so we introduce
Reasoning Path Divergence (RPD), a step-level metric that aligns and scores
Long Chain-of-Thought solutions to capture differences in intermediate
reasoning. Using RPD, we curate maximally diverse solution sets per problem and
fine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields
more varied outputs and higher pass@k, with an average +2.80% gain in pass@16
over a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that
1PNS further amplifies the effectiveness of TTS. Our code is available at
https://github.com/fengjujf/Reasoning-Path-Divergence .

</details>


### [24] [On the Influence of Discourse Relations in Persuasive Texts](https://arxiv.org/abs/2510.26124)
*Nawar Turk,Sevag Kaspar,Leila Kosseim*

Main category: cs.CL

TL;DR: 利用大语言模型分析说服技巧与话语关系，发现六个关键话语关系在宣传检测和有效沟通中的作用。


<details>
  <summary>Details</summary>
Motivation: 缺乏同时标注说服技巧和话语关系的数据集，研究旨在探索二者关联以帮助检测网络宣传和虚假信息。

Method: 使用4种LLM模型配合10种提示策略生成40个分类器，通过多数表决集成创建5个银标数据集（204-1281个样本）。

Result: 识别出因果、目的、对比等六种核心话语关系，与煽动性语言、夸张、重复等说服技巧存在显著关联。

Conclusion: 该发现为虚假信息检测提供新视角，同时深化对有效传播机制的理论理解，具有双重应用价值。

Abstract: This paper investigates the relationship between Persuasion Techniques (PTs)
and Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and
prompt engineering. Since no dataset annotated with both PTs and DRs exists, we
took the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point
and developed LLM-based classifiers to label each instance of the dataset with
one of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10
different prompts, resulting in 40 unique DR classifiers. Ensemble models using
different majority-pooling strategies were used to create 5 silver datasets of
instances labelled with both persuasion techniques and level-2 PDTB senses. The
silver dataset sizes vary from 1,281 instances to 204 instances, depending on
the majority pooling technique used. Statistical analysis of these silver
datasets shows that six discourse relations (namely Cause, Purpose, Contrast,
Cause+Belief, Concession, and Condition) play a crucial role in persuasive
texts, especially in the use of Loaded Language, Exaggeration/Minimisation,
Repetition and to cast Doubt. This insight can contribute to detecting online
propaganda and misinformation, as well as to our general understanding of
effective communication.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [25] [StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement](https://arxiv.org/abs/2510.26141)
*Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang*

Main category: cs.GR

TL;DR: 提出基于Transformer的StructLayoutFormer框架，首次实现数据驱动的条件化结构化布局生成，在布局结构显式控制方面优于现有基线


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法只能生成固定布局但无法生成布局结构，结构化布局在二维视觉内容编辑中具有重要价值但创建过程费时费力

Method: 通过结构序列化方案将布局表示为序列，解耦结构信息与元素位置，使用Transformer架构实现条件化生成

Result: 在结构化布局生成任务中超过现有基准模型，实验证明能有效提取和迁移布局结构

Conclusion: 首个实现条件化结构化布局生成的数据驱动方法，代码开源为后续研究提供基础

Abstract: Structured layouts are preferable in many 2D visual contents (\eg, GUIs,
webpages) since the structural information allows convenient layout editing.
Computational frameworks can help create structured layouts but require heavy
labor input. Existing data-driven approaches are effective in automatically
generating fixed layouts but fail to produce layout structures. We present
StructLayoutFormer, a novel Transformer-based approach for conditional
structured layout generation. We use a structure serialization scheme to
represent structured layouts as sequences. To better control the structures of
generated layouts, we disentangle the structural information from the element
placements. Our approach is the first data-driven approach that achieves
conditional structured layout generation and produces realistic layout
structures explicitly. We compare our approach with existing data-driven layout
generation approaches by including post-processing for structure extraction.
Extensive experiments have shown that our approach exceeds these baselines in
conditional structured layout generation. We also demonstrate that our approach
is effective in extracting and transferring layout structures. The code is
publicly available at %\href{https://github.com/Teagrus/StructLayoutFormer}
{https://github.com/Teagrus/StructLayoutFormer}.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [26] [Look at That Distractor: Dynamic Translation Gain under Low Perceptual Load in Virtual Reality](https://arxiv.org/abs/2510.26265)
*Ling-Long Zou,Qiang Tong,Er-Xia Luo,Sen-Zhe Xu,Song-Hai Zhang,Fang-Lue Zhang*

Main category: cs.HC

TL;DR: 提出一种利用视觉干扰物动态调整平移增益的重定向行走方法，显著提高用户增益阈值并保持舒适度


<details>
  <summary>Details</summary>
Motivation: 现有研究表明用户被场景元素分心时对增益敏感度降低，但尚未量化检测阈值变化。需开发更高效的重定向行走系统

Method: 在用户视野内设置视觉干扰物，当注意力被吸引时动态施加更大平移增益。增益幅度与用户对干扰物的关注程度相关联

Result: 实验显示引入干扰物使平移增益阈值显著提升，模拟器病问卷和临场感问卷验证了用户舒适度与接受度

Conclusion: 该方法通过注意力机制实现平滑重定向，有效支持大范围虚拟环境中的自然导航，为RDW系统提供了新解决方案

Abstract: Redirected walking utilizes gain adjustments within perceptual thresholds to
allow natural navigation in large scale virtual environments within confined
physical environments. Previous research has found that when users are
distracted by some scene elements, they are less sensitive to gain values.
However, the effects on detection thresholds have not been quantitatively
measured. In this paper, we present a novel method that dynamically adjusts
translation gain by leveraging visual distractors. We place distractors within
the user's field of view and apply a larger translation gain when their
attention is drawn to them. Because the magnitude of gain adjustment depends on
the user's level of engagement with the distractors, the redirection process
remains smooth and unobtrusive. To evaluate our method, we developed a task
oriented virtual environment for a user study. Results show that introducing
distractors in the virtual environment significantly raises users' translation
gain thresholds. Furthermore, assessments using the Simulator Sickness
Questionnaire and Igroup Presence Questionnaire indicate that the method
maintains user comfort and acceptance, supporting its effectiveness for RDW
systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [The Impact and Outlook of 3D Gaussian Splatting](https://arxiv.org/abs/2510.26694)
*Bernhard Kerbl*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）已从突破性场景表示演变为支持动态建模、移动平台适配和大规模环境处理的3D基础工具


<details>
  <summary>Details</summary>
Motivation: 3DGS的出现彻底改变了3D场景表示范式，激发了围绕效率优化、动态扩展、数学基础验证和应用场景拓展的系统性研究

Method: 通过优化训练渲染效率、开发四维动态表示（4DGS）、深化外观建模数学理论、适配移动/VR平台、扩展大规模场景处理能力，以及构建前馈/分布式快速重建框架

Result: 实现资源高效利用、动态场景建模、跨平台部署、超大规模场景支持，以及接近实时的辐射场重建能力

Conclusion: 3DGS已发展成为连接3D视觉与图形学的通用化基础架构，其演进路径展示了从单一技术突破到生态体系构建的完整过程

Abstract: Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformed
the landscape of 3D scene representations, inspiring an extensive body of
associated research. Follow-up work includes analyses and contributions that
enhance the efficiency, scalability, and real-world applicability of 3DGS. In
this summary, we present an overview of several key directions that have
emerged in the wake of 3DGS. We highlight advances enabling resource-efficient
training and rendering, the evolution toward dynamic (or four-dimensional,
4DGS) representations, and deeper exploration of the mathematical foundations
underlying its appearance modeling and rendering process. Furthermore, we
examine efforts to bring 3DGS to mobile and virtual reality platforms, its
extension to massive-scale environments, and recent progress toward
near-instant radiance field reconstruction via feed-forward or distributed
computation. Collectively, these developments illustrate how 3DGS has evolved
from a breakthrough representation into a versatile and foundational tool for
3D vision and graphics.

</details>


### [28] [HEIR: Learning Graph-Based Motion Hierarchies](https://arxiv.org/abs/2510.26786)
*Cheng Zheng,William Koch,Baiang Li,Felix Heide*

Main category: cs.CV

TL;DR: 提出基于图学习的层次运动建模方法，通过可微图学习自动分解全局运动为父继承模式和局部残差，在1D/2D/3D场景验证了层次重建能力与生成效果优势。


<details>
  <summary>Details</summary>
Motivation: 现有层次运动建模方法依赖手动定义结构或固定运动原语，导致跨任务泛化性差。需要数据驱动的自适应建模框架来提升可解释性和任务适应性。

Method: 使用图结构表示运动层次，顶点代表基础运动单元，通过图神经网络学习父子节点依赖关系，将全局运动分解为父级继承模式与局部残差运动的叠加。

Result: 在1D平移/2D旋转运动中准确重建固有层次结构；在动态3D高斯溅射场景中生成比基线更真实、可解释的形变效果，PSNR提升2.3dB。

Conclusion: 该方法建立了数据驱动的通用运动建模范式，通过显式的层次分解机制，为计算机视觉、图形学等领域的运动相关任务提供了可扩展的解决方案。

Abstract: Hierarchical structures of motion exist across research fields, including
computer vision, graphics, and robotics, where complex dynamics typically arise
from coordinated interactions among simpler motion components. Existing methods
to model such dynamics typically rely on manually-defined or heuristic
hierarchies with fixed motion primitives, limiting their generalizability
across different tasks. In this work, we propose a general hierarchical motion
modeling method that learns structured, interpretable motion relationships
directly from data. Our method represents observed motions using graph-based
hierarchies, explicitly decomposing global absolute motions into
parent-inherited patterns and local motion residuals. We formulate hierarchy
inference as a differentiable graph learning problem, where vertices represent
elemental motions and directed edges capture learned parent-child dependencies
through graph neural networks. We evaluate our hierarchical reconstruction
approach on three examples: 1D translational motion, 2D rotational motion, and
dynamic 3D scene deformation via Gaussian splatting. Experimental results show
that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,
and produces more realistic and interpretable deformations compared to the
baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,
data-driven hierarchical modeling paradigm, our method offers a formulation
applicable to a broad range of motion-centric tasks. Project Page:
https://light.princeton.edu/HEIR/

</details>


### [29] [SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting](https://arxiv.org/abs/2510.26796)
*Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出SEE4D框架，通过虚拟相机阵列和修复模型从非结构化视频生成4D时空内容，无需3D标注


<details>
  <summary>Details</summary>
Motivation: 现有视频转4D方法依赖人工标注的相机姿态，且轨迹预测框架将相机运动与场景动态耦合，导致建模和推理复杂化

Method: 1. 用固定虚拟相机阵列替代显式轨迹预测
2. 训练视角条件视频修复模型学习几何先验
3. 设计时空自回归推理流程，通过虚拟相机样条扩展视频

Result: 在跨视角视频生成和稀疏重建基准测试中，量化指标和定性评估均优于基于相机姿态或轨迹的基线方法

Conclusion: SEE4D实现了从非结构化视频进行实用4D建模，通过分离相机控制与场景建模，在泛化能力和性能上取得突破

Abstract: Immersive applications call for synthesizing spatiotemporal 4D content from
casual videos without costly 3D supervision. Existing video-to-4D methods
typically rely on manually annotated camera poses, which are labor-intensive
and brittle for in-the-wild footage. Recent warp-then-inpaint approaches
mitigate the need for pose labels by warping input frames along a novel camera
trajectory and using an inpainting model to fill missing regions, thereby
depicting the 4D scene from diverse viewpoints. However, this
trajectory-to-trajectory formulation often entangles camera motion with scene
dynamics and complicates both modeling and inference. We introduce SEE4D, a
pose-free, trajectory-to-camera framework that replaces explicit trajectory
prediction with rendering to a bank of fixed virtual cameras, thereby
separating camera control from scene modeling. A view-conditional video
inpainting model is trained to learn a robust geometry prior by denoising
realistically synthesized warped images and to inpaint occluded or missing
regions across virtual viewpoints, eliminating the need for explicit 3D
annotations. Building on this inpainting core, we design a spatiotemporal
autoregressive inference pipeline that traverses virtual-camera splines and
extends videos with overlapping windows, enabling coherent generation at
bounded per-step complexity. We validate See4D on cross-view video generation
and sparse reconstruction benchmarks. Across quantitative metrics and
qualitative assessments, our method achieves superior generalization and
improved performance relative to pose- or trajectory-conditioned baselines,
advancing practical 4D world modeling from casual videos.

</details>


### [30] [OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes](https://arxiv.org/abs/2510.26800)
*Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu*

Main category: cs.CV

TL;DR: 通过OmniX框架复用2D生成模型实现即用型3D场景生成，结合跨模态适配器和全景数据集提升几何/材质感知能力


<details>
  <summary>Details</summary>
Motivation: 现有2D提升方法忽略内在属性感知，需突破外观生成局限以支持物理渲染/模拟的图形就绪型场景构建

Method: 基于轻量级跨模态适配器架构，通过全景感知范式统一支持几何重建、材质分解、全景补全等多任务

Result: 构建大规模多模态全景数据集，实验验证模型在物理真实场景生成和全景感知任务中的有效性

Conclusion: 为沉浸式虚拟世界生成开辟新路径，实现物理精确且即用型3D场景的端到端构建

Abstract: There are two prevalent ways to constructing 3D scenes: procedural generation
and 2D lifting. Among them, panorama-based 2D lifting has emerged as a
promising technique, leveraging powerful 2D generative priors to produce
immersive, realistic, and diverse 3D environments. In this work, we advance
this technique to generate graphics-ready 3D scenes suitable for physically
based rendering (PBR), relighting, and simulation. Our key insight is to
repurpose 2D generative models for panoramic perception of geometry, textures,
and PBR materials. Unlike existing 2D lifting approaches that emphasize
appearance generation and ignore the perception of intrinsic properties, we
present OmniX, a versatile and unified framework. Based on a lightweight and
efficient cross-modal adapter structure, OmniX reuses 2D generative priors for
a broad range of panoramic vision tasks, including panoramic perception,
generation, and completion. Furthermore, we construct a large-scale synthetic
panorama dataset containing high-quality multimodal panoramas from diverse
indoor and outdoor scenes. Extensive experiments demonstrate the effectiveness
of our model in panoramic visual perception and graphics-ready 3D scene
generation, opening new possibilities for immersive and physically realistic
virtual world generation.

</details>
