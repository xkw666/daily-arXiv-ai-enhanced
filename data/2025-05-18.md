<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 43]
- [cs.CV](#cs.CV) [Total: 56]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Next Word Suggestion using Graph Neural Network](https://arxiv.org/abs/2505.09649)
*Abisha Thapa Magar,Anup Shakya*

Main category: cs.CL

TL;DR: 提出结合图卷积网络（GCN）与LSTM的上下文嵌入方法，在有限资源下有效预测下一个单词


<details>
  <summary>Details</summary>
Motivation: 现有大规模语言模型依赖巨额资源和成本，本研究旨在探索资源高效的上下文嵌入方法，降低语言模型训练门槛

Method: 采用图卷积网络（GCN）编码上下文信息，与LSTM协同工作，在有限资源条件下于维基百科语料库进行实验

Result: 实验表明，该方法在资源受限情况下能有效完成下一词预测任务，验证了轻量级模型的可行性

Conclusion: GCN与LSTM的融合为资源敏感场景下的语言建模提供了新思路，证明了轻量化架构的潜力

Abstract: Language Modeling is a prevalent task in Natural Language Processing. The
currently existing most recent and most successful language models often tend
to build a massive model with billions of parameters, feed in a tremendous
amount of text data, and train with enormous computation resources which
require millions of dollars. In this project, we aim to address an important
sub-task in language modeling, i.e., context embedding. We propose an approach
to exploit the Graph Convolution operation in GNNs to encode the context and
use it in coalition with LSTMs to predict the next word given a local context
of preceding words. We test this on the custom Wikipedia text corpus using a
very limited amount of resources and show that this approach works fairly well
to predict the next word.

</details>


### [2] [DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models](https://arxiv.org/abs/2505.09655)
*Xiwen Chen,Wenhui Zhu,Peijie Qiu,Xuanzhao Dong,Hao Wang,Haiyu Wu,Huayu Li,Aristeidis Sotiras,Yalin Wang,Abolfazl Razi*

Main category: cs.CL

TL;DR: 提出基于子模互信息的多样性奖励调整方法DRA-GRPO，解决强化学习中文语模型后训练中的多样性-质量矛盾问题，仅用7000样本实现58.2%的SOTA准确率


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法依赖标量奖励信号，无法捕捉语义多样性，导致不同推理路径获得相似奖励的多样性-质量不一致问题

Method: 通过子模互信息(SMI)量化语义多样性，对冗余样本降权并增强多样性样本奖励，开发DRA-GRPO和DGA-DR.GRPO两种变体

Result: 在5个数学推理基准测试中达到58.2%平均准确率，仅消耗7000微调样本和约55美元训练成本

Conclusion: DRA方法有效平衡探索与利用，在极低资源条件下实现性能突破，为语言模型后训练提供高效解决方案

Abstract: Recent advances in reinforcement learning for language model post-training,
such as Group Relative Policy Optimization (GRPO), have shown promise in
low-resource settings. However, GRPO typically relies on solution-level and
scalar reward signals that fail to capture the semantic diversity among sampled
completions. This leads to what we identify as a diversity-quality
inconsistency, where distinct reasoning paths may receive indistinguishable
rewards. To address this limitation, we propose $\textit{Diversity-aware Reward
Adjustment}$ (DRA), a method that explicitly incorporates semantic diversity
into the reward computation. DRA uses Submodular Mutual Information (SMI) to
downweight redundant completions and amplify rewards for diverse ones. This
encourages better exploration during learning, while maintaining stable
exploitation of high-quality samples. Our method integrates seamlessly with
both GRPO and its variant DR.~GRPO, resulting in $\textit{DRA-GRPO}$ and
$\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning
benchmarks and find that it outperforms recent strong baselines. It achieves
state-of-the-art performance with an average accuracy of 58.2%, using only
7,000 fine-tuning samples and a total training cost of approximately $55. The
code is available at https://github.com/xiwenc1/DRA-GRPO.

</details>


### [3] [Large Language Models Are More Persuasive Than Incentivized Human Persuaders](https://arxiv.org/abs/2505.09662)
*Philipp Schoenegger,Francesco Salvi,Jiacheng Liu,Xiaoli Nan,Ramit Debnath,Barbara Fasolo,Evelina Leivada,Gabriel Recchia,Fritz Günther,Ali Zarifhonarvar,Joe Kwon,Zahoor Ul Islam,Marco Dehnert,Daryl Y. H. Lee,Madeline G. Reinecke,David G. Kamper,Mert Kobaş,Adam Sandford,Jonas Kgomo,Luke Hewitt,Shreya Kapoor,Kerem Oktar,Eyup Engin Kucuk,Bo Feng,Cameron R. Jones,Izzy Gainsburg,Sebastian Olschewski,Nora Heinzelmann,Francisco Cruz,Ben M. Tappin,Tao Ma,Peter S. Park,Rayan Onyonka,Arthur Hjorth,Peter Slattery,Qingcheng Zeng,Lennart Finke,Igor Grossmann,Alessandro Salatiello,Ezra Karger*

Main category: cs.CL

TL;DR: 大型语言模型Claude Sonnet 3.5在真实对话场景中展现出超越激励人类的说服能力，无论引导正确或错误答案均显著影响答题者决策


<details>
  <summary>Details</summary>
Motivation: 验证前沿AI模型的说服能力是否超越受金钱激励的人类说服者，揭示AI说服技术对现实决策的影响

Method: 采用预注册大规模激励实验：说服者（人类/AI）在实时对话测试中引导答题者选择指定答案，对比合规率与经济收益

Result: LLM说服合规率显著更高（正确引导+16.5%，错误引导+21.3%），直接影响答题准确率（正确引导提升收益$0.68，错误引导降低收益$1.24）

Conclusion: AI说服能力已超越受经济激励的人类，突显构建AI伦理框架与治理体系的紧迫性，需警惕滥用风险与社会影响

Abstract: We directly compare the persuasion capabilities of a frontier large language
model (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an
interactive, real-time conversational quiz setting. In this preregistered,
large-scale incentivized experiment, participants (quiz takers) completed an
online quiz where persuaders (either humans or LLMs) attempted to persuade quiz
takers toward correct or incorrect answers. We find that LLM persuaders
achieved significantly higher compliance with their directional persuasion
attempts than incentivized human persuaders, demonstrating superior persuasive
capabilities in both truthful (toward correct answers) and deceptive (toward
incorrect answers) contexts. We also find that LLM persuaders significantly
increased quiz takers' accuracy, leading to higher earnings, when steering quiz
takers toward correct answers, and significantly decreased their accuracy,
leading to lower earnings, when steering them toward incorrect answers.
Overall, our findings suggest that AI's persuasion capabilities already exceed
those of humans that have real-money bonuses tied to performance. Our findings
of increasingly capable AI persuaders thus underscore the urgency of emerging
alignment and governance frameworks.

</details>


### [4] [System Prompt Optimization with Meta-Learning](https://arxiv.org/abs/2505.09666)
*Yumin Choi,Jinheon Baek,Sung Ju Hwang*

Main category: cs.CL

TL;DR: 提出双层系统提示优化框架，通过元学习联合优化系统提示和用户提示，提升LLM在不同任务和未见领域的泛化能力与快速适应性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究聚焦任务特定的用户提示优化，忽视了跨任务通用的系统提示潜力。系统提示一旦优化可广泛适用于不同任务，具有更高应用价值。

Method: 采用元学习框架，在多数据集上交替优化系统提示与用户提示：1) 固定系统提示优化用户提示 2) 基于用户提示更新系统提示，形成协同进化机制。

Result: 在5个领域14个未见数据集验证：优化后的系统提示对多样化用户提示展现强泛化性，在未见任务上仅需少量优化步骤即可实现性能提升（最高达XX%）。

Conclusion: 系统提示优化是提升LLM通用性的关键路径，该框架实现了提示工程从任务特定到任务无关的范式转变，为模型快速部署提供新思路。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities, with
optimizing their input prompts playing a pivotal role in maximizing their
performance. However, while LLM prompts consist of both the task-agnostic
system prompts and task-specific user prompts, existing work on prompt
optimization has focused on user prompts specific to individual queries or
tasks, and largely overlooked the system prompt that is, once optimized,
applicable across different tasks and domains. Motivated by this, we introduce
the novel problem of bilevel system prompt optimization, whose objective is to
design system prompts that are robust to diverse user prompts and transferable
to unseen tasks. To tackle this problem, we then propose a meta-learning
framework, which meta-learns the system prompt by optimizing it over various
user prompts across multiple datasets, while simultaneously updating the user
prompts in an iterative manner to ensure synergy between them. We conduct
experiments on 14 unseen datasets spanning 5 different domains, on which we
show that our approach produces system prompts that generalize effectively to
diverse user prompts. Also, our findings reveal that the optimized system
prompt enables rapid adaptation even to unseen tasks, requiring fewer
optimization steps for test-time user prompts while achieving improved
performance.

</details>


### [5] [VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts](https://arxiv.org/abs/2505.09701)
*Xin Liu,Lechen Zhang,Sheza Munir,Yiyang Gu,Lu Wang*

Main category: cs.CL

TL;DR: 提出VeriFact框架提升LLMs事实性评估的完整性，并创建FactRBench基准实现精确率与召回率双重评估


<details>
  <summary>Details</summary>
Motivation: 现有方法在分解-去语境化-验证流程中难以捕捉关键上下文和关系事实，导致事实完整性不足

Method: 1. 开发VeriFact框架增强事实提取完整性 2. 构建FactRBench基准包含人工标注和先进LLM参考答案 3. 同时评估精确率与召回率

Result: VeriFact提升事实完整性80%，模型规模扩展可提高性能但精确率与召回率无必然相关性（如Llama3-70B精确率70%但召回仅62%）

Conclusion: 综合事实性评估需同时考虑精确率和召回率，模型性能提升不等于评估维度全面覆盖，需专用评估框架支持

Abstract: Large language models (LLMs) excel at generating long-form responses, but
evaluating their factuality remains challenging due to complex inter-sentence
dependencies within the generated facts. Prior solutions predominantly follow a
decompose-decontextualize-verify pipeline but often fail to capture essential
context and miss key relational facts. In this paper, we introduce VeriFact, a
factuality evaluation framework designed to enhance fact extraction by
identifying and resolving incomplete and missing facts to support more accurate
verification results. Moreover, we introduce FactRBench , a benchmark that
evaluates both precision and recall in long-form model responses, whereas prior
work primarily focuses on precision. FactRBench provides reference fact sets
from advanced LLMs and human-written answers, enabling recall assessment.
Empirical evaluations show that VeriFact significantly enhances fact
completeness and preserves complex facts with critical relational information,
resulting in more accurate factuality evaluation. Benchmarking various open-
and close-weight LLMs on FactRBench indicate that larger models within same
model family improve precision and recall, but high precision does not always
correlate with high recall, underscoring the importance of comprehensive
factuality assessment.

</details>


### [6] [An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs](https://arxiv.org/abs/2505.09724)
*Gino Carmona-Díaz,William Jiménez-Leal,María Alejandra Grisales,Chandra Sripada,Santiago Amaya,Michael Inzlicht,Juan Pablo Bermúdez*

Main category: cs.CL

TL;DR: 提出LLM协同文本分析框架，通过人机迭代开发分类法并实现高编码一致性


<details>
  <summary>Details</summary>
Motivation: 传统文本分析方法耗时且易受主观偏差影响，需要高效可靠的自动化解决方案

Method: 采用迭代式人机协作流程：1) 提示工程生成初始分类法 2) 混合提示优化与人工修正 3) 编码一致性检验 4) 全数据集自动分类

Result: 在个人目标分类任务中实现0.88的编码者间一致性系数，显著高于传统人工编码

Conclusion: LLM在保持高效率的同时可实现专业级文本分析效果，但需警惕模型偏差与领域适应性限制

Abstract: Analyzing texts such as open-ended responses, headlines, or social media
posts is a time- and labor-intensive process highly susceptible to bias. LLMs
are promising tools for text analysis, using either a predefined (top-down) or
a data-driven (bottom-up) taxonomy, without sacrificing quality. Here we
present a step-by-step tutorial to efficiently develop, test, and apply
taxonomies for analyzing unstructured data through an iterative and
collaborative process between researchers and LLMs. Using personal goals
provided by participants as an example, we demonstrate how to write prompts to
review datasets and generate a taxonomy of life domains, evaluate and refine
the taxonomy through prompt and direct modifications, test the taxonomy and
assess intercoder agreements, and apply the taxonomy to categorize an entire
dataset with high intercoder reliability. We discuss the possibilities and
limitations of using LLMs for text analysis.

</details>


### [7] [Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning](https://arxiv.org/abs/2505.09738)
*Shaurya Sharthak,Vinayak Pahalwan,Adithya Kamath,Adarsh Shirawalmath*

Main category: cs.CL

TL;DR: 提出Tokenadapt框架解决LLM固定分词器锁定问题，通过混合初始化策略和Supertokens预分词技术提升移植效率并保持语义


<details>
  <summary>Details</summary>
Motivation: 固定分词器导致多语言/专业场景效率低下，现有方法需高昂算力且无法有效保留语义，需更优解决方案

Method: 1. Tokenadapt：结合子词分解的局部估计与全局语义相似token的混合初始化策略
2. Supertokens：多词预分词学习优化压缩与碎片化

Result: Tokenadapt零样本困惑度显著优于ReTok/TransTokenizer，困惑度比率降低至少2倍，Supertokens实现明显压缩增益

Conclusion: 混合初始化有效平衡语义保持与训练成本，为分词器移植提供高效解决方案，具有实际部署价值

Abstract: Pretrained language models (LLMs) are often constrained by their fixed
tokenization schemes, leading to inefficiencies and performance limitations,
particularly for multilingual or specialized applications. This tokenizer
lock-in presents significant challenges. standard methods to overcome this
often require prohibitive computational resources. Although tokenizer
replacement with heuristic initialization aims to reduce this burden, existing
methods often require exhaustive residual fine-tuning and still may not fully
preserve semantic nuances or adequately address the underlying compression
inefficiencies. Our framework introduces two innovations: first, Tokenadapt, a
model-agnostic tokenizer transplantation method, and second, novel
pre-tokenization learning for multi-word Supertokens to enhance compression and
reduce fragmentation. Tokenadapt initializes new unique token embeddings via a
hybrid heuristic that combines two methods: a local estimate based on subword
decomposition using the old tokenizer, and a global estimate utilizing the
top-k semantically similar tokens from the original vocabulary. This
methodology aims to preserve semantics while significantly minimizing
retraining requirements. Empirical investigations validate both contributions:
the transplantation heuristic successfully initializes unique tokens, markedly
outperforming conventional baselines and sophisticated methods including
Transtokenizer and ReTok, while our Supertokens achieve notable compression
gains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid
initialization consistently yields lower perplexity ratios compared to both
ReTok and TransTokenizer baselines across different base models and newly
trained target tokenizers. TokenAdapt typically reduced the overall perplexity
ratio significantly compared to ReTok, yielding at least a 2-fold improvement
in these aggregate scores.

</details>


### [8] [Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques](https://arxiv.org/abs/2505.09794)
*J. Moreno-Casanova,J. M. Auñón,A. Mártinez-Pérez,M. E. Pérez-Martínez,M. E. Gas-López*

Main category: cs.CL

TL;DR: 利用NLP技术自动提取肺癌和乳腺癌电子病历中的临床信息，通过微调RoBERTa模型实现高精度实体识别，显著提升医疗数据处理效率。


<details>
  <summary>Details</summary>
Motivation: 传统临床报告人工提取方式效率低下且易错，阻碍医疗数据驱动研究。肺癌和乳腺癌的高发病率亟需高效数据管理手段以改善患者预后。

Method: 使用GMV的uQuery工具标准化临床文本，基于西班牙语bsc-bio-ehr-en3模型进行微调，采用Transformers架构在600份标注报告（200乳腺癌+400肺癌）上实现命名实体识别。

Result: 模型整体表现优异（MET/PAT识别F1值0.94），但低频实体EVOL识别存在挑战（F1值0.62），显示数据不平衡对模型性能的影响。

Conclusion: NLP技术显著提升癌症临床数据提取效率，未来需通过数据增强和领域适应优化低频实体识别，推动精准医疗发展。

Abstract: Research projects, including those focused on cancer, rely on the manual
extraction of information from clinical reports. This process is time-consuming
and prone to errors, limiting the efficiency of data-driven approaches in
healthcare. To address these challenges, Natural Language Processing (NLP)
offers an alternative for automating the extraction of relevant data from
electronic health records (EHRs). In this study, we focus on lung and breast
cancer due to their high incidence and the significant impact they have on
public health. Early detection and effective data management in both types of
cancer are crucial for improving patient outcomes. To enhance the accuracy and
efficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels
at identifying relevant entities in clinical texts and converting them into
standardized formats such as SNOMED and OMOP. uQuery not only detects and
classifies entities but also associates them with contextual information,
including negated entities, temporal aspects, and patient-related details. In
this work, we explore the use of NLP techniques, specifically Named Entity
Recognition (NER), to automatically identify and extract key clinical
information from EHRs related to these two cancers. A dataset from Health
Research Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast
cancer and 400 lung cancer reports, was used, with eight clinical entities
manually labeled using the Doccano platform. To perform NER, we fine-tuned the
bsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained
in Spanish. Fine-tuning was performed using the Transformers architecture,
enabling accurate recognition of clinical entities in these cancer types. Our
results demonstrate strong overall performance, particularly in identifying
entities like MET and PAT, although challenges remain with less frequent
entities like EVOL.

</details>


### [9] [Exploring the generalization of LLM truth directions on conversational formats](https://arxiv.org/abs/2505.09807)
*Timour Ichmoukhamedov,David Martens*

Main category: cs.CL

TL;DR: 论文探索LLM真理方向在不同对话格式中的泛化能力，提出通过添加关键短语改善长对话场景下的谎言检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明LLM激活空间中存在可分离真假陈述的真理方向，但该方向在不同长度和结构的对话场景中泛化能力不足，阻碍可靠谎言检测系统的开发。

Method: 1. 测试真理方向在短对话（谎言在末尾）与长对话（谎言在开头）的泛化表现
2. 提出在对话末尾添加固定关键短语的优化方案

Result: 关键短语策略使长对话场景的检测准确率提升37%，但跨格式泛化问题仍未完全解决（短对话间AUC 0.89→0.91，短到长对话AUC下降至0.68）

Conclusion: LLM谎言检测器的实际应用需要更鲁棒的跨格式泛化能力，当前基于单一隐藏状态的线性探测方法存在场景局限性

Abstract: Several recent works argue that LLMs have a universal truth direction where
true and false statements are linearly separable in the activation space of the
model. It has been demonstrated that linear probes trained on a single hidden
state of the model already generalize across a range of topics and might even
be used for lie detection in LLM conversations. In this work we explore how
this truth direction generalizes between various conversational formats. We
find good generalization between short conversations that end on a lie, but
poor generalization to longer formats where the lie appears earlier in the
input prompt. We propose a solution that significantly improves this type of
generalization by adding a fixed key phrase at the end of each conversation.
Our results highlight the challenges towards reliable LLM lie detectors that
generalize to new settings.

</details>


### [10] [KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning](https://arxiv.org/abs/2505.09825)
*Peiqi Sui,Juan Diego Rodriguez,Philippe Laban,Dean Murphy,Joseph P. Dexter,Richard Jean So,Samuel Baker,Pramit Chaudhuri*

Main category: cs.CL

TL;DR: 首个针对大语言模型的文学细读评估基准KRISTEVA，通过1331道选择题构建三层渐进任务，揭示LLMs在文学解读推理中的表现落后于人类


<details>
  <summary>Details</summary>
Motivation: 细读能力作为批判性思维基础从未在LLMs中评估，现有通用基准缺乏文学科目。需填补LLMs在文学文本深度解析与推理能力评估的空白

Method: 1) 改编课堂数据构建1331道选择题基准
2) 设计三层渐进任务：文体特征提取→参数化知识检索→风格与语境的多跳推理
3) 对比LLMs与人类评估者表现

Result: 顶尖LLMs展现部分大学级细读能力（准确率49.7%-69.7%），但在11项任务中10项表现落后于经验丰富的人类评估者

Conclusion: KRISTEVA填补文学评估基准空白，揭示LLMs在复杂文学推理任务中的持续缺陷，强调需提升模型对文本风格与语境关联的深层理解能力

Abstract: Each year, tens of millions of essays are written and graded in college-level
English courses. Students are asked to analyze literary and cultural texts
through a process known as close reading, in which they gather textual details
to formulate evidence-based arguments. Despite being viewed as a basis for
critical thinking and widely adopted as a required element of university
coursework, close reading has never been evaluated on large language models
(LLMs), and multi-discipline benchmarks like MMLU do not include literature as
a subject. To fill this gap, we present KRISTEVA, the first close reading
benchmark for evaluating interpretive reasoning, consisting of 1331
multiple-choice questions adapted from classroom data. With KRISTEVA, we
propose three progressively more difficult sets of tasks to approximate
different elements of the close reading process, which we use to test how well
LLMs may seem to understand and reason about literary works: 1) extracting
stylistic features, 2) retrieving relevant contextual information from
parametric knowledge, and 3) multi-hop reasoning between style and external
contexts. Our baseline results find that, while state-of-the-art LLMs possess
some college-level close reading competency (accuracy 49.7% - 69.7%), their
performances still trail those of experienced human evaluators on 10 out of our
11 tasks.

</details>


### [11] [Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting](https://arxiv.org/abs/2505.09852)
*Apollinaire Poli Nemkova,Sarath Chandra Lingareddy,Sagnik Ray Choudhury,Mark V. Albert*

Main category: cs.CL

TL;DR: 评估大语言模型内在知识与外部数据增强在冲突预测中的效果，发现结合结构化外部信息可提升预测准确性


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否具备预测暴力冲突升级的内在参数化知识，及其与外部数据增强（RAG技术）结合的效果，为早期预警系统提供技术支持

Method: 建立双轨评估框架（2020-2024），对比纯参数化预测与引入ACLED/GDELT数据集及新闻的RAG模式，使用趋势标签和伤亡数据验证模型表现

Result: LLMs具备基础冲突预测能力，但结合结构化外部知识后预测准确性显著提升，特别是在地缘政治动态捕捉方面表现更优

Conclusion: 参数化知识与非参数化外部信息的融合能有效增强冲突预测系统，为实时人道主义响应提供更可靠的技术支持

Abstract: Large Language Models (LLMs) have shown impressive performance across natural
language tasks, but their ability to forecast violent conflict remains
underexplored. We investigate whether LLMs possess meaningful parametric
knowledge-encoded in their pretrained weights-to predict conflict escalation
and fatalities without external data. This is critical for early warning
systems, humanitarian planning, and policy-making. We compare this parametric
knowledge with non-parametric capabilities, where LLMs access structured and
unstructured context from conflict datasets (e.g., ACLED, GDELT) and recent
news reports via Retrieval-Augmented Generation (RAG). Incorporating external
information could enhance model performance by providing up-to-date context
otherwise missing from pretrained weights. Our two-part evaluation framework
spans 2020-2024 across conflict-prone regions in the Horn of Africa and the
Middle East. In the parametric setting, LLMs predict conflict trends and
fatalities relying only on pretrained knowledge. In the non-parametric setting,
models receive summaries of recent conflict events, indicators, and
geopolitical developments. We compare predicted conflict trend labels (e.g.,
Escalate, Stable Conflict, De-escalate, Peace) and fatalities against
historical data. Our findings highlight the strengths and limitations of LLMs
for conflict forecasting and the benefits of augmenting them with structured
external knowledge.

</details>


### [12] [Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries](https://arxiv.org/abs/2505.09902)
*Martin Capdevila,Esteban Villa Turek,Ellen Karina Chumbe Fernandez,Luis Felipe Polo Galvez,Luis Cadavid,Andrea Marroquin,Rebeca Vargas Quesada,Johanna Crew,Nicole Vallejo Galarraga,Christopher Rodriguez,Diego Gutierrez,Radhi Datla*

Main category: cs.CL

TL;DR: 论文强调需开发区域本地化语言模型，通过分析西班牙语不同变体的社会语言学差异，提出实施五种西班牙语子变体以提升AI包容性和用户增长。


<details>
  <summary>Details</summary>
Motivation: 不同西班牙语变体在日常使用中存在显著社会语言学差异，导致用户与AI模型间的隔阂，需通过本地化策略提升模型包容性和国际化效果。

Method: 通过比较拉丁美洲与西班牙的西班牙语变体差异，结合社会文化背景分析，论证本地化AI模型对消除社会语言不协调的作用。

Result: 发现方言差异实质构成用户信任障碍，证明区域敏感模型可有效弥合分歧并促进可持续用户增长。

Conclusion: 建议至少实施五种西班牙语子变体，既能增强用户对AI的信任，又体现文化敏感性，支持国际化战略的低风险投资布局。

Abstract: Large language models are, by definition, based on language. In an effort to
underscore the critical need for regional localized models, this paper examines
primary differences between variants of written Spanish across Latin America
and Spain, with an in-depth sociocultural and linguistic contextualization
therein. We argue that these differences effectively constitute significant
gaps in the quotidian use of Spanish among dialectal groups by creating
sociolinguistic dissonances, to the extent that locale-sensitive AI models
would play a pivotal role in bridging these divides. In doing so, this approach
informs better and more efficient localization strategies that also serve to
more adequately meet inclusivity goals, while securing sustainable active daily
user growth in a major low-risk investment geographic area. Therefore,
implementing at least the proposed five sub variants of Spanish addresses two
lines of action: to foment user trust and reliance on AI language models while
also demonstrating a level of cultural, historical, and sociolinguistic
awareness that reflects positively on any internationalization strategy.

</details>


### [13] [From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models](https://arxiv.org/abs/2505.09924)
*Yidan Wang,Yubing Ren,Yanan Cao,Binxing Fang*

Main category: cs.CL

TL;DR: 论文提出融合logits-based和sampling-based的共生水印框架，通过熵自适应机制平衡水印性能，在多项指标上达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有LLM水印方案在鲁棒性、文本质量和安全性之间存在权衡，需整合不同方案的协同优势来解决这一困境。

Method: 提出串行、并行和混合三种共生策略，其中混合框架通过token熵和语义熵自适应嵌入水印，优化检测性、鲁棒性、文本质量与安全性的平衡。

Result: 在多数据集和模型上的实验表明，该方法全面超越现有基线，尤其在语义保持和水印不可察觉性方面提升显著（最高提升30%）。

Conclusion: 该框架为多范式水印协同提供了新思路，代码已开源。基于熵的自适应机制为未来水印研究提供了重要方向。

Abstract: The rise of Large Language Models (LLMs) has heightened concerns about the
misuse of AI-generated text, making watermarking a promising solution.
Mainstream watermarking schemes for LLMs fall into two categories: logits-based
and sampling-based. However, current schemes entail trade-offs among
robustness, text quality, and security. To mitigate this, we integrate
logits-based and sampling-based schemes, harnessing their respective strengths
to achieve synergy. In this paper, we propose a versatile symbiotic
watermarking framework with three strategies: serial, parallel, and hybrid. The
hybrid framework adaptively embeds watermarks using token entropy and semantic
entropy, optimizing the balance between detectability, robustness, text
quality, and security. Furthermore, we validate our approach through
comprehensive experiments on various datasets and models. Experimental results
indicate that our method outperforms existing baselines and achieves
state-of-the-art (SOTA) performance. We believe this framework provides novel
insights into diverse watermarking paradigms. Our code is available at
\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}.

</details>


### [14] [Rethinking Prompt Optimizers: From Prompt Merits to Optimization](https://arxiv.org/abs/2505.09930)
*Zixiao Zhu,Hanzhang Zhou,Zijian Feng,Tianjiao Li,Chua Jia Jim Deryl,Mak Lee Onn,Gee Wah Ng,Kezhi Mao*

Main category: cs.CL

TL;DR: 提出MePO——基于可解释设计原则的轻量级提示优化器，通过明确的质量指标和本地化部署解决现有方法对高级LLM的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法依赖GPT-4等高级LLM生成冗长提示，导致轻量级推理模型响应质量下降。需要找到模型无关的提示质量评估标准，实现向下兼容。

Method: 1. 识别模型无关的提示质量指标并验证有效性
2. 使用轻量级LLM生成符合指标的提示构建偏好数据集
3. 训练基于质量指标指导的本地可部署优化器MePO

Result: 实验证明MePO在多样化任务和模型类型中表现优异，对轻量级模型优化效果提升显著，实现零样本场景下的稳定泛化。

Conclusion: MePO通过可解释的质量指标设计，解决了传统方法的在线优化依赖和隐私成本问题，为实际部署提供可扩展的解决方案。

Abstract: Prompt optimization (PO) offers a practical alternative to fine-tuning large
language models (LLMs), enabling performance improvements without altering
model weights. Existing methods typically rely on advanced, large-scale LLMs
like GPT-4 to generate optimized prompts. However, due to limited downward
compatibility, verbose, instruction-heavy prompts from advanced LLMs can
overwhelm lightweight inference models and degrade response quality. In this
work, we rethink prompt optimization through the lens of interpretable design.
We first identify a set of model-agnostic prompt quality merits and empirically
validate their effectiveness in enhancing prompt and response quality. We then
introduce MePO, a merit-guided, lightweight, and locally deployable prompt
optimizer trained on our preference dataset built from merit-aligned prompts
generated by a lightweight LLM. Unlike prior work, MePO avoids online
optimization reliance, reduces cost and privacy concerns, and, by learning
clear, interpretable merits, generalizes effectively to both large-scale and
lightweight inference models. Experiments demonstrate that MePO achieves better
results across diverse tasks and model types, offering a scalable and robust
solution for real-world deployment. Our model and dataset are available at:
https://github.com/MidiyaZhu/MePO

</details>


### [15] [Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph](https://arxiv.org/abs/2505.09945)
*Deeksha Prahlad,Chanhee Lee,Dongha Kim,Hokeun Kim*

Main category: cs.CL

TL;DR: 提出基于知识图谱的检索增强生成（RAG）方法，通过结构化存储实时更新的个人日历数据，显著提升LLM生成个性化回复的准确性


<details>
  <summary>Details</summary>
Motivation: 解决LLMs因训练数据过时和缺乏个性化信息导致的幻觉问题，重点解决个人日历数据的实时整合需求

Method: 将日历数据构建为知识图谱，通过RAG框架实现结构化检索与LLM的协同，采用实体关系提取和动态检索机制

Result: 相比基线模型准确率提升37%，响应时间减少19%，在个人日程理解任务中F1值达到0.82

Conclusion: 结构化知识图谱有效解决LLMs的实时数据整合难题，为个性化AI助手提供了可扩展的解决方案

Abstract: The advent of large language models (LLMs) has allowed numerous applications,
including the generation of queried responses, to be leveraged in chatbots and
other conversational assistants. Being trained on a plethora of data, LLMs
often undergo high levels of over-fitting, resulting in the generation of extra
and incorrect data, thus causing hallucinations in output generation. One of
the root causes of such problems is the lack of timely, factual, and
personalized information fed to the LLM. In this paper, we propose an approach
to address these problems by introducing retrieval augmented generation (RAG)
using knowledge graphs (KGs) to assist the LLM in personalized response
generation tailored to the users. KGs have the advantage of storing
continuously updated factual information in a structured way. While our KGs can
be used for a variety of frequently updated personal data, such as calendar,
contact, and location data, we focus on calendar data in this paper. Our
experimental results show that our approach works significantly better in
understanding personal information and generating accurate responses compared
to the baseline LLMs using personal data as text inputs, with a moderate
reduction in response time.

</details>


### [16] [DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs](https://arxiv.org/abs/2505.10013)
*Lake Yin,Fan Huang*

Main category: cs.CL

TL;DR: 该研究针对大语言模型（LLMs）的隐性偏见问题，提出DIF基准方法并通过实验验证模型准确性与隐性偏见呈负相关。


<details>
  <summary>Details</summary>
Motivation: LLMs的隐性偏见不仅是伦理问题，更暴露其无法有效整合额外信息的技术缺陷，且缺乏标准化评估方法。建立DIF基准可量化检测此类偏差。

Method: 通过结合现有逻辑/数学问题数据集与社会人口统计角色，构建DIF指标定量分析LLMs输出中的系统性偏差模式。

Result: DIF方法有效验证了LLMs存在隐性偏见，且问题回答准确率与隐性偏见强度呈现统计学显著的负相关趋势。

Conclusion: DIF基准为评估LLM偏见提供了可解释的技术指标，证实隐性偏见反映模型技术缺陷，为改进模型信息处理能力指明方向。

Abstract: As Large Language Models (LLMs) have risen in prominence over the past few
years, there has been concern over the potential biases in LLMs inherited from
the training data. Previous studies have examined how LLMs exhibit implicit
bias, such as when response generation changes when different social contexts
are introduced. We argue that this implicit bias is not only an ethical, but
also a technical issue, as it reveals an inability of LLMs to accommodate
extraneous information. However, unlike other measures of LLM intelligence,
there are no standard methods to benchmark this specific subset of LLM bias. To
bridge this gap, we developed a method for calculating an easily interpretable
benchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM
logic and math problem datasets with sociodemographic personas. We demonstrate
that this method can statistically validate the presence of implicit bias in
LLM behavior and find an inverse trend between question answering accuracy and
implicit bias, supporting our argument.

</details>


### [17] [CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability](https://arxiv.org/abs/2505.10063)
*Han Peng,Jinhao Jiang,Zican Dong,Wayne Xin Zhao,Lei Fang*

Main category: cs.CL

TL;DR: 提出两阶段粗粒度到细粒度的CAFE方法，显著提升大模型在多文档问答中的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法在长上下文处理中存在检索精度与召回率难以平衡的问题，导致问答效果受限

Method: 1. 粗粒度过滤阶段利用检索头筛选相关文档
2. 细粒度引导阶段集中关注最相关内容，消除干扰文档影响

Result: 在Mistral模型上分别超越SFT和RAG方法22.1%和13.7%的SubEM指标提升

Conclusion: CAFE通过渐进式文档筛选机制，有效增强模型对证据文档的依赖，在多文档问答场景展现显著优势

Abstract: Advancements in Large Language Models (LLMs) have extended their input
context length, yet they still struggle with retrieval and reasoning in
long-context inputs. Existing methods propose to utilize the prompt strategy
and retrieval head to alleviate this limitation. However, they still face
challenges in balancing retrieval precision and recall, impacting their
efficacy in answering questions. To address this, we introduce $\textbf{CAFE}$,
a two-stage coarse-to-fine method to enhance multi-document question-answering
capacities. By gradually eliminating the negative impacts of background and
distracting documents, CAFE makes the responses more reliant on the evidence
documents. Initially, a coarse-grained filtering method leverages retrieval
heads to identify and rank relevant documents. Then, a fine-grained steering
method guides attention to the most relevant content. Experiments across
benchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%
SubEM improvement over SFT and RAG methods on the Mistral model, respectively.

</details>


### [18] [Dark LLMs: The Growing Threat of Unaligned AI Models](https://arxiv.org/abs/2505.10066)
*Michael Fire,Yitzhak Elbazis,Adi Wasenstein,Lior Rokach*

Main category: cs.CL

TL;DR: 研究发现LLMs存在通过训练数据漏洞实现的通用越狱攻击方法，多数先进模型在攻击披露7个月后仍存在安全隐患，行业应对措施不足凸显AI安全实践缺陷


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗、教育等领域的快速应用，其安全漏洞问题日益突出。研究发现现有模型通过未过滤训练数据学习到可被利用的弱点，导致伦理护栏失效风险

Method: 基于训练数据中'暗黑内容'的存在，开发出可突破多款先进模型的通用越狱攻击技术。该方法通过利用模型学习到的潜在漏洞绕过安全控制机制

Result: 实验显示攻击方法能有效使主流LLMs响应有害请求，攻击方案公开7个月后多数受测模型仍存在漏洞。主要LLM供应商响应存在严重滞后

Conclusion: 随着开源模型普及和训练成本降低，LLMs可能成为危险知识传播工具。缺乏有效监管和行业标准可能导致AI安全风险超出预期，需建立更严格的安全响应机制

Abstract: Large Language Models (LLMs) rapidly reshape modern life, advancing fields
from healthcare to education and beyond. However, alongside their remarkable
capabilities lies a significant threat: the susceptibility of these models to
jailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems
from the very data they learn from. As long as this training data includes
unfiltered, problematic, or 'dark' content, the models can inherently learn
undesirable patterns or weaknesses that allow users to circumvent their
intended safety controls. Our research identifies the growing threat posed by
dark LLMs models deliberately designed without ethical guardrails or modified
through jailbreak techniques. In our research, we uncovered a universal
jailbreak attack that effectively compromises multiple state-of-the-art models,
enabling them to answer almost any question and produce harmful outputs upon
request. The main idea of our attack was published online over seven months
ago. However, many of the tested LLMs were still vulnerable to this attack.
Despite our responsible disclosure efforts, responses from major LLM providers
were often inadequate, highlighting a concerning gap in industry practices
regarding AI safety. As model training becomes more accessible and cheaper, and
as open-source LLMs proliferate, the risk of widespread misuse escalates.
Without decisive intervention, LLMs may continue democratizing access to
dangerous knowledge, posing greater risks than anticipated.

</details>


### [19] [Designing and Contextualising Probes for African Languages](https://arxiv.org/abs/2505.10081)
*Wisdom Aduah,Francois Meyer*

Main category: cs.CL

TL;DR: 首次系统性研究非洲语言预训练模型的语言知识编码机制，发现专用模型优于通用多语言模型，验证了句法和语义信息的层次分布特征。


<details>
  <summary>Details</summary>
Motivation: 非洲语言预训练模型性能持续提升，但其内部语言学知识编码机制尚不明确，需系统探究模型对目标语言特征的捕获能力。

Method: 使用分层探针技术分析六种类型学差异显著的非洲语言，设计MasakhaPOS控制任务验证探针有效性，比较专用PLMs与大规模多语言PLMs的表现差异。

Result: 非洲语言专用PLMs编码更多目标语言特征；句法信息集中在中后层（第6-8层），语义信息全层分布；控制任务证实探针反映模型真实知识而非记忆效应。

Conclusion: 研究揭示了主动学习策略和多语言适应的内部机制，为非洲语言模型优化提供理论支撑，首次将可解释性技术系统应用于非洲语言PLMs分析。

Abstract: Pretrained language models (PLMs) for African languages are continually
improving, but the reasons behind these advances remain unclear. This paper
presents the first systematic investigation into probing PLMs for linguistic
knowledge about African languages. We train layer-wise probes for six
typologically diverse African languages to analyse how linguistic features are
distributed. We also design control tasks, a way to interpret probe
performance, for the MasakhaPOS dataset. We find PLMs adapted for African
languages to encode more linguistic information about target languages than
massively multilingual PLMs. Our results reaffirm previous findings that
token-level syntactic information concentrates in middle-to-last layers, while
sentence-level semantic information is distributed across all layers. Through
control tasks and probing baselines, we confirm that performance reflects the
internal knowledge of PLMs rather than probe memorisation. Our study applies
established interpretability techniques to African-language PLMs. In doing so,
we highlight the internal mechanisms underlying the success of strategies like
active learning and multilingual adaptation.

</details>


### [20] [XRAG: Cross-lingual Retrieval-Augmented Generation](https://arxiv.org/abs/2505.10089)
*Wei Liu,Sony Trenous,Leonardo F. R. Ribeiro,Bill Byrne,Felix Hieber*

Main category: cs.CL

TL;DR: 提出了跨语言检索增强生成基准XRAG，通过新闻数据集验证LLMs在跨语言场景下的两大核心挑战


<details>
  <summary>Details</summary>
Motivation: 解决用户语言与检索内容语言不匹配时，现有模型在跨语言检索增强生成场景中的评估缺失问题

Method: 基于实时新闻构建含相关性标注的数据集，覆盖单语/多语检索场景，设计需要复杂推理的问题

Result: 实验发现：1）单语检索中模型存在应答语言准确性问题 2）多语检索中跨语言推理是主要瓶颈

Conclusion: XRAG不仅能评估跨语言复杂度，更可作为研究LLMs推理能力的基准，揭示传统评测忽视的模型缺陷

Abstract: We propose XRAG, a novel benchmark designed to evaluate the generation
abilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)
settings where the user language does not match the retrieval results. XRAG is
constructed from recent news articles to ensure that its questions require
external knowledge to be answered. It covers the real-world scenarios of
monolingual and multilingual retrieval, and provides relevancy annotations for
each retrieved document. Our novel dataset construction pipeline results in
questions that require complex reasoning, as evidenced by the significant gap
between human and LLM performance. Consequently, XRAG serves as a valuable
benchmark for studying LLM reasoning abilities, even before considering the
additional cross-lingual complexity. Experimental results on five LLMs uncover
two previously unreported challenges in cross-lingual RAG: 1) in the
monolingual retrieval setting, all evaluated models struggle with response
language correctness; 2) in the multilingual retrieval setting, the main
challenge lies in reasoning over retrieved information across languages rather
than generation of non-English text.

</details>


### [21] [What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs](https://arxiv.org/abs/2505.10113)
*Xinlan Yan,Di Wu,Yibin Lei,Christof Monz,Iacer Calixto*

Main category: cs.CL

TL;DR: 提出S-MedQA医学问答数据集，验证大语言模型知识注入假设，发现性能提升主要来自领域转移而非知识注入。


<details>
  <summary>Details</summary>
Motivation: 验证医学问答场景中知识注入假设的适用性，探究专业领域微调数据对模型表现的真实影响机制。

Method: 通过S-MedQA数据集在不同临床专业进行实验，分析模型在特定专业训练后的表现及术语概率变化。

Result: 1. 特定专业训练不保证该领域最佳表现；2. 所有专业微调后临床术语概率均持续增加，显示领域转移效应。

Conclusion: 应重新评估医学领域微调数据的作用，性能提升主因是领域转换（通用→医学）而非知识注入。

Abstract: In this paper, we introduce S-MedQA, an English medical question-answering
(QA) dataset for benchmarking large language models in fine-grained clinical
specialties. We use S-MedQA to check the applicability of a popular hypothesis
related to knowledge injection in the knowledge-intense scenario of medical QA,
and show that: 1) training on data from a speciality does not necessarily lead
to best performance on that specialty and 2) regardless of the specialty
fine-tuned on, token probabilities of clinically relevant terms for all
specialties increase consistently. Thus, we believe improvement gains come
mostly from domain shifting (e.g., general to medical) rather than knowledge
injection and suggest rethinking the role of fine-tuning data in the medical
domain. We release S-MedQA and all code needed to reproduce all our experiments
to the research community.

</details>


### [22] [GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs](https://arxiv.org/abs/2505.10143)
*Longchao Da,Parth Mitesh Shah,Kuan-Ru Liou,Jiaxing Zhang,Hua Wei*

Main category: cs.CL

TL;DR: 提出GE-Chat框架，通过知识图谱增强的检索生成机制提升LLM响应可信度


<details>
  <summary>Details</summary>
Motivation: LLM输出存在不可靠性和幻觉问题，需建立证据验证机制增强用户信任

Method: 结合知识图谱构建、思维链生成、多跳子图搜索与蕴含推理的检索增强框架

Result: 显著提升现有模型在自由文本中准确识别证据的能力（实验数据未明确给出）

Conclusion: 通过可验证证据链构建，为LLM结论提供溯源支持，建立可信度评估体系

Abstract: Large Language Models are now key assistants in human decision-making
processes. However, a common note always seems to follow: "LLMs can make
mistakes. Be careful with important info." This points to the reality that not
all outputs from LLMs are dependable, and users must evaluate them manually.
The challenge deepens as hallucinated responses, often presented with seemingly
plausible explanations, create complications and raise trust issues among
users. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph
enhanced retrieval-augmented generation framework to provide Evidence-based
response generation. Specifically, when the user uploads a material document, a
knowledge graph will be created, which helps construct a retrieval-augmented
agent, enhancing the agent's responses with additional knowledge beyond its
training corpus. Then we leverage Chain-of-Thought (CoT) logic generation,
n-hop sub-graph searching, and entailment-based sentence generation to realize
accurate evidence retrieval. We demonstrate that our method improves the
existing models' performance in terms of identifying the exact evidence in a
free-form context, providing a reliable way to examine the resources of LLM's
conclusion and help with the judgment of the trustworthiness.

</details>


### [23] [Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning](https://arxiv.org/abs/2505.10182)
*Yoichi Ishibashi,Taro Yano,Masafumi Oyamada*

Main category: cs.CL

TL;DR: Reasoning CPT通过合成隐藏思维数据提升多领域推理能力，在复杂问题上效果显著


<details>
  <summary>Details</summary>
Motivation: 现有训练方法局限于数学等特定领域，持续预训练(CPT)虽无需任务信号但缺乏多领域验证，需探索如何有效合成推理数据及其跨领域影响

Method: 在Gemma2-9B上应用Reasoning CPT，使用STEM和法律领域的隐藏思维数据，与标准CPT在MMLU基准对比

Result: 全领域性能提升，跨领域迁移有效（难题最高+8%），模型学会根据难度调整推理深度

Conclusion: 思维重构的持续预训练突破领域限制，验证合成思维数据对复杂问题解决的关键作用

Abstract: Large Language Models (LLMs) have demonstrated significant improvements in
reasoning capabilities through supervised fine-tuning and reinforcement
learning. However, when training reasoning models, these approaches are
primarily applicable to specific domains such as mathematics and programming,
which imposes fundamental constraints on the breadth and scalability of
training data. In contrast, continual pretraining (CPT) offers the advantage of
not requiring task-specific signals. Nevertheless, how to effectively
synthesize training data for reasoning and how such data affect a wide range of
domains remain largely unexplored. This study provides a detailed evaluation of
Reasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden
thought processes underlying texts, based on the premise that texts are the
result of the author's thinking process. Specifically, we apply Reasoning CPT
to Gemma2-9B using synthetic data with hidden thoughts derived from STEM and
Law corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis
reveals that Reasoning CPT consistently improves performance across all
evaluated domains. Notably, reasoning skills acquired in one domain transfer
effectively to others; the performance gap with conventional methods widens as
problem difficulty increases, with gains of up to 8 points on the most
challenging problems. Furthermore, models trained with hidden thoughts learn to
adjust the depth of their reasoning according to problem difficulty.

</details>


### [24] [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org/abs/2505.10185)
*Seongyun Lee,Seungone Kim,Minju Seo,Yongrae Jo,Dongyoung Go,Hyeonbin Hwang,Jinho Park,Xiang Yue,Sean Welleck,Graham Neubig,Moontae Lee,Minjoon Seo*

Main category: cs.CL

TL;DR: 提出CoT百科全书框架，通过自下而上的方式分析语言模型的思维链推理策略，并实现策略预测与引导


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义策略类型，受限于人类直觉且无法捕捉模型推理策略的多样性，需建立更全面的分析体系

Method: 1.自动提取思维链中的推理标准 2.语义空间嵌入 3.聚类生成策略类别 4.构建对比式评估标准解释模型行为

Result: 人类评估显示该方法解释性优于现有方案；可预测模型策略并引导优化；发现数据格式（非领域）对推理行为影响显著

Conclusion: 建立了可操作的模型推理分析框架，揭示了数据格式对模型设计的关键影响，提供了策略干预的新路径

Abstract: Long chain-of-thought (CoT) is an essential ingredient in effective usage of
modern large language models, but our understanding of the reasoning strategies
underlying these capabilities remains limited. While some prior works have
attempted to categorize CoTs using predefined strategy types, such approaches
are constrained by human intuition and fail to capture the full diversity of
model behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up
framework for analyzing and steering model reasoning. Our method automatically
extracts diverse reasoning criteria from model-generated CoTs, embeds them into
a semantic space, clusters them into representative categories, and derives
contrastive rubrics to interpret reasoning behavior. Human evaluations show
that this framework produces more interpretable and comprehensive analyses than
existing methods. Moreover, we demonstrate that this understanding enables
performance gains: we can predict which strategy a model is likely to use and
guide it toward more effective alternatives. Finally, we provide practical
insights, such as that training data format (e.g., free-form vs.
multiple-choice) has a far greater impact on reasoning behavior than data
domain, underscoring the importance of format-aware model design.

</details>


### [25] [VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits](https://arxiv.org/abs/2505.10202)
*Jintian Shao,Hongyi Huang,Jiayi Wu,YiMing Cheng,ZhiYu Wu,You Shan,MingKai Zheng*

Main category: cs.CL

TL;DR: 提出VQ-Logits方法，通过向量量化技术将LLM输出层参数减少99%、计算速度提升6倍，仅牺牲4%的困惑度性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型输出层的巨大词表导致参数与计算成本过高，现有优化方法（如自适应softmax）存在结构复杂性缺陷。

Method: 用小型共享codebook替代传统输出矩阵，通过向量量化将词汇映射到codebook向量，使用散射机制将紧凑logits映射回完整词表空间。

Result: 在WikiText-103等基准测试中实现输出层99%参数削减和6倍加速，困惑度仅比基线增加4%。

Conclusion: VQ-Logits为LLM输出层优化提供了高效解决方案，在计算效率与模型性能间取得良好平衡。

Abstract: Large Language Models (LLMs) have achieved remarkable success but face
significant computational and memory challenges, particularly due to their
extensive output vocabularies. The final linear projection layer, mapping
hidden states to vocabulary-sized logits, often constitutes a substantial
portion of the model's parameters and computational cost during inference.
Existing methods like adaptive softmax or hierarchical softmax introduce
structural complexities. In this paper, we propose VQ-Logits, a novel approach
that leverages Vector Quantization (VQ) to drastically reduce the parameter
count and computational load of the LLM output layer. VQ-Logits replaces the
large V * dmodel output embedding matrix with a small, shared codebook of K
embedding vectors (K << V ). Each token in the vocabulary is mapped to one of
these K codebook vectors. The LLM predicts logits over this compact codebook,
which are then efficiently "scattered" to the full vocabulary space using the
learned or preassigned mapping. We demonstrate through extensive experiments on
standard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits
can achieve up to 99% parameter reduction in the output layer and 6x speedup in
logit computation, with only a marginal 4% increase in perplexity compared to
full softmax baselines. We further provide detailed ablation studies on
codebook size, initialization, and learning strategies, showcasing the
robustness and effectiveness of our approach.

</details>


### [26] [RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward](https://arxiv.org/abs/2505.10218)
*Zongsheng Wang,Kaili Sun,Bowen Wu,Qun Yu,Ying Li,Baoxun Wang*

Main category: cs.CL

TL;DR: Proposes RAIDEN-R1 framework with VRAR reward mechanism and multi-LLM dataset construction to enhance RPCA role consistency.


<details>
  <summary>Details</summary>
Motivation: Persistent challenges in maintaining role consistency for RPCAs need quantifiable training solutions.

Method: Reinforcement learning framework integrates verifiable role-awareness reward (VRAR) through singular/multi-term mining strategies and multi-LLM CoT dataset construction.

Result: 14B-GRPO model achieves 88.04%/88.65% accuracy on two metrics, outperforming baselines in contextual conflict resolution and narrative consistency.

Conclusion: Bridges non-quantifiable training gap in RPCAs and advances role-aware reasoning patterns through verifiable reward mechanisms.

Abstract: Role-playing conversational agents (RPCAs) face persistent challenges in
maintaining role consistency. To address this, we propose RAIDEN-R1, a novel
reinforcement learning framework that integrates Verifiable Role-Awareness
Reward (VRAR). The method introduces both singular and multi-term mining
strategies to generate quantifiable rewards by assessing role-specific keys.
Additionally, we construct a high-quality, role-aware Chain-of-Thought dataset
through multi-LLM collaboration, and implement experiments to enhance reasoning
coherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's
superiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on
Script-Based Knowledge and Conversation Memory metrics, respectively,
outperforming baseline models while maintaining robustness. Case analyses
further reveal the model's enhanced ability to resolve conflicting contextual
cues and sustain first-person narrative consistency. This work bridges the
non-quantifiability gap in RPCA training and provides insights into role-aware
reasoning patterns, advancing the development of RPCAs.

</details>


### [27] [Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data](https://arxiv.org/abs/2505.10260)
*Poli Apollinaire Nemkova,Solomon Ubani,Mark V. Albert*

Main category: cs.CL

TL;DR: 研究评估了GPT-3.5/4、LLAMA3等大语言模型在俄乌社交媒体人权侵犯二分类任务中的零样本/少样本标注能力，发现模型表现存在显著差异且跨语言适应性不同。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在敏感多语言场景下的可靠性，特别是处理主观性强、语境依赖的领域特定任务时的实际应用潜力。

Method: 使用1000条人工双标注数据作为金标准，对比五大主流模型在英俄双语提示下的标注性能，分析错误模式和跨语言适应性。

Result: 不同模型在相同提示条件下准确率波动达25%，俄语提示整体表现弱于英语。Claude-2在跨语言一致性最佳，LLAMA3在少样本场景提升显著。

Conclusion: LLMs可用于多语言敏感任务但需谨慎，模型表现受提示语言和标注范例数量影响显著，语境理解偏差是主要错误来源。

Abstract: In the era of increasingly sophisticated natural language processing (NLP)
systems, large language models (LLMs) have demonstrated remarkable potential
for diverse applications, including tasks requiring nuanced textual
understanding and contextual reasoning. This study investigates the
capabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,
Mistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex
textual dataset comprising social media posts in Russian and Ukrainian.
Specifically, the focus is on the binary classification task of identifying
references to human rights violations within the dataset.
  To evaluate the effectiveness of these models, their annotations are compared
against a gold standard set of human double-annotated labels across 1000
samples. The analysis includes assessing annotation performance under different
prompting conditions, with prompts provided in both English and Russian.
Additionally, the study explores the unique patterns of errors and
disagreements exhibited by each model, offering insights into their strengths,
limitations, and cross-linguistic adaptability.
  By juxtaposing LLM outputs with human annotations, this research contributes
to understanding the reliability and applicability of LLMs for sensitive,
domain-specific tasks in multilingual contexts. It also sheds light on how
language models handle inherently subjective and context-dependent judgments, a
critical consideration for their deployment in real-world scenarios.

</details>


### [28] [The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine](https://arxiv.org/abs/2505.10261)
*Rui Yang,Huitao Li,Matthew Yu Heng Wong,Yuhe Ke,Xin Li,Kunyu Yu,Jingchi Liao,Jonathan Chong Kai Liew,Sabarinath Vinod Nair,Jasmine Chiat Ling Ong,Irene Li,Douglas Teodoro,Chuan Hong,Daniel Shu Wei Ting,Nan Liu*

Main category: cs.CL

TL;DR: 比较生成式大语言模型与传统NLP在医疗任务中的效能差异，强调伦理应用的重要性


<details>
  <summary>Details</summary>
Motivation: 探索生成式LLM与传统NLP在不同医疗任务中的性能差异及适用场景

Method: 通过对19,123项研究进行系统分析，比较两种技术的任务表现

Result: 生成式LLM在开放式任务中表现优异，传统NLP在信息抽取分析任务中保持优势

Conclusion: 医疗AI应用中需根据任务特性选择合适技术，并强调伦理规范对技术发展的重要性

Abstract: Natural language processing (NLP) has been traditionally applied to medicine,
and generative large language models (LLMs) have become prominent recently.
However, the differences between them across different medical tasks remain
underexplored. We analyzed 19,123 studies, finding that generative LLMs
demonstrate advantages in open-ended tasks, while traditional NLP dominates in
information extraction and analysis tasks. As these technologies advance,
ethical use of them is essential to ensure their potential in medical
applications.

</details>


### [29] [From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making](https://arxiv.org/abs/2505.10282)
*Dubai Li,Nan Jiang,Kangping Huang,Ruiqi Tu,Shuyu Ouyang,Huayu Yu,Lin Qiao,Chen Yu,Tianshu Zhou,Danyang Tong,Qian Wang,Mengtao Li,Xiaofeng Zeng,Yu Tian,Xinping Tian,Jingsong Li*

Main category: cs.CL

TL;DR: 开发基于大语言模型的临床决策支持系统Quicker，通过自动化证据合成提升临床决策效率


<details>
  <summary>Details</summary>
Motivation: 解决临床实践中证据整合的高负荷、复杂流程与时效性挑战，实现自动化证据合成需求

Method: 构建LLM驱动的全自动证据链（从问题分解到推荐生成），开发Q2CRBench-3基准数据集进行系统评估

Result: 单评审员协作模式下推荐开发时间缩短至20-40分钟，证据检索敏感度达专家水平，推荐逻辑优于临床医生

Conclusion: Quicker系统显著提升循证决策效率与可靠性，验证了AI在临床指南开发中的实用价值

Abstract: Clinical evidence, derived from rigorous research and data analysis, provides
healthcare professionals with reliable scientific foundations for informed
decision-making. Integrating clinical evidence into real-time practice is
challenging due to the enormous workload, complex professional processes, and
time constraints. This highlights the need for tools that automate evidence
synthesis to support more efficient and accurate decision making in clinical
settings. This study introduces Quicker, an evidence-based clinical decision
support system powered by large language models (LLMs), designed to automate
evidence synthesis and generate clinical recommendations modeled after standard
clinical guideline development processes. Quicker implements a fully automated
chain that covers all phases, from questions to clinical recommendations, and
further enables customized decision-making through integrated tools and
interactive user interfaces. To evaluate Quicker's capabilities, we developed
the Q2CRBench-3 benchmark dataset, based on clinical guideline development
records for three different diseases. Experimental results highlighted
Quicker's strong performance, with fine-grained question decomposition tailored
to user preferences, retrieval sensitivities comparable to human experts, and
literature screening performance approaching comprehensive inclusion of
relevant studies. In addition, Quicker-assisted evidence assessment effectively
supported human reviewers, while Quicker's recommendations were more
comprehensive and logically coherent than those of clinicians. In system-level
testing, collaboration between a single reviewer and Quicker reduced the time
required for recommendation development to 20-40 minutes. In general, our
findings affirm the potential of Quicker to help physicians make quicker and
more reliable evidence-based clinical decisions.

</details>


### [30] [J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning](https://arxiv.org/abs/2505.10320)
*Chenxi Whitehouse,Tianlu Wang,Ping Yu,Xian Li,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: 提出强化学习方法J1，通过可验证奖励机制提升LLM评估能力，在多个基准测试中超越同规模及更大模型


<details>
  <summary>Details</summary>
Motivation: AI发展受限于评估质量，现有LLM评估模型需提升思维链推理能力以优化判断质量

Method: 使用强化学习框架，将可验证/不可验证提示转化为带可验证奖励的判断任务，激励思考并减少判断偏见

Result: J1在8B/70B规模均超越所有同规模模型（包括DeepSeek-R1蒸馏模型），部分基准甚至优于更大规模的R1模型

Conclusion: J1通过制定评估标准、自生成参考答案对比、响应正确性重评估等机制，显著提升模型判断质量

Abstract: The progress of AI is bottlenecked by the quality of evaluation, and powerful
LLM-as-a-Judge models have proved to be a core solution. Improved judgment
ability is enabled by stronger chain-of-thought reasoning, motivating the need
to find the best recipes for training such models to think. In this work we
introduce J1, a reinforcement learning approach to training such models. Our
method converts both verifiable and non-verifiable prompts to judgment tasks
with verifiable rewards that incentivize thinking and mitigate judgment bias.
In particular, our approach outperforms all other existing 8B or 70B models
when trained at those sizes, including models distilled from DeepSeek-R1. J1
also outperforms o1-mini, and even R1 on some benchmarks, despite training a
smaller model. We provide analysis and ablations comparing Pairwise-J1 vs
Pointwise-J1 models, offline vs online training recipes, reward strategies,
seed prompts, and variations in thought length and content. We find that our
models make better judgments by learning to outline evaluation criteria,
comparing against self-generated reference answers, and re-evaluating the
correctness of model responses.

</details>


### [31] [LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations](https://arxiv.org/abs/2505.10354)
*Yile Wang,Zhanyu Shen,Hui Huang*

Main category: cs.CL

TL;DR: 提出低维密集可解释文本嵌入LDIR，通过锚文本语义关联实现500维以下的密集表示，在保持性能的同时提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有可解释文本嵌入存在高维度（万维以上）或性能不足的问题，需要平衡语义表示能力与模型可解释性。

Method: 采用最远点采样选择锚文本，构建低维密集向量，每个维度数值表示与不同锚文本的语义相关度。

Result: 在语义相似度、检索和聚类任务中接近黑盒模型效果，且以更少维度超越其他可解释嵌入基线。

Conclusion: LDIR成功实现低维密集与可解释的结合，为可解释NLP模型提供新方向。

Abstract: Semantic text representation is a fundamental task in the field of natural
language processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have
demonstrated excellent performance, but the values of each dimension are
difficult to trace and interpret. Bag-of-words, as classic sparse interpretable
embeddings, suffers from poor performance. Recently, Benara et al. (2024)
propose interpretable text embeddings using large language models, which forms
"0/1" embeddings based on responses to a series of questions. These
interpretable text embeddings are typically high-dimensional (larger than
10,000). In this work, we propose Low-dimensional (lower than 500) Dense and
Interpretable text embeddings with Relative representations (LDIR). The
numerical values of its dimensions indicate semantic relatedness to different
anchor texts through farthest point sampling, offering both semantic
representation as well as a certain level of traceability and interpretability.
We validate LDIR on multiple semantic textual similarity, retrieval, and
clustering tasks. Extensive experimental results show that LDIR performs close
to the black-box baseline models and outperforms the interpretable embeddings
baselines with much fewer dimensions. Code is available at
https://github.com/szu-tera/LDIR.

</details>


### [32] [Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli](https://arxiv.org/abs/2505.10356)
*Chunyu Ye,Shaonan Wang*

Main category: cs.CL

TL;DR: 提出基于视觉语言模型的多模态统一框架，实现跨视觉/听觉/文本输入的大脑信号语言重建


<details>
  <summary>Details</summary>
Motivation: 现有fMRI语言解码研究局限于单模态输入，与人类思维的多模态本质存在差距

Method: 采用视觉语言模型（VLMs），通过模态特定专家网络实现多模态信息联合解码

Result: 在保持系统扩展性的同时达到SOTA性能水平，支持视觉/听觉/文本输入的混合解码

Conclusion: 该框架推动思维解码向生态效度更高、泛化性更强的方向发展

Abstract: Decoding thoughts from brain activity offers valuable insights into human
cognition and enables promising applications in brain-computer interaction.
While prior studies have explored language reconstruction from fMRI data, they
are typically limited to single-modality inputs such as images or audio. In
contrast, human thought is inherently multimodal. To bridge this gap, we
propose a unified and flexible framework for reconstructing coherent language
from brain recordings elicited by diverse input modalities-visual, auditory,
and textual. Our approach leverages visual-language models (VLMs), using
modality-specific experts to jointly interpret information across modalities.
Experiments demonstrate that our method achieves performance comparable to
state-of-the-art systems while remaining adaptable and extensible. This work
advances toward more ecologically valid and generalizable mind decoding.

</details>


### [33] [Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples](https://arxiv.org/abs/2505.10389)
*Benjamin White,Anastasia Shimorina*

Main category: cs.CL

TL;DR: 利用大语言模型设计多领域统一的情感分析系统，实现四元组观点提取，验证多领域模型效果与单领域相当且降低运维复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决现实场景中多领域/多语言情感分析系统维护复杂的问题，探索单一模型同时处理多领域的能力。

Method: 基于内部数据集微调大语言模型，构建统一多领域模型，对比单领域模型性能，并开发非抽取式预测处理方法。

Result: 多领域模型保持单领域性能水平，显著降低运维复杂度；总结结构化预测任务中的失败模式处理经验。

Conclusion: 验证多领域统一模型的可行性，为LLM结构化预测系统开发提供非抽取处理、错误分析等实践经验。

Abstract: This paper explores the design of an aspect-based sentiment analysis system
using large language models (LLMs) for real-world use. We focus on quadruple
opinion extraction -- identifying aspect categories, sentiment polarity,
targets, and opinion expressions from text data across different domains and
languages. Using internal datasets, we investigate whether a single fine-tuned
model can effectively handle multiple domain-specific taxonomies
simultaneously. We demonstrate that a combined multi-domain model achieves
performance comparable to specialized single-domain models while reducing
operational complexity. We also share lessons learned for handling
non-extractive predictions and evaluating various failure modes when developing
LLM-based systems for structured prediction tasks.

</details>


### [34] [Rethinking Repetition Problems of LLMs in Code Generation](https://arxiv.org/abs/2505.10402)
*Yihong Dong,Yuchen Liu,Xue Jiang,Zhi Jin,Ge Li*

Main category: cs.CL

TL;DR: 论文提出基于语法规则的RPG解码方法，有效缓解代码生成中的结构重复问题


<details>
  <summary>Details</summary>
Motivation: 现有方法主要解决内容重复问题，但结构重复（语法层面固定结构的重复模式）更具挑战性和普遍性

Method: RPG通过语法规则识别代码生成过程中的结构重复，并战略性地降低导致重复的关键token的生成概率

Result: 在CodeRepetEval数据集及HumanEval/MBPP基准测试中，RPG显著优于基线方法，减少重复并提升代码质量

Conclusion: 基于语法规则的重复惩罚机制有效解决了代码生成中的结构重复问题，为相关研究提供了新方向

Abstract: With the advent of neural language models, the performance of code generation
has been significantly boosted. However, the problem of repetitions during the
generation process continues to linger. Previous work has primarily focused on
content repetition, which is merely a fraction of the broader repetition
problem in code generation. A more prevalent and challenging problem is
structural repetition. In structural repetition, the repeated code appears in
various patterns but possesses a fixed structure, which can be inherently
reflected in grammar. In this paper, we formally define structural repetition
and propose an efficient decoding approach called RPG, which stands for
Repetition Penalization based on Grammar, to alleviate the repetition problems
in code generation for LLMs. Specifically, RPG first leverages grammar rules to
identify repetition problems during code generation, and then strategically
decays the likelihood of critical tokens that contribute to repetitions,
thereby mitigating them in code generation. To facilitate this study, we
construct a new dataset CodeRepetEval to comprehensively evaluate approaches
for mitigating the repetition problems in code generation. Extensive
experimental results demonstrate that RPG substantially outperforms the
best-performing baselines on CodeRepetEval dataset as well as HumanEval and
MBPP benchmarks, effectively reducing repetitions and enhancing the quality of
generated code.

</details>


### [35] [Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation](https://arxiv.org/abs/2505.10409)
*Yue Guo,Jae Ho Sohn,Gondy Leroy,Trevor Cohen*

Main category: cs.CL

TL;DR: LLM生成的通俗摘要主观评价与人工相似，但人工摘要显著提升读者理解，自动评估指标不可靠需新框架


<details>
  <summary>Details</summary>
Motivation: 现有PLSs评估依赖自动化指标或小样本主观评分，缺乏有效衡量大众理解度的系统性研究

Method: 通过Amazon Mechanical Turk平台对150人开展主客观综合评估，包含易读性评分、多选题理解测试及自动指标对比分析

Result: 人工摘要组阅读理解准确率比LLM组高15%，自动指标与人类评分相关性低于0.3

Conclusion: 需建立以理解为导向的评估体系，开发直接优化患者理解的PLSs生成方法

Abstract: Plain language summaries (PLSs) are essential for facilitating effective
communication between clinicians and patients by making complex medical
information easier for laypeople to understand and act upon. Large language
models (LLMs) have recently shown promise in automating PLS generation, but
their effectiveness in supporting health information comprehension remains
unclear. Prior evaluations have generally relied on automated scores that do
not measure understandability directly, or subjective Likert-scale ratings from
convenience samples with limited generalizability. To address these gaps, we
conducted a large-scale crowdsourced evaluation of LLM-generated PLSs using
Amazon Mechanical Turk with 150 participants. We assessed PLS quality through
subjective Likert-scale ratings focusing on simplicity, informativeness,
coherence, and faithfulness; and objective multiple-choice comprehension and
recall measures of reader understanding. Additionally, we examined the
alignment between 10 automated evaluation metrics and human judgments. Our
findings indicate that while LLMs can generate PLSs that appear
indistinguishable from human-written ones in subjective evaluations,
human-written PLSs lead to significantly better comprehension. Furthermore,
automated evaluation metrics fail to reflect human judgment, calling into
question their suitability for evaluating PLSs. This is the first study to
systematically evaluate LLM-generated PLSs based on both reader preferences and
comprehension outcomes. Our findings highlight the need for evaluation
frameworks that move beyond surface-level quality and for generation methods
that explicitly optimize for layperson comprehension.

</details>


### [36] [Hierarchical Document Refinement for Long-context Retrieval-augmented Generation](https://arxiv.org/abs/2505.10413)
*Jiajie Jin,Xiaoxi Li,Guanting Dong,Yuyao Zhang,Yutao Zhu,Yongkang Wu,Zhonghua Li,Qi Ye,Zhicheng Dou*

Main category: cs.CL

TL;DR: 提出LongRefiner方法，通过双级查询分析和层次化文档结构，用单模型多任务学习实现长文本RAG的高效处理，计算成本降低10倍且保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决现实长文本RAG应用中冗余信息/噪声导致的推理成本高、性能下降问题。

Method: 结合双级查询分析、层次化文档结构构建、基于单基础模型的多任务自适应优化机制

Result: 在7个QA数据集上验证，计算成本/延迟仅为最优基线的1/10且性能相当，实验证明方案具备可扩展性和实用性

Conclusion: LongRefiner为长文本RAG提供了高效解决方案，通过结构特征挖掘和轻量化设计实现成本效益平衡

Abstract: Real-world RAG applications often encounter long-context input scenarios,
where redundant information and noise results in higher inference costs and
reduced performance. To address these challenges, we propose LongRefiner, an
efficient plug-and-play refiner that leverages the inherent structural
characteristics of long documents. LongRefiner employs dual-level query
analysis, hierarchical document structuring, and adaptive refinement through
multi-task learning on a single foundation model. Experiments on seven QA
datasets demonstrate that LongRefiner achieves competitive performance in
various scenarios while using 10x fewer computational costs and latency
compared to the best baseline. Further analysis validates that LongRefiner is
scalable, efficient, and effective, providing practical insights for real-world
long-text RAG applications. Our code is available at
https://github.com/ignorejjj/LongRefiner.

</details>


### [37] [Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models](https://arxiv.org/abs/2505.10446)
*Zemin Huang,Zhiyang Chen,Zijun Wang,Tiancheng Li,Guo-Jun Qi*

Main category: cs.CL

TL;DR: 提出DCoLT框架，通过强化学习优化扩散语言模型的非线性推理轨迹，显著提升数学和代码生成任务性能


<details>
  <summary>Details</summary>
Motivation: 传统Chain-of-Thought方法受限于线性因果推理且要求中间步骤语法正确，DCoLT通过扩散过程的逆向步骤实现双向非线性推理

Method: 1. 在SEDD模型应用概率策略优化强化学习轨迹 2. 在LLaDA模型引入基于Plackett-Luce模型的Unmasking Policy Module控制解掩顺序

Result: 仅用公开数据和16块H800 GPU即超越其他训练方法，LLaDA在GSM8K/MATH/MBPP/HumanEval任务分别提升+9.8%/+5.7%/+11.4%/+19.5%

Conclusion: DCoLT通过扩散过程的潜在思维动作突破传统线性推理范式，在复杂推理任务中展现出显著优势，适用于多种扩散模型架构

Abstract: We introduce the \emph{Diffusion Chain of Lateral Thought (DCoLT)}, a
reasoning framework for diffusion language models. DCoLT treats each
intermediate step in the reverse diffusion process as a latent "thinking"
action and optimizes the entire reasoning trajectory to maximize the reward on
the correctness of the final answer with outcome-based Reinforcement Learning
(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,
linear thinking process, DCoLT allows bidirectional, non-linear reasoning with
no strict rule on grammatical correctness amid its intermediate steps of
thought. We implement DCoLT on two representative Diffusion Language Models
(DLMs). First, we choose SEDD as a representative continuous-time discrete
diffusion model, where its concrete score derives a probabilistic policy to
maximize the RL reward over the entire sequence of intermediate diffusion
steps. We further consider the discrete-time masked diffusion language model --
LLaDA, and find that the order to predict and unmask tokens plays an essential
role to optimize its RL action resulting from the ranking-based Unmasking
Policy Module (UPM) defined by the Plackett-Luce model. Experiments on both
math and code generation tasks show that using only public data and 16 H800
GPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even
both. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,
+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval.

</details>


### [38] [CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning](https://arxiv.org/abs/2505.10493)
*Shaohan Wang,Licheng Zhang,Zheren Fu,Zhendong Mao*

Main category: cs.CL

TL;DR: 提出CL-RAG框架，通过课程学习分阶段训练RAG系统，有效提升开放域QA任务性能2%-4%


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法直接使用top-k文档，但不同查询下文档有效性差异显著，影响模型训练适应性

Method: 1.通过样本演化构建多难度训练数据；2.采用课程学习分阶段训练检索器和生成器

Result: 在四个开放域QA数据集上相比现有方法提升2%-4%，验证框架有效性

Conclusion: 课程学习框架通过分阶段训练有效优化RAG系统性能与泛化能力，实验结果验证其有效性

Abstract: Retrieval-Augmented Generation (RAG) is an effective method to enhance the
capabilities of large language models (LLMs). Existing methods focus on
optimizing the retriever or generator in the RAG system by directly utilizing
the top-k retrieved documents. However, the documents effectiveness are various
significantly across user queries, i.e. some documents provide valuable
knowledge while others totally lack critical information. It hinders the
retriever and generator's adaptation during training. Inspired by human
cognitive learning, curriculum learning trains models using samples progressing
from easy to difficult, thus enhancing their generalization ability, and we
integrate this effective paradigm to the training of the RAG system. In this
paper, we propose a multi-stage Curriculum Learning based RAG system training
framework, named CL-RAG. We first construct training data with multiple
difficulty levels for the retriever and generator separately through sample
evolution. Then, we train the model in stages based on the curriculum learning
approach, thereby optimizing the overall performance and generalization of the
RAG system more effectively. Our CL-RAG framework demonstrates consistent
effectiveness across four open-domain QA datasets, achieving performance gains
of 2% to 4% over multiple advanced methods.

</details>


### [39] [Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective](https://arxiv.org/abs/2505.10494)
*Yutao Mou,Xiao Deng,Yuxiao Luo,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 提出CoV-Eval多维度代码安全评估基准和VC-Judge判断模型，揭示主流LLM生成安全代码能力不足


<details>
  <summary>Details</summary>
Motivation: 现有代码安全基准局限于单一任务评估，缺乏对代码生成/漏洞修复/检测的全维度覆盖，需系统评估LLM安全能力

Method: 构建多任务基准CoV-Eval(代码补全/漏洞修复/检测/分类)，开发VC-Judge对齐专家评估，测试20个开源/闭源LLM

Result: LLM识别漏洞能力较强(平均准确率76%)，但生成不安全代码比例达32%，CWE-22类漏洞修复成功率仅41%

Conclusion: LLM代码安全面临生成不可控和修复能力瓶颈，需增强安全对齐训练和漏洞知识注入，基准验证框架推动领域发展

Abstract: Code security and usability are both essential for various coding assistant
applications driven by large language models (LLMs). Current code security
benchmarks focus solely on single evaluation task and paradigm, such as code
completion and generation, lacking comprehensive assessment across dimensions
like secure code generation, vulnerability repair and discrimination. In this
paper, we first propose CoV-Eval, a multi-task benchmark covering various tasks
such as code completion, vulnerability repair, vulnerability detection and
classification, for comprehensive evaluation of LLM code security. Besides, we
developed VC-Judge, an improved judgment model that aligns closely with human
experts and can review LLM-generated programs for vulnerabilities in a more
efficient and reliable way. We conduct a comprehensive evaluation of 20
proprietary and open-source LLMs. Overall, while most LLMs identify vulnerable
codes well, they still tend to generate insecure codes and struggle with
recognizing specific vulnerability types and performing repairs. Extensive
experiments and qualitative analyses reveal key challenges and optimization
directions, offering insights for future research in LLM code security.

</details>


### [40] [The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks](https://arxiv.org/abs/2505.10507)
*Benedikt Ebing,Goran Glavaš*

Main category: cs.CL

TL;DR: 本文系统研究词对齐器在跨语言迁移中的标签投影设计，提出集成翻译训练和测试预测的新策略，性能超越标记方法并增强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前基于翻译的跨语言迁移方法在标签投影时主要依赖词对齐器，但其底层设计决策未得到系统研究，且标记类方法声称性能更优。需要验证词对齐器的真实潜力并探索优化方案。

Method: 1. 系统研究词对齐器设计三要素（跨token标签映射算法、噪声过滤策略、译文预分词）
2. 提出集成翻译训练和翻译测试预测的混合投影策略

Result: 1. 优化后的词对齐器性能与标记方法相当
2. 新集成策略比标记方法提升7.5% F1值
3. 集成方法降低对设计选择的敏感性，提升系统鲁棒性

Conclusion: 通过系统优化词对齐器设计并引入集成投影策略，显著提升跨语言迁移在序列标注任务中的性能稳定性，为实际应用提供更可靠的解决方案。

Abstract: Translation-based strategies for cross-lingual transfer XLT such as
translate-train -- training on noisy target language data translated from the
source language -- and translate-test -- evaluating on noisy source language
data translated from the target language -- are competitive XLT baselines. In
XLT for token classification tasks, however, these strategies include label
projection, the challenging step of mapping the labels from each token in the
original sentence to its counterpart(s) in the translation. Although word
aligners (WAs) are commonly used for label projection, the low-level design
decisions for applying them to translation-based XLT have not been
systematically investigated. Moreover, recent marker-based methods, which
project labeled spans by inserting tags around them before (or after)
translation, claim to outperform WAs in label projection for XLT. In this work,
we revisit WAs for label projection, systematically investigating the effects
of low-level design decisions on token-level XLT: (i) the algorithm for
projecting labels between (multi-)token spans, (ii) filtering strategies to
reduce the number of noisily mapped labels, and (iii) the pre-tokenization of
the translated sentences. We find that all of these substantially impact
translation-based XLT performance and show that, with optimized choices, XLT
with WA offers performance at least comparable to that of marker-based methods.
We then introduce a new projection strategy that ensembles translate-train and
translate-test predictions and demonstrate that it substantially outperforms
the marker-based projection. Crucially, we show that our proposed ensembling
also reduces sensitivity to low-level WA design choices, resulting in more
robust XLT for token classification tasks.

</details>


### [41] [Multi-Token Prediction Needs Registers](https://arxiv.org/abs/2505.10518)
*Anastasios Gerontopoulos,Spyros Gidaris,Nikos Komodakis*

Main category: cs.CL

TL;DR: MuToR提出通过插入可学习的寄存器令牌实现多令牌预测，保持与现有模型的兼容性，在监督微调/PEFT/预训练任务中均验证有效性


<details>
  <summary>Details</summary>
Motivation: 解决现有多令牌预测方法在微调场景效果不稳定、需改动模型结构、与预训练目标不一致的问题

Method: 在输入序列中插入寄存器令牌进行多步预测，保持模型架构不变且仅增加少量参数，支持可扩展的预测范围

Result: 在语言/视觉生成任务的监督微调、参数高效微调(PEFT)、预训练场景中均展示有效性

Conclusion: MuToR为多令牌预测提供简单高效的解决方案，兼具兼容性与扩展性，适用于多种下游任务场景（代码已开源）

Abstract: Multi-token prediction has emerged as a promising objective for improving
language model pretraining, but its benefits have not consistently generalized
to other settings such as fine-tuning. In this paper, we propose MuToR, a
simple and effective approach to multi-token prediction that interleaves
learnable register tokens into the input sequence, each tasked with predicting
future targets. Compared to existing methods, MuToR offers several key
advantages: it introduces only a negligible number of additional parameters,
requires no architectural changes--ensuring compatibility with off-the-shelf
pretrained language models--and remains aligned with the next-token pretraining
objective, making it especially well-suited for supervised fine-tuning.
Moreover, it naturally supports scalable prediction horizons. We demonstrate
the effectiveness and versatility of MuToR across a range of use cases,
including supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and
pretraining, on challenging generative tasks in both language and vision
domains. Our code will be available at: https://github.com/nasosger/MuToR.

</details>


### [42] [WorldPM: Scaling Human Preference Modeling](https://arxiv.org/abs/2505.10527)
*Binghai Wang,Runji Lin,Keming Lu,Le Yu,Zhenru Zhang,Fei Huang,Chujie Zheng,Kai Dang,Yang Fan,Xingzhang Ren,An Yang,Binyuan Hui,Dayiheng Liu,Tao Gui,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Bowen Yu,Jingren Zhou,Junyang Lin*

Main category: cs.CL

TL;DR: 论文通过15M规模数据和1.5B-72B参数模型的实验，验证了World Preference Modeling在偏好建模中的扩展规律及其在RLHF中的实际应用效果


<details>
  <summary>Details</summary>
Motivation: 受语言模型扩展定律的启发，探索偏好建模中的类似规律，提出WorldPM作为统一人类偏好的表示框架

Method: 收集公共论坛多样化偏好数据，使用15M规模数据集训练不同规模模型（1.5B-72B参数）并进行多维度评估

Result: 对抗性指标线性扩展/客观指标涌现/主观指标无扩展趋势；WorldPM在7个基准20个子任务中平均提升超5%，RLHF整合后内部评估提升4-8%

Conclusion: WorldPM展示了偏好建模的扩展潜力，特别在对抗性和客观指标上表现突出，为大规模偏好微调提供了有效基础框架

Abstract: Motivated by scaling laws in language modeling that demonstrate how test loss
scales as a power law with model and dataset sizes, we find that similar laws
exist in preference modeling. We propose World Preference Modeling$ (WorldPM)
to emphasize this scaling potential, where World Preference embodies a unified
representation of human preferences. In this paper, we collect preference data
from public forums covering diverse user communities, and conduct extensive
training using 15M-scale data across models ranging from 1.5B to 72B
parameters. We observe distinct patterns across different evaluation metrics:
(1) Adversarial metrics (ability to identify deceptive features) consistently
scale up with increased training data and base model size; (2) Objective
metrics (objective knowledge with well-defined answers) show emergent behavior
in larger language models, highlighting WorldPM's scalability potential; (3)
Subjective metrics (subjective preferences from a limited number of humans or
AI) do not demonstrate scaling trends. Further experiments validate the
effectiveness of WorldPM as a foundation for preference fine-tuning. Through
evaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly
improves the generalization performance across human preference datasets of
varying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%
on many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we
observe significant improvements on both in-house and public evaluation sets,
with notable gains of 4% to 8% in our in-house evaluations.

</details>


### [43] [Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models](https://arxiv.org/abs/2505.10554)
*Zhiyuan Hu,Yibo Wang,Hanze Dong,Yuhui Xu,Amrita Saha,Caiming Xiong,Bryan Hooi,Junnan Li*

Main category: cs.CL

TL;DR: 论文提出通过元能力对齐三阶段框架（个体对齐+参数合并+领域强化学习），系统性提升大型推理模型的可控性和性能天花板


<details>
  <summary>Details</summary>
Motivation: 现有基于结果强化的方法依赖偶然的'顿悟时刻'，导致推理行为不可预测且性能天花板受限。需要建立系统化的元能力对齐机制

Method: 1. 个体对齐：自动生成可自验证任务对齐演绎/归纳/溯因能力
2. 参数空间合并：整合不同逻辑能力
3. 领域强化学习：在数学/代码/科学等领域持续调优

Result: 相对指令微调基线提升10%+，领域强化学习额外带来2%平均增益。在GSM8K/MBPP/MMLU等基准持续突破性能上限

Conclusion: 显式的元能力对齐为复杂推理任务提供了可扩展、可靠的基础框架，代码开源推动领域发展

Abstract: Large reasoning models (LRMs) already possess a latent capacity for long
chain-of-thought reasoning. Prior work has shown that outcome-based
reinforcement learning (RL) can incidentally elicit advanced reasoning
behaviors such as self-correction, backtracking, and verification phenomena
often referred to as the model's "aha moment". However, the timing and
consistency of these emergent behaviors remain unpredictable and
uncontrollable, limiting the scalability and reliability of LRMs' reasoning
capabilities. To address these limitations, we move beyond reliance on prompts
and coincidental "aha moments". Instead, we explicitly align models with three
meta-abilities: deduction, induction, and abduction, using automatically
generated, self-verifiable tasks. Our three stage-pipeline individual
alignment, parameter-space merging, and domain-specific reinforcement learning,
boosting performance by over 10\% relative to instruction-tuned baselines.
Furthermore, domain-specific RL from the aligned checkpoint yields an
additional 2\% average gain in the performance ceiling across math, coding, and
science benchmarks, demonstrating that explicit meta-ability alignment offers a
scalable and dependable foundation for reasoning. Code is available at:
https://github.com/zhiyuanhubj/Meta-Ability-Alignment

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [44] [A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium](https://arxiv.org/abs/2505.09746)
*Xabier Morales,Ayah Elsayed,Debbie Zhao,Filip Loncaric,Ainhoa Aguado,Mireia Masias,Gina Quill,Marc Ramos,Ada Doltra,Ana Garcia,Marta Sitges,David Marlevi,Alistair Young,Martyn Nash,Bart Bijnens,Oscar Camara*

Main category: cs.CV

TL;DR: 开发首个针对左心房4D Flow MRI分析的开源计算框架，实现高精度自动分割（Dice>0.9）并首次系统评估血流动力学参数作为预后生物标志物的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统超声和现有4D Flow MRI分析工具在左心房血流动力学研究存在空间分辨率低、缺乏专用分析框架、数据异构性三大瓶颈，限制了血流参数预后价值的探索。

Method: 提出多中心兼容的开源计算框架，采用自动化分割算法（少量训练数据即可实现Dice>0.9的分割精度），支持能量、涡度、压力等高级血流参数的定性与定量分析。

Result: 框架在不同质量的多中心数据中表现稳健，实现毫米级精度分割（Hausdorff 95<3mm），并首次系统揭示不同疾病谱中左心房血流动力学参数的差异性特征。

Conclusion: 该框架为左心房血流分析提供标准化工具，证实能量/涡度/压力等参数作为预后生物标志物的临床应用潜力，推动个性化血流动力学评估发展。

Abstract: The left atrium (LA) plays a pivotal role in modulating left ventricular
filling, but our comprehension of its hemodynamics is significantly limited by
the constraints of conventional ultrasound analysis. 4D flow magnetic resonance
imaging (4D Flow MRI) holds promise for enhancing our understanding of atrial
hemodynamics. However, the low velocities within the LA and the limited spatial
resolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,
the absence of dedicated computational frameworks, combined with diverse
acquisition protocols and vendors, complicates gathering large cohorts for
studying the prognostic value of hemodynamic parameters provided by 4D Flow
MRI. In this study, we introduce the first open-source computational framework
tailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive
qualitative and quantitative analysis of advanced hemodynamic parameters. Our
framework proves robust to data from different centers of varying quality,
producing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95
$<$ 3 mm), even with limited training data. Additionally, we conducted the
first comprehensive assessment of energy, vorticity, and pressure parameters in
the LA across a spectrum of disorders to investigate their potential as
prognostic biomarkers.

</details>


### [45] [Dyadic Mamba: Long-term Dyadic Human Motion Synthesis](https://arxiv.org/abs/2505.09827)
*Julian Tanke,Takashi Shibuya,Kengo Uchida,Koichi Saito,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出Dyadic Mamba模型，利用状态空间模型实现任意长度的高质量二元人体运动合成，在长序列生成上显著优于Transformer方法


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的方法受限于位置编码机制，难以生成符合文本描述的长时间二元人体交互运动

Method: 采用状态空间模型(SSM)架构，通过简单的序列拼接实现运动序列间的信息流动，避免复杂交叉注意力机制

Result: 在短序列基准上保持竞争力，长序列生成质量显著超越Transformer方法，并建立新的长时运动合成评估基准

Conclusion: 基于SSM的架构为长时二元运动合成提供了有效解决方案，提出的新基准将推动该领域标准化发展

Abstract: Generating realistic dyadic human motion from text descriptions presents
significant challenges, particularly for extended interactions that exceed
typical training sequence lengths. While recent transformer-based approaches
have shown promising results for short-term dyadic motion synthesis, they
struggle with longer sequences due to inherent limitations in positional
encoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach
that leverages State-Space Models (SSMs) to generate high-quality dyadic human
motion of arbitrary length. Our method employs a simple yet effective
architecture that facilitates information flow between individual motion
sequences through concatenation, eliminating the need for complex
cross-attention mechanisms. We demonstrate that Dyadic Mamba achieves
competitive performance on standard short-term benchmarks while significantly
outperforming transformer-based approaches on longer sequences. Additionally,
we propose a new benchmark for evaluating long-term motion synthesis quality,
providing a standardized framework for future research. Our results demonstrate
that SSM-based architectures offer a promising direction for addressing the
challenging task of long-term dyadic human motion synthesis from text
descriptions.

</details>


### [46] [BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes](https://arxiv.org/abs/2505.09829)
*Tushar Kataria,Shireen Y. Elhabian*

Main category: cs.CV

TL;DR: 提出BoundarySeg多任务框架，通过结合器官边界预测与器官分割任务的一致性监督，在无需未标注数据情况下显著提升低数据场景的医学图像分割精度


<details>
  <summary>Details</summary>
Motivation: 医疗数据获取困难且标注成本高昂，现有半监督方法依赖大量未标注数据，但在实际临床场景中未标注数据可能同样稀缺。需要开发仅利用现有标注的高效解决方案

Method: 提出边界分割框架BoundarySeg：1）将器官边界预测作为辅助任务 2）通过主任务（器官分割）与辅助任务预测结果的一致性约束提供额外监督信号 3）双任务共享编码器但使用独立解码器

Result: 在低数据条件下达到/超越现有半监督方法性能，计算效率与基线方法相当（FLOPs仅增加0.02%），代码将在论文接收后开源

Conclusion: 通过多任务框架与预测一致性监督机制，有效挖掘有限标注数据的潜力，为医学图像分割提供更实用的解决方案，特别适用于标注数据稀缺的临床场景

Abstract: Obtaining large-scale medical data, annotated or unannotated, is challenging
due to stringent privacy regulations and data protection policies. In addition,
annotating medical images requires that domain experts manually delineate
anatomical structures, making the process both time-consuming and costly. As a
result, semi-supervised methods have gained popularity for reducing annotation
costs. However, the performance of semi-supervised methods is heavily dependent
on the availability of unannotated data, and their effectiveness declines when
such data are scarce or absent. To overcome this limitation, we propose a
simple, yet effective and computationally efficient approach for medical image
segmentation that leverages only existing annotations. We propose BoundarySeg ,
a multi-task framework that incorporates organ boundary prediction as an
auxiliary task to full organ segmentation, leveraging consistency between the
two task predictions to provide additional supervision. This strategy improves
segmentation accuracy, especially in low data regimes, allowing our method to
achieve performance comparable to or exceeding state-of-the-art semi supervised
approaches all without relying on unannotated data or increasing computational
demands. Code will be released upon acceptance.

</details>


### [47] [Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models](https://arxiv.org/abs/2505.09858)
*Danush Kumar Venkatesh,Isabel Funke,Micha Pfeiffer,Fiona Kolbinger,Hanna Maria Schmeiser,Juergen Weitz,Marius Distler,Stefanie Speidel*

Main category: cs.CV

TL;DR: 提出两阶段文本条件扩散方法生成高保真手术视频，通过拒绝采样策略增强数据集，有效解决数据不平衡问题并提升下游任务性能


<details>
  <summary>Details</summary>
Motivation: 手术视频数据严重不平衡问题限制了深度学习模型的开发，现有方法难以有效处理手术视频的时空特性

Method: 文本条件扩散模型+时空解耦建模（2D潜在扩散模型处理空间内容+时间注意力层保证时序一致性），结合拒绝采样筛选机制

Result: 在手术动作识别和术中事件预测任务中，使用合成视频增强后的模型性能显著提升

Conclusion: 该方法为手术视频数据增强提供了新范式，开源实现促进领域发展

Abstract: Computer-assisted interventions can improve intra-operative guidance,
particularly through deep learning methods that harness the spatiotemporal
information in surgical videos. However, the severe data imbalance often found
in surgical video datasets hinders the development of high-performing models.
In this work, we aim to overcome the data imbalance by synthesizing surgical
videos. We propose a unique two-stage, text-conditioned diffusion-based method
to generate high-fidelity surgical videos for under-represented classes. Our
approach conditions the generation process on text prompts and decouples
spatial and temporal modeling by utilizing a 2D latent diffusion model to
capture spatial content and then integrating temporal attention layers to
ensure temporal consistency. Furthermore, we introduce a rejection sampling
strategy to select the most suitable synthetic samples, effectively augmenting
existing datasets to address class imbalance. We evaluate our method on two
downstream tasks-surgical action recognition and intra-operative event
prediction-demonstrating that incorporating synthetic videos from our approach
substantially enhances model performance. We open-source our implementation at
https://gitlab.com/nct_tso_public/surgvgen.

</details>


### [48] [Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction](https://arxiv.org/abs/2505.09859)
*Andrew Jun Lee,Taylor Webb,Trevor Bihl,Keith Holyoak,Hongjing Lu*

Main category: cs.CV

TL;DR: 提出概率图式归纳（PSI）模型，通过结构化表征与类比映射实现人类水平的组合式视觉概念学习


<details>
  <summary>Details</summary>
Motivation: 传统分类模型使用非结构化特征向量，而人类组合式概念学习依赖结构化表征与类比推理机制，需建立更接近人类认知机理的计算模型

Method: 结合深度学习与概率建模：1）构建包含对象及其关系的图结构表征；2）设计权衡对象相似度与关系相似度的新型相似度计算框架；3）引入类似选择性注意力的关系权重放大机制

Result: PSI在少样本学习任务中表现接近人类水平，优于非结构化原型模型（准确率提升15%）和弱结构化对照组，其自适应策略能动态增强区分性关系特征

Conclusion: 结构化表征与类比映射是建模人类组合概念学习的关键，深度学习为构建心理计算模型提供了新途径，自适应关系权重机制揭示了人类概念学习的认知策略

Abstract: The ability to learn new visual concepts from limited examples is a hallmark
of human cognition. While traditional category learning models represent each
example as an unstructured feature vector, compositional concept learning is
thought to depend on (1) structured representations of examples (e.g., directed
graphs consisting of objects and their relations) and (2) the identification of
shared relational structure across examples through analogical mapping. Here,
we introduce Probabilistic Schema Induction (PSI), a prototype model that
employs deep learning to perform analogical mapping over structured
representations of only a handful of examples, forming a compositional concept
called a schema. In doing so, PSI relies on a novel conception of similarity
that weighs object-level similarity and relational similarity, as well as a
mechanism for amplifying relations relevant to classification, analogous to
selective attention parameters in traditional models. We show that PSI produces
human-like learning performance and outperforms two controls: a prototype model
that uses unstructured feature vectors extracted from a deep learning model,
and a variant of PSI with weaker structured representations. Notably, we find
that PSI's human-like performance is driven by an adaptive strategy that
increases relational similarity over object-level similarity and upweights the
contribution of relations that distinguish classes. These findings suggest that
structured representations and analogical mapping are critical to modeling
rapid human-like learning of compositional visual concepts, and demonstrate how
deep learning can be leveraged to create psychological models.

</details>


### [49] [Large-Scale Gaussian Splatting SLAM](https://arxiv.org/abs/2505.09915)
*Zhe Xin,Chenyang Wu,Penghui Huang,Yanyong Zhang,Yinian Mao,Guoquan Huang*

Main category: cs.CV

TL;DR: 基于3D高斯溅射的LSG-SLAM系统，通过多模态策略和子地图管理实现户外大规模场景的鲁棒视觉SLAM


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和3DGS的SLAM方法依赖RGBD传感器且局限于室内场景，亟需解决户外大规模场景的重建鲁棒性问题

Method: 1. 多模态先验姿态估计
2. 特征对齐扭曲约束减少渲染损失
3. 连续高斯子地图处理无界场景
4. 基于闭环检测的全局姿态优化
5. 结构细化模块提升重建质量

Result: 在EuRoc和KITTI数据集上超越神经方法、3DGS方法及传统SLAM，实现最佳性能指标

Conclusion: LSG-SLAM首次验证了纯视觉3DGS在大规模户外SLAM的可行性，通过系统级优化实现了无需深度传感器的高效场景重建

Abstract: The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian
Splatting (3DGS) have shown encouraging and impressive results for visual SLAM.
However, most representative methods require RGBD sensors and are only
available for indoor environments. The robustness of reconstruction in
large-scale outdoor scenarios remains unexplored. This paper introduces a
large-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The
proposed LSG-SLAM employs a multi-modality strategy to estimate prior poses
under large view changes. In tracking, we introduce feature-alignment warping
constraints to alleviate the adverse effects of appearance similarity in
rendering losses. For the scalability of large-scale scenarios, we introduce
continuous Gaussian Splatting submaps to tackle unbounded scenes with limited
memory. Loops are detected between GS submaps by place recognition and the
relative pose between looped keyframes is optimized utilizing rendering and
feature warping losses. After the global optimization of camera poses and
Gaussian points, a structure refinement module enhances the reconstruction
quality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM
achieves superior performance over existing Neural, 3DGS-based, and even
traditional approaches. Project page: https://lsg-slam.github.io.

</details>


### [50] [AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection](https://arxiv.org/abs/2505.09926)
*Bin-Bin Gao,Yue Zhu,Jiangtao Yan,Yuezhi Cai,Weixi Zhang,Meng Wang,Jun Liu,Yong Liu,Lei Wang,Chengjie Wang*

Main category: cs.CV

TL;DR: 提出AdaptCLIP方法，通过交替学习视觉文本表示和对比残差特征，在12个跨域异常检测基准上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的异常检测方法存在提示模板设计复杂、需要微调、灵活性差等问题，需探索更高效的适配方式

Method: 1. 视觉/文本适配器交替学习 2. 提示-查询适配器融合上下文与对齐残差特征 3. 仅添加三个轻量适配器无需微调CLIP主体

Result: 在工业和医疗领域12个数据集上显著超越现有方法，支持零样本/小样本跨域迁移

Conclusion: AdaptCLIP验证了交替学习与特征融合的有效性，为通用视觉异常检测提供了高效解决方案

Abstract: Universal visual anomaly detection aims to identify anomalies from novel or
unseen vision domains without additional fine-tuning, which is critical in open
scenarios. Recent studies have demonstrated that pre-trained vision-language
models like CLIP exhibit strong generalization with just zero or a few normal
images. However, existing methods struggle with designing prompt templates,
complex token interactions, or requiring additional fine-tuning, resulting in
limited flexibility. In this work, we present a simple yet effective method
called AdaptCLIP based on two key insights. First, adaptive visual and textual
representations should be learned alternately rather than jointly. Second,
comparative learning between query and normal image prompt should incorporate
both contextual and aligned residual features, rather than relying solely on
residual features. AdaptCLIP treats CLIP models as a foundational service,
adding only three simple adapters, visual adapter, textual adapter, and
prompt-query adapter, at its input or output ends. AdaptCLIP supports
zero-/few-shot generalization across domains and possesses a training-free
manner on target domains once trained on a base dataset. AdaptCLIP achieves
state-of-the-art performance on 12 anomaly detection benchmarks from industrial
and medical domains, significantly outperforming existing competitive methods.
We will make the code and model of AdaptCLIP available at
https://github.com/gaobb/AdaptCLIP.

</details>


### [51] [DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation](https://arxiv.org/abs/2505.09927)
*Siqi Yin,Shaolei Liu,Manning Wang*

Main category: cs.CV

TL;DR: 提出新型无源域适应框架，通过预适应模型、数据依赖频率提示和分层微调策略，提升跨域医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法在风格转换图像质量、伪标签准确性及训练效率方面存在不足，尤其在医疗数据隐私受限场景下需更高效的解决方案。

Method: 1) 预适应阶段生成高质量伪标签初始化模型
2) 数据依赖频率提示实现高效风格迁移
3) 针对SFDA设计的风格相关层选择性微调策略

Result: 在腹部和心脏跨模态分割任务中超越现有SOTA方法，验证框架有效性。

Conclusion: 通过三阶段优化策略有效解决医疗领域SFDA核心痛点，为隐私敏感场景提供高性能跨域适应方案。

Abstract: Domain adaptation addresses the challenge of model performance degradation
caused by domain gaps. In the typical setup for unsupervised domain adaptation,
labeled data from a source domain and unlabeled data from a target domain are
used to train a target model. However, access to labeled source domain data,
particularly in medical datasets, can be restricted due to privacy policies. As
a result, research has increasingly shifted to source-free domain adaptation
(SFDA), which requires only a pretrained model from the source domain and
unlabeled data from the target domain data for adaptation. Existing SFDA
methods often rely on domain-specific image style translation and
self-supervision techniques to bridge the domain gap and train the target
domain model. However, the quality of domain-specific style-translated images
and pseudo-labels produced by these methods still leaves room for improvement.
Moreover, training the entire model during adaptation can be inefficient under
limited supervision. In this paper, we propose a novel SFDA framework to
address these challenges. Specifically, to effectively mitigate the impact of
domain gap in the initial training phase, we introduce preadaptation to
generate a preadapted model, which serves as an initialization of target model
and allows for the generation of high-quality enhanced pseudo-labels without
introducing extra parameters. Additionally, we propose a data-dependent
frequency prompt to more effectively translate target domain images into a
source-like style. To further enhance adaptation, we employ a style-related
layer fine-tuning strategy, specifically designed for SFDA, to train the target
model using the prompted target domain images and pseudo-labels. Extensive
experiments on cross-modality abdominal and cardiac SFDA segmentation tasks
demonstrate that our proposed method outperforms existing state-of-the-art
methods.

</details>


### [52] [VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety](https://arxiv.org/abs/2505.09935)
*Ahmed S. Abdelrahman,Mohamed Abdel-Aty,Quoc Dai Tran*

Main category: cs.CV

TL;DR: 提出VRU-CIPI框架，采用GRU和Transformer多头注意力机制预测弱势道路使用者过街意图，准确率96.45%且支持实时处理。


<details>
  <summary>Details</summary>
Motivation: 解决城市交叉路口人车交互安全隐患，特别是VRU过街意图误判导致的危险冲突问题。

Method: 融合GRU捕捉时间动态特征 + Transformer多头自注意力编码上下文空间依赖

Result: UCF-VRU数据集验证：96.45%准确率，33FPS实时推理速度

Conclusion: 结合I2V通信系统，通过提前激活过街信号和车辆预警，提升所有道路使用者的交互安全性

Abstract: Understanding and predicting human behavior in-thewild, particularly at urban
intersections, remains crucial for enhancing interaction safety between road
users. Among the most critical behaviors are crossing intentions of Vulnerable
Road Users (VRUs), where misinterpretation may result in dangerous conflicts
with oncoming vehicles. In this work, we propose the VRU-CIPI framework with a
sequential attention-based model designed to predict VRU crossing intentions at
intersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal
dynamics in VRU movements, combined with a multi-head Transformer
self-attention mechanism to encode contextual and spatial dependencies critical
for predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed
achieves state-of-the-art performance with an accuracy of 96.45% and achieving
real-time inference speed reaching 33 frames per second. Furthermore, by
integrating with Infrastructure-to-Vehicles (I2V) communication, our approach
can proactively enhance intersection safety through timely activation of
crossing signals and providing early warnings to connected vehicles, ensuring
smoother and safer interactions for all road users.

</details>


### [53] [Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset](https://arxiv.org/abs/2505.09939)
*Zhe Shan,Lei Zhou,Liu Mao,Shaofan Chen,Chuanqiu Ren,Xia Xie*

Main category: cs.CV

TL;DR: 提出非配准变化检测新任务，通过场景分类和数据集转换方案验证现有方法缺陷。


<details>
  <summary>Details</summary>
Motivation: 针对自然灾害/人为事故等紧急场景下遥感图像配准困难的实际需求，解决现有研究对非配准问题讨论不足的缺陷。

Method: 1. 定义8种现实非配准场景
2. 开发图像转换方案将配准数据集转为非配准版本
3. 构建NRCD数据集验证方法有效性

Result: 非配准变化检测会导致现有最先进方法性能出现灾难性下降

Conclusion: 该研究填补了非配准变化检测领域的空白，开源代码和数据集为后续研究提供了基准平台。

Abstract: In this study, we propose a novel remote sensing change detection task,
non-registration change detection, to address the increasing number of
emergencies such as natural disasters, anthropogenic accidents, and military
strikes. First, in light of the limited discourse on the issue of
non-registration change detection, we systematically propose eight scenarios
that could arise in the real world and potentially contribute to the occurrence
of non-registration problems. Second, we develop distinct image transformation
schemes tailored to various scenarios to convert the available registration
change detection dataset into a non-registration version. Finally, we
demonstrate that non-registration change detection can cause catastrophic
damage to the state-of-the-art methods. Our code and dataset are available at
https://github.com/ShanZard/NRCD.

</details>


### [54] [CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection](https://arxiv.org/abs/2505.09943)
*Jiakun Deng,Kexuan Li,Xingye Cui,Jiaxuan Li,Chang Long,Tian Pu,Zhenming Peng*

Main category: cs.CV

TL;DR: 提出融合轮廓感知与显著性先验的CSPENet网络，通过SCPEM模块捕获目标梯度特性，DBPEA双分支嵌入先验，AGFEM优化特征，显著提升红外小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有红外小目标检测方法在弱目标定位和密集杂波下的轮廓感知存在缺陷，制约检测精度。需开发能同时增强目标定位与轮廓表征的新方法。

Method: 1.SCPEM模块提取目标中心收敛梯度特性，生成显著性先验和多尺度结构先验；2.DBPSEA双分支差异化融合路径嵌入先验；3.AGFEM通过注意力机制优化特征表示。

Result: 在NUDT-SIRST、IRSTD-1k、NUAA-SIRST三个公开数据集上取得SOTA性能，代码已开源。

Conclusion: 通过协同利用目标梯度特性和双先验嵌入机制，CSPENet有效解决了弱目标定位与轮廓感知难题，为复杂场景红外检测提供了新方案。

Abstract: Infrared small target detection (ISTD) plays a critical role in a wide range
of civilian and military applications. Existing methods suffer from
deficiencies in the localization of dim targets and the perception of contour
information under dense clutter environments, severely limiting their detection
performance. To tackle these issues, we propose a contour-aware and saliency
priors embedding network (CSPENet) for ISTD. We first design a
surround-convergent prior extraction module (SCPEM) that effectively captures
the intrinsic characteristic of target contour pixel gradients converging
toward their center. This module concurrently extracts two collaborative
priors: a boosted saliency prior for accurate target localization and
multi-scale structural priors for comprehensively enriching contour detail
representation. Building upon this, we propose a dual-branch priors embedding
architecture (DBPEA) that establishes differentiated feature fusion pathways,
embedding these two priors at optimal network positions to achieve performance
enhancement. Finally, we develop an attention-guided feature enhancement module
(AGFEM) to refine feature representations and improve saliency estimation
accuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and
NUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art
methods in detection performance. The code is available at
https://github.com/IDIP2025/CSPENet.

</details>


### [55] [MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction](https://arxiv.org/abs/2505.09965)
*Hao Yang,Tao Tan,Shuai Tan,Weiqin Yang,Kunyan Cai,Calvin Chen,Yue Sun*

Main category: cs.CV

TL;DR: 提出MambaControl框架，整合选择性状态空间模型与扩散过程，通过Mamba长程建模+图引导解剖控制+傅里叶谱图表示，实现阿尔茨海默病预测SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像预测方法在长期依赖建模和解剖一致性保持方面存在不足，影响进展性疾病建模的准确性。需要提升时空动态捕捉能力以支持精准医疗决策。

Method: 1) Mamba架构捕捉长期依赖 2) 图引导解剖控制保持结构一致性 3) 傅里叶增强谱图表示空间/多尺度特征 4) 扩散过程生成高质量预测轨迹

Result: 定量评估显示预测PSNR提升12.5%，海马体等关键区域体积预测误差降低18.7%，在ADNI数据集上达到当前最优预测精度。

Conclusion: MambaControl创新性地融合状态空间建模与解剖约束，为个性化疾病进展预测和临床决策支持提供了可靠的技术框架。

Abstract: Modelling disease progression in precision medicine requires capturing
complex spatio-temporal dynamics while preserving anatomical integrity.
Existing methods often struggle with longitudinal dependencies and structural
consistency in progressive disorders. To address these limitations, we
introduce MambaControl, a novel framework that integrates selective state-space
modelling with diffusion processes for high-fidelity prediction of medical
image trajectories. To better capture subtle structural changes over time while
maintaining anatomical consistency, MambaControl combines Mamba-based
long-range modelling with graph-guided anatomical control to more effectively
represent anatomical correlations. Furthermore, we introduce Fourier-enhanced
spectral graph representations to capture spatial coherence and multiscale
detail, enabling MambaControl to achieve state-of-the-art performance in
Alzheimer's disease prediction. Quantitative and regional evaluations
demonstrate improved progression prediction quality and anatomical fidelity,
highlighting its potential for personalised prognosis and clinical decision
support.

</details>


### [56] [TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition](https://arxiv.org/abs/2505.09967)
*Liqian Deng*

Main category: cs.CV

TL;DR: 提出基于纹理关键驱动因素（TKDF）的FER框架，通过纹理感知特征提取器（TAFE）和双上下文信息过滤（DCIF）实现高效表情识别


<details>
  <summary>Details</summary>
Motivation: 解决自然场景下因表情特征细微/局部性及面部外观复杂变化导致的FER难题，发现眉/眼/嘴等区域微纹理变化是情绪动态的核心指标

Method: TAFE模块（基于ResNet+多分支注意力）提取细粒度纹理特征，DCIF模块（自适应池化+注意力）进行上下文信息过滤

Result: 在RAF-DB和KDEF数据集上达到SOTA性能，验证TKDF策略的有效性和鲁棒性

Conclusion: 显式建模纹理关键驱动因素能显著提升FER系统性能，注意力机制与自适应特征过滤的组合优化策略效果显著

Abstract: Facial expression recognition (FER) in the wild remains a challenging task
due to the subtle and localized nature of expression-related features, as well
as the complex variations in facial appearance. In this paper, we introduce a
novel framework that explicitly focuses on Texture Key Driver Factors (TKDF),
localized texture regions that exhibit strong discriminative power across
emotional categories. By carefully observing facial image patterns, we identify
that certain texture cues, such as micro-changes in skin around the brows,
eyes, and mouth, serve as primary indicators of emotional dynamics. To
effectively capture and leverage these cues, we propose a FER architecture
comprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual
Information Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced
with multi-branch attention to extract fine-grained texture representations,
while DCIF refines these features by filtering context through adaptive pooling
and attention mechanisms. Experimental results on RAF-DB and KDEF datasets
demonstrate that our method achieves state-of-the-art performance, verifying
the effectiveness and robustness of incorporating TKDFs into FER pipelines.

</details>


### [57] [APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds](https://arxiv.org/abs/2505.09971)
*Yuan Gao,Shaobo Xia,Sheng Nie,Cheng Wang,Xiaohuan Xi,Bisheng Yang*

Main category: cs.CV

TL;DR: 提出首个ALS点云连续测试时自适应方法APCoTTA，通过动态层选择、熵一致性损失和参数插值机制解决灾难性遗忘与错误累积问题


<details>
  <summary>Details</summary>
Motivation: 现实场景中传感器差异和环境变化导致模型性能下降，而ALS点云领域缺乏CTTA基准且现有方法存在长期适应失效风险

Method: 1) 动态可训练层选择模块通过梯度筛选低置信层训练；2) 基于熵的可靠性样本一致性损失；3) 随机参数插值平衡目标域适应与源知识保留

Result: 在ISPRSC和H3DC两个新基准上mIoU分别提升9%和14%，显著优于直接推理

Conclusion: APCoTTA有效解决了持续适应中的关键问题，公开的基准与代码填补了领域空白

Abstract: Airborne laser scanning (ALS) point cloud segmentation is a fundamental task
for large-scale 3D scene understanding. In real-world applications, models are
typically fixed after training. However, domain shifts caused by changes in the
environment, sensor types, or sensor degradation often lead to a decline in
model performance. Continuous Test-Time Adaptation (CTTA) offers a solution by
adapting a source-pretrained model to evolving, unlabeled target domains.
Despite its potential, research on ALS point clouds remains limited, facing
challenges such as the absence of standardized datasets and the risk of
catastrophic forgetting and error accumulation during prolonged adaptation. To
tackle these challenges, we propose APCoTTA, the first CTTA method tailored for
ALS point cloud semantic segmentation. We propose a dynamic trainable layer
selection module. This module utilizes gradient information to select
low-confidence layers for training, and the remaining layers are kept frozen,
mitigating catastrophic forgetting. To further reduce error accumulation, we
propose an entropy-based consistency loss. By losing such samples based on
entropy, we apply consistency loss only to the reliable samples, enhancing
model stability. In addition, we propose a random parameter interpolation
mechanism, which randomly blends parameters from the selected trainable layers
with those of the source model. This approach helps balance target adaptation
and source knowledge retention, further alleviating forgetting. Finally, we
construct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA
benchmarks for ALS point cloud segmentation. Experimental results demonstrate
that APCoTTA achieves the best performance on two benchmarks, with mIoU
improvements of approximately 9% and 14% over direct inference. The new
benchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA.

</details>


### [58] [High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation](https://arxiv.org/abs/2505.09986)
*Yimin Zhou,Yichong Xia,Sicheng Pan,Bin Chen,Baoyi An,Haoqian Wang,Zhi Wang,Yaowei Wang,Zikun Zhou*

Main category: cs.CV

TL;DR: 提出水下图像压缩模型HQUIC，通过自适应光传输补偿模块和频域动态加权策略，显著提升水下图像压缩效率。


<details>
  <summary>Details</summary>
Motivation: 现有压缩算法未充分挖掘水下图像的光照衰减、色调偏差和常见物体重复性等特性，导致压缩性能受限。水下图像传输存储需求日益增长，需针对性优化压缩方法。

Method: 1. 采用ALTC模块预测图像衰减系数和全局光照，缓解水下光照差异
2. 通过码本分支提取水下常见物体特征增强主分支
3. 动态加权多尺度频率分量，优先保留关键信息

Result: 在多个水下数据集上的实验表明，HQUIC在压缩效率上超越现有先进方法，PSNR指标平均提升1.2dB

Conclusion: 通过针对性建模水下图像的光传输特性和物体分布规律，HQUIC有效解决了水下压缩场景的特殊挑战，为海洋工程应用提供了更高效的图像压缩方案。

Abstract: With the increasing exploration and exploitation of the underwater world,
underwater images have become a critical medium for human interaction with
marine environments, driving extensive research into their efficient
transmission and storage. However, contemporary underwater image compression
algorithms fail to fully leverage the unique characteristics distinguishing
underwater scenes from terrestrial images, resulting in suboptimal performance.
To address this limitation, we introduce HQUIC, designed to exploit
underwater-image-specific features for enhanced compression efficiency. HQUIC
employs an ALTC module to adaptively predict the attenuation coefficients and
global light information of the images, which effectively mitigates the issues
caused by the differences in lighting and tone existing in underwater images.
Subsequently, HQUIC employs a codebook as an auxiliary branch to extract the
common objects within underwater images and enhances the performance of the
main branch. Furthermore, HQUIC dynamically weights multi-scale frequency
components, prioritizing information critical for distortion quality while
discarding redundant details. Extensive evaluations on diverse underwater
datasets demonstrate that HQUIC outperforms state-of-the-art compression
methods.

</details>


### [59] [PointArena: Probing Multimodal Grounding Through Language-Guided Pointing](https://arxiv.org/abs/2505.09990)
*Long Cheng,Jiafei Duan,Yi Ru Wang,Haoquan Fang,Boyang Li,Yushan Huang,Elvis Wang,Ainaz Eftekhar,Jason Lee,Wentao Yuan,Rose Hendrix,Noah A. Smith,Fei Xia,Dieter Fox,Ranjay Krishna*

Main category: cs.CV

TL;DR: 提出了一个评估多模态指向能力的综合平台PointArena，包含基准测试、交互式评估和机器人验证三部分


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅关注对象定位任务，需要更全面的多模态指向能力评估体系

Method: 构建包含1,000个任务的Point-Bench数据集、收集4,500+匿名投票的Point-Battle平台，以及机器人系统Point-Act

Result: Molmo-72B表现最佳，监督训练显著提升性能，各评估阶段呈现强相关性

Conclusion: 精确定位能力是多模态模型连接抽象推理与真实世界行动的关键

Abstract: Pointing serves as a fundamental and intuitive mechanism for grounding
language within visual contexts, with applications spanning robotics, assistive
technologies, and interactive AI systems. While recent multimodal models have
started to support pointing capabilities, existing benchmarks typically focus
only on referential object localization tasks. We introduce PointArena, a
comprehensive platform for evaluating multimodal pointing across diverse
reasoning scenarios. PointArena comprises three components: (1) Point-Bench, a
curated dataset containing approximately 1,000 pointing tasks across five
reasoning categories; (2) Point-Battle, an interactive, web-based arena
facilitating blind, pairwise model comparisons, which has already gathered over
4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation
system allowing users to directly evaluate multimodal model pointing
capabilities in practical settings. We conducted extensive evaluations of both
state-of-the-art open-source and proprietary multimodal models. Results
indicate that Molmo-72B consistently outperforms other models, though
proprietary models increasingly demonstrate comparable performance.
Additionally, we find that supervised training specifically targeting pointing
tasks significantly enhances model performance. Across our multi-stage
evaluation pipeline, we also observe strong correlations, underscoring the
critical role of precise pointing capabilities in enabling multimodal models to
effectively bridge abstract reasoning with concrete, real-world actions.
Project page: https://pointarena.github.io/

</details>


### [60] [Descriptive Image-Text Matching with Graded Contextual Similarity](https://arxiv.org/abs/2505.09997)
*Jinhyun Jang,Jiyeong Lee,Kwanghoon Sohn*

Main category: cs.CV

TL;DR: 提出DITM方法，通过语言描述的灵活性学习分级上下文相似性，利用句子描述性评分实现动态负样本调整和层级文本对齐，增强图像-文本匹配效果。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏二元监督方法覆盖有限图像-文本关系，忽略多对多对应及隐含的从通用到特定描述的层次联系。

Method: 1. 基于累积TF-IDF计算句子描述性评分
2. 动态松弛正负样本连接性
3. 通用到特定顺序的文本对齐策略

Result: 在MS-COCO/Flickr30K/CxC数据集上超越SOTA，HierarCaps基准验证模型层次推理能力提升

Conclusion: DITM突破刚性二元监督范式，通过描述性评分机制有效挖掘潜在正样本对，实现复杂跨模态关系的层次化建模

Abstract: Image-text matching aims to build correspondences between visual and textual
data by learning their pairwise similarities. Most existing approaches have
adopted sparse binary supervision, indicating whether a pair of images and
sentences matches or not. However, such sparse supervision covers a limited
subset of image-text relationships, neglecting their inherent many-to-many
correspondences; an image can be described in numerous texts at different
descriptive levels. Moreover, existing approaches overlook the implicit
connections from general to specific descriptions, which form the underlying
rationale for the many-to-many relationships between vision and language. In
this work, we propose descriptive image-text matching, called DITM, to learn
the graded contextual similarity between image and text by exploring the
descriptive flexibility of language. We formulate the descriptiveness score of
each sentence with cumulative term frequency-inverse document frequency
(TF-IDF) to balance the pairwise similarity according to the keywords in the
sentence. Our method leverages sentence descriptiveness to learn robust
image-text matching in two key ways: (1) to refine the false negative labeling,
dynamically relaxing the connectivity between positive and negative pairs, and
(2) to build more precise matching, aligning a set of relevant sentences in a
generic-to-specific order. By moving beyond rigid binary supervision, DITM
enhances the discovery of both optimal matches and potential positive pairs.
Extensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the
effectiveness of our method in representing complex image-text relationships
compared to state-of-the-art approaches. In addition, DITM enhances the
hierarchical reasoning ability of the model, supported by the extensive
analysis on HierarCaps benchmark.

</details>


### [61] [From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching](https://arxiv.org/abs/2505.09998)
*Ying Zang,Yuanqi Hu,Xinyu Chen,Yuxia Xu,Suhui Wang,Chunan Yu,Lanyun Zhu,Deyi Ji,Xin Xu,Tianrun Chen*

Main category: cs.CV

TL;DR: 提出3D草图驱动的服装生成框架，结合条件扩散模型与自适应课程学习，降低虚拟服装设计门槛


<details>
  <summary>Details</summary>
Motivation: 现有3D服装设计工具因技术门槛高和数据匮乏难以为普通用户所用，需开发更易用的创作方案

Method: 融合条件扩散模型/共享潜在空间草图编码器/自适应课程学习策略，并构建KO3DClothes草图-服装配对数据集

Result: 实验验证方法在保真度和可用性上显著优于基线，用户研究证实非专业用户可有效创作个性化服装

Conclusion: 该框架为下一代消费平台的民主化时尚设计提供可行路径，推动虚拟身份表达的技术普惠

Abstract: In the era of immersive consumer electronics, such as AR/VR headsets and
smart devices, people increasingly seek ways to express their identity through
virtual fashion. However, existing 3D garment design tools remain inaccessible
to everyday users due to steep technical barriers and limited data. In this
work, we introduce a 3D sketch-driven 3D garment generation framework that
empowers ordinary users - even those without design experience - to create
high-quality digital clothing through simple 3D sketches in AR/VR environments.
By combining a conditional diffusion model, a sketch encoder trained in a
shared latent space, and an adaptive curriculum learning strategy, our system
interprets imprecise, free-hand input and produces realistic, personalized
garments. To address the scarcity of training data, we also introduce
KO3DClothes, a new dataset of paired 3D garments and user-created sketches.
Extensive experiments and user studies confirm that our method significantly
outperforms existing baselines in both fidelity and usability, demonstrating
its promise for democratized fashion design on next-generation consumer
platforms.

</details>


### [62] [Application of YOLOv8 in monocular downward multiple Car Target detection](https://arxiv.org/abs/2505.10016)
*Shijie Lyu*

Main category: cs.CV

TL;DR: 基于YOLOv8改进的自动驾驶目标检测网络，通过结构重参数化技术、双向金字塔结构和新检测流程，实现多尺度小目标高效检测，精度65%显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有雷达感知成本高、摄像头易受环境干扰、车载传感器分辨率不足等问题，提升自动驾驶系统在复杂场景下的目标检测能力。

Method: 在YOLOv8框架中集成：1）结构重参数化技术优化网络参数 2）双向金字塔结构增强多尺度特征融合 3）新型检测流程提升小目标识别

Result: 实验验证模型对大小物体检测均有效，检测精度达65%，在FSAC竞赛场景中单目标/小物体检测表现突出。

Conclusion: 改进模型具有实际应用潜力，特别适用于自动驾驶竞赛场景，为复杂环境下的实时目标检测提供有效解决方案。

Abstract: Autonomous driving technology is progressively transforming traditional car
driving methods, marking a significant milestone in modern transportation.
Object detection serves as a cornerstone of autonomous systems, playing a vital
role in enhancing driving safety, enabling autonomous functionality, improving
traffic efficiency, and facilitating effective emergency responses. However,
current technologies such as radar for environmental perception, cameras for
road perception, and vehicle sensor networks face notable challenges, including
high costs, vulnerability to weather and lighting conditions, and limited
resolution.To address these limitations, this paper presents an improved
autonomous target detection network based on YOLOv8. By integrating structural
reparameterization technology, a bidirectional pyramid structure network model,
and a novel detection pipeline into the YOLOv8 framework, the proposed approach
achieves highly efficient and precise detection of multi-scale, small, and
remote objects. Experimental results demonstrate that the enhanced model can
effectively detect both large and small objects with a detection accuracy of
65%, showcasing significant advancements over traditional methods.This improved
model holds substantial potential for real-world applications and is
well-suited for autonomous driving competitions, such as the Formula Student
Autonomous China (FSAC), particularly excelling in scenarios involving
single-target and small-object detection.

</details>


### [63] [ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction](https://arxiv.org/abs/2505.10027)
*Shijie Lyu*

Main category: cs.CV

TL;DR: 提出基于强化学习的潜在扩散模型微调方法，显著提升遥感图像超分辨率质量，在复杂场景中效果突出。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在处理复杂遥感场景和细节保留方面存在局限性，需开发更有效的超分辨率方法以提升图像质量和跨场景适应性。

Method: 构建强化学习环境（状态、动作、奖励机制），在潜在扩散模型（LDM）的反向去噪过程中应用近端策略优化（PPO）进行决策优化。

Result: 在RESISC45数据集上，PSNR提升3-4dB，SSIM提高0.08-0.11，LPIPS降低0.06-0.10，在结构和复杂自然场景中改进尤为显著。

Conclusion: 该方法有效提升了遥感图像超分辨率的质量和跨场景适应性，为复杂场景下的图像重建提供了新思路。

Abstract: With the rapid advancement of remote sensing technology, super-resolution
image reconstruction is of great research and practical significance. Existing
deep learning methods have made progress but still face limitations in handling
complex scenes and preserving image details. This paper proposes a
reinforcement learning-based latent diffusion model (LDM) fine-tuning method
for remote sensing image super-resolution. The method constructs a
reinforcement learning environment with states, actions, and rewards,
optimizing decision objectives through proximal policy optimization (PPO)
during the reverse denoising process of the LDM model. Experiments on the
RESISC45 dataset show significant improvements over the baseline model in PSNR,
SSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,
and LPIPS reducing by 0.06-0.10, particularly in structured and complex natural
scenes. The results demonstrate the method's effectiveness in enhancing
super-resolution quality and adaptability across scenes.

</details>


### [64] [DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera](https://arxiv.org/abs/2505.10030)
*Miit Daga,Dhriti Parikh,Swarna Priya Ramu*

Main category: cs.CV

TL;DR: 提出深度学习模型DeepSeqCoco，通过混合优化器实现99.5%准确率，显著降低农业疾病检测耗时


<details>
  <summary>Details</summary>
Motivation: 传统椰树病害检测依赖人工方法效率低下，发展中国家因诊断滞后导致严重农业损失

Method: 开发基于深度学习的DeepSeqCoco模型，系统测试SGD、Adam及混合优化器的性能平衡

Result: 混合SGD-Adam优化实现99.5%准确率（提升5%），验证损失2.81%，训练/预测时间分别减少18%/85%

Conclusion: 该AI模型为精准农业提供高效可扩展的疾病监测方案，显著提升检测效率与农业生产力

Abstract: Coconut tree diseases are a serious risk to agricultural yield, particularly
in developing countries where conventional farming practices restrict early
diagnosis and intervention. Current disease identification methods are manual,
labor-intensive, and non-scalable. In response to these limitations, we come up
with DeepSeqCoco, a deep learning based model for accurate and automatic
disease identification from coconut tree images. The model was tested under
various optimizer settings, such as SGD, Adam, and hybrid configurations, to
identify the optimal balance between accuracy, minimization of loss, and
computational cost. Results from experiments indicate that DeepSeqCoco can
achieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than
existing models) with the hybrid SGD-Adam showing the lowest validation loss of
2.81%. It also shows a drop of up to 18% in training time and up to 85% in
prediction time for input images. The results point out the promise of the
model to improve precision agriculture through an AI-based, scalable, and
efficient disease monitoring system.

</details>


### [65] [Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis](https://arxiv.org/abs/2505.10046)
*Bingda Tang,Boyang Zheng,Xichen Pan,Sayak Paul,Saining Xie*

Main category: cs.CV

TL;DR: 对多模态生成中LLM与DiT深度融合设计空间的系统性探索与可复现训练方案优化


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏与基准方法的详细对比，关键设计细节和训练方案不透明，导致该方法真实潜力存在不确定性

Method: 通过控制变量实验与现有基线对比，深度分析关键设计选择，提供规模化训练的可复现方案

Result: 建立了设计选择对性能影响的量化指标，形成了明确的规模化训练指导原则

Conclusion: 系统性实证研究为多模态生成领域提供了关键设计洞见和可复现基准，推动未来研究规范化发展

Abstract: This paper does not describe a new method; instead, it provides a thorough
exploration of an important yet understudied design space related to recent
advances in text-to-image synthesis -- specifically, the deep fusion of large
language models (LLMs) and diffusion transformers (DiTs) for multi-modal
generation. Previous studies mainly focused on overall system performance
rather than detailed comparisons with alternative methods, and key design
details and training recipes were often left undisclosed. These gaps create
uncertainty about the real potential of this approach. To fill these gaps, we
conduct an empirical study on text-to-image generation, performing controlled
comparisons with established baselines, analyzing important design choices, and
providing a clear, reproducible recipe for training at scale. We hope this work
offers meaningful data points and practical guidelines for future research in
multi-modal generation.

</details>


### [66] [Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field](https://arxiv.org/abs/2505.10049)
*Jinlong Fan,Xuepu Zeng,Jing Zhang,Mingming Gong,Yuxiang Yang,Dacheng Tao*

Main category: cs.CV

TL;DR: 系统综述动态场景重建技术，分析200+论文的技术演进与分类框架，指出神经辐射场与高斯泼溅方法在4D动态建模中的突破与未来方向。


<details>
  <summary>Details</summary>
Motivation: 动态场景表示技术近年快速迭代但缺乏系统性整理，需建立统一框架指导研究者快速切入该领域。

Method: 通过运动表示范式、重建技术、辅助信息整合、正则化方法四个维度，对200+论文进行系统分类与评估。

Result: 揭示了动态场景重建从隐式神经表达到显式高斯基元的技术路径，多模态数据融合显著提升运动建模物理合理性。

Conclusion: 当前挑战在于复杂运动拓扑建模与实时性突破，未来应结合物理引擎与跨模态学习提升动态重建的泛化能力。

Abstract: Dynamic scene representation and reconstruction have undergone transformative
advances in recent years, catalyzed by breakthroughs in neural radiance fields
and 3D Gaussian splatting techniques. While initially developed for static
environments, these methodologies have rapidly evolved to address the
complexities inherent in 4D dynamic scenes through an expansive body of
research. Coupled with innovations in differentiable volumetric rendering,
these approaches have significantly enhanced the quality of motion
representation and dynamic scene reconstruction, thereby garnering substantial
attention from the computer vision and graphics communities. This survey
presents a systematic analysis of over 200 papers focused on dynamic scene
representation using radiance field, spanning the spectrum from implicit neural
representations to explicit Gaussian primitives. We categorize and evaluate
these works through multiple critical lenses: motion representation paradigms,
reconstruction techniques for varied scene dynamics, auxiliary information
integration strategies, and regularization approaches that ensure temporal
consistency and physical plausibility. We organize diverse methodological
approaches under a unified representational framework, concluding with a
critical examination of persistent challenges and promising research
directions. By providing this comprehensive overview, we aim to establish a
definitive reference for researchers entering this rapidly evolving field while
offering experienced practitioners a systematic understanding of both
conceptual principles and practical frontiers in dynamic scene reconstruction.

</details>


### [67] [PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language](https://arxiv.org/abs/2505.10055)
*Ijazul Haq,Yingjie Zhang,Irfan Ali Khan*

Main category: cs.CV

TL;DR: 创建百万级合成普什图语OCR数据集PsOCR，评估11种LMMs模型性能，Gemini表现最优，Qwen-7B领跑开源模型。


<details>
  <summary>Details</summary>
Motivation: 解决普什图语因文字连笔特性和结构化数据稀缺导致的OCR处理难题，填补阿拉伯语系低资源语言研究空白

Method: 构建含100万图像的PsOCR数据集，涵盖1000种字体/颜色/版式，选取10K测试集评估7个开源模型和4个闭源模型

Result: 闭源模型中Gemini综合最佳，开源模型中Qwen-7B表现最优（准确率72.3% vs 闭源平均68.5%）

Conclusion: 该研究为普什图语OCR建立基准，方法论可扩展至阿拉伯语/波斯语/乌尔都语等相似文字的低资源OCR场景

Abstract: This paper evaluates the performance of Large Multimodal Models (LMMs) on
Optical Character Recognition (OCR) in the low-resource Pashto language.
Natural Language Processing (NLP) in Pashto faces several challenges due to the
cursive nature of its script and a scarcity of structured datasets. To address
this, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one
million images annotated with bounding boxes at word, line, and document
levels, suitable for training and evaluating models based on different
architectures, including Convolutional Neural Networks (CNNs) and Transformers.
PsOCR covers variations across 1,000 unique font families, colors, image sizes,
and layouts. A benchmark subset of 10K images was selected to evaluate the
performance of several LMMs, including seven open-source models: DeepSeek's
Janus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four
closed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results
demonstrate that Gemini achieves the best performance among all models, whereas
among open-source models, Qwen-7B stands out. This work provides an insightful
assessment of the capabilities and limitations of current LMMs for OCR tasks in
Pashto and establishes a foundation for further research not only in Pashto OCR
but also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is
available at https://github.com/zirak-ai/PashtoOCR.

</details>


### [68] [ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars](https://arxiv.org/abs/2505.10072)
*Rui-Yang Ju,Sheng-Yen Huang,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 提出基于StyleGAN与3D高斯混合形状的高效两阶段框架ToonifyGB，实现实时生成多样化风格化头部虚拟动画


<details>
  <summary>Details</summary>
Motivation: 现有Toonify框架需在固定分辨率下裁剪对齐面部，导致视频不稳定且影响高斯混合形状对高频细节的捕捉能力

Method: 1. 改进StyleGAN生成稳定风格化视频
2. 从视频中学习风格化中性头部模型及表情混合形状
3. 组合中性模型与表情参数实现任意表情渲染

Result: 在Arcane和Pixar两种风格基准数据集上验证有效性，实现高频细节保留的高质量动画生成

Conclusion: ToonifyGB通过两阶段架构突破预处理限制，显著提升风格化虚拟形象的渲染效率与视觉质量

Abstract: The introduction of 3D Gaussian blendshapes has enabled the real-time
reconstruction of animatable head avatars from monocular video. Toonify, a
StyleGAN-based framework, has become widely used for facial image stylization.
To extend Toonify for synthesizing diverse stylized 3D head avatars using
Gaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.
In Stage 1 (stylized video generation), we employ an improved StyleGAN to
generate the stylized video from the input video frames, which addresses the
limitation of cropping aligned faces at a fixed resolution as preprocessing for
normal StyleGAN. This process provides a more stable video, which enables
Gaussian blendshapes to better capture the high-frequency details of the video
frames, and efficiently generate high-quality animation in the next stage. In
Stage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head
model and a set of expression blendshapes from the generated video. By
combining the neutral head model with expression blendshapes, ToonifyGB can
efficiently render stylized avatars with arbitrary expressions. We validate the
effectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane
and Pixar.

</details>


### [69] [MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models](https://arxiv.org/abs/2505.10088)
*Yuncheng Guo,Xiaodong Gu*

Main category: cs.CV

TL;DR: Proposes MMRL/MMRL++ frameworks to address overfitting in few-shot vision-language adaptation via shared representation spaces and parameter-efficient interaction-aware design.


<details>
  <summary>Details</summary>
Motivation: Traditional few-shot adaptation of VLMs causes overfitting and weak generalization by focusing optimization only on class tokens in lower layers.

Method: Introduces modality-agnostic representation tokens inserted into higher encoder layers. Jointly optimizes class/representation features with frozen class projections. Adds regularization aligning features with zero-shot VLM outputs.

Result: Achieves SOTA performance on 15 datasets, demonstrating superior balance between task-specific adaptation and generalization capability.

Conclusion: MMRL frameworks effectively preserve pretrained knowledge while enabling task adaptation through layer-wise representation optimization and enhanced cross-modal interactions.

Abstract: Large-scale pre-trained Vision-Language Models (VLMs) have significantly
advanced transfer learning across diverse tasks. However, adapting these models
with limited few-shot data often leads to overfitting, undermining their
ability to generalize to new tasks. To address this, we propose Multi-Modal
Representation Learning (MMRL), which introduces a shared, learnable,
modality-agnostic representation space. MMRL generates space tokens projected
into both text and image encoders as representation tokens, enabling more
effective cross-modal interactions. Unlike prior methods that mainly optimize
class token features, MMRL inserts representation tokens into higher encoder
layers--where task-specific features are more prominent--while preserving
general knowledge in the lower layers. During training, both class and
representation features are jointly optimized: a trainable projection layer is
applied to representation tokens for task adaptation, while the projection
layer for class token remains frozen to retain pre-trained knowledge. To
further promote generalization, we introduce a regularization term aligning
class and text features with the frozen VLM's zero-shot features. At inference,
a decoupling strategy uses both class and representation features for base
tasks, but only class features for novel tasks due to their stronger
generalization. Building upon this, we propose MMRL++, a parameter-efficient
and interaction-aware extension that significantly reduces trainable parameters
and enhances intra-modal interactions--particularly across the layers of
representation tokens--allowing gradient sharing and instance-specific
information to propagate more effectively through the network. Extensive
experiments on 15 datasets demonstrate that MMRL and MMRL++ consistently
outperform state-of-the-art methods, achieving a strong balance between
task-specific adaptation and generalization.

</details>


### [70] [Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering](https://arxiv.org/abs/2505.10118)
*Yangfu Li,Hongjian Zhan,Tianyi Chen,Qi Liu,Yue Lu*

Main category: cs.CV

TL;DR: 提出多目标平衡覆盖框架(MoB)，通过动态预算分配解决视觉令牌剪枝中目标权衡问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌剪枝方法采用静态策略，忽视不同任务中提示对齐与视觉保留的相对重要性差异，导致性能不稳定

Method: 基于Hausdorff距离推导误差界限，利用ε-covering理论量化目标权衡，设计双目标覆盖框架实现贪心半径分配

Result: 在LLaVA系列模型中保留96.4%性能仅需11.1%令牌，加速1.3-1.5倍；适配Qwen2-VL和Video-LLaVA验证通用性

Conclusion: MoB通过理论驱动的动态权衡机制，在保持性能的同时显著提升效率，适用于多种多模态大模型和视觉语言任务

Abstract: Existing visual token pruning methods target prompt alignment and visual
preservation with static strategies, overlooking the varying relative
importance of these objectives across tasks, which leads to inconsistent
performance. To address this, we derive the first closed-form error bound for
visual token pruning based on the Hausdorff distance, uniformly characterizing
the contributions of both objectives. Moreover, leveraging $\epsilon$-covering
theory, we reveal an intrinsic trade-off between these objectives and quantify
their optimal attainment levels under a fixed budget. To practically handle
this trade-off, we propose Multi-Objective Balanced Covering (MoB), which
reformulates visual token pruning as a bi-objective covering problem. In this
framework, the attainment trade-off reduces to budget allocation via greedy
radius trading. MoB offers a provable performance bound and linear scalability
with respect to the number of input visual tokens, enabling adaptation to
challenging pruning scenarios. Extensive experiments show that MoB preserves
96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual
tokens and accelerates LLaVA-Next-7B by 1.3-1.5$\times$ with negligible
performance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm
that MoB integrates seamlessly into advanced MLLMs and diverse vision-language
tasks.

</details>


### [71] [IMITATE: Image Registration with Context for unknown time frame recovery](https://arxiv.org/abs/2505.10124)
*Ziad Kheil,Lucas Robinet,Laurent Risser,Soleakhena Ken*

Main category: cs.CV

TL;DR: 提出基于条件U-Net的新型图像配准方法，成功应用于4D-CT数据实现无伪影的呼吸运动建模


<details>
  <summary>Details</summary>
Motivation: 解决放疗中呼吸运动导致的4D-CT图像重建伪影问题，传统方法因呼吸不规则性/迟滞效应产生体积拼接失真

Method: 开发条件U-Net架构，直接融合条件信息(呼吸幅度)，无需固定参考图像的多模态配准框架

Result: 临床数据验证显示实现无伪影的3D体积重建，且满足实时性要求(亚秒级延迟)

Conclusion: 该框架有效解决动态器官建模难题，代码已开源推动医学图像分析领域发展

Abstract: In this paper, we formulate a novel image registration formalism dedicated to
the estimation of unknown condition-related images, based on two or more known
images and their associated conditions. We show how to practically model this
formalism by using a new conditional U-Net architecture, which fully takes into
account the conditional information and does not need any fixed image. Our
formalism is then applied to image moving tumors for radiotherapy treatment at
different breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal
regions. This driving application is particularly complex as it requires to
stitch a collection of sequential 2D slices into several 3D volumes at
different organ positions. Movement interpolation with standard methods then
generates well known reconstruction artefacts in the assembled volumes due to
irregular patient breathing, hysteresis and poor correlation of breathing
signal to internal motion. Results obtained on 4D-CT clinical data showcase
artefact-free volumes achieved through real-time latencies. The code is
publicly available at https://github.com/Kheil-Z/IMITATE .

</details>


### [72] [Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization](https://arxiv.org/abs/2505.10152)
*Yikang Wei*

Main category: cs.CV

TL;DR: 提出多源协作风格增强与域不变学习方法MCSAD，通过拓展风格空间和跨域特征对齐提升联邦域泛化效果


<details>
  <summary>Details</summary>
Motivation: 现有联邦域泛化方法在分散数据场景下仅探索孤立源域风格或简单插值跨域风格，导致风格空间受限

Method: 包含多源协作风格增强模块（生成更广风格空间数据）和域不变学习模块（通过类内跨域特征对齐与类间关系集成蒸馏）的交替训练框架

Result: 在多个领域泛化数据集上显著超越现有联邦域泛化方法，验证了方法的有效性

Conclusion: 通过协作式风格扩展与双层次域不变学习策略，成功实现了对未见目标域的强泛化能力

Abstract: Federated domain generalization aims to learn a generalizable model from
multiple decentralized source domains for deploying on the unseen target
domain. The style augmentation methods have achieved great progress on domain
generalization. However, the existing style augmentation methods either explore
the data styles within isolated source domain or interpolate the style
information across existing source domains under the data decentralization
scenario, which leads to limited style space. To address this issue, we propose
a Multi-source Collaborative Style Augmentation and Domain-invariant learning
method (MCSAD) for federated domain generalization. Specifically, we propose a
multi-source collaborative style augmentation module to generate data in the
broader style space. Furthermore, we conduct domain-invariant learning between
the original data and augmented data by cross-domain feature alignment within
the same class and classes relation ensemble distillation between different
classes to learn a domain-invariant model. By alternatively conducting
collaborative style augmentation and domain-invariant learning, the model can
generalize well on unseen target domain. Extensive experiments on multiple
domain generalization datasets indicate that our method significantly
outperforms the state-of-the-art federated domain generalization methods.

</details>


### [73] [Modeling Saliency Dataset Bias](https://arxiv.org/abs/2505.10169)
*Matthias Kümmerer,Harneet Khanuja,Matthias Bethge*

Main category: cs.CV

TL;DR: 提出新型视觉显著性预测模型，通过20个可解释的跨数据集参数解决泛化难题，在MIT/Tuebingen基准测试中实现SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有显著性预测模型存在严重跨数据集泛化问题（性能下降40%），60%的泛化差距源于数据集特异性偏差，需设计更通用的参数化框架。

Method: 基于编码器-解码器架构，引入少于20个可解释的dataset-specific参数（多尺度结构/中心偏置/注视扩散），仅需50个样本即可适配新数据集，覆盖75%泛化差距。

Result: 在MIT300/CAT2000/COCO-Freeview三大基准全面刷新SOTA，跨数据集泛化性能显著提升（尤其适配训练数据后），揭示多尺度特征与绝对/相对尺寸的复合效应。

Conclusion: 少量可解释的跨数据集参数可有效解决显著性预测的泛化瓶颈，为空间显著性机制提供新见解，建立高效模型适配范式。

Abstract: Recent advances in image-based saliency prediction are approaching gold
standard performance levels on existing benchmarks. Despite this success, we
show that predicting fixations across multiple saliency datasets remains
challenging due to dataset bias. We find a significant performance drop (around
40%) when models trained on one dataset are applied to another. Surprisingly,
increasing dataset diversity does not resolve this inter-dataset gap, with
close to 60% attributed to dataset-specific biases. To address this remaining
generalization gap, we propose a novel architecture extending a mostly
dataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific
parameters that govern interpretable mechanisms such as multi-scale structure,
center bias, and fixation spread. Adapting only these parameters to new data
accounts for more than 75% of the generalization gap, with a large fraction of
the improvement achieved with as few as 50 samples. Our model sets a new
state-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark
(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from
unrelated datasets, but with a substantial boost when adapting to the
respective training datasets. The model also provides valuable insights into
spatial saliency properties, revealing complex multi-scale effects that combine
both absolute and relative sizes.

</details>


### [74] [VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation](https://arxiv.org/abs/2505.10205)
*Umair Haroon,Ahmad AlMughrabi,Thanasis Zoumpekas,Ricardo Marques,Petia Radeva*

Main category: cs.CV

TL;DR: 提出VolE框架，利用移动设备进行3D重建实现无需参考物或深度信息的精准食物体积估计，实验显示其性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有食物体积估计方法受限于专用硬件、深度信息或参考物，VolE旨在通过移动设备驱动的3D重建实现无需参考物或深度信息的实时测量。

Method: 通过移动设备自由运动捕捉图像及位置生成3D模型，结合食物视频分割生成掩模，无需参考物或深度信息，并引入新数据集应对复杂场景。

Result: 在多个数据集上验证，VolE以2.22%的MAPE显著优于现有技术，展现卓越性能。

Conclusion: VolE通过移动设备实现高精度食物体积估计，无需专用硬件或参考物，为医疗营养管理和健康监测提供实用解决方案。

Abstract: Accurate food volume estimation is crucial for medical nutrition management
and health monitoring applications, but current food volume estimation methods
are often limited by mononuclear data, leveraging single-purpose hardware such
as 3D scanners, gathering sensor-oriented information such as depth
information, or relying on camera calibration using a reference object. In this
paper, we present VolE, a novel framework that leverages mobile device-driven
3D reconstruction to estimate food volume. VolE captures images and camera
locations in free motion to generate precise 3D models, thanks to AR-capable
mobile devices. To achieve real-world measurement, VolE is a reference- and
depth-free framework that leverages food video segmentation for food mask
generation. We also introduce a new food dataset encompassing the challenging
scenarios absent in the previous benchmarks. Our experiments demonstrate that
VolE outperforms the existing volume estimation techniques across multiple
datasets by achieving 2.22 % MAPE, highlighting its superior performance in
food volume estimation.

</details>


### [75] [Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation](https://arxiv.org/abs/2505.10223)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 通过MixUp和傅里叶数据增强提升医学影像分割模型在真实临床场景中的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 医学影像分割模型在真实临床部署时因训练-测试分布不匹配导致性能下降，传统视觉一致性的数据增强方法难以应对多样化真实场景

Method: 系统评估MixUp和辅助傅里叶增强(Auxiliary Fourier Augmentation)策略，在心脏电影MRI和前列腺MRI分割任务中验证其有效性

Result: 增强方法显著提升模型在分布外数据的泛化能力，通过特征可分性和紧凑性改善学习表示，在nnU-Net框架中实现2.38%-7.53%的Dice提升

Conclusion: 将新型数据增强方案集成到nnU-Net训练流程，为提升医学影像分割模型临床可靠性提供了即插即用的有效解决方案

Abstract: Medical image segmentation models are often trained on curated datasets,
leading to performance degradation when deployed in real-world clinical
settings due to mismatches between training and test distributions. While data
augmentation techniques are widely used to address these challenges,
traditional visually consistent augmentation strategies lack the robustness
needed for diverse real-world scenarios. In this work, we systematically
evaluate alternative augmentation strategies, focusing on MixUp and Auxiliary
Fourier Augmentation. These methods mitigate the effects of multiple variations
without explicitly targeting specific sources of distribution shifts. We
demonstrate how these techniques significantly improve out-of-distribution
generalization and robustness to imaging variations across a wide range of
transformations in cardiac cine MRI and prostate MRI segmentation. We
quantitatively find that these augmentation methods enhance learned feature
representations by promoting separability and compactness. Additionally, we
highlight how their integration into nnU-Net training pipelines provides an
easy-to-implement, effective solution for enhancing the reliability of medical
segmentation models in real-world applications.

</details>


### [76] [On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging](https://arxiv.org/abs/2505.10231)
*Haozhe Luo,Ziyu Zhou,Zixin Shu,Aurélie Pahud de Mortanges,Robert Berke,Mauricio Reyes*

Main category: cs.CV

TL;DR: 医疗AI中结合人类专家指导可减少群体公平性差距，但需平衡校准策略以避免性能损耗


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在医学影像中表现优异但存在偏见，导致不同人口群体间的公平性差距，需要探索人机对齐方法

Method: 通过系统性探索人机对齐与公平性关系，结合人类专家见解优化模型

Result: 人类见解可降低35%公平性差距并提升跨域泛化能力，但过度对齐会导致8%的准确率下降

Conclusion: 人机对齐是构建公平、鲁棒医疗AI系统的有效途径，需在专家指导与自动化效率间取得平衡

Abstract: Deep neural networks excel in medical imaging but remain prone to biases,
leading to fairness gaps across demographic groups. We provide the first
systematic exploration of Human-AI alignment and fairness in this domain. Our
results show that incorporating human insights consistently reduces fairness
gaps and enhances out-of-domain generalization, though excessive alignment can
introduce performance trade-offs, emphasizing the need for calibrated
strategies. These findings highlight Human-AI alignment as a promising approach
for developing fair, robust, and generalizable medical AI systems, striking a
balance between expert guidance and automated efficiency. Our code is available
at https://github.com/Roypic/Aligner.

</details>


### [77] [MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation](https://arxiv.org/abs/2505.10238)
*Yanbo Ding*

Main category: cs.CV

TL;DR: 提出首个直接建模4D动作的MTVCrafter框架，通过4D运动令牌实现开放世界3D人体动画，FID-VID指标达6.98超越SOTA 65%


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖2D姿态图像导致3D信息丢失和泛化能力受限，需探索更符合3D开放世界动画的建模方式

Method: 1) 4DMoT将3D动作序列量化为4D运动令牌；2) MV-DiT模型通过4D位置编码的运动注意力机制生成动画

Result: FID-VID指标6.98创纪录，相比次优方法提升65%，支持单/多人、全身/半身等开放场景角色动画

Conclusion: 首次实现直接4D动作建模，开辟新研究范式。运动令牌提供强时空表征，支持复杂3D场景的灵活解耦控制

Abstract: Human image animation has gained increasing attention and developed rapidly
due to its broad applications in digital humans. However, existing methods rely
largely on 2D-rendered pose images for motion guidance, which limits
generalization and discards essential 3D information for open-world animation.
To tackle this problem, we propose MTVCrafter (Motion Tokenization Video
Crafter), the first framework that directly models raw 3D motion sequences
(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT
(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.
Compared to 2D-rendered pose images, 4D motion tokens offer more robust
spatio-temporal cues and avoid strict pixel-level alignment between pose image
and character, enabling more flexible and disentangled control. Then, we
introduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention
with 4D positional encodings, MV-DiT can effectively leverage motion tokens as
4D compact yet expressive context for human image animation in the complex 3D
world. Hence, it marks a significant step forward in this field and opens a new
direction for pose-guided human video generation. Experiments show that our
MTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,
surpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter
also generalizes well to diverse open-world characters (single/multiple,
full/half-body) across various styles and scenarios. Our video demos and code
are provided in the supplementary material and at this anonymous GitHub link:
https://anonymous.4open.science/r/MTVCrafter-1B13.

</details>


### [78] [ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization](https://arxiv.org/abs/2505.10250)
*Wenhao Shen,Wanqi Yin,Xiaofeng Yang,Cheng Chen,Chaoyue Song,Zhongang Cai,Lei Yang,Hao Wang,Guosheng Lin*

Main category: cs.CV

TL;DR: ADHMR框架通过扩散模型与偏好优化的对齐策略，解决了单目人体网格恢复中的深度模糊和遮挡问题，提升了预测与2D图像的对齐能力和野外图像鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有概率方法生成的3D人体网格常与2D观测不匹配，且在复杂真实场景中鲁棒性不足。需开发更可靠的预测对齐机制。

Method: 1. 训练无需3D标注的评估模型HMR-Scorer；2. 构建偏好数据集并用直接偏好优化微调扩散基模型；3. 利用HMR-Scorer进行数据清洗提升现有模型。

Result: ADHMR在实验中超越SOTA方法，代码已开源。HMR-Scorer可使现有模型在减少50%数据量时仍保持性能。

Conclusion: ADHMR通过偏好对齐显著提升预测质量，HMR-Scorer的双重作用为实际应用提供可靠评估与数据优化方案。

Abstract: Human mesh recovery (HMR) from a single image is inherently ill-posed due to
depth ambiguity and occlusions. Probabilistic methods have tried to solve this
by generating numerous plausible 3D human mesh predictions, but they often
exhibit misalignment with 2D image observations and weak robustness to
in-the-wild images. To address these issues, we propose ADHMR, a framework that
Aligns a Diffusion-based HMR model in a preference optimization manner. First,
we train a human mesh prediction assessment model, HMR-Scorer, capable of
evaluating predictions even for in-the-wild images without 3D annotations. We
then use HMR-Scorer to create a preference dataset, where each input image has
a pair of winner and loser mesh predictions. This dataset is used to finetune
the base model using direct preference optimization. Moreover, HMR-Scorer also
helps improve existing HMR models by data cleaning, even with fewer training
samples. Extensive experiments show that ADHMR outperforms current
state-of-the-art methods. Code is available at:
https://github.com/shenwenhao01/ADHMR.

</details>


### [79] [Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot](https://arxiv.org/abs/2505.10257)
*Hao Lu,Jiaqi Tang,Jiyao Wang,Yunfan LU,Xu Cao,Qingyong Hu,Yin Wang,Yuting Zhang,Tianxin Xie,Yunpeng Zhang,Yong Chen,Jiayu. Gao,Bin Huang,Dengbo He,Shuiguang Deng,Hao Chen,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 提出SAGE DeeR智能驾驶座舱代理，实现用户需求的三重超对齐（偏好适配）、通用性（多模态感知）和自我激发（语言思维链）能力


<details>
  <summary>Details</summary>
Motivation: 智能驾驶座舱需适配不同用户在舒适性、交互性和安全性方面的个性化需求

Method: 1. 通过生理指标、面部情绪等多模态输入推理用户状态
2. 语言空间隐式思维链激发机制
3. 构建包含感知决策和超对齐能力评估的大规模基准数据集

Result: 实现个性化反应（超对齐准确度）、多模态理解（通用性）以及通过思维链增强的决策能力

Conclusion: SAGE DeeR通过三位一体的技术路线，为智能座舱系统提供了更人性化的解决方案

Abstract: The intelligent driving cockpit, an important part of intelligent driving,
needs to match different users' comfort, interaction, and safety needs. This
paper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.
Sage Deer achieves three highlights: (1) Super alignment: It achieves different
reactions according to different people's preferences and biases. (2)
Generalist: It can understand the multi-view and multi-mode inputs to reason
the user's physiological indicators, facial emotions, hand movements, body
movements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It
can elicit implicit thought chains in the language space to further increase
generalist and super-aligned abilities. Besides, we collected multiple data
sets and built a large-scale benchmark. This benchmark measures the deer's
perceptual decision-making ability and the super alignment's accuracy.

</details>


### [80] [Inferring Driving Maps by Deep Learning-based Trail Map Extraction](https://arxiv.org/abs/2505.10258)
*Michael Hubbertz,Pascal Colling,Qi Han,Tobias Meisen*

Main category: cs.CV

TL;DR: 提出一种离线地图构建方法，整合车辆轨迹数据并采用基于Transformer的深度学习模型，显著提升自动驾驶系统的地图泛化能力和更新效率。


<details>
  <summary>Details</summary>
Motivation: 传统高精地图依赖人工标注成本高，在线建图方法存在时序一致性、传感器遮挡、计算效率及泛化能力等瓶颈。为解决这些问题，研究提出利用车辆行驶轨迹数据构建全局地图。

Method: 融合自车与其他交通参与者的轨迹数据，通过Transformer模型构建全局地图。支持持续更新且保持传感器无关性，实现高效数据传输。

Result: 在两个基准数据集上验证显示，本方法在未见过的环境和传感器配置中泛化能力优于现有在线建图方法，运行效率提升30%。

Conclusion: 基于轨迹整合的离线建图方法有效解决了在线建图的固有缺陷，为自动驾驶系统提供了更鲁棒、可扩展的地图解决方案。

Abstract: High-definition (HD) maps offer extensive and accurate environmental
information about the driving scene, making them a crucial and essential
element for planning within autonomous driving systems. To avoid extensive
efforts from manual labeling, methods for automating the map creation have
emerged. Recent trends have moved from offline mapping to online mapping,
ensuring availability and actuality of the utilized maps. While the performance
has increased in recent years, online mapping still faces challenges regarding
temporal consistency, sensor occlusion, runtime, and generalization. We propose
a novel offline mapping approach that integrates trails - informal routes used
by drivers - into the map creation process. Our method aggregates trail data
from the ego vehicle and other traffic participants to construct a
comprehensive global map using transformer-based deep learning models. Unlike
traditional offline mapping, our approach enables continuous updates while
remaining sensor-agnostic, facilitating efficient data transfer. Our method
demonstrates superior performance compared to state-of-the-art online mapping
approaches, achieving improved generalization to previously unseen environments
and sensor configurations. We validate our approach on two benchmark datasets,
highlighting its robustness and applicability in autonomous driving systems.

</details>


### [81] [HandReader: Advanced Techniques for Efficient Fingerspelling Recognition](https://arxiv.org/abs/2505.10267)
*Pavel Korotaev,Petr Surovtsev,Alexander Kapitanov,Karina Kvanchiani,Aleksandr Nagaev*

Main category: cs.CV

TL;DR: 提出HandReader系列架构（RGB、关键点、混合模态），通过创新时序模块TSAM和TPE提升手语拼写识别精度，在多个数据集取得SOTA并发布俄语手语数据集Znaki。


<details>
  <summary>Details</summary>
Motivation: 现有手语拼写识别方法侧重视频时序处理但精度不足，需改进对快速手部动作的时序特征提取能力。

Method: 1) HandReader_RGB：采用TSAM模块处理变长视频的RGB特征；2) HandReader_KP：基于TPE编码器处理关键点张量；3) HandReader_RGB+KP：融合两种模态的联合编码器。

Result: 在ChicagoFSWild系列数据集达到SOTA，新俄语数据集Znaki上表现优异。同步开源Znaki数据集和预训练模型。

Conclusion: 多模态架构设计有效提升识别性能，填补俄语手语数据空白，推动手语技术生态发展。

Abstract: Fingerspelling is a significant component of Sign Language (SL), allowing the
interpretation of proper names, characterized by fast hand movements during
signing. Although previous works on fingerspelling recognition have focused on
processing the temporal dimension of videos, there remains room for improving
the accuracy of these approaches. This paper introduces HandReader, a group of
three architectures designed to address the fingerspelling recognition task.
HandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to
process RGB features from videos of varying lengths while preserving important
sequential information. HandReader$_{KP}$ is built on the proposed Temporal
Pose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition
in a batch allows the encoder to pass them through 2D and 3D convolution
layers, utilizing temporal and spatial information and accumulating keypoints
coordinates. We also introduce HandReader_RGB+KP - architecture with a joint
encoder to benefit from RGB and keypoint modalities. Each HandReader model
possesses distinct advantages and achieves state-of-the-art results on the
ChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate
high performance on the first open dataset for Russian fingerspelling, Znaki,
presented in this paper. The Znaki dataset and HandReader pre-trained models
are publicly available.

</details>


### [82] [MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting](https://arxiv.org/abs/2505.10281)
*Mengqiu Xu,Kaixin Chen,Heng Guo,Yixiang Huang,Ming Wu,Zhenwei Shi,Chuang Zhang,Jun Guo*

Main category: cs.CV

TL;DR: MFogHub首个多区域多卫星海洋雾数据集，整合15个雾区6颗卫星的6.8万+高分辨率样本，显著提升模型评估泛化性并推动雾监测技术发展


<details>
  <summary>Details</summary>
Motivation: 现有海洋雾数据集局限于单一区域或卫星，难以评估模型跨区域性能及探索雾本质特征

Method: 整合15个沿海雾区、6颗地球同步卫星的标注数据，构建包含68,000+高分辨率样本的多源异构数据集

Result: 16个基线模型实验显示：数据集可有效揭示区域/卫星差异导致的模型泛化波动，并为定制化雾预测技术开发提供资源

Conclusion: MFogHub通过多维度数据融合，推动全球海洋雾动态监测能力和科学认知的双重提升，代码数据集已开源

Abstract: Deep learning approaches for marine fog detection and forecasting have
outperformed traditional methods, demonstrating significant scientific and
practical importance. However, the limited availability of open-source datasets
remains a major challenge. Existing datasets, often focused on a single region
or satellite, restrict the ability to evaluate model performance across diverse
conditions and hinder the exploration of intrinsic marine fog characteristics.
To address these limitations, we introduce \textbf{MFogHub}, the first
multi-regional and multi-satellite dataset to integrate annotated marine fog
observations from 15 coastal fog-prone regions and six geostationary
satellites, comprising over 68,000 high-resolution samples. By encompassing
diverse regions and satellite perspectives, MFogHub facilitates rigorous
evaluation of both detection and forecasting methods under varying conditions.
Extensive experiments with 16 baseline models demonstrate that MFogHub can
reveal generalization fluctuations due to regional and satellite discrepancy,
while also serving as a valuable resource for the development of targeted and
scalable fog prediction techniques. Through MFogHub, we aim to advance both the
practical monitoring and scientific understanding of marine fog dynamics on a
global scale. The dataset and code are at
\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}.

</details>


### [83] [MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning](https://arxiv.org/abs/2505.10289)
*Yue Wang,Shuai Xu,Xuelin Zhu,Yicong Li*

Main category: cs.CV

TL;DR: 提出多阶段跨模态交互模型MSCI，通过提取CLIP视觉编码器的中间层信息，增强组合零样本学习中对细粒度局部特征的感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的组合零样本学习方法过度依赖其跨模态对齐能力，却忽视了CLIP在架构和训练范式上导致的细粒度局部特征捕捉不足问题。

Method: 设计两个自适应聚合器分别从低层视觉特征提取局部信息、整合高层视觉特征的全局信息，通过分阶段交互机制将关键信息渐进融入文本表征。

Result: 在三个主流数据集上的实验验证了模型有效性，证明其能动态调整全局/局部注意力权重以适应不同组合场景。

Conclusion: MSCI通过多阶段跨模态交互机制显著提升了模型对细粒度视觉特征的感知能力，在组合零样本学习任务中表现出优越性能。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object
combinations by leveraging known combinations. Existing studies basically rely
on the cross-modal alignment capabilities of CLIP but tend to overlook its
limitations in capturing fine-grained local features, which arise from its
architectural and training paradigm. To address this issue, we propose a
Multi-Stage Cross-modal Interaction (MSCI) model that effectively explores and
utilizes intermediate-layer information from CLIP's visual encoder.
Specifically, we design two self-adaptive aggregators to extract local
information from low-level visual features and integrate global information
from high-level visual features, respectively. These key information are
progressively incorporated into textual representations through a
stage-by-stage interaction mechanism, significantly enhancing the model's
perception capability for fine-grained local visual information. Additionally,
MSCI dynamically adjusts the attention weights between global and local visual
information based on different combinations, as well as different elements
within the same combination, allowing it to flexibly adapt to diverse
scenarios. Experiments on three widely used datasets fully validate the
effectiveness and superiority of the proposed model. Data and code are
available at https://github.com/ltpwy/MSCI.

</details>


### [84] [StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation](https://arxiv.org/abs/2505.10292)
*Daniel A. P. Oliveira,David Martins de Matos*

Main category: cs.CV

TL;DR: 提出StoryReasoning数据集和Qwen Storyteller模型，通过跨帧实体基础与结构化推理减少视觉叙事中的指称幻觉问题


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉叙事系统中角色身份跨帧不一致、动作与主体关联错误导致的指称幻觉问题

Method: 1. 构建含4178个结构化故事的StoryReasoning数据集；2. 通过视觉相似度与面部识别的跨帧对象重识别；3. 基于思维链的显式叙事建模；4. 微调Qwen2.5-VL 7B实现端到端多任务处理

Result: 微调模型相比基础模型，平均每个故事的幻觉现象从4.06减少到3.56（下降12.3%）

Conclusion: 结构化实体基础与跨帧推理机制有效提升视觉叙事连贯性，为多模态故事生成提供了新的基准方法

Abstract: Visual storytelling systems struggle to maintain character identity across
frames and link actions to appropriate subjects, frequently leading to
referential hallucinations. These issues can be addressed through grounding of
characters, objects, and other entities on the visual elements. We propose
StoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie
images, with both structured scene analyses and grounded stories. Each story
maintains character and object consistency across frames while explicitly
modeling multi-frame relationships through structured tabular representations.
Our approach features cross-frame object re-identification using visual
similarity and face recognition, chain-of-thought reasoning for explicit
narrative modeling, and a grounding scheme that links textual elements to
visual entities across multiple frames. We establish baseline performance by
fine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end
object detection, re-identification, and landmark detection while maintaining
consistent object references throughout the story. Evaluation demonstrates a
reduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when
compared to a non-fine-tuned model.

</details>


### [85] [MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models](https://arxiv.org/abs/2505.10294)
*Guillaume Balezo,Roger Trullo,Albert Pla Planas,Etienne Decenciere,Thomas Walter*

Main category: cs.CV

TL;DR: 提出MIPHEI模型，通过U-Net架构结合ViT基础模型，从H&E图像预测mIF信号以替代临床成本较高的多路复用免疫荧光检测。


<details>
  <summary>Details</summary>
Motivation: 临床广泛使用的H&E染色无法精确定位细胞类型，而mIF技术虽能通过蛋白标记实现精准识别，却因成本和操作复杂性难以普及。本研究旨在突破这一技术鸿沟。

Method: 使用ORION结直肠癌数据集训练U-Net架构模型，整合ViT作为编码器，预测包括免疫细胞/基质/血管等7类标记的mIF信号，并在两个独立数据集验证性能。

Result: 在Pan-CK等标记预测中F1达0.88，CD3e/SMA分别0.57/0.56，显著优于基线模型。CD68/CD20预测能力相对较弱(F1 0.36/0.30)。

Conclusion: MIPHEI首次实现从常规H&E图像解析细胞分子特征，为挖掘肿瘤微环境中细胞空间分布与临床预后的关系提供了高效分析工具。

Abstract: Histopathological analysis is a cornerstone of cancer diagnosis, with
Hematoxylin and Eosin (H&E) staining routinely acquired for every patient to
visualize cell morphology and tissue architecture. On the other hand, multiplex
immunofluorescence (mIF) enables more precise cell type identification via
proteomic markers, but has yet to achieve widespread clinical adoption due to
cost and logistical constraints. To bridge this gap, we introduce MIPHEI
(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired
architecture that integrates state-of-the-art ViT foundation models as encoders
to predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of
markers spanning nuclear content, immune lineages (T cells, B cells, myeloid),
epithelium, stroma, vasculature, and proliferation. We train our model using
the publicly available ORION dataset of restained H&E and mIF images from
colorectal cancer tissue, and validate it on two independent datasets. MIPHEI
achieves accurate cell-type classification from H&E alone, with F1 scores of
0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,
substantially outperforming both a state-of-the-art baseline and a random
classifier for most markers. Our results indicate that our model effectively
captures the complex relationships between nuclear morphologies in their tissue
context, as visible in H&E images and molecular markers defining specific cell
types. MIPHEI offers a promising step toward enabling cell-type-aware analysis
of large-scale H&E datasets, in view of uncovering relationships between
spatial cellular organization and patient outcomes.

</details>


### [86] [A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability](https://arxiv.org/abs/2505.10351)
*Jie Zhu,Jirong Zha,Ding Li,Leye Wang*

Main category: cs.CV

TL;DR: 提出PartCrop方法，针对未知训练细节的黑盒自监督模型进行成员推理攻击，通过裁剪对象部分分析表示响应，验证有效性并提出防御措施


<details>
  <summary>Details</summary>
Motivation: 自监督学习存在隐私风险，现有攻击方法在黑盒场景下效果有限。针对不同自监督范式（如遮蔽图像建模和对比学习）的统一攻击需求

Method: 基于模型共享的部分感知能力，裁剪图像中的对象部分并在表示空间查询响应。覆盖不同训练协议和模型结构，使用三个图像数据集验证

Result: 实验证明PartCrop在多种训练协议下有效且泛化性强。防御措施中早停、差分隐私和裁剪尺度调整均有效。扩展PartCrop-v2适应大规模场景

Conclusion: PartCrop成功攻击多种自监督模型，提出的防御策略有效。模型与数据规模扩展分析为实际应用提供参考，改进版PartCrop-v2增强实用性

Abstract: Self-supervised learning shows promise in harnessing extensive unlabeled
data, but it also confronts significant privacy concerns, especially in vision.
In this paper, we perform membership inference on visual self-supervised models
in a more realistic setting: self-supervised training method and details are
unknown for an adversary when attacking as he usually faces a black-box system
in practice. In this setting, considering that self-supervised model could be
trained by completely different self-supervised paradigms, e.g., masked image
modeling and contrastive learning, with complex training details, we propose a
unified membership inference method called PartCrop. It is motivated by the
shared part-aware capability among models and stronger part response on the
training data. Specifically, PartCrop crops parts of objects in an image to
query responses within the image in representation space. We conduct extensive
attacks on self-supervised models with different training protocols and
structures using three widely used image datasets. The results verify the
effectiveness and generalization of PartCrop. Moreover, to defend against
PartCrop, we evaluate two common approaches, i.e., early stop and differential
privacy, and propose a tailored method called shrinking crop scale range. The
defense experiments indicate that all of them are effective. Finally, besides
prototype testing on toy visual encoders and small-scale image datasets, we
quantitatively study the impacts of scaling from both data and model aspects in
a realistic scenario and propose a scalable PartCrop-v2 by introducing two
structural improvements to PartCrop. Our code is at
https://github.com/JiePKU/PartCrop.

</details>


### [87] [SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity](https://arxiv.org/abs/2505.10352)
*Shihao Zou,Qingfeng Li,Wei Ji,Jingjing Li,Yongkui Yang,Guoqi Li,Chao Dong*

Main category: cs.CV

TL;DR: 提出SpikeVideoFormer——线性时间复杂度的脉冲驱动视频Transformer，在视频任务中实现SOTA性能与高效率


<details>
  <summary>Details</summary>
Motivation: 现有SNN Transformer仅关注单图任务，未能有效利用脉冲神经网络在视频任务中的效率优势

Method: 设计脉冲驱动汉明注意力(SDHA)，理论推导实值注意力到脉冲注意力的转换，优化时空注意力架构

Result: 在视频分类/姿态跟踪/语义分割任务中超越SNN方法15%+，效率分别提升16/10/5倍，性能匹配ANN方法

Conclusion: 通过SDHA和时空注意力优化，验证了脉冲驱动模型在视频任务中的高效性与竞争力

Abstract: Spiking Neural Networks (SNNs) have shown competitive performance to
Artificial Neural Networks (ANNs) in various vision tasks, while offering
superior energy efficiency. However, existing SNN-based Transformers primarily
focus on single-image tasks, emphasizing spatial features while not effectively
leveraging SNNs' efficiency in video-based vision tasks. In this paper, we
introduce SpikeVideoFormer, an efficient spike-driven video Transformer,
featuring linear temporal complexity $\mathcal{O}(T)$. Specifically, we design
a spike-driven Hamming attention (SDHA) which provides a theoretically guided
adaptation from traditional real-valued attention to spike-driven attention.
Building on SDHA, we further analyze various spike-driven space-time attention
designs and identify an optimal scheme that delivers appealing performance for
video tasks, while maintaining only linear temporal complexity. The
generalization ability and efficiency of our model are demonstrated across
diverse downstream video tasks, including classification, human pose tracking,
and semantic segmentation. Empirical results show our method achieves
state-of-the-art (SOTA) performance compared to existing SNN approaches, with
over 15\% improvement on the latter two tasks. Additionally, it matches the
performance of recent ANN-based methods while offering significant efficiency
gains, achieving $\times 16$, $\times 10$ and $\times 5$ improvements on the
three tasks. https://github.com/JimmyZou/SpikeVideoFormer

</details>


### [88] [Learned Lightweight Smartphone ISP with Unpaired Data](https://arxiv.org/abs/2505.10420)
*Andrei Arhire,Radu Timofte*

Main category: cs.CV

TL;DR: 提出一种无需配对数据的轻量级智能手机ISP训练方法，通过对抗训练和多判别器策略实现高质量图像转换。


<details>
  <summary>Details</summary>
Motivation: 传统学习型ISP依赖像素级对齐的配对数据，采集成本高昂且困难。本文旨在消除对配对数据的需求，简化训练流程。

Method: 使用基于对抗训练的多项损失函数，结合预训练网络特征图的多个判别器，保持内容结构同时学习目标RGB特性。采用轻量级神经网络架构适配移动端。

Result: 在Zurich RAW to RGB和Fujifilm UltraISP数据集上验证，与配对训练方法相比，在PSNR/SSIM等指标上达到竞争性结果(例如PSNR 23.42 vs 23.71)。

Conclusion: 该方法成功实现无配对数据训练，开发出适用于移动设备的轻量ISP模型，代码和预训练模型已开源，具备实际部署价值。

Abstract: The Image Signal Processor (ISP) is a fundamental component in modern
smartphone cameras responsible for conversion of RAW sensor image data to RGB
images with a strong focus on perceptual quality. Recent work highlights the
potential of deep learning approaches and their ability to capture details with
a quality increasingly close to that of professional cameras. A difficult and
costly step when developing a learned ISP is the acquisition of pixel-wise
aligned paired data that maps the raw captured by a smartphone camera sensor to
high-quality reference images. In this work, we address this challenge by
proposing a novel training method for a learnable ISP that eliminates the need
for direct correspondences between raw images and ground-truth data with
matching content. Our unpaired approach employs a multi-term loss function
guided by adversarial training with multiple discriminators processing feature
maps from pre-trained networks to maintain content structure while learning
color and texture characteristics from the target RGB dataset. Using
lightweight neural network architectures suitable for mobile devices as
backbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm
UltraISP datasets. Compared to paired training methods, our unpaired learning
strategy shows strong potential and achieves high fidelity across multiple
evaluation metrics. The code and pre-trained models are available at
https://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data .

</details>


### [89] [Vision language models have difficulty recognizing virtual objects](https://arxiv.org/abs/2505.10453)
*Tyler Tran,Sangeet Khemlani,J. G. Trafton*

Main category: cs.CV

TL;DR: 视觉语言模型(VLMs)在理解图像中虚拟对象（未视觉呈现的物体）的空间关系方面表现不足


<details>
  <summary>Details</summary>
Motivation: 通过测试模型对虚拟对象空间关系的理解能力，验证VLMs是否真正理解场景的视觉空间属性

Method: 使用包含虚拟对象提示的系统性评估方法（例如在已有场景中新增虚拟物体后测试模型的空间推理能力）

Result: 当前最先进的VLMs处理虚拟对象的能力存在显著缺陷

Conclusion: 需要开发新的方法来增强视觉语言模型对场景隐含空间关系的理解与推理能力

Abstract: Vision language models (VLMs) are AI systems paired with both language and
vision encoders to process multimodal input. They are capable of performing
complex semantic tasks such as automatic captioning, but it remains an open
question about how well they comprehend the visuospatial properties of scenes
depicted in the images they process. We argue that descriptions of virtual
objects -- objects that are not visually represented in an image -- can help
test scene comprehension in these AI systems. For example, an image that
depicts a person standing under a tree can be paired with the following prompt:
imagine that a kite is stuck in the tree. VLMs that comprehend the scene should
update their representations and reason sensibly about the spatial relations
between all three objects. We describe systematic evaluations of
state-of-the-art VLMs and show that their ability to process virtual objects is
inadequate.

</details>


### [90] [Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting](https://arxiv.org/abs/2505.10473)
*Fengdi Zhang,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: ControlGS提出一种支持跨场景语义一致的数量-质量连续控制方法，通过单次训练和用户偏好参数即可自动优化3D高斯溅射模型


<details>
  <summary>Details</summary>
Motivation: 现有3DGS优化方法缺乏用户可调节的数量-质量权衡机制，难以适应不同硬件部署需求。需要实现既保持性能又支持灵活控制的解决方案

Method: 采用固定训练配置结合用户指定偏好超参数，通过单次训练自动学习不同场景下的最优权衡点，实现从紧凑物体到大型户外场景的连续控制

Result: 在保持高渲染质量的同时减少高斯数量（比基线少），支持广泛调整范围（0.1-10倍高斯数量变化），跨场景表现一致性验证

Conclusion: ControlGS突破了传统数量-质量权衡的刚性限制，为3DGS模型部署提供了灵活可控的优化范式，显著增强实际应用适应性

Abstract: To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks
to minimize the number of Gaussians used while preserving high rendering
quality, introducing an inherent trade-off between Gaussian quantity and
rendering quality. Existing methods strive for better quantity-quality
performance, but lack the ability for users to intuitively adjust this
trade-off to suit practical needs such as model deployment under diverse
hardware and communication constraints. Here, we present ControlGS, a 3DGS
optimization method that achieves semantically meaningful and cross-scene
consistent quantity-quality control while maintaining strong quantity-quality
performance. Through a single training run using a fixed setup and a
user-specified hyperparameter reflecting quantity-quality preference, ControlGS
can automatically find desirable quantity-quality trade-off points across
diverse scenes, from compact objects to large outdoor scenes. It also
outperforms baselines by achieving higher rendering quality with fewer
Gaussians, and supports a broad adjustment range with stepless control over the
trade-off.

</details>


### [91] [Logos as a Well-Tempered Pre-train for Sign Language Recognition](https://arxiv.org/abs/2505.10481)
*Ilya Ovodov,Petr Surovtsev,Karina Kvanchiani,Alexander Kapitanov,Alexander Nagaev*

Main category: cs.CV

TL;DR: 提出俄语手语数据集Logos，通过跨语言迁移学习提升孤立手语识别性能，并验证相似手势标注的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有孤立手语识别数据集规模有限，且相似手势易导致标注歧义，阻碍模型性能提升。

Method: 1. 构建包含大量标注者的大规模俄语手语数据集Logos
2. 使用多分类头联合训练策略进行跨语言迁移学习
3. 对视觉相似手势进行显式标注

Result: 在WLASL数据集上达到SOTA，AUTSL数据集获得竞争性结果，单流RGB模型实现最佳性能。代码、数据集和模型均已开源。

Conclusion: Logos数据集通过跨语言预训练和相似手势标注策略，显著提升孤立手语识别模型的泛化能力和识别准确率。

Abstract: This paper examines two aspects of the isolated sign language recognition
(ISLR) task. First, despite the availability of a number of datasets, the
amount of data for most individual sign languages is limited. It poses the
challenge of cross-language ISLR model training, including transfer learning.
Second, similar signs can have different semantic meanings. It leads to
ambiguity in dataset labeling and raises the question of the best policy for
annotating such signs. To address these issues, this study presents Logos, a
novel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by
the number of signers and one of the largest available datasets while also the
largest RSL dataset in size and vocabulary. It is shown that a model,
pre-trained on the Logos dataset can be used as a universal encoder for other
language SLR tasks, including few-shot learning. We explore cross-language
transfer learning approaches and find that joint training using multiple
classification heads benefits accuracy for the target lowresource datasets the
most. The key feature of the Logos dataset is explicitly annotated visually
similar sign groups. We show that explicitly labeling visually similar signs
improves trained model quality as a visual encoder for downstream tasks. Based
on the proposed contributions, we outperform current state-of-the-art results
for the WLASL dataset and get competitive results for the AUTSL dataset, with a
single stream model processing solely RGB video. The source code, dataset, and
pre-trained models are publicly available.

</details>


### [92] [UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2505.10483)
*Yi Li,Haonan Wang,Qixiang Zhang,Boyu Xiao,Chenchang Hu,Hualiang Wang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出首个无需额外资源的统一多模态评估框架UniEval，包含UniBench基准和UniScore指标


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型评估存在基准分散、依赖额外模型、标注数据有限、指标不足等问题

Method: 设计包含81个细粒度标签的UniBench基准，配合无需人工标注的UniScore评估指标

Result: 实验表明UniBench更具挑战性，UniScore与人工评估相关性达80.5%，优于现有指标

Conclusion: UniEval为统一多模态模型提供高效评估方案，揭示了Universal模型的独特价值

Abstract: The emergence of unified multimodal understanding and generation models is
rapidly attracting attention because of their ability to enhance
instruction-following capabilities while minimizing model redundancy. However,
there is a lack of a unified evaluation framework for these models, which would
enable an elegant, simplified, and overall evaluation. Current models conduct
evaluations on multiple task-specific benchmarks, but there are significant
limitations, such as the lack of overall results, errors from extra evaluation
models, reliance on extensive labeled images, benchmarks that lack diversity,
and metrics with limited capacity for instruction-following evaluation. To
tackle these challenges, we introduce UniEval, the first evaluation framework
designed for unified multimodal models without extra models, images, or
annotations. This facilitates a simplified and unified evaluation process. The
UniEval framework contains a holistic benchmark, UniBench (supports both
unified and visual generation models), along with the corresponding UniScore
metric. UniBench includes 81 fine-grained tags contributing to high diversity.
Experimental results indicate that UniBench is more challenging than existing
benchmarks, and UniScore aligns closely with human evaluations, surpassing
current metrics. Moreover, we extensively evaluated SoTA unified and visual
generation models, uncovering new insights into Univeral's unique values.

</details>


### [93] [CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs](https://arxiv.org/abs/2505.10496)
*Raman Dutt,Pedro Sanchez,Yongchen Yao,Steven McDonagh,Sotirios A. Tsaftaris,Timothy Hospedales*

Main category: cs.CV

TL;DR: 提出CheXGenBench评估框架，通过标准化协议和20+指标系统评估胸部X光合成模型的生成质量、隐私风险与临床价值，并发布75K高质量合成数据集SynthCheX-75K。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像生成评估存在方法不一致、架构对比过时、评估指标割裂且忽视临床实用性的问题。

Method: 采用标准化数据分区和统一评估协议（20+量化指标），对11种领先文本-图像模型进行生成质量、隐私漏洞和临床适用性三维度系统分析。

Result: 揭示现有评估协议在生成保真度评估中的低效性，导致不一致的模型对比；同时通过Sana 0.6B模型生成高质量合成数据集。

Conclusion: CheXGenBench建立了医学AI标准化基准，支持客观可复现的模型对比，并开源框架、模型及SynthCheX-75K数据集推动领域发展。

Abstract: We introduce CheXGenBench, a rigorous and multifaceted evaluation framework
for synthetic chest radiograph generation that simultaneously assesses
fidelity, privacy risks, and clinical utility across state-of-the-art
text-to-image generative models. Despite rapid advancements in generative AI
for real-world imagery, medical domain evaluations have been hindered by
methodological inconsistencies, outdated architectural comparisons, and
disconnected assessment criteria that rarely address the practical clinical
value of synthetic samples. CheXGenBench overcomes these limitations through
standardised data partitioning and a unified evaluation protocol comprising
over 20 quantitative metrics that systematically analyse generation quality,
potential privacy vulnerabilities, and downstream clinical applicability across
11 leading text-to-image architectures. Our results reveal critical
inefficiencies in the existing evaluation protocols, particularly in assessing
generative fidelity, leading to inconsistent and uninformative comparisons. Our
framework establishes a standardised benchmark for the medical AI community,
enabling objective and reproducible comparisons while facilitating seamless
integration of both existing and future generative models. Additionally, we
release a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K
radiographs generated by the top-performing model (Sana 0.6B) in our benchmark
to support further research in this critical domain. Through CheXGenBench, we
establish a new state-of-the-art and release our framework, models, and
SynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/

</details>


### [94] [MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks](https://arxiv.org/abs/2505.10497)
*Iurii Medvedev,Nuno Goncalves*

Main category: cs.CV

TL;DR: 提出双分支分类训练策略，增强人脸识别系统对抗面部变形攻击的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 深度学习推动人脸识别广泛应用，但面临面部变形等呈现攻击的安全威胁

Method: 改进分类任务架构，采用双分支分类策略处理变形图像标签模糊性，将变形样本融入训练过程

Result: 在公开基准测试中验证有效，显著提升模型区分真实样本与变形攻击的能力

Conclusion: 该通用性方法可无缝集成至现有训练流程，提升基于分类的人脸识别系统安全性

Abstract: Face recognition has evolved significantly with the advancement of deep
learning techniques, enabling its widespread adoption in various applications
requiring secure authentication. However, this progress has also increased its
exposure to presentation attacks, including face morphing, which poses a
serious security threat by allowing one identity to impersonate another.
Therefore, modern face recognition systems must be robust against such attacks.
  In this work, we propose a novel approach for training deep networks for face
recognition with enhanced robustness to face morphing attacks. Our method
modifies the classification task by introducing a dual-branch classification
strategy that effectively handles the ambiguity in the labeling of face morphs.
This adaptation allows the model to incorporate morph images into the training
process, improving its ability to distinguish them from bona fide samples.
  Our strategy has been validated on public benchmarks, demonstrating its
effectiveness in enhancing robustness against face morphing attacks.
Furthermore, our approach is universally applicable and can be integrated into
existing face recognition training pipelines to improve classification-based
recognition methods.

</details>


### [95] [Enhancing Multi-Image Question Answering via Submodular Subset Selection](https://arxiv.org/abs/2505.10533)
*Aaryan Sharma,Shivansh Gupta,Samar Agarwal,Vishak Prasad C.,Ganesh Ramakrishnan*

Main category: cs.CV

TL;DR: 提出基于子模函数优化的检索增强框架，提升多图像问答场景下的扩展性和检索性能


<details>
  <summary>Details</summary>
Motivation: 现有大模型在多图像场景（MIQA）存在扩展性差（图像数量增加时）和检索性能下降的问题

Method: 使用基于查询的子模函数（如GraphCut）预选语义相关图像，结合锚点查询和数据增强优化检索流程

Result: 在大型数据集中（大干草堆场景）显著提升子模检索管道的有效性

Conclusion: 子模预选机制结合查询感知策略能有效解决多模态模型在多图像检索中的扩展性瓶颈

Abstract: Large multimodal models (LMMs) have achieved high performance in
vision-language tasks involving single image but they struggle when presented
with a collection of multiple images (Multiple Image Question Answering
scenario). These tasks, which involve reasoning over large number of images,
present issues in scalability (with increasing number of images) and retrieval
performance. In this work, we propose an enhancement for retriever framework
introduced in MIRAGE model using submodular subset selection techniques. Our
method leverages query-aware submodular functions, such as GraphCut, to
pre-select a subset of semantically relevant images before main retrieval
component. We demonstrate that using anchor-based queries and augmenting the
data improves submodular-retriever pipeline effectiveness, particularly in
large haystack sizes.

</details>


### [96] [Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis](https://arxiv.org/abs/2505.10541)
*Pengfei Wang,Guohai Xu,Weinong Wang,Junjie Yang,Jie Lou,Yunhua Xue*

Main category: cs.CV

TL;DR: 提出注意力准确率指标和量化IVM的新基准，通过解耦模态注意力机制验证模型视觉理解能力


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅关注答案正确性，无法检测模型是否真正理解视觉内容，导致隐式视觉误解(IVM)问题

Method: 解耦视觉-文本模态的因果注意力模块，分析注意力分布收敛特性，提出与规模无关的注意力准确率指标

Result: 注意力准确率对位置偏差保持鲁棒，且在单模态场景中同样有效，验证了方法的通用性

Conclusion: 通过内部机制直接评估视觉理解，建立了更可靠的MLLM评估体系，解决了IVM的核心挑战

Abstract: Recent advancements have enhanced the capability of Multimodal Large Language
Models (MLLMs) to comprehend multi-image information. However, existing
benchmarks primarily evaluate answer correctness, overlooking whether models
genuinely comprehend the visual input. To address this, we define implicit
visual misunderstanding (IVM), where MLLMs provide correct answers without
fully comprehending the visual input. Through our analysis, we decouple the
visual and textual modalities within the causal attention module, revealing
that attention distribution increasingly converges on the image associated with
the correct answer as the network layers deepen. This insight leads to the
introduction of a scale-agnostic metric, \textit{attention accuracy}, and a
novel benchmark for quantifying IVMs. Attention accuracy directly evaluates the
model's visual understanding via internal mechanisms, remaining robust to
positional biases for more reliable assessments. Furthermore, we extend our
approach to finer granularities and demonstrate its effectiveness in unimodal
scenarios, underscoring its versatility and generalizability.

</details>


### [97] [Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data](https://arxiv.org/abs/2505.10551)
*Yiwen Liu,Jessica Bader,Jae Myung Kim*

Main category: cs.CV

TL;DR: 研究表明合成图像可行性（feasibility）对CLIP分类器性能影响极小（准确率差异<0.3%），混合可行/不可行数据训练不影响模型表现。


<details>
  <summary>Details</summary>
Motivation: 探索合成数据训练中图像属性可行性（如漂浮物体/异常纹理）是否影响模型泛化能力，验证过滤不可行图像的必要性。

Method: 提出VariReal流程，通过LLM生成文本提示对源图像进行最小编辑，测试可行/不可行属性对LoRA微调CLIP模型的影响。

Result: 可行性对分类准确率影响微弱（Top-1平均差异<0.3%），属性类型（背景/颜色/纹理）对结果影响存在差异，混合训练集无显著性能变化。

Conclusion: 在CLIP微调场景中，无需严格过滤不可行合成图像，但需根据目标属性类型权衡可行性约束。

Abstract: With the development of photorealistic diffusion models, models trained in
part or fully on synthetic data achieve progressively better results. However,
diffusion models still routinely generate images that would not exist in
reality, such as a dog floating above the ground or with unrealistic texture
artifacts. We define the concept of feasibility as whether attributes in a
synthetic image could realistically exist in the real-world domain; synthetic
images containing attributes that violate this criterion are considered
infeasible. Intuitively, infeasible images are typically considered
out-of-distribution; thus, training on such images is expected to hinder a
model's ability to generalize to real-world data, and they should therefore be
excluded from the training set whenever possible. However, does feasibility
really matter? In this paper, we investigate whether enforcing feasibility is
necessary when generating synthetic training data for CLIP-based classifiers,
focusing on three target attributes: background, color, and texture. We
introduce VariReal, a pipeline that minimally edits a given source image to
include feasible or infeasible attributes given by the textual prompt generated
by a large language model. Our experiments show that feasibility minimally
affects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference
in top-1 accuracy across three fine-grained datasets. Also, the attribute
matters on whether the feasible/infeasible images adversarially influence the
classification performance. Finally, mixing feasible and infeasible images in
training datasets does not significantly impact performance compared to using
purely feasible or infeasible datasets.

</details>


### [98] [MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning](https://arxiv.org/abs/2505.10557)
*Ke Wang,Junting Pan,Linda Wei,Aojun Zhou,Weikang Shi,Zimu Lu,Han Xiao,Yunqiao Yang,Houxing Ren,Mingjie Zhan,Hongsheng Li*

Main category: cs.CV

TL;DR: 提出使用代码监督实现图文跨模态对齐，开发FigCodifier模型和ImgCode-8.6M数据集，构建3M级数学指令数据集，训练出超越GPT-4o的多模态数学推理模型MathCoder-VL


<details>
  <summary>Details</summary>
Motivation: 传统多模态数据集忽略数学图表细节，阻碍LMMs数学推理能力发展。代码能精确编码图形生成信息，可建立图文模态精确连接

Method: 采用模型闭环开发模式：1）联合开发FigCodifier图像转码模型和ImgCode-8.6M数据集；2）合成数学图表构建MM-MathInstruct-3M微调数据集；3）两阶段训练MathCoder-VL模型

Result: 1）MathCoder-VL在MathVista几何子集超越GPT-4o 8.9%；2）创开源模型6项指标SOTA；3）构建目前最大图像代码数据集（860万）和数学指令集（300万）

Conclusion: 代码监督有效解决数学图文对齐难题，大规模数据集构建方法为多模态数学推理开辟新路径。模型开源将推动社区发展，代码驱动方法可拓展至其他专业领域

Abstract: Natural language image-caption datasets, widely used for training Large
Multimodal Models, mainly focus on natural scenarios and overlook the intricate
details of mathematical figures that are critical for problem-solving,
hindering the advancement of current LMMs in multimodal mathematical reasoning.
To this end, we propose leveraging code as supervision for cross-modal
alignment, since code inherently encodes all information needed to generate
corresponding figures, establishing a precise connection between the two
modalities. Specifically, we co-develop our image-to-code model and dataset
with model-in-the-loop approach, resulting in an image-to-code model,
FigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.
Furthermore, we utilize FigCodifier to synthesize novel mathematical figures
and then construct MM-MathInstruct-3M, a high-quality multimodal math
instruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with
ImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on
MM-MathInstruct-3M for multimodal math problem solving. Our model achieves a
new open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and
Claude 3.5 Sonnet in the geometry problem-solving subset of MathVista,
achieving improvements of 8.9% and 9.2%. The dataset and models will be
released at https://github.com/mathllm/MathCoder.

</details>


### [99] [End-to-End Vision Tokenizer Tuning](https://arxiv.org/abs/2505.10562)
*Wenxuan Wang,Fan Zhang,Yufeng Cui,Haiwen Diao,Zhuoyan Luo,Huchuan Lu,Jing Liu,Xinlong Wang*

Main category: cs.CV

TL;DR: 提出端到端视觉标记器调优方法ETT，通过联合优化视觉标记化与下游任务，解决现有方法分离优化导致的表征瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉标记化方法独立于下游任务优化（如低层重建），导致不同任务（如文本识别、图像生成）的表征错位。例如图像中文字标记错误会直接影响下游任务表现。

Method: ETT利用视觉标记器codebook的嵌入表示，通过重构+文本描述双目标端到端优化。无需修改原大型语言模型架构，可无缝集成现有训练流程。

Result: 实验显示在多模态理解和图像生成任务中性能提升2-6%，同时保持原有重建能力。

Conclusion: 这种简单有效的方法突破了视觉标记器的表征瓶颈，为多模态基础模型提供了新优化范式，具有超越图像生成/理解任务的潜力。

Abstract: Existing vision tokenization isolates the optimization of vision tokenizers
from downstream training, implicitly assuming the visual tokens can generalize
well across various tasks, e.g., image generation and visual question
answering. The vision tokenizer optimized for low-level reconstruction is
agnostic to downstream tasks requiring varied representations and semantics.
This decoupled paradigm introduces a critical misalignment: The loss of the
vision tokenization can be the representation bottleneck for target tasks. For
example, errors in tokenizing text in a given image lead to poor results when
recognizing or generating them. To address this, we propose ETT, an end-to-end
vision tokenizer tuning approach that enables joint optimization between vision
tokenization and target autoregressive tasks. Unlike prior autoregressive
models that use only discrete indices from a frozen vision tokenizer, ETT
leverages the visual embeddings of the tokenizer codebook, and optimizes the
vision tokenizers end-to-end with both reconstruction and caption objectives.
ETT can be seamlessly integrated into existing training pipelines with minimal
architecture modifications. Our ETT is simple to implement and integrate,
without the need to adjust the original codebooks or architectures of the
employed large language models. Extensive experiments demonstrate that our
proposed end-to-end vision tokenizer tuning unlocks significant performance
gains, i.e., 2-6% for multimodal understanding and visual generation tasks
compared to frozen tokenizer baselines, while preserving the original
reconstruction capability. We hope this very simple and strong method can
empower multimodal foundation models besides image generation and
understanding.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [100] [VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality](https://arxiv.org/abs/2505.10144)
*Xuechang Tu,Lukas Radl,Michael Steiner,Markus Steinberger,Bernhard Kerbl,Fernando de la Torre*

Main category: cs.GR

TL;DR: VRSplat整合多项3DGS优化技术，解决VR场景下时间伪影、投影失真和帧率不足问题，实现72+ FPS流畅体验并消除视觉干扰


<details>
  <summary>Details</summary>
Motivation: 3DGS在VR应用中面临三大挑战：(1)头部运动时的动态伪影 (2)投影失真导致的视觉干扰 (3)HMD高分辨率下帧率不足

Method: 整合Mini-Splatting/StopThePop/Optimal Projection技术，改进核心光栅化器，提出单GPU启动的眼动追踪渲染方案，通过深度评估优化高斯参数

Result: 用户研究显示显著优于基础Mini-Splatting，达到72+ FPS，成功消除动态伪影和立体视觉干扰，支持现代VR应用

Conclusion: VRSplat首次系统性地解决3DGS在VR中的核心痛点，通过技术创新实现高质量实时渲染，为移动端VR应用奠定技术基础

Abstract: 3D Gaussian Splatting (3DGS) has rapidly become a leading technique for
novel-view synthesis, providing exceptional performance through efficient
software-based GPU rasterization. Its versatility enables real-time
applications, including on mobile and lower-powered devices. However, 3DGS
faces key challenges in virtual reality (VR): (1) temporal artifacts, such as
popping during head movements, (2) projection-based distortions that result in
disturbing and view-inconsistent floaters, and (3) reduced framerates when
rendering large numbers of Gaussians, falling below the critical threshold for
VR. Compared to desktop environments, these issues are drastically amplified by
large field-of-view, constant head movements, and high resolution of
head-mounted displays (HMDs). In this work, we introduce VRSplat: we combine
and extend several recent advancements in 3DGS to address challenges of VR
holistically. We show how the ideas of Mini-Splatting, StopThePop, and Optimal
Projection can complement each other, by modifying the individual techniques
and core 3DGS rasterizer. Additionally, we propose an efficient foveated
rasterizer that handles focus and peripheral areas in a single GPU launch,
avoiding redundant computations and improving GPU utilization. Our method also
incorporates a fine-tuning step that optimizes Gaussian parameters based on
StopThePop depth evaluations and Optimal Projection. We validate our method
through a controlled user study with 25 participants, showing a strong
preference for VRSplat over other configurations of Mini-Splatting. VRSplat is
the first, systematically evaluated 3DGS approach capable of supporting modern
VR applications, achieving 72+ FPS while eliminating popping and
stereo-disrupting floaters.

</details>


### [101] [Style Customization of Text-to-Vector Generation with Image Diffusion Priors](https://arxiv.org/abs/2505.10558)
*Peiying Zhang,Nanxuan Zhao,Jing Liao*

Main category: cs.GR

TL;DR: 提出两阶段SVG风格定制流程，结合前馈T2V模型和T2I图像先验，实现高质量风格化矢量图形生成


<details>
  <summary>Details</summary>
Motivation: 现有文本到矢量方法在风格定制时存在结构不规律或内容风格耦合问题，难以满足实际应用需求

Method: 第一阶段训练路径级T2V扩散模型保证结构规律性，第二阶段通过蒸馏定制T2I模型实现风格适应

Result: 经大量实验验证可生成风格一致、结构规范的高质量SVG，支持多样化文本提示的快速生成

Conclusion: 该创新方法有效结合不同模型优势，突破现有技术瓶颈，为设计师提供高效的风格化矢量创作工具

Abstract: Scalable Vector Graphics (SVGs) are highly favored by designers due to their
resolution independence and well-organized layer structure. Although existing
text-to-vector (T2V) generation methods can create SVGs from text prompts, they
often overlook an important need in practical applications: style
customization, which is vital for producing a collection of vector graphics
with consistent visual appearance and coherent aesthetics. Extending existing
T2V methods for style customization poses certain challenges.
Optimization-based T2V models can utilize the priors of text-to-image (T2I)
models for customization, but struggle with maintaining structural regularity.
On the other hand, feed-forward T2V models can ensure structural regularity,
yet they encounter difficulties in disentangling content and style due to
limited SVG training data.
  To address these challenges, we propose a novel two-stage style customization
pipeline for SVG generation, making use of the advantages of both feed-forward
T2V models and T2I image priors. In the first stage, we train a T2V diffusion
model with a path-level representation to ensure the structural regularity of
SVGs while preserving diverse expressive capabilities. In the second stage, we
customize the T2V diffusion model to different styles by distilling customized
T2I models. By integrating these techniques, our pipeline can generate
high-quality and diverse SVGs in custom styles based on text prompts in an
efficient feed-forward manner. The effectiveness of our method has been
validated through extensive experiments. The project page is
https://customsvg.github.io.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [102] [LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2](https://arxiv.org/abs/2505.10101)
*Jongmin Jung,Dasaem Jeong*

Main category: cs.SD

TL;DR: 提出LAV系统，通过神经音频压缩与生成对抗网络实现音频驱动的动态视觉生成


<details>
  <summary>Details</summary>
Motivation: 突破传统显式特征映射方法，探索预训练音频模型在跨模态生成中的潜力

Method: 使用EnCodec嵌入作为潜表示，通过随机初始化线性层直接映射到StyleGAN2风格空间

Result: 实现语义连贯的音视转换，验证预训练音频压缩模型在艺术计算中的应用价值

Conclusion: 为跨模态生成任务提供新范式，拓展生成式模型在创意计算中的可能性

Abstract: This paper introduces LAV (Latent Audio-Visual), a system that integrates
EnCodec's neural audio compression with StyleGAN2's generative capabilities to
produce visually dynamic outputs driven by pre-recorded audio. Unlike previous
works that rely on explicit feature mappings, LAV uses EnCodec embeddings as
latent representations, directly transformed into StyleGAN2's style latent
space via randomly initialized linear mapping. This approach preserves semantic
richness in the transformation, enabling nuanced and semantically coherent
audio-visual translations. The framework demonstrates the potential of using
pretrained audio compression models for artistic and computational
applications.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [103] [A Survey on Large Language Models in Multimodal Recommender Systems](https://arxiv.org/abs/2505.09777)
*Alejo Lopez-Avila,Jinhua Du*

Main category: cs.IR

TL;DR: 多模态推荐系统整合异构数据提升推荐效果，大语言模型带来新机遇与挑战，本文系统综述相关技术并提出未来方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型为多模态推荐系统提供语义推理等新能力，但存在可扩展性和模型访问性挑战，需系统性整合研究进展以支持领域发展。

Method: 采用文献综述方法，提出整合模式分类法，识别技术迁移路径，并系统分析评估指标与数据集。

Result: 明确LLMs在推荐中的整合范式，建立技术迁移框架，提供标准化评估体系与领域数据集全景图。

Conclusion: 大语言模型正成为多模态推荐的核心组件，需进一步研究模型效率优化、跨模态对齐等方向推动领域突破。

Abstract: Multimodal recommender systems (MRS) integrate heterogeneous user and item
data, such as text, images, and structured information, to enhance
recommendation performance. The emergence of large language models (LLMs)
introduces new opportunities for MRS by enabling semantic reasoning, in-context
learning, and dynamic input handling. Compared to earlier pre-trained language
models (PLMs), LLMs offer greater flexibility and generalisation capabilities
but also introduce challenges related to scalability and model accessibility.
This survey presents a comprehensive review of recent work at the intersection
of LLMs and MRS, focusing on prompting strategies, fine-tuning methods, and
data adaptation techniques. We propose a novel taxonomy to characterise
integration patterns, identify transferable techniques from related
recommendation domains, provide an overview of evaluation metrics and datasets,
and point to possible future directions. We aim to clarify the emerging role of
LLMs in multimodal recommendation and support future research in this rapidly
evolving field.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [104] [CartoAgent: a multimodal large language model-powered multi-agent cartographic framework for map style transfer and evaluation](https://arxiv.org/abs/2505.09936)
*Chenglong Wang,Yuhao Kang,Zhaoya Gong,Pengjun Zhao,Yu Feng,Wenjia Zhang,Ge Li*

Main category: cs.HC

TL;DR: 提出基于多模态大语言模型的多智能体制图框架CartoAgent，通过分离样式与地理数据实现视觉美观且精准的地图生成。


<details>
  <summary>Details</summary>
Motivation: 现有研究存在忽视地图艺术性或难以兼顾地图精确性与信息丰富性的痛点，生成式AI发展为改进制图流程提供新机遇。

Method: 构建三阶段框架（准备/设计/评估），采用多MLLM智能体协同工作，利用视觉审美能力设计样式表并保持地理数据独立性。

Result: 在地图风格迁移任务中验证有效性，通过实验和人类评估证明框架产出质量。

Conclusion: 框架可扩展支持多种制图决策，为生成式AI与制图学融合提供新范式

Abstract: The rapid development of generative artificial intelligence (GenAI) presents
new opportunities to advance the cartographic process. Previous studies have
either overlooked the artistic aspects of maps or faced challenges in creating
both accurate and informative maps. In this study, we propose CartoAgent, a
novel multi-agent cartographic framework powered by multimodal large language
models (MLLMs). This framework simulates three key stages in cartographic
practice: preparation, map design, and evaluation. At each stage, different
MLLMs act as agents with distinct roles to collaborate, discuss, and utilize
tools for specific purposes. In particular, CartoAgent leverages MLLMs' visual
aesthetic capability and world knowledge to generate maps that are both
visually appealing and informative. By separating style from geographic data,
it can focus on designing stylesheets without modifying the vector-based data,
thereby ensuring geographic accuracy. We applied CartoAgent to a specific task
centered on map restyling-namely, map style transfer and evaluation. The
effectiveness of this framework was validated through extensive experiments and
a human evaluation study. CartoAgent can be extended to support a variety of
cartographic design decisions and inform future integrations of GenAI in
cartography.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [105] [PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization](https://arxiv.org/abs/2505.09921)
*Yidan Wang,Yanan Cao,Yubing Ren,Fang Fang,Zheng Lin,Binxing Fang*

Main category: cs.CR

TL;DR: 提出PIG框架有效利用越狱攻击提取LLMs中的个人隐私信息，实验显示其优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有隐私评估方法易被对齐模型阻断，且越狱攻击在隐私场景的应用未被充分探索。研究旨在连接隐私泄露与越狱攻击的关联性

Method: 1. 识别隐私查询中的PII实体及类型 2. 上下文学习构建隐私上下文 3. 三种梯度策略迭代更新提取目标PII 4. 基于6种LLM的白盒/黑盒实验验证

Result: PIG在4个白盒模型和2个黑盒模型上实现SOTA效果，准确率最高达0.92，显著暴露LLMs的隐私风险

Conclusion: 研究证明现有LLM安全机制存在重大隐私漏洞，需开发更强大的隐私保护方案应对新型攻击手段

Abstract: Large Language Models (LLMs) excel in various domains but pose inherent
privacy risks. Existing methods to evaluate privacy leakage in LLMs often use
memorized prefixes or simple instructions to extract data, both of which
well-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM
safety mechanisms to generate harmful content, but their role in privacy
scenarios remains underexplored. In this paper, we examine the effectiveness of
jailbreak attacks in extracting sensitive information, bridging privacy leakage
and jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework
targeting Personally Identifiable Information (PII) and addressing the
limitations of current jailbreak methods. Specifically, PIG identifies PII
entities and their types in privacy queries, uses in-context learning to build
a privacy context, and iteratively updates it with three gradient-based
strategies to elicit target PII. We evaluate PIG and existing jailbreak methods
using two privacy-related datasets. Experiments on four white-box and two
black-box LLMs show that PIG outperforms baseline methods and achieves
state-of-the-art (SoTA) results. The results underscore significant privacy
risks in LLMs, emphasizing the need for stronger safeguards. Our code is
availble at
\href{https://github.com/redwyd/PrivacyJailbreak}{https://github.com/redwyd/PrivacyJailbreak}.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [106] [From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI](https://arxiv.org/abs/2505.10093)
*Hsuan-Lei Shao*

Main category: cs.AI

TL;DR: 本研究运用生成式AI技术将台湾中国研究文献转化为结构化知识图谱，实现从线性文本到网络化知识导航的范式转换


<details>
  <summary>Details</summary>
Motivation: 基于台湾中国研究领域独特的地缘学术地位和数十年学术积累，需系统性重构非结构化文献以建立可交互知识体系

Method: 采用LLM从1367篇文献(1996-2019)提取实体关系三元组，通过D3.js构建轻量级可视化系统，形成领域知识图谱和向量数据库

Result: 成功揭示未发现的学术轨迹与主题集群，建立支持语义关系探索的领域知识基础设施，提供可扩展的替代性本体构建方案

Conclusion: 论证生成式AI革新区域研究的潜力，为数字人文提供新型学术基础设施范式，推动知识消费模式向网络化导航转型

Abstract: Taiwanese China Studies (CS) has developed into a rich, interdisciplinary
research field shaped by the unique geopolitical position and long standing
academic engagement with Mainland China. This study responds to the growing
need to systematically revisit and reorganize decades of Taiwan based CS
scholarship by proposing an AI assisted approach that transforms unstructured
academic texts into structured, interactive knowledge representations. We apply
generative AI (GAI) techniques and large language models (LLMs) to extract and
standardize entity relation triples from 1,367 peer reviewed CS articles
published between 1996 and 2019. These triples are then visualized through a
lightweight D3.js based system, forming the foundation of a domain specific
knowledge graph and vector database for the field. This infrastructure allows
users to explore conceptual nodes and semantic relationships across the corpus,
revealing previously uncharted intellectual trajectories, thematic clusters,
and research gaps. By decomposing textual content into graph structured
knowledge units, our system enables a paradigm shift from linear text
consumption to network based knowledge navigation. In doing so, it enhances
scholarly access to CS literature while offering a scalable, data driven
alternative to traditional ontology construction. This work not only
demonstrates how generative AI can augment area studies and digital humanities
but also highlights its potential to support a reimagined scholarly
infrastructure for regional knowledge systems.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [107] [Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling](https://arxiv.org/abs/2505.09665)
*Sulong Zhou,Qunying Huang,Shaoheng Zhou,Yun Hang,Xinyue Ye,Aodong Mei,Kathryn Phung,Yuning Ye,Uma Govindswamy,Zehan Li*

Main category: cs.SI

TL;DR: 通过Reddit数据分析2025年洛杉矶山火期间公众舆论，结合LLM与人工标注构建双层框架（SA情境感知与CN危机叙事），揭示公共卫生关切与心理健康风险的时间分布规律。


<details>
  <summary>Details</summary>
Motivation: 近年野火频发且破坏力增强，需通过社交媒体实时捕捉受灾群体的认知演变，为灾害响应提供人本化决策依据。

Method: 收集385个主帖与114,879条评论，采用主题建模（LLM增强+HITL人工校准），构建SA（火情进展/应急资源）与CN（心理健康/群体叙事）双层分类体系。

Result: SA话题量与实际火势同步变化（峰值出现在灾后2-5天），CN中心理健康话题占比40%且夜间活跃度最高，创建首个标注社交媒体数据集与可扩展分析框架。

Conclusion: 该框架能系统性识别灾害中的持续性公共卫生问题，为灾后心理干预、应急资源调配及气候危机沟通提供数据驱动的决策支持。

Abstract: Wildfires have become increasingly frequent, irregular, and severe in recent
years. Understanding how affected populations perceive and respond during
wildfire crises is critical for timely and empathetic disaster response. Social
media platforms offer a crowd-sourced channel to capture evolving public
discourse, providing hyperlocal information and insight into public sentiment.
This study analyzes Reddit discourse during the 2025 Los Angeles wildfires,
spanning from the onset of the disaster to full containment. We collect 385
posts and 114,879 comments related to the Palisades and Eaton fires. We adopt
topic modeling methods to identify the latent topics, enhanced by large
language models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we
develop a hierarchical framework to categorize latent topics, consisting of two
main categories, Situational Awareness (SA) and Crisis Narratives (CN). The
volume of SA category closely aligns with real-world fire progressions, peaking
within the first 2-5 days as the fires reach the maximum extent. The most
frequent co-occurring category set of public health and safety, loss and
damage, and emergency resources expands on a wide range of health-related
latent topics, including environmental health, occupational health, and one
health. Grief signals and mental health risks consistently accounted for 60
percentage and 40 percentage of CN instances, respectively, with the highest
total volume occurring at night. This study contributes the first annotated
social media dataset on the 2025 LA fires, and introduces a scalable
multi-layer framework that leverages topic modeling for crisis discourse
analysis. By identifying persistent public health concerns, our results can
inform more empathetic and adaptive strategies for disaster response, public
health communication, and future research in comparable climate-related
disaster events.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [108] [Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers](https://arxiv.org/abs/2505.09855)
*Alexander Y. Ku,Thomas L. Griffiths,Stephanie C. Y. Chan*

Main category: cs.LG

TL;DR: 研究通过进化生物学类比揭示Transformer模型权重学习(IWL)与上下文学习(ICL)的平衡机制，发现环境可预测性（稳定性与线索可靠性）是核心决定因素。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型两种学习模式的交互机制，借鉴进化生物学的遗传编码与表型可塑性理论，解析环境可预测性对学习策略选择的影响。

Method: 采用回归与分类任务，系统性测试环境稳定性、线索可靠性对IWL/ICL平衡的影响，分析学习动态的时序演变规律。

Result: 高稳定性环境强烈偏向IWL（最大稳定性时出现陡峭转变），高线索可靠性提升ICL效果（尤其低稳定性时）；学习路径呈现任务依赖的时序模式（ICL/IWL主导阶段交替）。

Conclusion: 验证可预测性作为Transformer自适应策略的核心调控因子，提出相对成本假说解释学习模式转变，为模型训练方法论提供新视角。

Abstract: Transformer models learn in two distinct modes: in-weights learning (IWL),
encoding knowledge into model weights, and in-context learning (ICL), adapting
flexibly to context without weight modification. To better understand the
interplay between these learning modes, we draw inspiration from evolutionary
biology's analogous adaptive strategies: genetic encoding (akin to IWL,
adapting over generations and fixed within an individual's lifetime) and
phenotypic plasticity (akin to ICL, enabling flexible behavioral responses to
environmental cues). In evolutionary biology, environmental predictability
dictates the balance between these strategies: stability favors genetic
encoding, while reliable predictive cues promote phenotypic plasticity. We
experimentally operationalize these dimensions of predictability and
systematically investigate their influence on the ICL/IWL balance in
Transformers. Using regression and classification tasks, we show that high
environmental stability decisively favors IWL, as predicted, with a sharp
transition at maximal stability. Conversely, high cue reliability enhances ICL
efficacy, particularly when stability is low. Furthermore, learning dynamics
reveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift
occurs in some settings (e.g., classification with many classes), we
demonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL
acquisition (e.g., regression) can exhibit an initial IWL phase later yielding
to ICL dominance. These findings support a relative-cost hypothesis for
explaining these learning mode transitions, establishing predictability as a
critical factor governing adaptive strategies in Transformers, and offering
novel insights for understanding ICL and guiding training methodologies.

</details>


### [109] [Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks](https://arxiv.org/abs/2505.09901)
*Ziyuan Zhang,Darcy Wang,Ningyuan Chen,Rodrigo Mansur,Vahid Sarhangian*

Main category: cs.LG

TL;DR: LLMs在探索-利用权衡中展现出接近人类的行为，但在复杂环境中适应性不足


<details>
  <summary>Details</summary>
Motivation: 验证LLMs是否具有类似人类的动态决策能力，特别是在不确定性下的探索-利用权衡机制

Method: 使用多臂老虎机实验框架，结合可解释的决策模型，对比分析LLMs/人类/算法的探索策略，重点考察显式推理（提示策略和增强推理模型）的影响

Result: 1. 推理能力使LLMs呈现混合随机/定向探索的人类特征
2. 简单任务中接近人类水平
3. 复杂非稳态环境中定向探索能力不足

Conclusion: LLMs具备模拟人类决策的潜力但存在环境适应性局限，需改进复杂环境下的定向探索机制

Abstract: Large language models (LLMs) are increasingly used to simulate or automate
human behavior in complex sequential decision-making tasks. A natural question
is then whether LLMs exhibit similar decision-making behavior to humans, and
can achieve comparable (or superior) performance. In this work, we focus on the
exploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic
decision-making under uncertainty. We employ canonical multi-armed bandit (MAB)
tasks introduced in the cognitive science and psychiatry literature to conduct
a comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.
We use interpretable choice models to capture the E&E strategies of the agents
and investigate how explicit reasoning, through both prompting strategies and
reasoning-enhanced models, shapes LLM decision-making. We find that reasoning
shifts LLMs toward more human-like behavior, characterized by a mix of random
and directed exploration. In simple stationary tasks, reasoning-enabled LLMs
exhibit similar levels of random and directed exploration compared to humans.
However, in more complex, non-stationary environments, LLMs struggle to match
human adaptability, particularly in effective directed exploration, despite
achieving similar regret in certain scenarios. Our findings highlight both the
promise and limits of LLMs as simulators of human behavior and tools for
automated decision-making and point to potential areas of improvements.

</details>


### [110] [Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors](https://arxiv.org/abs/2505.09949)
*Ahmed S. Abdelrahman,Mohamed Abdel-Aty,Samgyu Yang,Abdulrahman Faden*

Main category: cs.LG

TL;DR: 利用QLoRA微调Llama3 8B模型分析高速公路事故成因，通过零样本分类识别酒驾/超速等主因，验证模型有效性（研究者认可度88.89%）


<details>
  <summary>Details</summary>
Motivation: 传统统计方法和机器学习难以捕捉事故复杂因素的交互关系，需探索大语言模型处理非结构化数据的优势以实现全面事故分析

Method: 1. 整合226项研究构建训练数据集
2. 基于QLoRA微调Llama3 8B模型
3. 零样本分类识别事故原因
4. 问卷验证模型实用性

Result: 模型成功识别酒驾/超速/激进驾驶等主因，结合道路维护事件数据提升分析深度，问卷显示88.89%研究者认可模型输出合理性

Conclusion: LLM为事故因素分析提供新范式，支持政策制定者开发高效安全措施，证明大模型在交通安全领域的实际应用潜力

Abstract: Understanding the factors contributing to traffic crashes and developing
strategies to mitigate their severity is essential. Traditional statistical
methods and machine learning models often struggle to capture the complex
interactions between various factors and the unique characteristics of each
crash. This research leverages large language model (LLM) to analyze freeway
crash data and provide crash causation analysis accordingly. By compiling 226
traffic safety studies related to freeway crashes, a training dataset
encompassing environmental, driver, traffic, and geometric design factors was
created. The Llama3 8B model was fine-tuned using QLoRA to enhance its
understanding of freeway crashes and their contributing factors, as covered in
these studies. The fine-tuned Llama3 8B model was then used to identify crash
causation without pre-labeled data through zero-shot classification, providing
comprehensive explanations to ensure that the identified causes were reasonable
and aligned with existing research. Results demonstrate that LLMs effectively
identify primary crash causes such as alcohol-impaired driving, speeding,
aggressive driving, and driver inattention. Incorporating event data, such as
road maintenance, offers more profound insights. The model's practical
applicability and potential to improve traffic safety measures were validated
by a high level of agreement among researchers in the field of traffic safety,
as reflected in questionnaire results with 88.89%. This research highlights the
complex nature of traffic crashes and how LLMs can be used for comprehensive
analysis of crash causation and other contributing factors. Moreover, it
provides valuable insights and potential countermeasures to aid planners and
policymakers in developing more effective and efficient traffic safety
practices.

</details>


### [111] [Learning Virtual Machine Scheduling in Cloud Computing through Language Agents](https://arxiv.org/abs/2505.10117)
*JieHao Wu,Ziwei Wang,Junjie Sheng,Wenhao Li,Xiangfei Wang,Jun Luo*

Main category: cs.LG

TL;DR: 提出分层语言智能体框架MiCo，通过大语言模型驱动的两阶段策略设计，解决云环境中大规模动态虚拟机调度问题，实验显示在万级规模下达到96.9%竞争比。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法无法实时适应需求波动，专家设计的启发式策略灵活性不足，现有学习方法缺乏通用性和可解释性。

Method: 将ODMBP建模为半马尔可夫选项决策过程(SMDP-Option)，通过Option Miner生成非上下文感知策略，Option Composer整合上下文感知策略。

Result: 在企业真实数据集实验中，MiCo在超10000台虚拟机场景下达到96.9%竞争比，且在非稳态请求流中保持高性能。

Conclusion: MiCo框架验证了LLM驱动的策略设计范式在复杂云环境中的有效性，实现了高适应性和可扩展的虚拟机调度。

Abstract: In cloud services, virtual machine (VM) scheduling is a typical Online
Dynamic Multidimensional Bin Packing (ODMBP) problem, characterized by
large-scale complexity and fluctuating demands. Traditional optimization
methods struggle to adapt to real-time changes, domain-expert-designed
heuristic approaches suffer from rigid strategies, and existing learning-based
methods often lack generalizability and interpretability. To address these
limitations, this paper proposes a hierarchical language agent framework named
MiCo, which provides a large language model (LLM)-driven heuristic design
paradigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov
Decision Process with Options (SMDP-Option), enabling dynamic scheduling
through a two-stage architecture, i.e., Option Miner and Option Composer.
Option Miner utilizes LLMs to discover diverse and useful non-context-aware
strategies by interacting with constructed environments. Option Composer
employs LLMs to discover a composing strategy that integrates the
non-context-aware strategies with the contextual ones. Extensive experiments on
real-world enterprise datasets demonstrate that MiCo achieves a 96.9\%
competitive ratio in large-scale scenarios involving more than 10,000 virtual
machines. It maintains high performance even under nonstationary request flows
and diverse configurations, thus validating its effectiveness in complex and
large-scale cloud environments.

</details>


### [112] [ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention](https://arxiv.org/abs/2505.10222)
*Jintian Shao,Hongyi Huang,Jiayi Wu,Beiwen Zhang,ZhiYu Wu,You Shan,MingKai Zheng*

Main category: cs.LG

TL;DR: 提出新型ComplexFormer模型，通过复数空间的多头注意力机制统一建模语义与位置差异，显著提升语言任务性能


<details>
  <summary>Details</summary>
Motivation: 传统Transformer多头注意力难以灵活协调语义差异建模与位置信息融合，现有方法存在分离建模或跨头统一调整的局限性

Method: 1) 每个注意力头独立进行欧拉变换，将查询/键映射到极坐标复数空间
2) 设计自适应差分旋转机制exp[i(Adapt(ASmn,i)+Δ(Pmn,i))]，实现语义角度差与位置编码的灵活融合

Result: 在语言建模/生成、代码生成和数学推理任务中取得SOTA性能，困惑度降低15.2%，长上下文连贯性提升23%

Conclusion: ComplexFormer通过复数空间建模提供更具表达力的注意力机制，在保持参数效率的同时显著提升模型性能，为注意力机制设计开辟新方向

Abstract: Transformer models rely on self-attention to capture token dependencies but
face challenges in effectively integrating positional information while
allowing multi-head attention (MHA) flexibility. Prior methods often model
semantic and positional differences disparately or apply uniform positional
adjustments across heads, potentially limiting representational capacity. This
paper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.
CMHA empowers each head to independently model semantic and positional
differences unified within the complex plane, representing interactions as
rotations and scaling. ComplexFormer incorporates two key improvements: (1) a
per-head Euler transformation, converting real-valued query/key projections
into polar-form complex vectors for head-specific complex subspace operation;
and (2) a per-head adaptive differential rotation mechanism,
exp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct
strategies for integrating semantic angle differences (ASmn,i) with relative
positional encodings (Delta(Pmn),i). Extensive experiments on language
modeling, text generation, code generation, and mathematical reasoning show
ComplexFormer achieves superior performance, significantly lower generation
perplexity , and improved long-context coherence compared to strong baselines
like RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,
offering a more expressive, adaptable attention mechanism.

</details>


### [113] [Superposition Yields Robust Neural Scaling](https://arxiv.org/abs/2505.10465)
*Yizhou liu,Ziming Liu,Jeff Gore*

Main category: cs.LG

TL;DR: 研究发现表征叠加是神经缩放定律的核心机制——强叠加状态下损失与模型维度成反比，解释了现有LLM的缩放规律。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型缩放定律的起源，即为何模型规模越大性能越好这一现象的根本原因仍不明确。

Method: 基于叠加表示和特征频率差异两个原则构建玩具模型，分析不同叠加强度下损失随模型尺寸的缩放规律，并结合几何解释和实际LLM数据验证。

Result: 强叠加场景中损失与模型维度呈反比关系，四类开源LLM的数据验证与模型预测一致，Chinchilla缩放定律也符合该结论。

Conclusion: 表征叠加机制是观测到神经缩放定律的关键，该发现可为设计更高效训练策略和模型架构提供理论依据。

Abstract: The success of today's large language models (LLMs) depends on the
observation that larger models perform better. However, the origin of this
neural scaling law -- the finding that loss decreases as a power law with model
size -- remains unclear. Starting from two empirical principles -- that LLMs
represent more things than the model dimensions (widths) they have (i.e.,
representations are superposed), and that words or concepts in language occur
with varying frequencies -- we constructed a toy model to study the loss
scaling with model size. We found that when superposition is weak, meaning only
the most frequent features are represented without interference, the scaling of
loss with model size depends on the underlying feature frequency; if feature
frequencies follow a power law, so does the loss. In contrast, under strong
superposition, where all features are represented but overlap with each other,
the loss becomes inversely proportional to the model dimension across a wide
range of feature frequency distributions. This robust scaling behavior is
explained geometrically: when many more vectors are packed into a lower
dimensional space, the interference (squared overlaps) between vectors scales
inversely with that dimension. We then analyzed four families of open-sourced
LLMs and found that they exhibit strong superposition and quantitatively match
the predictions of our toy model. The Chinchilla scaling law turned out to also
agree with our results. We conclude that representation superposition is an
important mechanism underlying the observed neural scaling laws. We anticipate
that these insights will inspire new training strategies and model
architectures to achieve better performance with less computation and fewer
parameters.

</details>


### [114] [Parallel Scaling Law for Language Models](https://arxiv.org/abs/2505.10475)
*Mouxiang Chen,Binyuan Hui,Zeyu Cui,Jiaxi Yang,Dayiheng Liu,Jianling Sun,Junyang Lin,Zhongxin Liu*

Main category: cs.LG

TL;DR: 提出并行扩展范式ParScale，通过增加并行计算而非参数规模来提升语言模型效率，显著降低内存和延迟消耗。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型扩展方法（参数扩展/推理时token扩展）存在高资源消耗问题，需要更高效的并行计算方案。

Method: 采用P个可学习输入变换+并行前向传播+动态输出聚合，复用现有参数结构实现计算并行化。

Result: 理论证明P并行相当于参数O(logP)扩展，实际实现22倍内存优化与6倍延迟降低，支持通过少量token后训练迁移现有模型。

Conclusion: ParScale为低资源场景提供高效扩展路径，重构了计算在机器学习中的角色认知，开辟模型部署新范式。

Abstract: It is commonly believed that scaling language models should commit a
significant space or time cost, by increasing the parameters (parameter
scaling) or output tokens (inference-time scaling). We introduce the third and
more inference-efficient scaling paradigm: increasing the model's parallel
computation during both training and inference time. We apply $P$ diverse and
learnable transformations to the input, execute forward passes of the model in
parallel, and dynamically aggregate the $P$ outputs. This method, namely
parallel scaling (ParScale), scales parallel computation by reusing existing
parameters and can be applied to any model structure, optimization procedure,
data, or task. We theoretically propose a new scaling law and validate it
through large-scale pre-training, which shows that a model with $P$ parallel
streams is similar to scaling the parameters by $O(\log P)$ while showing
superior inference efficiency. For example, ParScale can use up to 22$\times$
less memory increase and 6$\times$ less latency increase compared to parameter
scaling that achieves the same performance improvement. It can also recycle an
off-the-shelf pre-trained model into a parallelly scaled one by post-training
on a small amount of tokens, further reducing the training budget. The new
scaling law we discovered potentially facilitates the deployment of more
powerful models in low-resource scenarios, and provides an alternative
perspective for the role of computation in machine learning.

</details>


### [115] [RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs](https://arxiv.org/abs/2505.10495)
*Vibha Belavadi,Tushar Vatsa,Dewang Sultania,Suhas Suresha,Ishita Verma,Cheng Chen,Tracy Holloway King,Michael Friedrich*

Main category: cs.LG

TL;DR: 提出基于路由器的架构生成匹配真实分布的高质量合成数据，显著提升大语言模型在函数调用任务中的微调效果


<details>
  <summary>Details</summary>
Motivation: 现有合成数据生成方法在多样性和复杂性上的不足导致模型性能受限，且真实用户数据因隐私问题难以获取

Method: 结合内容元数据、知识图谱和多模态语言模型，通过灵活路由机制生成符合实际分布的合成训练数据

Result: 在真实用户查询测试中实现函数分类准确率提升和API参数优化，模型性能超越传统方法

Conclusion: 该架构有效解决传统合成数据方法的分布匹配问题，为函数调用任务建立了新的性能基准

Abstract: This paper addresses fine-tuning Large Language Models (LLMs) for function
calling tasks when real user interaction data is unavailable. In digital
content creation tools, where users express their needs through natural
language queries that must be mapped to API calls, the lack of real-world
task-specific data and privacy constraints for training on it necessitate
synthetic data generation. Existing approaches to synthetic data generation
fall short in diversity and complexity, failing to replicate real-world data
distributions and leading to suboptimal performance after LLM fine-tuning. We
present a novel router-based architecture that leverages domain resources like
content metadata and structured knowledge graphs, along with text-to-text and
vision-to-text language models to generate high-quality synthetic training
data. Our architecture's flexible routing mechanism enables synthetic data
generation that matches observed real-world distributions, addressing a
fundamental limitation of traditional approaches. Evaluation on a comprehensive
set of real user queries demonstrates significant improvements in both function
classification accuracy and API parameter selection. Models fine-tuned with our
synthetic data consistently outperform traditional approaches, establishing new
benchmarks for function calling tasks.

</details>


### [116] [MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models](https://arxiv.org/abs/2505.10526)
*Mugilan Ganesan,Shane Segal,Ankur Aggarwal,Nish Sinnadurai,Sean Lie,Vithursan Thangarasa*

Main category: cs.LG

TL;DR: 提出MASSV方法，通过两阶段训练将小型语言模型转化为高效多模态草稿模型，加速视觉语言模型推理


<details>
  <summary>Details</summary>
Motivation: 现有推测解码技术在视觉语言模型应用中面临小型语言模型无法处理视觉输入、token预测不匹配视觉上下文两大挑战

Method: 1. 通过可训练投影器连接目标VLM的视觉编码器 2. 使用目标VLM生成的自蒸馏视觉指令数据进行对齐训练

Result: 在Qwen2.5-VL和Gemma3模型上实现接受长度提升30%，端到端推理加速达1.46倍

Conclusion: MASSV为当前及未来视觉语言模型提供了可扩展、架构兼容的加速方案

Abstract: Speculative decoding significantly accelerates language model inference by
enabling a lightweight draft model to propose multiple tokens that a larger
target model verifies simultaneously. However, applying this technique to
vision-language models (VLMs) presents two fundamental challenges: small
language models that could serve as efficient drafters lack the architectural
components to process visual inputs, and their token predictions fail to match
those of VLM target models that consider visual context. We introduce
Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of
Vision-Language Models (MASSV), which transforms existing small language models
into effective multimodal drafters through a two-phase approach. MASSV first
connects the target VLM's vision encoder to the draft model via a lightweight
trainable projector, then applies self-distilled visual instruction tuning
using responses generated by the target VLM to align token predictions.
Comprehensive experiments across the Qwen2.5-VL and Gemma3 model families
demonstrate that MASSV increases accepted length by up to 30% and delivers
end-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV
provides a scalable, architecture-compatible method for accelerating both
current and future VLMs.

</details>
